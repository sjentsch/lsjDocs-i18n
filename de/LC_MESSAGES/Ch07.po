msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-06-12 11:37+0200\n"
"PO-Revision-Date: 2025-07-02 12:43+0000\n"
"Last-Translator: Sebastian Jentschke <sebastian.jentschke@uib.no>\n"
"Language-Team: German <https://hosted.weblate.org/projects/lsjdocs/ch07/de/>"
"\n"
"Language: de\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"X-Generator: Weblate 5.13-dev\n"
"Generated-By: Babel 2.10.3\n"

#: ../../Ch07/Ch07_Probability.rst:4
msgid "Introduction to probability"
msgstr "Einführung in die Wahrscheinlichkeitsrechnung"

#: ../../Ch07/Ch07_Probability.rst:0
msgid "*[God] has afforded us only the twilight … of Probability.*"
msgstr "*[Gott] hat uns nur das Zwielicht … der Wahrscheinlichkeit geschenkt.*"

#: ../../Ch07/Ch07_Probability.rst:23
msgid "John Locke"
msgstr "John Locke"

#: ../../Ch07/Ch07_Probability.rst:25
msgid ""
"Up to this point in the book we’ve discussed some of the key ideas in "
"experimental design, and we’ve talked a little about how you can summarise a "
"data set. To a lot of people this is all there is to statistics: collecting "
"all the numbers, calculating averages, drawing pictures, and putting them "
"all in a report somewhere. Kind of like stamp collecting but with numbers. "
"However, statistics covers much more than that. In fact, descriptive "
"statistics is one of the smallest parts of statistics and one of the least "
"powerful. The bigger and more useful part of statistics is that it provides "
"information that lets you make inferences about data."
msgstr ""
"Bis zu diesem Punkt in diesem Buch haben wir einige der wichtigsten Ideen "
"zur Versuchsplanung erörtert und ein wenig darüber gesprochen, wie man einen "
"Datensatz zusammenfassen kann. Für viele Menschen ist das alles, was "
"Statistik ausmacht: alle Zahlen sammeln, Durchschnittswerte berechnen, "
"Bilder zeichnen und alles irgendwo in einen Bericht packen. Ein bisschen wie "
"Briefmarkensammeln, aber mit Zahlen. Statistik umfasst jedoch viel mehr als "
"das. Tatsächlich ist die deskriptive Statistik einer der kleinsten Teile der "
"Statistik und einer der am wenigsten leistungsfähigen. Der größere und "
"nützlichere Teil der Statistik besteht darin, dass sie Informationen "
"liefert, die Rückschlüsse auf die Daten zulassen."

#: ../../Ch07/Ch07_Probability.rst:36
msgid ""
"Once you start thinking about statistics in these terms, that statistics is "
"there to help us draw inferences from data, you start seeing examples of it "
"everywhere. For instance, here’s a tiny extract from a newspaper article in "
"the Sydney Morning Herald (30 Oct 2010):"
msgstr ""
"Sobald man anfängt, über Statistik in diesem Sinne zu denken, nämlich dass "
"Statistik dazu da ist, uns dabei zu helfen, Schlüsse aus Daten zu ziehen, "
"sieht man überall Beispiele dafür. Hier zum Beispiel ein kleiner Auszug aus "
"einem Zeitungsartikel im *Sydney Morning Herald* (30. Oktober 2010):"

#: ../../Ch07/Ch07_Probability.rst:41
msgid ""
"“I have a tough job,” the Premier said in response to a poll which found her "
"government is now the most unpopular Labor administration in polling "
"history, with a primary vote of just 23 per cent."
msgstr ""
"„Ich habe einen harten Job“, sagte die Premierministerin als Reaktion auf "
"eine Umfrage, die ergab, dass ihre Regierung mit einem Stimmenanteil von nur "
"23 Prozent die unbeliebteste Regierung in der Geschichte der "
"Meinungsumfragen ist."

#: ../../Ch07/Ch07_Probability.rst:45
msgid ""
"This kind of remark is entirely unremarkable in the papers or in everyday "
"life, but let’s have a think about what it entails. A polling company has "
"conducted a survey, usually a pretty big one because they can afford it. I’m "
"too lazy to track down the original survey so let’s just imagine that they "
"called 1000 New South Wales (NSW) voters at random, and 230 (23\\%) of those "
"claimed that they intended to vote for the Australian Labor Party (ALP). For "
"the 2010 Federal election the Australian Electoral Commission reported "
"4,610,795 enrolled voters in NSW, so the opinions of the remaining 4,609,795 "
"voters (about 99.98\\% of voters) remain unknown to us. Even assuming that "
"no-one lied to the polling company the only thing we can say with 100\\% "
"confidence is that the true ALP primary vote is somewhere between "
"230/4610795 (about \\0.005\\%) and 4610025/4610795 (about 99.83\\%). So, on "
"what basis is it legitimate for the polling company, the newspaper, and the "
"readership to conclude that the ALP primary vote is only about 23\\%?"
msgstr ""
"Diese Art von Bemerkung ist in den Zeitungen oder im Alltag völlig "
"unauffällig, aber denken wir einmal darüber nach, was sie bedeutet. Ein "
"Meinungsforschungsinstitut hat eine Umfrage durchgeführt, in der Regel eine "
"ziemlich große, weil sie es sich leisten können. Ich bin zu faul, um die "
"Originalumfrage ausfindig zu machen, also stellen wir uns einfach vor, dass "
"1000 Wähler aus New South Wales (NSW) nach dem Zufallsprinzip angerufen "
"wurden und 230 (23 %) von ihnen angaben, dass sie beabsichtigten, für die "
"Australian Labor Party (ALP) zu stimmen. Für die Parlamentswahl 2010 meldete "
"die australische Wahlkommission 4 610 795 registrierte Wähler in NSW, so "
"dass uns die Meinung der übrigen 4 609 795 Wähler (etwa 99,98 % der Wähler) "
"unbekannt bleibt. Selbst wenn man davon ausgeht, dass niemand das "
"Meinungsforschungsinstitut belogen hat, können wir mit 100 % "
"Wahrscheinlichkeit nur sagen, dass das wahre Ergebnis der ALP-Vorwahlen "
"irgendwo zwischen 230 / 4610795 (etwa 0,005 %) und 4610025 / 4610795 (etwa "
"99,83 %) liegt. Auf welcher Grundlage ist es also legitim, dass das "
"Meinungsforschungsinstitut, die Zeitung und die Leserschaft zu dem Schluss "
"kommen, dass die Vorzugsstimmen der ALP nur etwa 23 % betragen?"

#: ../../Ch07/Ch07_Probability.rst:61
msgid ""
"The answer to the question is pretty obvious. If I call 1000 people at "
"random, and 230 of them say they intend to vote for the ALP, then it seems "
"very unlikely that these are the *only* 230 people out of the entire voting "
"public who actually intend to vote ALP. In other words, we assume that the "
"data collected by the polling company is pretty representative of the "
"population at large. But how representative? Would we be surprised to "
"discover that the true ALP primary vote is actually 24\\%? 29\\%? 37\\%? At "
"this point everyday intuition starts to break down a bit. No-one would be "
"surprised by 24\\%, and everybody would be surprised by 37\\%, but it’s a "
"bit hard to say whether 29\\% is plausible. We need some more powerful tools "
"than just looking at the numbers and guessing."
msgstr ""
"Die Antwort auf diese Frage ist ziemlich offensichtlich. Wenn ich 1000 "
"Personen nach dem Zufallsprinzip anrufe und 230 von ihnen sagen, dass sie "
"beabsichtigen, die ALP zu wählen, dann ist es sehr unwahrscheinlich, dass "
"dies die *nur* 230 Personen der gesamten Wählerschaft sind, die tatsächlich "
"beabsichtigen, die ALP zu wählen. Mit anderen Worten: Wir gehen davon aus, "
"dass die vom Meinungsforschungsinstitut erhobenen Daten ziemlich "
"repräsentativ für die Gesamtbevölkerung sind. Aber wie repräsentativ sind "
"sie? Würde es uns überraschen, wenn wir herausfänden, dass das tatsächliche "
"Wahlergebnis der ALP in den Vorwahlen bei 24 % liegt? 29 %? 37 %? An diesem "
"Punkt beginnt die alltägliche Intuition ein wenig zu versagen. Niemand wäre "
"von 24 % überrascht, und jeder wäre von 37 % überrascht, aber es ist ein "
"bisschen schwierig zu sagen, ob 29 % plausibel ist. Wir brauchen "
"leistungsfähigere Instrumente, als nur auf die Zahlen zu schauen und zu "
"raten."

#: ../../Ch07/Ch07_Probability.rst:73
msgid ""
"**Inferential statistics** provides the tools that we need to answer these "
"sorts of questions, and since these kinds of questions lie at the heart of "
"the scientific enterprise, they take up the lions share of every "
"introductory course on statistics and research methods. However, the theory "
"of statistical inference is built on top of **probability theory**. And it "
"is to probability theory that we must now turn. This discussion of "
"probability theory is basically background detail. There’s not a lot of "
"statistics per se in this chapter, and you don’t need to understand this "
"material in as much depth as the other chapters in this part of the book. "
"Nevertheless, because probability theory does underpin so much of "
"statistics, it’s worth covering some of the basics."
msgstr ""
"Die **Inferenzstatistik** liefert die Werkzeuge, die wir zur Beantwortung "
"dieser Art von Fragen benötigen. Da diese Art von Fragen im Mittelpunkt des "
"wissenschaftlichen Betriebs stehen, nehmen sie den Löwenanteil jedes "
"Einführungskurses in Statistik und Forschungsmethoden ein. Die Theorie der "
"statistischen Schlussfolgerungen baut jedoch auf der "
"**Wahrscheinlichkeitstheorie** auf. Und der Wahrscheinlichkeitstheorie "
"müssen wir uns nun zuwenden. Die Erörterung der Wahrscheinlichkeitstheorie "
"ist im Wesentlichen eine Hintergrundinformation. In diesem Kapitel geht es "
"nicht um Statistik an sich, und Sie müssen dieses Material nicht so "
"gründlich verstehen wie die anderen Kapitel in diesem Teil des Buches. Da "
"die Wahrscheinlichkeitstheorie jedoch einen großen Teil der Statistik "
"untermauert, lohnt es sich, einige der Grundlagen zu behandeln."

#: ../../Ch07/Ch07_Probability_1.rst:4
msgid "How are probability and statistics different?"
msgstr "Was ist der Unterschied zwischen Wahrscheinlichkeit und Statistik?"

#: ../../Ch07/Ch07_Probability_1.rst:6
msgid ""
"Before we start talking about probability theory, it’s helpful to spend a "
"moment thinking about the relationship between probability and statistics. "
"The two disciplines are closely related but they’re not identical. "
"Probability theory is “the doctrine of chances”. It’s a branch of "
"mathematics that tells you how often different kinds of events will happen. "
"For example, all of these questions are things you can answer using "
"probability theory:"
msgstr ""
"Bevor wir uns mit der Wahrscheinlichkeitstheorie befassen, ist es hilfreich, "
"einen Moment über die Beziehung zwischen Wahrscheinlichkeit und Statistik "
"nachzudenken. Die beiden Disziplinen sind eng miteinander verwandt, aber sie "
"sind nicht identisch. Die Wahrscheinlichkeitstheorie ist „die Lehre vom "
"Zufallsgeschehen“. Es handelt sich um einen Zweig der Mathematik, der "
"angibt, wie oft verschiedene Arten von Ereignissen eintreten werden. Alle "
"diese Fragen lassen sich zum Beispiel mit Hilfe der "
"Wahrscheinlichkeitstheorie beantworten:"

#: ../../Ch07/Ch07_Probability_1.rst:14
msgid "What are the chances of a fair coin coming up heads 10 times in a row?"
msgstr ""
"Wie hoch ist die Wahrscheinlichkeit, dass eine Münze 10 Mal hintereinander "
"Kopf zeigt?"

#: ../../Ch07/Ch07_Probability_1.rst:17
msgid ""
"If I roll a six sided dice twice, how likely is it that I’ll roll two sixes?"
msgstr ""
"Wenn ich einen sechsseitigen Würfel zweimal werfe, wie wahrscheinlich ist "
"es, dass ich zwei Sechsen werfe?"

#: ../../Ch07/Ch07_Probability_1.rst:20
msgid ""
"How likely is it that five cards drawn from a perfectly shuffled deck will "
"all be hearts?"
msgstr ""
"Wie wahrscheinlich ist es, dass fünf Karten, die aus einem perfekt "
"gemischten Stapel gezogen werden, alle die Kartenfarbe Herz haben?"

#: ../../Ch07/Ch07_Probability_1.rst:23
msgid "What are the chances that I’ll win the lottery?"
msgstr "Wie stehen die Chancen, dass ich im Lotto gewinne?"

#: ../../Ch07/Ch07_Probability_1.rst:25
msgid ""
"Notice that all of these questions have something in common. In each case "
"the “truth of the world” is known and my question relates to the “what kind "
"of events” will happen. In the first question I *know* that the coin is fair "
"so there’s a 50\\% chance that any individual coin flip will come up heads. "
"In the second question I *know* that the chance of rolling a 6 on a single "
"die is 1 in 6. In the third question I *know* that the deck is shuffled "
"properly. And in the fourth question I *know* that the lottery follows "
"specific rules. You get the idea. The critical point is that probabilistic "
"questions start with a known **model** of the world, and we use that model "
"to do some calculations. The underlying model can be quite simple. For "
"instance, in the coin flipping example we can write down the model like this:"
msgstr ""
"Beachten Sie, dass alle diese Fragen etwas gemeinsam haben. In jedem Fall "
"ist die „Wahrheit der Welt“ bekannt und meine Frage bezieht sich auf die "
"„welche Art von Ereignissen“ eintreten könnten. In der ersten Frage *weiß* "
"ich, dass wenn die Münze echt ist, die Wahrscheinlichkeit dafür, dass ein "
"Münzwurf Kopf ergibt, 50 % ist. Bei der zweiten Frage *weiß ich*, dass die "
"Wahrscheinlichkeit, eine 6 zu würfeln, 1 zu 6 ist. Bei der dritten Frage "
"*weiß* ich, dass das Kartenspiel richtig gemischt wurde. Und bei der vierten "
"Frage *weiß* ich, dass die Lotterie bestimmten Regeln folgt. Sie verstehen "
"die Idee. Der entscheidende Punkt ist, dass probabilistische Fragen mit "
"einem bekannten **Modell** der Welt beginnen, und wir verwenden dieses "
"Modell, um einige Berechnungen durchzuführen. Das zugrunde liegende Modell "
"kann recht einfach sein. Im Beispiel des Münz-Werfens können wir das Modell "
"zum Beispiel so aufschreiben:"

#: ../../Ch07/Ch07_Probability_1.rst:38
msgid "*P*\\ (heads) = *0.5*"
msgstr "P\\ (Kopf) = 0,5"

#: ../../Ch07/Ch07_Probability_1.rst:40
msgid ""
"which you can read as “the probability of heads is 0.5”. As we’ll see later, "
"in the same way that percentages are numbers that range from 0\\% to 100\\%, "
"probabilities are just numbers that range from 0 to 1. When using this "
"probability model to answer the first question I don’t actually know exactly "
"what’s going to happen. Maybe I’ll get 10 heads, like the question says. But "
"maybe I’ll get three heads. That’s the key thing. In probability theory the "
"*model* is known but the *data* are not."
msgstr ""
"was man als „die Wahrscheinlichkeit von Kopf ist 0,5“ lesen kann. Wie wir "
"später sehen werden, sind Wahrscheinlichkeiten genauso wie Prozentsätze "
"Zahlen, die zwischen 0 und 100 % liegen, nur Zahlen, die zwischen 0 und 1 "
"liegen. Wenn ich dieses Wahrscheinlichkeitsmodell zur Beantwortung der "
"ersten Frage verwende, weiß ich eigentlich nicht genau, was passieren wird. "
"Vielleicht erhalte ich 10 Köpfe, wie in der Frage angegeben. Vielleicht "
"erhalte ich aber auch drei Köpfe. Das ist der springende Punkt. In der "
"Wahrscheinlichkeitstheorie ist das *Modell* bekannt, die *Daten* sind es "
"aber nicht."

#: ../../Ch07/Ch07_Probability_1.rst:49
msgid ""
"So that’s probability. What about statistics? Statistical questions work the "
"other way around. In statistics we do not know the truth about the world. "
"All we have is the data and it is from the data that we want to *learn* the "
"truth about the world. Statistical questions tend to look more like these:"
msgstr ""
"Das ist also die Wahrscheinlichkeit. Was ist mit Statistik? Statistische "
"Fragen funktionieren genau andersherum. In der Statistik kennen wir die "
"Wahrheit über die Welt nicht. Alles, was wir haben, sind die Daten, und aus "
"diesen Daten wollen wir die Wahrheit über die Welt *erfahren*. Statistische "
"Fragen sehen in der Regel eher wie folgt aus:"

#: ../../Ch07/Ch07_Probability_1.rst:55
msgid ""
"If my friend flips a coin 10 times and gets 10 heads are they playing a "
"trick on me?"
msgstr ""
"Wenn ein Freund 10 Mal eine Münze wirft und 10 Mal Kopf erhält, spielt er "
"mir dann einen Streich?"

#: ../../Ch07/Ch07_Probability_1.rst:58
msgid ""
"If five cards off the top of the deck are all hearts how likely is it that "
"the deck was shuffled?"
msgstr ""
"Wie wahrscheinlich ist es, dass der Kartenstapel gemischt wurde, wenn die "
"fünf obersten Karten alle die Farbe Herz haben?"

#: ../../Ch07/Ch07_Probability_1.rst:61
msgid ""
"If the lottery commissioner’s spouse wins the lottery how likely is it that "
"the lottery was rigged?"
msgstr ""
"Wenn der Ehepartner des Lotteriekommissars in der Lotterie gewinnt, wie "
"wahrscheinlich ist es dann, dass die Lotterie manipuliert wurde?"

#: ../../Ch07/Ch07_Probability_1.rst:64
msgid ""
"This time around the only thing we have are data. What I *know* is that I "
"saw my friend flip the coin 10 times and it came up heads every time. And "
"what I want to **infer** is whether or not I should conclude that what I "
"just saw was actually a fair coin being flipped 10 times in a row, or "
"whether I should suspect that my friend is playing a trick on me. The data I "
"have look like this:"
msgstr ""
"Dieses Mal haben wir nur die Daten. Was ich *weiß* ist, dass ich gesehen "
"habe, wie mein Freund die Münze 10 Mal geworfen hat und jedes Mal Kopf "
"herauskam. Und was ich **ableiten möchte** ist, ob ich daraus schließen "
"sollte, dass das, was ich gerade gesehen habe, tatsächlich eine „normale“ "
"Münze war, die 10 Mal hintereinander geworfen wurde, oder ob ich vermuten "
"sollte, dass mein Freund mir einen Streich spielt. Die Daten, die ich habe, "
"sehen wie folgt aus:"

#: ../../Ch07/Ch07_Probability_1.rst:75
msgid ""
"and what I’m trying to do is work out which “model of the world” I should "
"put my trust in. If the coin is fair then the model I should adopt is one "
"that says that the probability of heads is 0.5, that is *P*\\ (heads) = "
"*0.5*. If the coin is not fair then I should conclude that the probability "
"of heads is *not* 0.5, which we would write as *P*\\ (heads) ≠ *0.5*. In "
"other words, the statistical inference problem is to figure out which of "
"these probability models is right. Clearly, the statistical question isn’t "
"the same as the probability question, but they’re deeply connected to one "
"another. Because of this, a good introduction to statistical theory will "
"start with a discussion of what probability is and how it works."
msgstr ""
"und ich versuche herauszufinden, auf welches „Weltmodell“ ich mein Vertrauen "
"setzen sollte. Wenn die Münze „normal“ ist, dann ist das Modell, das ich "
"annehmen sollte, eines, das besagt, dass die Wahrscheinlichkeit von Kopf 0,5 "
"ist, also *P*\\ (Kopf) = *0,5*. Wenn die Münze nicht „normal“ ist, dann "
"sollte ich zu dem Schluss kommen, dass die Wahrscheinlichkeit von Kopf "
"*nicht* 0,5 ist, was wir als *P*\\ (Kopf) ≠ *0,5* schreiben würden. Mit "
"anderen Worten: Das Problem der statistischen Schlussfolgerung besteht "
"darin, herauszufinden, welches dieser Wahrscheinlichkeitsmodelle richtig "
"ist. Es ist klar, dass die statistische Frage nicht dasselbe ist wie die "
"Wahrscheinlichkeitsfrage, aber sie sind eng miteinander verknüpft. Aus "
"diesem Grund beginnt eine gute Einführung in die statistische Theorie mit "
"einer Diskussion darüber, was Wahrscheinlichkeit ist und wie sie "
"funktioniert."

#: ../../Ch07/Ch07_Probability_2.rst:4
msgid "What does probability mean?"
msgstr "Was bedeutet Wahrscheinlichkeit?"

#: ../../Ch07/Ch07_Probability_2.rst:6
msgid ""
"Let’s start with the first of these questions. What is “probability”? It "
"might seem surprising to you but while statisticians and mathematicians "
"(mostly) agree on what the *rules* of probability are, there’s much less of "
"a consensus on what the word really *means*. It seems weird because we’re "
"all very comfortable using words like “chance”, “likely”, “possible” and "
"“probable”, and it doesn’t seem like it should be a very difficult question "
"to answer. But if you’ve ever had that experience in real life you might "
"walk away from the conversation feeling like you didn’t quite get it right, "
"and that (like many everyday concepts) it turns out that you don’t *really* "
"know what it’s all about."
msgstr ""
"Beginnen wir mit der ersten dieser Fragen. Was ist „Wahrscheinlichkeit“? Es "
"mag Sie vielleicht überraschen, aber während sich Statistiker und "
"Mathematiker (größtenteils) einig sind, was die *Regeln* der "
"Wahrscheinlichkeit sind, besteht weitaus weniger Einigkeit darüber, was das "
"Wort wirklich *bedeutet*. Das erscheint seltsam, weil wir alle sehr vertraut "
"mit Wörtern wie „Zufall“, „wahrscheinlich“, „möglich“ und „wahrscheinlich“ "
"sind. Es scheint daher nicht so, als ob die Antwort auf diese Frage sehr "
"schwierig sein sollte. Aber wenn Sie diese Erfahrung schon einmal im "
"wirklichen Leben gemacht haben, gehen Sie vielleicht mit dem Gefühl aus dem "
"Gespräch, dass Sie es nicht ganz richtig verstanden haben, und dass sich ("
"wie bei vielen alltäglichen Begriffen) herausstellt, dass Sie nicht "
"*wirklich* wissen, worum es eigentlich geht."

#: ../../Ch07/Ch07_Probability_2.rst:17
msgid ""
"So I’ll have a go at it. Let’s suppose I want to bet on a soccer game "
"between two teams of robots, *Arduino Arsenal* and *C Milan*. After thinking "
"about it, I decide that there is an 80\\% probability of *Arduino Arsenal* "
"winning. What do I mean by that? Here are three possibilities:"
msgstr ""
"Ich werde es also versuchen. Nehmen wir an, ich möchte auf ein Fußballspiel "
"zwischen zwei Roboterteams wetten, *Arduino Arsenal* und *C Milan*. Nachdem "
"ich darüber nachgedacht habe, entscheide ich, dass die Wahrscheinlichkeit, "
"dass *Arduino Arsenal* gewinnt, bei 80 % liegt. Was will ich damit sagen? "
"Hier sind drei Möglichkeiten:"

#: ../../Ch07/Ch07_Probability_2.rst:22
msgid ""
"They’re robot teams so I can make them play over and over again, and if I "
"did that *Arduino Arsenal* would win 8 out of every 10 games on average."
msgstr ""
"Da es sich um Roboterteams handelt, kann ich sie immer wieder spielen "
"lassen, und wenn ich das täte, würde *Arduino Arsenal* im Durchschnitt 8 von "
"10 Spielen gewinnen."

#: ../../Ch07/Ch07_Probability_2.rst:26
msgid ""
"For any given game, I would agree that betting on this game is only “fair” "
"if a $1 bet on *C Milan* gives a $5 payoff (i.e. I get my $1 back plus a $4 "
"reward for being correct), as would a $4 bet on *Arduino Arsenal* (i.e., my "
"$4 bet plus a $1 reward)."
msgstr ""
"Für jedes beliebige Spiel würde ich zustimmen, dass eine Wette auf dieses "
"Spiel nur dann „fair” ist, wenn eine $1-Wette auf *C Milan* eine $5-"
"Auszahlung ergibt (d. h. ich bekomme meine $1 zurück plus eine $4-Belohnung "
"für die Richtigkeit), ebenso wie eine $4-Wette auf *Arduino Arsenal* (d. h. "
"meine $4-Wette plus eine $1-Belohnung)."

#: ../../Ch07/Ch07_Probability_2.rst:31
msgid ""
"My subjective “belief” or “confidence” in an *Arduino Arsenal* victory is "
"four times as strong as my belief in a *C Milan* victory."
msgstr ""
"Mein subjektiver „Glaube“ oder meine „Zuversicht“ an einen Sieg von *Arduino "
"Arsenal* ist also viermal so stark wie mein Glaube an einen Sieg von *C "
"Milan*."

#: ../../Ch07/Ch07_Probability_2.rst:34
msgid ""
"Each of these seems sensible. However, they’re not identical and not every "
"statistician would endorse all of them. The reason is that there are "
"different statistical ideologies (yes, really!) and depending on which one "
"you subscribe to, you might say that some of those statements are "
"meaningless or irrelevant. In this section I give a brief introduction the "
"two main approaches that exist in the literature. These are by no means the "
"only approaches, but they’re the two big ones."
msgstr ""
"Jede dieser Möglichkeiten erscheint sinnvoll. Sie sind jedoch nicht "
"identisch, und nicht jeder Statistiker würde sie alle gutheißen. Der Grund "
"dafür ist, dass es verschiedene statistische Ideologien gibt (ja, wirklich!)"
", und je nachdem, welcher man angehört, könnte man sagen, dass einige dieser "
"Aussagen sinnlos oder irrelevant sind. In diesem Abschnitt gebe ich eine "
"kurze Einführung in die beiden wichtigsten Ansätze, die in der Literatur "
"existieren. Dies sind keineswegs die einzigen Ansätze, aber es sind die "
"beiden wichtigsten."

#: ../../Ch07/Ch07_Probability_2.rst:43
msgid "The frequentist view"
msgstr "Die frequentistische Sichtweise"

#: ../../Ch07/Ch07_Probability_2.rst:45
msgid ""
"The first of the two major approaches to probability, and the more dominant "
"one in statistics, is referred to as the **frequentist view** and it defines "
"probability as a **long-run frequency**. Suppose we were to try flipping a "
"fair coin over and over again. By definition this is a coin that has "
"*P*\\(H) = *0.5*. What might we observe? One possibility is that the first "
"20 flips might look like this:"
msgstr ""
"Der erste der beiden Hauptansätze zur Wahrscheinlichkeit, der in der "
"Statistik dominanter ist, wird als **frequentistische Sichtweise** "
"bezeichnet und definiert die Wahrscheinlichkeit als eine **langfristige "
"Häufigkeit**. Nehmen wir an, wir würden versuchen, eine „normale“ Münze "
"immer wieder zu werfen. Per Definition ist dies eine Münze, die *P*\\(K) = "
"*0,5* hat. Was könnten wir beobachten? Eine Möglichkeit ist, dass die ersten "
"20 Würfe wie folgt aussehen könnten:"

#: ../../Ch07/Ch07_Probability_2.rst:56
msgid ""
"In this case 11 of these 20 coin flips (55\\%) came up heads. Now suppose "
"that I’d been keeping a running tally of the number of heads (which I’ll "
"call *N*\\ :sub:`H`\\ ) that I’ve seen, across the first *N* flips, and "
"calculate the proportion of heads *N*\\ :sub:`H` / *N* every time. Here’s "
"what I’d get (I did literally flip coins to produce this!):"
msgstr ""
"In diesem Fall ergaben 11 dieser 20 Münzwürfe (55 %) Kopf. Nehmen wir nun "
"an, dass ich die Anzahl der Kopf-Würfe (die ich *N*\\ :sub:`K`\\ nenne), die "
"ich bei den ersten *N* Münzwürfen gesehen habe, laufend notiere und den "
"Anteil der Köpfe *N*\\ :sub:`K` / *N* jedes Mal berechne. Hier ist das "
"Ergebnis (ich habe wirklich Münzen geworfen, um diese Daten zu produzieren!):"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:71
msgid "number of flips"
msgstr "Anzahl der Würfe"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "1"
msgstr "1"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "2"
msgstr "2"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "3"
msgstr "3"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "4"
msgstr "4"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "5"
msgstr "5"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "6"
msgstr "6"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "7"
msgstr "7"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:73
msgid "8"
msgstr "8"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:73
msgid "9"
msgstr "9"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:73
msgid "10"
msgstr "10"

#: ../../Ch07/Ch07_Probability_2.rst:65 ../../Ch07/Ch07_Probability_2.rst:73
msgid "**number of heads**"
msgstr "**Anzahl der Seite „Kopf“**"

#: ../../Ch07/Ch07_Probability_2.rst:65
msgid "0"
msgstr "0"

#: ../../Ch07/Ch07_Probability_2.rst:67 ../../Ch07/Ch07_Probability_2.rst:75
msgid "**proportion**"
msgstr "**Anteil**"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.00"
msgstr "0.00"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.50"
msgstr "0.50"

#: ../../Ch07/Ch07_Probability_2.rst:67 ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.67"
msgstr "0.67"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.75"
msgstr "0.75"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.80"
msgstr "0.80"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.57"
msgstr "0.57"

#: ../../Ch07/Ch07_Probability_2.rst:67 ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.63"
msgstr "0.63"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.70"
msgstr "0.70"

#: ../../Ch07/Ch07_Probability_2.rst:71 ../../Ch07/Ch07_Probability_2.rst:73
msgid "11"
msgstr "11"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "12"
msgstr "12"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "13"
msgstr "13"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "14"
msgstr "14"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "15"
msgstr "15"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "16"
msgstr "16"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "17"
msgstr "17"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "18"
msgstr "18"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "19"
msgstr "19"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "20"
msgstr "20"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.73"
msgstr "0.73"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.69"
msgstr "0.69"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.71"
msgstr "0.71"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.59"
msgstr "0.59"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.56"
msgstr "0.56"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.53"
msgstr "0.53"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.55"
msgstr "0.55"

#: ../../Ch07/Ch07_Probability_2.rst:78
msgid ""
"Notice that at the start of the sequence the *proportion* of heads "
"fluctuates wildly, starting at 0.00 and rising as high as 0.80. Later on, "
"one gets the impression that it dampens out a bit, with more and more of the "
"values actually being pretty close to the “right” answer of 0.50. This is "
"the frequentist definition of probability in a nutshell. Flip a fair coin "
"over and over again, and as *N* grows large (approaches infinity, denoted "
"*N* → ∞) the proportion of heads will converge to 50\\%. There are some "
"subtle technicalities that the mathematicians care about, but qualitatively "
"speaking that’s how the frequentists define probability. Unfortunately, I "
"don’t have an infinite number of coins or the infinite patience required to "
"flip a coin an infinite number of times. However, I do have a computer and "
"computers excel at mindless repetitive tasks. So I asked my computer to "
"simulate flipping a coin 1000 times and then drew a picture of what happens "
"to the proportion *N*\\ :sub:`H` / *N* as *N* increases. Actually, I did it "
"four times just to make sure it wasn’t a fluke. The results are shown in :"
"numref:`fig-frequentistProb`. As you can see, the *proportion of observed "
"heads* eventually stops fluctuating and settles down. When it does, the "
"number at which it finally settles is the true probability of heads."
msgstr ""
"Beachten Sie, dass zu Beginn der Sequenz der *Anteil* der Kopf-Würfe stark "
"schwankt und bei 0,00 beginnt und bis auf 0,80 ansteigt. Später hat man den "
"Eindruck, dass sich die Schwankungen etwas abschwächen und immer mehr Werte "
"tatsächlich ziemlich nahe an der „richtigen“ Antwort von 0,50 liegen. Dies "
"ist die frequentistische Definition der Wahrscheinlichkeit in Kurzform. "
"Wirft man eine „normale“ Münze immer wieder, so konvergiert der Anteil der "
"Köpfe bei *N* mit zunehmender Größe (gegen unendlich, *N* → ∞) auf 50 %. Es "
"gibt einige technische Feinheiten, um die sich die Mathematiker kümmern, "
"aber qualitativ gesehen ist das die Art und Weise, wie die Frequentisten die "
"Wahrscheinlichkeit definieren. Leider verfüge ich weder über eine unendliche "
"Anzahl von Münzen noch über die unendliche Geduld, die erforderlich ist, um "
"eine Münze unendlich oft zu werfen. Aber ich habe einen Computer, und "
"Computer eignen sich hervorragend für sinnlose, sich wiederholende Aufgaben. "
"Also habe ich meinen Computer gebeten, das 1000-malige Werfen einer Münze zu "
"simulieren und dann ein Bild davon gezeichnet, was mit dem Verhältnis *N*\\ :"
"sub:`K` / *N* passiert, wenn *N* zunimmt. Ich habe es sogar viermal gemacht, "
"nur um sicherzugehen, dass das Ergebnis nicht reiner Zufall war. Die "
"Ergebnisse sind in :numref:`fig-frequentistProb` dargestellt. Wie Sie sehen "
"können, hört der Anteil der beobachteten *Kopf-Würfe* schließlich auf zu "
"schwanken und pendelt sich ein. Die Zahl, bei der sie sich schließlich "
"einpendelt, ist die „wahre“ Wahrscheinlichkeit für Kopf."

#: ../../Ch07/Ch07_Probability_2.rst:100
msgid "Illustration of how frequentist probability works"
msgstr ""
"Veranschaulichung der Funktionsweise der frequentistischen "
"Wahrscheinlichkeitsrechnung"

#: ../../Ch07/Ch07_Probability_2.rst:104
msgid ""
"Illustration of how frequentist probability works: If you flip a fair coin "
"over and over again the proportion of heads that you’ve seen eventually "
"settles down and converges to the true probability of 0.5. Each panel shows "
"four different simulated experiments. In each case we pretend we flipped a "
"coin 1000 times and kept track of the proportion of flips that were heads as "
"we went along. Although none of these sequences actually ended up with an "
"exact value of 0.5, if we’d extended the experiment for an infinite number "
"of coin flips they would have."
msgstr ""
"Illustration der Funktionsweise der frequentistischen "
"Wahrscheinlichkeitsrechnung: Wenn man eine „normale“ Münze immer und immer "
"wieder wirft, pendelt sich der Anteil der Kopf-Würfe, die man beobachtet, "
"ein und konvergiert gegen die „wahre“ Wahrscheinlichkeit von 0,5. Jedes Feld "
"zeigt vier verschiedene simulierte Experimente. In jedem Fall tun wir so, "
"als ob wir 1000 Mal eine Münze geworfen hätten, und verfolgen den Anteil der "
"Würfe, die Kopf waren, im Laufe der Zeit. Obwohl keine dieser Sequenzen "
"tatsächlich mit einem exakten Wert von 0,5 endete, hätten sie es getan, wenn "
"wir das Experiment auf eine unendliche Anzahl von Münzwürfen ausgedehnt "
"hätten."

#: ../../Ch07/Ch07_Probability_2.rst:115
msgid ""
"The frequentist definition of probability has some desirable "
"characteristics. First, it is objective. The probability of an event is "
"*necessarily* grounded in the world. The only way that probability "
"statements can make sense is if they refer to (a sequence of) events that "
"occur in the physical universe.\\ [#]_ Secondly, it is unambiguous. Any two "
"people watching the same sequence of events unfold, trying to calculate the "
"probability of an event, must inevitably come up with the same answer."
msgstr ""
"Die frequentistische Definition der Wahrscheinlichkeit hat einige "
"wünschenswerte Eigenschaften. Erstens ist sie objektiv: Die "
"Wahrscheinlichkeit eines Ereignisses ist *notwendigerweise* in der Welt "
"verankert. Wahrscheinlichkeitsaussagen sind nur dann sinnvoll, wenn sie sich "
"auf (eine Abfolge von) Ereignissen beziehen, die im physikalischen Universum "
"stattfinden.\\ [#]_ Zweitens ist sie eindeutig: Zwei Personen, die dieselbe "
"Abfolge von Ereignissen beobachten und versuchen, die Wahrscheinlichkeit "
"eines Ereignisses zu berechnen, müssen unweigerlich auf dieselbe Antwort "
"kommen."

#: ../../Ch07/Ch07_Probability_2.rst:124
msgid ""
"However, it also has undesirable characteristics. First, infinite sequences "
"don’t exist in the physical world. Suppose you picked up a coin from your "
"pocket and started to flip it. Every time it lands it impacts on the ground. "
"Each impact wears the coin down a bit. Eventually the coin will be "
"destroyed. So, one might ask whether it really makes sense to pretend that "
"an “infinite” sequence of coin flips is even a meaningful concept, or an "
"objective one. We can’t say that an “infinite sequence” of events is a real "
"thing in the physical universe, because the physical universe doesn’t allow "
"infinite anything. More seriously, the frequentist definition has a narrow "
"scope. There are lots of things out there that human beings are happy to "
"assign probability to in everyday language, but cannot (even in theory) be "
"mapped onto a hypothetical sequence of events. For instance, if a "
"meteorologist comes on TV and says “the probability of rain in Adelaide on 2 "
"November 2048 is 60\\%” we humans are happy to accept this. But it’s not "
"clear how to define this in frequentist terms. There’s only one city of "
"Adelaide, and only one 2 November 2048. There’s no infinite sequence of "
"events here, just a one-off thing. Frequentist probability genuinely "
"*forbids* us from making probability statements about a single event. From "
"the frequentist perspective it will either rain tomorrow or it will not. "
"There is no “probability” that attaches to a single non-repeatable event. "
"Now, it should be said that there are some very clever tricks that "
"frequentists can use to get around this. One possibility is that what the "
"meteorologist means is something like “There is a category of days for which "
"I predict a 60\\% chance of rain, and if we look only across those days for "
"which I make this prediction, then on 60\\% of those days it will actually "
"rain”. It’s very weird and counterintuitive to think of it this way, but you "
"do see frequentists do this sometimes. And it *will* come up later in this "
"book (see :doc:`../Ch08/Ch08_Estimation_5`)."
msgstr ""
"Sie hat jedoch auch unerwünschte Eigenschaften. Erstens gibt es in der "
"physischen Welt keine unendlichen Folgen. Nehmen wir an, Sie nehmen eine "
"Münze aus Ihrer Tasche und beginnen, sie zu werfen. Jedes Mal, wenn sie "
"landet, schlägt sie auf dem Boden auf. Bei jedem Aufprall wird die Münze ein "
"wenig abgenutzt. Irgendwann ist die Münze zerstört. Man könnte sich also "
"fragen, ob es wirklich sinnvoll ist, so zu tun, als sei eine „unendliche“ "
"Folge von Münzwürfen überhaupt ein sinnvolles Konzept oder ein objektives "
"Konzept. Wir können nicht sagen, dass eine „unendliche Folge“ von "
"Ereignissen im physikalischen Universum eine reale Sache ist, weil das "
"physikalische Universum keine unendlichen Dinge zulässt. Wichtiger ist, dass "
"die frequentistische Definition einen engen Anwendungsbereich hat. Es gibt "
"viele Dinge, denen wir Menschen in der Alltagssprache gerne eine "
"Wahrscheinlichkeit zuordnen, die sich aber (selbst in der Theorie) nicht auf "
"eine hypothetische Abfolge von Ereignissen übertragen lassen. Wenn zum "
"Beispiel ein Meteorologe im Fernsehen sagt: „Die Wahrscheinlichkeit, dass es "
"am 2. November 2048 in Adelaide regnet, beträgt 60 %“, dann akzeptieren wir "
"Menschen das gerne. Aber es ist nicht klar, wie man dies in "
"frequentistischen Begriffen definieren kann. Es gibt nur eine Stadt "
"Adelaide, und nur einen 2. November 2048. Es gibt hier keine unendliche "
"Folge von Ereignissen, sondern nur ein einmaliges Ereignis. Die "
"frequentistische Wahrscheinlichkeitsrechnung *verbietet* es uns, "
"Wahrscheinlichkeitsaussagen über ein einzelnes Ereignis zu machen. Aus der "
"Sicht der Frequentisten wird es entweder morgen regnen oder nicht. Es gibt "
"keine „Wahrscheinlichkeit“, die einem einzelnen, nicht wiederholbaren "
"Ereignis zugeordnet werden kann. Nun gibt es aber einige sehr clevere "
"Tricks, mit denen Anhänger der frequentistischen Sichtweise dies umgehen "
"können. Eine Möglichkeit ist, dass der Meteorologe etwas meint wie: „Es gibt "
"eine Kategorie von Tagen, für die ich eine Regenwahrscheinlichkeit von 60 % "
"vorhersage, und wenn wir nur die Tage betrachten, für die ich diese "
"Vorhersage mache, dann wird es an 60 % dieser Tage tatsächlich regnen“. Es "
"ist sehr seltsam und kontraintuitiv, so darüber zu denken, aber man sieht, "
"dass Vielleser dies manchmal tun. Und *wird* später in diesem Buch wieder "
"auftauchen (siehe :doc:`../Ch08/Ch08_Estimation_5`)."

#: ../../Ch07/Ch07_Probability_2.rst:155
msgid "The Bayesian view"
msgstr "Die Bayessche Sichtweise"

#: ../../Ch07/Ch07_Probability_2.rst:157
msgid ""
"The **Bayesian view** of probability is often called the subjectivist view, "
"and although it has been a minority view among statisticians it has been "
"steadily gaining traction for the last several decades. There are many "
"flavours of Bayesianism, making it hard to say exactly what “the” Bayesian "
"view is. The most common way of thinking about subjective probability is to "
"define the probability of an event as the **degree of belief** that an "
"intelligent and rational agent assigns to that truth of that event. From "
"that perspective, probabilities don’t exist in the world but rather in the "
"thoughts and assumptions of people and other intelligent beings."
msgstr ""
"Die **Bayessche Sichtweise** der Wahrscheinlichkeit wird oft als "
"subjektivistische Sichtweise bezeichnet, und obwohl ihre Anhänger innerhalb "
"der Statistiker immer noch in der Minderzahl sind, hat sie in den letzten "
"Jahrzehnten stetig an Bedeutung gewonnen. Es gibt viele Ausprägungen der **"
"Bayesschen Sichtweise**, so dass es schwierig ist, genau zu sagen, was „die“ "
"Bayessche Sichtweise ist. Die gängigste Art, über subjektive "
"Wahrscheinlichkeit nachzudenken, besteht darin, die Wahrscheinlichkeit eines "
"Ereignisses als den **Grad des Glaubens** zu definieren, den ein "
"intelligenter und rationaler Akteur der Wahrheit dieses Ereignisses "
"beimisst. Aus dieser Perspektive existieren Wahrscheinlichkeiten nicht in "
"der Welt, sondern eher in den Gedanken und Annahmen von Menschen und anderen "
"intelligenten Wesen."

#: ../../Ch07/Ch07_Probability_2.rst:168
msgid ""
"However, in order for this approach to work we need some way of "
"operationalising “degree of belief”. One way that you can do this is to "
"formalise it in terms of “rational gambling”, though there are many other "
"ways. Suppose that I believe that there’s a 60\\% probability of rain "
"tomorrow. If someone offers me a bet that if it rains tomorrow then I win "
"$5, but if it doesn’t rain I lose $5. Clearly, from my perspective, this is "
"a pretty good bet. On the other hand, if I think that the probability of "
"rain is only 40\\% then it’s a bad bet to take. So we can operationalise the "
"notion of a “subjective probability” in terms of what bets I’m willing to "
"accept."
msgstr ""
"Damit dieser Ansatz funktioniert, brauchen wir jedoch eine Möglichkeit, den "
"„Grad des Glaubens“ zu operationalisieren. Eine Möglichkeit, dies zu tun, "
"besteht darin, es als „rationales Glücksspiel“ zu formalisieren, obwohl es "
"viele andere Möglichkeiten gibt. Angenommen, ich glaube, dass es morgen mit "
"einer Wahrscheinlichkeit von 60 % regnen wird. Wenn mir jemand eine Wette "
"anbietet, dass ich 5 Dollar gewinne, wenn es morgen regnet, aber 5 Dollar "
"verliere, wenn es nicht regnet, dann ist das aus meiner Sicht eine ziemlich "
"gute Wette. Wenn ich hingegen glaube, dass die Wahrscheinlichkeit, dass es "
"regnet, nur 40 % beträgt, dann ist es eine schlechte Wette, die ich nicht "
"eingehen sollte. Wir können also den Begriff der „subjektiven "
"Wahrscheinlichkeit“ dahingehend operationalisieren, welche Wetten ich zu "
"akzeptieren bereit bin."

#: ../../Ch07/Ch07_Probability_2.rst:179
msgid ""
"What are the advantages and disadvantages to the Bayesian approach? The main "
"advantage is that it allows you to assign probabilities to any event you "
"want to. You don’t need to be limited to those events that are repeatable. "
"The main disadvantage (to many people) is that we can’t be purely objective. "
"Specifying a probability requires us to specify an entity that has the "
"relevant degree of belief. This entity might be a human, an alien, a robot, "
"or even a statistician. But there has to be an intelligent agent out there "
"that believes in things. To many people this is uncomfortable, it seems to "
"make probability arbitrary. Whilst the Bayesian approach requires that the "
"agent in question be rational (i.e., obey the rules of probability), it does "
"allow everyone to have their own beliefs. I can believe the coin is fair and "
"you don’t have to, even though we’re both rational. The frequentist view "
"doesn’t allow any two observers to attribute different probabilities to the "
"same event. When that happens then at least one of them must be wrong. The "
"Bayesian view does not prevent this from occurring. Two observers with "
"different background knowledge can legitimately hold different beliefs about "
"the same event. In short, where the frequentist view is sometimes considered "
"to be too narrow (forbids lots of things that that we want to assign "
"probabilities to), the Bayesian view is sometimes thought to be too broad "
"(allows too many differences between observers)."
msgstr ""
"Was sind die Vor- und Nachteile der Bayesschen Sichtweise? Der Hauptvorteil "
"besteht darin, dass man jedem beliebigen Ereignis Wahrscheinlichkeiten "
"zuordnen kann. Man muss sich nicht auf die Ereignisse beschränken, die "
"wiederholbar sind. Der größte Nachteil (für viele Menschen) ist, dass wir "
"nicht rein objektiv sein können. Wenn wir eine Wahrscheinlichkeit angeben, "
"müssen wir eine Person benennen, die den entsprechenden Grad an Überzeugung "
"hat. Dieses Wesen kann ein Mensch, ein Außerirdischer, ein Roboter oder "
"sogar ein Statistiker sein. Aber es muss ein intelligentes Wesen da draußen "
"geben, das an Dinge glaubt. Viele Menschen empfinden dies als unangenehm, da "
"es die Wahrscheinlichkeit als willkürlich erscheinen lässt. Die Bayessche "
"Sichtweise setzt zwar voraus, dass der betreffende Akteur rational ist (d. "
"h. den Regeln der Wahrscheinlichkeit gehorcht), aber er erlaubt es jedem, "
"seine eigenen Überzeugungen zu haben. Ich kann glauben, dass die Münze "
"„normal“ ist, Sie müssen es nicht, obwohl wir beide rational sind. Die "
"frequentistische Sichtweise lässt es nicht zu, dass zwei Beobachter "
"demselben Ereignis unterschiedliche Wahrscheinlichkeiten zuschreiben. Wenn "
"das passiert, muss mindestens einer von ihnen falsch liegen. Die Bayessche "
"Sichtweise verhindert dies nicht. Zwei Beobachter mit unterschiedlichem "
"Hintergrundwissen können legitimerweise unterschiedliche Überzeugungen über "
"ein und dasselbe Ereignis haben. Kurz gesagt, während die frequentistische "
"Sichtweise manchmal als zu eng angesehen wird (sie verbietet viele Dinge, "
"denen wir Wahrscheinlichkeiten zuordnen wollen), wird die Bayessche "
"Sichtweise manchmal als zu breit angesehen (sie erlaubt zu viele "
"Unterschiede zwischen Beobachtern)."

#: ../../Ch07/Ch07_Probability_2.rst:202
msgid "What’s the difference? And who is right?"
msgstr "Was ist der Unterschied? Und wer hat Recht?"

#: ../../Ch07/Ch07_Probability_2.rst:204
msgid ""
"Now that you’ve seen each of these two views independently it’s useful to "
"make sure you can compare the two. Go back to the hypothetical robot soccer "
"game at the start of the section. What do you think a frequentist and a "
"Bayesian would say about these three statements? Which statement would a "
"frequentist say is the correct definition of probability? Which one would a "
"Bayesian opt for? Would some of these statements be meaningless to a "
"frequentist or a Bayesian? If you’ve understood the two perspectives you "
"should have some sense of how to answer those questions."
msgstr ""
"Nachdem Sie nun beide Ansichten unabhängig voneinander gesehen haben, ist es "
"sinnvoll, sie miteinander zu vergleichen. Gehen Sie zurück zu dem "
"hypothetischen Roboterfußballspiel vom Anfang des Abschnitts. Was denken "
"Sie, würden ein Frequentist und ein Bayesianer zu diesen drei Aussagen "
"sagen? Welche Aussage würde ein Frequentist als die richtige Definition von "
"Wahrscheinlichkeit bezeichnen? Für welche würde sich ein Bayesianer "
"entscheiden? Würden einige dieser Aussagen für einen Frequentisten oder "
"einen Bayesianer bedeutungslos sein? Wenn Sie die beiden Perspektiven "
"verstanden haben, sollten Sie eine Vorstellung davon haben, wie Sie diese "
"Fragen beantworten können."

#: ../../Ch07/Ch07_Probability_2.rst:214
msgid ""
"Okay, assuming you understand the difference then you might be wondering "
"which of them is *right*? Honestly, I don’t know that there is a right "
"answer. As far as I can tell there’s nothing mathematically incorrect about "
"the way frequentists think about sequences of events, and there’s nothing "
"mathematically incorrect about the way that Bayesians define the beliefs of "
"a rational agent. In fact, when you dig down into the details Bayesians and "
"frequentists actually agree about a lot of things. Many frequentist methods "
"lead to decisions that Bayesians agree a rational agent would make. Many "
"Bayesian methods have very good frequentist properties."
msgstr ""
"Okay, vorausgesetzt, Sie verstehen den Unterschied, dann fragen Sie sich "
"vielleicht, welche von beiden Sichtweisen *richtig* ist? Ehrlich gesagt, "
"weiß ich nicht, ob es eine „richtige“ Antwort gibt. Soweit ich das "
"beurteilen kann, gibt es nichts mathematisch Falsches an der Art und Weise, "
"wie Frequentisten über Ereignisfolgen denken, und es gibt nichts "
"mathematisch Falsches an der Art und Weise, wie Bayesianer die Überzeugungen "
"eines rationalen Akteurs definieren. Wenn man ins Detail geht, stimmen "
"Bayesianer und Frequentisten sogar in vielen Dingen überein. Viele "
"frequentistische Methoden führen zu Entscheidungen, die nach Ansicht der "
"Bayesianer auch ein rationaler Akteur treffen würde. Und viele Bayessche "
"Methoden haben sehr gute frequentistische Eigenschaften."

#: ../../Ch07/Ch07_Probability_2.rst:225
msgid ""
"For the most part, I’m a pragmatist so I’ll use any statistical method that "
"I trust. As it turns out, that makes me prefer Bayesian methods for reasons "
"I’ll explain towards the end of the book. But I’m not fundamentally opposed "
"to frequentist methods. Not everyone is quite so relaxed. For instance, "
"consider Sir Ronald Fisher, one of the towering figures of 20th century "
"statistics and a vehement opponent to all things Bayesian, whose paper on "
"the mathematical foundations of statistics referred to Bayesian probability "
"as “an impenetrable jungle [that] arrests progress towards precision of "
"statistical concepts” (:ref:`Fisher, 1922b <Fisher_1922b>`). Or the "
"psychologist Paul Meehl, who suggests that relying on frequentist methods "
"could turn you into “a potent but sterile intellectual rake who leaves in "
"his merry path a long train of ravished maidens but no viable scientific "
"offspring” (:ref:`Meehl, 1967 <Meehl_1967>`; p. 114). The history of "
"statistics, as you might gather, is not devoid of entertainment."
msgstr ""
"In den meisten Fällen bin ich pragmatisch und verwende daher jede "
"statistische Methode, der ich vertraue. Wie sich herausstellt, bevorzuge ich "
"deshalb aus Gründen, die ich gegen Ende des Buches erläutern werde, "
"Bayessche Methoden. Aber ich bin nicht grundsätzlich gegen frequentistische "
"Methoden. Nicht jeder ist ganz so entspannt. Denken Sie zum Beispiel an Sir "
"Ronald Fisher, eine der herausragenden Persönlichkeiten der Statistik und "
"ein vehementer Gegner aller Bayesschen Methoden: Er bezeichnet in seiner "
"Abhandlung über die mathematischen Grundlagen der Statistik die Bayessche "
"Wahrscheinlichkeit als „einen undurchdringlichen Dschungel, der den "
"Fortschritt in Richtung Präzision der statistischen Konzepte aufhält“ (:ref:"
"`Fisher, 1922b <Fisher_1922b>`). Oder der Psychologe Paul Meehl, der darauf "
"hinweist, dass das Vertrauen in frequentistische Methoden einen „potenten, "
"aber unfruchtbaren intellektuellen Wüstling, der auf seinem fröhlichen Weg "
"eine lange Reihe von geschändeten Jungfrauen, aber keinen lebensfähigen "
"wissenschaftlichen Nachwuchs hinterlässt“, ausmachen kann (:ref:`Meehl, 1967 "
"<Meehl_1967>` ; S. 114). Die Geschichte der Statistik kann, wie Sie sich "
"denken können, recht unterhaltsam sein."

#: ../../Ch07/Ch07_Probability_2.rst:241
msgid ""
"In any case, whilst I personally prefer the Bayesian view, the majority of "
"statistical analyses are based on the frequentist approach. My reasoning is "
"pragmatic. The goal of this book is to cover roughly the same territory as a "
"typical undergraduate stats class in psychology, and if you want to "
"understand the statistical tools used by most psychologists you’ll need a "
"good grasp of frequentist methods. I promise you that this isn’t wasted "
"effort. Even if you end up wanting to switch to the Bayesian perspective, "
"you really should read through at least one book on the “orthodox” "
"frequentist view. Besides, I won’t completely ignore the Bayesian "
"perspective. Every now and then I’ll add some commentary from a Bayesian "
"point of view, and I’ll revisit the topic in more depth in chapter :doc:`../"
"Ch16/Ch16_Bayes`."
msgstr ""
"Ich persönlich bevorzuge zwar die Bayessche Sichtweise, doch die meisten "
"statistischen Analysen basieren auf der frequentistischen Sichtweise. Meine "
"Überlegungen sind pragmatisch. Das Ziel dieses Buches ist es, in etwa das "
"gleiche Gebiet abzudecken wie ein typischer Statistikkurs im Grundstudium "
"der Psychologie. Wenn Sie die statistischen Werkzeuge verstehen wollen, die "
"von den meisten Psychologen verwendet werden, brauchen Sie ein gutes "
"Verständnis der frequentistischen Methoden. Ich verspreche Ihnen, dass dies "
"keine vergebliche Mühe ist. Selbst wenn Sie am Ende zur Bayesschen "
"Sichtweise wechseln wollen, sollten Sie zumindest ein Buch über die "
"„orthodoxe“ frequentistische Sichtweise lesen. Außerdem werde ich die "
"Bayessche Sichtweise nicht völlig ignorieren. Von Zeit zu Zeit werde ich "
"einige Kommentare aus Bayesscher Sicht hinzufügen, und ich werde das Thema "
"in Kapitel :doc:`../Ch16/Ch16_Bayes` noch einmal vertiefen."

#: ../../Ch07/Ch07_Probability_2.rst:257
msgid ""
"This doesn’t mean that frequentists can’t make hypothetical statements, of "
"course. It’s just that if you want to make a statement about probability "
"then it must be possible to redescribe that statement in terms of a sequence "
"of potentially observable events, together with the relative frequencies of "
"different outcomes that appear within that sequence."
msgstr ""
"Das bedeutet natürlich nicht, dass Frequentisten keine hypothetischen "
"Aussagen machen können. Es ist nur so, dass, wenn man eine Aussage über "
"Wahrscheinlichkeit machen will, es möglich sein muss, diese Aussage in Form "
"einer Sequenz von potenziell beobachtbaren Ereignissen zu beschreiben, "
"zusammen mit den relativen Häufigkeiten der verschiedenen Ergebnisse, die "
"innerhalb dieser Sequenz auftreten."

#: ../../Ch07/Ch07_Probability_3.rst:4
msgid "Basic probability theory"
msgstr "Grundlagen der Wahrscheinlichkeitsrechnung"

#: ../../Ch07/Ch07_Probability_3.rst:6
msgid ""
"Ideological arguments between Bayesians and frequentists notwithstanding, it "
"turns out that people mostly agree on the rules that probabilities should "
"obey. There are lots of different ways of arriving at these rules. The most "
"commonly used approach is based on the work of Andrey Kolmogorov, one of the "
"great Soviet mathematicians of the 20th century. I won’t go into a lot of "
"detail, but I’ll try to give you a bit of a sense of how it works. And in "
"order to do so I’m going to have to talk about my trousers."
msgstr ""
"Ungeachtet der ideologischen Auseinandersetzungen zwischen Bayesianern und "
"Frequentisten zeigt sich, dass die meisten Menschen sich über die Regeln "
"einig sind, denen Wahrscheinlichkeiten gehorchen sollten. Es gibt viele "
"verschiedene Methoden, um zu diesen Regeln zu gelangen. Der am weitesten "
"verbreitete Ansatz basiert auf der Arbeit von Andrej Kolmogorow, einem der "
"großen sowjetischen Mathematiker des 20. Jahrhunderts. Ich werde nicht zu "
"sehr ins Detail gehen, aber ich werde versuchen, Ihnen einen Eindruck davon "
"zu vermitteln, wie es funktioniert. Und dazu muss ich über meine Hose "
"sprechen."

#: ../../Ch07/Ch07_Probability_3.rst:16
msgid "Introducing probability distributions"
msgstr "Einführung in Wahrscheinlichkeitsverteilungen"

#: ../../Ch07/Ch07_Probability_3.rst:18
msgid ""
"One of the disturbing truths about my life is that I only own 5 pairs of "
"trousers. Three pairs of jeans, the bottom half of a suit, and a pair of "
"tracksuit pants. Even sadder, I’ve given them names: I call them *X*\\ :sub:"
"`1`\\ , *X*\\ :sub:`2`\\ , *X*\\ :sub:`3`\\ , *X*\\ :sub:`4`  and *X*\\ :sub:"
"`5`\\ . I really have, that’s why they call me Mister Imaginative. Now, on "
"any given day, I pick out exactly one of pair of trousers to wear. Not even "
"I’m so stupid as to try to wear two pairs of trousers, and thanks to years "
"of training I never go outside without wearing trousers anymore. If I were "
"to describe this situation using the language of probability theory, I would "
"refer to each pair of trousers (i.e., each *X*) as an **elementary event**. "
"The key characteristic of elementary events is that every time we make an "
"observation (e.g., every time I put on a pair of trousers) then the outcome "
"will be one and only one of these events. Like I said, these days I always "
"wear exactly one pair of trousers so my trousers satisfy this constraint. "
"Similarly, the set of all possible events is called a **sample space**. "
"Granted, some people would call it a “wardrobe”, but that’s because they’re "
"refusing to think about my trousers in probabilistic terms. Sad."
msgstr ""
"Eine der beunruhigenden Wahrheiten über mein Leben ist, dass ich nur 5 Paar "
"Hosen besitze. Drei Paar Jeans, die untere Hälfte eines Anzugs und eine "
"Jogginghose. Noch trauriger ist, dass ich ihnen Namen gegeben habe: Ich "
"nenne sie *X*\\ :sub:`1`\\ , *X*\\ :sub:`2`\\ , *X*\\ :sub:`3`\\ , *X*\\ "
":sub:`4` und *X*\\ :sub:`5`\\ . Das habe ich wirklich, deshalb nennt man "
"mich auch Mister Fantasievoll. Jetzt suche ich mir jeden Tag genau eine Hose "
"aus, die ich anziehen kann. Nicht einmal ich bin so dumm, dass ich versuche, "
"zwei Hosen zu tragen, und dank jahrelangem Training gehe ich auch nie mehr "
"ohne Hose aus dem Haus. Wenn ich diese Situation in der Sprache der "
"Wahrscheinlichkeitstheorie beschreiben würde, könnte ich jede Hose (d. h. "
"jedes *X*) als **Elementarereignis** bezeichnen. Das Hauptmerkmal von "
"Elementarereignissen ist, dass jedes Mal, wenn wir eine Beobachtung machen ("
"z. B. jedes Mal, wenn ich eine Hose anziehe), das Ergebnis eines und nur "
"eines dieser Ereignisse sein kann. Wie ich schon sagte, trage ich heutzutage "
"immer genau eine Hose, so dass meine Hose diese Bedingung erfüllt. In "
"ähnlicher Weise wird die Menge aller möglichen Ereignisse als "
"**Stichprobenraum** bezeichnet. Zugegeben, manche Leute würden ihn als "
"„Kleiderschrank“ bezeichnen, aber das liegt daran, dass sie sich weigern, "
"über meine Hosen in probabilistischen Begriffen zu denken. Schade."

#: ../../Ch07/Ch07_Probability_3.rst:37
msgid ""
"Okay, now that we have a sample space (a wardrobe), which is built from lots "
"of possible elementary events (trousers), what we want to do is assign a "
"**probability** of one of these elementary events. For an event *X*, the "
"probability of that event *P*\\ (X) is a number that lies between 0 and 1. "
"The bigger the value of *P*\\ (X), the more likely the event is to occur. "
"So, for example, if *P*\\ (X) = 0 it means the event *X* is impossible (i."
"e., I never wear those trousers). On the other hand, if *P*\\ (X) = 1 it "
"means that event *X* is certain to occur (i.e., I always wear those "
"trousers). For probability values in the middle it means that I sometimes "
"wear those trousers. For instance, if *P*\\ (X) = 0.5 it means that I wear "
"those trousers half of the time."
msgstr ""
"Jetzt haben wir einen Stichprobenraum (einen Kleiderschrank), der aus vielen "
"möglichen Elementarereignissen (Hosen) aufgebaut ist. Was wir tun wollen, "
"ist, eine **Wahrscheinlichkeit** zu jedem dieser Elementarereignisse "
"zuzuordnen. Für ein Ereignis *X* ist die Wahrscheinlichkeit dieses "
"Ereignisses *P*\\ (X) eine Zahl, die zwischen 0 und 1 liegt. Je größer der "
"Wert von *P*\\ (X), desto wahrscheinlicher ist das Eintreten des "
"Ereignisses. Wenn also zum Beispiel *P*\\ (X) = 0 ist, bedeutet dies, dass "
"das Ereignis *X* unmöglich ist (d. h., ich trage diese Hose nie). Wenn "
"andererseits *P*\\ (X) = 1 ist, bedeutet dies, dass das Ereignis *X* mit "
"Sicherheit eintritt (d. h., ich trage diese Hose immer). Für "
"Wahrscheinlichkeitswerte in der Mitte bedeutet es, dass ich diese Hose "
"manchmal trage. Wenn zum Beispiel *P*\\(X) = 0,5 ist, bedeutet dies, dass "
"ich diese Hose die Hälfte der Zeit trage."

#: ../../Ch07/Ch07_Probability_3.rst:50
msgid ""
"At this point, we’re almost done. The last thing we need to recognise is "
"that “something always happens”. Every time I put on trousers, I really do "
"end up wearing trousers (crazy, right?). What this somewhat trite statement "
"means, in probabilistic terms, is that the probabilities of the elementary "
"events need to add up to 1. This is known as the **law of total "
"probability**, not that any of us really care. More importantly, if these "
"requirements are satisfied then what we have is a **probability "
"distribution**. For example, this is an example of a probability "
"distribution:"
msgstr ""
"An diesem Punkt sind wir fast fertig. Das letzte, was wir erkennen müssen, "
"ist, dass „immer etwas passiert“. Jedes Mal, wenn ich eine Hose anziehe, "
"habe ich am Ende wirklich eine Hose an (verrückt, nicht wahr?). Diese etwas "
"banale Aussage bedeutet in der Wahrscheinlichkeitsrechnung, dass sich die "
"Wahrscheinlichkeiten der Elementarereignisse zu 1 addieren müssen. Dies ist "
"als **Gesetz der Gesamtwahrscheinlichkeit** bekannt, auch wenn es niemanden "
"von uns wirklich interessiert. Noch wichtiger ist, dass wir, wenn diese "
"Voraussetzungen erfüllt sind, eine **Wahrscheinlichkeitsverteilung** haben. "
"Dies ist zum Beispiel ein Beispiel für eine Wahrscheinlichkeitsverteilung:"

#: ../../Ch07/Ch07_Probability_3.rst:61
msgid "Which trousers?"
msgstr "Welche Hose?"

#: ../../Ch07/Ch07_Probability_3.rst:61
msgid "Label"
msgstr "Bezeichnung"

#: ../../Ch07/Ch07_Probability_3.rst:61
msgid "Probability"
msgstr "Wahrscheinlichkeit"

#: ../../Ch07/Ch07_Probability_3.rst:63
msgid "Blue jeans"
msgstr "Blaue Jeans"

#: ../../Ch07/Ch07_Probability_3.rst:63
msgid "*X*\\ :sub:`1`"
msgstr "*X*\\ :sub:`1`"

#: ../../Ch07/Ch07_Probability_3.rst:63
msgid "*P*\\ (X\\ :sub:`1`\\ ) = 0.5"
msgstr "*P*\\ (X\\ :sub:`1`\\ ) = 0.5"

#: ../../Ch07/Ch07_Probability_3.rst:65
msgid "Grey jeans"
msgstr "Graue Jeans"

#: ../../Ch07/Ch07_Probability_3.rst:65
msgid "*X*\\ :sub:`2`"
msgstr "*X*\\ :sub:`2`"

#: ../../Ch07/Ch07_Probability_3.rst:65
msgid "*P*\\ (X\\ :sub:`2`\\ ) = 0.3"
msgstr "*P*\\ (X\\ :sub:`2`\\ ) = 0.3"

#: ../../Ch07/Ch07_Probability_3.rst:67
msgid "Black jeans"
msgstr "Schwarze Jeans"

#: ../../Ch07/Ch07_Probability_3.rst:67
msgid "*X*\\ :sub:`3`"
msgstr "*X*\\ :sub:`3`"

#: ../../Ch07/Ch07_Probability_3.rst:67
msgid "*P*\\ (X\\ :sub:`3`\\ ) = 0.1"
msgstr "*P*\\ (X\\ :sub:`3`\\ ) = 0.1"

#: ../../Ch07/Ch07_Probability_3.rst:69
msgid "Black suit"
msgstr "Schwarze Anzughose"

#: ../../Ch07/Ch07_Probability_3.rst:69
msgid "*X*\\ :sub:`4`"
msgstr "*X*\\ :sub:`4`"

#: ../../Ch07/Ch07_Probability_3.rst:69
msgid "*P*\\ (X\\ :sub:`4`\\ ) = 0"
msgstr "*P*\\ (X\\ :sub:`4`\\ ) = 0"

#: ../../Ch07/Ch07_Probability_3.rst:71
msgid "Blue tracksuit"
msgstr "Blaue Trainingshose"

#: ../../Ch07/Ch07_Probability_3.rst:71
msgid "*X*\\ :sub:`5`"
msgstr "*X*\\ :sub:`5`"

#: ../../Ch07/Ch07_Probability_3.rst:71
msgid "*P*\\ (X\\ :sub:`5`\\ ) = 0.1"
msgstr "*P*\\ (X\\ :sub:`5`\\ ) = 0.1"

#: ../../Ch07/Ch07_Probability_3.rst:74
msgid ""
"Each of the events has a probability that lies between 0 and 1, and if we "
"add up the probability of all events they sum to 1. Awesome. We can even "
"draw a nice bar graph (see :doc:`../Ch05/Ch05_Graphics_3`) to visualise this "
"distribution, as shown in :numref:`fig-pantsDistribution`. And, at this "
"point, we’ve all achieved something. You’ve learned what a probability "
"distribution is, and I’ve finally managed to find a way to create a graph "
"that focuses entirely on my trousers. Everyone wins!"
msgstr ""
"Jedes der Ereignisse hat eine Wahrscheinlichkeit, die zwischen 0 und 1 "
"liegt, und wenn wir die Wahrscheinlichkeiten aller Ereignisse addieren, "
"ergeben sie 1. Fantastisch. Wir können sogar ein hübsches Balkendiagramm "
"zeichnen (siehe :doc:`../Ch05/Ch05_Graphics_3`), um diese Verteilung zu "
"visualisieren, wie in :numref:`fig-pantsDistribution` gezeigt. Und an diesem "
"Punkt haben wir alle etwas erreicht. Sie haben gelernt, was eine "
"Wahrscheinlichkeitsverteilung ist, und ich habe endlich einen Weg gefunden, "
"ein Diagramm zu erstellen, das sich ausschließlich auf meine Hose "
"konzentriert. Alle haben gewonnen!"

#: ../../Ch07/Ch07_Probability_3.rst:84
msgid "“Trousers” probability distribution"
msgstr "„Hosen“-Wahrscheinlichkeitsverteilung"

#: ../../Ch07/Ch07_Probability_3.rst:88
msgid ""
"Visual depiction of the “trousers” probability distribution. There are five "
"“elementary events”, corresponding to the five pairs of trousers that I own. "
"Each event has some probability of occurring: this probability is a number "
"between 0 to 1. The sum of these probabilities is 1."
msgstr ""
"Visuelle Darstellung der „Hosen“-Wahrscheinlichkeitsverteilung. Es gibt fünf "
"„Elementarereignisse“, die den fünf Hosen entsprechen, die ich besitze. "
"Jedes dieser Ereignis hat eine gewisse Eintrittswahrscheinlichkeit: Diese "
"Wahrscheinlichkeit ist eine Zahl zwischen 0 und 1. Die Summe dieser "
"Wahrscheinlichkeiten ist 1."

#: ../../Ch07/Ch07_Probability_3.rst:95
msgid ""
"The only other thing that I need to point out is that probability theory "
"allows you to talk about **non elementary events** as well as elementary "
"ones. The easiest way to illustrate the concept is with an example. In the "
"trousers example it’s perfectly legitimate to refer to the probability that "
"I wear jeans. In this scenario, the “Dani wears jeans” event is said to have "
"happened as long as the elementary event that actually did occur is one of "
"the appropriate ones. In this case “blue jeans”, “black jeans” or “grey "
"jeans”. In mathematical terms we defined the “jeans” event *E* to correspond "
"to the set of elementary events (X\\ :sub:`1`\\ , X\\ :sub:`2`\\ , X\\ :sub:"
"`3`\\ )`. If any of these elementary events occurs then *E* is also said to "
"have occurred. Having decided to write down the definition of the *E* this "
"way, it’s pretty straightforward to state what the probability *P*\\ (E) is: "
"we just add everything up. In this particular case"
msgstr ""
"Die einzige andere Sache, auf die ich hinweisen muss, ist, dass man in der "
"Wahrscheinlichkeitstheorie sowohl über **nicht elementare Ereignisse** als "
"auch über elementare Ereignisse sprechen kann. Am einfachsten lässt sich das "
"Konzept anhand eines Beispiels veranschaulichen. Im Hosenbeispiel ist es "
"völlig legitim, von der Wahrscheinlichkeit zu sprechen, dass ich Jeans "
"trage. In diesem Szenario gilt das Ereignis „Dani trägt Jeans“ als "
"eingetreten, solange das Elementarereignis, das tatsächlich eingetreten ist, "
"eines der entsprechenden Ereignisse ist. In diesem Fall „blaue Jeans“, „"
"schwarze Jeans“ oder „graue Jeans“. Mathematisch gesehen haben wir das "
"Ereignis „Jeans“ *E* so definiert, dass es der Menge der Elementarereignisse "
"(X\\ :sub:`1`\\ , X\\ :sub:`2`\\ , X\\ :sub:`3`\\ )` entspricht. Wenn eines "
"dieser Elementarereignisse eintritt, dann gilt auch *E* als eingetreten. "
"Nachdem wir uns entschlossen haben, die Definition von *E* auf diese Weise "
"niederzuschreiben, ist es ziemlich einfach, die Wahrscheinlichkeit *P*\\ (E) "
"zu bestimmen: Wir addieren einfach alles zusammen. In diesem besonderen Fall"

#: ../../Ch07/Ch07_Probability_3.rst:110
msgid ""
"*P*\\ (E) = *P*\\ (X\\ :sub:`1`\\ ) + *P*\\ (X\\ :sub:`2`\\ ) + *P*\\ (X\\ :"
"sub:`3`\\ )"
msgstr ""
"*P*\\ (E) = *P*\\ (X\\ :sub:`1`\\ ) + *P*\\ (X\\ :sub:`2`\\ ) + *P*\\ (X\\ :"
"sub:`3`\\ )"

#: ../../Ch07/Ch07_Probability_3.rst:112
msgid ""
"and, since the probabilities of blue, grey and black jeans respectively are "
"0.5, 0.3 and 0.1, the probability that I wear jeans is equal to 0.9."
msgstr ""
"und da die Wahrscheinlichkeiten für blaue, graue und schwarze Jeans jeweils "
"0,5, 0,3 und 0,1 betragen, ist die Wahrscheinlichkeit, dass ich Jeans trage, "
"gleich 0,9."

#: ../../Ch07/Ch07_Probability_3.rst:115
msgid ""
"At this point you might be thinking that this is all terribly obvious and "
"simple and you’d be right. All we’ve really done is wrap some basic "
"mathematics around a few common sense intuitions. However, from these simple "
"beginnings it’s possible to construct some extremely powerful mathematical "
"tools. I’m definitely not going to go into the details in this book, but "
"what I will do is list, in :numref:`tab-probrules`, some of the other rules "
"that probabilities satisfy. These rules can be derived from the simple "
"assumptions that I’ve outlined above, but since we don’t actually use these "
"rules for anything in this book I won’t do so here."
msgstr ""
"An dieser Stelle denken Sie vielleicht, dass dies alles furchtbar "
"offensichtlich und einfach ist, und Sie hätten Recht. Alles, was wir bisher "
"getan haben, ist, einige grundlegende mathematische Konzepte mit einigen "
"Intuitionen auf der Basis gesunden Menschenverstands zu verbinden. Aus "
"diesen einfachen Anfängen lassen sich jedoch einige äußerst leistungsfähige "
"mathematische Werkzeuge konstruieren. Ich werde in diesem Buch sicher nicht "
"ins Detail gehen, aber ich werde in :numref:`tab-probrules` einige der "
"anderen Regeln auflisten, die Wahrscheinlichkeiten erfüllen. Diese Regeln "
"lassen sich aus den einfachen Annahmen ableiten, die ich oben skizziert "
"habe. Aber da wir diese Regeln in diesem Buch nicht wirklich für irgendetwas "
"verwenden, werde ich das hier nicht tun."

#: ../../Ch07/Ch07_Probability_3.rst:125
msgid ""
"Some basic rules that probabilities must satisfy. You don’t really need to "
"know these rules in order to understand the analyses that we’ll talk about "
"later in the book, but they are important if you want to understand "
"probability theory a bit more deeply."
msgstr ""
"Wahrscheinlichkeiten müssen einige grundlegende Regeln erfüllen. Sie müssen "
"diese Regeln nicht unbedingt kennen, um die Analysen zu verstehen, über die "
"wir später im Buch sprechen werden, aber sie sind wichtig, wenn Sie die "
"Wahrscheinlichkeitstheorie etwas tiefer verstehen wollen."

#: ../../Ch07/Ch07_Probability_3.rst:134
msgid "English"
msgstr "Englisch"

#: ../../Ch07/Ch07_Probability_3.rst:134
msgid "Notation"
msgstr "Notation"

#: ../../Ch07/Ch07_Probability_3.rst:134
msgid "Formula"
msgstr "Formel"

#: ../../Ch07/Ch07_Probability_3.rst:136
msgid "not *A*"
msgstr "nicht *A*"

#: ../../Ch07/Ch07_Probability_3.rst:136
msgid "*P*\\ (¬ A)"
msgstr "*P*\\ (¬ A)"

#: ../../Ch07/Ch07_Probability_3.rst:136 ../../Ch07/Ch07_Probability_3.rst:138
#: ../../Ch07/Ch07_Probability_3.rst:140
msgid "="
msgstr "="

#: ../../Ch07/Ch07_Probability_3.rst:136
msgid "1 - *P*\\ (A)"
msgstr "1 - *P*\\ (A)"

#: ../../Ch07/Ch07_Probability_3.rst:138
msgid "*A* or *B*"
msgstr "*A* oder *B*"

#: ../../Ch07/Ch07_Probability_3.rst:138
msgid "*P*\\ (A ∪ B)"
msgstr "*P*\\ (A ∪ B)"

#: ../../Ch07/Ch07_Probability_3.rst:138
msgid "*P*\\ (A) + *P*\\ (B) - *P*\\ (A ∩ B)"
msgstr "*P*\\ (A) + *P*\\ (B) - *P*\\ (A ∩ B)"

#: ../../Ch07/Ch07_Probability_3.rst:140
msgid "*A* and *B*"
msgstr "*A* und *B*"

#: ../../Ch07/Ch07_Probability_3.rst:140
msgid "*P*\\ (A ∩ B)"
msgstr "*P*\\ (A ∩ B)"

#: ../../Ch07/Ch07_Probability_3.rst:140
msgid "*P*\\ (A|B) *P*\\ (B)"
msgstr "*P*\\ (A|B) *P*\\ (B)"

#: ../../Ch07/Ch07_Probability_4.rst:4
msgid "The binomial distribution"
msgstr "Die Binomialverteilung"

#: ../../Ch07/Ch07_Probability_4.rst:6
msgid ""
"As you might imagine, probability distributions vary enormously and there’s "
"an enormous range of distributions out there. However, they aren’t all "
"equally important. In fact, the vast majority of the content in this book "
"relies on one of five distributions: the binomial distribution, the normal "
"distribution, the *t*-distribution, the χ²-distribution (chi-square) and the "
"*F*-distribution. Given this, what I’ll do over the next few sections is "
"provide a brief introduction to all five of these, paying special attention "
"to the binomial and the normal. I’ll start with the binomial distribution "
"since it’s the simplest of the five."
msgstr ""
"Wie Sie sich vielleicht vorstellen können, sind "
"Wahrscheinlichkeitsverteilungen sehr unterschiedlich, und es gibt eine "
"enorme Bandbreite an Verteilungen. Sie sind jedoch nicht alle gleich "
"wichtig. Der größte Teil des Inhalts dieses Buches bezieht sich auf eine von "
"fünf Verteilungen: die Binomialverteilung, die Normalverteilung, die *t*-"
"Verteilung, die χ²-Verteilung (Chi-Quadrat) und die *F*-Verteilung. Aus "
"diesem Grund werde ich in den nächsten Abschnitten eine kurze Einführung in "
"alle fünf Verteilungen geben. Dabei werde ich besonders auf die Binomial- "
"und die Normalverteilung eingehen. Ich beginne mit der Binomialverteilung, "
"da sie die einfachste der fünf ist."

#: ../../Ch07/Ch07_Probability_4.rst:17
msgid "Introducing the binomial"
msgstr "Einführung des Binomialsystems"

#: ../../Ch07/Ch07_Probability_4.rst:19
msgid ""
"The theory of probability originated in the attempt to describe how games of "
"chance work, so it seems fitting that our discussion of the **binomial "
"distribution** should involve a discussion of rolling dice and flipping "
"coins. Let’s imagine a simple “experiment”. In my hot little hand I’m "
"holding 20 identical six-sided dice. On one face of each die there’s a "
"picture of a skull, the other five faces are all blank. If I proceed to roll "
"all 20 dice, what’s the probability that I’ll get exactly 4 skulls? Assuming "
"that the dice are fair, we know that the chance of any one die coming up "
"skulls is 1 in 6. To say this another way, the skull probability for a "
"single die is approximately 0.167. This is enough information to answer our "
"question, so let’s have a look at how it’s done."
msgstr ""
"Die Wahrscheinlichkeitstheorie hat ihren Ursprung in dem Versuch, die "
"Funktionsweise von Glücksspielen zu beschreiben. Daher erscheint es passend, "
"dass unsere Diskussion über die **Binomialverteilung** eine Diskussion über "
"das Würfeln und das Werfen von Münzen einschließt. Stellen wir uns ein "
"einfaches „Experiment“ vor. In meiner kleinen Hand halte ich 20 identische "
"sechsseitige Würfel. Auf einer Seite eines jeden Würfels ist ein Totenkopf "
"abgebildet, die anderen fünf Seiten sind leer. Wenn ich nun alle 20 Würfel "
"werfe, wie hoch ist die Wahrscheinlichkeit, dass ich genau 4 Totenköpfe "
"erhalte? Unter der Annahme, dass die Würfel „normal“ sind, wissen wir, dass "
"die Wahrscheinlichkeit, dass ein Würfel einen Schädel zeigt, 1 zu 6 ist. "
"Anders ausgedrückt: Die Wahrscheinlichkeit, dass ein einzelner Würfel einen "
"Schädel ergibt, liegt bei 0,167. Das sind genug Informationen, um unsere "
"Frage zu beantworten, also schauen wir uns an, wie das geht."

#: ../../Ch07/Ch07_Probability_4.rst:32
msgid ""
"Formulas for the binomial and normal distributions. We don’t really use "
"these formulas for anything in this book, but they’re pretty important for "
"more advanced work, so I thought it might be best to put them here in a "
"table, where they can’t get in the way of the text. In the equation for the "
"binomial, *X!* is the factorial function (i.e., multiply all whole numbers "
"from 1 to *X*), and for the normal distribution “exp” refers to the "
"exponential function, which we discussed in chapter :doc:`../Ch06/"
"Ch06_DataHandling`. If these equations don’t make a lot of sense to you, "
"don’t worry too much about them."
msgstr ""
"Formeln für die Binomial- und Normalverteilung. Wir verwenden diese Formeln "
"in diesem Buch eigentlich für nichts, aber sie sind ziemlich wichtig für "
"fortgeschrittene Arbeiten, daher dachte ich, es wäre am besten, sie hier in "
"einer Tabelle aufzuführen. In der Gleichung für die Binomialverteilung ist "
"*X!* die Fakultät (d.h. alle ganzen Zahlen von 1 bis *X* multiplizieren), "
"und für die Normalverteilung bezieht sich „exp“ auf die Exponentialfunktion, "
"die wir in Kapitel :doc:`../Ch06/Ch06_DataHandling` besprochen haben. Wenn "
"diese Gleichungen für Sie nicht viel Sinn ergeben, machen Sie sich nicht "
"allzu viele Gedanken darüber."

#: ../../Ch07/Ch07_Probability_4.rst:44
msgid "Binomial"
msgstr "Binomial"

#: ../../Ch07/Ch07_Probability_4.rst:44
msgid "Normal"
msgstr "Normal"

#: ../../Ch07/Ch07_Probability_4.rst:46
msgid "|binomial|"
msgstr "|binomial|"

#: ../../Ch07/Ch07_Probability_4.rst:46
msgid "|normal|"
msgstr "|normal|"

#: ../../Ch07/Ch07_Probability_4.rst:49
msgid ""
"As usual, we’ll want to introduce some names and some notation. We’ll let "
"*N* denote the number of dice rolls in our experiment, which is often "
"referred to as the **size parameter** of our binomial distribution. We’ll "
"also use *θ* to refer to the the probability that a single die comes up "
"skulls, a quantity that is usually called the **success probability** of the "
"binomial.\\ [#]_ Finally, we’ll use *X* to refer to the results of our "
"experiment, namely the number of skulls I get when I roll the dice. Since "
"the actual value of *X* is due to chance we refer to it as a **random "
"variable**. In any case, now that we have all this terminology and notation "
"we can use it to state the problem a little more precisely. The quantity "
"that we want to calculate is the probability that *X* = 4 given that we know "
"that *θ* = 0.167 and *N* = 20. The general “form” of the thing I’m "
"interested in calculating could be written as"
msgstr ""
"Wie üblich werden wir einige Namen und eine Notation einführen. Mit *N* "
"bezeichnen wir die Anzahl der Würfelwürfe in unserem Experiment, was oft als "
"**Größenparameter** unserer Binomialverteilung bezeichnet wird. Wir werden "
"auch *θ* verwenden, um uns auf die Wahrscheinlichkeit zu beziehen, dass ein "
"bestimmer Wurf einen Totenkopf ergibt, eine Größe, die gewöhnlich als "
"**Erfolgswahrscheinlichkeit** der Binomialverteilung bezeichnet wird.\\ [#]_ "
"Schließlich werden wir *X* verwenden, um uns auf die Ergebnisse unseres "
"Experiments zu beziehen, nämlich die Anzahl der Totenköpfe, die ich erhalte, "
"wenn ich würfele. Da der tatsächliche Wert von *X* auf den Zufall "
"zurückzuführen ist, bezeichnen wir ihn als **Zufallsvariable**. Da wir nun "
"alle diese Begriffe und Bezeichnungen kennen, können wir sie verwenden, um "
"das Problem ein wenig genauer zu formulieren. Die Größe, die wir berechnen "
"wollen, ist die Wahrscheinlichkeit, dass *X* = 4 ist, wenn wir wissen, dass "
"*θ* = 0,167 und *N* = 20 ist. Die allgemeine „Form“ der Sache, die ich "
"berechnen möchte, könnte wie folgt geschrieben werden"

#: ../../Ch07/Ch07_Probability_4.rst:65
msgid "*P*\\ (X | θ, N)"
msgstr "*P*\\ (X | θ, N)"

#: ../../Ch07/Ch07_Probability_4.rst:67
msgid ""
"and we’re interested in the special case where *X* = 4, *θ* = 0.167 and *N* "
"= 20. There’s only one more piece of notation I want to refer to before "
"moving on to discuss the solution to the problem. If I want to say that *X* "
"is generated randomly from a binomial distribution with parameters *θ* and "
"*N*, the notation I would use is as follows:"
msgstr ""
"und wir interessieren uns für den speziellen Fall, dass *X* = 4, *θ* = 0,167 "
"und *N* = 20 ist. Es gibt nur noch eine weitere Notation, auf die ich "
"hinweisen möchte, bevor ich zur Lösung des Problems übergehe. Wenn ich sagen "
"möchte, dass *X* zufällig aus einer Binomialverteilung mit den Parametern *θ*"
" und *N* generiert wird, würde ich die folgende Notation verwenden:"

#: ../../Ch07/Ch07_Probability_4.rst:74
msgid "*X* ~ Binomial(θ, N)"
msgstr "*X* ~ Binomial(θ, N)"

#: ../../Ch07/Ch07_Probability_4.rst:76
msgid ""
"Yeah, yeah. I know what you’re thinking: notation, notation, notation. "
"Really, who cares? Very few readers of this book are here for the notation, "
"so I should probably move on and talk about how to use the binomial "
"distribution. I’ve included the formula for the binomial distribution in :"
"numref:`tab-distformulas`, since some readers may want to play with it "
"themselves, but since most people probably don’t care that much and because "
"we don’t need the formula in this book, I won’t talk about it in any detail. "
"Instead, I just want to show you what the binomial distribution looks like."
msgstr ""
"Ja, ja, ja. Ich weiß, was Sie denken: Notation, Notation, Notation. "
"Wirklich, wen interessiert das? Die wenigsten Leser dieses Buches sind wegen "
"der Notation hier, also sollte ich wahrscheinlich weitermachen und darüber "
"sprechen, wie man die Binomialverteilung verwendet. Ich habe die Formel für "
"die Binomialverteilung in :numref:`tab-distformulas` aufgenommen, da einige "
"Leser vielleicht selbst damit spielen wollen, aber da die meisten Leute sich "
"wahrscheinlich nicht so sehr dafür interessieren und wir die Formel in "
"diesem Buch nicht brauchen, werde ich nicht im Detail darauf eingehen. "
"Stattdessen möchte ich Ihnen nur zeigen, wie die Binomialverteilung aussieht."

#: ../../Ch07/Ch07_Probability_4.rst:88
msgid "Binomial distribution for *N* = 20 and θ = 1/6"
msgstr "Binomialverteilung für *N* = 20 und θ = 1/6"

#: ../../Ch07/Ch07_Probability_4.rst:92
msgid ""
"Binomial distribution with size parameter of *N* = 20 and an underlying "
"success probability of θ = 1/6. Each vertical bar depicts the probability of "
"one specific outcome (i.e., one possible value of X). Because this is a "
"probability distribution, each of the probabilities must be a number between "
"0 and 1, and the heights of the bars must sum to 1 as well."
msgstr ""
"Binomialverteilung mit einem Größenparameter von *N* = 20 und einer zugrunde "
"liegenden Erfolgswahrscheinlichkeit von θ = 1/6. Jeder vertikale Balken "
"stellt die Wahrscheinlichkeit eines bestimmten Ergebnisses dar (d. h. einen "
"möglichen Wert von X). Da es sich um eine Wahrscheinlichkeitsverteilung "
"handelt, muss jede der Wahrscheinlichkeiten eine Zahl zwischen 0 und 1 sein, "
"und die Höhe aller Balken muss sich ebenfalls zu 1 summieren."

#: ../../Ch07/Ch07_Probability_4.rst:100
msgid ""
"To that end, :numref:`fig-binomSkulls20` plots the binomial probabilities "
"for all possible values of *X* for our dice rolling experiment, from *X* = 0 "
"(no skulls) all the way up to *X* = 20 (all skulls). Note that this is "
"basically a bar chart, and is no different to the “trousers probability” "
"plot I drew in :numref:`fig-pantsDistribution`. On the horizontal axis we "
"have all the possible events, and on the vertical axis we can read off the "
"probability of each of those events. So, the probability of rolling 4 skulls "
"out of 20 is about 0.20 (the actual answer is 0.2022036, as we’ll see in a "
"moment). In other words, you’d expect that to happen about 20\\% of the "
"times you repeated this experiment."
msgstr ""
"Zu diesem Zweck zeigt :numref:`fig-binomSkulls20` die binomischen "
"Wahrscheinlichkeiten für alle möglichen Werte von *X* in unserem "
"Würfelexperiment, von *X* = 0 (keine Totenköpfe) bis zu *X* = 20 (nur "
"Totenköpfe). Beachten Sie, dass dies im Grunde ein Balkendiagramm ist und "
"sich nicht von der Darstellung der „Hosenwahrscheinlichkeit“ unterscheidet, "
"die ich in :numref:`fig-pantsDistribution` gezeichnet habe. Auf der "
"horizontalen Achse befinden sich alle möglichen Ereignisse, und auf der "
"vertikalen Achse können wir die Wahrscheinlichkeit für jedes dieser "
"Ereignisse ablesen. Die Wahrscheinlichkeit, bei 4 von 20 Würfen Totenköpfe "
"zu erhalten, liegt also bei 0,20 (die genaue Antwort ist 0,2022036, wie wir "
"gleich sehen werden). Mit anderen Worten, es wäre zu erwarten, dass dies in "
"etwa 20 % der Fälle passiert, wenn das Experiment wiederholt wird."

#: ../../Ch07/Ch07_Probability_4.rst:111
msgid ""
"To give you a feel for how the binomial distribution changes when we alter "
"the values of *θ* and *N*, let’s suppose that instead of rolling dice I’m "
"actually flipping coins. This time around, my experiment involves flipping a "
"fair coin repeatedly and the outcome that I’m interested in is the number of "
"heads that I observe. In this scenario, the success probability is now *θ* = "
"1/2. Suppose I were to flip the coin *N* = 20 times. In this example, I’ve "
"changed the success probability but kept the size of the experiment the "
"same. What does this do to our binomial distribution? Well, as the left "
"panel of :numref:`fig-binomHeads` shows, the main effect of this is to shift "
"the whole distribution, as you’d expect. Okay, what if we flipped a coin *N* "
"= 100 times? Well, in that case we get what is shown in the right panel. The "
"distribution stays roughly in the middle but there’s a bit more variability "
"in the possible outcomes."
msgstr ""
"Um Ihnen ein Gefühl dafür zu vermitteln, wie sich die Binomialverteilung "
"verändert, wenn wir die Werte von *θ* und *N* ändern, nehmen wir an, dass "
"ich statt zu würfeln, Münzen werfe. Dieses Mal besteht mein Experiment "
"darin, eine „normale“ Münze wiederholt zu werfen. Das Ergebnis, das mich "
"interessiert, ist die Anzahl der Kopf-Würfe, die ich beobachte. In diesem "
"Szenario ist die Erfolgswahrscheinlichkeit *θ* = 1/2. Angenommen, ich werfe "
"die Münze *N* = 20 Mal. In diesem Beispiel habe ich die "
"Erfolgswahrscheinlichkeit geändert, aber den Umfang des Experiments gleich "
"gelassen. Was bedeutet das für unsere Binomialverteilung? Nun, wie :numref:"
"`fig-binomHeads` (links) zeigt, besteht der Haupteffekt darin, die gesamte "
"Verteilung zu verschieben, wie Sie es erwarten würden. Was würde passieren, "
"wenn wir eine Münze *N* = 100 Mal werfen würden? In diesem Fall erhalten wir "
"das, was auf der rechten Seite zu sehen ist. Die Verteilung bleibt ungefähr "
"in der Mitte, aber es gibt etwas mehr Variabilität bei den möglichen "
"Resultaten."

#: ../../Ch07/Ch07_Probability_4.rst:128
msgid "Binomial distribution: θ = 1/2 and *N* = 20 (left) or *N* = 100 (right)"
msgstr ""
"Binomialverteilung: θ = 1/2 und *N* = 20 (links) oder *N* = 100 (rechts)"

#: ../../Ch07/Ch07_Probability_4.rst:132
msgid ""
"Two binomial distributions, involving a scenario in which I’m flipping a "
"fair coin, so the underlying success probability is θ = 1/2. In the left "
"panel, we assume I’m flipping the coin *N* = 20 times. In the right panel, "
"we assume that the coin is flipped *N* = 100 times."
msgstr ""
"Zwei Binomialverteilungen in einem Szenario, in dem ich eine „normale“ Münze "
"werfe, so dass die zugrunde liegende Erfolgswahrscheinlichkeit θ = 1/2 ist. "
"Im linken Feld wird angenommen, dass ich die Münze *N* = 20 Mal werfe. Im "
"rechten Feld nehmen wir an, dass die Münze *N* = 100-mal geworfen wird."

#: ../../Ch07/Ch07_Probability_4.rst:142
msgid ""
"Note that the term “success” is pretty arbitrary and doesn’t actually imply "
"that the outcome is something to be desired. If *θ* referred to the "
"probability that any one passenger gets injured in a bus crash I’d still "
"call it the success probability, but that doesn’t mean I want people to get "
"hurt in bus crashes!"
msgstr ""
"Beachten Sie, dass der Begriff „Erfolg“ ziemlich willkürlich ist und "
"eigentlich nicht bedeutet, dass das Ergebnis etwas Erwünschtes ist. Wenn *θ* "
"sich auf die Wahrscheinlichkeit bezöge, dass ein Fahrgast bei einem "
"Busunfall verletzt wird, würde ich es immer noch Erfolgswahrscheinlichkeit "
"nennen, aber das bedeutet nicht, dass ich will, dass Menschen bei "
"Busunfällen verletzt werden!"

#: ../../Ch07/Ch07_Probability_5.rst:4
msgid "The normal distribution"
msgstr "Die Normalverteilung"

#: ../../Ch07/Ch07_Probability_5.rst:6
msgid ""
"While the binomial distribution is conceptually the simplest distribution to "
"understand, it’s not the most important one. That particular honour goes to "
"the **normal distribution**, also referred to as “the bell curve” or a "
"“Gaussian distribution”. A normal distribution is described using two "
"parameters: the mean of the distribution µ and the standard deviation of the "
"distribution σ."
msgstr ""
"Die Binomialverteilung ist zwar konzeptionell am einfachsten zu verstehen, "
"sie ist aber nicht die wichtigste Verteilung. Diese Ehre kommt der "
"**Normalverteilung** zu, die auch als „Glockenkurve“ oder „Gaußverteilung“ "
"bezeichnet wird. Eine Normalverteilung wird durch zwei Parameter "
"beschrieben: den Mittelwert der Verteilung µ und die Standardabweichung der "
"Verteilung σ."

#: ../../Ch07/Ch07_Probability_5.rst:13
msgid ""
"The notation that we sometimes use to say that a variable *X* is normally "
"distributed is as follows:"
msgstr ""
"Die Notation, die wir verwenden, um zu sagen, dass eine Variable *X* "
"normalverteilt ist, lautet wie folgt:"

#: ../../Ch07/Ch07_Probability_5.rst:16
msgid "X ~ Normal(µ, σ)"
msgstr "X ~ Normal(µ, σ)"

#: ../../Ch07/Ch07_Probability_5.rst:18
msgid ""
"Of course, that’s just notation. It doesn’t tell us anything interesting "
"about the normal distribution itself. As was the case with the binomial "
"distribution, I have included the formula for the normal distribution in "
"this book, because I think it’s important enough that everyone who learns "
"statistics should at least look at it, but since this is an introductory "
"text I don’t want to focus on it, so I’ve tucked it away in :numref:`tab-"
"distformulas`."
msgstr ""
"Das ist natürlich nur eine Notation. Sie sagt uns nichts Interessantes über "
"die Normalverteilung selbst. Wie bei der Binomialverteilung habe ich die "
"Formel für die Normalverteilung in dieses Buch aufgenommen, weil ich sie für "
"so wichtig halte, dass jeder, der Statistik lernt, sie sich zumindest einmal "
"gesehen haben sollte. Da es sich aber um einen Einführungstext handelt, "
"möchte ich mich nicht zu sehr darauf konzentrieren. Deshalb habe ich sie in "
":numref:`tab-distformulas` versteckt."

#: ../../Ch07/Ch07_Probability_5.rst:28
msgid "Normal distribution with mean μ = 0 and standard deviation σ = 1"
msgstr ""
"Normalverteilung mit dem Mittelwert μ = 0 und der Standardabweichung σ = 1"

#: ../../Ch07/Ch07_Probability_5.rst:32
msgid ""
"The normal distribution with mean μ = 0 and standard deviation σ = 1. The x-"
"axis corresponds to the value of some variable, and the y-axis tells us "
"something about how likely we are to observe that value. However, notice "
"that the y-axis is labelled “Probability Density” and not “Probability”. "
"There is a subtle and somewhat frustrating characteristic of continuous "
"distributions that makes the y axis behave a bit oddly: the height of the "
"curve here isn’t actually the probability of observing a particular x value. "
"On the other hand, it is true that the heights of the curve tells you which "
"x values are more likely (the higher ones!; see :ref:`Probability density "
"<probability_density>` for all the annoying details)."
msgstr ""
"Die Normalverteilung hat einen Mittelwert μ = 0 und eine Standardabweichung "
"σ = 1. Die x-Achse entspricht dem Wert einer Variablen, und die y-Achse sagt "
"uns etwas darüber, wie wahrscheinlich es ist, dass wir diesen Wert "
"beobachten. Beachten Sie jedoch, dass die y-Achse mit „*Probability "
"Density*“ („Wahrscheinlichkeitsdichte“) und nicht mit "
"„*Probability*“ („Wahrscheinlichkeit“) beschriftet ist. Es gibt eine subtile "
"und etwas frustrierende Eigenschaft kontinuierlicher Verteilungen, die dazu "
"führen, dass die y-Achse sich etwas seltsam verhält: Die Höhe der Kurve ist "
"hier nicht wirklich die Wahrscheinlichkeit, einen bestimmten x-Wert zu "
"beobachten. Andererseits ist es richtig, dass die Höhe der Kurve angibt, "
"welche x-Werte wahrscheinlicher sind (die höheren!; siehe :ref:"
"`Wahrscheinlichkeitsdichte <probability_density>` für alle lästigen Details)."

#: ../../Ch07/Ch07_Probability_5.rst:45
msgid ""
"Instead of focusing on the maths, let’s try to get a sense for what it means "
"for a variable to be normally distributed. To that end, have a look at :"
"numref:`fig-standardNormal` which plots a normal distribution with mean µ = "
"0 and standard deviation σ = 1. You can see where the name “bell curve” "
"comes from; it looks a bit like a bell. Notice that, unlike the plots that I "
"drew to illustrate the binomial distribution, the picture of the normal "
"distribution in :numref:`fig-standardNormal` shows a smooth curve instead of "
"“histogram-like” bars. This isn’t an arbitrary choice, the normal "
"distribution is continuous whereas the binomial is discrete. For instance, "
"in the die rolling example from the last section it was possible to get 3 "
"skulls or 4 skulls, but impossible to get 3.9 skulls. The figures that I "
"drew in the previous section reflected this fact. In :numref:`fig-"
"binomSkulls20`, for instance, there’s a bar located at *X* = 3 and another "
"one at *X* = 4 but there’s nothing in between. Continuous quantities don’t "
"have this constraint. For instance, suppose we’re talking about the weather. "
"The temperature on a pleasant Spring day could be 23 degrees, 24 degrees, "
"23.9 degrees, or anything in between since temperature is a continuous "
"variable |continuous|. And so a normal distribution might be quite "
"appropriate for describing Spring temperatures.\\ [#]_"
msgstr ""
"Anstatt sich auf die Mathematik zu konzentrieren, sollten wir versuchen, ein "
"Gefühl dafür zu bekommen, was es bedeutet, wenn eine Variable normalverteilt "
"ist. Zu diesem Zweck sehen Sie sich :numref:`fig-standardNormal` an, welche "
"eine Normalverteilung mit dem Mittelwert µ = 0 und der Standardabweichung σ "
"= 1 abbildet. Sie sehen, woher der Name „Glockenkurve“ kommt; sie sieht ein "
"wenig wie eine Glocke aus. Beachten Sie, dass im Gegensatz zu den Grafiken, "
"die ich zur Veranschaulichung der Binomialverteilung gezeichnet habe, das "
"Bild der Normalverteilung in :numref:`fig-standardNormal` eine glatte Kurve "
"anstelle von „histogrammartigen“ Balken zeigt. Dies ist keine willkürliche "
"Wahl, denn die Normalverteilung ist kontinuierlich, während die "
"Binomialverteilung diskret ist. Im Würfel-Beispiel aus dem letzten Abschnitt "
"war es zum Beispiel möglich, 3 oder 4 Schädel zu erhalten, aber unmöglich, "
"3,9 Schädel zu erhalten. Die Zahlen, die ich im vorherigen Abschnitt "
"gezeichnet habe, spiegeln diese Tatsache wider. In :numref:`fig-"
"binomSkulls20` gibt es zum Beispiel einen Balken bei *X* = 3 und einen "
"weiteren bei *X* = 4, aber dazwischen gibt es nichts. Für kontinuierliche "
"Mengen gilt diese Einschränkung nicht. Nehmen wir zum Beispiel an, wir "
"sprechen über das Wetter. Die Temperatur an einem angenehmen Frühlingstag "
"könnte 23 Grad, 24 Grad, 23,9 Grad oder irgendetwas dazwischen betragen, da "
"die Temperatur eine kontinuierliche Variable |continuous| ist. Eine "
"Normalverteilung könnte also durchaus geeignet sein, um die "
"Frühlingstemperaturen zu beschreiben.\\ [#]_"

#: ../../Ch07/Ch07_Probability_5.rst:252
msgid "continuous"
msgstr "continuous"

#: ../../Ch07/Ch07_Probability_5.rst:68
msgid "Normal distribution: σ = 1 and µ = 4 (solid) or µ = 7 (dashed)"
msgstr ""
"Normalverteilung: σ = 1 und µ = 4 (durchgezogene Linie) oder µ = 7 ("
"gestrichelte Linie)"

#: ../../Ch07/Ch07_Probability_5.rst:72
msgid ""
"Illustration of what happens when you change the mean of a normal "
"distribution. The solid line depicts a normal distribution with a mean of μ "
"= 4. The dashed line shows a normal distribution with a mean of μ = 7. In "
"both cases, the standard deviation is σ = 1. Not surprisingly, the two "
"distributions have the same shape, but the dashed line is shifted to the "
"right."
msgstr ""
"Illustration, was passiert, wenn man den Mittelwert einer Normalverteilung "
"ändert. Die durchgezogene Linie stellt eine Normalverteilung mit einem "
"Mittelwert von μ = 4 dar. Die gestrichelte Linie zeigt eine Normalverteilung "
"mit einem Mittelwert von μ = 7. In beiden Fällen beträgt die "
"Standardabweichung σ = 1. Es überrascht nicht, dass die beiden Verteilungen "
"die gleiche Form haben, aber die gestrichelte Linie ist nach rechts "
"verschoben."

#: ../../Ch07/Ch07_Probability_5.rst:81
msgid ""
"With this in mind, let’s see if we can’t get an intuition for how the normal "
"distribution works. First, let’s have a look at what happens when we play "
"around with the parameters of the distribution. To that end, :numref:`fig-"
"meanShiftNormal` plots normal distributions that have different means but "
"have the same standard deviation. As you might expect, all of these "
"distributions have the same “width”. The only difference between them is "
"that they’ve been shifted to the left or to the right. In every other "
"respect they’re identical. In contrast, if we increase the standard "
"deviation while keeping the mean constant, the peak of the distribution "
"stays in the same place but the distribution gets wider, as you can see in :"
"numref:`fig-scaleShiftNormal`."
msgstr ""
"Lassen Sie uns sehen, ob wir ein Gefühl dafür bekommen, wie die "
"Normalverteilung funktioniert. Schauen wir uns zunächst an, was passiert, "
"wenn wir mit den Parametern der Verteilung herumspielen. Zu diesem Zweck "
"stellt :numref:`fig-meanShiftNormal` Normalverteilungen dar, die "
"unterschiedliche Mittelwerte, aber die gleiche Standardabweichung haben. Wie "
"zu erwarten, haben alle diese Verteilungen die gleiche „Breite“. Der einzige "
"Unterschied zwischen ihnen ist, dass sie nach links oder rechts verschoben "
"wurden. In jeder anderen Hinsicht sind sie identisch. Erhöht man dagegen die "
"Standardabweichung, während der Mittelwert sich nicht verändert, bleibt der "
"Scheitelpunkt der Verteilung an der gleichen Stelle, aber die Verteilung "
"wird breiter, wie Sie in :numref:`fig-scaleShiftNormal` sehen können."

#: ../../Ch07/Ch07_Probability_5.rst:95
msgid "Normal distribution: µ = 5 and σ = 1 (solid) or σ = 2 (dashed)"
msgstr ""
"Normalverteilung: µ = 5 und σ = 1 (durchgezogene Linie) oder σ = 2 ("
"gestrichelte Linie)"

#: ../../Ch07/Ch07_Probability_5.rst:99
msgid ""
"Illustration of what happens when you change the standard deviation of a "
"normal distribution. Both distributions plotted in this figure have a mean "
"of μ = 5, but they have different standard deviations. The solid line plots "
"a distribution with standard deviation σ = 1, and the dashed line shows a "
"distribution with standard deviation σ = 2. As a consequence, both "
"distributions are “centred” on the same spot, but the dashed line is wider "
"than the solid one."
msgstr ""
"Illustration, was passiert, wenn man die Standardabweichung einer "
"Normalverteilung ändert. Beide in dieser Abbildung dargestellten "
"Verteilungen haben einen Mittelwert von μ = 5, aber sie haben "
"unterschiedliche Standardabweichungen. Die durchgezogene Linie stellt eine "
"Verteilung mit einer Standardabweichung σ = 1 dar, die gestrichelte Linie "
"eine Verteilung mit einer Standardabweichung σ = 2. Folglich sind beide "
"Verteilungen auf demselben Punkt „zentriert“, aber die gestrichelte Linie "
"ist breiter als die durchgezogene Linie."

#: ../../Ch07/Ch07_Probability_5.rst:109
msgid ""
"Notice, though, that when we widen the distribution the height of the peak "
"shrinks. This has to happen, in the same way that the heights of the bars "
"that we used to draw a discrete binomial distribution have to *sum* to 1, "
"the total *area under the curve* for the normal distribution must equal 1. "
"Before moving on, I want to point out one important characteristic of the "
"normal distribution. Irrespective of what the actual mean and standard "
"deviation are, 68.3\\% of the area falls within 1 standard deviation of the "
"mean. Similarly, 95.4\\% of the distribution falls within 2 standard "
"deviations of the mean, and 99.7\\% of the distribution is within 3 standard "
"deviations. This idea is illustrated in :numref:`fig-normAreaSD`."
msgstr ""
"Beachten Sie jedoch, dass die Höhe der Spitze schrumpft, wenn wir die "
"Verteilung verbreitern. Genauso wie die Höhen der Balken, die wir zum "
"Zeichnen einer diskreten Binomialverteilung verwendet haben, die *Summe* zu "
"1 ergeben müssen, muss die *Gesamtfläche unter der Kurve* für die "
"Normalverteilung gleich 1 sein. Bevor ich fortfahre, möchte ich auf eine "
"wichtige Eigenschaft der Normalverteilung hinweisen. Unabhängig davon, wie "
"hoch der tatsächliche Mittelwert und die Standardabweichung sind, liegt 68,3 "
"% der Fläche innerhalb einer Standardabweichung um den Mittelwert. In "
"ähnlicher Weise liegt 95,4 % der Verteilung innerhalb von 2 "
"Standardabweichungen um den Mittelwert und 99,7 % der Verteilung innerhalb "
"von 3 Standardabweichungen. Diese Idee wird in :numref:`fig-normAreaSD` "
"veranschaulicht."

#: ../../Ch07/Ch07_Probability_5.rst:123
msgid "Normal distribution: area under the curve for 1 and 2 SD"
msgstr "Normalverteilung: Fläche unter der Kurve für 1 und 2 SD (Standardabw.)"

#: ../../Ch07/Ch07_Probability_5.rst:127
msgid ""
"The area under the curve tells you the probability that an observation falls "
"within a particular range. The solid lines plot normal distributions with "
"mean μ = 0 and standard deviation σ = 1. The shaded areas illustrate “areas "
"under the curve” for two important cases. In the left panel, we can see that "
"there is a 68.3\\% chance that an observation will fall within one standard "
"deviation of the mean. In the right panel, we see that there is a 95.4\\% "
"chance that an observation will fall within two standard deviations of the "
"mean."
msgstr ""
"Die Fläche unter der Kurve gibt die Wahrscheinlichkeit an, dass eine "
"Beobachtung in einen bestimmten Bereich fällt. Die durchgezogenen Linien "
"stellen Normalverteilungen mit Mittelwert μ = 0 und Standardabweichung σ = 1 "
"dar. Die schattierten Flächen zeigen die „Flächen unter der Kurve“ für zwei "
"wichtige Fälle. Links sehen wir, dass die Wahrscheinlichkeit, dass eine "
"Beobachtung innerhalb einer Standardabweichung um den Mittelwert liegt, 68,3 "
"% beträgt. Rechts sehen wir, dass die Wahrscheinlichkeit, dass eine "
"Beobachtung innerhalb von zwei Standardabweichungen um den Mittelwert liegt, "
"95,4 % beträgt."

#: ../../Ch07/Ch07_Probability_5.rst:138
msgid "Area under the curve for 1 SD bordering the mean and at the tails"
msgstr ""
"Fläche unter der Kurve für 1 SD direkt neben dem Mittelwert sowie am "
"Ausläufer der Verteilung"

#: ../../Ch07/Ch07_Probability_5.rst:142
msgid ""
"Two more examples of the “area under the curve” idea. There is a 15.9\\% "
"chance that an observation is one standard deviation below the mean or "
"smaller (left panel), and a 34.1\\% chance that the observation is somewhere "
"between one standard deviation below the mean and the mean (right panel). "
"Notice that if you add these two numbers together you get 15.9\\% + 34.1\\% "
"= 50\\%. For normally distributed data, there is a 50\\% chance that an "
"observation falls below the mean. And of course that also implies that there "
"is a 50\\% chance that it falls above the mean."
msgstr ""
"Zwei weitere Beispiele für die Idee der „Fläche unter der Kurve“. Die "
"Wahrscheinlichkeit, dass eine Beobachtung eine Standardabweichung unter dem "
"Mittelwert oder darunter liegt, beträgt 15,9 % (links), und die "
"Wahrscheinlichkeit, dass die Beobachtung irgendwo zwischen einer "
"Standardabweichung unter dem Mittelwert und dem Mittelwert liegt, beträgt "
"34,1 % (rechts). Wenn Sie diese beiden Zahlen zusammenzählen, erhalten Sie "
"15,9 % + 34.1 % = 50 %. Bei normalverteilten Daten besteht eine 50 % "
"Wahrscheinlichkeit, dass eine Beobachtung unter dem Mittelwert liegt. Das "
"bedeutet natürlich auch, dass die Wahrscheinlichkeit, dass sie über dem "
"Mittelwert liegt, ebenfalls 50 % beträgt."

#: ../../Ch07/Ch07_Probability_5.rst:156
msgid "Probability density"
msgstr "Wahrscheinlichkeitsdichte"

#: ../../Ch07/Ch07_Probability_5.rst:158
msgid ""
"There’s something I’ve been trying to hide throughout my discussion of the "
"normal distribution, something that some introductory textbooks omit "
"completely. They might be right to do so. This “thing” that I’m hiding is "
"weird and counter-intuitive even by the admittedly distorted standards that "
"apply in statistics. Fortunately, it’s not something that you need to "
"understand at a deep level in order to do basic statistics. Rather, it’s "
"something that starts to become important later on when you move beyond the "
"basics. So, if it doesn’t make complete sense, don’t worry too much, but try "
"to make sure that you follow the gist of it."
msgstr ""
"Es gibt etwas, das ich während meiner gesamten Diskussion über die "
"Normalverteilung zu verbergen versucht habe. Es ist etwas, das selbst einige "
"einführende Lehrbücher völlig auslassen und sie haben vielleicht Recht "
"damit. Diese „Sache“, die ich verheimliche, ist selbst nach den "
"zugegebenermaßen verzerrten Maßstäben, die in der Statistik gelten, seltsam "
"und kontraintuitiv. Glücklicherweise ist es nichts, was man auf einer tiefen "
"Ebene verstehen muss, um Statistiken zu erstellen. Vielmehr ist es eher "
"etwas, was erst später wichtig wird, wenn man über die Grundlagen "
"hinausgeht. Machen Sie sich also keine allzu großen Sorgen, wenn es nicht "
"ganz verständlich ist, aber versuchen Sie, das Wesentliche zu verstehen."

#: ../../Ch07/Ch07_Probability_5.rst:168
msgid ""
"Throughout my discussion of the normal distribution there’s been one or two "
"things that don’t quite make sense. Perhaps you noticed that the *y*-axis in "
"these figures is labelled “Probability Density” rather than “Density”. Maybe "
"you noticed that I used *p*\\ (X) instead of *P*\\ (X) when giving the "
"formula for the normal distribution."
msgstr ""
"Während meiner Diskussion über die Normalverteilung gab es ein oder zwei "
"Dinge, die vielleicht keinen Sinn ergaben. Vielleicht ist Ihnen aufgefallen, "
"dass die *y*-Achse in diesen Abbildungen mit „Wahrscheinlichkeitsdichte“ und "
"nicht mit „Dichte“ beschriftet ist. Und vielleicht ist Ihnen aufgefallen, "
"dass ich *p*\\ (X) anstelle von *P*\\ (X) verwendet habe, als ich die Formel "
"für die Normalverteilung angegeben habe."

#: ../../Ch07/Ch07_Probability_5.rst:174
msgid ""
"As it turns out, what is presented here isn’t actually a probability, it’s "
"something else. To understand what that something is you have to spend a "
"little time thinking about what it really *means* to say that *X* is a "
"continuous variable |continuous|. Let’s say we’re talking about the "
"temperature outside. The thermometer tells me it’s 23 degrees, but I know "
"that’s not really true. It’s not *exactly* 23 degrees. Maybe it’s \\23.1 "
"degrees, I think to myself. But I know that that’s not really true either "
"because it might actually be 23.09 degrees. But I know that… well, you get "
"the idea. The tricky thing with genuinely continuous quantities is that you "
"never really know exactly what they are."
msgstr ""
"Wie sich herausstellt, ist das, was hier dargestellt wird, nicht wirklich "
"eine Wahrscheinlichkeit, sondern etwas anderes. Um zu verstehen, was dieses "
"Etwas ist, muss man ein wenig Zeit damit verbringen, darüber nachzudenken, "
"was es wirklich *bedeutet* zu sagen, dass *X* eine kontinuierliche Variable |"
"continuous| ist. Nehmen wir an, wir sprechen über die Außentemperatur. Das "
"Thermometer sagt mir, dass es 23 Grad sind, aber ich weiß, dass das nicht "
"wirklich stimmt. Es ist nicht *genau* 23 Grad. Vielleicht sind es 23,1 Grad. "
"Aber ich weiß, dass das auch nicht wirklich stimmt, denn es könnten auch "
"23,09 Grad sein. Aber ich weiß, dass… Sie verstehen schon. Das Tückische an "
"wirklich kontinuierlichen Größen ist, dass man ihre exakte Größe nie genau "
"kennt."

#: ../../Ch07/Ch07_Probability_5.rst:185
msgid ""
"Now think about what this implies when we talk about probabilities. Suppose "
"that tomorrow’s maximum temperature is sampled from a normal distribution "
"with mean 23 and standard deviation 1. What’s the probability that the "
"temperature will be *exactly* 23 degrees? The answer is “zero”, or possibly "
"“a number so close to zero that it might as well be zero”. Why is this? It’s "
"like trying to throw a dart at an infinitely small dart board. No matter how "
"good your aim, you’ll never hit it. In real life you’ll never get a value of "
"exactly 23. It’ll always be something like 23.1 or 22.99998 or suchlike. In "
"other words, it’s completely meaningless to talk about the probability that "
"the temperature is exactly 23 degrees. However, in everyday language if I "
"told you that it was 23 degrees outside and it turned out to be 22.9998 "
"degrees you probably wouldn’t call me a liar. Because in everyday language "
"“23 degrees” usually means something like “somewhere between \\22.5 and 23.5 "
"degrees”. And while it doesn’t feel very meaningful to ask about the "
"probability that the temperature is exactly 23 degrees, it does seem "
"sensible to ask about the probability that the temperature lies between 22.5 "
"and 23.5, or between 20 and 30, or any other range of temperatures."
msgstr ""
"Überlegen Sie nun, was dies bedeutet, wenn wir über Wahrscheinlichkeiten "
"sprechen. Nehmen wir an, dass die morgige Höchsttemperatur aus einer "
"Normalverteilung mit dem Mittelwert 23 und der Standardabweichung 1 "
"abgeleitet ist (gezogen wurde). Wie groß ist die Wahrscheinlichkeit, dass "
"die Temperatur *genau* 23 Grad betragen wird? Die Antwort ist „Null“, oder "
"möglicherweise „eine Zahl, die so nahe bei Null liegt, dass sie genauso gut "
"Null sein könnte“. Warum ist das so? Es ist, als würde man versuchen, einen "
"Dartpfeil auf eine unendlich kleine Dartscheibe zu werfen. Egal wie gut Sie "
"zielen, Sie werden nie genau treffen. Im wirklichen Leben werden Sie nie "
"einen Wert von genau 23 erhalten. Es wird immer etwas wie 23,1 oder 22,99998 "
"oder so ähnlich sein. Mit anderen Worten: Es ist völlig sinnlos, über die "
"Wahrscheinlichkeit zu sprechen, dass die Temperatur genau 23 Grad beträgt. "
"Wenn ich Ihnen aber in der Alltagssprache sage, dass es draußen 23 Grad warm "
"ist, und es sind 22,9998 Grad, dann würden Sie mich wahrscheinlich nicht als "
"Lügner bezeichnen. Denn in der Alltagssprache bedeutet „23 Grad“ "
"normalerweise so viel wie „irgendwo zwischen 22,5 und 23,5 Grad“. Und obwohl "
"es nicht sehr sinnvoll ist, nach der Wahrscheinlichkeit zu fragen, dass die "
"Temperatur genau 23 Grad beträgt, scheint es doch sinnvoll zu sein, nach der "
"Wahrscheinlichkeit zu fragen, dass die Temperatur zwischen 22,5 und 23,5 "
"oder zwischen 20 und 30 oder einem anderen Temperaturbereich liegt."

#: ../../Ch07/Ch07_Probability_5.rst:205
msgid ""
"The point of this discussion is to make clear that when we’re talking about "
"continuous distributions it’s not meaningful to talk about the probability "
"of a specific value. However, what we *can* talk about is the probability "
"that the value lies within a particular range of values. To find out the "
"probability associated with a particular range what you need to do is "
"calculate the “area under the curve”. We’ve seen this concept already, in :"
"numref:`fig-normAreaSD` the shaded areas shown depict genuine probabilities "
"(e.g., in the left panel of :numref:`fig-normAreaSD` it shows the "
"probability of observing a value that falls within 1 standard deviation of "
"the mean)."
msgstr ""
"Diese Diskussion soll deutlich machen, dass es bei kontinuierlichen "
"Verteilungen nicht sinnvoll ist, über die Wahrscheinlichkeit eines "
"bestimmten Wertes zu sprechen. Worüber wir jedoch sprechen *können*, ist die "
"Wahrscheinlichkeit, dass der Wert innerhalb eines bestimmten Wertebereichs "
"liegt. Um die mit einem bestimmten Bereich verbundene Wahrscheinlichkeit zu "
"ermitteln, muss man die „Fläche unter der Kurve“ berechnen. Wir haben dieses "
"Konzept bereits gesehen, in :numref:`fig-normAreaSD` stellen die "
"schattierten Bereiche echte Wahrscheinlichkeiten dar (z.B. zeigt das linke "
"Feld von :numref:`fig-normAreaSD` die Wahrscheinlichkeit, einen Wert zu "
"beobachten, der innerhalb einer Standardabweichung vom Mittelwert liegt)."

#: ../../Ch07/Ch07_Probability_5.rst:216
msgid ""
"Okay, so that explains part of the story. I’ve explained a little bit about "
"how continuous probability distributions should be interpreted (i.e., area "
"under the curve is the key thing). But what does the formula for *p*\\ (x) "
"that I described earlier actually mean? Obviously, p*\\ (x) doesn’t describe "
"a probability, but what is it? The name for this quantity *p*\\ (x) is a "
"**probability density**, and in terms of the plots we’ve been drawing it "
"corresponds to the *height* of the curve. The densities themselves aren’t "
"meaningful in and of themselves, but they’re “rigged” to ensure that the "
"*area* under the curve is always interpretable as genuine probabilities. To "
"be honest, that’s about as much as you really need to know for now.\\ [#]_"
msgstr ""
"Damit ist ein Teil der Geschichte erklärt. Ich habe ein wenig erklärt, wie "
"kontinuierliche Wahrscheinlichkeitsverteilungen zu interpretieren sind (d. "
"h. die Fläche unter der Kurve ist das Wichtigste). Aber was bedeutet "
"eigentlich die Formel für *p*\\ (x), die ich vorhin beschrieben habe? "
"Offensichtlich beschreibt *p*\\ (x) keine Wahrscheinlichkeit, aber was ist "
"es dann? Der Name für diese Größe *p*\\ (x) ist **Wahrscheinlichkeitsdichte**"
". In Bezug auf die Diagramme, die wir gezeichnet haben, entspricht sie der "
"*Höhe* der Kurve. Die Dichten selbst sind an und für sich nicht "
"aussagekräftig, aber sie werden „manipuliert“, um sicherzustellen, dass die "
"*Fläche* unter der Kurve immer als echte Wahrscheinlichkeiten interpretiert "
"werden kann. Um ehrlich zu sein, ist das alles, was Sie im Moment wissen "
"müssen.\\ [#]_"

#: ../../Ch07/Ch07_Probability_5.rst:231
msgid ""
"In practice, the normal distribution is so handy that people tend to use it "
"even when the variable isn’t actually continuous. As long as there are "
"enough categories (e.g., Likert scale responses to a questionnaire), it’s "
"pretty standard practice to use the normal distribution as an approximation. "
"This works out much better in practice than you’d think."
msgstr ""
"In der Praxis ist die Normalverteilung so praktisch, dass man sie auch dann "
"verwendet, wenn die Variable eigentlich nicht kontinuierlich ist. Solange es "
"genügend Kategorien gibt (z. B. Antworten auf einer Likert-Skala in einem "
"Fragebogen), ist es ziemlich üblich, die Normalverteilung als Näherung zu "
"verwenden. Das funktioniert in der Praxis viel besser, als man denken würde."

#: ../../Ch07/Ch07_Probability_5.rst:239
msgid ""
"For those readers who know a little calculus, I’ll give a slightly more "
"precise explanation. In the same way that probabilities are non-negative "
"numbers that must sum to 1, probability densities are non-negative numbers "
"that must integrate to 1 (where the integral is taken across all possible "
"values of *X*). To calculate the probability that *X* falls between *a* and "
"*b* we calculate the definite integral of the density function over the "
"corresponding range, :math:`\\int_a^b p(x) \\ dx`. If you don’t remember or "
"never learned calculus, don’t worry about this. It’s not needed for this "
"book."
msgstr ""
"Für die Leser, die sich ein wenig mit Infinitesimalrechnung auskennen, werde "
"ich eine etwas genauere Erklärung geben. Genauso wie Wahrscheinlichkeiten "
"nicht-negative Zahlen sind, die sich zu 1 summieren müssen, sind "
"Wahrscheinlichkeitsdichten nicht-negative Zahlen, deren Integral 1 ergeben "
"muss (wobei das Integral über alle möglichen Werte von *X* genommen wird). "
"Um die Wahrscheinlichkeit zu berechnen, dass *X* zwischen *a* und *b* liegt, "
"berechnen wir das definite Integral der Dichtefunktion über den "
"entsprechenden Bereich, :math:`\\int_a^b p(x) \\ dx`. Wenn Sie sich nicht an "
"Infinitesimalrechnung erinnern oder sie nie gelernt haben, brauchen Sie sich "
"keine Sorgen zu machen. Es ist für dieses Buch nicht erforderlich."

#: ../../Ch07/Ch07_Probability_6.rst:4
msgid "Other useful distributions"
msgstr "Weitere nützliche Verteilungen"

#: ../../Ch07/Ch07_Probability_6.rst:6
msgid ""
"The normal distribution is the distribution that statistics makes most use "
"of (for reasons to be discussed shortly), and the binomial distribution is a "
"very useful one for lots of purposes. But the world of statistics is filled "
"with probability distributions, some of which we’ll run into in passing. In "
"particular, the three that will appear in this book are the *t*-"
"distribution, the χ²-distribution and the *F*-distribution. I won’t give "
"formulas for any of these, or talk about them in too much detail, but I will "
"show you some pictures."
msgstr ""
"Die Normalverteilung ist die Verteilung, die in der Statistik am häufigsten "
"verwendet wird (aus Gründen, die in Kürze erläutert werden), und auch die "
"Binomialverteilung ist für viele Zwecke sehr nützlich. Aber die Welt der "
"Statistik ist voll von Wahrscheinlichkeitsverteilungen, von denen wir einige "
"nur am Rande kennenlernen werden. Die drei, die in diesem Buch vorkommen "
"werden, sind die *t*-Verteilung, die χ²-Verteilung und die *F*-Verteilung. "
"Ich werde keine Formeln für diese Verteilungen angeben oder zu detailliert "
"auf sie eingehen, aber ich werde Ihnen einige Bilder zeigen."

#: ../../Ch07/Ch07_Probability_6.rst:15
msgid ""
"The **t-distribution** is a continuous distribution that looks very similar "
"to a normal distribution, see :numref:`fig-tdist`. Note that the “tails” of "
"the *t*-distribution are “heavier” (i.e., extend further outwards) than the "
"tails of the normal distribution). That’s the important difference between "
"the two. This distribution tends to arise in situations where you think that "
"the data actually follow a normal distribution, but you don’t know the mean "
"or standard deviation. We’ll run into this distribution again in chapter :"
"doc:`../Ch11/Ch11_tTest`."
msgstr ""
"Die **t-Verteilung** ist eine kontinuierliche Verteilung, die einer "
"Normalverteilung sehr ähnlich sieht, siehe :numref:`fig-tdist`. Beachten "
"Sie, dass die „Ausläufer“ der *t*-Verteilung „schwerer“ sind (d.h. sie "
"reichen weiter nach außen) als die Schwänze der Normalverteilung. Das ist "
"der wichtigste Unterschied zwischen den beiden. Die *t*-Verteilung wird in "
"der Regel in Situationen verwendet, in denen man denkt, dass die Daten "
"tatsächlich einer Normalverteilung folgen, man aber weder den „wahren“ "
"Mittelwert noch die Standardabweichung (in der Population) kennt. Wir werden "
"dieser Verteilung in Kapitel :doc:`../Ch11/Ch11_tTest` wieder begegnen."

#: ../../Ch07/Ch07_Probability_6.rst:26
msgid "*t*-distribution with *df* = 3 in comparison to a normal distribution"
msgstr "*t*-Verteilung mit *df* = 3 im Vergleich zu einer Normalverteilung"

#: ../../Ch07/Ch07_Probability_6.rst:30
msgid ""
"*t*-distribution with 3 degrees of freedom (solid line). It looks similar to "
"a normal distribution, but it’s not quite the same. For comparison purposes "
"I’ve plotted a standard normal distribution as the dashed line."
msgstr ""
"*t*-Verteilung mit 3 Freiheitsgraden (*df*; durchgezogene Linie). Sie sieht "
"einer Normalverteilung sehr ähnlich, ist aber nicht ganz dasselbe. Zum "
"Vergleich habe ich eine Standard-Normalverteilung als gestrichelte Linie "
"eingezeichnet."

#: ../../Ch07/Ch07_Probability_6.rst:36
msgid ""
"The **χ²-distribution** is another distribution that turns up in lots of "
"different places. The situation in which we’ll see it is when doing :doc:`../"
"Ch10/Ch10_ChiSquare`, but it’s one of those things that actually pops up all "
"over the place. When you dig into the maths (and who doesn’t love doing "
"that?), it turns out that the main reason why the χ²-distribution turns up "
"all over the place is that if you have a bunch of variables that are "
"normally distributed, square their values and then add them up (a procedure "
"referred to as taking a “sum of squares”), this sum has a χ²-distribution. "
"You’d be amazed how often this fact turns out to be useful. Anyway, :numref:"
"`fig-chiSqDist` illustrates what a χ²-distribution looks like."
msgstr ""
"Die **χ²-Verteilung** ist eine weitere Verteilung, die oft verwendet wird. "
"Die Situation, in der wir sie sehen werden, ist bei der :doc:`../Ch10/"
"Ch10_ChiSquare`, aber sie ist eines dieser Dinge, die eigentlich überall "
"auftauchen. Wenn man sich in die Mathematik vertieft (und wer tut das nicht "
"gerne?), stellt sich heraus, dass der Hauptgrund, warum die χ²-Verteilung "
"überall auftaucht. Das liegt darin, dass, wenn die Werte einer Reihe "
"normalverteilter Variablen quadriert und dann addiert werden (was als "
"„Quadratsumme“ bezeichnet wird), diese Summe eine χ²-Verteilung hat. Sie "
"werden erstaunt sein, wie oft sich diese Tatsache als nützlich erweist. Wie "
"auch immer, :numref:`fig-chiSqDist` veranschaulicht, wie eine χ²-Verteilung "
"aussieht."

#: ../../Ch07/Ch07_Probability_6.rst:50
msgid "χ²-distribution with *df* = 3"
msgstr "χ²-Verteilung mit *df* = 3"

#: ../../Ch07/Ch07_Probability_6.rst:54
msgid ""
"χ²-distribution with 3 degrees of freedom. Notice that the observed values "
"must always be greater than zero, and that the distribution is pretty "
"skewed. These are the key features of a χ²-distribution."
msgstr ""
"χ²-Verteilung mit 3 Freiheitsgraden. Die wichtigsten Merkmale einer χ²-"
"Verteilung sind, dass die beobachteten Werte immer größer als Null sein "
"müssen und dass die Verteilung ziemlich schief ist."

#: ../../Ch07/Ch07_Probability_6.rst:60
msgid ""
"The **F-distribution** looks a bit like a χ²-distribution, and it arises "
"whenever you need to compare two χ²-distributions to one another. "
"Admittedly, this doesn’t exactly sound like something that any sane person "
"would want to do, but it turns out to be very important in real world data "
"analysis. Remember when I said that χ² turns out to be the key distribution "
"when we’re taking a “sum of squares”? Well, what that means is if you want "
"to compare two different “sums of squares”, you’re probably talking about "
"something that has an *F*-distribution. Of course, as yet I still haven’t "
"given you an example of anything that involves a sum of squares, but I will "
"in chapter :doc:`../Ch13/Ch13_ANOVA`. And that’s where we’ll run into the "
"*F*-distribution. Oh, and there’s a picture in :numref:`fig-Fdist`."
msgstr ""
"Die **F-Verteilung** sieht ein bisschen wie eine χ²-Verteilung aus. Sie wird "
"immer dann verwendet, wenn man zwei χ²-Verteilungen miteinander vergleichen "
"muss. Obwohl das nicht gerade nach etwas klingt, das ein vernünftiger Mensch "
"tun möchte, ist es in der realen Welt der Datenanalyse äußerst wichtig. "
"Erinnern Sie sich, als ich sagte, dass χ² die Schlüsselverteilung ist, wenn "
"wir eine „Quadratsumme“ berechnen? Wenn Sie zwei verschiedene "
"„Quadratsummen“ vergleichen wollen, bedeutet das, dass Sie, wahrscheinlich "
"über etwas sprechen, das eine *F*-Verteilung hat. Natürlich habe ich Ihnen "
"noch kein Beispiel für etwas gegeben, das eine Quadratsumme beinhaltet, aber "
"das werde ich in Kapitel :doc:`../Ch13/Ch13_ANOVA` machen. Und da werden wir "
"auch wieder auf die *F*-Verteilung stoßen. Oh, und es gibt ein Bild in :"
"numref:`fig-Fdist`."

#: ../../Ch07/Ch07_Probability_6.rst:74
msgid "*F*-distribution with *df* = 3 and *df* = 5"
msgstr "*F*-Verteilung mit *df* = 3 und *df* = 5"

#: ../../Ch07/Ch07_Probability_6.rst:78
msgid ""
"*F*-distribution with 3 and 5 degrees of freedom. Qualitatively speaking, it "
"looks pretty similar to a χ²-distribution, but they’re not quite the same in "
"general."
msgstr ""
"*F*-Verteilung mit 3 und 5 Freiheitsgraden. Obwohl sie einer χ²-Verteilung "
"ziemlich ähnlich sieht, sie sind die beiden Verteilungen aber nicht dasselbe."

#: ../../Ch07/Ch07_Probability_6.rst:84
msgid ""
"Okay, time to wrap this section up. We’ve seen three new distributions: *t*, "
"χ² and *F*. They’re all continuous distributions, and they’re all closely "
"related to the normal distribution. The main thing for our purposes is that "
"you grasp the basic idea that these distributions are all deeply related to "
"one another, and to the normal distribution. Later on in this book we’re "
"going to run into data that are normally distributed, or at least assumed to "
"be normally distributed. What I want you to understand right now is that, if "
"you make the assumption that your data are normally distributed, you "
"shouldn’t be surprised to see *t*-, χ²- and *F*-distributions popping up all "
"over the place when you start trying to do your data analysis."
msgstr ""
"Es ist Zeit, diesen Abschnitt abzuschließen. Wir haben drei weitere "
"Verteilungen kennengelernt: *t*, χ² und *F*. Es handelt sich bei allen "
"dreien um kontinuierliche Verteilungen, die eng mit der Normalverteilung "
"verwandt sind. Die Hauptsache für unsere Zwecke ist, dass Sie die Grundidee "
"begreifen, dass diese Verteilungen alle eng miteinander und mit der "
"Normalverteilung verwandt sind. Später in diesem Buch werden wir auf Daten "
"stoßen, die normalverteilt sind (oder von denen zumindest angenommen wird, "
"dass sie normalverteilt sind). Wenn Sie davon ausgehen, dass Ihre Daten "
"normalverteilt sind, sollten Sie sich nicht wundern, wenn die Verteilungen "
"*t*-, χ²- und *F*-überall auftauchen, wenn Sie versuchen, Ihre Daten zu "
"analysieren."

#: ../../Ch07/Ch07_Probability_7.rst:4
msgid "Summary"
msgstr "Zusammenfassung"

#: ../../Ch07/Ch07_Probability_7.rst:6
msgid ""
"In this chapter we’ve talked about probability. We’ve talked about what "
"probability means and why statisticians can’t agree on what it means. We "
"talked about the rules that probabilities have to obey. And we introduced "
"the idea of a probability distribution and spent a good chunk of the chapter "
"talking about some of the more important probability distributions that "
"statisticians work with. The section by section breakdown looks like this:"
msgstr ""
"In diesem Kapitel haben wir über Wahrscheinlichkeit gesprochen. Wir haben "
"darüber gesprochen, was Wahrscheinlichkeit bedeutet und warum sich "
"Statistiker nicht immer darüber einig sind, was sie bedeutet. Wir haben über "
"die Regeln gesprochen, denen Wahrscheinlichkeiten gehorchen müssen. Außerdem "
"haben wir den Begriff der Wahrscheinlichkeitsverteilung eingeführt und einen "
"großen Teil des Kapitels damit verbracht, über einige der wichtigsten "
"Wahrscheinlichkeitsverteilungen zu sprechen, mit denen Statistiker arbeiten. "
"Die Aufschlüsselung nach Abschnitten sieht wie folgt aus:"

#: ../../Ch07/Ch07_Probability_7.rst:14
msgid ":doc:`Probability theory versus statistics <Ch07_Probability_1>`"
msgstr ""
":doc:`Wahrscheinlichkeitstheorie versus Statistik <Ch07_Probability_1>`"

#: ../../Ch07/Ch07_Probability_7.rst:16
msgid ""
":doc:`Frequentist versus Bayesian views of probability <Ch07_Probability_2>`"
msgstr ""
":doc:`Frequentistische vs. Bayessche Sichtweise der Wahrscheinlichkeit "
"<Ch07_Probability_2>`"

#: ../../Ch07/Ch07_Probability_7.rst:18
msgid ":doc:`Basics of probability theory <Ch07_Probability_3>`"
msgstr ":doc:`Grundlagen der Wahrscheinlichkeitsrechnung <Ch07_Probability_3>`"

#: ../../Ch07/Ch07_Probability_7.rst:20
msgid ""
":doc:`Binomial distribution <Ch07_Probability_4>`, :doc:`normal distribution "
"<Ch07_Probability_5>`, and :doc:`other useful distributions "
"<Ch07_Probability_6>`"
msgstr ""
":doc:`Binomialverteilung <Ch07_Probability_4>`, :doc:`Normalverteilung "
"<Ch07_Probability_5>` und :doc:`weitere nützliche Verteilungen "
"<Ch07_Probability_6>`"

#: ../../Ch07/Ch07_Probability_7.rst:24
msgid ""
"As you’d expect, my coverage is by no means exhaustive. Probability theory "
"is a large branch of mathematics in its own right, entirely separate from "
"its application to statistics and data analysis. As such, there are "
"thousands of books written on the subject and universities generally offer "
"multiple classes devoted entirely to probability theory. Even the “simpler” "
"task of documenting standard probability distributions is a big topic. I’ve "
"described five standard probability distributions in this chapter, but "
"sitting on my bookshelf I have a 47-chapter book called “Statistical "
"Distributions” (:ref:`Forbes et al., 2010 <Forbes_2010>`) that lists a *lot* "
"more than that. Fortunately for you, very little of this is necessary. "
"You’re unlikely to need to know dozens of statistical distributions when you "
"go out and do real world data analysis, and you definitely won’t need them "
"for this book, but it never hurts to know that there’s other possibilities "
"out there."
msgstr ""
"Wie zu erwarten, ist meine Darstellung keineswegs erschöpfend. Die "
"Wahrscheinlichkeitstheorie ist ein großer, eigenständiger Zweig der "
"Mathematik, der von seiner Anwendung in der Statistik und Datenanalyse "
"völlig getrennt ist. Es gibt Tausende von Büchern zu diesem Thema, und an "
"den Universitäten werden in der Regel mehrere Kurse angeboten, die "
"ausschließlich der Wahrscheinlichkeitstheorie gewidmet sind. Selbst die "
"„einfachere“ Aufgabe, Standardwahrscheinlichkeitsverteilungen zu "
"dokumentieren, ist ein großes Thema. Ich habe in diesem Kapitel fünf oft "
"verwendete Wahrscheinlichkeitsverteilungen beschrieben, aber in meinem "
"Bücherregal steht ein 47 Kapitel umfassendes Buch mit dem Titel "
"„*Statistical Distributions*“ (:ref:`Forbes et al., 2010 <Forbes_2010>`), in "
"dem noch *viel mehr* aufgeführt sind. Zum Glück für Sie sind nur sehr wenige "
"davon wirklich notwendig. Es ist unwahrscheinlich, dass Sie Dutzende von "
"statistischen Verteilungen kennen müssen, wenn Sie Daten in der realen Welt "
"analysieren. Sie werden sie definitiv nicht für dieses Buch brauchen, aber "
"es schadet nie, zu wissen, dass es noch weitere Möglichkeiten gibt."

#: ../../Ch07/Ch07_Probability_7.rst:38
msgid ""
"Picking up on that last point, there’s a sense in which this whole chapter "
"is something of a digression. Many undergraduate psychology classes on "
"statistics skim over this content very quickly (I know mine did), and even "
"the more advanced classes will often “forget” to revisit the basic "
"foundations of the field. Most academic psychologists would not know the "
"difference between probability and density, and until recently very few "
"would have been aware of the difference between Bayesian and frequentist "
"probability. However, I think it’s important to understand these things "
"before moving onto the applications. For example, there are a lot of rules "
"about what you’re “allowed” to say when doing statistical inference and many "
"of these can seem arbitrary and weird. However, they start to make sense if "
"you understand that there is this Bayesian / frequentist distinction. "
"Similarly, in chapter :doc:`../Ch11/Ch11_tTest` we’re going to talk about "
"something called the *t*-test, and if you really want to have a grasp of the "
"mechanics of the *t*-test it really helps to have a sense of what a *t*-"
"distribution actually looks like. You get the idea, I hope."
msgstr ""
"Um auf den letzten Punkt zurückzukommen: In gewisser Weise ist das ganze "
"Kapitel eine Art Abschweifung. Viele Psychologie-Vorlesungen im Grundstudium "
"überfliegen diesen Inhalt sehr schnell (ich weiß, dass es in meiner "
"Vorlesung so war). Selbst in den fortgeschritteneren Vorlesungen wird oft "
"„vergessen“, die Grundlagen des Fachs erneut zu behandeln. Die meisten "
"akademischen Psychologen kennen den Unterschied zwischen Wahrscheinlichkeit "
"und Dichte nicht, und bis vor kurzem kannten nur sehr wenige den Unterschied "
"zwischen Bayesscher und frequentistischer Statistik. Ich denke jedoch, dass "
"es wichtig ist, diese Dinge zu verstehen, bevor man sich mit den Anwendungen "
"befasst. Es gibt zum Beispiel eine Menge Regeln darüber, was man bei "
"statistischen Schlussfolgerungen sagen „darf“. Viele davon können "
"willkürlich und seltsam erscheinen. Sie ergeben jedoch einen Sinn, wenn man "
"versteht, dass es diese Unterscheidung zwischen Bayesianern und "
"Frequentisten gibt. In ähnlicher Weise werden wir in Kapitel :doc:`../Ch11/"
"Ch11_tTest` über etwas sprechen, das *t*-Test genannt wird. Wenn Sie die "
"Mechanik des *t*-Tests wirklich verstehen wollen, ist es sehr hilfreich, "
"eine Vorstellung davon zu haben, wie eine *t*-Verteilung tatsächlich "
"aussieht. Ich hoffe, Sie haben die Idee verstanden."
