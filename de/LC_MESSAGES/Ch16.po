# #-#-#-#-#  Ch16.pot (Learning statistics with jamovi )  #-#-#-#-#
# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020-2022, Danielle J. Navarro & David R. Foxcroft. This work is licensed under a Creative Commons Attribution-Non Commercial 4.0 International License.
# This file is distributed under the same license as the Learning statistics with jamovi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
# #-#-#-#-#  Ch16.po (Learning statistics with jamovi )  #-#-#-#-#
# #-#-#-#-#  Ch16.pot (Learning statistics with jamovi )  #-#-#-#-#
# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020-2022, Danielle J. Navarro & David R. Foxcroft. This work is licensed under a Creative Commons Attribution-Non Commercial 4.0 International License.
# This file is distributed under the same license as the Learning statistics with jamovi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
# #-#-#-#-#  Ch16.po (Learning statistics with jamovi )  #-#-#-#-#
# #-#-#-#-#  Ch16.pot (Learning statistics with jamovi )  #-#-#-#-#
# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020-2022, Danielle J. Navarro & David R. Foxcroft. This work is licensed under a Creative Commons Attribution-Non Commercial 4.0 International License.
# This file is distributed under the same license as the Learning statistics with jamovi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
# #-#-#-#-#  Ch16.po (PROJECT VERSION)  #-#-#-#-#
# #-#-#-#-#  Ch16.pot (Learning statistics with jamovi )  #-#-#-#-#
# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020-2022, Danielle J. Navarro & David R. Foxcroft. This
# work is licensed under a Creative Commons Attribution-Non Commercial 4.0
# International License.
# This file is distributed under the same license as the Learning statistics
# with jamovi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
# #-#-#-#-#  Ch16.po (Learning statistics with jamovi )  #-#-#-#-#
# #-#-#-#-#  Ch16.po (Learning statistics with jamovi)  #-#-#-#-#
#, fuzzy
msgid ""
msgstr ""
"#-#-#-#-#  Ch16.pot (Learning statistics with jamovi )  #-#-#-#-#\n"
"Project-Id-Version: Learning statistics with jamovi \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-21 13:16+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"#-#-#-#-#  Ch16.po (Learning statistics with jamovi )  #-#-#-#-#\n"
"#-#-#-#-#  Ch16.pot (Learning statistics with jamovi )  #-#-#-#-#\n"
"Project-Id-Version: Learning statistics with jamovi \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-21 13:14+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"#-#-#-#-#  Ch16.po (Learning statistics with jamovi )  #-#-#-#-#\n"
"#-#-#-#-#  Ch16.pot (Learning statistics with jamovi )  #-#-#-#-#\n"
"Project-Id-Version: Learning statistics with jamovi \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-21 12:42+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"#-#-#-#-#  Ch16.po (PROJECT VERSION)  #-#-#-#-#\n"
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"
"POT-Creation-Date: 2022-11-16 00:38+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../../Ch16/Ch16_Bayes.rst:4
msgid "Bayesian statistics"
msgstr ""

#: ../../Ch16/Ch16_Bayes.rst:0 ../../Ch16/Ch16_Bayes.rst
msgid ""
"*In our reasonings concerning matter of fact, there are all imaginable "
"degrees of assurance, from the highest certainty to the lowest species of "
"moral evidence. A wise man, therefore, proportions his belief to the "
"evidence.*"
msgstr ""

#: ../../Ch16/Ch16_Bayes.rst:30
msgid "`David Hume <https://en.wikiquote.org/wiki/David_Hume>`__"
msgstr ""

#: ../../Ch16/Ch16_Bayes.rst:26
msgid ""
"The ideas I’ve presented to you in this book describe inferential statistics "
"from the frequentist perspective. I’m not alone in doing this. In fact, "
"almost every textbook given to undergraduate psychology students presents "
"the opinions of the frequentist statistician as *the* theory of inferential "
"statistics, the one true way to do things. I have taught this way for "
"practical reasons. The frequentist view of statistics dominated the academic "
"field of statistics for most of the 20th century, and this dominance is even "
"more extreme among applied scientists. It was and is current practice among "
"psychologists to use frequentist methods. Because frequentist methods are "
"ubiquitous in scientific papers, every student of statistics needs to "
"understand those methods, otherwise they will be unable to make sense of "
"what those papers are saying! Unfortunately, in my opinion at least, the "
"current practice in psychology is often misguided and the reliance on "
"frequentist methods is partly to blame. In this chapter I explain why I "
"think this and provide an introduction to Bayesian statistics, an approach "
"that I think is generally superior to the orthodox approach."
msgstr ""

#: ../../Ch16/Ch16_Bayes.rst:44
msgid ""
"This chapter comes in two parts: In sections :doc:`Probabilistic reasoning "
"by rational agents <../Ch16/Ch16_Bayes_1>` through :doc:`Why be a Bayesian? "
"<../Ch16/Ch16_Bayes_3>` I talk about what Bayesian statistics are all about, "
"covering the basic mathematical rules for how it works as well as an "
"explanation for why I think the Bayesian approach is so useful. Afterwards, "
"I provide a brief overview of how you can do :doc:`Bayesian versions of t-"
"tests <../Ch16/Ch16_Bayes_5>`."
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:4
msgid "Probabilistic reasoning by rational agents"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:6
msgid ""
"From a Bayesian perspective statistical inference is all about *belief "
"revision*. I start out with a set of candidate hypotheses *h* about the "
"world. I don’t know which of these hypotheses is true, but do I have some "
"beliefs about which hypotheses are plausible and which are not. When I "
"observe the data, *d*, I have to revise those beliefs. If the data are "
"consistent with a hypothesis, my belief in that hypothesis is strengthened. "
"If the data are inconsistent with the hypothesis, my belief in that "
"hypothesis is weakened. That’s it! At the end of this section I’ll give a "
"precise description of how Bayesian reasoning works, but first I want to "
"work through a simple example in order to introduce the key ideas. Consider "
"the following reasoning problem."
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:19
msgid "*I’m carrying an umbrella. Do you think it will rain?*"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:21
msgid ""
"In this problem I have presented you with a single piece of data (*d* = I’m "
"carrying the umbrella), and I’m asking you to tell me your belief or "
"hypothesis about whether it’s raining. You have two alternatives, *h*: "
"either it will rain today or it will not. How should you solve this problem?"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:28
msgid "Priors: what you believed before"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:30
msgid ""
"The first thing you need to do is ignore what I told you about the umbrella, "
"and write down your pre-existing beliefs about rain. This is important. If "
"you want to be honest about how your beliefs have been revised in the light "
"of new evidence (data) then you *must* say something about what you believed "
"before those data appeared! So, what might you believe about whether it will "
"rain today? You probably know that I live in Australia and that much of "
"Australia is hot and dry. The city of Adelaide where I live has a "
"Mediterranean climate, very similar to southern California, southern Europe "
"or northern Africa. I’m writing this in January and so you can assume it’s "
"the middle of summer. In fact, you might have decided to take a quick look "
"on Wikipedia and discovered that Adelaide gets an `average of 4.6 days of "
"rain across the 31 days of January <https://en.wikipedia.org/wiki/"
"Climate_of_Adelaide>`__. Without knowing anything else, you might conclude "
"that the probability of January rain in Adelaide is about 15%, and the "
"probability of a dry day is 85%. If this is really what you believe about "
"Adelaide rainfall (and now that I’ve told it to you I’m betting that this "
"really *is* what you believe) then what I have written here is your **prior "
"distribution**, written *P*\\ (h):"
msgstr ""
"Das Erste, was Sie tun müssen, ist zu ignorieren, was ich Ihnen über den "
"Regenschirm gesagt habe, und Ihre bestehenden Überzeugungen über Regen "
"aufzuschreiben. Das ist wichtig. Wenn Sie ehrlich beschreiben wollen, wie "
"Ihre Überzeugungen im Lichte neuer Beweise (Daten) revidiert wurden, dann "
"*müssen* Sie etwas darüber sagen, was Sie glaubten, bevor diese Daten "
"erschienen! Für wie wahrscheinlich halten Sie es, dass es heute regnen wird? "
"Sie wissen wahrscheinlich, dass ich in Australien lebe und dass es in weiten "
"Teilen Australiens heiß und trocken ist. Die Stadt Adelaide, in der ich "
"lebe, hat ein mediterranes Klima, das dem in Südkalifornien, Südeuropa oder "
"Nordafrika sehr ähnlich ist. Da ich dies im Januar schreibe, können Sie "
"davon ausgehen, dass es mitten im Sommer ist. Vielleicht haben Sie sogar "
"einen kurzen Blick auf Wikipedia geworfen und herausgefunden, dass es in "
"Adelaide `an den 31 Tagen im Januar durchschnittlich 4,6 Tage regnet "
"<https://en.wikipedia.org/wiki/Climate_of_Adelaide>`__. Ohne etwas anderes "
"zu wissen, könnten Sie zu dem Schluss kommen, dass die Wahrscheinlichkeit, "
"dass es im Januar in Adelaide regnet, bei etwa 15 % liegt und die "
"Wahrscheinlichkeit eines trockenen Tages bei 85 %. Wenn dies wirklich das "
"ist, was Sie über die Regenfälle in Adelaide glauben (und jetzt, wo ich es "
"Ihnen gesagt habe, wette ich, dass dies wirklich *ist*, was Sie glauben), "
"dann ist das, was ich hier geschrieben habe, Ihre **a-priori-Verteilung**, "
"geschrieben *P*\\ (h):"

#: ../../Ch16/Ch16_Bayes_1.rst:50 ../../Ch16/Ch16_Bayes_1.rst:71
msgid "Hypothesis"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:50
msgid "Degree of Belief"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:52 ../../Ch16/Ch16_Bayes_1.rst:73
msgid "**Rainy day**"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:52 ../../Ch16/Ch16_Bayes_1.rst:144
msgid "0.15"
msgstr "0.15"

#: ../../Ch16/Ch16_Bayes_1.rst:54 ../../Ch16/Ch16_Bayes_1.rst:75
msgid "**Dry day**"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:54 ../../Ch16/Ch16_Bayes_1.rst:146
msgid "0.85"
msgstr "0.85"

#: ../../Ch16/Ch16_Bayes_1.rst:58
msgid "Likelihoods: theories about the data"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:60
msgid ""
"To solve the reasoning problem you need a theory about my behaviour. When "
"does Dani carry an umbrella? You might guess that I’m not a complete idiot,"
"\\ [#]_ and I try to carry umbrellas only on rainy days. On the other hand, "
"you also know that I have young kids, and you wouldn’t be all that surprised "
"to know that I’m pretty forgetful about this sort of thing. Let’s suppose "
"that on rainy days I remember my umbrella about 30% of the time (I really am "
"awful at this). But let’s say that on dry days I’m only about 5% likely to "
"be carrying an umbrella. So you might write out a little table like this:"
msgstr ""
"Um das Argumentationsproblem zu lösen, brauchen Sie eine Theorie über mein "
"Verhalten. Wann trägt Dani einen Regenschirm? Sie können sich denken, dass "
"ich kein kompletter Idiot bin,\\ [#]_ und ich versuche, Regenschirme nur an "
"regnerischen Tagen mitzunehmen. Andererseits wissen Sie auch, dass ich "
"kleine Kinder habe. Es würde Sie daher nicht überraschen, wenn Sie wüssten, "
"dass ich bei solchen Dingen ziemlich vergesslich bin. Nehmen wir an, dass "
"ich an Regentagen meinen Regenschirm etwa 30% der Zeit nicht vergesse (ich "
"bin wirklich schlecht darin). Aber nehmen wir an, dass ich an trockenen "
"Tagen nur etwa 5% wahrscheinlich einen Regenschirm dabei habe. Man könnte "
"also eine kleine Tabelle wie diese aufstellen:"

#: ../../Ch16/Ch16_Bayes_1.rst:71 ../../Ch16/Ch16_Bayes_1.rst:130
#: ../../Ch16/Ch16_Bayes_1.rst:142 ../../Ch16/Ch16_Bayes_1.rst:173
#: ../../Ch16/Ch16_Bayes_1.rst:219 ../../Ch16/Ch16_Bayes_1.rst:252
msgid "Umbrella"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:71
msgid "No umbrella"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:73
msgid "0.30"
msgstr "0.30"

#: ../../Ch16/Ch16_Bayes_1.rst:73
msgid "0.70"
msgstr "0.70"

#: ../../Ch16/Ch16_Bayes_1.rst:75
msgid "0.05"
msgstr "0.05"

#: ../../Ch16/Ch16_Bayes_1.rst:75
msgid "0.95"
msgstr "0.95"

#: ../../Ch16/Ch16_Bayes_1.rst:78
msgid ""
"It’s important to remember that each cell in this table describes your "
"beliefs about what data *d* will be observed, *given* the truth of a "
"particular hypothesis *h*. This “conditional probability” is written *P*\\ "
"(d|h), which you can read as “the probability of *d* given *h*”. In Bayesian "
"statistics, this is referred to as the **likelihood** of the data *d* given "
"the hypothesis *h*.\\ [#]_"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:87
msgid "The joint probability of data and hypothesis"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:89
msgid ""
"At this point all the elements are in place. Having written down the priors "
"and the likelihood, you have all the information you need to do Bayesian "
"reasoning. The question now becomes *how* do we use this information? As it "
"turns out, there’s a very simple equation that we can use here, but it’s "
"important that you understand why we use it so I’m going to try to build it "
"up from more basic ideas."
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:96
msgid ""
"Let’s start out with one of the rules of probability theory. I listed it way "
"back in :numref:`tab-probrules`, but I didn’t make a big deal out of it at "
"the time and you probably ignored it. The rule in question is the one that "
"talks about the probability that *two* things are true. In our example you "
"might want to calculate the probability that today is rainy (i.e., "
"hypothesis *h* is true) and I’m carrying an umbrella (i.e., data *d* is "
"observed). The **joint probability** of the hypothesis and the data is "
"written *P*\\ (d, h), and you can calculate it by multiplying the prior "
"*P*\\ (h) by the likelihood *P*\\ (d|h). Mathematically, we say that:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:106
msgid "*P*\\ (d, h) = *P*\\ (d|h) *P*\\ (h)"
msgstr "*P*\\ (d, h) = *P*\\ (d|h) *P*\\ (h)"

#: ../../Ch16/Ch16_Bayes_1.rst:108
msgid ""
"So, what is the probability that today is a rainy day *and* I remember to "
"carry an umbrella? As we discussed earlier, the prior tells us that the "
"probability of a rainy day is 15%, and the likelihood tells us that the "
"probability of me remembering my umbrella on a rainy day is 30%. So the "
"probability that both of these things are true is calculated by multiplying "
"the two:"
msgstr ""
"Wie hoch ist also die Wahrscheinlichkeit, dass heute ein Regentag ist *und* "
"ich daran denke, einen Regenschirm mitzunehmen? Wie wir bereits besprochen "
"haben, sagt uns die a-priori-Verteilung, dass die Wahrscheinlichkeit für "
"einen Regentag 15 % beträgt, und die Wahrscheinlichkeit, dass ich an einem "
"Regentag an meinen Regenschirm denke, beträgt 30 %. Die Wahrscheinlichkeit, "
"dass beide Dinge wahr sind, wird durch Multiplikation der beiden "
"Wahrscheinlichkeiten berechnet:"

#: ../../Ch16/Ch16_Bayes_1.rst:115
msgid ""
"\\begin{aligned}\n"
"P(\\mbox{rainy}, \\mbox{umbrella}) & = & P(\\mbox{umbrella} | \\mbox{rainy}) "
"\\times P(\\mbox{rainy}) \\\\\n"
"& = & 0.30 \\times 0.15 \\\\\n"
"& = & 0.045\\end{aligned}"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:122
msgid ""
"In other words, before being told anything about what actually happened, you "
"think that there is a 4.5% probability that today will be a rainy day and "
"that I will remember an umbrella. However, there are of course *four* "
"possible things that could happen, right? So let’s repeat the exercise for "
"all four. If we do that, we end up with the following table:"
msgstr ""
"Mit anderen Worten: Bevor man etwas über die tatsächlichen Ereignisse "
"erfährt, denkt man, dass die Wahrscheinlichkeit, dass es heute regnet, 4,5% "
"beträgt und dass ich an einen Regenschirm denken werde. Aber es gibt "
"natürlich *vier* mögliche Dinge, die passieren könnten, oder? Wiederholen "
"wir also die Übung für alle vier. Wenn wir das tun, erhalten wir die "
"folgende Tabelle:"

#: ../../Ch16/Ch16_Bayes_1.rst:130 ../../Ch16/Ch16_Bayes_1.rst:142
#: ../../Ch16/Ch16_Bayes_1.rst:173 ../../Ch16/Ch16_Bayes_1.rst:219
#: ../../Ch16/Ch16_Bayes_1.rst:252
msgid "No-umbrella"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:132 ../../Ch16/Ch16_Bayes_1.rst:144
#: ../../Ch16/Ch16_Bayes_1.rst:175 ../../Ch16/Ch16_Bayes_1.rst:221
#: ../../Ch16/Ch16_Bayes_1.rst:254
msgid "**Rainy**"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:132 ../../Ch16/Ch16_Bayes_1.rst:144
msgid "0.0450"
msgstr "0.0450"

#: ../../Ch16/Ch16_Bayes_1.rst:132 ../../Ch16/Ch16_Bayes_1.rst:144
msgid "0.1050"
msgstr "0.1050"

#: ../../Ch16/Ch16_Bayes_1.rst:134 ../../Ch16/Ch16_Bayes_1.rst:146
#: ../../Ch16/Ch16_Bayes_1.rst:177 ../../Ch16/Ch16_Bayes_1.rst:223
#: ../../Ch16/Ch16_Bayes_1.rst:256
msgid "**Dry**"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:134 ../../Ch16/Ch16_Bayes_1.rst:146
msgid "0.0425"
msgstr "0.0425"

#: ../../Ch16/Ch16_Bayes_1.rst:134 ../../Ch16/Ch16_Bayes_1.rst:146
msgid "0.8075"
msgstr "0.8075"

#: ../../Ch16/Ch16_Bayes_1.rst:137
msgid ""
"This table captures all the information about which of the four "
"possibilities are likely. To really get the full picture, though, it helps "
"to add the row totals and column totals. That gives us this table:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:142
msgid "Total"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:148 ../../Ch16/Ch16_Bayes_1.rst:225
#: ../../Ch16/Ch16_Bayes_1.rst:258
msgid "**Total**"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:148
msgid "0.0875"
msgstr "0.0875"

#: ../../Ch16/Ch16_Bayes_1.rst:148
msgid "0.9125"
msgstr "0.9125"

#: ../../Ch16/Ch16_Bayes_1.rst:148
msgid "1.00"
msgstr "1.00"

#: ../../Ch16/Ch16_Bayes_1.rst:151
msgid ""
"This is a very useful table, so it’s worth taking a moment to think about "
"what all these numbers are telling us. First, notice that the row sums "
"aren’t telling us anything new at all. For example, the first row tells us "
"that if we ignore all this umbrella business, the chance that today will be "
"a rainy day is 15%. That’s not surprising, of course, as that’s our prior.\\ "
"[#]_ The important thing isn’t the number itself. Rather, the important "
"thing is that it gives us some confidence that our calculations are "
"sensible! Now take a look at the column sums and notice that they tell us "
"something that we haven’t explicitly stated yet. In the same way that the "
"row sums tell us the probability of rain, the column sums tell us the "
"probability of me carrying an umbrella. Specifically, the first column tells "
"us that on average (i.e., ignoring whether it’s a rainy day or not) the "
"probability of me carrying an umbrella is 8.75%. Finally, notice that when "
"we sum across all four logically-possible events, everything adds up to 1. "
"In other words, what we have written down is a proper probability "
"distribution defined over all possible combinations of data and hypothesis."
msgstr ""
"Dies ist eine sehr nützliche Tabelle, es lohnt sich also, einen Moment "
"darüber nachzudenken, was all diese Zahlen uns sagen. Zunächst fällt auf, "
"dass die Zeilensummen uns überhaupt nichts Neues sagen. Die erste Zeile sagt "
"uns zum Beispiel, dass die Wahrscheinlichkeit, dass es heute regnet, 15 % "
"beträgt, wenn wir die Sache mit dem Regenschirm ignorieren. Das ist "
"natürlich nicht überraschend, denn das ist unsere Vorhersage.\\ [#]_ Das "
"Wichtige ist nicht die Zahl selbst. Wichtig ist vielmehr, dass sie uns eine "
"gewisse Sicherheit gibt, dass unsere Berechnungen sinnvoll sind! Schauen Sie "
"sich nun die Spaltensummen an und stellen Sie fest, dass sie uns etwas "
"sagen, was wir noch nicht explizit gesagt haben. Genauso wie die "
"Zeilensummen die Regenwahrscheinlichkeit angeben, sagen die Spaltensummen "
"etwas über die Wahrscheinlichkeit aus, dass ich einen Regenschirm dabei "
"habe. Die erste Spalte sagt uns, dass die Wahrscheinlichkeit, dass ich einen "
"Regenschirm mitnehme, im Durchschnitt 8,75 % beträgt (d. h. unabhängig "
"davon, ob es regnet oder nicht). Beachten Sie schließlich, dass die Summe "
"aller vier logisch möglichen Ereignisse 1 ergibt. Mit anderen Worten: Was "
"wir aufgeschrieben haben, ist eine Wahrscheinlichkeitsverteilung, die über "
"alle möglichen Kombinationen von Daten und Hypothese definiert ist."

#: ../../Ch16/Ch16_Bayes_1.rst:169
msgid ""
"Now, because this table is so useful, I want to make sure you understand "
"what all the elements correspond to and how they written:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:175
msgid "*P*\\ (Umbrella, Rainy)"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:175
msgid "*P*\\ (No-umbrella, Rainy)"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:175
msgid "*P*\\ (Rainy)"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:177
msgid "*P*\\ (Umbrella, Dry)"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:177
msgid "*P*\\ (No-umbrella, Dry)"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:177
msgid "*P*\\ (Dry)"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:179
msgid "*P*\\ (Umbrella)"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:179
msgid "*P*\\ (No-umbrella)"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:182
msgid ""
"Finally, let’s use “proper” statistical notation. In the rainy day problem, "
"the data corresponds to the observation that I do or do not have an "
"umbrella. So we’ll let *d*\\ :sub:`1` refer to the possibility that you "
"observe me carrying an umbrella, and *d*\\ :sub:`2` refers to you observing "
"me not carrying one. Similarly, *h*\\ :sub:`1` is your hypothesis that today "
"is rainy, and *h*\\ :sub:`2` is the hypothesis that it is not. Using this "
"notation, the table looks like this:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:191
msgid "**d**\\ :sub:`1`"
msgstr "**d**\\ :sub:`1`"

#: ../../Ch16/Ch16_Bayes_1.rst:191
msgid "**d**\\ :sub:`2`"
msgstr "**d**\\ :sub:`2`"

#: ../../Ch16/Ch16_Bayes_1.rst:193
msgid "**h**\\ :sub:`1`"
msgstr "**h**\\ :sub:`1`"

#: ../../Ch16/Ch16_Bayes_1.rst:193
msgid "*P*\\ (h\\ :sub:`1`\\ , d\\ :sub:`1`\\ )"
msgstr "*P*\\ (h\\ :sub:`1`\\ , d\\ :sub:`1`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:193
msgid "*P*\\ (h\\ :sub:`1`\\ , d\\ :sub:`2`\\ )"
msgstr "*P*\\ (h\\ :sub:`1`\\ , d\\ :sub:`2`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:193
msgid "*P*\\ (h\\ :sub:`1`\\ )"
msgstr "*P*\\ (h\\ :sub:`1`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:195
msgid "**h**\\ :sub:`2`"
msgstr "**h**\\ :sub:`2`"

#: ../../Ch16/Ch16_Bayes_1.rst:195
msgid "*P*\\ (h\\ :sub:`2`\\ , d\\ :sub:`1`\\ )"
msgstr "*P*\\ (h\\ :sub:`2`\\ , d\\ :sub:`1`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:195
msgid "*P*\\ (h\\ :sub:`2`\\ , d\\ :sub:`2`\\ )"
msgstr "*P*\\ (h\\ :sub:`2`\\ , d\\ :sub:`2`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:195
msgid "*P*\\ (h\\ :sub:`2`\\ )"
msgstr "*P*\\ (h\\ :sub:`2`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:197
msgid "*P*\\ (d\\ :sub:`1`\\ )"
msgstr "*P*\\ (d\\ :sub:`1`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:197
msgid "*P*\\ (d\\ :sub:`2`\\ )"
msgstr "*P*\\ (d\\ :sub:`2`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:201
msgid "Updating beliefs using Bayes’ rule"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:203
msgid ""
"The table we laid out in the last section is a very powerful tool for "
"solving the rainy day problem, because it considers all four logical "
"possibilities and states exactly how confident you are in each of them "
"before being given any data. It’s now time to consider what happens to our "
"beliefs when we are actually given the data. In the rainy day problem, you "
"are told that I really *am* carrying an umbrella. This is something of a "
"surprising event. According to our table, the probability of me carrying an "
"umbrella is only 8.75%. But that makes sense, right? A guy carrying an "
"umbrella on a summer day in a hot dry city is pretty unusual, and so you "
"really weren’t expecting that. Nevertheless, the data tells you that it is "
"true. No matter how unlikely you thought it was, you must now adjust your "
"beliefs to accommodate the fact that you now *know* that I have an umbrella."
"\\ [#]_ To reflect this new knowledge, our *revised* table must have the "
"following numbers:"
msgstr ""
"Die Tabelle, die wir im letzten Abschnitt erstellt haben, ist ein sehr "
"leistungsfähiges Instrument zur Lösung des Regentagsproblems, weil sie alle "
"vier logischen Möglichkeiten berücksichtigt und genau angibt, wie "
"wahrscheinlich jede von ihnen ist, bevor man irgendwelche Daten erhält. Nun "
"ist es an der Zeit zu überlegen, was mit unseren Überzeugungen geschieht, "
"wenn wir die Daten tatsächlich erhalten. Bei dem Problem mit dem Regentag "
"wird Ihnen gesagt, dass ich *wirklich* einen Regenschirm trage. Das ist ein "
"etwas überraschendes Ereignis. Laut unserer Tabelle beträgt die "
"Wahrscheinlichkeit, dass ich einen Regenschirm dabei habe, nur 8,75 %. Aber "
"das macht doch Sinn, oder? Ein Mann, der an einem Sommertag in einer heißen, "
"trockenen Stadt einen Regenschirm mit sich führt, ist ziemlich ungewöhnlich, "
"und deshalb haben Sie das wirklich nicht erwartet. Dennoch zeigen die Daten, "
"dass es wahr ist. Egal, für wie unwahrscheinlich Sie es gehalten haben, "
"müssen Sie jetzt Ihre Überzeugungen anpassen, um der Tatsache Rechnung zu "
"tragen, dass Sie jetzt *wissen*, dass ich einen Regenschirm habe.\\ [#]_ Um "
"dieses neue Wissen widerzuspiegeln, muss unsere *überarbeitete* Tabelle die "
"folgenden Zahlen enthalten:"

#: ../../Ch16/Ch16_Bayes_1.rst:221 ../../Ch16/Ch16_Bayes_1.rst:223
#: ../../Ch16/Ch16_Bayes_1.rst:225 ../../Ch16/Ch16_Bayes_1.rst:254
#: ../../Ch16/Ch16_Bayes_1.rst:256 ../../Ch16/Ch16_Bayes_1.rst:258
msgid "0"
msgstr "0"

#: ../../Ch16/Ch16_Bayes_1.rst:225 ../../Ch16/Ch16_Bayes_1.rst:258
msgid "1"
msgstr "1"

#: ../../Ch16/Ch16_Bayes_1.rst:228
msgid ""
"In other words, the facts have eliminated any possibility of “no umbrella”, "
"so we have to put zeros into any cell in the table that implies that I’m not "
"carrying an umbrella. Also, you know for a fact that I am carrying an "
"umbrella, so the column sum on the left must be 1 to correctly describe the "
"fact that *P*\\ (umbrella) = 1."
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:234
msgid ""
"What two numbers should we put in the empty cells? Again, let’s not worry "
"about the maths, and instead think about our intuitions. When we wrote out "
"our table the first time, it turned out that those two cells had almost "
"identical numbers, right? We worked out that the joint probability of “rain "
"and umbrella” was 4.5%, and the joint probability of “dry and umbrella” was "
"4.25%. In other words, before I told you that I am in fact carrying an "
"umbrella, you’d have said that these two events were almost identical in "
"probability, yes? But notice that *both* of these possibilities are "
"consistent with the fact that I actually am carrying an umbrella. From the "
"perspective of these two possibilities, very little has changed. I hope "
"you’d agree that it’s *still* true that these two possibilities are equally "
"plausible. So what we expect to see in our final table is some numbers that "
"preserve the fact that “rain and umbrella” is *slightly* more plausible than "
"“dry and umbrella”, while still ensuring that numbers in the table add up. "
"Something like this, perhaps?"
msgstr ""
"Welche zwei Zahlen sollen wir in die leeren Zellen einsetzen? Auch hier "
"sollten wir uns keine Gedanken über die Mathematik machen, sondern unsere "
"Intuition benutzen. Als wir unsere Tabelle das erste Mal ausfüllten, stellte "
"sich heraus, dass diese beiden Zellen fast identische Zahlen enthielten. Wir "
"haben ausgerechnet, dass die gemeinsame Wahrscheinlichkeit für „Regen und "
"Regenschirm“ 4,5% und die gemeinsame Wahrscheinlichkeit für „trocken und "
"Regenschirm“ 4,25% beträgt. Mit anderen Worten: Bevor ich Ihnen gesagt habe, "
"dass ich tatsächlich einen Regenschirm trage, hätten Sie gesagt, dass die "
"Wahrscheinlichkeit dieser beiden Ereignisse fast identisch ist. Aber "
"beachten Sie, dass *beide* dieser Möglichkeiten mit der Tatsache "
"übereinstimmen, dass ich tatsächlich einen Regenschirm bei mir habe. Aus der "
"Perspektive dieser beiden Möglichkeiten hat sich sehr wenig geändert. Ich "
"hoffe, Sie stimmen mir zu, dass es *immer noch* wahr ist, dass diese beiden "
"Möglichkeiten gleichermaßen plausibel sind. Was wir also in unserer "
"endgültigen Tabelle erwarten, sind einige Zahlen, welche die Tatsache "
"reflektieren, dass „Regen und Regenschirm“ *etwas* plausibler ist als "
"„trocken und Regenschirm“, und gleichzeitig sicherstellen, dass sich die "
"Zahlen in der Tabelle addieren. Vielleicht so etwas wie dies?"

#: ../../Ch16/Ch16_Bayes_1.rst:254
msgid "0.514"
msgstr "0.514"

#: ../../Ch16/Ch16_Bayes_1.rst:256
msgid "0.486"
msgstr "0.486"

#: ../../Ch16/Ch16_Bayes_1.rst:261
msgid ""
"What this table is telling you is that, after being told that I’m carrying "
"an umbrella, you believe that there’s a 51.4% chance that today will be a "
"rainy day, and a 48.6% chance that it won’t. That’s the answer to our "
"problem! The **posterior probability** of rain *P*\\ (h|d) given that I am "
"carrying an umbrella is 51.4%"
msgstr ""
"Diese Tabelle sagt Ihnen, dass Sie, nachdem Sie erfahren haben, dass ich "
"einen Regenschirm dabei habe, glauben, dass die Wahrscheinlichkeit, dass es "
"heute regnet, bei 51,4% liegt und bei 48,6% dass es nicht regnet. Das ist "
"die Antwort auf unser Problem! Die **a-posteriori-Wahrscheinlichkeit** von "
"Regen *P*\\ (h|d), wenn ich einen Regenschirm trage, ist 51,4%"

#: ../../Ch16/Ch16_Bayes_1.rst:267
msgid ""
"How did I calculate these numbers? You can probably guess. To work out that "
"there was a 0.514 probability of “rain”, all I did was take the 0.045 "
"probability of “rain and umbrella” and divide it by the 0.0875 chance of "
"“umbrella”. This produces a table that satisfies our need to have everything "
"sum to 1, and our need not to interfere with the relative plausibility of "
"the two events that are actually consistent with the data. To say the same "
"thing using fancy statistical jargon, what I’ve done here is divide the "
"joint probability of the hypothesis and the data *P*\\ (d, h) by the "
"**marginal probability** of the data *P*\\ (d), and this is what gives us "
"the posterior probability of the hypothesis *given* the data that have been "
"observed. To write this as an equation:\\ [#]_"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:280
msgid ""
"P(h | d) = \\frac{P(d,h)}{P(d)}\n"
"\n"
msgstr ""
"P(h | d) = \\frac{P(d,h)}{P(d)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_1.rst:282
msgid ""
"However, remember what I said at the start of the last section, namely that "
"the joint probability *P*\\ (d, h) is calculated by multiplying the prior "
"*P*\\ (h) by the likelihood *P*\\ (d|h). In real life, the things we "
"actually know how to write down are the priors and the likelihood, so let’s "
"substitute those back into the equation. This gives us the following formula "
"for the posterior probability"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:289
msgid ""
"P(h | d) = \\frac{P(d|h) P(h)}{P(d)}\n"
"\n"
msgstr ""
"P(h | d) = \\frac{P(d|h) P(h)}{P(d)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_1.rst:291
msgid ""
"And this formula, folks, is known as **Bayes’ rule**. It describes how a "
"learner starts out with prior beliefs about the plausibility of different "
"hypotheses, and tells you how those beliefs should be revised in the face of "
"data. In the Bayesian paradigm, all statistical inference flows from this "
"one simple rule."
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:300
msgid "It’s a leap of faith, I know, but let’s run with it okay?"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:303
msgid ""
"Um. I hate to bring this up, but some statisticians would object to me using "
"the word “likelihood” here. The problem is that the word “likelihood” has a "
"very specific meaning in frequentist statistics, and it’s not quite the same "
"as what it means in Bayesian statistics. As far as I can tell Bayesians "
"didn’t originally have any agreed upon name for the likelihood, and so it "
"became common practice for people to use the frequentist terminology. This "
"wouldn’t have been a problem except for the fact that the way that Bayesians "
"use the word turns out to be quite different to the way frequentists do. "
"This isn’t the place for yet another lengthy history lesson but, to put it "
"crudely, when a Bayesian says “*a* likelihood function” they’re usually "
"referring one of the *rows* of the table. When a frequentist says the same "
"thing, they’re referring to the same table, but to them “*a* likelihood "
"function” almost always refers to one of the *columns*. This distinction "
"matters in some contexts, but it’s not important for our purposes."
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:321
msgid ""
"Just to be clear, “prior” information is pre-existing knowledge or beliefs, "
"before we collect or use any data to improve that information."
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:326
msgid ""
"If we were being a bit more sophisticated, we could extend the example to "
"accommodate the possibility that I’m lying about the umbrella. But let’s "
"keep things simple, shall we?"
msgstr ""

#: ../../Ch16/Ch16_Bayes_1.rst:331
msgid ""
"You might notice that this equation is actually a restatement of the same "
"basic rule I listed at the start of the last section. If you multiply both "
"sides of the equation by *P*\\ (d), then you get *P*\\ (d) *P*\\ (h|d) = "
"*P*\\ (d, h), which is the rule for how joint probabilities are calculated. "
"So I’m not actually introducing any “new” rules here, I’m just using the "
"same rule in a different way."
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:4
msgid "Bayesian hypothesis tests"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:6
msgid ""
"In chapter :doc:`Hypothesis testing <../Ch09/Ch09_HypothesisTesting>`, I "
"described the orthodox approach to hypothesis testing. It took an entire "
"chapter to describe, because null hypothesis testing is a very elaborate "
"contraption that people find very hard to make sense of. In contrast, the "
"Bayesian approach to hypothesis testing is incredibly simple. Let’s pick a "
"setting that is closely analogous to the orthodox scenario. There are two "
"hypotheses that we want to compare, a null hypothesis *h*\\ :sub:`0` and an "
"alternative hypothesis *h*\\ :sub:`1`. Prior to running the experiment we "
"have some beliefs *P*\\ (h) about which hypotheses are true. We run an "
"experiment and obtain data *d*. Unlike frequentist statistics, Bayesian "
"statistics does allow us to talk about the probability that the null "
"hypothesis is true. Better yet, it allows us to calculate the **posterior "
"probability of the null hypothesis**, using Bayes’ rule:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:20
msgid ""
"P(h_0 | d) = \\frac{P(d|h_0) P(h_0)}{P(d)}\n"
"\n"
msgstr ""
"P(h_0 | d) = \\frac{P(d|h_0) P(h_0)}{P(d)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:22
msgid ""
"This formula tells us exactly how much belief we should have in the null "
"hypothesis after having observed the data *d*. Similarly, we can work out "
"how much belief to place in the alternative hypothesis using essentially the "
"same equation. All we do is change the subscript:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:27
msgid ""
"P(h_1 | d) = \\frac{P(d|h_1) P(h_1)}{P(d)}\n"
"\n"
msgstr ""
"P(h_1 | d) = \\frac{P(d|h_1) P(h_1)}{P(d)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:29
msgid ""
"It’s all so simple that I feel like an idiot even bothering to write these "
"equations down, since all I’m doing is copying Bayes rule from the previous "
"section.\\ [#]_"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:34
msgid "The Bayes factor"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:36
msgid ""
"In practice, most Bayesian data analysts tend not to talk in terms of the "
"raw posterior probabilities *P*\\ (h\\ :sub:`0`\\|d) and *P*\\ (h\\ :sub:"
"`1`\\|d). Instead, we tend to talk in terms of the **posterior odds** ratio. "
"Think of it like betting. Suppose, for instance, the posterior probability "
"of the null hypothesis is 25%, and the posterior probability of the "
"alternative is 75%. The alternative hypothesis is three times as probable as "
"the null, so we say that the *odds* are 3:1 in favour of the alternative. "
"Mathematically, all we have to do to calculate the posterior odds is divide "
"one posterior probability by the other"
msgstr ""
"In der Praxis neigen die meisten Bayesianischen Datenanalysten dazu, nicht "
"von den rohen Posterior-Wahrscheinlichkeiten *P*\\ (h\\ :sub:`0`\\|d) und "
"*P*\\ (h\\ :sub:`1`\\|d) zu sprechen. Stattdessen neigen wir dazu, vom "
"**Verhältnis der a-posteriori-Wahrscheinlichkeiten** zu sprechen. Stellen "
"Sie sich das wie eine Wette vor. Angenommen, die a-posteriori-"
"Wahrscheinlichkeit der Nullhypothese beträgt 25% und die a-posteriori-"
"Wahrscheinlichkeit der Alternativhypothese beträgt 75%. Die "
"Alternativhypothese ist dreimal so wahrscheinlich wie die Nullhypothese, "
"also sagen wir, das *Verhältnis* sei 3:1 zugunsten der Alternative. "
"Mathematisch gesehen müssen wir zur Berechnung des Verhältnisses der a-"
"posteriori-Wahrscheinlichkeiten nur die eine posteriori-Wahrscheinlichkeit "
"durch die andere dividieren"

#: ../../Ch16/Ch16_Bayes_2.rst:46
msgid ""
"\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{0.75}{0.25} = 3\n"
"\n"
msgstr ""
"\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{0.75}{0.25} = 3\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:48
msgid "Or, to write the same thing in terms of the equations above"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:50
msgid ""
"\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{P(d|h_1)}{P(d|h_0)} \\times "
"\\frac{P(h_1)}{P(h_0)}\n"
"\n"
msgstr ""
"\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{P(d|h_1)}{P(d|h_0)} \\times "
"\\frac{P(h_1)}{P(h_0)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:52
msgid ""
"Actually, this equation is worth expanding on. There are three different "
"terms here that you should know. On the left hand side, we have the "
"posterior odds, which tells you what you believe about the relative "
"plausibilty of the null hypothesis and the alternative hypothesis *after* "
"seeing the data. On the right hand side, we have the **prior odds**, which "
"indicates what you thought *before* seeing the data. In the middle, we have "
"the **Bayes factor**, which describes the amount of evidence provided by the "
"data"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:61
msgid ""
"\\begin{array}{ccccc}\\displaystyle\n"
"\\frac{P(h_1 | d)}{P(h_0 | d)} & = & \\displaystyle\\frac{P(d|h_1)}{P(d|"
"h_0)} & \\times & \\displaystyle\\frac{P(h_1)}{P(h_0)} \\\\[6pt] \\\\[-2pt]\n"
"\\uparrow                      & ~ & \\uparrow                               "
"& ~      & \\uparrow                           \\\\[6pt]\n"
"\\mbox{Posterior odds}         & ~ & \\mbox{\\bf{Bayes "
"factor}}               & ~      & \\mbox{Prior odds}                  \\\\\n"
"\\end{array}"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:69
msgid ""
"The Bayes factor (sometimes abbreviated as **BF**) has a special place in "
"Bayesian hypothesis testing, because it serves a similar role to the *p*-"
"value in orthodox hypothesis testing. The Bayes factor quantifies the "
"strength of evidence provided by the data, and as such it is the Bayes "
"factor that people tend to report when running a Bayesian hypothesis test. "
"The reason for reporting Bayes factors rather than posterior odds is that "
"different researchers will have different priors. Some people might have a "
"strong bias to believe the null hypothesis is true, others might have a "
"strong bias to believe it is false. Because of this, the polite thing for an "
"applied researcher to do is report the Bayes factor. That way, anyone "
"reading the paper can multiply the Bayes factor by their own *personal* "
"prior odds, and they can work out for themselves what the posterior odds "
"would be. In any case, by convention we like to pretend that we give equal "
"consideration to both the null hypothesis and the alternative, in which case "
"the prior odds equals 1, and the posterior odds becomes the same as the "
"Bayes factor."
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:87
msgid "Interpreting Bayes factors"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:89
msgid ""
"One of the really nice things about the Bayes factor is the numbers are "
"inherently meaningful. If you run an experiment and you compute a Bayes "
"factor of 4, it means that the evidence provided by your data corresponds to "
"betting odds of 4:1 in favour of the alternative. However, there have been "
"some attempts to quantify the standards of evidence that would be considered "
"meaningful in a scientific context. The two most widely used are from "
"`Jeffreys (1961) <../Other/References.html#jeffreys-1961>`__ and `Kass and "
"Raftery (1995) <../Other/References.html#kass-1995>`__. Of the two, I tend "
"to prefer the `Kass and Raftery (1995) <../Other/References."
"html#kass-1995>`__ table because it’s a bit more conservative. So here it is:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:101
msgid "Bayes factor"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:101
msgid "Interpretation"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:103
msgid "1 –   3"
msgstr "1 –   3"

#: ../../Ch16/Ch16_Bayes_2.rst:103
msgid "Negligible evidence"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:105
msgid "3 –  20"
msgstr "3 –  20"

#: ../../Ch16/Ch16_Bayes_2.rst:105
msgid "Positive evidence"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:107
msgid "20 – 150"
msgstr "20 – 150"

#: ../../Ch16/Ch16_Bayes_2.rst:107
msgid "Strong evidence"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:109
msgid "> 150"
msgstr "> 150"

#: ../../Ch16/Ch16_Bayes_2.rst:109
msgid "Very strong evidence"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:112
msgid ""
"And to be perfectly honest, I think that even the `Kass and Raftery (1995) "
"<../Other/References.html#kass-1995>`__ standards are being a bit "
"charitable. If it were up to me, I’d have called the “positive evidence” "
"category “weak evidence”. To me, anything in the range 3:1 to 20:1 is “weak” "
"or “modest” evidence at best. But there are no hard and fast rules here. "
"What counts as strong or weak evidence depends entirely on how conservative "
"you are and upon the standards that your community insists upon before it is "
"willing to label a finding as “true”."
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:121
msgid ""
"In any case, note that all the numbers listed above make sense if the Bayes "
"factor is greater than 1 (i.e., the evidence favours the alternative "
"hypothesis). However, one big practical advantage of the Bayesian approach "
"relative to the orthodox approach is that it also allows you to quantify "
"evidence *for* the null. When that happens, the Bayes factor will be less "
"than 1. You can choose to report a Bayes factor less than 1, but to be "
"honest I find it confusing. For example, suppose that the likelihood of the "
"data under the null hypothesis *P*\\ (d|h\\ :sub:`0`) is equal to 0.2, and "
"the corresponding likelihood *P*\\ (d|h\\ :sub:`1`) under the alternative "
"hypothesis is 0.1. Using the equations given above, Bayes factor here would "
"be"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:133
msgid ""
"\\mbox{BF} = \\frac{P(d|h_1)}{P(d|h_0)} = \\frac{0.1}{0.2} = 0.5\n"
"\n"
msgstr ""
"\\mbox{BF} = \\frac{P(d|h_1)}{P(d|h_0)} = \\frac{0.1}{0.2} = 0.5\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:135
msgid ""
"Read literally, this result tells is that the evidence in favour of the "
"alternative is 0.5 to 1. I find this hard to understand. To me, it makes a "
"lot more sense to turn the equation “upside down”, and report the amount op "
"evidence in favour of the *null*. In other words, what we calculate is this"
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:141
msgid ""
"\\mbox{BF}^\\prime = \\frac{P(d|h_0)}{P(d|h_1)} = \\frac{0.2}{0.1} = 2\n"
"\n"
msgstr ""
"\\mbox{BF}^\\prime = \\frac{P(d|h_0)}{P(d|h_1)} = \\frac{0.2}{0.1} = 2\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:143
msgid ""
"And what we would report is a Bayes factor of 2:1 in favour of the null. "
"Much easier to understand, and you can interpret this using the table above."
msgstr ""

#: ../../Ch16/Ch16_Bayes_2.rst:150
msgid ""
"Obviously, this is a highly simplified story. All the complexity of real "
"life Bayesian hypothesis testing comes down to how you calculate the "
"likelihood *P*\\ (d|h) when the hypothesis *h* is a complex and vague thing. "
"I’m not going to talk about those complexities in this book, but I do want "
"to highlight that although this simple story is true as far as it goes, real "
"life is messier than I’m able to cover in an introductory stats textbook."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:4
msgid "Why be a Bayesian?"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:6
msgid ""
"Up to this point I’ve focused exclusively on the logic underpinning Bayesian "
"statistics. We’ve talked about the idea of “probability as a degree of "
"belief”, and what it implies about how a rational agent should reason about "
"the world. The question that you have to answer for yourself is this: how do "
"*you* want to do your statistics? Do you want to be an orthodox "
"statistician, relying on sampling distributions and *p*-values to guide your "
"decisions? Or do you want to be a Bayesian, relying on things like prior "
"beliefs, Bayes factors and the rules for rational belief revision? And to be "
"perfectly honest, I can’t answer this question for you. Ultimately it "
"depends on what you think is right. It’s your call and your call alone. That "
"being said, I can talk a little about why *I* prefer the Bayesian approach."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:20
msgid "Statistics that mean what you think they mean"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:0 ../../Ch16/Ch16_Bayes_3.rst
msgid ""
"*You keep using that word. I do not think it means what you think it means*"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:32
msgid ""
"`Inigo Montoya, The Princess Bride <https://www.imdb.com/title/tt0093779/"
"quotes>`__\\ [#]_"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:30
msgid ""
"To me, one of the biggest advantages to the Bayesian approach is that it "
"answers the right questions. Within the Bayesian framework, it is perfectly "
"sensible and allowable to refer to “the probability that a hypothesis is "
"true”. You can even try to calculate this probability. Ultimately, isn’t "
"that what you *want* your statistical tests to tell you? To an actual human "
"being, this would seem to be the whole *point* of doing statistics, i.e., to "
"determine what is true and what isn’t. Any time that you aren’t exactly sure "
"about what the truth is, you should use the language of probability theory "
"to say things like “there is an 80% chance that Theory A is true, but a 20% "
"chance that Theory B is true instead”."
msgstr ""
"Für mich besteht einer der größten Vorteile des Bayes'schen Ansatzes darin, "
"dass er die richtigen Fragen beantwortet. Im Rahmen des Bayes'schen Ansatzes "
"ist es durchaus sinnvoll und zulässig, sich auf die „Wahrscheinlichkeit, "
"dass eine Hypothese wahr ist“ zu beziehen. Man kann sogar versuchen, diese "
"Wahrscheinlichkeit zu berechnen. Ist es nicht genau das, was *Ihre "
"statistischen Tests Ihnen sagen sollten?* Für einen echten Menschen scheint "
"dies der *Punkt* der Statistik zu sein, d. h. zu bestimmen, was wahr ist und "
"was nicht. Jedes Mal, wenn Sie sich nicht ganz sicher sind, was die Wahrheit "
"ist, sollten Sie die Sprache der Wahrscheinlichkeitstheorie verwenden, um "
"Dinge zu sagen wie: „Es besteht eine 80% Wahrscheinlichkeit, dass Theorie A "
"wahr ist, aber eine 20% Wahrscheinlichkeit, dass stattdessen Theorie B wahr "
"ist“."

#: ../../Ch16/Ch16_Bayes_3.rst:42
msgid ""
"This seems so obvious to a human, yet it is explicitly forbidden within the "
"orthodox framework. To a frequentist, such statements are a nonsense because "
"“the theory is true” is not a repeatable event. A theory is true or it is "
"not, and no probabilistic statements are allowed, no matter how much you "
"might want to make them. There’s a reason why, back in section :doc:`The p "
"value of a test <../Ch09/Ch09_HypothesisTesting_05>`, I repeatedly warned "
"you *not* to interpret the *p*-value as the probability that the null "
"hypothesis is true. There’s a reason why almost every textbook on statstics "
"is forced to repeat that warning. It’s because people desperately *want* "
"that to be the correct interpretation. Frequentist dogma notwithstanding, a "
"lifetime of experience of teaching undergraduates and of doing data analysis "
"on a daily basis suggests to me that most actual humans think that “the "
"probability that the hypothesis is true” is not only meaningful, it’s the "
"thing we care *most* about. It’s such an appealing idea that even trained "
"statisticians fall prey to the mistake of trying to interpret a *p*-value "
"this way. For example, here is a quote from an `official Newspoll report in "
"2013 <https://about.abc.net.au/reports-publications/appreciation-survey-"
"summary-report-2013>`__, explaining how to interpret their (frequentist) "
"data analysis:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:61
msgid ""
"Throughout the report, where relevant, statistically significant changes "
"have been noted. All significance tests have been based on the 95 percent "
"level of confidence. **This means that if a change is noted as being "
"statistically significant, there is a 95 percent probability that a real "
"change has occurred**, and is not simply due to chance variation. (emphasis "
"added)"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:68
msgid ""
"Nope! That’s *not* what *p* < 0.05 means. That’s *not* what 95% confidence "
"means to a frequentist statistician. The bolded section is just plain wrong. "
"Orthodox methods cannot tell you that “there is a 95% chance that a real "
"change has occurred”, because this is not the kind of event to which "
"frequentist probabilities may be assigned. To an ideological frequentist, "
"this sentence should be meaningless. Even if you’re a more pragmatic "
"frequentist, it’s still the wrong definition of a *p*-value. It is simply "
"not an allowed or correct thing to say if you want to rely on orthodox "
"statistical tools."
msgstr ""
"Nö! Das ist *nicht* was *p* < 0,05 bedeutet. Und es ist auch *nicht*, was "
"95% Konfidenz für einen frequentistischen Statistiker bedeutet. Der "
"fettgedruckte Abschnitt ist schlichtweg falsch. Orthodoxe (frequentistische) "
"Methoden können nicht sagen: „Es besteht eine 95%-ige Wahrscheinlichkeit, "
"dass eine echte Veränderung eingetreten ist“, weil dies nicht die Art von "
"Ereignis ist, dem sich frequentistische Wahrscheinlichkeiten zuordnen "
"lassen. Für einen orthodoxen Frequentisten dürfte dieser Satz bedeutungslos "
"sein. Selbst wenn Sie ein pragmatischer Frequentist sind, ist dies immer "
"noch die falsche Definition eines *p*-Wertes. Es ist einfach nicht erlaubt "
"oder richtig, so etwas zu sagen, wenn man sich auf frequentistische "
"statistische Werkzeuge verlassen will."

#: ../../Ch16/Ch16_Bayes_3.rst:78
msgid ""
"On the other hand, let’s suppose you are a Bayesian. Although the bolded "
"passage is the wrong definition of a *p*-value, it’s pretty much exactly "
"what a Bayesian means when they say that the posterior probability of the "
"alternative hypothesis is greater than 95%. And here’s the thing. If the "
"Bayesian posterior is actually the thing you *want* to report, why are you "
"even trying to use orthodox methods? If you want to make Bayesian claims, "
"all you have to do is be a Bayesian and use Bayesian tools."
msgstr ""
"Nehmen wir andererseits an, Sie sind ein Bayesianer. Obwohl die "
"fettgedruckte Passage die falsche Definition eines *p*-Wertes ist, ist es "
"ziemlich genau das, was ein Bayesianer meint, wenn er sagt, dass die a-"
"posteriori-Wahrscheinlichkeit der Alternativhypothese größer als 95% ist. "
"Und das ist der springende Punkt. Wenn die Bayes'sche a-posteriori-"
"Wahrscheinlichkeit tatsächlich das ist, was Sie berichten *wollen*, warum "
"versuchen Sie dann überhaupt, frequentistische Methoden zu verwenden? Um "
"Bayes'sche Behauptungen aufzustellen, genügt es, ein Bayesianer zu sein, und "
"Bayes'sche Werkzeuge zu verwenden."

#: ../../Ch16/Ch16_Bayes_3.rst:87
msgid ""
"Speaking for myself, I found this to be the most liberating thing about "
"switching to the Bayesian view. Once you’ve made the jump, you no longer "
"have to wrap your head around counter-intuitive definitions of *p*-values. "
"You don’t have to bother remembering why you can’t say that you’re 95% "
"confident that the true mean lies within some interval. All you have to do "
"is be honest about what you believed before you ran the study and then "
"report what you learned from doing it. Sounds nice, doesn’t it? To me, this "
"is the big promise of the Bayesian approach. You do the analysis you really "
"want to do, and express what you really believe the data are telling you."
msgstr ""
"Für mich persönlich war dies das Befreiendste an der Umstellung auf die "
"Bayes'sche Sichtweise. Wenn man den Sprung geschafft hat, muss man sich "
"nicht mehr mit kontraintuitiven Definitionen von *p*-Werten herumschlagen. "
"Man muss sich nicht mehr daran erinnern, warum man nicht sagen kann, dass "
"man 95% sicher ist, dass der wahre Mittelwert innerhalb eines Intervalls "
"liegt. Alles, was Sie tun müssen, ist, ehrlich zu sagen, was Sie vor der "
"Studie geglaubt haben, und dann zu berichten, was Sie aus der Studie gelernt "
"haben. Klingt gut, nicht wahr? Für mich ist gerade dies das große "
"Versprechen des Bayes'schen Ansatzes. Sie führen die Analyse durch, die Sie "
"wirklich durchführen wollen, und bringen zum Ausdruck, was Sie wirklich "
"glauben, dass die Daten Ihnen sagen."

#: ../../Ch16/Ch16_Bayes_3.rst:99
msgid "Evidentiary standards you can believe"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:0 ../../Ch16/Ch16_Bayes_3.rst
msgid ""
"If [*p*] is below 0.02 it is strongly indicated that the [null] hypothesis "
"fails to account for the whole of the facts. We shall not often be astray if "
"we draw a conventional line at 0.05 and consider that [smaller values of "
"*p*] indicate a real discrepancy."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:116
msgid "`Sir Ronald Fisher (1925) <../Other/References.html#fisher-1925>`__"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:111
msgid ""
"Consider the quote above by Sir Ronald Fisher, one of the founders of what "
"has become the orthodox approach to statistics. If anyone has ever been "
"entitled to express an opinion about the intended function of *p*-values, "
"it’s Fisher. In this passage, taken from his classic guide *Statistical "
"Methods for Research Workers*, he’s pretty clear about what it means to "
"reject a null hypothesis at *p* < 0.05. In his opinion, if we take *p* < "
"0.05 to mean there is “a real effect”, then “we shall not often be astray”. "
"This view is hardly unusual. In my experience, most practitioners express "
"views very similar to Fisher’s. In essence, the *p* < 0.05 convention is "
"assumed to represent a fairly stringent evidential standard."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:123
msgid ""
"Well, how true is that? One way to approach this question is to try to "
"convert *p*-values to Bayes factors, and see how the two compare. It’s not "
"an easy thing to do because a *p*-value is a fundamentally different kind of "
"calculation to a Bayes factor, and they don’t measure the same thing. "
"However, there have been some attempts to work out the relationship between "
"the two, and it’s somewhat surprising. For example, `Johnson (2013) <../"
"Other/References.html#johnson-2013>`__ presents a pretty compelling case "
"that (for *t*-tests at least) the *p* < 0.05 threshold corresponds roughly "
"to a Bayes factor of somewhere between 3:1 and 5:1 in favour of the "
"alternative. If that’s right, then Fisher’s claim is a bit of a stretch. "
"Let’s suppose that the null hypothesis is true about half the time (i.e., "
"the prior probability of H\\ :sub:`0` is 0.5), and we use those numbers to "
"work out the posterior probability of the null hypothesis given that it has "
"been rejected at *p* < 0.05. Using the data from `Johnson (2013) <../Other/"
"References.html#johnson-2013>`__ , we see that if you reject the null at *p* "
"< 0.05, you’ll be correct about 80% of the time. I don’t know about you but, "
"in my opinion, an evidential standard that ensures you’ll be wrong on 20% of "
"your decisions isn’t good enough. The fact remains that, quite contrary to "
"Fisher’s claim, if you reject at *p* < 0.05 you shall quite often go astray. "
"It’s not a very stringent evidential threshold at all."
msgstr ""
"Nun, wie wahr ist das? Eine Möglichkeit, sich dieser Frage zu nähern, ist "
"der Versuch, *p*-Werte in Bayes-Faktoren umzuwandeln und zu sehen, ob sich "
"die beiden vergleichen lassen. Das ist nicht einfach, denn ein *p*-Wert "
"unterliegt einer grundsätzlich anderen Art von Berechnung als ein Bayes-"
"Faktor, und sie messen nicht dasselbe. Es hat jedoch einige Versuche "
"gegeben, die Beziehung zwischen den beiden herauszuarbeiten. Zum Beispiel "
"präsentiert `Johnson (2013) <../Other/References.html#johnson-2013>`__ ein "
"ziemlich überzeugendes Argument dafür, dass (zumindest für *t*-Tests) die "
"Schwelle von *p* < 0,05 ungefähr einem Bayes-Faktor von irgendwo zwischen "
"3:1 und 5:1 zugunsten der Alternative entspricht. Wenn das stimmt, dann ist "
"Fishers Behauptung ein bisschen weit hergeholt. Nehmen wir an, dass die "
"Nullhypothese in etwa der Hälfte der Fälle zutrifft (d. h., die a-priori-"
"Wahrscheinlichkeit von H\\ :sub:`0` ist 0,5), und wir verwenden diese "
"Zahlen, um die a-posteriori-Wahrscheinlichkeit der Nullhypothese zu "
"berechnen, wenn sie unter *p* < 0,05 zurückgewiesen würde. Anhand der Daten "
"von `Johnson (2013) <../Other/References.html#johnson-2013>`__ sehen wir, "
"dass, wenn Sie die Nullhypothese bei *p* < 0,05 ablehnen, in etwa 80% der "
"Fälle richtig liegen. Ich weiß nicht, wie es Ihnen geht, aber meiner Meinung "
"nach ist ein Standard, der sicherstellt, dass Sie bei lediglich 20% Ihrer "
"Entscheidungen falsch liegen, nicht gut genug. Tatsache ist, dass man "
"entgegen der Behauptung von Fisher ziemlich oft falsch liegt, wenn man eine "
"Hypothese bei *p* < 0,05 verwirft. Das ist keine sehr strenge Beweisschwelle."

#: ../../Ch16/Ch16_Bayes_3.rst:146
msgid "The *p*-value is a lie."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:0 ../../Ch16/Ch16_Bayes_3.rst
msgid "*The cake is a lie.*"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:162
msgid "`Portal <https://knowyourmeme.com/memes/the-cake-is-a-lie>`__"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:158
msgid ""
"Okay, at this point you might be thinking that the real problem is not with "
"orthodox statistics, just the *p* < 0.05 standard. In one sense, that’s "
"true. The recommendation that `Johnson (2013) <../Other/References."
"html#johnson-2013>`__ gives is not that “everyone must be a Bayesian now”. "
"Instead, the suggestion is that it would be wiser to shift the conventional "
"standard to something like a *p* < 0.01 level. That’s not an unreasonable "
"view to take, but in my view the problem is a little more severe than that. "
"In my opinion, there’s a fairly big problem built into the way most (but not "
"all) orthodox hypothesis tests are constructed. They are grossly naive about "
"how humans actually do research, and because of this most *p*-values are "
"wrong."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:169
msgid ""
"Sounds like an absurd claim, right? Well, consider the following scenario. "
"You’ve come up with a really exciting research hypothesis and you design a "
"study to test it. You’re very diligent, so you run a power analysis to work "
"out what your sample size should be, and you run the study. You run your "
"hypothesis test and out pops a *p*-value of 0.072. Really bloody annoying, "
"right?"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:176
msgid "What should you do? Here are some possibilities:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:178
msgid ""
"You conclude that there is no effect and try to publish it as a null result"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:181
msgid ""
"You guess that there might be an effect and try to publish it as a "
"“borderline significant” result"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:184
msgid "You give up and try a new study"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:186
msgid ""
"You collect some more data to see if the *p* value goes up or (preferably!) "
"drops below the “magic” criterion of *p* < 0.05"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:189
msgid ""
"Which would *you* choose? Before reading any further, I urge you to take "
"some time to think about it. Be honest with yourself. But don’t stress about "
"it too much, because you’re screwed no matter what you choose. Based on my "
"own experiences as an author, reviewer and editor, as well as stories I’ve "
"heard from others, here’s what will happen in each case:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:195
msgid ""
"Let’s start with option 1. If you try to publish it as a null result, the "
"paper will struggle to be published. Some reviewers will think that *p* = "
"0.072 is not really a null result. They’ll argue it’s borderline "
"significant. Other reviewers will agree it’s a null result but will claim "
"that even though some null results *are* publishable, yours isn’t. One or "
"two reviewers might even be on your side, but you’ll be fighting an uphill "
"battle to get it through."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:203
msgid ""
"Okay, let’s think about option number 2. Suppose you try to publish it as a "
"borderline significant result. Some reviewers will claim that it’s a null "
"result and should not be published. Others will claim that the evidence is "
"ambiguous, and that you should collect more data until you get a clear "
"significant result. Again, the publication process does not favour you."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:210
msgid ""
"Given the difficulties in publishing an “ambiguous” result like *p* = 0.072, "
"option number 3 might seem tempting: give up and do something else. But "
"that’s a recipe for career suicide. If you give up and try a new project "
"every time you find yourself faced with ambiguity, your work will never be "
"published. And if you’re in academia without a publication record you can "
"lose your job. So that option is out."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:218
msgid ""
"It looks like you’re stuck with option 4. You don’t have conclusive results, "
"so you decide to collect some more data and re-run the analysis. Seems "
"sensible, but unfortunately for you, if you do this all of your *p*-values "
"are now incorrect. *All* of them. Not just the *p*-values that you "
"calculated for *this* study. All of them. All the *p*-values you calculated "
"in the past and all the *p*-values you will calculate in the future. "
"Fortunately, no-one will notice. You’ll get published, and you’ll have lied."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:227
msgid ""
"Wait, what? How can that last part be true? I mean, it sounds like a "
"perfectly reasonable strategy doesn’t it? You collected some data, the "
"results weren’t conclusive, so now what you want to do is collect more data "
"until the the results *are* conclusive. What’s wrong with that?"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:232
msgid ""
"Honestly, there’s nothing wrong with it. It’s a reasonable, sensible and "
"rational thing to do. In real life, this is exactly what every researcher "
"does. Unfortunately, the theory of null hypothesis testing as I described it "
"in chapter :doc:`Hypothesis testing <../Ch09/Ch09_HypothesisTesting>` "
"*forbids* you from doing this.\\ [#]_ The reason is that the theory assumes "
"that the experiment is finished and all the data are in. And because it "
"assumes the experiment is over, it only considers *two* possible decisions. "
"If you’re using the conventional *p* < 0.05 threshold, those decisions are:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:242 ../../Ch16/Ch16_Bayes_3.rst:256
msgid "Outcome"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:242 ../../Ch16/Ch16_Bayes_3.rst:256
msgid "Action"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:244 ../../Ch16/Ch16_Bayes_3.rst:258
msgid "*p* less than 0.05"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:244
msgid "Reject the null"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:246
msgid "*p* greater than 0.05"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:246
msgid "Retain the null"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:249
msgid ""
"What *you’re* doing is adding a third possible action to the decision making "
"problem. Specifically, what you’re doing is using the *p*-value itself as a "
"reason to justify continuing the experiment. And as a consequence you’ve "
"transformed the decision-making procedure into one that looks more like this:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:258
msgid "Stop the experiment and reject the null"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:260
msgid "*p* between 0.05 and 0.1"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:260
msgid "Continue the experiment"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:262
msgid "*p* greater than 0.1"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:262
msgid "Stop the experiment and retain the null"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:265
msgid ""
"The “basic” theory of null hypothesis testing isn’t built to handle this "
"sort of thing, not in the form I described back in chapter :doc:`Hypothesis "
"testing <../Ch09/Ch09_HypothesisTesting>`. If you’re the kind of person who "
"would choose to “collect more data” in real life, it implies that you are "
"*not* making decisions in accordance with the rules of null hypothesis "
"testing. Even if you happen to arrive at the same decision as the hypothesis "
"test, you aren’t following the decision *process* it implies, and it’s this "
"failure to follow the process that is causing the problem (a `related "
"problem <https://xkcd.com/1478>`__). Your *p*-values are a lie."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:275
msgid ""
"Worse yet, they’re a lie in a dangerous way, because they’re all *too "
"small*. To give you a sense of just how bad it can be, consider the "
"following (worst case) scenario. Imagine you’re a really super-enthusiastic "
"researcher on a tight budget who didn’t pay any attention to my warnings "
"above. You design a study comparing two groups. You desperately want to see "
"a significant result at the *p* < 0.05 level, but you really don’t want to "
"collect any more data than you have to (because it’s expensive). In order to "
"cut costs you start collecting data but every time a new observation arrives "
"you run a *t*-test on your data. If the *t*-tests says *p* < 0.05 then you "
"stop the experiment and report a significant result. If not, you keep "
"collecting data. You keep doing this until you reach your pre-defined "
"spending limit for this experiment. Let’s say that limit kicks in at *N* = "
"1000 observations. As it turns out, the truth of the matter is that there is "
"no real effect to be found: the null hypothesis is true. So, what’s the "
"chance that you’ll make it to the end of the experiment and (correctly) "
"conclude that there is no effect? In an ideal world, the answer here should "
"be 95%. After all, the whole *point* of the *p* < 0.05 criterion is to "
"control the Type I error rate at 5%, so what we’d hope is that there’s only "
"a 5% chance of falsely rejecting the null hypothesis in this situation. "
"However, there’s no guarantee that will be true. You’re breaking the rules. "
"Because you’re running tests repeatedly, “peeking” at your data to see if "
"you’ve gotten a significant result, all bets are off."
msgstr ""
"Schlimmer noch, sie sind eine gefährliche Lüge, denn sie sind alle *zu "
"klein*. Um Ihnen ein Gefühl dafür zu geben, wie schlimm es sein kann, "
"stellen Sie sich folgendes Szenario vor (schlimmstmöglicher Fall). Stellen "
"Sie sich vor, Sie sind ein wirklich begeisterter Forscher mit einem knappen "
"Budget, der meine obigen Warnungen nicht beachtet hat. Sie entwerfen eine "
"Studie zum Vergleich zweier Gruppen. Sie wollen unbedingt ein signifikantes "
"Ergebnis mit *p* < 0,05 erzielen, aber Sie wollen nicht mehr Daten erheben "
"als nötig (denn das ist teuer). Um die Kosten zu sparen, beginnen Sie mit "
"dem Sammeln von Daten, aber jedes Mal, wenn eine neue Beobachtung eintrifft, "
"führen Sie einen *t*-Test mit Ihren Daten durch. Wenn der *t*-Test *p* < "
"0,05 ergibt, brechen Sie das Experiment ab und melden ein signifikantes "
"Ergebnis. Wenn nicht, sammeln Sie weiter Daten. Das machen Sie so lange, bis "
"Sie Ihr vorher festgelegtes Ausgabenlimit für dieses Experiment erreicht "
"haben. Sagen wir, diese Grenze wird bei *N* = 1000 Beobachtungen erreicht. "
"Es stellt sich heraus, dass in Wahrheit kein Effekt existiert: Die "
"Nullhypothese ist wahr. Wie groß ist also die Wahrscheinlichkeit, dass Sie "
"das Experiment zu Ende führen und (korrekt) zu dem Schluss kommen, dass es "
"keine Wirkung gibt? In einer idealen Welt sollte die Antwort hier 95% "
"lauten. Schließlich besteht der *Sinn* des Kriteriums *p* < 0,05 darin, die "
"Fehlerrate vom Typ I auf 5% zu begrenzen, so dass wir hoffen können, dass "
"die Wahrscheinlichkeit, die Nullhypothese fälschlicherweise zurückzuweisen, "
"in dieser Situation nur 5% beträgt. Es gibt jedoch keine Garantie dafür, "
"dass dieser Fall eintritt. Sie brechen die Regeln. Da Sie die Tests "
"wiederholt durchführen und Ihre Daten „überprüfen“, um zu sehen, ob Sie ein "
"signifikantes Ergebnis erhalten haben, sind alle Wetten verloren."

#: ../../Ch16/Ch16_Bayes_3.rst:306
msgid "Effect of re-running your tests every time new data arrive"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:306
msgid ""
"How badly can things go wrong if you re-run your tests every time new data "
"arrive? If you are a frequentist, the answer is “very wrong”."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:311
msgid ""
"So how bad is it? The answer is shown as the solid black line in :numref:"
"`fig-adapt`, and it’s *astoundingly* bad. If you peek at your data after "
"every single observation, there is a 49% chance that you will make a Type I "
"error. That’s, um, quite a bit bigger than the 5% that it’s supposed to be. "
"By way of comparison, imagine that you had used the following strategy. "
"Start collecting data. Every single time an observation arrives, run a :doc:"
"`Bayesian t-test <../Ch16/Ch16_Bayes_5>` and look at the Bayes factor. I’ll "
"assume that `Johnson (2013) <../Other/References.html#johnson-2013>`__ is "
"right, and I’ll treat a Bayes factor of 3:1 as roughly equivalent to a *p*-"
"value of 0.05.\\ [#]_ This time around, our trigger happy researcher uses "
"the following procedure. If the Bayes factor is 3:1 or more in favour of the "
"null, stop the experiment and retain the null. If it is 3:1 or more in "
"favour of the alternative, stop the experiment and reject the null. "
"Otherwise continue testing. Now, just like last time, let’s assume that the "
"null hypothesis is true. What happens? As it happens, I ran the simulations "
"for this scenario too, and the results are shown as the dashed line in :"
"numref:`fig-adapt`. It turns out that the Type I error rate is much much "
"lower than the 49% rate that we were getting by using the orthodox *t*-test."
msgstr ""
"Wie schlimm ist es also? Die Antwort wird als durchgezogene schwarze Linie "
"in :numref:`fig-adapt` angezeigt, und sie ist *erstaunlich* schlecht. Wenn "
"Sie nach jeder einzelnen Beobachtung einen Blick auf Ihre Daten werfen, "
"besteht eine 49%-ige Wahrscheinlichkeit, dass Sie einen Fehler vom Typ I "
"machen. Das ist, ähm, ziemlich viel größer als der 5%-Hut, den man "
"eigentlich aufsetzen sollte. Zum Vergleich: Stellen Sie sich vor, Sie hätten "
"die folgende Strategie angewandt. Beginnen Sie mit dem Sammeln von Daten. "
"Jedes Mal, wenn eine Beobachtung eintrifft, führen Sie einen :doc:"
"`Bayes'schen t-Test <../Ch16/Ch16_Bayes_5>` durch und sehen sich den Bayes-"
"Faktor an. Ich gehe davon aus, dass `Johnson (2013) <../Other/References."
"html#johnson-2013>`__ Recht hat, und behandle einen Bayes-Faktor von 3:1 als "
"ungefähr gleichwertig mit einem *p*-Wert von 0,05.\\ [#]_ Dieses Mal "
"verwendet unser Forscher das folgende Verfahren. Wenn der Bayes-Faktor 3:1 "
"oder mehr zu Gunsten der Nullhypothese beträgt, wird das Experiment "
"abgebrochen und die Nullhypothese beibehalten. Wenn der Bayes-Faktor 3:1 "
"oder mehr für die Alternativhypothese beträgt, wird das Experiment "
"abgebrochen und die Nullhypothese verworfen. Andernfalls setzen Sie den "
"Versuch fort. Nehmen wir nun wie beim letzten Mal an, dass die Nullhypothese "
"wahr ist. Was geschieht nun? Ich habe die Simulationen auch für dieses "
"Szenario durchgeführt, und die Ergebnisse sind als gestrichelte Linie in :"
"numref:`fig-adapt` dargestellt. Es stellt sich heraus, dass die Fehlerrate "
"vom Typ I sehr viel niedriger ist, als die 49%-ige Wahrscheinlichkeit, die "
"wir bei Verwendung des frequentistischen *t*-Tests erhielten."

#: ../../Ch16/Ch16_Bayes_3.rst:330
msgid ""
"In some ways, this is remarkable. The entire *point* of orthodox null "
"hypothesis testing is to control the Type I error rate. Bayesian methods "
"aren’t actually designed to do this at all. Yet, as it turns out, when faced "
"with a “trigger happy” researcher who keeps running hypothesis tests as the "
"data come in, the Bayesian approach is much more effective. Even the 3:1 "
"standard, which most Bayesians would consider unacceptably lax, is much "
"safer than the *p* < 0.05 rule."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:339
msgid "Is it really this bad?"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:341
msgid ""
"The example I gave in the previous section is a pretty extreme situation. In "
"real life, people don’t run hypothesis tests every time a new observation "
"arrives. So it’s not fair to say that the *p* < 0.05 threshold “really” "
"corresponds to a 49% Type I error rate (i.e., *p* = 0.49). But the fact "
"remains that if you want your *p*-values to be honest then you either have "
"to switch to a completely different way of doing hypothesis tests or enforce "
"a strict rule of *no peeking*. You are *not* allowed to use the data to "
"decide when to terminate the experiment. You are *not* allowed to look at a "
"“borderline” *p*-value and decide to collect more data. You aren’t even "
"allowed to change your data analyis strategy after looking at data. You are "
"strictly required to follow these rules, otherwise the *p*-values you "
"calculate will be nonsense."
msgstr ""
"Das Beispiel, welches ich im vorigen Abschnitt benutzt habe, beschreibt eine "
"ziemlich extreme Situation. Im wirklichen Leben führt man nicht jedes Mal "
"einen Hypothesentest durch, wenn eine neue Beobachtung eintrifft. Es ist "
"also nicht fair zu sagen, dass der Schwellenwert *p* < 0,05 „wirklich“ einer "
"Typ-I-Fehlerquote vom von 49 % entspricht (d. h. *p* = 0,49). Aber wenn Sie "
"wollen, dass Ihre *p*-Werte ehrlich sind, dann müssen Sie entweder zu einer "
"völlig anderen Art der Durchführung von Hypothesentests übergehen oder eine "
"strenge Regel durchsetzen: *no peeking*. Es ist *nicht* erlaubt, die Daten "
"zu verwenden, um zu entscheiden, wann das Experiment abgebrochen werden "
"soll. Es ist *nicht* erlaubt, sich einen „grenzwertigen“ *p*-Wert anzusehen "
"und zu entscheiden, mehr Daten zu sammeln. Sie dürfen nicht einmal Ihre "
"Strategie zur Datenanalyse ändern, nachdem Sie sich die Daten angesehen "
"haben. Sie müssen sich strikt an diese Regeln halten, sonst werden die *p*-"
"Werte, die Sie berechnen, unsinnig sein."

#: ../../Ch16/Ch16_Bayes_3.rst:355
msgid ""
"And yes, these rules are surprisingly strict. As a class exercise a couple "
"of years back, I asked students to think about this scenario. Suppose you "
"started running your study with the intention of collecting *N* = 80 people. "
"When the study starts out you follow the rules, refusing to look at the data "
"or run any tests. But when you reach *N* = 50 your willpower gives in... and "
"you take a peek. Guess what? You’ve got a significant result! Now, sure, you "
"know you *said* that you’d keep running the study out to a sample size of "
"*N* = 80, but it seems sort of pointless now, right? The result is "
"significant with a sample size of *N* = 50, so wouldn’t it be wasteful and "
"inefficient to keep collecting data? Aren’t you tempted to stop? Just a "
"little? Well, keep in mind that if you do, your Type I error rate at *p* < "
"0.05 just ballooned out to 8%. When you report *p* < 0.05 in your paper, "
"what you’re *really* saying is p < 0.08. That’s how bad the consequences of "
"“just one peek” can be."
msgstr ""
"Es ist korrekt, zu sagen, dass diese Regeln sind erstaunlich streng sind. "
"Vor ein paar Jahren habe ich die Schüler gebeten, über folgendes Szenario "
"nachzudenken. Angenommen, Sie beginnen Ihre Studie mit der Absicht, Daten "
"von *N* = 80 Personen zu erheben. Zu Beginn der Studie halten Sie sich an "
"die Regeln und weigern sich, die Daten anzusehen oder irgendwelche Tests "
"durchzuführen. Aber wenn Sie *N* = 50 erreichen, gibt Ihre Willenskraft "
"nach... und Sie werfen einen Blick auf Ihre Daten. Und raten Sie mal? Sie "
"haben ein signifikantes Ergebnis erhalten! Natürlich wissen Sie, dass Sie "
"*gesagt haben*, dass Sie die Studie bis zu einer Stichprobengröße von *N* = "
"80 weiterführen würden, aber das erscheint Ihnen jetzt irgendwie sinnlos, "
"oder? Das Ergebnis ist bei einer Stichprobengröße von *N* = 50 signifikant, "
"wäre es also nicht verschwenderisch und ineffizient, weiterhin Daten zu "
"sammeln? Sind Sie nicht versucht, damit aufzuhören? Nur ein bisschen? Dann "
"sollten Sie bedenken, dass Ihre Typ-I-Fehlerwahrscheinlichkeit gerade von 5% "
"auf 8% gestiegen ist. Wenn Sie in Ihrer Arbeit *p* < 0,05 angeben, heißt es "
"in Wirklichkeit *p* < 0,08. So schlimm können die Folgen von „nur einem "
"Blick“ sein."

#: ../../Ch16/Ch16_Bayes_3.rst:371
msgid ""
"Now consider this. The scientific literature is filled with *t*-tests, "
"ANOVAs, regressions and χ²-tests. When I wrote this book I didn’t pick these "
"tests arbitrarily. The reason why these four tools appear in most "
"introductory statistics texts is that these are the bread and butter tools "
"of science. None of these tools include a correction to deal with “data "
"peeking”: they all assume that you’re not doing it. But how realistic is "
"that assumption? In real life, how many people do you think have “peeked” at "
"their data before the experiment was finished and adapted their subsequent "
"behaviour after seeing what the data looked like? Except when the sampling "
"procedure is fixed by an external constraint, I’m guessing the answer is "
"“most people have done it”. If that has happened, you can infer that the "
"reported *p*-values are wrong. Worse yet, because we don’t know what "
"decision process they actually followed, we have no way to know what the *p*-"
"values *should* have been. You can’t compute a *p*-value when you don’t know "
"the decision making procedure that the researcher used. And so the reported "
"*p*-value remains a lie."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:387
msgid ""
"Given all of the above, what is the take home message? It’s not that "
"Bayesian methods are foolproof. If a researcher is determined to cheat, they "
"can always do so. Bayes’ rule cannot stop people from lying, nor can it stop "
"them from rigging an experiment. That’s not my point here. My point is the "
"same one I made at the very beginning of the book in section :doc:`On the "
"psychology of statistics <../Ch01/Ch01_WhyStats_1>`: the reason why we run "
"statistical tests is to protect us from ourselves. And the reason why “data "
"peeking” is such a concern is that it’s so tempting, *even for honest "
"researchers*. A theory for statistical inference has to acknowledge this. "
"Yes, you might try to defend *p*-values by saying that it’s the fault of the "
"researcher for not using them properly, but to my mind that misses the "
"point. A theory of statistical inference that is so completely naive about "
"humans that it doesn’t even consider the possibility that the researcher "
"might *look at their own data* isn’t a theory worth having. In essence, my "
"point is this:"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:0 ../../Ch16/Ch16_Bayes_3.rst
msgid "*Good laws have their origins in bad morals.*"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:410
msgid "`Ambrosius Macrobius <https://www.quotes.net/quote/20857>`__"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:409
msgid ""
"Good rules for statistical testing have to acknowledge human frailty. None "
"of us are without sin. None of us are beyond temptation. A good system for "
"statistical inference should still work even when it is used by actual "
"humans. Orthodox null hypothesis testing does not.\\ [#]_"
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:417
msgid ""
"I should note in passing that I’m not the first person to use this quote to "
"complain about frequentist methods. Rich Morey and colleagues had the idea "
"first. I’m shamelessly stealing it because it’s such an awesome pull quote "
"to use in this context and I refuse to miss any opportunity to quote *The "
"Princess Bride*."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:424
msgid ""
"In the interests of being completely honest, I should acknowledge that not "
"all orthodox statistical tests rely on this silly assumption. There are a "
"number of *sequential analysis* tools that are sometimes used in clinical "
"trials and the like. These methods are built on the assumption that data are "
"analysed as they arrive, and these tests aren’t horribly broken in the way "
"I’m complaining about here. However, sequential analysis methods are "
"constructed in a very different fashion to the “standard” version of null "
"hypothesis testing. They don’t make it into any introductory textbooks, and "
"they’re not very widely used in the psychological literature. The concern "
"I’m raising here is valid for every single orthodox test I’ve presented so "
"far and for almost every test I’ve seen reported in the papers I read."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:437
msgid ""
"Some readers might wonder why I picked 3:1 rather than 5:1, given that "
"`Johnson (2013) <../Other/References.html#johnson-2013>`__ suggests that *p* "
"= 0.05 lies somewhere in that range. I did so in order to be charitable to "
"the *p*-value. If I’d chosen a 5:1 Bayes factor instead, the results would "
"look even better for the Bayesian approach."
msgstr ""

#: ../../Ch16/Ch16_Bayes_3.rst:444
msgid ""
"Okay, I just *know* that some knowledgeable frequentists will read this and "
"start complaining about this section. Look, I’m not dumb. I absolutely know "
"that if you adopt a sequential analysis perspective you can avoid these "
"errors within the orthodox framework. I also know that you can explictly "
"design studies with interim analyses in mind. So yes, in one sense I’m "
"attacking a “straw man” version of orthodox methods. However, the straw man "
"that I’m attacking is the one that *is used by almost every single "
"practitioner*. If it ever reaches the point where sequential methods become "
"the norm among experimental psychologists and I’m no longer forced to read "
"20 extremely dubious ANOVAs a day, I promise I’ll rewrite this section and "
"dial down the vitriol. But until that day arrives, I stand by my claim that "
"*default* Bayes factor methods are much more robust in the face of data "
"analysis practices as they exist in the real world. *Default* orthodox "
"methods suck, and we all know it."
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:4
msgid "Bayesian t-tests"
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:6
msgid ""
"An important type of statistical inference problem discussed in this book is "
"the comparison between two means, discussed in some detail in the chapter on "
"*t*-tests (chapter :doc:`Comparing two means <../Ch11/Ch11_tTest>`). If you "
"can remember back that far, you’ll recall that there are several versions of "
"the *t*-test. I’ll talk a little about Bayesian versions of the independent "
"samples *t*-tests and the paired samples *t*-test in this section."
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:14
msgid "Independent samples t-test"
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:16
msgid ""
"The most common type of *t*-test is the independent samples *t*-test, and it "
"arises when you have data as in the |harpo|_ data set that we used in the "
"earlier chapter on *t*-tests (chapter :doc:`Comparing two means <../Ch11/"
"Ch11_tTest>`). In this data set, we have two groups of students, those who "
"received lessons from Anastasia and those who took their classes with "
"Bernadette. The question we want to answer is whether there’s any difference "
"in the grades received by these two groups of students. Back in that "
"chapter, I suggested you could analyse this kind of data using the "
"Independent Samples *t*-test in jamovi, which gave us the results in :numref:"
"`fig-bayes1`. As we obtain a *p*-value less than \\0.05, we reject the null "
"hypothesis."
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:33
msgid "``Independent Samples T-Test`` result in jamovi"
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:37
msgid ""
"What does the Bayesian version of the *t*-test look like? We can get the "
"Bayes factor by selecting the ``Bayes Factor`` checkbox under the ``Tests`` "
"option, and accepting the suggested default value for the ``Prior``. This "
"gives the results shown in the table in :numref:`fig-bayes2`. What we get in "
"this table is a Bayes factor statistic of 1.75, meaning that the evidence "
"provided by these data are about 1.8:1 in favour of the alternative "
"hypothesis."
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:50
msgid "``Bayes Factor`` analysis alongside ``Independent Samples T-Test``"
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:54
msgid ""
"Before moving on, it’s worth highlighting the difference between the "
"orthodox test results and the Bayesian one. According to the orthodox test, "
"we obtained a significant result, though only barely. Nevertheless, many "
"people would happily accept *p* = 0.043 as reasonably strong evidence for an "
"effect. In contrast, notice that the Bayesian test doesn’t even reach 2:1 "
"odds in favour of an effect, and would be considered very weak evidence at "
"best. In my experience that’s a pretty typical outcome. Bayesian methods "
"usually require more evidence before rejecting the null."
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:64
msgid "Paired samples *t*-test"
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:66
msgid ""
"Back in section :doc:`The paired-samples t-test <../Ch11/Ch11_tTest_05>` I "
"discussed the |chico|_ data set in which student grades were measured on two "
"tests, and we were interested in finding out whether grades went up from "
"test 1 to test 2. Because every student did both tests, the tool we used to "
"analyse the data was a paired samples *t*-test. :numref:`fig-bayes3` shows "
"the jamovi results table for the conventional ``Paired Samples T-Test`` "
"alongside the ``Bayes Factor`` analysis. At this point, I hope you can read "
"this output without any difficulty. The data provide evidence of about "
"6000:1 in favour of the alternative. We could probably reject the null with "
"some confidence!"
msgstr ""

#: ../../Ch16/Ch16_Bayes_5.rst:82
msgid "``Paired Samples T-Test`` and ``Bayes Factor`` result in jamovi"
msgstr ""

#: ../../Ch16/Ch16_Bayes_8.rst:4
msgid "Summary"
msgstr "Zusammenfassung"

#: ../../Ch16/Ch16_Bayes_8.rst:6
msgid ""
"The first half of this chapter was focused primarily on the theoretical "
"underpinnings of Bayesian statistics. I introduced the mathematics for how "
"Bayesian inference works (section :doc:`Probabilistic reasoning by rational "
"agents <../Ch16/Ch16_Bayes_1>`), and gave a very basic overview of how :doc:"
"`Bayesian hypothesis testing <../Ch16/Ch16_Bayes_2>` is typically done. "
"Finally, I devoted some space to talking about why I think Bayesian methods "
"are worth using (section :doc:`Why be a Bayesian? <../Ch16/Ch16_Bayes_3>`). "
"Then I gave a practical example, a :doc:`Bayesian t-test <../Ch16/"
"Ch16_Bayes_5>`."
msgstr ""

#: ../../Ch16/Ch16_Bayes_8.rst:15
msgid ""
"If you’re interested in learning more about the Bayesian approach, there are "
"many good books you could look into. `John Kruschke’s (2015) <../Other/"
"References.html#kruschke-2015>`__ book *Doing Bayesian Data Analysis* is a "
"pretty good place to start and is a nice mix of theory and practice. His "
"approach is a little different to the “Bayes factor” approach that I’ve "
"discussed here, so you won’t be covering the same ground. If you’re a "
"cognitive psychologist, you might want to check out `Michael Lee and Eric-"
"Jan Wagenmakers’ (2014) <../Other/References.html#lee-2014>`__ book "
"*Bayesian Cognitive Modeling*. I picked these two because I think they’re "
"especially useful for people in my discipline, but there’s a lot of good "
"books out there, so look around!"
msgstr ""
