#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Learning statistics with jamovi \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-04-01 22:32+0200\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Project-Id-Version: Learning statistics with jamovi \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-04-01 22:32+0200\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Project-Id-Version: Learning statistics with jamovi \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-17 18:06+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Project-Id-Version: Learning statistics with jamovi \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-17 18:06+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Project-Id-Version: Learning statistics with jamovi\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-03-17 18:06+0100\n"
"PO-Revision-Date: 2025-03-31 16:04+0000\n"
"Last-Translator: Sebastian Jentschke <sebastian.jentschke@uib.no>\n"
"Language-Team: Norwegian Bokmål <https://hosted.weblate.org/projects/lsjdocs/"
"ch02/nb_NO/>\n"
"Language: nb\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"X-Generator: Weblate 5.11-dev\n"
"Generated-By: Babel 2.10.3\n"

#: ../../Ch02/Ch02_StudyDesign.rst:4
msgid "A brief introduction to research design"
msgstr "En kort innføring i forskningsdesign"

#: ../../Ch02/Ch02_StudyDesign.rst:0
msgid ""
"*To consult the statistician after an experiment is finished is often merely "
"to ask him to conduct a post mortem examination. He can perhaps say what the "
"experiment died of.*"
msgstr ""
"* Å oppsøke statistikeren etter at et eksperiment er avsluttet, er ofte det "
"samme som å be ham om å foreta en obduksjon. Han kan kanskje si hva "
"eksperimentet døde av.*"

#: ../../Ch02/Ch02_StudyDesign.rst:25
msgid "Sir Ronald Fisher\\ [#]_"
msgstr "Sir Ronald Fisher\\ [#]_"

#: ../../Ch02/Ch02_StudyDesign.rst:27
msgid ""
"In this chapter, we’re going to start thinking about the basic ideas that go "
"into designing a study, collecting data, checking whether your data "
"collection works, and so on. It won’t give you enough information to allow "
"you to design studies of your own, but it will give you a lot of the basic "
"tools that you need to assess the studies done by other people. However, "
"since the focus of this book is much more on data analysis than on data "
"collection, I’m only giving a very brief overview. Note that this chapter is "
"“special” in two ways. Firstly, it’s much more psychology-specific than the "
"later chapters. Secondly, it focuses much more heavily on the scientific "
"problem of research methodology, and much less on the statistical problem of "
"data analysis. Nevertheless, the two problems are related to one another, so "
"it’s traditional for stats textbooks to discuss the problem in a little "
"detail. This chapter relies heavily on :ref:`Campbell and Stanley (1963) "
"<Campbell_1963>` for the discussion of study design, and :ref:`Stevens "
"(1946) <Stevens_1946>` for the discussion of scales of measurement."
msgstr ""
"I dette kapittelet skal vi begynne å tenke på de grunnleggende ideene som "
"ligger til grunn for å utforme en studie, samle inn data, sjekke om "
"datainnsamlingen fungerer, og så videre. Det vil ikke gi deg nok informasjon "
"til at du kan utforme dine egne studier, men det vil gi deg mange av de "
"grunnleggende verktøyene du trenger for å vurdere andres studier. Men siden "
"fokuset i denne boken er mye mer på dataanalyse enn på datainnsamling, gir "
"jeg bare en svært kortfattet oversikt. Merk at dette kapittelet er "
"«spesielt» på to måter. For det første er det mye mer psykologispesifikt enn "
"de senere kapitlene. For det andre fokuserer det mye sterkere på det "
"vitenskapelige problemet med forskningsmetodikk, og mye mindre på det "
"statistiske problemet med dataanalyse. Likevel er de to problemene knyttet "
"til hverandre, så det er tradisjon for at lærebøker i statistikk diskuterer "
"problemet litt i detalj. Dette kapitlet bygger i stor grad på :ref:`Campbell "
"og Stanley (1963) <Campbell_1963>` for diskusjonen av studiedesign, og :ref:"
"`Stevens (1946) <Stevens_1946>` for diskusjonen av målenivåer."

#: ../../Ch02/Ch02_StudyDesign.rst:47
msgid ""
"`Presidential Address to the First Indian Statistical Congress, 1938 "
"<https://en.wikiquote.org/wiki/Ronald_Fisher>`__."
msgstr ""
"`Presidentens tale til den første indiske statistikkongressen, 1938 <https://"
"en.wikiquote.org/wiki/Ronald_Fisher>`__."

#: ../../Ch02/Ch02_StudyDesign_1.rst:4
msgid "Introduction to psychological measurement"
msgstr "Introduksjon til psykologisk måling"

#: ../../Ch02/Ch02_StudyDesign_1.rst:6
msgid ""
"The first thing to understand is data collection can be thought of as a kind "
"of **measurement**. That is, what we’re trying to do here is measure "
"something about human behaviour or the human mind. What do I mean by "
"“measurement”?"
msgstr ""
"Det første du må forstå, er at datainnsamling kan betraktes som en slags "
"**måling**. Det vil si at det vi prøver å gjøre her, er å måle noe om "
"menneskelig atferd eller menneskesinnet. Hva mener jeg med «måling»?"

#: ../../Ch02/Ch02_StudyDesign_1.rst:11
msgid ""
"Measurement itself is a subtle concept, but basically it comes down to "
"finding some way of assigning numbers, or labels, or some other kind of well-"
"defined descriptions, to “stuff”. So, any of the following would count as a "
"psychological measurement:"
msgstr ""
"Måling er i seg selv et subtilt begrep, men i bunn og grunn handler det om å "
"finne en måte å tilordne tall, etiketter eller andre veldefinerte "
"beskrivelser til «ting» på. Alle de følgende tingene kan regnes som "
"psykologiske målinger:"

#: ../../Ch02/Ch02_StudyDesign_1.rst:16
msgid "My **age** is *33 years*."
msgstr "Min **alder** er *33 år*."

#: ../../Ch02/Ch02_StudyDesign_1.rst:18
msgid "I *do not* **like anchovies**."
msgstr "Jeg **liker** *ikke* **ansjos**."

#: ../../Ch02/Ch02_StudyDesign_1.rst:20
msgid "My **chromosomal gender** is *male*."
msgstr "Mitt **kromosomale kjønn** er *mann*."

#: ../../Ch02/Ch02_StudyDesign_1.rst:22
msgid "My **self-identified gender** is *female*."
msgstr "Mitt **selvidentifiserte kjønn** er *kvinne*."

#: ../../Ch02/Ch02_StudyDesign_1.rst:24
msgid ""
"In the short list above, the **bolded part** is “the thing to be measured”, "
"and the *italicised part* is “the measurement itself”. In fact, we can "
"expand on this a little bit, by thinking about the set of possible "
"measurements that could have arisen in each case:"
msgstr ""
"I den korte listen ovenfor er det som er skrevet **fet** «tingen som skal "
"måles», og det som er skrevet *kursivt* er «selve målingen». Vi kan faktisk "
"utvide dette litt, ved å tenke på mengden av mulige målinger som kunne ha "
"vært gjennomført i hvert enkelt tilfelle:"

#: ../../Ch02/Ch02_StudyDesign_1.rst:29
msgid ""
"My **age** (in years) could have been *0, 1, 2, 3 …*, etc. The upper bound "
"on what my age could possibly be is a bit fuzzy, but in practice you’d be "
"safe in saying that the largest possible age is *150*, since no human has "
"ever lived that long."
msgstr ""
"Min **alder** (i år) kunne ha vært *0, 1, 2, 3 …* osv. Den øvre grensen for "
"hva alderen min kan være, er litt uklar, men i praksis kan man trygt si at "
"den høyest mulige alderen er *150*, siden ingen mennesker noensinne har levd "
"så lenge."

#: ../../Ch02/Ch02_StudyDesign_1.rst:34
msgid ""
"When asked if I **like anchovies**, I might have said that *I do*, or *I do "
"not*, or *I have no opinion*, or *I sometimes do*."
msgstr ""
"På spørsmål om jeg **liker ansjos**, kunne jeg ha sagt at *jeg gjør det*, "
"eller *jeg gjør det ikke*, eller *jeg har ingen mening*, eller *jeg gjør det "
"av og til*."

#: ../../Ch02/Ch02_StudyDesign_1.rst:37
msgid ""
"My **chromosomal gender** is almost certainly going to be *male (XY)* or "
"*female (XX)*, but there are a few other possibilities. I could also have "
"*Klinfelter’s syndrome (XXY)*, which is more similar to male than to female. "
"And I imagine there are other possibilities too."
msgstr ""
"Mitt **kromosomale kjønn** kommer nesten helt sikkert til å være *mann (XY)* "
"eller *kvinne (XX)*, men det finnes noen andre muligheter. Jeg kan også ha "
"*Klinfelters syndrom (XXY)*, som ligner mer på mann enn på kvinne. Og jeg "
"kan tenke meg at det finnes andre muligheter også."

#: ../../Ch02/Ch02_StudyDesign_1.rst:42
msgid ""
"My **self-identified gender** is also very likely to be *male* or *female*, "
"but it doesn’t have to agree with my chromosomal gender. I may also choose "
"to identify with *neither*, or to explicitly call myself *transgender*."
msgstr ""
"Mitt **selvidentifiserte kjønn** er også med stor sannsynlighet *mann* eller "
"*kvinne*, men det trenger ikke å stemme overens med mitt kromosomale kjønn. "
"Jeg kan også velge å identifisere meg med *ingen av delene*, eller å "
"eksplisitt kalle meg *transgender*."

#: ../../Ch02/Ch02_StudyDesign_1.rst:47
msgid ""
"As you can see, for some things (like age) it seems fairly obvious what the "
"set of possible measurements should be, whereas for other things it gets a "
"bit tricky. But I want to point out that even in the case of someone’s age "
"it’s much more subtle than this. For instance, in the example above I "
"assumed that it was okay to measure age in years. But if you’re a "
"developmental psychologist, that’s way too crude, and so you often measure "
"age in *years and months* (if a child is 2 years and 11 months this is "
"usually written as “2;11”). If you’re interested in newborns you might want "
"to measure age in *days since birth*, maybe even *hours since birth*. In "
"other words, the way in which you specify the allowable measurement values "
"is important."
msgstr ""
"Som du kan se, virker det for noen ting (som alder) ganske opplagt hva "
"settet av mulige målinger bør være, mens det for andre ting blir litt "
"vanskeligere. Men jeg vil påpeke at selv når det gjelder en persons alder, "
"er det mye mer subtilt enn dette. I eksempelet ovenfor antok jeg for "
"eksempel at det var greit å måle alder i år. Men hvis du er "
"utviklingspsykolog, er det altfor grovt, og derfor måler du ofte alder i *år "
"og måneder* (hvis et barn er 2 år og 11 måneder, skrives dette vanligvis som "
"«2;11»). Hvis du er interessert i nyfødte, kan det være lurt å måle alder i "
"*dager siden fødselen*, kanskje til og med *timer siden fødselen*. Det er "
"med andre ord viktig hvordan du spesifiserer de tillatte måleverdiene."

#: ../../Ch02/Ch02_StudyDesign_1.rst:59
msgid ""
"Looking at this a bit more closely, you might also realise that the concept "
"of “age” isn’t actually all that precise. In general, when we say “age” we "
"implicitly mean “the length of time since birth”. But that’s not always the "
"right way to do it. Suppose you’re interested in how newborn babies control "
"their eye movements. If you’re interested in kids that young, you might also "
"start to worry that “birth” is not the only meaningful point in time to care "
"about. If Baby Alice is born 3 weeks premature and Baby Bianca is born 1 "
"week late, would it really make sense to say that they are the “same age” if "
"we encountered them “2 hours after birth”? In one sense, yes. By social "
"convention we use birth as our reference point for talking about age in "
"everyday life, since it defines the amount of time the person has been "
"operating as an independent entity in the world. But from a scientific "
"perspective that’s not the only thing we care about. When we think about the "
"biology of human beings, it’s often useful to think of ourselves as "
"organisms that have been growing and maturing since conception, and from "
"that perspective Alice and Bianca aren’t the same age at all. So you might "
"want to define the concept of “age” in two different ways: the length of "
"time since conception and the length of time since birth. When dealing with "
"adults it won’t make much difference, but when dealing with newborns it "
"might."
msgstr ""
"Hvis du ser litt nærmere på dette, vil du kanskje også innse at begrepet "
"«alder» faktisk ikke er så presist. Når vi sier «alder», mener vi vanligvis "
"implisitt «tiden siden fødselen». Men det er ikke alltid den riktige måten å "
"gjøre det på. Sett at du er interessert i hvordan nyfødte barn kontrollerer "
"øyebevegelsene sine. Hvis du er interessert i så små barn, kan du også "
"begynne å bekymre deg for at «fødsel» ikke er det eneste meningsfulle "
"tidspunktet å bry seg om. Hvis Baby Alice er født tre uker for tidlig og "
"Baby Bianca er født én uke for sent, gir det da mening å si at de er «like "
"gamle» hvis vi møter dem «to timer etter fødselen»? På én måte, ja. Av "
"sosial konvensjon bruker vi fødselen som referansepunkt for å snakke om "
"alder i hverdagen, siden den definerer hvor lenge personen har fungert som "
"en selvstendig enhet i verden. Men fra et vitenskapelig perspektiv er det "
"ikke det eneste vi bryr oss om. Når vi tenker på menneskets biologi, er det "
"ofte nyttig å tenke på oss selv som organismer som har vokst og modnet siden "
"unnfangelsen, og ut fra det perspektivet er Alice og Bianca ikke like gamle "
"i det hele tatt. Det kan derfor være lurt å definere begrepet «alder» på to "
"forskjellige måter: tiden siden unnfangelsen og tiden siden fødselen. Når "
"det gjelder voksne, vil det ikke utgjøre noen stor forskjell, men når det "
"gjelder nyfødte, kan det gjøre det."

#: ../../Ch02/Ch02_StudyDesign_1.rst:81
msgid ""
"Moving beyond these issues, there’s the question of methodology. What "
"specific “measurement method” are you going to use to find out someone’s "
"age? As before, there are lots of different possibilities:"
msgstr ""
"I tillegg til disse spørsmålene kommer spørsmålet om metodikk. Hvilken "
"spesifikk «målemetode» skal du bruke for å finne ut noens alder? Som "
"tidligere finnes det mange ulike muligheter:"

#: ../../Ch02/Ch02_StudyDesign_1.rst:85
msgid ""
"You could just ask people “how old are you?” The method of self-report is "
"fast, cheap and easy. But it only works with people old enough to understand "
"the question, and some people lie about their age."
msgstr ""
"Du kan bare spørre folk «hvor gammel er du?». Metoden med selvrapportering "
"er rask, billig og enkel. Men den fungerer bare med folk som er gamle nok "
"til å forstå spørsmålet, og noen lyver om alderen sin."

#: ../../Ch02/Ch02_StudyDesign_1.rst:90
msgid ""
"You could ask an authority (e.g., a parent) “how old is your child?” This "
"method is fast, and when dealing with kids it’s not all that hard since the "
"parent is almost always around. It doesn’t work as well if you want to know "
"“age since conception”, since a lot of parents can’t say for sure when "
"conception took place. For that, you might need a different authority (e.g., "
"an obstetrician)."
msgstr ""
"Du kan spørre en autoritet (f.eks. en forelder): «Hvor gammelt er barnet "
"ditt?» Denne metoden er rask, og når det gjelder barn, er det ikke så "
"vanskelig, siden foreldrene nesten alltid er til stede. Den fungerer ikke "
"like bra hvis du vil vite «alder siden unnfangelsen», siden mange foreldre "
"ikke kan si sikkert når unnfangelsen fant sted. Da trenger du kanskje en "
"annen autoritet (f.eks. en fødselslege)."

#: ../../Ch02/Ch02_StudyDesign_1.rst:97
msgid ""
"You could look up official records, for example birth or death certificates. "
"This is a time consuming and frustrating endeavour, but it has its uses (e."
"g., if the person is now dead)."
msgstr ""
"Du kan slå opp i offisielle registre, for eksempel fødsels- eller "
"dødsattester. Dette er et tidkrevende og frustrerende arbeid, men det har "
"sine fordeler (f.eks. hvis personen nå er død)."

#: ../../Ch02/Ch02_StudyDesign_1.rst:102
msgid "Operationalisation: defining your measurement"
msgstr "Operasjonalisering: definere målingen din"

#: ../../Ch02/Ch02_StudyDesign_1.rst:104
msgid ""
"All of the ideas discussed in the previous section relate to the concept of "
"**operationalisation**. To be a bit more precise about the idea, "
"operationalisation is the process by which we take a meaningful but somewhat "
"vague concept and turn it into a precise measurement. The process of "
"operationalisation can involve several different things:"
msgstr ""
"Alle ideene som er diskutert i forrige avsnitt, er knyttet til begrepet "
"**operasjonalisering**. For å være litt mer presis: Operasjonalisering er "
"prosessen der vi tar et meningsfylt, men noe vagt begrep og gjør det om til "
"en presis måling. Operasjonaliseringsprosessen kan innebære flere "
"forskjellige ting:"

#: ../../Ch02/Ch02_StudyDesign_1.rst:110
msgid ""
"Being precise about what you are trying to measure. For instance, does “age” "
"mean “time since birth” or “time since conception” in the context of your "
"research?"
msgstr ""
"Vær presis med hensyn til hva du prøver å måle. Betyr for eksempel «alder» "
"«tid siden fødsel» eller «tid siden unnfangelse» i forbindelse med "
"forskningen din?"

#: ../../Ch02/Ch02_StudyDesign_1.rst:114
msgid ""
"Determining what method you will use to measure it. Will you use self-report "
"to measure age, ask a parent, or look up an official record? If you’re using "
"self-report, how will you phrase the question?"
msgstr ""
"Bestem hvilken metode du vil bruke for å måle den. Skal du bruke "
"selvrapportering for å måle alder, spørre en forelder eller slå opp i et "
"offisielt register? Hvis du bruker selvrapportering, hvordan skal du "
"formulere spørsmålet?"

#: ../../Ch02/Ch02_StudyDesign_1.rst:119
msgid ""
"Defining the set of allowable values that the measurement can take. Note "
"that these values don’t always have to be numerical, though they often are. "
"When measuring age the values are numerical, but we still need to think "
"carefully about what numbers are allowed. Do we want age in years, years and "
"months, days, or hours? For other types of measurements (e.g., gender) the "
"values aren’t numerical. But, just as before, we need to think about what "
"values are allowed. If we’re asking people to self-report their gender, what "
"options to we allow them to choose between? Is it enough to allow only "
"“male” or “female”? Do you need an “other” option? Or should we not give "
"people specific options and instead let them answer in their own words? And "
"if you open up the set of possible values to include all verbal response, "
"how will you interpret their answers?"
msgstr ""
"Definere settet av tillatte verdier som målingen kan ta. Merk at disse "
"verdiene ikke alltid trenger å være numeriske, selv om de ofte er det. Når "
"vi måler alder, er verdiene numeriske, men vi må likevel tenke nøye gjennom "
"hvilke tall som er tillatt. Vil vi ha alder i år, år og måneder, dager eller "
"timer? For andre typer målinger (f.eks. kjønn) er verdiene ikke numeriske. "
"Men akkurat som før må vi tenke på hvilke verdier som er tillatt. Hvis vi "
"ber folk om å oppgi kjønn, hvilke alternativer skal vi la dem velge mellom? "
"Er det nok å bare tillate «mann» eller «kvinne»? Trenger du et «annet»-"
"alternativ? Eller bør vi ikke gi folk spesifikke alternativer, og i stedet "
"la dem svare med sine egne ord? Og hvis du åpner opp for alle mulige "
"verdier, hvordan skal du tolke svarene deres?"

#: ../../Ch02/Ch02_StudyDesign_1.rst:133
msgid ""
"Operationalisation is a tricky business, and there’s no “one, true way” to "
"do it. The way in which you choose to operationalise the informal concept of "
"“age” or “gender” into a formal measurement depends on what you need to use "
"the measurement for. Often you’ll find that the community of scientists who "
"work in your area have some fairly well-established ideas for how to go "
"about it. In other words, operationalisation needs to be thought through on "
"a case by case basis. Nevertheless, while there a lot of issues that are "
"specific to each individual research project, there are some aspects to it "
"that are pretty general."
msgstr ""
"Operasjonalisering er en vanskelig øvelse, og det finnes ikke «én riktig "
"måte» å gjøre det på. Hvordan du velger å operasjonalisere det uformelle "
"begrepet «alder» eller «kjønn» til et formelt mål, avhenger av hva du skal "
"bruke målet til. Ofte vil du oppdage at forskningsmiljøet som jobber på ditt "
"område, har noen ganske veletablerte ideer om hvordan du skal gå frem. Med "
"andre ord må operasjonalisering vurderes fra sak til sak. Selv om det er "
"mange spørsmål som er spesifikke for hvert enkelt forskningsprosjekt, er det "
"likevel noen aspekter som er ganske generelle."

#: ../../Ch02/Ch02_StudyDesign_1.rst:144
msgid ""
"Before moving on I want to take a moment to clear up our terminology, and in "
"the process introduce one more term. Here are four different things that are "
"closely related to each other:"
msgstr ""
"Før vi går videre, vil jeg bruke et øyeblikk på å rydde opp i terminologien, "
"og i samme slengen introdusere et nytt begrep. Her er fire forskjellige ting "
"som er nært beslektet med hverandre:"

#: ../../Ch02/Ch02_StudyDesign_1.rst:148
msgid ""
"**A theoretical construct**. This is the thing that you’re trying to take a "
"measurement of, like “age”, “gender” or an “opinion”. A theoretical "
"construct can’t be directly observed, and often they’re actually a bit vague."
msgstr ""
"**En teoretisk konstrukt**. Dette er det du prøver å måle, som «alder», "
"«kjønn» eller en «mening». En teoretisk konstrukt kan ikke observeres "
"direkte, og ofte er de faktisk litt vage."

#: ../../Ch02/Ch02_StudyDesign_1.rst:153
msgid ""
"**A measure**. The measure refers to the method or the tool that you use to "
"make your observations. A question in a survey, a behavioural observation or "
"a brain scan could all count as a measure."
msgstr ""
"**Et mål**. Tiltaket refererer til metoden eller verktøyet du bruker for å "
"gjøre observasjonene dine. Et spørsmål i en spørreundersøkelse, en "
"atferdsobservasjon eller en hjerneskanning kan alle regnes som et tiltak."

#: ../../Ch02/Ch02_StudyDesign_1.rst:157
msgid ""
"**An operationalisation**. The term “operationalisation” refers to the "
"logical connection between the measure and the theoretical construct, or to "
"the process by which we try to derive a measure from a theoretical construct."
msgstr ""
"**En operasjonalisering**. Begrepet «operasjonalisering» refererer til den "
"logiske forbindelsen mellom målingen og det teoretiske konstruktet, eller "
"til prosessen der vi forsøker å utlede en måling fra et teoretisk konstrukt."

#: ../../Ch02/Ch02_StudyDesign_1.rst:162
msgid ""
"**A variable**. Finally, a new term. A variable is what we end up with when "
"we apply our measure to something in the world. That is, variables are the "
"actual “data” that we end up with in our data sets."
msgstr ""
"**En variabel**. Endelig et nytt begrep. En variabel er det vi ender opp med "
"når vi bruker målet vårt på noe i verden. Det vil si at variabler er de "
"faktiske «dataene» som vi ender opp med i datasettene våre."

#: ../../Ch02/Ch02_StudyDesign_1.rst:166
msgid ""
"In practice, even scientists tend to blur the distinction between these "
"things, but it’s very helpful to try to understand the differences."
msgstr ""
"I praksis har selv forskere en tendens til å viske ut skillet mellom disse "
"tingene, men det er veldig nyttig å prøve å forstå forskjellene."

#: ../../Ch02/Ch02_StudyDesign_2.rst:4
msgid "Scales of measurement and types of variables"
msgstr "Målenivåer og variabletyper"

#: ../../Ch02/Ch02_StudyDesign_2.rst:6
msgid ""
"As the previous section indicates, the outcome of a psychological "
"measurement is called a variable. But not all variables are of the same "
"qualitative type and so it’s useful to understand what types there are. A "
"very useful concept for distinguishing between different types of variables "
"is what’s known as **scales of measurement**."
msgstr ""
"Som det fremgår av forrige avsnitt, kalles resultatet av en psykologisk "
"måling for en variabel. Men ikke alle variabler er av samme kvalitative "
"type, og det er derfor nyttig å forstå hvilke typer det finnes. Et svært "
"nyttig begrep for å skille mellom ulike typer variabler er det som kalles "
"**målenivåer**."

#: ../../Ch02/Ch02_StudyDesign_2.rst:13
msgid "Nominal scale"
msgstr "Nominell skala"

#: ../../Ch02/Ch02_StudyDesign_2.rst:15
msgid ""
"A **nominal scale** variable (also referred to as a **categorical** "
"variable) is one in which there is no particular relationship between the "
"different possibilities. For these kinds of variables it doesn’t make any "
"sense to say that one of them is “bigger’ or “better” than any other one, "
"and it absolutely doesn’t make any sense to average them. The classic "
"example for this is “eye colour”. Eyes can be blue, green or brown, amongst "
"other possibilities, but none of them is any “bigger” than any other one. As "
"a result, it would feel really weird to talk about an “average eye colour”. "
"Similarly, gender is nominal too: male isn’t better or worse than female. "
"Neither does it make sense to try to talk about an “average gender”. In "
"short, nominal scale variables are those for which the only thing you can "
"say about the different possibilities is that they are different. That’s it."
msgstr ""
"En **nominell skala**-variabel (også kalt en **kategorisk** variabel) er en "
"variabel der det ikke er noen spesiell sammenheng mellom de ulike "
"mulighetene. For denne typen variabler gir det ingen mening å si at én av "
"dem er «større» eller «bedre» enn noen annen, og det gir absolutt ingen "
"mening å beregne et gjennomsnitt av dem. Det klassiske eksempelet på dette "
"er «øyenfarge». Øynene kan være blå, grønne eller brune, blant mange andre "
"muligheter, men ingen av dem er «større» enn noen andre. Derfor ville det "
"føles veldig rart å snakke om en «gjennomsnittlig øyenfarge». På samme måte "
"er kjønn også nominelt: Mann er ikke bedre eller verre enn kvinne. Det gir "
"heller ikke mening å snakke om et «gjennomsnittskjønn». Kort sagt er "
"variabler på nominal skala variabler der det eneste du kan si om de ulike "
"mulighetene, er at de er forskjellige. Det er alt."

#: ../../Ch02/Ch02_StudyDesign_2.rst:29
msgid ""
"Let’s take a slightly closer look at this. Suppose I was doing research on "
"how people commute to and from work. One variable I would have to measure "
"would be what kind of transportation people use to get to work. This "
"“transport type” variable could have quite a few possible values, including: "
"“train”, “bus”, “car”, “bicycle”. For now, let’s suppose that these four are "
"the only possibilities. Then imagine that I ask 100 people how they got to "
"work today, with this result:"
msgstr ""
"La oss se litt nærmere på dette. Anta at jeg skulle forske på hvordan folk "
"pendler til og fra jobb. En variabel jeg må måle, er hva slags "
"transportmiddel folk bruker for å komme seg til og fra jobb. Denne "
"«transporttype»-variabelen kan ha ganske mange mulige verdier, f.eks: «tog», "
"«buss», «bil», «sykkel». La oss foreløpig anta at disse fire er de eneste "
"mulighetene. Tenk deg så at jeg spør 100 personer om hvordan de kom seg til "
"jobb i dag, og får dette resultatet:"

#: ../../Ch02/Ch02_StudyDesign_2.rst:38 ../../Ch02/Ch02_StudyDesign_2.rst:57
msgid "Transportation"
msgstr "Transport"

#: ../../Ch02/Ch02_StudyDesign_2.rst:38 ../../Ch02/Ch02_StudyDesign_2.rst:57
msgid "Number of people"
msgstr "Antall personer"

#: ../../Ch02/Ch02_StudyDesign_2.rst:40 ../../Ch02/Ch02_StudyDesign_2.rst:61
msgid "Train"
msgstr "Tog"

#: ../../Ch02/Ch02_StudyDesign_2.rst:40 ../../Ch02/Ch02_StudyDesign_2.rst:61
msgid "12"
msgstr "12"

#: ../../Ch02/Ch02_StudyDesign_2.rst:42 ../../Ch02/Ch02_StudyDesign_2.rst:65
msgid "Bus"
msgstr "Buss"

#: ../../Ch02/Ch02_StudyDesign_2.rst:42 ../../Ch02/Ch02_StudyDesign_2.rst:65
msgid "30"
msgstr "30"

#: ../../Ch02/Ch02_StudyDesign_2.rst:44 ../../Ch02/Ch02_StudyDesign_2.rst:59
msgid "Car"
msgstr "Bil"

#: ../../Ch02/Ch02_StudyDesign_2.rst:44 ../../Ch02/Ch02_StudyDesign_2.rst:59
msgid "48"
msgstr "48"

#: ../../Ch02/Ch02_StudyDesign_2.rst:46 ../../Ch02/Ch02_StudyDesign_2.rst:63
msgid "Bicycle"
msgstr "Sykkel"

#: ../../Ch02/Ch02_StudyDesign_2.rst:46 ../../Ch02/Ch02_StudyDesign_2.rst:63
#: ../../Ch02/Ch02_StudyDesign_2.rst:119
msgid "10"
msgstr "10"

#: ../../Ch02/Ch02_StudyDesign_2.rst:49
msgid ""
"So, what’s the average transportation type? Obviously, the answer here is "
"that there isn’t one. It’s a silly question to ask. You can say that travel "
"by car is the most popular method, and travel by train is the least popular "
"method, but that’s about all. Similarly, notice that the order in which I "
"list the options isn’t very interesting. I could have chosen to display the "
"data like this…"
msgstr ""
"Så hva er den gjennomsnittlige transporttypen? Svaret her er selvsagt at det "
"ikke finnes noen. Det er et dumt spørsmål å stille. Du kan si at bil er den "
"mest populære reisemåten, og at tog er den minst populære, men det er alt. "
"Legg også merke til at rekkefølgen jeg lister opp alternativene i, ikke er "
"særlig interessant. Jeg kunne ha valgt å vise dataene slik…"

#: ../../Ch02/Ch02_StudyDesign_2.rst:68
msgid "…and nothing really changes."
msgstr "…og ingenting forandrer seg egentlig."

#: ../../Ch02/Ch02_StudyDesign_2.rst:71
msgid "Ordinal scale"
msgstr "Ordinal skala"

#: ../../Ch02/Ch02_StudyDesign_2.rst:73
msgid ""
"**Ordinal scale** variables have a bit more structure than nominal scale "
"variables, but not by a lot. An ordinal scale variable is one in which there "
"is a natural, meaningful way to order the different possibilities, but you "
"can’t do anything else. The usual example given of an ordinal variable is "
"“finishing position in a race”. You *can* say that the person who finished "
"first was faster than the person who finished second, but you *don’t* know "
"how much faster. As a consequence we know that 1st > 2nd, and we know that "
"2nd > 3rd, but the difference between 1st and 2nd might be much larger than "
"the difference between 2nd and 3rd."
msgstr ""
"**Ordinalskalavariabler** har litt mer struktur enn nominalskalavariabler, "
"men ikke mye. En ordinalvariabel er en variabel der det finnes en naturlig "
"og meningsfull måte å ordne de ulike mulighetene på, men du kan ikke gjøre "
"noe annet. Det vanligste eksemplet på en ordinalvariabel er «plassering i et "
"løp». Du *kan* si at personen som kom først i mål var raskere enn personen "
"som kom på andreplass, men du vet *ikke* hvor mye raskere. Derfor vet vi at "
"1. > 2., og vi vet at 2. > 3., men forskjellen mellom 1. og 2. kan være mye "
"større enn forskjellen mellom 2. og 3."

#: ../../Ch02/Ch02_StudyDesign_2.rst:83
msgid ""
"Here’s a more psychologically interesting example. Suppose I’m interested in "
"people’s attitudes to climate change. I then go and ask some people to pick "
"the statement (from four listed statements) that most closely matches their "
"beliefs:"
msgstr ""
"Her er et mer psykologisk interessant eksempel. Anta at jeg er interessert i "
"folks holdninger til klimaendringer. Jeg ber noen personer om å velge det "
"utsagnet (blant fire opplistede utsagn) som stemmer best overens med deres "
"holdninger:"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(1\\) Temperatures are rising because of human activity"
msgstr "\\(1\\) Temperaturen stiger på grunn av menneskelig aktivitet"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(2\\) Temperatures are rising but we don’t know why"
msgstr "\\(2\\) Temperaturene stiger, men vi vet ikke hvorfor"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(3\\) Temperatures are rising but not because of humans"
msgstr "\\(3\\) Temperaturen stiger, men ikke på grunn av mennesker"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(4\\) Temperatures are not rising"
msgstr "\\(4\\) Temperaturene stiger ikke"

#: ../../Ch02/Ch02_StudyDesign_2.rst:93
msgid ""
"Notice that these four statements actually do have a natural ordering, in "
"terms of “the extent to which they agree with the current science”. "
"Statement 1 is a close match, statement 2 is a reasonable match, statement 3 "
"isn’t a very good match, and statement 4 is in strong opposition to current "
"science. So, in terms of the thing I’m interested in (the extent to which "
"people endorse the science), I can order the items as 1 > 2 > 3 > 4. Since "
"this ordering exists, it would be very weird to list the options like this…"
msgstr ""
"Legg merke til at disse fire utsagnene faktisk har en naturlig rekkefølge, i "
"form av «i hvilken grad de stemmer overens med dagens vitenskap». Utsagn 1 "
"stemmer godt overens, utsagn 2 stemmer rimelig godt overens, utsagn 3 "
"stemmer ikke så godt overens, og utsagn 4 er i sterk opposisjon til dagens "
"vitenskap. Når det gjelder det jeg er interessert i (i hvilken grad folk "
"støtter vitenskapen), kan jeg ordne påstandene som 1 > 2 > 3 > 4. Siden "
"denne rekkefølgen eksisterer, ville det vært veldig rart å liste opp "
"alternativene slik…"

#: ../../Ch02/Ch02_StudyDesign_2.rst:107
msgid "…because it seems to violate the natural “structure” to the question."
msgstr "…fordi det bryter med den naturlige «strukturen» i spørsmålet."

#: ../../Ch02/Ch02_StudyDesign_2.rst:109
msgid ""
"So, let’s suppose I asked 100 people these questions, and got the following "
"answers:"
msgstr ""
"Så la oss si at jeg stilte 100 personer disse spørsmålene, og fikk følgende "
"svar:"

#: ../../Ch02/Ch02_StudyDesign_2.rst:113
msgid "Response"
msgstr "Svar"

#: ../../Ch02/Ch02_StudyDesign_2.rst:113
msgid "Number"
msgstr "Antall"

#: ../../Ch02/Ch02_StudyDesign_2.rst:115
msgid "Temperatures are rising because of human activity (1)"
msgstr "Temperaturene stiger på grunn av menneskelig aktivitet (1)"

#: ../../Ch02/Ch02_StudyDesign_2.rst:115
msgid "51"
msgstr "51"

#: ../../Ch02/Ch02_StudyDesign_2.rst:117
msgid "Temperatures are rising but we don’t know why (2)"
msgstr "Temperaturene stiger, men vi vet ikke hvorfor (2)"

#: ../../Ch02/Ch02_StudyDesign_2.rst:117
msgid "20"
msgstr "20"

#: ../../Ch02/Ch02_StudyDesign_2.rst:119
msgid "Temperatures are rising but not because of humans (3)"
msgstr "Temperaturene stiger, men ikke på grunn av mennesker (3)"

#: ../../Ch02/Ch02_StudyDesign_2.rst:121
msgid "Temperatures are not rising (4)"
msgstr "Temperaturene stiger ikke (4)"

#: ../../Ch02/Ch02_StudyDesign_2.rst:121
msgid "19"
msgstr "19"

#: ../../Ch02/Ch02_StudyDesign_2.rst:124
msgid ""
"When analysing these data it seems quite reasonable to try to group (1), "
"\\(2) and (3) together, and say that 81 out of 100 people were willing to "
"*at least partially* endorse the science. And it’s *also* quite reasonable "
"to group (2), (3) and (4) together and say that 49 out of 100 people "
"registered *at least some disagreement* with the dominant scientific view. "
"However, it would be entirely bizarre to try to group (1), (2) and (4) "
"together and say that 90 out of 100 people said… what? There’s nothing "
"sensible that allows you to group those responses together at all."
msgstr ""
"Når man analyserer disse dataene, virker det ganske rimelig å forsøke å slå "
"sammen (1), \\(2) og (3), og si at 81 av 100 personer var villige til å *i "
"det minste delvis* slutte seg til vitenskapen. Og det er *også* ganske "
"rimelig å slå sammen (2), (3) og (4) og si at 49 av 100 personer registrerte "
"*i det minste en viss uenighet* med den dominerende vitenskapelige "
"oppfatningen. Det ville imidlertid være helt bisart å prøve å slå sammen "
"(1), (2) og (4) og si at 90 av 100 personer sa… hva? Det er ingenting "
"fornuftig som gjør at du i det hele tatt kan gruppere disse svarene sammen."

#: ../../Ch02/Ch02_StudyDesign_2.rst:134
msgid ""
"That said, notice that while we *can* use the natural ordering of these "
"items to construct sensible groupings, what we *can’t* do is average them. "
"For instance, in my simple example here, the “average” response to the "
"question is 1.97. If you can tell me what that means I’d love to know, "
"because it seems like gibberish to me!"
msgstr ""
"Når det er sagt, må du legge merke til at selv om vi *kan* bruke den "
"naturlige rekkefølgen av disse elementene til å lage fornuftige "
"grupperinger, kan vi *ikke* lage et gjennomsnitt av dem. I mitt enkle "
"eksempel her er for eksempel det «gjennomsnittlige» svaret på spørsmålet "
"1,97. Hvis du kan fortelle meg hva det betyr, vil jeg gjerne vite det, for "
"det virker som volapyk for meg!"

#: ../../Ch02/Ch02_StudyDesign_2.rst:141
msgid "Interval scale"
msgstr "Intervallskala"

#: ../../Ch02/Ch02_StudyDesign_2.rst:143
msgid ""
"In contrast to nominal and ordinal scale variables, **interval scale** and "
"ratio scale variables are variables for which the numerical value is "
"genuinely meaningful. In the case of interval scale variables the "
"*differences* between the numbers are interpretable, but the variable "
"doesn’t have a “natural” zero value. A good example of an interval scale "
"variable is measuring temperature in degrees celsius. For instance, if it "
"was 15° yesterday and 18° today, then the 3° difference between the two is "
"genuinely meaningful. Moreover, that 3° difference is *exactly the same* as "
"the 3° difference between 7° and 10°. In short, addition and subtraction are "
"meaningful for interval scale variables.\\ [#]_"
msgstr ""
"I motsetning til nominal- og ordinalskalavariabler er **intervallskala**- og "
"forholdstallsvariabler variabler der tallverdien er genuint meningsfull. Ved "
"intervallskalavariabler er *forskjellene* mellom tallene tolkbare, men "
"variabelen har ikke en «naturlig» nullverdi. Et godt eksempel på en "
"intervallvariabel er måling av temperatur i grader celsius. Hvis det for "
"eksempel var 15° i går og 18° i dag, er forskjellen på 3° mellom de to "
"virkelig meningsfull. Dessuten er denne forskjellen på 3° *nøyaktig den "
"samme* som forskjellen på 3° mellom 7° og 10°. Kort sagt, addisjon og "
"subtraksjon er meningsfylt for variabler på intervallskala.\\ [#]_"

#: ../../Ch02/Ch02_StudyDesign_2.rst:154
msgid ""
"However, notice that the 0° does not mean “no temperature at all”. It "
"actually means “the temperature at which water freezes”, which is pretty "
"arbitrary. As a consequence it becomes pointless to try to multiply and "
"divide temperatures. It is wrong to say that 20° is *twice as hot* as 10°, "
"just as it is weird and meaningless to try to claim that 20° is negative two "
"times as hot as -10°."
msgstr ""
"Legg imidlertid merke til at 0° ikke betyr «ingen temperatur i det hele "
"tatt». Det betyr faktisk «temperaturen der vann fryser», noe som er ganske "
"vilkårlig. Derfor blir det meningsløst å forsøke å multiplisere og dividere "
"temperaturer. Det er feil å si at 20° er *dobbelt så varmt* som 10°, på "
"samme måte som det er rart og meningsløst å hevde at 20° er negativt to "
"ganger så varmt som -10°."

#: ../../Ch02/Ch02_StudyDesign_2.rst:160
msgid ""
"Again, lets look at a more psychological example. Suppose I’m interested in "
"looking at how the attitudes of first-year university students have changed "
"over time. Obviously, I’m going to want to record the year in which each "
"student started. This is an interval scale variable. A student who started "
"in 2003 did arrive 5 years before a student who started in 2008. However, it "
"would be completely daft for me to divide 2008 by 2003 and say that the "
"second student started “1.0024 times later” than the first one. That doesn’t "
"make any sense at all."
msgstr ""
"La oss igjen se på et mer psykologisk eksempel. Anta at jeg er interessert i "
"å se på hvordan holdningene til førsteårsstudenter på universitetet har "
"endret seg over tid. Jeg vil selvsagt registrere hvilket år hver enkelt "
"student begynte. Dette er en variabel på intervallskala. En student som "
"begynte i 2003, kom fem år før en student som begynte i 2008. Det ville "
"imidlertid være helt idiotisk for meg å dividere 2008 med 2003 og si at den "
"andre studenten startet «1,0024 ganger senere» enn den første. Det gir ingen "
"mening i det hele tatt."

#: ../../Ch02/Ch02_StudyDesign_2.rst:170
msgid "Ratio scale"
msgstr "Forholdstallskala"

#: ../../Ch02/Ch02_StudyDesign_2.rst:172
msgid ""
"The fourth and final type of variable to consider is a **ratio scale** "
"variable, in which zero really means zero, and it’s okay to multiply and "
"divide. A good psychological example of a ratio scale variable is response "
"time (RT). In a lot of tasks it’s very common to record the amount of time "
"somebody takes to solve a problem or answer a question, because it’s an "
"indicator of how difficult the task is. Suppose that Alan takes 2.3 seconds "
"to respond to a question, whereas Ben takes 3.1 seconds. As with an interval "
"scale variable, addition and subtraction are both meaningful here. Ben "
"really did take 3.1 - 2.3 = 0.8 seconds longer than Alan did. However, "
"notice that multiplication and division also make sense here too: Ben took "
"3.1 / 2.3 = 1.35 times as long as Alan did to answer the question. And the "
"reason why you can do this is that for a ratio scale variable such as RT "
"“zero seconds” really does mean “no time at all”."
msgstr ""
"Den fjerde og siste typen variabel vi bør vurdere, er en "
"**forholdstallvariabel**, der null virkelig betyr null, og der det er greit "
"å multiplisere og dividere. Et godt psykologisk eksempel på en "
"forholdstallsvariabel er responstid (RT). I mange oppgaver er det veldig "
"vanlig å registrere hvor lang tid noen bruker på å løse et problem eller "
"svare på et spørsmål, fordi det er en indikator på hvor vanskelig oppgaven "
"er. Anta at Alan bruker 2,3 sekunder på å svare på et spørsmål, mens Ben "
"bruker 3,1 sekunder. Som med en intervallvariabel er både addisjon og "
"subtraksjon meningsfullt her. Ben brukte i virkeligheten 3,1 - 2,3 = 0,8 "
"sekunder lenger enn Alan. Legg imidlertid merke til at multiplikasjon og "
"divisjon også gir mening her: Ben brukte 3,1 / 2,3 = 1,35 ganger så lang tid "
"som Alan på å svare på spørsmålet. Og grunnen til at du kan gjøre dette, er "
"at for en forholdstallsvariabel som RT betyr «null sekunder» faktisk «ingen "
"tid i det hele tatt»."

#: ../../Ch02/Ch02_StudyDesign_2.rst:188
msgid "Continuous versus discrete variables"
msgstr "Kontinuerlige versus diskrete variabler"

#: ../../Ch02/Ch02_StudyDesign_2.rst:190
msgid ""
"There’s a second kind of distinction that you need to be aware of, regarding "
"what types of variables you can run into. This is the distinction between "
"continuous variables and discrete variables. The difference between these is "
"as follows:"
msgstr ""
"Det er en annen type distinksjon du må være klar over når det gjelder hvilke "
"typer variabler du kan støte på. Dette er skillet mellom kontinuerlige "
"variabler og diskrete variabler. Forskjellen mellom disse er som følger:"

#: ../../Ch02/Ch02_StudyDesign_2.rst:195
msgid ""
"A **continuous variable** is one in which, for any two values that you can "
"think of, it’s always logically possible to have another value in between."
msgstr ""
"En **kontinuerlig variabel** er en variabel der det alltid er logisk mulig å "
"finne en annen verdi mellom to verdier."

#: ../../Ch02/Ch02_StudyDesign_2.rst:199
msgid ""
"A **discrete variable** is, in effect, a variable that isn’t continuous. For "
"a discrete variable it’s sometimes the case that there’s nothing in the "
"middle."
msgstr ""
"En **diskret variabel** er i realiteten en variabel som ikke er "
"kontinuerlig. For en diskret variabel er det noen ganger slik at det ikke "
"finnes noe i midten."

#: ../../Ch02/Ch02_StudyDesign_2.rst:203
msgid ""
"These definitions probably seem a bit abstract, but they’re pretty simple "
"once you see some examples. For instance, response time is continuous. If "
"Alan takes 3.1 seconds and Ben takes 2.3 seconds to respond to a question, "
"then Cameron’s response time will lie in between if he took 3.0 seconds. And "
"of course it would also be possible for David to take 3.031 seconds to "
"respond, meaning that his RT would lie in between Cameron’s and Alan’s. And "
"while in practice it might be impossible to measure RT that precisely, it’s "
"certainly possible in principle. Because we can always find a new value for "
"RT in between any two other ones we regard RT as a continuous measure."
msgstr ""
"Disse definisjonene virker kanskje litt abstrakte, men de er ganske enkle "
"når du ser noen eksempler. For eksempel er responstiden kontinuerlig. Hvis "
"Alan bruker 3,1 sekunder og Ben 2,3 sekunder på å svare på et spørsmål, vil "
"Camerons svartid ligge midt imellom hvis han brukte 3,0 sekunder. Og det er "
"selvsagt også mulig for David å bruke 3,031 sekunder på å svare, noe som "
"betyr at hans RT vil ligge mellom Camerons og Alans. Og selv om det i "
"praksis kan være umulig å måle RT så nøyaktig, er det absolutt mulig i "
"prinsippet. Fordi vi alltid kan finne en ny verdi for RT mellom to andre "
"verdier, anser vi RT som et kontinuerlig mål."

#: ../../Ch02/Ch02_StudyDesign_2.rst:214
msgid ""
"Discrete variables occur when this rule is violated. For example, nominal "
"scale variables are always discrete. There isn’t a type of transportation "
"that falls “in between” trains and bicycles, not in the strict mathematical "
"way that 2.3 falls in between 2 and 3. So transportation type is discrete. "
"Similarly, ordinal scale variables are always discrete. Although “2nd place” "
"does fall between “1st place” and “3rd place”, there’s nothing that can "
"logically fall in between “1st place” and “2nd place”. Interval scale and "
"ratio scale variables can go either way. As we saw above, response time (a "
"ratio scale variable) is continuous. Temperature in degrees celsius (an "
"interval scale variable) is also continuous. However, the year you went to "
"school (an interval scale variable) is discrete. There’s no year in between "
"2002 and 2003. The number of questions you get right on a true-or-false test "
"(a ratio scale variable) is also discrete. Since a true-or-false question "
"doesn’t allow you to be “partially correct”, there’s nothing in between 5/10 "
"and 6/10. The relationship between the scales of measurement and the "
"discrete / continuity distinction is summarized in :numref:`tab-scl`. Cells "
"with a tick mark correspond to things that are possible. I’m trying to "
"hammer this point home, because (a) some textbooks get this wrong, and (b) "
"people very often say things like “discrete variable” when they mean "
"“nominal scale variable”. It’s very unfortunate."
msgstr ""
"Diskrete variabler oppstår når denne regelen brytes. For eksempel er "
"variabler på nominalskala alltid diskrete. Det finnes ikke en type "
"transportmiddel som faller «mellom» tog og sykkel, ikke på den strenge "
"matematiske måten som 2,3 faller mellom 2 og 3. Transportmiddeltypen er "
"altså diskret. På samme måte er variabler på ordinalskala alltid diskrete. "
"Selv om «2. plass» faller mellom «1. plass» og «3. plass», er det ingenting "
"som logisk sett kan falle mellom «1. plass» og «2. plass». Variabler på "
"intervallskala og forholdstallskala kan gå begge veier. Som vi så ovenfor, "
"er responstid (en forholdstallvariabel) kontinuerlig. Temperatur i grader "
"celsius (en intervallvariabel) er også kontinuerlig. Året du gikk på skolen "
"(en intervallvariabel), er derimot diskret. Det finnes ikke noe år mellom "
"2002 og 2003. Antall spørsmål du svarer riktig på en sant-eller-falskt-test "
"(en forholdstallvariabel), er også diskret. Siden det ikke er mulig å svare "
"«delvis riktig» på et sant-eller-falskt-spørsmål, er det ikke noe mellom "
"5/10 og 6/10. Forholdet mellom målenivåene og skillet mellom diskret og "
"kontinuitet er oppsummert i :numref:`tab-scl`. Celler med en hake tilsvarer "
"ting som er mulige. Jeg prøver å hamre dette poenget inn, fordi (a) noen "
"lærebøker tar feil, og (b) folk ofte sier ting som «diskret variabel» når de "
"mener «nominalskala-variabel». Det er veldig uheldig."

#: ../../Ch02/Ch02_StudyDesign_2.rst:235
msgid ""
"The relationship between the scales of measurement and the discrete / "
"continuity distinction. Cells with a tick mark correspond to things that are "
"possible."
msgstr ""
"Forholdet mellom målenivåene og skillet mellom diskresjon og kontinuitet. "
"Celler med en hake tilsvarer ting som er mulige."

#: ../../Ch02/Ch02_StudyDesign_2.rst:241
msgid "continuous"
msgstr "continuous"

#: ../../Ch02/Ch02_StudyDesign_2.rst:241
msgid "discrete"
msgstr "diskrete"

#: ../../Ch02/Ch02_StudyDesign_2.rst:243
msgid "**nominal**"
msgstr "**nominal**"

#: ../../Ch02/Ch02_StudyDesign_2.rst:243 ../../Ch02/Ch02_StudyDesign_2.rst:245
#: ../../Ch02/Ch02_StudyDesign_2.rst:247 ../../Ch02/Ch02_StudyDesign_2.rst:249
msgid "✓"
msgstr "✓"

#: ../../Ch02/Ch02_StudyDesign_2.rst:245
msgid "**ordinal**"
msgstr "**ordinal**"

#: ../../Ch02/Ch02_StudyDesign_2.rst:247
msgid "**interval**"
msgstr "**intervall**"

#: ../../Ch02/Ch02_StudyDesign_2.rst:249
msgid "**ratio**"
msgstr "**forhold**"

#: ../../Ch02/Ch02_StudyDesign_2.rst:254
msgid "Some complexities"
msgstr "Noen kompleksiteter"

#: ../../Ch02/Ch02_StudyDesign_2.rst:256
msgid ""
"Okay, I know you’re going to be shocked to hear this, but the real world is "
"much messier than this little classification scheme suggests. Very few "
"variables in real life actually fall into these nice neat categories, so you "
"need to be kind of careful not to treat the scales of measurement as if they "
"were hard and fast rules. It doesn’t work like that. They’re guidelines, "
"intended to help you think about the situations in which you should treat "
"different variables differently. Nothing more."
msgstr ""
"Ok, jeg vet at du kommer til å bli sjokkert over å høre dette, men den "
"virkelige verden er mye mer rotete enn dette lille klassifiseringsskjemaet "
"antyder. Svært få variabler i det virkelige liv faller faktisk inn i disse "
"fine, sirlige kategoriene, så du må være forsiktig med å behandle "
"målenivåene som om de var harde og faste regler. Det fungerer ikke slik. De "
"er retningslinjer som skal hjelpe deg å tenke gjennom i hvilke situasjoner "
"du bør behandle ulike variabler forskjellig. Ikke noe mer enn det."

#: ../../Ch02/Ch02_StudyDesign_2.rst:265
msgid ""
"So let’s take a classic example, maybe *the* classic example, of a "
"psychological measurement tool: the **Likert scale**. The humble Likert "
"scale is the bread and butter tool of all survey design. You yourself have "
"filled out hundreds, maybe thousands, of them and odds are you’ve even used "
"one yourself. Suppose we have a survey question that looks like this:"
msgstr ""
"La oss ta et klassisk eksempel, kanskje *det* klassiske eksempelet på et "
"psykologisk måleverktøy: **Likert-skalaen**. Den ydmyke Likert-skalaen er "
"det viktigste verktøyet i all utforming av spørreundersøkelser. Du har selv "
"fylt ut hundrevis, kanskje tusenvis, av dem, og det er stor sjanse for at du "
"til og med har brukt en selv. Anta at vi har et spørsmål i en undersøkelse "
"som ser slik ut:"

#: ../../Ch02/Ch02_StudyDesign_2.rst:272
msgid ""
"Which of the following best describes your opinion of the statement that "
"“all pirates are freaking awesome”?"
msgstr ""
"Hvilket av følgende utsagn beskriver best hva du mener om påstanden om at "
"«alle pirater er freaking awesome»?"

#: ../../Ch02/Ch02_StudyDesign_2.rst:275
msgid "and then the options presented to the participant are these:"
msgstr "og deretter får deltakeren følgende alternativer:"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(1\\) Strongly disagree"
msgstr "\\(1\\) Helt uenig"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(2\\) Disagree"
msgstr "\\(2\\) Uenig"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(3\\) Neither agree nor disagree"
msgstr "\\(3\\) Verken enig eller uenig"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(4\\) Agree"
msgstr "\\(4\\) Enig"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(5\\) Strongly agree"
msgstr "\\(5\\) Helt enig"

#: ../../Ch02/Ch02_StudyDesign_2.rst:283
msgid ""
"This set of items is an example of a 5-point Likert scale, in which people "
"are asked to choose among one of several (in this case 5) clearly ordered "
"possibilities, generally with a verbal descriptor given in each case. "
"However, it’s not necessary that all items are explicitly described. This is "
"a perfectly good example of a 5-point Likert scale too:"
msgstr ""
"Dette settet med spørsmål er et eksempel på en 5-punkts Likert-skala, der "
"folk blir bedt om å velge mellom en av flere (i dette tilfellet 5) klart "
"ordnede muligheter, vanligvis med en verbal beskrivelse i hvert tilfelle. "
"Det er imidlertid ikke nødvendig at alle elementene er eksplisitt beskrevet. "
"Dette er også et godt eksempel på en 5-punkts Likert-skala:"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(2\\)"
msgstr "\\(2\\)"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(3\\)"
msgstr "\\(3\\)"

#: ../../Ch02/Ch02_StudyDesign_2.rst:0
msgid "\\(4\\)"
msgstr "\\(4\\)"

#: ../../Ch02/Ch02_StudyDesign_2.rst:296
msgid ""
"Likert scales are very handy, if somewhat limited, tools. The question is "
"what kind of variable are they? They’re obviously discrete, since you can’t "
"give a response of 2.5. They’re obviously not nominal scale, since the items "
"are ordered; and they’re not ratio scale either, since there’s no natural "
"zero."
msgstr ""
"Likert-skalaer er svært praktiske, om enn noe begrensede, verktøy. "
"Spørsmålet er hva slags variabler de er. De er åpenbart diskrete, siden du "
"ikke kan gi et svar på 2,5. De er åpenbart ikke nominalskalaer, siden "
"svaralternativene er ordnet, og de er heller ikke forholdstallsskalaer, "
"siden det ikke finnes noen naturlig null."

#: ../../Ch02/Ch02_StudyDesign_2.rst:302
msgid ""
"But are they ordinal scale or interval scale? One argument says that we "
"can’t really prove that the difference between “strongly agree” and “agree” "
"is of the same size as the difference between “agree” and “neither agree nor "
"disagree”. In fact, in everyday life it’s pretty obvious that they’re not "
"the same at all. So this suggests that we ought to treat Likert scales as "
"ordinal variables. On the other hand, in practice most participants do seem "
"to take the whole “on a scale from 1 to 5” part fairly seriously, and they "
"tend to act as if the differences between the five response options were "
"fairly similar to one another. As a consequence, a lot of researchers treat "
"Likert scale data as interval scale.\\ [#]_ It’s not interval scale, but in "
"practice it’s close enough that we usually think of it as being **quasi-"
"interval scale**."
msgstr ""
"Men er det ordinalskala eller intervallskala? Et argument sier at vi ikke "
"kan bevise at forskjellen mellom «helt enig» og «enig» er like stor som "
"forskjellen mellom «enig» og «verken enig eller uenig». I dagliglivet er det "
"faktisk ganske åpenbart at de ikke er like store i det hele tatt. Dette "
"tyder på at vi bør behandle Likert-skalaer som ordinalvariabler. På den "
"annen side ser det i praksis ut til at de fleste deltakere tar hele «på en "
"skala fra 1 til 5»-delen ganske alvorlig, og de har en tendens til å oppføre "
"seg som om forskjellene mellom de fem svaralternativene var ganske like "
"hverandre. Som en konsekvens av dette behandler mange forskere Likert-"
"skalaer som intervallskalaer,\\ [#]_ men i praksis er det såpass nært at vi "
"vanligvis tenker på det som **kvasi-intervallskalaer**."

#: ../../Ch02/Ch02_StudyDesign_2.rst:318
msgid ""
"Actually, I’ve been informed by readers with greater physics knowledge than "
"I that temperature isn’t strictly an interval scale, in the sense that the "
"amount of energy required to heat something up by 3° depends on it’s current "
"temperature. So in the sense that physicists care about, temperature isn’t "
"actually an interval scale. But it still makes a cute example so I’m going "
"to ignore this little inconvenient truth."
msgstr ""
"Faktisk har jeg blitt informert av lesere med større fysikkunnskaper enn meg "
"om at temperatur ikke strengt tatt er en intervallskala, i den forstand at "
"energimengden som kreves for å varme opp noe med 3°, avhenger av den "
"aktuelle temperaturen. Så i den forstand som fysikere bryr seg om, er "
"temperatur faktisk ikke en intervallskala. Men det er likevel et søtt "
"eksempel, så jeg skal ignorere denne lille, ubeleilige sannheten."

#: ../../Ch02/Ch02_StudyDesign_2.rst:327
msgid "Ah, psychology… never an easy answer to anything!"
msgstr "Psykologi… aldri et enkelt svar på noe!"

#: ../../Ch02/Ch02_StudyDesign_3.rst:4
msgid "Assessing the reliability of a measurement"
msgstr "Vurdere reliabiliteten til en måling"

#: ../../Ch02/Ch02_StudyDesign_3.rst:6
msgid ""
"At this point we’ve thought a little bit about how to operationalise a "
"theoretical construct and thereby create a psychological measure. And we’ve "
"seen that by applying psychological measures we end up with variables, which "
"can come in many different types. At this point, we should start discussing "
"the obvious question: is the measurement any good? We’ll do this in terms of "
"two related ideas: *reliability* and *validity*. Put simply, the "
"**reliability** of a measure tells you how *precisely* you are measuring "
"something, whereas the validity of a measure tells you how *accurate* the "
"measure is. In this section I’ll talk about reliability; we’ll talk about "
"validity in section :doc:`Ch02_StudyDesign_5`."
msgstr ""
"Nå har vi tenkt litt på hvordan man kan operasjonalisere et teoretisk "
"konstrukt og dermed skape et psykologisk mål. Og vi har sett at ved å bruke "
"psykologiske mål ender vi opp med variabler, som kan komme i mange "
"forskjellige typer. Nå bør vi begynne å diskutere det åpenbare spørsmålet: "
"Er målingen god? Vi skal gjøre dette med utgangspunkt i to beslektede "
"begreper: *reliabilitet* og *validitet*. Enkelt sagt forteller "
"**reliabiliteten** til et mål deg hvor *presist* du måler noe, mens "
"validiteten til et mål forteller deg hvor *nøyaktig* målet er. I dette "
"avsnittet skal jeg snakke om reliabilitet, mens vi skal snakke om validitet "
"i avsnitt :doc:`Ch02_StudyDesign_5`."

#: ../../Ch02/Ch02_StudyDesign_3.rst:17
msgid ""
"Reliability is actually a very simple concept. It refers to the "
"repeatability or consistency of your measurement. The measurement of my "
"weight by means of a “bathroom scale” is very reliable. If I step on and off "
"the scales over and over again, it’ll keep giving me the same answer. "
"Measuring my intelligence by means of “asking my mum” is very unreliable. "
"Some days she tells me I’m a bit thick, and other days she tells me I’m a "
"complete idiot. Notice that this concept of reliability is different to the "
"question of whether the measurements are correct (the correctness of a "
"measurement relates to it’s validity). If I’m holding a sack of potatos when "
"I step on and off the bathroom scales the measurement will still be "
"reliable: it will always give me the same answer. However, this highly "
"reliable answer doesn’t match up to my true weight at all, therefore it’s "
"wrong. In technical terms, this is a *reliable but invalid* measurement. "
"Similarly, whilst my mum’s estimate of my intelligence is a bit unreliable, "
"she might be right. Maybe I’m just not too bright, and so while her estimate "
"of my intelligence fluctuates pretty wildly from day to day, it’s basically "
"right. That would be an *unreliable but valid* measure. Of course, if my "
"mum’s estimates are too unreliable it’s going to be very hard to figure out "
"which one of her many claims about my intelligence is actually the right "
"one. To some extent, then, a very unreliable measure tends to end up being "
"invalid for practical purposes; so much so that many people would say that "
"reliability is necessary (but not sufficient) to ensure validity."
msgstr ""
"Reliabilitet er egentlig et veldig enkelt begrep. Det refererer til "
"repeterbarheten eller konsistensen i målingen. Måling av vekten min ved "
"hjelp av en «badevekt» er svært reliabel. Hvis jeg går av og på vekten om og "
"om igjen, vil den gi meg det samme svaret. Å måle intelligensen min ved å "
"«spørre moren min» er svært lite reliabel. Noen dager sier hun at jeg er "
"litt dum, og andre dager sier hun at jeg er en komplett idiot. Legg merke "
"til at begrepet reliabilitet er noe annet enn spørsmålet om hvorvidt "
"målingene er korrekte (en målings korrekthet er knyttet til dens validitet). "
"Hvis jeg holder en sekk med potet når jeg går på og av badevekten, vil "
"målingen fortsatt være reliabel: Den vil alltid gi meg det samme svaret. Men "
"dette svært reliable svaret stemmer ikke overens med min virkelige vekt i "
"det hele tatt, og derfor er det feil. Teknisk sett er dette en *reliabel, "
"men ugyldig* måling. På samme måte kan det hende at moren min har rett i at "
"jeg er litt ureliabel når det gjelder intelligens. Kanskje er jeg bare ikke "
"så smart, og selv om hennes vurdering av intelligensen min svinger ganske "
"mye fra dag til dag, er den i utgangspunktet riktig. Det ville være et * "
"ureliabel, men gyldig* mål. Men hvis mammas estimater er for ureliabel, blir "
"det selvsagt veldig vanskelig å finne ut hvilken av hennes mange påstander "
"om min intelligens som faktisk er den riktige. Til en viss grad vil derfor "
"et svært ureliabel mål ha en tendens til å ende opp med å være ugyldig for "
"praktiske formål; så mye at mange vil si at reliabilitet er nødvendig (men "
"ikke tilstrekkelig) for å sikre validitet."

#: ../../Ch02/Ch02_StudyDesign_3.rst:42
msgid ""
"Okay, now that we’re clear on the distinction between reliability and "
"validity, let’s have a think about the different ways in which we might "
"measure reliability:"
msgstr ""
"Nå som vi har fått klarhet i skillet mellom reliabilitet og validitet, kan "
"vi se nærmere på de ulike måtene vi kan måle reliabilitet på:"

#: ../../Ch02/Ch02_StudyDesign_3.rst:46
msgid ""
"**Test-retest reliability**. This relates to consistency over time. If we "
"repeat the measurement at a later date do we get a the same answer?"
msgstr ""
"**Test-retest-reliabilitet**. Dette handler om konsistens over tid. Hvis vi "
"gjentar målingen på et senere tidspunkt, får vi da det samme svaret?"

#: ../../Ch02/Ch02_StudyDesign_3.rst:50
msgid ""
"**Inter-rater reliability**. This relates to consistency across people. If "
"someone else repeats the measurement (e.g., someone else rates my "
"intelligence) will they produce the same answer?"
msgstr ""
"**Reliabilitet mellom bedømmere**. Dette handler om konsistens på tvers av "
"personer. Hvis noen andre gjentar målingen (f.eks. hvis noen andre vurderer "
"intelligensen min), vil de komme frem til det samme svaret?"

#: ../../Ch02/Ch02_StudyDesign_3.rst:54
msgid ""
"**Parallel forms reliability**. This relates to consistency across "
"theoretically-equivalent measurements. If I use a different set of bathroom "
"scales to measure my weight does it give the same answer?"
msgstr ""
"**Parallellformsreliabilitet**. Dette dreier seg om konsistens på tvers av "
"teoretisk ekvivalente målinger. Hvis jeg bruker en annen badevekt til å måle "
"vekten min, gir den samme svar?"

#: ../../Ch02/Ch02_StudyDesign_3.rst:58
msgid ""
"**Internal consistency reliability**. If a measurement is constructed from "
"lots of different parts that perform similar functions (e.g., a personality "
"questionnaire result is added up across several questions) do the individual "
"parts tend to give similar answers. We’ll look at this particular form of "
"reliability later in the book, in section :doc:`../Ch15/"
"Ch15_FactorAnalysis_4`."
msgstr ""
"**Intern konsistens**. Hvis en måling er konstruert av mange ulike deler som "
"utfører lignende funksjoner (f.eks. et personlighetsspørsmål som er summert "
"over flere spørsmål), har de enkelte delene en tendens til å gi lignende "
"svar. Vi skal se nærmere på denne spesielle formen for reliabilitet senere i "
"boken, i avsnitt :doc:`../Ch15/Ch15_FactorAnalysis_4`."

#: ../../Ch02/Ch02_StudyDesign_3.rst:65
msgid ""
"Not all measurements need to possess all forms of reliability. For instance, "
"educational assessment can be thought of as a form of measurement. One of "
"the subjects that I teach, *Computational Cognitive Science*, has an "
"assessment structure that has a research component and an exam component "
"(plus other things). The exam component is *intended* to measure something "
"different from the research component, so the assessment as a whole has low "
"internal consistency. However, within the exam there are several questions "
"that are intended to (approximately) measure the same things, and those tend "
"to produce similar outcomes. So the exam on its own has a fairly high "
"internal consistency. Which is as it should be. You should only demand "
"reliability in those situations where you want to be measuring the same "
"thing!"
msgstr ""
"Ikke alle målinger trenger å ha alle former for reliabilitet. For eksempel "
"kan pedagogisk vurdering betraktes som en form for måling. Et av fagene jeg "
"underviser i, *Computational Cognitive Science*, har en vurderingsstruktur "
"som består av en forskningskomponent og en eksamenskomponent (pluss andre "
"ting). Eksamenskomponenten er *tiltenkt* å måle noe annet enn "
"forskningskomponenten, så vurderingen som helhet har lav intern konsistens. "
"I eksamenen er det imidlertid flere spørsmål som er ment å måle (omtrent) "
"det samme, og disse har en tendens til å gi lignende resultater. Så "
"eksamenen i seg selv har en ganske høy intern konsistens. Og det er som det "
"skal være. Du bør bare kreve reliabilitet i de situasjonene der du ønsker å "
"måle det samme!"

#: ../../Ch02/Ch02_StudyDesign_4.rst:4
msgid "The “role” of variables: predictors and outcomes"
msgstr "Variablenes «rolle»: prediktorer og utfall"

#: ../../Ch02/Ch02_StudyDesign_4.rst:6
msgid ""
"I’ve got one last piece of terminology that I need to explain to you before "
"moving away from variables. Normally, when we do some research we end up "
"with lots of different variables. Then, when we analyse our data, we usually "
"try to explain some of the variables in terms of some of the other "
"variables. It’s important to keep the two roles “thing doing the explaining” "
"and “thing being explained” distinct. So let’s be clear about this now. "
"First, we might as well get used to the idea of using mathematical symbols "
"to describe variables, since it’s going to happen over and over again. Let’s "
"denote the “to be explained” variable ``Y``, and denote the variables “doing "
"the explaining” as ``X_1``, ``X_2``, etc."
msgstr ""
"Jeg har en siste del av terminologien som jeg må forklare før jeg går videre "
"til variabler. Når vi gjør forskning, ender vi vanligvis opp med mange "
"forskjellige variabler. Når vi så analyserer dataene våre, prøver vi "
"vanligvis å forklare noen av variablene ut fra noen av de andre variablene. "
"Det er viktig å holde de to rollene «det som forklarer» og «det som blir "
"forklart» adskilt. Så la oss være tydelige på dette nå. For det første kan "
"vi like gjerne venne oss til tanken på å bruke matematiske symboler for å "
"beskrive variabler, siden det kommer til å skje om og om igjen. La oss "
"betegne variabelen «som skal forklares» med ``Y``, og betegne variablene som "
"«forklarer» med ``X_1``, ``X_2``, osv."

#: ../../Ch02/Ch02_StudyDesign_4.rst:17
msgid ""
"When we are doing an analysis we have different names for ``X`` and ``Y``, "
"since they play different roles in the analysis. The classical names for "
"these roles are **independent variable** (IV) and **dependent variable** "
"(DV). The IV is the variable that you use to do the explaining (i.e., ``X``) "
"and the DV is the variable being explained (i.e., ``Y``). The logic behind "
"these names goes like this: if there really is a relationship between ``X`` "
"and ``Y`` then we can say that ``Y`` depends on ``X``, and if we have "
"designed our study “properly” then ``X`` isn’t dependent on anything else. "
"However, I personally find those names horrible. They’re hard to remember "
"and they’re highly misleading because (a) the IV is never actually "
"“independent of everything else”, and (b) if there’s no relationship then "
"the DV doesn’t actually depend on the IV. And in fact, because I’m not the "
"only person who thinks that IV and DV are just awful names, there are a "
"number of alternatives that I find more appealing. The terms that I’ll use "
"in this book are **predictors** and **outcomes**. The idea here is that what "
"you’re trying to do is use ``X`` (the predictors) to make guesses about "
"``Y`` (the outcomes).\\ [#]_ This is summarised in :numref:`tab-ivdv`."
msgstr ""
"Når vi gjør en analyse, har vi forskjellige navn på ``X`` og ``Y``, siden de "
"spiller ulike roller i analysen. De klassiske navnene på disse rollene er "
"**uavhengig variabel** (UV) og **avhengig variabel** (AV). UV er den "
"variabelen du bruker til å forklare (dvs. ``X``), og AV er den variabelen "
"som skal forklares (dvs. ``Y``). Logikken bak disse navnene er som følger: "
"Hvis det virkelig er en sammenheng mellom ``X`` og ``Y``, kan vi si at ``Y`` "
"avhenger av ``X``, og hvis vi har designet studien vår «riktig», er ``X`` "
"ikke avhengig av noe annet. Personlig synes jeg imidlertid at disse navnene "
"er forferdelige. De er vanskelige å huske, og de er svært misvisende fordi "
"(a) UV aldri er «uavhengig av alt annet», og (b) hvis det ikke er noen "
"sammenheng, så er AV faktisk ikke avhengig av UV. Og siden jeg ikke er den "
"eneste som synes at UV og AV bare er forferdelige navn, finnes det faktisk "
"en rekke alternativer som jeg synes er mer tiltalende. I denne boken bruker "
"jeg begrepene **prediktorer** og **utfall**. Tanken her er at det du prøver "
"å gjøre, er å bruke ``X`` (prediktorene) til å gjette om ``Y`` (utfallene)."
"\\ [#]_ Dette er oppsummert i :numref:`tab-ivdv`."

#: ../../Ch02/Ch02_StudyDesign_4.rst:35
msgid ""
"The terminology used to distinguish between different roles that a variable "
"can play when analysing a data set. Note that this book will tend to avoid "
"the classical terminology in favour of the newer names."
msgstr ""
"Terminologien som brukes for å skille mellom de ulike rollene en variabel "
"kan spille når man analyserer et datasett. Merk at vi i denne boken vil "
"unngå den klassiske terminologien til fordel for nyere navn."

#: ../../Ch02/Ch02_StudyDesign_4.rst:41
msgid "role of the variable"
msgstr "variabelens rolle"

#: ../../Ch02/Ch02_StudyDesign_4.rst:41
msgid "classical name"
msgstr "klassisk navn"

#: ../../Ch02/Ch02_StudyDesign_4.rst:41
msgid "modern name"
msgstr "moderne navn"

#: ../../Ch02/Ch02_StudyDesign_4.rst:43
msgid "“to be explained”"
msgstr "«skal forklares»"

#: ../../Ch02/Ch02_StudyDesign_4.rst:43
msgid "dependent variable (DV)"
msgstr "avhengig variabel (AV)"

#: ../../Ch02/Ch02_StudyDesign_4.rst:43
msgid "outcome"
msgstr "resultat"

#: ../../Ch02/Ch02_StudyDesign_4.rst:45
msgid "“to do the explaining”"
msgstr "«for å forklare»"

#: ../../Ch02/Ch02_StudyDesign_4.rst:45
msgid "independent variable (IV)"
msgstr "uavhengig variabel (UV)"

#: ../../Ch02/Ch02_StudyDesign_4.rst:45
msgid "predictor"
msgstr "prediktor"

#: ../../Ch02/Ch02_StudyDesign_4.rst:51
msgid ""
"Annoyingly though, there’s a lot of different names used out there. I won’t "
"list all of them – there would be no point in doing that – other than to "
"note that “response variable” is sometimes used where I’ve used “outcome”. "
"Sigh. This sort of terminological confusion is very common, I’m afraid."
msgstr ""
"Irriterende nok er det imidlertid mange forskjellige navn som brukes der "
"ute. Jeg skal ikke liste opp alle sammen - det ville det ikke være noen vits "
"i å gjøre - annet enn å konstatere at «responsvariabel» noen ganger brukes "
"der jeg har brukt «utfall». Sukk. Denne typen terminologisk forvirring er "
"dessverre svært vanlig."

#: ../../Ch02/Ch02_StudyDesign_5.rst:4
msgid "Experimental and non-experimental research"
msgstr "Eksperimentell og ikke-eksperimentell forskning"

#: ../../Ch02/Ch02_StudyDesign_5.rst:6
msgid ""
"One of the big distinctions that you should be aware of is the distinction "
"between “experimental research” and “non-experimental research”. When we "
"make this distinction, what we’re really talking about is the degree of "
"control that the researcher exercises over the people and events in the "
"study."
msgstr ""
"En av de store distinksjonene du bør være klar over, er skillet mellom "
"«eksperimentell forskning» og «ikke-eksperimentell forskning». Når vi gjør "
"dette skillet, snakker vi egentlig om graden av kontroll som forskeren "
"utøver over personene og hendelsene i studien."

#: ../../Ch02/Ch02_StudyDesign_5.rst:13
msgid "Experimental research"
msgstr "Eksperimentell forskning"

#: ../../Ch02/Ch02_StudyDesign_5.rst:15
msgid ""
"The key feature of **experimental research** is that the researcher controls "
"all aspects of the study, especially what participants experience during the "
"study. In particular, the researcher manipulates or varies the predictor "
"variables (IVs) but allows the outcome variable (DV) to vary naturally. The "
"idea here is to deliberately vary the predictors (IVs) to see if they have "
"any causal effects on the outcomes. Moreover, in order to ensure that "
"there’s no possibility that something other than the predictor variables is "
"causing the outcomes, everything else is kept constant or is in some other "
"way “balanced”, to ensure that they have no effect on the results. In "
"practice, it’s almost impossible to *think* of everything else that might "
"have an influence on the outcome of an experiment, much less keep it "
"constant. The standard solution to this is **randomisation**. That is, we "
"randomly assign people to different groups, and then give each group a "
"different treatment (i.e., assign them different values of the predictor "
"variables). We’ll talk more about randomisation later, but for now it’s "
"enough to say that what randomisation does is minimise (but not eliminate) "
"the possibility that there are any systematic difference between groups."
msgstr ""
"Det viktigste kjennetegnet ved **eksperimentell forskning** er at forskeren "
"kontrollerer alle aspekter ved studien, spesielt hva deltakerne opplever i "
"løpet av studien. Forskeren manipulerer eller varierer prediktorvariablene "
"(UV), men lar utfallsvariabelen (AV) variere naturlig. Tanken her er å "
"bevisst variere prediktorene (UV-ene) for å se om de har noen kausale "
"effekter på utfallet. For å sikre at det ikke er noen mulighet for at noe "
"annet enn prediktorvariablene forårsaker resultatene, holdes alt annet "
"konstant eller «balanseres» på annen måte, for å sikre at de ikke har noen "
"effekt på resultatene. I praksis er det nesten umulig å *tenke* på alt annet "
"som kan påvirke utfallet av et eksperiment, og enda mindre å holde det "
"konstant. Standardløsningen på dette er **randomisering**. Det vil si at vi "
"tildeler folk tilfeldig til ulike grupper, og deretter gir hver gruppe ulik "
"behandling (dvs. tildeler dem ulike verdier av prediktorvariablene). Vi skal "
"snakke mer om randomisering senere, men foreløpig er det nok å si at "
"randomisering minimerer (men ikke eliminerer) muligheten for at det finnes "
"systematiske forskjeller mellom gruppene."

#: ../../Ch02/Ch02_StudyDesign_5.rst:35
msgid ""
"Let’s consider a very simple, completely unrealistic and grossly unethical "
"example. Suppose you wanted to find out if smoking causes lung cancer. One "
"way to do this would be to find people who smoke and people who don’t smoke "
"and look to see if smokers have a higher rate of lung cancer. This is *not* "
"a proper experiment, since the researcher doesn’t have a lot of control over "
"who is and isn’t a smoker. And this really matters. For instance, it might "
"be that people who choose to smoke cigarettes also tend to have poor diets, "
"or maybe they tend to work in asbestos mines, or whatever. The point here is "
"that the groups (smokers and non-smokers) actually differ on lots of things, "
"not *just* smoking. So it might be that the higher incidence of lung cancer "
"among smokers is caused by something else, and not by smoking per se. In "
"technical terms these other things (e.g. diet) are called “confounders”, and "
"we’ll talk about those in just a moment."
msgstr ""
"La oss ta et veldig enkelt, fullstendig urealistisk og grovt uetisk "
"eksempel. Anta at du ønsker å finne ut om røyking forårsaker lungekreft. En "
"måte å gjøre dette på ville være å finne personer som røyker og personer som "
"ikke røyker, og se om røykere har en høyere forekomst av lungekreft. Dette "
"er *ikke* et ordentlig eksperiment, siden forskeren ikke har særlig kontroll "
"over hvem som er røykere og ikke. Og dette er virkelig viktig. Det kan for "
"eksempel være at folk som velger å røyke sigaretter også har en tendens til "
"å ha et dårlig kosthold, eller kanskje de har en tendens til å jobbe i "
"asbestgruver, eller hva det måtte være. Poenget her er at gruppene (røykere "
"og ikke-røykere) faktisk skiller seg fra hverandre på mange områder, ikke "
"*bare* røyking. Det kan altså være at den høyere forekomsten av lungekreft "
"blant røykere skyldes noe annet, og ikke røyking i seg selv. På fagspråket "
"kalles disse andre tingene (f.eks. kosthold) for «konfunderende faktorer», "
"og vi skal snakke om dem om et øyeblikk."

#: ../../Ch02/Ch02_StudyDesign_5.rst:50
msgid ""
"In the meantime, let’s consider what a proper experiment might look like. "
"Recall that our concern was that smokers and non-smokers might differ in "
"lots of ways. The solution, as long as you have no ethics, is to *control* "
"who smokes and who doesn’t. Specifically, if we randomly divide young non-"
"smokers into two groups and force half of them to become smokers, then it’s "
"very unlikely that the groups will differ in any respect other than the fact "
"that half of them smoke. That way, if our smoking group gets cancer at a "
"higher rate than the non-smoking group, we can feel pretty confident that "
"(a) smoking does cause cancer and (b) we’re murderers."
msgstr ""
"I mellomtiden kan vi vurdere hvordan et skikkelig eksperiment kan se ut. "
"Husk at vår bekymring var at røykere og ikke-røykere kan være forskjellige "
"på mange måter. Løsningen, så lenge du ikke har noen etikk, er å "
"*kontrollere* hvem som røyker og hvem som ikke gjør det. Hvis vi deler unge "
"ikke-røykere tilfeldig inn i to grupper og tvinger halvparten av dem til å "
"bli røykere, er det svært usannsynlig at gruppene vil skille seg fra "
"hverandre på noe annet punkt enn at halvparten av dem røyker. Hvis "
"røykegruppen vår får kreft i større grad enn ikke-røykegruppen, kan vi føle "
"oss ganske sikre på at (a) røyking faktisk forårsaker kreft og (b) at vi er "
"mordere."

#: ../../Ch02/Ch02_StudyDesign_5.rst:62
msgid "Non-experimental research"
msgstr "Ikke-eksperimentell forskning"

#: ../../Ch02/Ch02_StudyDesign_5.rst:64
msgid ""
"**Non-experimental research** is a broad term that covers “any study in "
"which the researcher doesn’t have as much control as they do in an "
"experiment”. Obviously, control is something that scientists like to have, "
"but as the previous example illustrates there are lots of situations in "
"which you can’t or shouldn’t try to obtain that control. Since it’s grossly "
"unethical (and almost certainly criminal) to force people to smoke in order "
"to find out if they get cancer, this is a good example of a situation in "
"which you really shouldn’t try to obtain experimental control. But there are "
"other reasons too. Even leaving aside the ethical issues, our “smoking "
"experiment” does have a few other issues. For instance, when I suggested "
"that we “force” half of the people to become smokers, I was talking about "
"*starting* with a sample of non-smokers, and then forcing them to become "
"smokers. While this sounds like the kind of solid, evil experimental design "
"that a mad scientist would love, it might not be a very sound way of "
"investigating the effect in the real world. For instance, suppose that "
"smoking only causes lung cancer when people have poor diets, and suppose "
"also that people who normally smoke do tend to have poor diets. However, "
"since the “smokers” in our experiment aren’t “natural” smokers (i.e., we "
"forced non-smokers to become smokers, but they didn’t take on all of the "
"other normal, real life characteristics that smokers might tend to possess) "
"they probably have better diets. As such, in this silly example they "
"wouldn’t get lung cancer and our experiment will fail, because it violates "
"the structure of the “natural” world (the technical name for this is an "
"“artefactual” result)."
msgstr ""
"**Ikke-eksperimentell forskning** er et vidt begrep som dekker «enhver "
"studie der forskeren ikke har like mye kontroll som i et eksperiment». "
"Kontroll er selvsagt noe forskere liker å ha, men som det forrige eksemplet "
"illustrerer, finnes det mange situasjoner der man ikke kan eller bør prøve å "
"oppnå denne kontrollen. Siden det er grovt uetisk (og nesten helt sikkert "
"kriminelt) å tvinge folk til å røyke for å finne ut om de får kreft, er "
"dette et godt eksempel på en situasjon der man virkelig ikke bør forsøke å "
"oppnå eksperimentell kontroll. Men det finnes også andre grunner. Selv om vi "
"ser bort fra de etiske problemstillingene, har vårt «røykeeksperiment» noen "
"andre problemer. Da jeg for eksempel foreslo at vi skulle «tvinge» "
"halvparten av deltakerne til å bli røykere, snakket jeg om å *begynne* med "
"et utvalg av ikke-røykere, og så tvinge dem til å bli røykere. Selv om dette "
"høres ut som et solid, ondskapsfullt eksperimentelt design som en gal "
"vitenskapsmann ville elske, er det ikke sikkert at det er en veldig god måte "
"å undersøke effekten på i den virkelige verden. Anta for eksempel at røyking "
"bare forårsaker lungekreft når folk har et dårlig kosthold, og anta også at "
"folk som vanligvis røyker, har en tendens til å ha et dårlig kosthold. Men "
"siden «røykerne» i eksperimentet vårt ikke er «naturlige» røykere (det vil "
"si at vi tvang ikke-røykere til å bli røykere, men de tok ikke på seg alle "
"de andre normale, virkelige egenskapene som røykere har en tendens til å "
"ha), har de sannsynligvis bedre kosthold. I dette tåpelige eksemplet ville "
"de derfor ikke fått lungekreft, og eksperimentet vårt vil mislykkes, fordi "
"det bryter med strukturen i den «naturlige» verden (det tekniske navnet på "
"dette er et «artefaktisk» resultat)."

#: ../../Ch02/Ch02_StudyDesign_5.rst:90
msgid ""
"One distinction worth making between two types of non-experimental research "
"is the difference between **quasi-experimental research** and **case "
"studies**. The example I discussed earlier, in which we wanted to examine "
"incidence of lung cancer among smokers and non-smokers without trying to "
"control who smokes and who doesn’t, is a quasi-experimental design. That is, "
"it’s the same as an experiment but we don’t control the predictors (IVs). We "
"can still use statistics to analyse the results, but we have to be a lot "
"more careful and circumspect."
msgstr ""
"Et skille som er verdt å trekke mellom to typer ikke-eksperimentell "
"forskning, er forskjellen mellom **kvasi-eksperimentell forskning** og "
"**case-studier**. Eksemplet jeg diskuterte tidligere, der vi ønsket å "
"undersøke forekomsten av lungekreft blant røykere og ikke-røykere uten å "
"prøve å kontrollere hvem som røyker og hvem som ikke røyker, er et "
"kvasieksperimentelt design. Det vil si at det er det samme som et "
"eksperiment, men vi kontrollerer ikke prediktorene (UV-ene). Vi kan fortsatt "
"bruke statistikk til å analysere resultatene, men vi må være mye mer "
"forsiktige og omtenksomme."

#: ../../Ch02/Ch02_StudyDesign_5.rst:99
msgid ""
"The alternative approach, case studies, aims to provide a very detailed "
"description of one or a few instances. In general, you can’t use statistics "
"to analyse the results of case studies and it’s usually very hard to draw "
"any general conclusions about “people in general” from a few isolated "
"examples. However, case studies are very useful in some situations. Firstly, "
"there are situations where you don’t have any alternative. Neuropsychology "
"has this issue a lot. Sometimes, you just can’t find a lot of people with "
"brain damage in a specific brain area, so the only thing you can do is "
"describe those cases that you do have in as much detail and with as much "
"care as you can. However, there’s also some genuine advantages to case "
"studies. Because you don’t have as many people to study you have the ability "
"to invest lots of time and effort trying to understand the specific factors "
"at play in each case. This is a very valuable thing to do. As a consequence, "
"case studies can complement the more statistically-oriented approaches that "
"you see in experimental and quasi-experimental designs. We won’t talk much "
"about case studies in this book, but they are nevertheless very valuable "
"tools!"
msgstr ""
"Den alternative tilnærmingen, casestudier, tar sikte på å gi en svært "
"detaljert beskrivelse av ett eller noen få tilfeller. Generelt kan du ikke "
"bruke statistikk til å analysere resultatene av casestudier, og det er "
"vanligvis svært vanskelig å trekke generelle konklusjoner om «folk flest» ut "
"fra noen få isolerte eksempler. I noen situasjoner er imidlertid casestudier "
"svært nyttige. For det første er det situasjoner der man ikke har noe "
"alternativ. Nevropsykologi har ofte dette problemet. Noen ganger finner man "
"ikke mange mennesker med hjerneskade i et spesifikt hjerneområde, og da er "
"det eneste man kan gjøre å beskrive de tilfellene man har, så detaljert og "
"nøye som mulig. Men det er også noen reelle fordeler med kasusstudier. Fordi "
"du ikke har så mange personer å studere, kan du bruke mye tid og krefter på "
"å prøve å forstå de spesifikke faktorene som spiller inn i hvert enkelt "
"tilfelle. Dette er svært verdifullt. Derfor kan casestudier utfylle de mer "
"statistisk orienterte tilnærmingene som man ser i eksperimentelle og "
"kvasieksperimentelle design. Vi kommer ikke til å snakke så mye om "
"casestudier i denne boken, men de er ikke desto mindre svært verdifulle "
"verktøy!"

#: ../../Ch02/Ch02_StudyDesign_6.rst:4
msgid "Assessing the validity of a study"
msgstr "Vurdering av en studies validitet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:6
msgid ""
"More than any other thing, a scientist wants their research to be “valid”. "
"The conceptual idea behind **validity** is very simple. Can you trust the "
"results of your study? If not, the study is invalid. However, whilst it’s "
"easy to state, in practice it’s much harder to check validity than it is to "
"check reliability. And in all honesty, there’s no precise, clearly agreed "
"upon notion of what validity actually is. In fact, there are lots of "
"different kinds of validity, each of which raises it’s own issues. And not "
"all forms of validity are relevant to all studies. I’m going to talk about "
"five different types of validity:"
msgstr ""
"Mer enn noe annet ønsker en forsker at forskningen hans skal være «valid». "
"Den konseptuelle ideen bak **validitet** er veldig enkel. Kan du stole på "
"resultatene av studien din? Hvis ikke, er studien ugyldig. Men selv om det "
"er enkelt å si, er det i praksis mye vanskeligere å kontrollere validiteten "
"enn det er å kontrollere reliabiliteten. Og for å være helt ærlig finnes det "
"ingen presis og entydig oppfatning av hva validitet egentlig er. Det finnes "
"faktisk mange ulike former for validitet, og hver av dem reiser sine egne "
"problemstillinger. Og ikke alle former for validitet er relevante for alle "
"studier. Jeg skal snakke om fem ulike typer validitet:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:16 ../../Ch02/Ch02_StudyDesign_6.rst:36
msgid "Internal validity"
msgstr "Intern validitet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:18 ../../Ch02/Ch02_StudyDesign_6.rst:62
msgid "External validity"
msgstr "Ekstern validitet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:20 ../../Ch02/Ch02_StudyDesign_6.rst:125
msgid "Construct validity"
msgstr "Konstrukt- / begrepsvaliditet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:22 ../../Ch02/Ch02_StudyDesign_6.rst:147
msgid "Face validity"
msgstr "Ansiktsvaliditet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:24 ../../Ch02/Ch02_StudyDesign_6.rst:192
msgid "Ecological validity"
msgstr "Økologisk validitet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:26
msgid ""
"First, a quick guide as to what matters here. (1) Internal and external "
"validity are the most important, since they tie directly to the fundamental "
"question of whether your study really works. (2) Construct validity asks "
"whether you’re measuring what you think you are. (3) Face validity isn’t "
"terribly important except insofar as you care about “appearances”. (4) "
"Ecological validity is a special case of face validity that corresponds to a "
"kind of appearance that you might care about a lot."
msgstr ""
"Først en rask veiledning om hva som er viktig her. (1) Intern og ekstern "
"validitet er viktigst, siden de er direkte knyttet til det grunnleggende "
"spørsmålet om hvorvidt studien din virkelig fungerer. (2) Begrepsvaliditet "
"handler om hvorvidt du måler det du tror du måler. (3) Ansiktsvaliditet er "
"ikke veldig viktig, bortsett fra i den grad du bryr deg om «utseende». (4) "
"Økologisk validitet er et spesialtilfelle av ansiktsvaliditet som tilsvarer "
"en type utseende som du kanskje bryr deg mye om."

#: ../../Ch02/Ch02_StudyDesign_6.rst:38
msgid ""
"**Internal validity** refers to the extent to which you are able draw the "
"correct conclusions about the causal relationships between variables. It’s "
"called “internal” because it refers to the relationships between things "
"“inside” the study. Let’s illustrate the concept with a simple example. "
"Suppose you’re interested in finding out whether a university education "
"makes you write better. To do so, you get a group of first year students, "
"ask them to write a 1000 word essay, and count the number of spelling and "
"grammatical errors they make. Then you find some third-year students, who "
"obviously have had more of a university education than the first-years, and "
"repeat the exercise. And let’s suppose it turns out that the third-year "
"students produce fewer errors. And so you conclude that a university "
"education improves writing skills. Right? Except that the big problem with "
"this experiment is that the third-year students are older and they’ve had "
"more experience with writing things. So it’s hard to know for sure what the "
"causal relationship is. Do older people write better? Or people who have had "
"more writing experience? Or people who have had more education? Which of the "
"above is the true *cause* of the superior performance of the third-years? "
"Age? Experience? Education? You can’t tell. This is an example of a failure "
"of internal validity, because your study doesn’t properly tease apart the "
"*causal* relationships between the different variables."
msgstr ""
"**Intern validitet** refererer til i hvilken grad du er i stand til å trekke "
"riktige konklusjoner om årsakssammenhenger mellom variabler. Den kalles "
"«intern» fordi den refererer til forholdet mellom ting «inne i» studien. La "
"oss illustrere konseptet med et enkelt eksempel. Anta at du er interessert i "
"å finne ut om en universitetsutdanning gjør deg bedre til å skrive. For å "
"finne ut av det, samler du en gruppe førsteårsstudenter, ber dem skrive et "
"essay på 1000 ord og teller hvor mange stave- og grammatikkfeil de gjør. "
"Deretter finner du noen tredjeårsstudenter, som åpenbart har fått mer "
"universitetsutdanning enn førsteårsstudentene, og gjentar øvelsen. Og la oss "
"anta at det viser seg at tredjeårsstudentene produserer færre feil. Og så "
"konkluderer du med at universitetsutdanning forbedrer skriveferdighetene. "
"Eller hva? Men det store problemet med dette eksperimentet er at "
"tredjeårsstudentene er eldre og har mer erfaring med å skrive ting. Så det "
"er vanskelig å vite sikkert hva som er årsakssammenhengen. Skriver eldre "
"mennesker bedre? Eller folk som har mer skriveerfaring? Eller folk som har "
"mer utdanning? Hva av det ovennevnte er den egentlige *årsaken* til at "
"tredjeårsstudentene presterer bedre? Alder? Erfaring? Utdanning? Det kan du "
"ikke si noe om. Dette er et eksempel på sviktende intern validitet, fordi "
"studien din ikke skiller ut *årsakssammenhengene* mellom de ulike variablene "
"på en god måte."

#: ../../Ch02/Ch02_StudyDesign_6.rst:64
msgid ""
"**External validity** relates to the **generalisability** or "
"**applicability** of your findings. That is, to what extent do you expect to "
"see the same pattern of results in “real life” as you saw in your study. To "
"put it a bit more precisely, any study that you do in psychology will "
"involve a fairly specific set of questions or tasks, will occur in a "
"specific environment, and will involve participants that are drawn from a "
"particular subgroup (disappointingly often it is college students!). So, if "
"it turns out that the results don’t actually generalise or apply to people "
"and situations beyond the ones that you studied, then what you’ve got is a "
"lack of external validity."
msgstr ""
"**Ekstern validitet** dreier seg om **generaliserbarheten** eller "
"**anvendeligheten** av funnene dine. Det vil si i hvilken grad du kan "
"forvente å se det samme mønsteret av resultater i «det virkelige liv» som du "
"så i studien din. For å si det litt mer presist: Enhver studie du gjør i "
"psykologi, vil involvere et ganske spesifikt sett med spørsmål eller "
"oppgaver, vil foregå i et spesifikt miljø, og vil involvere deltakere som er "
"hentet fra en bestemt undergruppe (skuffende ofte er det collegestudenter!). "
"Så hvis det viser seg at resultatene faktisk ikke kan generaliseres eller "
"gjelde for andre mennesker og situasjoner enn dem du har studert, har du en "
"mangel på ekstern validitet."

#: ../../Ch02/Ch02_StudyDesign_6.rst:75
msgid ""
"The classic example of this issue is the fact that a very large proportion "
"of studies in psychology will use undergraduate psychology students as the "
"participants. Obviously, however, the researchers don’t care *only* about "
"psychology students. They care about people in general. Given that, a study "
"that uses only psychology students as participants always carries a risk of "
"lacking external validity. That is, if there’s something “special” about "
"psychology students that makes them different to the general population in "
"some *relevant* respect, then we may start worrying about a lack of external "
"validity."
msgstr ""
"Det klassiske eksempelet på denne problemstillingen er det faktum at en "
"svært stor andel av studiene i psykologi bruker psykologistudenter som "
"deltakere. Men forskerne bryr seg selvsagt ikke *kun* om psykologistudenter. "
"De bryr seg om mennesker generelt. En studie som kun har psykologistudenter "
"som deltakere, risikerer derfor alltid å mangle ekstern validitet. Det vil "
"si at hvis det er noe «spesielt» med psykologistudenter som gjør dem "
"annerledes enn den generelle befolkningen på et eller annet *relevant* "
"punkt, så kan vi begynne å bekymre oss for manglende ekstern validitet."

#: ../../Ch02/Ch02_StudyDesign_6.rst:85
msgid ""
"That said, it is absolutely critical to realise that a study that uses only "
"psychology students does not necessarily have a problem with external "
"validity. I’ll talk about this again later, but it’s such a common mistake "
"that I’m going to mention it here. The external validity of a study is "
"threatened by the choice of population if (a) the population from which you "
"sample your participants is very narrow (e.g., psychology students), and (b) "
"the narrow population that you sampled from is systematically different from "
"the general population *in some respect that is relevant to the "
"psychological phenomenon that you intend to study*. The italicised part is "
"the bit that lots of people forget. It is true that psychology "
"undergraduates differ from the general population in lots of ways, and so a "
"study that uses only psychology students *may* have problems with external "
"validity. However, if those differences aren’t very relevant to the "
"phenomenon that you’re studying, then there’s nothing to worry about. To "
"make this a bit more concrete here are two extreme examples:"
msgstr ""
"Når det er sagt, er det helt avgjørende å være klar over at en studie som "
"kun bruker psykologistudenter, ikke nødvendigvis har et problem med ekstern "
"validitet. Jeg kommer tilbake til dette senere, men det er en så vanlig feil "
"at jeg nevner den her. Den eksterne validiteten til en studie er truet av "
"valget av populasjon hvis (a) populasjonen du trekker deltakere fra, er "
"svært smal (f.eks. psykologistudenter), og (b) den smale populasjonen du "
"trekker deltakere fra, er systematisk forskjellig fra den generelle "
"populasjonen *på et eller annet punkt som er relevant for det psykologiske "
"fenomenet du har til hensikt å studere*. Den kursiverte delen er den delen "
"som mange glemmer. Det er sant at psykologistudenter skiller seg fra den "
"generelle befolkningen på mange måter, og en studie som kun bruker "
"psykologistudenter *kan* derfor ha problemer med ekstern validitet. Men hvis "
"disse forskjellene ikke er veldig relevante for fenomenet du studerer, er "
"det ikke noe å bekymre seg for. For å gjøre dette litt mer konkret, her er "
"to ekstreme eksempler:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:102
msgid ""
"You want to measure “attitudes of the general public towards psychotherapy”, "
"but all of your participants are psychology students. This study would "
"almost certainly have a problem with external validity."
msgstr ""
"Du ønsker å måle «allmennhetens holdninger til psykoterapi», men alle "
"deltakerne er psykologistudenter. Denne studien vil nesten helt sikkert ha "
"et problem med ekstern validitet."

#: ../../Ch02/Ch02_StudyDesign_6.rst:107
msgid ""
"You want to measure the effectiveness of a visual illusion, and your "
"participants are all psychology students. This study is unlikely to have a "
"problem with external validity"
msgstr ""
"Du ønsker å måle effektiviteten av en visuell illusjon, og deltakerne er "
"alle psykologistudenter. Det er lite sannsynlig at denne studien vil ha "
"problemer med ekstern validitet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:111
msgid ""
"Having just spent the last couple of paragraphs focusing on the choice of "
"participants, since that’s a big issue that everyone tends to worry most "
"about, it’s worth remembering that external validity is a broader concept. "
"The following are also examples of things that might pose a threat to "
"external validity, depending on what kind of study you’re doing:"
msgstr ""
"Etter å ha brukt de siste par avsnittene til å fokusere på valg av "
"deltakere, siden det er et stort spørsmål som alle pleier å bekymre seg mest "
"for, er det verdt å huske at ekstern validitet er et bredere begrep. "
"Følgende er også eksempler på ting som kan utgjøre en trussel mot den "
"eksterne validiteten, avhengig av hva slags studie du gjør:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:118
msgid ""
"People might answer a “psychology questionnaire” in a manner that doesn’t "
"reflect what they would do in real life."
msgstr ""
"Folk kan svare på et «psykologisk spørreskjema» på en måte som ikke "
"gjenspeiler hva de ville gjort i det virkelige liv."

#: ../../Ch02/Ch02_StudyDesign_6.rst:121
msgid ""
"Your lab experiment on (say) “human learning” has a different structure to "
"the learning problems people face in real life."
msgstr ""
"Laboratorieeksperimentet ditt om (la oss si) «menneskelig læring» har en "
"annen struktur enn de læringsproblemene folk møter i det virkelige liv."

#: ../../Ch02/Ch02_StudyDesign_6.rst:127
msgid ""
"**Construct validity** is basically a question of whether you’re measuring "
"what you want to be measuring. A measurement has good construct validity if "
"it is actually measuring the correct theoretical construct, and bad "
"construct validity if it doesn’t. To give a very simple (if ridiculous) "
"example, suppose I’m trying to investigate the rates with which university "
"students cheat on their exams. And the way I attempt to measure it is by "
"asking the cheating students to stand up in the lecture theatre so that I "
"can count them. When I do this with a class of 300 students 0 people claim "
"to be cheaters. So I therefore conclude that the proportion of cheaters in "
"my class is 0\\%. Clearly this is a bit ridiculous. But the point here is "
"not that this is a very deep methodological example, but rather to explain "
"what construct validity is. The problem with my measure is that while I’m "
"*trying* to measure “the proportion of people who cheat” what I’m actually "
"measuring is “the proportion of people stupid enough to own up to cheating, "
"or bloody minded enough to pretend that they do”. Obviously, these aren’t "
"the same thing! So my study has gone wrong, because my measurement has very "
"poor construct validity."
msgstr ""
"**Konstrukt- / begrepsvaliditet** handler i bunn og grunn om hvorvidt du "
"måler det du ønsker å måle. En måling har god begrepsvaliditet hvis den "
"faktisk måler det riktige teoretiske konstrukt, og dårlig begrepsvaliditet "
"hvis den ikke gjør det. For å gi et veldig enkelt (om enn latterlig) "
"eksempel: Anta at jeg prøver å undersøke hvor ofte universitetsstudenter "
"jukser på eksamen. Og måten jeg forsøker å måle det på, er ved å be "
"studentene som jukser, om å reise seg opp i forelesningssalen slik at jeg "
"kan telle dem. Når jeg gjør dette med en klasse på 300 studenter, er det 0 "
"personer som hevder at de jukser. Jeg konkluderer derfor med at andelen "
"juksemakere i klassen min er 0\\%. Det er klart at dette er litt latterlig. "
"Men poenget her er ikke at dette er et veldig dypt metodologisk eksempel, "
"men heller å forklare hva begrepsvaliditet er. Problemet med målet mitt er "
"at selv om jeg *prøver* å måle «andelen som jukser», så måler jeg egentlig "
"«andelen som er dumme nok til å innrømme at de jukser, eller dumme nok til å "
"late som om de gjør det». Dette er åpenbart ikke det samme! Studien min har "
"altså gått galt, fordi målingen min har svært dårlig begrepsvaliditet."

#: ../../Ch02/Ch02_StudyDesign_6.rst:149
msgid ""
"**Face validity** simply refers to whether or not a measure “looks like” "
"it’s doing what it’s supposed to, nothing more. If I design a test of "
"intelligence, and people look at it and they say “no, that test doesn’t "
"measure intelligence”, then the measure lacks face validity. It’s as simple "
"as that. Obviously, face validity isn’t very important from a pure "
"scientific perspective. After all, what we care about is whether or not the "
"measure *actually* does what it’s supposed to do, not whether it *looks "
"like* it does what it’s supposed to do. As a consequence, we generally don’t "
"care very much about face validity. That said, the concept of face validity "
"serves three useful pragmatic purposes:"
msgstr ""
"**Ansiktsvaliditet** (*face validity*) refererer ganske enkelt til hvorvidt "
"et mål «ser ut som om» det gjør det det er ment å gjøre, ikke noe mer. Hvis "
"jeg utformer en intelligenstest, og folk ser på den og sier «nei, den testen "
"måler ikke intelligens», så mangler testen «face validity». Så enkelt er "
"det. Fra et rent vitenskapelig perspektiv er selvsagt ikke face validity "
"særlig viktig. Det vi bryr oss om, er tross alt om målet *faktisk* gjør det "
"det er ment å gjøre, ikke om det *ser ut som om* det gjør det det er ment å "
"gjøre. Som en konsekvens av dette bryr vi oss generelt sett ikke så mye om "
"ytre validitet. Når det er sagt, tjener begrepet «face validity» tre nyttige "
"pragmatiske formål:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:160
msgid ""
"Sometimes, an experienced scientist will have a “hunch” that a particular "
"measure won’t work. While these sorts of hunches have no strict evidentiary "
"value, it’s often worth paying attention to them. Because often times people "
"have knowledge that they can’t quite verbalise, so there might be something "
"to worry about even if you can’t quite say why. In other words, when someone "
"you trust criticises the face validity of your study, it’s worth taking the "
"time to think more carefully about your design to see if you can think of "
"reasons why it might go awry. Mind you, if you don’t find any reason for "
"concern, then you should probably not worry. After all, face validity really "
"doesn’t matter very much."
msgstr ""
"Noen ganger vil en erfaren forsker ha en «magefølelse» om at et bestemt "
"tiltak ikke vil fungere. Selv om slike fornemmelser ikke har noen streng "
"bevisverdi, er det ofte verdt å være oppmerksom på dem. For ofte har folk "
"kunnskap som de ikke helt kan sette ord på, så det kan være noe å bekymre "
"seg for, selv om du ikke helt kan si hvorfor. Med andre ord, når noen du "
"stoler på, kritiserer studiens ytre validitet, er det verdt å ta seg tid til "
"å tenke nøyere gjennom designet ditt for å se om du kan komme på grunner til "
"at det kan gå galt. Men hvis du ikke finner noen grunn til bekymring, bør du "
"sannsynligvis ikke bekymre deg. Tross alt betyr ikke ansiktsgyldighet så mye."

#: ../../Ch02/Ch02_StudyDesign_6.rst:172
msgid ""
"Often (very often), completely uninformed people will also have a “hunch” "
"that your research is crap. And they’ll criticise it on the internet or "
"something. On close inspection you may notice that these criticisms are "
"actually focused entirely on how the study “looks”, but not on anything "
"deeper. The concept of face validity is useful for gently explaining to "
"people that they need to substantiate their arguments further."
msgstr ""
"Ofte (veldig ofte) vil også helt uinformerte mennesker ha en «magefølelse» "
"om at forskningen din er dritt. Og så kritiserer de den på internett eller "
"lignende. Ved nærmere ettersyn vil du kanskje legge merke til at denne "
"kritikken faktisk utelukkende dreier seg om hvordan studien «ser ut», og "
"ikke om noe dypere. Begrepet «face validity» er nyttig for å forsiktig "
"forklare folk at de må underbygge argumentene sine ytterligere."

#: ../../Ch02/Ch02_StudyDesign_6.rst:180
msgid ""
"Expanding on the last point, if the beliefs of untrained people are critical "
"(e.g., this is often the case for applied research where you actually want "
"to convince policy makers of something or other) then you *have* to care "
"about face validity. Simply because, whether you like it or not, a lot of "
"people will use face validity as a proxy for real validity. If you want the "
"government to change a law on scientific psychological grounds, then it "
"won’t matter how good your studies “really” are. If they lack face validity "
"you’ll find that politicians ignore you. Of course, it’s somewhat unfair "
"that policy often depends more on appearance than fact, but that’s how "
"things go."
msgstr ""
"For å utdype det siste poenget: Hvis ufaglærte menneskers oppfatninger er "
"avgjørende (f.eks. er dette ofte tilfellet for anvendt forskning der du "
"faktisk ønsker å overbevise beslutningstakere om et eller annet), så *må* du "
"bry deg om ansiktsgyldighet. Enten du liker det eller ikke, er det nemlig "
"mange som vil bruke ansiktsgyldighet som en stedfortreder for reell "
"gyldighet. Hvis du vil at myndighetene skal endre en lov på vitenskapelig "
"psykologisk grunnlag, så spiller det ingen rolle hvor gode studiene dine "
"«egentlig» er. Hvis de mangler «face validity», vil du oppleve at "
"politikerne ignorerer deg. Det er selvfølgelig litt urettferdig at politikk "
"ofte er mer avhengig av utseende enn fakta, men slik er det."

#: ../../Ch02/Ch02_StudyDesign_6.rst:194
msgid ""
"**Ecological validity** is a different notion of validity, which is similar "
"to external validity, but less important. The idea is that, in order to be "
"ecologically valid, the entire set up of the study should closely "
"approximate the real world scenario that is being investigated. In a sense, "
"ecological validity is a kind of face validity. It relates mostly to whether "
"the study “looks” right, but with a bit more rigour to it. To be "
"ecologically valid the study has to look right in a fairly specific way. The "
"idea behind it is the intuition that a study that is ecologically valid is "
"more likely to be externally valid. It’s no guarantee, of course. But the "
"nice thing about ecological validity is that it’s much easier to check "
"whether a study is ecologically valid than it is to check whether a study is "
"externally valid. A simple example would be eyewitness identification "
"studies. Most of these studies tend to be done in a university setting, "
"often with a fairly simple array of faces to look at, rather than a line up. "
"The length of time between seeing the “criminal” and being asked to identify "
"the suspect in the “line up” is usually shorter. The “crime” isn’t real so "
"there’s no chance of the witness being scared, and there are no police "
"officers present so there’s not as much chance of feeling pressured. These "
"things all mean that the study *definitely* lacks ecological validity. They "
"might (but might not) mean that it also lacks external validity."
msgstr ""
"**Økologisk validitet** er et annet validitetsbegrep, som ligner på ekstern "
"validitet, men som er mindre viktig. Tanken er at for å være økologisk valid "
"bør hele oppsettet av studien ligge tett opp til det virkelige scenarioet "
"som undersøkes. Økologisk validitet er på sett og vis en slags ytre "
"validitet. Den dreier seg mest om hvorvidt studien «ser» riktig ut, men med "
"litt mer stringens. For å være økologisk valid må studien se riktig ut på en "
"ganske spesifikk måte. Tanken bak dette er intuisjonen om at en studie som "
"er økologisk valid, har større sannsynlighet for å være eksternt valid. Det "
"er selvsagt ingen garanti. Men det fine med økologisk validitet er at det er "
"mye enklere å sjekke om en studie er økologisk valid enn det er å sjekke om "
"en studie er eksternt valid. Et enkelt eksempel kan være studier av "
"øyenvitneidentifikasjon. De fleste av disse studiene utføres gjerne i "
"universitetsmiljøer, ofte med et ganske enkelt utvalg av ansikter å se på, i "
"stedet for en oppstilling. Det går vanligvis kortere tid fra man ser "
"«forbryteren» til man blir bedt om å identifisere den mistenkte i "
"«oppstillingen». «Forbrytelsen» er ikke reell, så det er ingen sjanse for at "
"vitnet blir skremt, og det er ingen politifolk til stede, så det er ikke "
"like stor sjanse for at vitnet føler seg presset. Alle disse tingene betyr "
"at studien *definitivt* mangler økologisk validitet. De kan (men trenger "
"ikke) bety at den også mangler ekstern validitet."

#: ../../Ch02/Ch02_StudyDesign_6.rst:218
msgid "Confounds, artefacts and other threats to validity"
msgstr "Forvirrende faktorer, artefakter og andre trusler mot validiteten"

#: ../../Ch02/Ch02_StudyDesign_6.rst:220
msgid ""
"If we look at the issue of validity in the most general fashion the two "
"biggest worries that we have are *confounders* and *artefacts*. These two "
"terms are defined in the following way:"
msgstr ""
"Hvis vi ser på spørsmålet om validitet på en mer generell måte, er de to "
"største bekymringene vi har *konfunderende variabler* og *artefakter*. Disse "
"to begrepene defineres på følgende måte:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:224
msgid ""
"**Confounder**: A confounder is an additional, often unmeasured variable\\ "
"[#]_ that turns out to be related to both the predictors and the outcome. "
"The existence of confounders threatens the internal validity of the study "
"because you can’t tell whether the predictor causes the outcome, or if the "
"confounding variable causes it."
msgstr ""
"**Konfunderende variabler**: En konfunderende variabel er en ekstra, ofte "
"umålt variabel\\ [#]_ som viser seg å være relatert til både prediktorene og "
"utfallet. Forvekslingsvariabler truer studiens interne validitet fordi man "
"ikke kan vite om det er prediktoren som forårsaker utfallet, eller om det er "
"forvekslingsvariabelen som forårsaker det."

#: ../../Ch02/Ch02_StudyDesign_6.rst:230
msgid ""
"**Artefact**: A result is said to be “artefactual” if it only holds in the "
"special situation that you happened to test in your study. The possibility "
"that your result is an artefact describes a threat to your external "
"validity, because it raises the possibility that you can’t generalise or "
"apply your results to the actual population that you care about."
msgstr ""
"**Artefakt**: Et resultat sies å være en «artefakt» hvis det bare holder i "
"den spesielle situasjonen som du tilfeldigvis testet i studien din. "
"Muligheten for at resultatet ditt er en artefakt, beskriver en trussel mot "
"den eksterne validiteten, fordi det øker muligheten for at du ikke kan "
"generalisere eller anvende resultatene dine på den faktiske populasjonen du "
"er interessert i."

#: ../../Ch02/Ch02_StudyDesign_6.rst:237
msgid ""
"As a general rule confounders are a bigger concern for non-experimental "
"studies, precisely because they’re not proper experiments. By definition, "
"you’re leaving lots of things uncontrolled, so there’s a lot of scope for "
"confounders being present in your study. Experimental research tends to be "
"much less vulnerable to confounders. The more control you have over what "
"happens during the study, the more you can prevent confounders from "
"affecting the results. With random allocation, for example, confounders are "
"distributed randomly, and evenly, between different groups."
msgstr ""
"Som en generell regel er konfunderende faktorer et større problem i ikke-"
"eksperimentelle studier, nettopp fordi de ikke er egentlige eksperimenter. "
"Per definisjon er det mange ting som ikke er kontrollert, og det er derfor "
"stor sjanse for at det finnes konfunderende faktorer i studien din. "
"Eksperimentell forskning er vanligvis mye mindre sårbar for konfunderende "
"faktorer. Jo mer kontroll du har over hva som skjer i løpet av studien, "
"desto mer kan du forhindre at konfunderende faktorer påvirker resultatene. "
"Med tilfeldig allokering, for eksempel, fordeles konfunderende faktorer "
"tilfeldig og jevnt mellom ulike grupper."

#: ../../Ch02/Ch02_StudyDesign_6.rst:247
msgid ""
"However, there are always swings and roundabouts and when we start thinking "
"about artefacts rather than confounders the shoe is very firmly on the other "
"foot. For the most part, artefactual results tend to be a concern for "
"experimental studies than for non-experimental studies. To see this, it "
"helps to realise that the reason that a lot of studies are non-experimental "
"is precisely because what the researcher is trying to do is examine human "
"behaviour in a more naturalistic context. By working in a more real-world "
"context you lose experimental control (making yourself vulnerable to "
"confounders), but because you tend to be studying human psychology “in the "
"wild” you reduce the chances of getting an artefactual result. Or, to put it "
"another way, when you take psychology out of the wild and bring it into the "
"lab (which we usually have to do to gain our experimental control), you "
"always run the risk of accidentally studying something different to what you "
"wanted to study."
msgstr ""
"Det er imidlertid alltid opp og ned, og når vi begynner å tenke på "
"artefakter i stedet for konfunderende faktorer, er det helt andre boller på "
"suppen. For det meste er artefakter et større problem i eksperimentelle "
"studier enn i ikke-eksperimentelle studier. For å forstå dette er det nyttig "
"å innse at grunnen til at mange studier er ikke-eksperimentelle, nettopp er "
"at forskeren prøver å undersøke menneskelig atferd i en mer naturalistisk "
"kontekst. Ved å arbeide i en mer virkelighetsnær kontekst mister man den "
"eksperimentelle kontrollen (og gjør seg sårbar for konfunderende faktorer), "
"men fordi man studerer menneskelig psykologi «i naturen», reduserer man "
"sjansen for å få et artefaktisk resultat. Eller for å si det på en annen "
"måte: Når man tar psykologien ut av naturen og bringer den inn i "
"laboratoriet (noe vi vanligvis må gjøre for å få eksperimentell kontroll), "
"risikerer man alltid å studere noe annet ved et uhell enn det man ønsket å "
"studere."

#: ../../Ch02/Ch02_StudyDesign_6.rst:262
msgid ""
"Be warned though. The above is a rough guide only. It’s absolutely possible "
"to have confounders in an experiment, and to get artefactual results with "
"non-experimental studies. This can happen for all sorts of reasons, not "
"least of which is experimenter or researcher error. In practice, it’s really "
"hard to think everything through ahead of time and even very good "
"researchers make mistakes."
msgstr ""
"Vær imidlertid advart. Ovennevnte er kun en grov veiledning. Det er fullt "
"mulig å ha konfunderende faktorer i et eksperiment, og å få artefaktiske "
"resultater med ikke-eksperimentelle studier. Dette kan skje av alle mulige "
"grunner, ikke minst på grunn av feil fra eksperimentatorens eller forskerens "
"side. I praksis er det veldig vanskelig å tenke gjennom alt på forhånd, og "
"selv svært dyktige forskere gjør feil."

#: ../../Ch02/Ch02_StudyDesign_6.rst:269
msgid ""
"Although there’s a sense in which almost any threat to validity can be "
"characterised as a confounder or an artefact, they’re pretty vague concepts. "
"So let’s have a look at some of the most common examples."
msgstr ""
"Selv om nesten enhver trussel mot validiteten kan karakteriseres som en "
"konfunderende faktor eller en artefakt, er dette ganske vage begreper. La "
"oss ta en titt på noen av de vanligste eksemplene."

#: ../../Ch02/Ch02_StudyDesign_6.rst:274
msgid "History effects"
msgstr "Historiske effekter"

#: ../../Ch02/Ch02_StudyDesign_6.rst:276
msgid ""
"**History effects** refer to the possibility that specific events may occur "
"during the study that might influence the outcome measure. For instance, "
"something might happen in between a pre-test and a post-test. Or in-between "
"testing participant 23 and participant 24. Alternatively, it might be that "
"you’re looking at a paper from an older study that was perfectly valid for "
"its time, but the world has changed enough since then that the conclusions "
"are no longer trustworthy. Examples of things that would count as history "
"effects are:"
msgstr ""
"**Historieeffekter** refererer til muligheten for at spesifikke hendelser "
"kan inntreffe i løpet av studien som kan påvirke utfallsmålet. Det kan for "
"eksempel skje noe mellom en pre-test og en post-test. Eller mellom testingen "
"av deltaker 23 og deltaker 24. Det kan også være at du ser på en artikkel "
"fra en eldre studie som var helt gyldig for sin tid, men at verden har "
"endret seg så mye siden den gang at konklusjonene ikke lenger er troverdige. "
"Eksempler på ting som kan regnes som historiske effekter, er:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:285
msgid ""
"You’re interested in how people think about risk and uncertainty. You "
"started your data collection in December 2010. But finding participants and "
"collecting data takes time, so you’re still finding new people in February "
"2011. Unfortunately for you (and even more unfortunately for others), the "
"Queensland floods occurred in January 2011 causing billions of dollars of "
"damage and killing many people. Not surprisingly, the people tested in "
"February 2011 express quite different beliefs about handling risk than the "
"people tested in December 2010. Which (if any) of these reflects the “true” "
"beliefs of participants? I think the answer is probably both. The Queensland "
"floods genuinely changed the beliefs of the Australian public, though "
"possibly only temporarily. The key thing here is that the “history” of the "
"people tested in February is quite different to people tested in December."
msgstr ""
"Du er interessert i hvordan folk tenker om risiko og usikkerhet. Du startet "
"datainnsamlingen i desember 2010. Men det tar tid å finne deltakere og samle "
"inn data, så i februar 2011 er du fortsatt i gang med å finne nye deltakere. "
"Dessverre for deg (og enda mer uheldig for andre) inntraff oversvømmelsene i "
"Queensland i januar 2011, som forårsaket skader for milliarder av dollar og "
"drepte mange mennesker. Ikke overraskende uttrykker de som ble testet i "
"februar 2011, helt andre oppfatninger om risikohåndtering enn de som ble "
"testet i desember 2010. Hvilken (om noen) av disse gjenspeiler deltakernes "
"«sanne» oppfatninger? Jeg tror svaret sannsynligvis er begge deler. "
"Oversvømmelsene i Queensland har virkelig endret den australske "
"befolkningens oppfatninger, om enn muligens bare midlertidig. Det viktigste "
"her er at «historien» til de som ble testet i februar, er en helt annen enn "
"hos dem som ble testet i desember."

#: ../../Ch02/Ch02_StudyDesign_6.rst:300
msgid ""
"You’re testing the psychological effects of a new anti-anxiety drug. So what "
"you do is measure anxiety before administering the drug (e.g., by self-"
"report, and taking physiological measures). Then you administer the drug, "
"and afterwards you take the same measures. In the middle however, because "
"your lab is in Los Angeles, there’s an earthquake which increases the "
"anxiety of the participants."
msgstr ""
"Du tester de psykologiske effektene av et nytt angstdempende legemiddel. Det "
"du gjør, er å måle angsten før du gir medisinen (f.eks. ved hjelp av "
"selvrapportering og fysiologiske målinger). Deretter administrerer du "
"legemiddelet, og etterpå tar du de samme målingene. Men midt i det hele, "
"fordi laboratoriet ditt ligger i Los Angeles, skjer det et jordskjelv som "
"øker angsten hos deltakerne."

#: ../../Ch02/Ch02_StudyDesign_6.rst:308
msgid "Maturation effects"
msgstr "Modningseffekter"

#: ../../Ch02/Ch02_StudyDesign_6.rst:310
msgid ""
"As with history effects, **maturational effects** are fundamentally about "
"change over time. However, maturation effects aren’t in response to specific "
"events. Rather, they relate to how people change on their own over time. We "
"get older, we get tired, we get bored, etc. Some examples of maturation "
"effects are:"
msgstr ""
"I likhet med historiske effekter handler **modningseffekter** i bunn og "
"grunn om endring over tid. Modningseffekter er imidlertid ikke en respons på "
"spesifikke hendelser. De er snarere knyttet til hvordan mennesker endrer seg "
"av seg selv over tid. Vi blir eldre, vi blir slitne, vi kjeder oss osv. Noen "
"eksempler på modningseffekter er:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:316
msgid ""
"When doing developmental psychology research you need to be aware that "
"children grow up quite rapidly. So, suppose that you want to find out "
"whether some educational trick helps with vocabulary size among 3 year olds. "
"One thing that you need to be aware of is that the vocabulary size of "
"children that age is growing at an incredible rate (multiple words per day) "
"all on its own. If you design your study without taking this maturational "
"effect into account, then you won’t be able to tell if your educational "
"trick works."
msgstr ""
"Når du driver med utviklingspsykologisk forskning, må du være klar over at "
"barn vokser opp ganske raskt. Så tenk deg at du ønsker å finne ut om et "
"eller annet pedagogisk triks hjelper på ordforrådet til treåringer. En ting "
"du må være klar over, er at ordforrådet til barn i den alderen vokser med en "
"utrolig hastighet (flere ord per dag) helt av seg selv. Hvis du utformer "
"studien din uten å ta hensyn til denne modningseffekten, vil du ikke være i "
"stand til å se om det pedagogiske trikset ditt virker."

#: ../../Ch02/Ch02_StudyDesign_6.rst:325
msgid ""
"When running a very long experiment in the lab (say, something that goes for "
"3 hours) it’s very likely that people will begin to get bored and tired, and "
"that this maturational effect will cause performance to decline regardless "
"of anything else going on in the experiment"
msgstr ""
"Når man kjører et veldig langt eksperiment i laboratoriet (for eksempel noe "
"som varer i tre timer), er det svært sannsynlig at folk begynner å kjede seg "
"og bli slitne, og at denne modningseffekten vil føre til at ytelsen synker, "
"uavhengig av alt annet som skjer i eksperimentet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:332
msgid "Repeated testing effects"
msgstr "Effekter av gjentatte tester"

#: ../../Ch02/Ch02_StudyDesign_6.rst:334
msgid ""
"An important type of history effect is the effect of **repeated testing**. "
"Suppose I want to take two measurements of some psychological construct (e."
"g., anxiety). One thing I might be worried about is if the first measurement "
"has an effect on the second measurement. In other words, this is a history "
"effect in which the “event” that influences the second measurement is the "
"first measurement itself! This is not at all uncommon. Examples of this "
"include:"
msgstr ""
"En viktig type historikkeffekt er effekten av **gjentatt testing**. Anta at "
"jeg ønsker å foreta to målinger av et psykologisk konstrukt (f.eks. angst). "
"En ting jeg kan være bekymret for, er om den første målingen har en effekt "
"på den andre målingen. Dette er med andre ord en historikkeffekt, der "
"«hendelsen» som påvirker den andre målingen, er selve den første målingen! "
"Dette er slett ikke uvanlig. Eksempler på dette er blant annet:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:342
msgid ""
"*Learning and practice*: e.g., “intelligence” at time 2 might appear to go "
"up relative to time 1 because participants learned the general rules of how "
"to solve “intelligence-test-style” questions during the first testing "
"session."
msgstr ""
"*Læring og øvelse*: F.eks. kan det se ut som om «intelligensen» ved "
"tidspunkt 2 øker i forhold til tidspunkt 1 fordi deltakerne lærte de "
"generelle reglene for hvordan man løser «intelligenstest-lignende» spørsmål "
"i løpet av den første testøkten."

#: ../../Ch02/Ch02_StudyDesign_6.rst:347
msgid ""
"*Familiarity with the testing situation*: e.g., if people are nervous at "
"time 1, this might make performance go down. But after sitting through the "
"first testing situation they might calm down a lot precisely because they’ve "
"seen what the testing looks like."
msgstr ""
"*Kjennskap til testsituasjonen*: Hvis folk f.eks. er nervøse på tidspunkt 1, "
"kan dette føre til at ytelsen går ned. Men etter å ha vært gjennom den "
"første testsituasjonen kan det hende at de roer seg mye ned, nettopp fordi "
"de har sett hvordan testingen ser ut."

#: ../../Ch02/Ch02_StudyDesign_6.rst:352
msgid ""
"*Auxiliary changes caused by testing*: e.g., if a questionnaire assessing "
"mood is boring then mood rating at measurement time 2 is more likely to be "
"“bored” precisely because of the boring measurement made at time 1."
msgstr ""
"*Supplerende endringer forårsaket av testing*: Hvis f.eks. et spørreskjema "
"som vurderer humøret er kjedelig, er det mer sannsynlig at humøret ved "
"måletidspunkt 2 er «kjedelig», nettopp på grunn av den kjedelige målingen "
"som ble gjort ved tidspunkt 1."

#: ../../Ch02/Ch02_StudyDesign_6.rst:358
msgid "Selection bias"
msgstr "Seleksjonsskevhet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:360
msgid ""
"**Selection bias** is a pretty broad term. Suppose that you’re running an "
"experiment with two groups of participants where each group gets a different "
"“treatment”, and you want to see if the different treatments lead to "
"different outcomes. However, suppose that, despite your best efforts, you’ve "
"ended up with a gender imbalance across groups (say, group A has 80\\% "
"females and group B has 50\\% females). It might sound like this could never "
"happen but, trust me, it can. This is an example of a selection bias, in "
"which the people “selected into” the two groups have different "
"characteristics. If any of those characteristics turns out to be relevant "
"(say, your treatment works better on females than males) then you’re in a "
"lot of trouble."
msgstr ""
"**Seleksjonsskevhet** er et ganske vidt begrep. Anta at du kjører et "
"eksperiment med to grupper deltakere der hver gruppe får ulik «behandling», "
"og at du ønsker å se om de ulike behandlingene fører til ulike resultater. "
"Men tenk deg at du, til tross for din beste innsats, har endt opp med en "
"kjønnsubalanse på tvers av gruppene (la oss si at gruppe A har 80\\% kvinner "
"og gruppe B har 50\\% kvinner). Det høres kanskje ut som om dette aldri kan "
"skje, men tro meg, det kan det. Dette er et eksempel på seleksjonsskevhet, "
"der personene som «velges inn» i de to gruppene har ulike egenskaper. Hvis "
"noen av disse egenskapene viser seg å være relevante (for eksempel at "
"behandlingen din virker bedre på kvinner enn på menn), har du et stort "
"problem."

#: ../../Ch02/Ch02_StudyDesign_6.rst:373
msgid "Differential attrition"
msgstr "Differensielt frafall"

#: ../../Ch02/Ch02_StudyDesign_6.rst:375
msgid ""
"When thinking about the effects of attrition, it is sometimes helpful to "
"distinguish between two different types. The first is **homogeneous "
"attrition**, in which the attrition effect is the same for all groups, "
"treatments or conditions. In the example I gave above, the attrition would "
"be homogeneous if (and only if) the easily bored participants are dropping "
"out of all of the conditions in my experiment at about the same rate. In "
"general, the main effect of homogeneous attrition is likely to be that it "
"makes your sample unrepresentative. As such, the biggest worry that you’ll "
"have is that the generalisability of the results decreases. In other words, "
"you lose external validity."
msgstr ""
"Når man tenker på effekten av frafall, er det noen ganger nyttig å skille "
"mellom to ulike typer. Den første er **homogent frafall**, der "
"frafallseffekten er den samme for alle grupper, behandlinger eller "
"betingelser. I eksempelet jeg ga ovenfor, vil frafallet være homogent hvis "
"(og bare hvis) de deltakerne som kjeder seg lett, dropper ut av alle "
"betingelsene i eksperimentet mitt i omtrent samme takt. Generelt vil den "
"viktigste effekten av homogent frafall sannsynligvis være at det gjør "
"utvalget ditt lite representativt. Den største bekymringen er derfor at "
"generaliserbarheten av resultatene reduseres. Du mister med andre ord den "
"eksterne validiteten."

#: ../../Ch02/Ch02_StudyDesign_6.rst:386
msgid ""
"The second type of attrition is **heterogeneous attrition**, in which the "
"attrition effect is different for different groups. More often called "
"**differential attrition**, this is a kind of selection bias that is caused "
"by the study itself. Suppose that, for the first time ever in the history of "
"psychology, I manage to find the perfectly balanced and representative "
"sample of people. I start running “Dani’s incredibly long and tedious "
"experiment” on my perfect sample but then, because my study is incredibly "
"long and tedious, lots of people start dropping out. I can’t stop this. "
"Participants absolutely have the right to stop doing any experiment, any "
"time, for whatever reason they feel like, and as researchers we are morally "
"(and professionally) obliged to remind people that they do have this right. "
"So, suppose that “Dani’s incredibly long and tedious experiment” has a very "
"high drop out rate. What do you suppose the odds are that this drop out is "
"random? Answer: zero. Almost certainly the people who remain are more "
"conscientious, more tolerant of boredom, etc., than those that leave. To the "
"extent that (say) conscientiousness is relevant to the psychological "
"phenomenon that I care about, this attrition can decrease the validity of my "
"results."
msgstr ""
"Den andre typen frafall er **heterogent frafall**, der frafallseffekten er "
"forskjellig for ulike grupper. Dette kalles ofte **differensielt frafall**, "
"og er en form for seleksjonsskevhet som skyldes selve studien. Anta at jeg "
"for første gang i psykologiens historie klarer å finne et perfekt balansert "
"og representativt utvalg av mennesker. Jeg begynner å kjøre «Danis utrolig "
"lange og kjedelige eksperiment» på det perfekte utvalget mitt, men fordi "
"studien min er utrolig lang og kjedelig, begynner mange å falle fra. Jeg kan "
"ikke stoppe dette. Deltakerne har absolutt rett til å avbryte et hvilket som "
"helst eksperiment, når som helst og av hvilken som helst grunn, og som "
"forskere er vi moralsk (og faglig) forpliktet til å minne folk på at de har "
"denne retten. Så la oss anta at «Danis utrolig lange og kjedelige "
"eksperiment» har en svært høy frafallsprosent. Hva tror du oddsen er for at "
"dette frafallet er tilfeldig? Svar: null. De som blir igjen, er nesten helt "
"sikkert mer samvittighetsfulle, mer tolerante overfor kjedsomhet osv. enn de "
"som slutter. I den grad (la oss si) samvittighetsfullhet er relevant for det "
"psykologiske fenomenet jeg er interessert i, kan dette frafallet redusere "
"gyldigheten av resultatene mine."

#: ../../Ch02/Ch02_StudyDesign_6.rst:405
msgid ""
"Here’s another example. Suppose I design my experiment with two conditions. "
"In the “treatment” condition, the experimenter insults the participant and "
"then gives them a questionnaire designed to measure obedience. In the "
"“control” condition, the experimenter engages in a bit of pointless chitchat "
"and then gives them the questionnaire. Leaving aside the questionable "
"scientific merits and dubious ethics of such a study, let’s have a think "
"about what might go wrong here. As a general rule, when someone insults me "
"to my face I tend to get much less co-operative. So, there’s a pretty good "
"chance that a lot more people are going to drop out of the treatment "
"condition than the control condition. And this drop out isn’t going to be "
"random. The people most likely to drop out would probably be the people who "
"don’t care all that much about the importance of obediently sitting through "
"the experiment. Since the most bloody minded and disobedient people all left "
"the treatment group but not the control group, we’ve introduced a confound: "
"the people who actually took the questionnaire in the treatment group were "
"*already* more likely to be dutiful and obedient than the people in the "
"control group. In short, in this study insulting people doesn’t make them "
"more obedient. It makes the more disobedient people leave the experiment! "
"The internal validity of this experiment is completely shot."
msgstr ""
"Her er et annet eksempel. Anta at jeg utformer eksperimentet mitt med to "
"betingelser. I «behandlingsbetingelsen» fornærmer eksperimentlederen "
"deltakeren og gir dem deretter et spørreskjema som er utformet for å måle "
"lydighet. I «kontrollbetingelsen» begynner forsøkslederen med litt "
"meningsløs småprat og gir dem deretter spørreskjemaet. Hvis vi ser bort fra "
"de tvilsomme vitenskapelige fordelene og den tvilsomme etikken ved en slik "
"studie, kan vi tenke litt på hva som kan gå galt her. Når noen fornærmer meg "
"ansikt til ansikt, blir jeg som regel mye mindre samarbeidsvillig. Så det er "
"en ganske stor sjanse for at mange flere kommer til å droppe ut av "
"behandlingsgruppen enn av kontrollgruppen. Og dette frafallet kommer ikke "
"til å være tilfeldig. De som mest sannsynlig vil droppe ut, er sannsynligvis "
"de som ikke bryr seg så mye om hvor viktig det er å lydig sitte gjennom "
"eksperimentet. Siden de mest blodtørstige og ulydige personene forlot "
"behandlingsgruppen, men ikke kontrollgruppen, har vi introdusert en "
"konfunderende faktor: Personene som faktisk besvarte spørreskjemaet i "
"behandlingsgruppen var *allerede* mer tilbøyelige til å være "
"pliktoppfyllende og lydige enn personene i kontrollgruppen. Kort sagt, i "
"denne studien gjør ikke fornærmelser folk mer lydige. Det får de mer ulydige "
"personene til å forlate eksperimentet! Den interne validiteten til dette "
"eksperimentet er fullstendig ødelagt."

#: ../../Ch02/Ch02_StudyDesign_6.rst:427
msgid "Non-response bias"
msgstr "Skevhet pga. frafall"

#: ../../Ch02/Ch02_StudyDesign_6.rst:429
msgid ""
"**Non-response bias** is closely related to selection bias and to "
"differential attrition. The simplest version of the problem goes like this. "
"You mail out a survey to 1000 people but only 300 of them reply. The 300 "
"people who replied are almost certainly not a random subsample. People who "
"respond to surveys are systematically different to people who don’t. This "
"introduces a problem when trying to generalise from those 300 people who "
"replied to the population at large, since you now have a very non-random "
"sample. The issue of non-response bias is more general than this, though. "
"Among the (say) 300 people that did respond to the survey, you might find "
"that not everyone answers every question. If (say) 80 people chose not to "
"answer one of your questions, does this introduce problems? As always, the "
"answer is maybe. If the question that wasn’t answered was on the last page "
"of the questionnaire, and those 80 surveys were returned with the last page "
"missing, there’s a good chance that the missing data isn’t a big deal; "
"probably the pages just fell off. However, if the question that 80 people "
"didn’t answer was the most confrontational or invasive personal question in "
"the questionnaire, then almost certainly you’ve got a problem. In essence, "
"what you’re dealing with here is what’s called the problem of **missing "
"data**. If the data that is missing was “lost” randomly, then it’s not a big "
"problem. If it’s missing systematically, then it can be a big problem."
msgstr ""
"**Skevhet pga. frafall** er nært knyttet til seleksjonsskevhet og "
"differensielt frafall. Den enkleste versjonen av problemet er som følger. Du "
"sender ut en spørreundersøkelse til 1000 personer, men bare 300 av dem "
"svarer. De 300 personene som har svart, er nesten helt sikkert ikke et "
"tilfeldig utvalg. Folk som svarer på spørreundersøkelser, er systematisk "
"forskjellige fra folk som ikke svarer. Dette skaper et problem når man "
"prøver å generalisere fra de 300 personene som svarte, til populasjonen som "
"helhet, siden man nå har etsvært ikke-tilfeldig utvalg. Problemet med "
"skevhet pga. frafall er imidlertid mer generelt enn dette. Blant de (la oss "
"si) 300 personene som svarte på undersøkelsen, kan det hende at ikke alle "
"svarer på alle spørsmålene. Hvis (la oss si) 80 personer velger å ikke svare "
"på ett av spørsmålene dine, skaper dette problemer? Som alltid er svaret "
"kanskje. Hvis spørsmålet som ikke ble besvart, sto på den siste siden av "
"spørreskjemaet, og de 80 undersøkelsene ble returnert uten den siste siden, "
"er det gode sjanser for at de manglende dataene ikke utgjør noe stort "
"problem; sannsynligvis har sidene bare falt av. Men hvis spørsmålet som 80 "
"personer ikke svarte på, var det mest konfronterende eller invaderende "
"personlige spørsmålet i spørreskjemaet, har du nesten helt sikkert et "
"problem. I bunn og grunn har du her å gjøre med det som kalles problemet med "
"**manglende verdier**. Hvis dataene som mangler, er «tapt» tilfeldig, er det "
"ikke noe stort problem. Hvis de mangler systematisk, kan det være et stort "
"problem."

#: ../../Ch02/Ch02_StudyDesign_6.rst:452
msgid "Regression to the mean"
msgstr "Regresjon mot gjennomsnittet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:454
msgid ""
"**Regression to the mean** refers to any situation where you select data "
"based on an extreme value on some measure. Because the variable has natural "
"variation it almost certainly means that when you take a subsequent "
"measurement the later measurement will be less extreme than the first one, "
"purely by chance."
msgstr ""
"**Regresjon mot gjennomsnittet** refererer til enhver situasjon der du "
"velger ut data basert på en ekstremverdi for en eller annen variabel. Fordi "
"variabelen har naturlig variasjon, betyr det nesten helt sikkert at når du "
"foretar en ny måling, vil den senere målingen være mindre ekstrem enn den "
"første, helt tilfeldig."

#: ../../Ch02/Ch02_StudyDesign_6.rst:460
msgid ""
"Here’s an example. Suppose I’m interested in whether a psychology education "
"has an adverse effect on very smart kids. To do this, I find the 20 "
"psychology I students with the best high school grades and look at how well "
"they’re doing at university. It turns out that they’re doing a lot better "
"than average, but they’re not topping the class at university even though "
"they did top their classes at high school. What’s going on? The natural "
"first thought is that this must mean that the psychology classes must be "
"having an adverse effect on those students. However, while that might very "
"well be the explanation, it’s more likely that what you’re seeing is an "
"example of “regression to the mean”. To see how it works, let’s take a "
"moment to think about what is required to get the best mark in a class, "
"regardless of whether that class be at high school or at university. When "
"you’ve got a big class there are going to be *lots* of very smart people "
"enrolled. To get the best mark you have to be very smart, work very hard, "
"and be a bit lucky. The exam has to ask just the right questions for your "
"idiosyncratic skills, and you have to avoid making any dumb mistakes (we all "
"do that sometimes) when answering them. And that’s the thing, whilst "
"intelligence and hard work are transferable from one class to the next, luck "
"isn’t. The people who got lucky in high school won’t be the same as the "
"people who get lucky at university. That’s the very definition of “luck”. "
"The consequence of this is that when you select people at the very extreme "
"values of one measurement (the top 20 students), you’re selecting for hard "
"work, skill and luck. But because the luck doesn’t transfer to the second "
"measurement (only the skill and work), these people will all be expected to "
"drop a little bit when you measure them a second time (at university). So "
"their scores fall back a little bit, back towards everyone else. This is "
"regression to the mean."
msgstr ""
"Her er et eksempel. Anta at jeg er interessert i å finne ut om "
"psykologiutdanningen har en negativ effekt på veldig smarte barn. For å "
"gjøre dette finner jeg de 20 studentene på psykologi I med de beste "
"karakterene fra videregående, og ser på hvor godt de gjør det på "
"universitetet. Det viser seg at de gjør det mye bedre enn gjennomsnittet, "
"men de er ikke best i klassen på universitetet, selv om de var best i "
"klassen på videregående. Hva er det som skjer? Den første naturlige tanken "
"er at dette må bety at psykologitimene må ha en negativ effekt på disse "
"studentene. Men selv om det godt kan være forklaringen, er det mer "
"sannsynlig at det du ser, er et eksempel på «regresjon mot gjennomsnittet». "
"For å se hvordan det fungerer, kan vi tenke litt på hva som kreves for å få "
"den beste karakteren i en klasse, uansett om det er på videregående skole "
"eller på universitetet. Når du har en stor klasse, kommer det til å være "
"*mange* veldig smarte mennesker påmeldt. For å få den beste karakteren må du "
"være veldig smart, jobbe veldig hardt og være litt heldig. Eksamen må stille "
"akkurat de riktige spørsmålene for dine idiosynkratiske ferdigheter, og du "
"må unngå å gjøre dumme feil (det gjør vi alle av og til) når du svarer på "
"dem. Og det er nettopp det som er greia: Mens intelligens og hardt arbeid "
"kan overføres fra en klasse til den neste, kan ikke flaks det. De som hadde "
"flaks på videregående, vil ikke være de samme som de som har flaks på "
"universitetet. Det er selve definisjonen av «flaks». Konsekvensen av dette "
"er at når du velger ut personer på de helt ekstreme verdiene av ett mål (de "
"20 beste studentene), velger du ut personer på grunnlag av hardt arbeid, "
"dyktighet og flaks. Men fordi flaksen ikke overføres til den andre målingen "
"(bare ferdighetene og arbeidet), vil alle disse personene forventes å falle "
"litt når du måler dem en gang til (på universitetet). Så deres poengsummer "
"faller litt tilbake, tilbake mot alle andre. Dette er regresjon mot "
"gjennomsnittet."

#: ../../Ch02/Ch02_StudyDesign_6.rst:489
msgid ""
"Regression to the mean is surprisingly common. For instance, if two very "
"tall people have kids their children will tend to be taller than average but "
"not as tall as the parents. The reverse happens with very short parents. Two "
"very short parents will tend to have short children, but nevertheless those "
"kids will tend to be taller than the parents. It can also be extremely "
"subtle. For instance, there have been studies done that suggested that "
"people learn better from negative feedback than from positive feedback. "
"However, the way that people tried to show this was to give people positive "
"reinforcement whenever they did good, and negative reinforcement when they "
"did bad. And what you see is that after the positive reinforcement people "
"tended to do worse, but after the negative reinforcement they tended to do "
"better. But notice that there’s a selection bias here! When people do very "
"well, you’re selecting for “high” values, and so you should *expect*, "
"because of regression to the mean, that performance on the next trial should "
"be worse regardless of whether reinforcement is given. Similarly, after a "
"bad trial, people will tend to improve all on their own. The apparent "
"superiority of negative feedback is an artefact caused by regression to the "
"mean (see :ref:`Kahneman & Tversky, 1973 <Kahneman_1973>` for a discussion)."
msgstr ""
"Regresjon mot gjennomsnittet er overraskende vanlig. Hvis for eksempel to "
"svært høye mennesker får barn, vil barna deres ha en tendens til å bli "
"høyere enn gjennomsnittet, men ikke like høye som foreldrene. Det motsatte "
"skjer med svært korte foreldre. To veldig korte foreldre vil ha en tendens "
"til å få korte barn, men barna vil likevel ha en tendens til å være høyere "
"enn foreldrene. Det kan også være ekstremt subtilt. Det er for eksempel "
"gjort studier som tyder på at folk lærer bedre av negative tilbakemeldinger "
"enn av positive. Måten man forsøkte å vise dette på, var å gi folk positiv "
"forsterkning når de gjorde noe bra, og negativ forsterkning når de gjorde "
"noe dårlig. Og det du ser, er at etter den positive forsterkningen hadde "
"folk en tendens til å gjøre det dårligere, men etter den negative "
"forsterkningen hadde de en tendens til å gjøre det bedre. Men legg merke til "
"at det er en seleksjonsskevhet her! Når folk gjør det veldig bra, selekterer "
"du for «høye» verdier, og derfor bør du *forvente*, på grunn av regresjon "
"mot gjennomsnittet, at prestasjonen i neste forsøk blir dårligere, uavhengig "
"av om det gis forsterkning eller ikke. På samme måte vil folk ha en tendens "
"til å forbedre seg av seg selv etter en dårlig prøve. Den tilsynelatende "
"overlegenheten til negative tilbakemeldinger er en artefakt forårsaket av "
"regresjon mot gjennomsnittet (se :ref:`Kahneman & Tversky, 1973 "
"<Kahneman_1973>` for en diskusjon)."

#: ../../Ch02/Ch02_StudyDesign_6.rst:510
msgid "Experimenter bias"
msgstr "Eksperimentatoreffekter"

#: ../../Ch02/Ch02_StudyDesign_6.rst:512
msgid ""
"**Experimenter bias** can come in multiple forms. The basic idea is that the "
"experimenter, despite the best of intentions, can accidentally end up "
"influencing the results of the experiment by subtly communicating the “right "
"answer” or the “desired behaviour” to the participants. Typically, this "
"occurs because the experimenter has special knowledge that the participant "
"does not, for example the right answer to the questions being asked or "
"knowledge of the expected pattern of performance for the condition that the "
"participant is in. The classic example of this happening is the case study "
"of “Clever Hans”, which dates back to 1907 (:ref:`Pfungst, 1911 "
"<Pfungst_1911>`; :ref:`Hothersall, 2004 <Hothersall_2004>`). Clever Hans was "
"a horse that apparently was able to read and count and perform other human "
"like feats of intelligence. After Clever Hans became famous, psychologists "
"started examining his behaviour more closely. It turned out that, not "
"surprisingly, Hans didn’t know how to do maths. Rather, Hans was responding "
"to the human observers around him, because the humans did know how to count "
"and the horse had learned to change its behaviour when people changed theirs."
msgstr ""
"**Eksperimentatoreffekter** kan komme i flere former. Den grunnleggende "
"ideen er at forsøkslederen, til tross for de beste intensjoner, ved et uhell "
"kan ende opp med å påvirke resultatene av eksperimentet ved subtilt å "
"kommunisere det «riktige svaret» eller den «ønskede atferden» til "
"deltakerne. Dette skjer typisk fordi forsøkslederen har spesialkunnskap som "
"deltakeren ikke har, for eksempel det riktige svaret på spørsmålene som "
"stilles, eller kunnskap om det forventede prestasjonsmønsteret for den "
"betingelsen deltakeren befinner seg i. Det klassiske eksemplet på dette er "
"casestudien av «Clever Hans», som stammer fra 1907 (:ref:`Pfungst, 1911 "
"<Pfungst_1911>`; :ref:`Hothersall, 2004 <Hothersall_2004>`). Clever Hans var "
"en hest som tilsynelatende var i stand til å lese og telle og utføre andre "
"menneskelignende intelligensprestasjoner. Etter at Clever Hans ble berømt, "
"begynte psykologer å undersøke atferden hans nærmere. Det viste seg, ikke "
"overraskende, at Hans ikke kunne regne. Hans reagerte snarere på de "
"menneskelige observatørene rundt seg, fordi menneskene kunne telle, og "
"hesten hadde lært seg å endre atferd når menneskene endret sin."

#: ../../Ch02/Ch02_StudyDesign_6.rst:530
msgid ""
"The general solution to the problem of experimenter bias is to engage in "
"double blind studies, where neither the experimenter nor the participant "
"knows which condition the participant is in or knows what the desired "
"behaviour is. This provides a very good solution to the problem, but it’s "
"important to recognise that it’s not quite ideal, and hard to pull off "
"perfectly. For instance, the obvious way that I could try to construct a "
"double blind study is to have one of my Ph.D. students (one who doesn’t know "
"anything about the experiment) run the study. That feels like it should be "
"enough. The only person (me) who knows all the details (e.g., correct "
"answers to the questions, assignments of participants to conditions) has no "
"interaction with the participants, and the person who does all the talking "
"to people (the Ph.D. student) doesn’t know anything. Except for the reality "
"that the last part is very unlikely to be true. In order for the Ph.D. "
"student to run the study effectively they need to have been briefed by me, "
"the researcher. And, as it happens, the Ph.D. student also knows me and "
"knows a bit about my general beliefs about people and psychology (e.g., I "
"tend to think humans are much smarter than psychologists give them credit "
"for). As a result of all this, it’s almost impossible for the experimenter "
"to avoid knowing a little bit about what expectations I have. And even a "
"little bit of knowledge can have an effect. Suppose the experimenter "
"accidentally conveys the fact that the participants are expected to do well "
"in this task. Well, there’s a thing called the “Pygmalion effect”, where if "
"you expect great things of people they’ll tend to rise to the occasion. But "
"if you expect them to fail then they’ll do that too. In other words, the "
"expectations become a self-fulfilling prophesy."
msgstr ""
"Den generelle løsningen på problemet med eksperimentatoreffekter er å "
"gjennomføre dobbeltblinde studier, der verken eksperimentator eller deltaker "
"vet hvilken betingelse deltakeren befinner seg i eller hva som er ønsket "
"atferd. Dette er en veldig god løsning på problemet, men det er viktig å "
"være klar over at det ikke er helt ideelt, og at det er vanskelig å få til "
"perfekt. For eksempel er den åpenbare måten jeg kan prøve å konstruere en "
"dobbeltblind studie på, å la en av doktorgradsstudentene mine (en som ikke "
"vet noe om eksperimentet) gjennomføre studien. Det føles som om det burde "
"være nok. Den eneste personen (meg) som kjenner alle detaljene (f.eks. "
"riktige svar på spørsmålene, tildeling av deltakere til betingelser), har "
"ingen interaksjon med deltakerne, og personen som snakker med folk "
"(doktorgradsstudenten), vet ingenting. Bortsett fra at det siste "
"sannsynligvis ikke er sant. For at doktorgradsstudenten skal kunne "
"gjennomføre studien på en effektiv måte, må han eller hun ha blitt informert "
"av meg, forskeren. Og tilfeldigvis kjenner doktorgradsstudenten også meg og "
"vet litt om mine generelle oppfatninger om mennesker og psykologi (jeg tror "
"for eksempel at mennesker er mye smartere enn psykologer tror). Som et "
"resultat av alt dette er det nesten umulig for eksperimentatoren å unngå å "
"vite litt om hvilke forventninger jeg har. Og selv litt kunnskap kan ha en "
"effekt. Sett at forsøkslederen ved et uhell kommer til å formidle at "
"deltakerne forventes å gjøre det bra i denne oppgaven. Det er noe som kalles "
"«Pygmalion-effekten», som går ut på at hvis du forventer store ting av folk, "
"vil de ha en tendens til å leve opp til forventningene. Men hvis du "
"forventer at de skal mislykkes, vil de også gjøre det. Forventningene blir "
"med andre ord en selvoppfyllende profeti."

#: ../../Ch02/Ch02_StudyDesign_6.rst:558
msgid "Demand effects and reactivity"
msgstr "Demand effects og reaktivitet"

#: ../../Ch02/Ch02_StudyDesign_6.rst:560
msgid ""
"When talking about experimenter bias, the worry is that the experimenter’s "
"knowledge or desires for the experiment are communicated to the "
"participants, and that these can change people’s behaviour (:ref:`Rosenthal, "
"1966 <Rosenthal_1966>`). However, even if you manage to stop this from "
"happening, it’s almost impossible to stop people from knowing that they’re "
"part of a psychological study. And the mere fact of knowing that someone is "
"watching or studying you can have a pretty big effect on behaviour. This is "
"generally referred to as **reactivity** or **demand effects**. The basic "
"idea is captured by the Hawthorne effect: people alter their performance "
"because of the attention that the study focuses on them. The effect takes "
"its name from a study that took place in the “Hawthorne Works” factory "
"outside of Chicago (see :ref:`Adair, 1984 <Adair_1984>`). This study, from "
"the 1920s, looked at the effects of factory lighting on worker productivity. "
"But, importantly, change in worker behaviour occurred because the workers "
"*knew* they were being studied, rather than any effect of factory lighting."
msgstr ""
"Når man snakker om eksperimentatoreffekter, er bekymringen at "
"eksperimentatorens kunnskap eller ønsker for eksperimentet blir kommunisert "
"til deltakerne, og at disse kan endre folks atferd (:ref:`Rosenthal, 1966 "
"<Rosenthal_1966>`). Men selv om man klarer å hindre at dette skjer, er det "
"nesten umulig å hindre at folk vet at de er en del av en psykologisk studie. "
"Og bare det å vite at noen følger med på eller studerer deg, kan ha en "
"ganske stor effekt på atferden din. Dette kalles gjerne **reaktivitet** "
"eller **demand effects**. Den grunnleggende ideen er beskrevet i Hawthorne-"
"effekten: Folk endrer prestasjonene sine på grunn av oppmerksomheten som "
"studien retter mot dem. Effekten har fått navnet sitt fra en studie som fant "
"sted i fabrikken «Hawthorne Works» utenfor Chicago (se :ref:`Adair, 1984 "
"<Adair_1984>`). Denne studien fra 1920-tallet så på effekten av "
"fabrikkbelysning på arbeidernes produktivitet. Men, og det er viktig å merke "
"seg, endringen i arbeidernes atferd skyldtes at arbeiderne *visste* at de "
"ble studert, snarere enn at fabrikkbelysningen hadde noen effekt."

#: ../../Ch02/Ch02_StudyDesign_6.rst:576
msgid ""
"To get a bit more specific about some of the ways in which the mere fact of "
"being in a study can change how people behave, it helps to think like a "
"social psychologist and look at some of the *roles* that people might "
"*adopt* during an experiment but might *not adopt* if the corresponding "
"events were occurring in the real world:"
msgstr ""
"For å bli litt mer spesifikk når det gjelder noen av de måtene det å delta i "
"en studie kan endre hvordan folk oppfører seg, kan det være nyttig å tenke "
"som en sosialpsykolog og se på noen av de *rollene* som folk kan *innta* "
"under et eksperiment, men som de kanskje *ikke ville ha inntatt* hvis de "
"tilsvarende hendelsene hadde funnet sted i den virkelige verden:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:582
msgid ""
"The *good participant* tries to be too helpful to the researcher. He or she "
"seeks to figure out the experimenter’s hypotheses and confirm them."
msgstr ""
"Den *gode deltakeren* prøver å være for hjelpsom mot forskeren. Han eller "
"hun forsøker å finne ut av eksperimentatorens hypoteser og bekrefte dem."

#: ../../Ch02/Ch02_StudyDesign_6.rst:586
msgid ""
"The *negative participant* does the exact opposite of the good participant. "
"He or she seeks to break or destroy the study or the hypothesis in some way."
msgstr ""
"Den *negative deltakeren* gjør det stikk motsatte av den gode deltakeren. "
"Han eller hun forsøker å ødelegge eller ødelegge studien eller hypotesen på "
"en eller annen måte."

#: ../../Ch02/Ch02_StudyDesign_6.rst:590
msgid ""
"The *faithful participant* is unnaturally obedient. He or she seeks to "
"follow instructions perfectly, regardless of what might have happened in a "
"more realistic setting."
msgstr ""
"Den *trofaste deltakeren* er unaturlig lydig. Han eller hun forsøker å følge "
"instruksjonene til punkt og prikke, uavhengig av hva som kunne ha skjedd i "
"en mer realistisk setting."

#: ../../Ch02/Ch02_StudyDesign_6.rst:594
msgid ""
"The *apprehensive participant* gets nervous about being tested or studied, "
"so much so that his or her behaviour becomes highly unnatural, or overly "
"socially desirable."
msgstr ""
"Den *engstelige deltakeren* blir nervøs for å bli testet eller studert, så "
"mye at hans eller hennes atferd blir svært unaturlig, eller altfor sosialt "
"ønskelig."

#: ../../Ch02/Ch02_StudyDesign_6.rst:599
msgid "Placebo effects"
msgstr "Placeboeffekter"

#: ../../Ch02/Ch02_StudyDesign_6.rst:601
msgid ""
"The **placebo effect** is a specific type of demand effect that we worry a "
"lot about. It refers to the situation where the mere fact of being treated "
"causes an improvement in outcomes. The classic example comes from clinical "
"trials. If you give people a completely chemically inert drug and tell them "
"that it’s a cure for a disease, they will tend to get better faster than "
"people who aren’t treated at all. In other words, it is people’s belief that "
"they are being treated that causes the improved outcomes, not the drug."
msgstr ""
"**Placeboeffekten** er en spesifikk type *demand effect* som vi bekymrer oss "
"mye for. Den refererer til en situasjon der bare det å bli behandlet fører "
"til en forbedring av resultatene. Det klassiske eksempelet kommer fra "
"kliniske studier. Hvis du gir folk et helt kjemisk inert legemiddel og "
"forteller dem at det er en kur mot en sykdom, vil de ha en tendens til å bli "
"raskere friske enn folk som ikke får behandling i det hele tatt. Det er med "
"andre ord folks tro på at de blir behandlet som gir bedre resultater, ikke "
"legemiddelet."

#: ../../Ch02/Ch02_StudyDesign_6.rst:610
msgid ""
"However, the current consensus in medicine is that true placebo effects are "
"quite rare and most of what was previously considered placebo effect is in "
"fact some combination of natural healing (some people just get better on "
"their own), regression to the mean and other quirks of study design. Of "
"interest to psychology is that the strongest evidence for at least some "
"placebo effect is in self-reported outcomes, most notably in treatment of "
"pain (:ref:`Hróbjartsson & Gøtzsche, 2010 <Hrobjartsson_2010>`)."
msgstr ""
"I dag er det imidlertid konsensus i medisinen om at ekte placeboeffekter er "
"ganske sjeldne, og at det meste av det som tidligere ble ansett som "
"placeboeffekt, i virkeligheten er en kombinasjon av naturlig helbredelse "
"(noen mennesker blir bare bedre av seg selv), regresjon mot gjennomsnittet "
"og andre særegenheter ved studiedesignet. Av interesse for psykologien er at "
"de sterkeste bevisene for i det minste en viss placeboeffekt finnes i "
"selvrapporterte resultater, særlig når det gjelder behandling av smerte (:"
"ref:`Hróbjartsson & Gøtzsche, 2010 <Hrobjartsson_2010>`)."

#: ../../Ch02/Ch02_StudyDesign_6.rst:619
msgid "Situation, measurement and sub-population effects"
msgstr "Situasjons-, måle- og subpopulasjonseffekter"

#: ../../Ch02/Ch02_StudyDesign_6.rst:621
msgid ""
"In some respects, these terms are a catch-all term for “all other threats to "
"external validity”. They refer to the fact that the choice of sub-population "
"from which you draw your participants, the location, timing and manner in "
"which you run your study (including who collects the data) and the tools "
"that you use to make your measurements might all be influencing the results. "
"Specifically, the worry is that these things might be influencing the "
"results in such a way that the results won’t generalise to a wider array of "
"people, places and measures."
msgstr ""
"På sett og vis er disse begrepene en samlebetegnelse for «alle andre trusler "
"mot den eksterne validiteten». De refererer til det faktum at valget av "
"delpopulasjon som du trekker deltakere fra, stedet, tidspunktet og måten du "
"gjennomfører studien på (inkludert hvem som samler inn dataene), og "
"verktøyene du bruker til å foreta målingene, kan påvirke resultatene. "
"Bekymringen er at disse faktorene kan påvirke resultatene på en slik måte at "
"de ikke kan generaliseres til et bredere spekter av mennesker, steder og "
"tiltak."

#: ../../Ch02/Ch02_StudyDesign_6.rst:631
msgid "Fraud, deception and self-deception"
msgstr "Bedrageri, bedrag og selvbedrag"

#: ../../Ch02/Ch02_StudyDesign_6.rst:0
msgid "*It is difficult to get a man to understand something,*"
msgstr "*Det er vanskelig å få en mann til å forstå noe.*"

#: ../../Ch02/Ch02_StudyDesign_6.rst:0
msgid "*when his salary depends on his not understanding it.*"
msgstr "*når lønnen hans avhenger av at han ikke forstår det*."

#: ../../Ch02/Ch02_StudyDesign_6.rst:638
msgid "Upton Sinclair"
msgstr "Upton Sinclair"

#: ../../Ch02/Ch02_StudyDesign_6.rst:640
msgid ""
"There’s one final thing I feel I should mention. While reading what the "
"textbooks often have to say about assessing the validity of a study I "
"couldn’t help but notice that they seem to make the assumption that the "
"researcher is honest. I find this hilarious. While the vast majority of "
"scientists are honest, in my experience at least, some are not.\\ [#]_ Not "
"only that, as I mentioned earlier, scientists are not immune to belief bias. "
"It’s easy for a researcher to end up deceiving themselves into believing the "
"wrong thing, and this can lead them to conduct subtly flawed research and "
"then hide those flaws when they write it up. So you need to consider not "
"only the (probably unlikely) possibility of outright fraud, but also the "
"(probably quite common) possibility that the research is unintentionally "
"“slanted”. I opened a few standard textbooks and didn’t find much of a "
"discussion of this problem, so here’s my own attempt to list a few ways in "
"which these issues can arise:"
msgstr ""
"Det er en siste ting jeg føler jeg bør nevne. Mens jeg leste hva lærebøkene "
"ofte har å si om å vurdere validiteten av en studie, kunne jeg ikke unngå å "
"legge merke til at de ser ut til å forutsette at forskeren er ærlig. Jeg "
"synes dette er morsomt. Selv om de aller fleste forskere er ærlige, er det, "
"i hvert fall etter min erfaring, noen som ikke er det.\\ [#]_ Det er lett "
"for en forsker å lure seg selv til å tro feil ting, og dette kan føre til at "
"de utfører subtilt mangelfull forskning og deretter skjuler disse feilene "
"når de skriver om den. Så du må ikke bare ta hensyn til muligheten for "
"direkte svindel (som sannsynligvis er usannsynlig), men også til muligheten "
"for at forskningen er utilsiktet «påvirket» (som sannsynligvis er ganske "
"vanlig). Jeg har slått opp i noen standard lærebøker, men fant ikke mye om "
"dette problemet, så her er mitt eget forsøk på å liste opp noen måter disse "
"problemene kan oppstå på:"

#: ../../Ch02/Ch02_StudyDesign_6.rst:656
msgid ""
"**Data fabrication**. Sometimes, people just make up the data. This is "
"occasionally done with “good” intentions. For instance, the researcher "
"believes that the fabricated data do reflect the truth, and may actually "
"reflect “slightly cleaned up” versions of actual data. On other occasions, "
"the fraud is deliberate and malicious. Some high-profile examples where data "
"fabrication has been alleged or shown include Cyril Burt (a psychologist who "
"is thought to have fabricated some of his data), Andrew Wakefield (who has "
"been accused of fabricating his data connecting the MMR vaccine to autism) "
"and Hwang Woo-suk (who falsified a lot of his data on stem cell research)."
msgstr ""
"**Fabrikasjon av data**. Noen ganger finner folk bare på data. Dette gjøres "
"av og til med «gode» hensikter. Forskeren tror for eksempel at de "
"fabrikkerte dataene gjenspeiler sannheten, og at de i virkeligheten kan være "
"en «litt opprenset» versjon av de faktiske dataene. I andre tilfeller er "
"svindelen bevisst og ondsinnet. Noen kjente eksempler på påstått eller "
"påvist datafabrikasjon er Cyril Burt (en psykolog som antas å ha fabrikkert "
"noen av dataene sine), Andrew Wakefield (som er blitt beskyldt for å ha "
"fabrikkert dataene sine om sammenhengen mellom MMR-vaksinen og autisme) og "
"Hwang Woo-suk (som forfalsket mange av dataene sine om stamcelleforskning)."

#: ../../Ch02/Ch02_StudyDesign_6.rst:668
msgid ""
"**Hoaxes**. Hoaxes share a lot of similarities with data fabrication, but "
"they differ in the intended purpose. A hoax is often a joke, and many of "
"them are intended to be (eventually) discovered. Often, the point of a hoax "
"is to discredit someone or some field. There’s quite a few well known "
"scientific hoaxes that have occurred over the years (e.g., Piltdown man) and "
"some were deliberate attempts to discredit particular fields of research (e."
"g., the Sokal affair)."
msgstr ""
"**Bløff**. Bløff (*hoaxes*) har mange likhetstrekk med datafabrikasjon, men "
"de skiller seg fra hverandre når det gjelder hensikten. En bløff er ofte en "
"spøk, og mange av dem er ment å bli oppdaget (etter hvert). Ofte er poenget "
"med en bløff å diskreditere noen eller et felt. Det finnes en rekke kjente "
"vitenskapelige bløffer som har funnet sted opp gjennom årene (f.eks. "
"Piltdown-mannen), og noen var bevisste forsøk på å diskreditere bestemte "
"forskningsfelt (f.eks. Sokal-affæren)."

#: ../../Ch02/Ch02_StudyDesign_6.rst:676
msgid ""
"**Data misrepresentation**. While fraud gets most of the headlines, it’s "
"much more common in my experience to see data being misrepresented. When I "
"say this I’m not referring to newspapers getting it wrong (which they do, "
"almost always). I’m referring to the fact that often the data don’t actually "
"say what the researchers think they say. My guess is that, almost always, "
"this isn’t the result of deliberate dishonesty but instead is due to a lack "
"of sophistication in the data analyses. For instance, think back to the "
"example of Simpson’s paradox that I discussed in the beginning of this book. "
"It’s very common to see people present “aggregated” data of some kind and "
"sometimes, when you dig deeper and find the raw data yourself you find that "
"the aggregated data tell a different story to the disaggregated data. "
"Alternatively, you might find that some aspect of the data is being hidden, "
"because it tells an inconvenient story (e.g., the researcher might choose "
"not to refer to a particular variable). There’s a lot of variants on this, "
"many of which are very hard to detect."
msgstr ""
"**Feilaktig presentasjon av data**. Selv om svindel får de fleste "
"overskriftene, er det etter min erfaring mye vanligere at data blir "
"feilaktig fremstilt. Når jeg sier dette, mener jeg ikke at avisene tar feil "
"(noe de nesten alltid gjør). Jeg sikter til det faktum at dataene ofte ikke "
"sier det forskerne tror de sier. Min gjetning er at dette nesten alltid ikke "
"skyldes bevisst uredelighet, men at dataanalysene er for lite sofistikerte. "
"Tenk for eksempel tilbake på Simpsons paradoks, som jeg diskuterte i "
"begynnelsen av denne boken. Det er veldig vanlig å se folk presentere "
"«aggregerte» data av et eller annet slag, og noen ganger, når du graver "
"dypere og finner rådataene selv, finner du ut at de aggregerte dataene "
"forteller en annen historie enn de disaggregerte dataene. Alternativt kan du "
"oppdage at noen aspekter ved dataene skjules fordi de forteller en upraktisk "
"historie (f.eks. kan forskeren velge å ikke referere til en bestemt "
"variabel). Det finnes mange varianter av dette, og mange av dem er svært "
"vanskelige å oppdage."

#: ../../Ch02/Ch02_StudyDesign_6.rst:694
msgid ""
"**Study “misdesign”**. Okay, this one is subtle. Basically, the issue here "
"is that a researcher designs a study that has built-in flaws and those flaws "
"are never reported in the paper. The data that are reported are completely "
"real and are correctly analysed, but they are produced by a study that is "
"actually quite wrongly put together. The researcher really wants to find a "
"particular effect and so the study is set up in such a way as to make it "
"“easy” to (artefactually) observe that effect. One sneaky way to do this, in "
"case you’re feeling like dabbling in a bit of fraud yourself, is to design "
"an experiment in which it’s obvious to the participants what they’re "
"“supposed” to be doing, and then let reactivity work its magic for you. If "
"you want you can add all the trappings of double blind experimentation but "
"it won’t make a difference since the study materials themselves are subtly "
"telling people what you want them to do. When you write up the results the "
"fraud won’t be obvious to the reader. What’s obvious to the participant when "
"they’re in the experimental context isn’t always obvious to the person "
"reading the paper. Of course, the way I’ve described this makes it sound "
"like it’s always fraud. Probably there are cases where this is done "
"deliberately, but in my experience the bigger concern has been with "
"unintentional misdesign. The researcher *believes* and so the study just "
"happens to end up with a built in flaw, and that flaw then magically erases "
"itself when the study is written up for publication."
msgstr ""
"**Utilstrekkelig studiedesign**. Ok, denne er litt mer subtil. I bunn og "
"grunn handler det om at en forsker utformer en studie som har innebygde "
"feil, og disse feilene blir aldri rapportert i artikkelen. Dataene som "
"rapporteres, er helt reelle og er korrekt analysert, men de er produsert av "
"en studie som faktisk er ganske feilaktig satt sammen. Forskeren ønsker "
"virkelig å finne en bestemt effekt, og derfor er studien lagt opp på en måte "
"som gjør det «lett» å observere denne effekten (artefaktisk). En lur måte å "
"gjøre dette på, i tilfelle du har lyst til å prøve deg på litt svindel selv, "
"er å designe et eksperiment der det er åpenbart for deltakerne hva de «skal» "
"gjøre, og så la reaktiviteten gjøre sitt magiske arbeid for deg. Hvis du "
"vil, kan du legge til alle fasadene til et dobbeltblindt eksperiment, men "
"det vil ikke utgjøre noen forskjell siden selve studiematerialet subtilt "
"forteller folk hva du vil at de skal gjøre. Når du skriver ned resultatene, "
"vil ikke svindelen være åpenbar for leseren. Det som er åpenbart for "
"deltakerne når de befinner seg i den eksperimentelle konteksten, er ikke "
"alltid åpenbart for den som leser artikkelen. Slik jeg har beskrevet dette, "
"høres det selvfølgelig ut som om det alltid er svindel. Det finnes nok "
"tilfeller der dette gjøres bevisst, men min erfaring er at det er mer snakk "
"om utilsiktet feildesign. Forskeren *tror*, og så ender studien tilfeldigvis "
"opp med en innebygd feil, og den feilen forsvinner på magisk vis når studien "
"skrives opp for publisering."

#: ../../Ch02/Ch02_StudyDesign_6.rst:718
msgid ""
"**Data mining & post-hoc hypothesising**. Another way in which the authors "
"of a study can more or less misrepresent the data is by engaging in what’s "
"referred to as “data mining” (see :ref:`Gelman & Loken, 2014 <Gelman_2014>`, "
"for a broader discussion of this as part of the “garden of forking paths” in "
"statistical analysis). As we’ll discuss later, if you keep trying to analyse "
"your data in lots of different ways, you’ll eventually find something that "
"“looks” like a real effect but isn’t. This is referred to as “data mining”. "
"It used to be quite rare because data analysis used to take weeks, but now "
"that everyone has very powerful statistical software on their computers it’s "
"becoming very common. Data mining per se isn’t “wrong”, but the more that "
"you do it the bigger the risk you’re taking. The thing that is wrong, and I "
"suspect is very common, is *unacknowledged* data mining. That is, the "
"researcher runs every possible analysis known to humanity, finds the one "
"that works, and then pretends that this was the only analysis that they ever "
"conducted. Worse yet, they often “invent” a hypothesis after looking at the "
"data to cover up the data mining. To be clear. It’s not wrong to change your "
"beliefs after looking at the data, and to reanalyse your data using your new "
"“post-hoc” hypotheses. What is wrong (and I suspect common) is failing to "
"acknowledge that you’ve done. If you acknowledge that you did it then other "
"researchers are able to take your behaviour into account. If you don’t, then "
"they can’t. And that makes your behaviour deceptive. Bad!"
msgstr ""
"**Gjentatte analyser og post-hoc-hypoteser**. En annen måte forfatterne av "
"en studie kan mer eller mindre fordreie dataene på, er ved å prøve ut "
"massevis forskjellige analyser (*data mining*, se :ref:`Gelman & Loken, 2014 "
"<Gelman_2014>`, for en bredere diskusjon av dette som en del av «*garden of "
"forking paths*» i statistisk analyse). Som vi skal komme tilbake til senere, "
"vil du, hvis du prøver å analysere dataene dine på mange forskjellige måter, "
"til slutt finne noe som «ser ut» som en reell effekt, men som ikke er det. "
"Dette kalles «*data mining*». Før var det ganske sjeldent fordi dataanalyser "
"tok flere uker, men nå som alle har svært kraftig statistisk programvare på "
"datamaskinene sine, er det blitt svært vanlig. Datautvinning i seg selv er "
"ikke «feil», men jo mer du gjør det, desto større risiko tar du. Det som er "
"galt, og som jeg mistenker er svært vanlig, er *uerkjent* datautvinning. Det "
"vil si at forskeren kjører alle mulige analyser som menneskeheten kjenner "
"til, finner den som fungerer, og deretter later som om dette var den eneste "
"analysen de noensinne har gjennomført. Enda verre er det at de ofte «finner "
"opp» en hypotese etter å ha sett på dataene for å dekke over "
"datautvinningen. For å gjøre det klart. Det er ikke galt å endre oppfatning "
"etter å ha sett på dataene, og å analysere dataene på nytt ved hjelp av de "
"nye «post-hoc»-hypotesene. Det som er galt (og jeg mistenker at det er "
"vanlig), er å unnlate å erkjenne at man har gjort det. Hvis du erkjenner at "
"du har gjort det, kan andre forskere ta hensyn til din atferd. Hvis du ikke "
"gjør det, kan de ikke det. Og det gjør atferden din villedende. Det er ille!"

#: ../../Ch02/Ch02_StudyDesign_6.rst:742
msgid ""
"**Publication bias & self-censoring**. Finally, a pervasive bias is “non-"
"reporting” of negative results. This is almost impossible to prevent. "
"Journals don’t publish every article that is submitted to them. They prefer "
"to publish articles that find “something”. So, if 20 people run an "
"experiment looking at whether reading *Finnegans Wake* causes insanity in "
"humans, and 19 of them find that it doesn’t, which one do you think is going "
"to get published? Obviously, it’s the one study that did find that "
"*Finnegans Wake* causes insanity.\\ [#]_ This is an example of a "
"*publication bias*. Since no-one ever published the 19 studies that didn’t "
"find an effect, a naive reader would never know that they existed. Worse "
"yet, most researchers “internalise” this bias and end up *self-censoring* "
"their research. Knowing that negative results aren’t going to be accepted "
"for publication, they never even try to report them. As a friend of mine "
"says “for every experiment that you get published, you also have 10 "
"failures”. And she’s right. The catch is, while some (maybe most) of those "
"studies are failures for boring reasons (e.g. you stuffed something up) "
"others might be genuine “null” results that you ought to acknowledge when "
"you write up the “good” experiment. And telling which is which is often hard "
"to do. A good place to start is a paper by :ref:`Ioannidis (2005) "
"<Ioannidis_2005>` with the depressing title “Why most published research "
"findings are false”. I’d also suggest taking a look at work by :ref:"
"`Kühberger et al. (2014) <Kühberger_2014>` presenting statistical evidence "
"that this actually happens in psychology."
msgstr ""
"**Skevhet i publisering og selvsensur**. Til slutt er det en gjennomgripende "
"skevhet at negative resultater «ikke rapporteres». Dette er nesten umulig å "
"forhindre. Tidsskrifter publiserer ikke alle artikler som sendes inn til "
"dem. De foretrekker å publisere artikler som finner «noe». Så hvis 20 "
"personer gjennomfører et eksperiment for å undersøke om lesing av *Finnegans "
"Wake* forårsaker sinnssykdom hos mennesker, og 19 av dem finner at det ikke "
"gjør det, hvilken av dem tror du kommer til å bli publisert? Det er åpenbart "
"den ene studien som fant at *Finnegans Wake* forårsaker sinnssykdom.\\ [#]_ "
"Dette er en eksempel på *skevhet i publiserings*. Siden ingen noen gang "
"publiserte de 19 studiene som ikke fant noen effekt, ville en naiv leser "
"aldri fått vite at de eksisterte. Enda verre er det at de fleste forskere "
"«internaliserer» denne skevheten og ender opp med å *selvsensurere* "
"forskningen sin. De vet at negative resultater ikke kommer til å bli "
"akseptert for publisering, og derfor prøver de ikke engang å rapportere dem. "
"Som en venn av meg sier: «For hvert eksperiment du får publisert, har du "
"også 10 fiaskoer». Og det har hun rett i. Haken er at selv om noen (kanskje "
"de fleste) av disse studiene er mislykkede av kjedelige grunner (f.eks. at "
"du har rotet til noe), kan andre være ekte «nullresultater» som du bør ta "
"hensyn til når du skriver om det «gode» eksperimentet. Og det er ofte "
"vanskelig å vite hva som er hva. Et godt sted å starte er en artikkel av :"
"ref:`Ioannidis (2005) <Ioannidis_2005>` med den deprimerende tittelen «Why "
"most published research findings are false». Jeg vil også foreslå at du tar "
"en titt på arbeidet til :ref:`Kühberger et al. (2014) <Kühberger_2014>`, som "
"presenterer statistiske bevis for at dette faktisk skjer i psykologien."

#: ../../Ch02/Ch02_StudyDesign_6.rst:767
msgid ""
"There’s probably a lot more issues like this to think about, but that’ll do "
"to start with. What I really want to point out is the blindingly obvious "
"truth that real world science is conducted by actual humans, and only the "
"most gullible of people automatically assumes that everyone else is honest "
"and impartial. Actual scientists aren’t usually *that* naive, but for some "
"reason the world likes to pretend that we are, and the textbooks we usually "
"write seem to reinforce that stereotype."
msgstr ""
"Det er sannsynligvis mange flere slike spørsmål å tenke på, men det holder "
"til å begynne med. Det jeg egentlig vil påpeke, er den åpenbare sannheten om "
"at vitenskapen i den virkelige verden utføres av mennesker, og at bare de "
"mest godtroende automatisk antar at alle andre er ærlige og upartiske. "
"Faktiske forskere er vanligvis ikke *så* naive, men av en eller annen grunn "
"liker verden å late som om vi er det, og lærebøkene vi vanligvis skriver, "
"ser ut til å forsterke den stereotypen."

#: ../../Ch02/Ch02_StudyDesign_6.rst:778
msgid ""
"The reason why I say that it’s unmeasured is that if you *have* measured it, "
"then you can use some fancy statistical tricks to deal with the confounder. "
"Because of the existence of these statistical solutions to the problem of "
"confounders, we often refer to a confounder that we have measured and dealt "
"with as a *covariate*. Dealing with covariates is a more advanced topic, but "
"I thought I’d mention it in passing since it’s kind of comforting to at "
"least know that this stuff exists."
msgstr ""
"Grunnen til at jeg sier at den er umålt, er at hvis du *har* målt den, så "
"kan du bruke noen fancy statistiske triks for å håndtere konfunderende "
"faktorer. Fordi det finnes slike statistiske løsninger på problemet med "
"konfunderende faktorer, kaller vi ofte en konfunderende faktor som vi har "
"målt og håndtert, for en *kovariat*. Håndtering av kovariater er et mer "
"avansert tema, men jeg tenkte jeg skulle nevne det i forbifarten, siden det "
"er betryggende å i det minste vite at disse tingene eksisterer."

#: ../../Ch02/Ch02_StudyDesign_6.rst:788
msgid ""
"Some people might argue that if you’re not honest then you’re not a real "
"scientist. Which does have some truth to it I guess, but that’s disingenuous "
"(look up the “No true Scotsman” fallacy). The fact is that there are lots of "
"people who are employed ostensibly as scientists, and whose work has all of "
"the trappings of science, but who are outright fraudulent. Pretending that "
"they don’t exist by saying that they’re not scientists is just muddled "
"thinking."
msgstr ""
"Noen vil kanskje hevde at hvis du ikke er ærlig, så er du ikke en ekte "
"forsker. Det har nok noe for seg, men det er uærlig (se «No true Scotsman»-"
"feilslutningen). Faktum er at det finnes mange mennesker som tilsynelatende "
"er ansatt som forskere, og hvis arbeid har alle vitenskapens kjennetegn, men "
"som er direkte uredelige. Å late som om de ikke eksisterer ved å si at de "
"ikke er forskere, er bare forvirret tenkning."

#: ../../Ch02/Ch02_StudyDesign_6.rst:797
msgid ""
"Clearly, the real effect is that only insane people would even try to read "
"*Finnegans Wake*."
msgstr ""
"Den virkelige effekten er tydeligvis at bare gale mennesker i det hele tatt "
"vil prøve å lese *Finnegans Wake*."

#: ../../Ch02/Ch02_StudyDesign_7.rst:4
msgid "Summary"
msgstr "Sammendrag"

#: ../../Ch02/Ch02_StudyDesign_7.rst:6
msgid ""
"This chapter isn’t really meant to provide a comprehensive discussion of "
"psychological research methods. It would require another volume just as long "
"as this one to do justice to the topic. However, in real life statistics and "
"study design are so tightly intertwined that it’s very handy to discuss some "
"of the key topics. In this chapter, I’ve briefly discussed the following "
"topics:"
msgstr ""
"Dette kapittelet er egentlig ikke ment å gi en uttømmende diskusjon av "
"psykologiske forskningsmetoder. Det ville kreve et like langt bind som dette "
"for å yte emnet rettferdighet. Men i det virkelige liv er statistikk og "
"studiedesign så tett sammenvevd at det er veldig nyttig å diskutere noen av "
"de viktigste temaene. I dette kapittelet har jeg kort omtalt følgende emner:"

#: ../../Ch02/Ch02_StudyDesign_7.rst:13
msgid ""
":doc:`Ch02_StudyDesign_1`: What does it mean to operationalise a theoretical "
"construct? What does it mean to have variables and take measurements?"
msgstr ""
":doc:`Ch02_StudyDesign_1`: Hva vil det si å operasjonalisere en teoretisk "
"konstrukt? Hva vil det si å ha variabler og foreta målinger?"

#: ../../Ch02/Ch02_StudyDesign_7.rst:16
msgid ""
":doc:`Ch02_StudyDesign_2`: Remember that there are *two* different "
"distinctions here. There’s the difference between discrete and continuous "
"data, and there’s the difference between the four different scale types "
"(nominal, ordinal, interval and ratio)."
msgstr ""
":doc:`Ch02_StudyDesign_2`: Husk at det er *to* forskjellige distinksjoner "
"her. Det er forskjellen mellom diskrete og kontinuerlige data, og det er "
"forskjellen mellom de fire ulike skalatypene (nominal, ordinal, intervall og "
"forholdstall)."

#: ../../Ch02/Ch02_StudyDesign_7.rst:21
msgid ""
":doc:`Reliability of a measurement <Ch02_StudyDesign_3>`: If I measure the "
"“same” thing twice, should I expect to see the same result? Only if my "
"measure is reliable. But what does it mean to talk about doing the “same” "
"thing? Well, that’s why we have different types of reliability. Make sure "
"you remember what they are."
msgstr ""
":doc:`Sannsynlighet av en måling <Ch02_StudyDesign_3>`: Hvis jeg måler «det "
"samme» to ganger, kan jeg forvente å se det samme resultatet? Bare hvis "
"målingen min er reliabel. Men hva betyr det å snakke om å gjøre «det samme»? "
"Det er derfor vi har ulike typer reliabilitet. Sørg for at du husker hva de "
"er."

#: ../../Ch02/Ch02_StudyDesign_7.rst:27
msgid ""
":doc:`Terminology: predictors and outcomes <Ch02_StudyDesign_4>`: What roles "
"do variables play in an analysis? Can you remember the difference between "
"predictors and outcomes? Dependent and independent variables? etc."
msgstr ""
":doc:`Terminologi: prediktorer og utfall <Ch02_StudyDesign_4>`: Hvilke "
"roller spiller variabler i en analyse? Kan du huske forskjellen mellom "
"prediktorer og utfall? Avhengige og uavhengige variabler? osv."

#: ../../Ch02/Ch02_StudyDesign_7.rst:31
msgid ""
":doc:`Experimental and non-experimental research designs "
"<Ch02_StudyDesign_5>`: What makes an experiment an experiment? Is it a nice "
"white lab coat, or does it have something to do with researcher control over "
"variables?"
msgstr ""
":doc:`Eksperimentelle og ikke-eksperimentelle forskningsdesign "
"<Ch02_StudyDesign_5>`: Hva gjør et eksperiment til et eksperiment? Er det en "
"fin hvit labfrakk, eller har det noe å gjøre med forskerens kontroll over "
"variabler?"

#: ../../Ch02/Ch02_StudyDesign_7.rst:36
msgid ""
":doc:`Validity and its threats <Ch02_StudyDesign_6>`: Does your study "
"measure what you want it to? How might things go wrong? And is it my "
"imagination, or was that a very long list of possible ways in which things "
"can go wrong?"
msgstr ""
":doc:`Validitet og dens trusler <Ch02_StudyDesign_6>`: Måler studien det du "
"ønsker at den skal måle? Hvordan kan ting gå galt? Og er det bare noe jeg "
"innbiller meg, eller var det en veldig lang liste over mulige måter ting kan "
"gå galt på?"

#: ../../Ch02/Ch02_StudyDesign_7.rst:41
msgid ""
"All this should make clear to you that study design is a critical part of "
"research methodology. I built this chapter from the classic little book by :"
"ref:`Campbell and Stanley (1963) <Campbell_1963>`, but there are of course a "
"large number of textbooks out there on research design. Spend a few minutes "
"with your favourite search engine and you’ll find dozens."
msgstr ""
"Alt dette burde gjøre det klart for deg at studiedesign er en kritisk del av "
"forskningsmetodikken. Jeg har bygget dette kapittelet på den klassiske lille "
"boken til :ref:`Campbell og Stanley (1963) <Campbell_1963>`, men det finnes "
"selvsagt et stort antall lærebøker der ute om forskningsdesign. Bruk noen "
"minutter med din favorittsøkemotor, og du vil finne dusinvis."
