#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Learning statistics with jamovi\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-08-12 22:11+0200\n"
"PO-Revision-Date: 2024-08-08 16:32+0200\n"
"Last-Translator: Sebastian Jentschke <sebastian.jentschke@uib.no>\n"
"Language-Team: \n"
"Language: nb\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.3\n"
"X-Generator: Poedit 3.5\n"

#: ../../Ch07/Ch07_Probability.rst:4
msgid "Introduction to probability"
msgstr "Introduksjon til sannsynlighetsregning"

#: ../../Ch07/Ch07_Probability.rst:0
msgid "*[God] has afforded us only the twilight … of Probability.*"
msgstr "*[Gud] har bare gitt oss skumringen … av sannsynlighet.*"

#: ../../Ch07/Ch07_Probability.rst:23
msgid "John Locke"
msgstr "John Locke"

#: ../../Ch07/Ch07_Probability.rst:25
msgid ""
"Up to this point in the book we’ve discussed some of the key ideas in "
"experimental design, and we’ve talked a little about how you can summarise a "
"data set. To a lot of people this is all there is to statistics: collecting "
"all the numbers, calculating averages, drawing pictures, and putting them "
"all in a report somewhere. Kind of like stamp collecting but with numbers. "
"However, statistics covers much more than that. In fact, descriptive "
"statistics is one of the smallest parts of statistics and one of the least "
"powerful. The bigger and more useful part of statistics is that it provides "
"information that lets you make inferences about data."
msgstr ""
"Så langt i boken har vi diskutert noen av de viktigste ideene i "
"forsøksdesign, og vi har snakket litt om hvordan du kan oppsummere et "
"datasett. For mange er dette alt som finnes av statistikk: å samle inn alle "
"tallene, beregne gjennomsnitt, tegne bilder og sette dem inn i en rapport. "
"Litt som frimerkesamling, men med tall. Statistikk dekker imidlertid mye mer "
"enn det. Faktisk er deskriptivstatistikk en av de minste delene av "
"statistikken, og en av de minst effektive. Den større og mer nyttige delen "
"av statistikken er at den gir informasjon som gjør det mulig å trekke "
"slutninger om data."

#: ../../Ch07/Ch07_Probability.rst:36
msgid ""
"Once you start thinking about statistics in these terms, that statistics is "
"there to help us draw inferences from data, you start seeing examples of it "
"everywhere. For instance, here’s a tiny extract from a newspaper article in "
"the Sydney Morning Herald (30 Oct 2010):"
msgstr ""
"Når man begynner å tenke på statistikk på denne måten, at statistikk er til "
"for å hjelpe oss med å trekke slutninger fra data, ser man eksempler på det "
"overalt. Her er for eksempel et lite utdrag fra en avisartikkel i Sydney "
"Morning Herald (30. oktober 2010):"

#: ../../Ch07/Ch07_Probability.rst:41
msgid ""
"“I have a tough job,” the Premier said in response to a poll which found her "
"government is now the most unpopular Labor administration in polling "
"history, with a primary vote of just 23 per cent."
msgstr ""
"«Jeg har en tøff jobb», sa statsministeren som svar på en meningsmåling som "
"viste at hennes regjering nå er den mest upopulære Labour-regjeringen i "
"meningsmålingens historie, med en oppslutning på bare 23 prosent."

#: ../../Ch07/Ch07_Probability.rst:45
msgid ""
"This kind of remark is entirely unremarkable in the papers or in everyday "
"life, but let’s have a think about what it entails. A polling company has "
"conducted a survey, usually a pretty big one because they can afford it. I’m "
"too lazy to track down the original survey so let’s just imagine that they "
"called 1000 New South Wales (NSW) voters at random, and 230 (23\\%) of those "
"claimed that they intended to vote for the Australian Labor Party (ALP). For "
"the 2010 Federal election the Australian Electoral Commission reported "
"4,610,795 enrolled voters in NSW, so the opinions of the remaining 4,609,795 "
"voters (about 99.98\\% of voters) remain unknown to us. Even assuming that "
"no-one lied to the polling company the only thing we can say with 100\\% "
"confidence is that the true ALP primary vote is somewhere between "
"230/4610795 (about \\0.005\\%) and 4610025/4610795 (about 99.83\\%). So, on "
"what basis is it legitimate for the polling company, the newspaper, and the "
"readership to conclude that the ALP primary vote is only about 23\\%?"
msgstr ""
"Denne typen bemerkninger er helt upåfallende i avisene eller i dagliglivet, "
"men la oss tenke litt på hva det innebærer. Et meningsmålingsinstitutt har "
"gjennomført en undersøkelse, som regel en ganske stor en, fordi de har råd "
"til det. Jeg er for lat til å finne den opprinnelige undersøkelsen, så la "
"oss bare tenke oss at de ringte 1000 tilfeldige velgere i New South Wales "
"(NSW), og at 230 (23\\%) av disse hevdet at de hadde tenkt å stemme på "
"Australian Labor Party (ALP). For det føderale valget i 2010 rapporterte den "
"australske valgkommisjonen 4 610 795 registrerte velgere i NSW, så meningene "
"til de resterende 4 609 795 velgerne (ca. 99,98\\% av velgerne) forblir "
"ukjente for oss. Selv om vi antar at ingen har løyet til "
"meningsmålingsinstituttet, er det eneste vi kan si med 100\\% sikkerhet at "
"det sanne antallet primærstemmer til ALP ligger et sted mellom 230/4610795 "
"(ca. \\0,005\\%) og 4610025/4610795 (ca. 99,83\\%). Så på hvilket grunnlag "
"er det legitimt for meningsmålingsinstituttet, avisen og leserne å "
"konkludere med at Aps primærstemmer bare ligger på ca. 23\\%?"

#: ../../Ch07/Ch07_Probability.rst:61
msgid ""
"The answer to the question is pretty obvious. If I call 1000 people at "
"random, and 230 of them say they intend to vote for the ALP, then it seems "
"very unlikely that these are the *only* 230 people out of the entire voting "
"public who actually intend to vote ALP. In other words, we assume that the "
"data collected by the polling company is pretty representative of the "
"population at large. But how representative? Would we be surprised to "
"discover that the true ALP primary vote is actually 24\\%? 29\\%? 37\\%? At "
"this point everyday intuition starts to break down a bit. No-one would be "
"surprised by 24\\%, and everybody would be surprised by 37\\%, but it’s a "
"bit hard to say whether 29\\% is plausible. We need some more powerful tools "
"than just looking at the numbers and guessing."
msgstr ""
"Svaret på spørsmålet er ganske åpenbart. Hvis jeg ringer 1000 tilfeldige "
"personer, og 230 av dem sier at de har tenkt å stemme på ALP, så virker det "
"svært usannsynlig at det *kun* er disse 230 personene av hele den "
"stemmeberettigede befolkningen som faktisk har tenkt å stemme på ALP. Med "
"andre ord antar vi at dataene som er samlet inn av meningsmålingsinstituttet "
"er ganske representative for befolkningen som helhet. Men hvor "
"representative? Ville vi bli overrasket om vi oppdaget at den sanne "
"oppslutningen om ALP faktisk er 24\\%? 29\\%? 37\\%? På dette punktet "
"begynner hverdagsintuisjonen å bryte litt sammen. Ingen ville blitt "
"overrasket over 24\\%, og alle ville blitt overrasket over 37\\%, men det er "
"litt vanskelig å si om 29\\% er plausibelt. Vi trenger noen kraftigere "
"verktøy enn bare å se på tallene og gjette."

#: ../../Ch07/Ch07_Probability.rst:73
msgid ""
"**Inferential statistics** provides the tools that we need to answer these "
"sorts of questions, and since these kinds of questions lie at the heart of "
"the scientific enterprise, they take up the lions share of every "
"introductory course on statistics and research methods. However, the theory "
"of statistical inference is built on top of **probability theory**. And it "
"is to probability theory that we must now turn. This discussion of "
"probability theory is basically background detail. There’s not a lot of "
"statistics per se in this chapter, and you don’t need to understand this "
"material in as much depth as the other chapters in this part of the book. "
"Nevertheless, because probability theory does underpin so much of "
"statistics, it’s worth covering some of the basics."
msgstr ""
"**Inferensstatistikk** gir oss de verktøyene vi trenger for å besvare slike "
"spørsmål, og siden denne typen spørsmål er selve kjernen i den "
"vitenskapelige virksomheten, opptar de en stor del av alle innføringskurs i "
"statistikk og forskningsmetoder. Teorien om statistisk inferens bygger "
"imidlertid på **sannsynlighetsteori**. Og det er til sannsynlighetsteorien "
"vi nå må vende oss. Denne diskusjonen om sannsynlighetsteori er i "
"utgangspunktet bakgrunnsinformasjon. Det er ikke mye statistikk i seg selv i "
"dette kapittelet, og du trenger ikke å forstå dette stoffet like inngående "
"som i de andre kapitlene i denne delen av boken. Men siden "
"sannsynlighetsteori ligger til grunn for så mye av statistikken, er det "
"likevel verdt å gå gjennom noe av det grunnleggende."

#: ../../Ch07/Ch07_Probability_1.rst:4
msgid "How are probability and statistics different?"
msgstr "Hva er forskjellen på sannsynlighet og statistikk?"

#: ../../Ch07/Ch07_Probability_1.rst:6
msgid ""
"Before we start talking about probability theory, it’s helpful to spend a "
"moment thinking about the relationship between probability and statistics. "
"The two disciplines are closely related but they’re not identical. "
"Probability theory is “the doctrine of chances”. It’s a branch of "
"mathematics that tells you how often different kinds of events will happen. "
"For example, all of these questions are things you can answer using "
"probability theory:"
msgstr ""
"Før vi begynner å snakke om sannsynlighetsteori, er det nyttig å bruke et "
"øyeblikk på å tenke over forholdet mellom sannsynlighetsregning og "
"statistikk. De to fagområdene er nært beslektet, men de er ikke identiske. "
"Sannsynlighetsteori er «læren om sjanser». Det er en gren av matematikken "
"som forteller deg hvor ofte ulike typer hendelser vil inntreffe. Alle disse "
"spørsmålene er for eksempel ting du kan svare på ved hjelp av "
"sannsynlighetsteori:"

#: ../../Ch07/Ch07_Probability_1.rst:14
msgid "What are the chances of a fair coin coming up heads 10 times in a row?"
msgstr ""
"Hvor stor er sjansen for at en rettferdig mynt slår kron 10 ganger på rad?"

#: ../../Ch07/Ch07_Probability_1.rst:17
msgid ""
"If I roll a six sided dice twice, how likely is it that I’ll roll two sixes?"
msgstr ""
"Hvis jeg kaster en sekssidig terning to ganger, hvor sannsynlig er det da at "
"jeg slår to seksere?"

#: ../../Ch07/Ch07_Probability_1.rst:20
msgid ""
"How likely is it that five cards drawn from a perfectly shuffled deck will "
"all be hearts?"
msgstr ""
"Hvor sannsynlig er det at fem kort som trekkes fra en perfekt blandet "
"kortstokk, alle er hjerter?"

#: ../../Ch07/Ch07_Probability_1.rst:23
msgid "What are the chances that I’ll win the lottery?"
msgstr "Hvor stor er sjansen for at jeg vinner i lotto?"

#: ../../Ch07/Ch07_Probability_1.rst:25
msgid ""
"Notice that all of these questions have something in common. In each case "
"the “truth of the world” is known and my question relates to the “what kind "
"of events” will happen. In the first question I *know* that the coin is fair "
"so there’s a 50\\% chance that any individual coin flip will come up heads. "
"In the second question I *know* that the chance of rolling a 6 on a single "
"die is 1 in 6. In the third question I *know* that the deck is shuffled "
"properly. And in the fourth question I *know* that the lottery follows "
"specific rules. You get the idea. The critical point is that probabilistic "
"questions start with a known **model** of the world, and we use that model "
"to do some calculations. The underlying model can be quite simple. For "
"instance, in the coin flipping example we can write down the model like this:"
msgstr ""
"Legg merke til at alle disse spørsmålene har noe til felles. I hvert "
"tilfelle er «sannheten om verden» kjent, og spørsmålet mitt er knyttet til "
"«hva slags hendelser» som vil inntreffe. I det første spørsmålet *vet* jeg "
"at mynten er rettferdig, slik at det er 50\\% sjanse for at et enkelt "
"myntkast vil gi krone. I det andre spørsmålet *vet* jeg at sjansen for å slå "
"6 på en terning er 1 av 6. I det tredje spørsmålet *vet* jeg at kortstokken "
"er riktig blandet. Og i det fjerde spørsmålet *vet* jeg at lotteriet følger "
"bestemte regler. Du skjønner hva jeg mener. Det kritiske poenget er at "
"sannsynlighetsteoretiske spørsmål starter med en kjent **modell** av verden, "
"og at vi bruker denne modellen til å gjøre noen beregninger. Den "
"underliggende modellen kan være ganske enkel. I eksemplet med myntkasting "
"kan vi for eksempel skrive ned modellen slik:"

#: ../../Ch07/Ch07_Probability_1.rst:38
msgid "*P*\\ (heads) = *0.5*"
msgstr "*P*\\(hoder) = *0,5*"

#: ../../Ch07/Ch07_Probability_1.rst:40
msgid ""
"which you can read as “the probability of heads is 0.5”. As we’ll see later, "
"in the same way that percentages are numbers that range from 0\\% to 100\\%, "
"probabilities are just numbers that range from 0 to 1. When using this "
"probability model to answer the first question I don’t actually know exactly "
"what’s going to happen. Maybe I’ll get 10 heads, like the question says. But "
"maybe I’ll get three heads. That’s the key thing. In probability theory the "
"*model* is known but the *data* are not."
msgstr ""
"som du kan lese som «sannsynligheten for krone er 0,5». Som vi skal se "
"senere, er sannsynligheter, på samme måte som prosenter er tall som varierer "
"fra 0\\% til 100\\%, bare tall som varierer fra 0 til 1. Når jeg bruker "
"denne sannsynlighetsmodellen til å svare på det første spørsmålet, vet jeg "
"faktisk ikke nøyaktig hva som kommer til å skje. Kanskje får jeg ti hoder, "
"slik spørsmålet sier. Men kanskje jeg får tre kron. Det er det som er "
"nøkkelen. I sannsynlighetsteori er *modellen* kjent, men *dataene* er det "
"ikke."

#: ../../Ch07/Ch07_Probability_1.rst:49
msgid ""
"So that’s probability. What about statistics? Statistical questions work the "
"other way around. In statistics we do not know the truth about the world. "
"All we have is the data and it is from the data that we want to *learn* the "
"truth about the world. Statistical questions tend to look more like these:"
msgstr ""
"Så det er sannsynlighet. Hva med statistikk? Statistiske spørsmål fungerer "
"omvendt. I statistikk vet vi ikke sannheten om verden. Alt vi har, er data, "
"og det er ut fra dataene vi ønsker å *lære* sannheten om verden. Statistiske "
"spørsmål ser gjerne ut som disse:"

#: ../../Ch07/Ch07_Probability_1.rst:55
msgid ""
"If my friend flips a coin 10 times and gets 10 heads are they playing a "
"trick on me?"
msgstr ""
"Hvis vennen min kaster en mynt 10 ganger og får 10 kron, spiller han meg et "
"puss?"

#: ../../Ch07/Ch07_Probability_1.rst:58
msgid ""
"If five cards off the top of the deck are all hearts how likely is it that "
"the deck was shuffled?"
msgstr ""
"Hvis fem kort fra toppen av kortstokken er hjerter, hvor sannsynlig er det "
"da at kortstokken ble blandet?"

#: ../../Ch07/Ch07_Probability_1.rst:61
msgid ""
"If the lottery commissioner’s spouse wins the lottery how likely is it that "
"the lottery was rigged?"
msgstr ""
"Hvis lotterikommisjonærens ektefelle vinner i lotteriet, hvor sannsynlig er "
"det da at lotteriet var rigget?"

#: ../../Ch07/Ch07_Probability_1.rst:64
msgid ""
"This time around the only thing we have are data. What I *know* is that I "
"saw my friend flip the coin 10 times and it came up heads every time. And "
"what I want to **infer** is whether or not I should conclude that what I "
"just saw was actually a fair coin being flipped 10 times in a row, or "
"whether I should suspect that my friend is playing a trick on me. The data I "
"have look like this:"
msgstr ""
"Denne gangen har vi bare data. Det jeg *vet* er at jeg så vennen min kaste "
"mynten 10 ganger, og at den ble krone hver gang. Og det jeg ønsker å "
"**avgjøre**, er om jeg bør konkludere med at det jeg nettopp så, faktisk var "
"en rettferdig mynt som ble kastet 10 ganger på rad, eller om jeg bør "
"mistenke at vennen min spiller meg et puss. Dataene jeg har ser slik ut:"

#: ../../Ch07/Ch07_Probability_1.rst:75
msgid ""
"and what I’m trying to do is work out which “model of the world” I should "
"put my trust in. If the coin is fair then the model I should adopt is one "
"that says that the probability of heads is 0.5, that is *P*\\ (heads) = "
"*0.5*. If the coin is not fair then I should conclude that the probability "
"of heads is *not* 0.5, which we would write as *P*\\ (heads) ≠ *0.5*. In "
"other words, the statistical inference problem is to figure out which of "
"these probability models is right. Clearly, the statistical question isn’t "
"the same as the probability question, but they’re deeply connected to one "
"another. Because of this, a good introduction to statistical theory will "
"start with a discussion of what probability is and how it works."
msgstr ""
"og jeg prøver å finne ut hvilken «modell av verden» jeg skal stole på. Hvis "
"mynten er rettferdig, bør jeg velge en modell som sier at sannsynligheten "
"for krone er 0,5, det vil si *P*\\(krone) = *0,5*. Hvis mynten ikke er "
"rettferdig, bør jeg konkludere med at sannsynligheten for krone *ikke* er "
"0,5, noe vi kan skrive som *P*\\ (krone) ≠ *0,5*. Med andre ord er det "
"statistiske inferensproblemet å finne ut hvilken av disse "
"sannsynlighetsmodellene som er riktig. Det statistiske spørsmålet er "
"selvsagt ikke det samme som sannsynlighetsspørsmålet, men de er nært knyttet "
"til hverandre. Derfor vil en god innføring i statistisk teori starte med en "
"diskusjon om hva sannsynlighet er og hvordan det fungerer."

#: ../../Ch07/Ch07_Probability_2.rst:4
msgid "What does probability mean?"
msgstr "Hva betyr sannsynlighet?"

#: ../../Ch07/Ch07_Probability_2.rst:6
msgid ""
"Let’s start with the first of these questions. What is “probability”? It "
"might seem surprising to you but while statisticians and mathematicians "
"(mostly) agree on what the *rules* of probability are, there’s much less of "
"a consensus on what the word really *means*. It seems weird because we’re "
"all very comfortable using words like “chance”, “likely”, “possible” and "
"“probable”, and it doesn’t seem like it should be a very difficult question "
"to answer. But if you’ve ever had that experience in real life you might "
"walk away from the conversation feeling like you didn’t quite get it right, "
"and that (like many everyday concepts) it turns out that you don’t *really* "
"know what it’s all about."
msgstr ""
"La oss begynne med det første av disse spørsmålene. Hva er «sannsynlighet»? "
"Det kan virke overraskende, men selv om statistikere og matematikere (stort "
"sett) er enige om hva *reglene* for sannsynlighet er, er det mye mindre "
"enighet om hva ordet egentlig *betyr*. Det virker rart, for vi er alle "
"veldig komfortable med å bruke ord som «sjanse», «sannsynlig», «mulig» og "
"«sannsynlig», og det virker ikke som om det burde være et veldig vanskelig "
"spørsmål å svare på. Men hvis du noen gang har opplevd det i det virkelige "
"liv, kan det hende at du går fra samtalen med en følelse av at du ikke helt "
"fikk det med deg, og at det (i likhet med mange hverdagsbegreper) viser seg "
"at du ikke *virkelig* vet hva det handler om."

#: ../../Ch07/Ch07_Probability_2.rst:17
msgid ""
"So I’ll have a go at it. Let’s suppose I want to bet on a soccer game "
"between two teams of robots, *Arduino Arsenal* and *C Milan*. After thinking "
"about it, I decide that there is an 80\\% probability of *Arduino Arsenal* "
"winning. What do I mean by that? Here are three possibilities:"
msgstr ""
"Så jeg skal prøve meg på det. La oss anta at jeg ønsker å vedde på en "
"fotballkamp mellom to robotlag, *Arduino Arsenal* og *C Milan*. Etter å ha "
"tenkt meg om kommer jeg frem til at det er 80\\% sannsynlighet for at "
"*Arduino Arsenal* vinner. Hva mener jeg med det? Her er tre muligheter:"

#: ../../Ch07/Ch07_Probability_2.rst:22
msgid ""
"They’re robot teams so I can make them play over and over again, and if I "
"did that *Arduino Arsenal* would win 8 out of every 10 games on average."
msgstr ""
"De er robotlag, så jeg kan få dem til å spille om og om igjen, og hvis jeg "
"gjorde det, ville *Arduino Arsenal* vunnet 8 av 10 kamper i gjennomsnitt."

#: ../../Ch07/Ch07_Probability_2.rst:26
msgid ""
"For any given game, I would agree that betting on this game is only “fair” "
"if a $1 bet on *C Milan* gives a $5 payoff (i.e. I get my $1 back plus a $4 "
"reward for being correct), as would a $4 bet on *Arduino Arsenal* (i.e., my "
"$4 bet plus a $1 reward)."
msgstr ""
"For et gitt spill er jeg enig i at spill på dette spillet bare er "
"«rettferdig» hvis et spill på 1 dollar på *C Milan* gir 5 dollar i gevinst "
"(dvs. jeg får tilbake 1 dollar pluss en belønning på 4 dollar for å ha hatt "
"rett), og det samme gjelder et spill på 4 dollar på *Arduino Arsenal* (dvs. "
"min innsats på 4 dollar pluss en belønning på 1 dollar)."

#: ../../Ch07/Ch07_Probability_2.rst:31
msgid ""
"My subjective “belief” or “confidence” in an *Arduino Arsenal* victory is "
"four times as strong as my belief in a *C Milan* victory."
msgstr ""
"Min subjektive «tro» eller «tillit» til en *Arduino Arsenal*-seier er fire "
"ganger så sterk som min tro på en *C Milan*-seier."

#: ../../Ch07/Ch07_Probability_2.rst:34
msgid ""
"Each of these seems sensible. However, they’re not identical and not every "
"statistician would endorse all of them. The reason is that there are "
"different statistical ideologies (yes, really!) and depending on which one "
"you subscribe to, you might say that some of those statements are "
"meaningless or irrelevant. In this section I give a brief introduction the "
"two main approaches that exist in the literature. These are by no means the "
"only approaches, but they’re the two big ones."
msgstr ""
"Hver av disse virker fornuftige. De er imidlertid ikke identiske, og ikke "
"alle statistikere vil slutte seg til dem alle. Årsaken er at det finnes "
"ulike statistiske ideologier (ja, virkelig!), og avhengig av hvilken "
"ideologi du tilhører, vil du kanskje si at noen av disse utsagnene er "
"meningsløse eller irrelevante. I dette avsnittet gir jeg en kort innføring i "
"de to hovedtilnærmingene som finnes i litteraturen. Dette er på ingen måte "
"de eneste tilnærmingene, men det er de to viktigste."

#: ../../Ch07/Ch07_Probability_2.rst:43
msgid "The frequentist view"
msgstr "Det frekventistiske synet"

#: ../../Ch07/Ch07_Probability_2.rst:45
msgid ""
"The first of the two major approaches to probability, and the more dominant "
"one in statistics, is referred to as the **frequentist view** and it defines "
"probability as a **long-run frequency**. Suppose we were to try flipping a "
"fair coin over and over again. By definition this is a coin that has "
"*P*\\(H) = *0.5*. What might we observe? One possibility is that the first "
"20 flips might look like this:"
msgstr ""
"Den første av de to hovedtilnærmingene til sannsynlighet, og den mest "
"dominerende innen statistikk, kalles **frekventistisk syn**, og definerer "
"sannsynlighet som en **langsiktig frekvens**. Anta at vi prøver å kaste en "
"rettferdig mynt om og om igjen. Per definisjon er dette en mynt som har "
"*P*\\(H) = *0,5*. Hva kan vi observere? En mulighet er at de første 20 "
"kastene kan se slik ut:"

#: ../../Ch07/Ch07_Probability_2.rst:56
msgid ""
"In this case 11 of these 20 coin flips (55\\%) came up heads. Now suppose "
"that I’d been keeping a running tally of the number of heads (which I’ll "
"call *N*\\ :sub:`H`\\ ) that I’ve seen, across the first *N* flips, and "
"calculate the proportion of heads *N*\\ :sub:`H` / *N* every time. Here’s "
"what I’d get (I did literally flip coins to produce this!):"
msgstr ""
"I dette tilfellet ble 11 av disse 20 myntkastene (55\\%) kron. Anta nå at "
"jeg hadde ført en løpende oversikt over antall kron (som jeg kaller *N*\\ :"
"sub:`H`\\) som jeg har sett, på tvers av de første *N* kastene, og beregnet "
"andelen kron *N*\\ :sub:`H` / *N* hver gang. Her er hva jeg ville fått (jeg "
"har bokstavelig talt kastet mynter for å produsere dette!):"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:71
msgid "number of flips"
msgstr "antall flips"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "1"
msgstr "1"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "2"
msgstr "2"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "3"
msgstr "3"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "4"
msgstr "4"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "5"
msgstr "5"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "6"
msgstr "6"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:65
msgid "7"
msgstr "7"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:73
msgid "8"
msgstr "8"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:73
msgid "9"
msgstr "9"

#: ../../Ch07/Ch07_Probability_2.rst:63 ../../Ch07/Ch07_Probability_2.rst:73
msgid "10"
msgstr "10"

#: ../../Ch07/Ch07_Probability_2.rst:65 ../../Ch07/Ch07_Probability_2.rst:73
msgid "**number of heads**"
msgstr "**antall hoder**"

#: ../../Ch07/Ch07_Probability_2.rst:65
msgid "0"
msgstr "0"

#: ../../Ch07/Ch07_Probability_2.rst:67 ../../Ch07/Ch07_Probability_2.rst:75
msgid "**proportion**"
msgstr "**proporsjon**"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.00"
msgstr "0.00"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.50"
msgstr "0.50"

#: ../../Ch07/Ch07_Probability_2.rst:67 ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.67"
msgstr "0.67"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.75"
msgstr "0.75"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.80"
msgstr "0.80"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.57"
msgstr "0.57"

#: ../../Ch07/Ch07_Probability_2.rst:67 ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.63"
msgstr "0.63"

#: ../../Ch07/Ch07_Probability_2.rst:67
msgid "0.70"
msgstr "0.70"

#: ../../Ch07/Ch07_Probability_2.rst:71 ../../Ch07/Ch07_Probability_2.rst:73
msgid "11"
msgstr "11"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "12"
msgstr "12"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "13"
msgstr "13"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "14"
msgstr "14"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "15"
msgstr "15"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "16"
msgstr "16"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "17"
msgstr "17"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "18"
msgstr "18"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "19"
msgstr "19"

#: ../../Ch07/Ch07_Probability_2.rst:71
msgid "20"
msgstr "20"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.73"
msgstr "0.73"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.69"
msgstr "0.69"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.71"
msgstr "0.71"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.59"
msgstr "0.59"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.56"
msgstr "0.56"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.53"
msgstr "0.53"

#: ../../Ch07/Ch07_Probability_2.rst:75
msgid "0.55"
msgstr "0.55"

#: ../../Ch07/Ch07_Probability_2.rst:78
msgid ""
"Notice that at the start of the sequence the *proportion* of heads "
"fluctuates wildly, starting at 0.00 and rising as high as 0.80. Later on, "
"one gets the impression that it dampens out a bit, with more and more of the "
"values actually being pretty close to the “right” answer of 0.50. This is "
"the frequentist definition of probability in a nutshell. Flip a fair coin "
"over and over again, and as *N* grows large (approaches infinity, denoted "
"*N* → ∞) the proportion of heads will converge to 50\\%. There are some "
"subtle technicalities that the mathematicians care about, but qualitatively "
"speaking that’s how the frequentists define probability. Unfortunately, I "
"don’t have an infinite number of coins or the infinite patience required to "
"flip a coin an infinite number of times. However, I do have a computer and "
"computers excel at mindless repetitive tasks. So I asked my computer to "
"simulate flipping a coin 1000 times and then drew a picture of what happens "
"to the proportion *N*\\ :sub:`H` / *N* as *N* increases. Actually, I did it "
"four times just to make sure it wasn’t a fluke. The results are shown in :"
"numref:`fig-frequentistProb`. As you can see, the *proportion of observed "
"heads* eventually stops fluctuating and settles down. When it does, the "
"number at which it finally settles is the true probability of heads."
msgstr ""
"Legg merke til at i starten av sekvensen svinger *andelen* hoder voldsomt, "
"fra 0,00 og helt opp til 0,80. Senere får man inntrykk av at det roer seg "
"litt ned, og at flere og flere av verdiene faktisk ligger ganske nær det "
"«riktige» svaret på 0,50. Dette er den frekventistiske definisjonen av "
"sannsynlighet i et nøtteskall. Kast en rettferdig mynt om og om igjen, og "
"etter hvert som *N* blir større (nærmer seg uendelig, betegnet *N* → ∞), vil "
"andelen kron konvergere mot 50\\%. Det er noen subtile teknikaliteter som "
"matematikerne bryr seg om, men kvalitativt sett er det slik frekvenstikerne "
"definerer sannsynlighet. Dessverre har jeg ikke et uendelig antall mynter "
"eller den uendelige tålmodigheten som kreves for å kaste en mynt uendelig "
"mange ganger. Men jeg har en datamaskin, og datamaskiner er gode på "
"tankeløse, repetitive oppgaver. Så jeg ba datamaskinen min om å simulere å "
"kaste en mynt 1000 ganger, og tegnet deretter et bilde av hva som skjer med "
"proporsjonen *N*\\ :sub:`H` / *N* når *N* øker. Jeg gjorde det faktisk fire "
"ganger, bare for å være sikker på at det ikke var tilfeldig. Resultatene "
"vises i :numref:`fig-frequentistProb`. Som du kan se, slutter *andelen av "
"observerte hoder* til slutt å svinge og stabiliserer seg. Når den gjør det, "
"er tallet den til slutt stabiliserer seg på, den sanne sannsynligheten for "
"kron."

#: ../../Ch07/Ch07_Probability_2.rst:104
msgid "Illustration of how frequentist probability works"
msgstr "Illustrasjon av hvordan frekventistisk sannsynlighetsregning fungerer"

#: ../../Ch07/Ch07_Probability_2.rst:104
msgid ""
"Illustration of how frequentist probability works: If you flip a fair coin "
"over and over again the proportion of heads that you’ve seen eventually "
"settles down and converges to the true probability of 0.5. Each panel shows "
"four different simulated experiments. In each case we pretend we flipped a "
"coin 1000 times and kept track of the proportion of flips that were heads as "
"we went along. Although none of these sequences actually ended up with an "
"exact value of 0.5, if we’d extended the experiment for an infinite number "
"of coin flips they would have."
msgstr ""
"Illustrasjon av hvordan frekventistisk sannsynlighetsregning fungerer: Hvis "
"du kaster en rettferdig mynt om og om igjen, vil andelen kron etter hvert "
"stabilisere seg og konvergere mot den sanne sannsynligheten på 0,5. Hvert "
"panel viser fire ulike simulerte eksperimenter. I hvert tilfelle later vi "
"som om vi har kastet en mynt 1000 ganger og holdt styr på andelen av kastene "
"som var kron underveis. Selv om ingen av disse sekvensene faktisk endte opp "
"med en nøyaktig verdi på 0,5, ville de ha gjort det hvis vi hadde forlenget "
"eksperimentet med et uendelig antall myntkast."

#: ../../Ch07/Ch07_Probability_2.rst:115
msgid ""
"The frequentist definition of probability has some desirable "
"characteristics. First, it is objective. The probability of an event is "
"*necessarily* grounded in the world. The only way that probability "
"statements can make sense is if they refer to (a sequence of) events that "
"occur in the physical universe.\\ [#]_ Secondly, it is unambiguous. Any two "
"people watching the same sequence of events unfold, trying to calculate the "
"probability of an event, must inevitably come up with the same answer."
msgstr ""
"Den frekventistiske definisjonen av sannsynlighet har noen ønskelige "
"egenskaper. For det første er den objektiv. Sannsynligheten for en hendelse "
"er *nødvendigvis* forankret i verden. Sannsynlighetsutsagn kan bare gi "
"mening hvis de refererer til (en sekvens av) hendelser som inntreffer i det "
"fysiske universet.\\ [#]_ For det andre er den entydig. To personer som ser "
"på det samme hendelsesforløpet og forsøker å beregne sannsynligheten for en "
"hendelse, vil uunngåelig komme frem til samme svar."

#: ../../Ch07/Ch07_Probability_2.rst:124
msgid ""
"However, it also has undesirable characteristics. First, infinite sequences "
"don’t exist in the physical world. Suppose you picked up a coin from your "
"pocket and started to flip it. Every time it lands it impacts on the ground. "
"Each impact wears the coin down a bit. Eventually the coin will be "
"destroyed. So, one might ask whether it really makes sense to pretend that "
"an “infinite” sequence of coin flips is even a meaningful concept, or an "
"objective one. We can’t say that an “infinite sequence” of events is a real "
"thing in the physical universe, because the physical universe doesn’t allow "
"infinite anything. More seriously, the frequentist definition has a narrow "
"scope. There are lots of things out there that human beings are happy to "
"assign probability to in everyday language, but cannot (even in theory) be "
"mapped onto a hypothetical sequence of events. For instance, if a "
"meteorologist comes on TV and says “the probability of rain in Adelaide on 2 "
"November 2048 is 60\\%” we humans are happy to accept this. But it’s not "
"clear how to define this in frequentist terms. There’s only one city of "
"Adelaide, and only one 2 November 2048. There’s no infinite sequence of "
"events here, just a one-off thing. Frequentist probability genuinely "
"*forbids* us from making probability statements about a single event. From "
"the frequentist perspective it will either rain tomorrow or it will not. "
"There is no “probability” that attaches to a single non-repeatable event. "
"Now, it should be said that there are some very clever tricks that "
"frequentists can use to get around this. One possibility is that what the "
"meteorologist means is something like “There is a category of days for which "
"I predict a 60\\% chance of rain, and if we look only across those days for "
"which I make this prediction, then on 60\\% of those days it will actually "
"rain”. It’s very weird and counterintuitive to think of it this way, but you "
"do see frequentists do this sometimes. And it *will* come up later in this "
"book (see :doc:`../Ch08/Ch08_Estimation_5`)."
msgstr ""
"Men den har også uønskede egenskaper. For det første finnes det ikke "
"uendelige sekvenser i den fysiske verden. Tenk deg at du tar opp en mynt fra "
"lommen og begynner å kaste den. Hver gang den lander, treffer den bakken. "
"Hver gang den treffer bakken, slites mynten litt ned. Til slutt vil mynten "
"bli ødelagt. Man kan spørre seg om det virkelig gir mening å late som om en "
"«uendelig» rekke av myntkast i det hele tatt er et meningsfylt eller "
"objektivt begrep. Vi kan ikke si at en «uendelig rekkefølge» av hendelser er "
"en reell ting i det fysiske universet, fordi det fysiske universet ikke "
"tillater uendelig noe som helst. Mer alvorlig er det at den frekventistiske "
"definisjonen har et snevert omfang. Det finnes mange ting der ute som vi "
"mennesker gjerne tillegger sannsynlighet i dagligtalen, men som ikke (selv "
"ikke i teorien) kan knyttes til en hypotetisk rekkefølge av hendelser. Hvis "
"for eksempel en meteorolog kommer på TV og sier at «sannsynligheten for regn "
"i Adelaide 2. november 2048 er 60\\%», aksepterer vi mennesker gjerne dette. "
"Men det er ikke klart hvordan vi skal definere dette i frekventistiske "
"termer. Det finnes bare én by, Adelaide, og bare én 2. november 2048. Det er "
"ingen uendelig rekkefølge av hendelser her, bare en engangshendelse. "
"Frekventistisk sannsynlighetsregning *forbyr* oss å si noe om "
"sannsynligheten for en enkelt hendelse. Fra et frekventistisk perspektiv vil "
"det enten regne i morgen, eller så vil det ikke regne. Det er ingen "
"«sannsynlighet» knyttet til en enkeltstående hendelse som ikke kan gjentas. "
"Nå skal det sies at det finnes noen veldig smarte triks som frekventister "
"kan bruke for å komme rundt dette. En mulighet er at meteorologen mener noe "
"sånt som «Det finnes en kategori av dager der jeg spår 60\\% sjanse for "
"regn, og hvis vi bare ser på de dagene jeg spår dette for, så vil det "
"faktisk regne 60\\% av disse dagene». Det er veldig rart og kontraintuitivt "
"å tenke på det på denne måten, men du ser at frekventister gjør dette noen "
"ganger. Og det *vil* komme opp senere i denne boken (se :doc:`../Ch08/"
"Ch08_Estimation_5`)."

#: ../../Ch07/Ch07_Probability_2.rst:155
msgid "The Bayesian view"
msgstr "Det bayesianske synet"

#: ../../Ch07/Ch07_Probability_2.rst:157
msgid ""
"The **Bayesian view** of probability is often called the subjectivist view, "
"and although it has been a minority view among statisticians it has been "
"steadily gaining traction for the last several decades. There are many "
"flavours of Bayesianism, making it hard to say exactly what “the” Bayesian "
"view is. The most common way of thinking about subjective probability is to "
"define the probability of an event as the **degree of belief** that an "
"intelligent and rational agent assigns to that truth of that event. From "
"that perspective, probabilities don’t exist in the world but rather in the "
"thoughts and assumptions of people and other intelligent beings."
msgstr ""
"Det bayesianske synet** på sannsynlighet kalles ofte det subjektivistiske "
"synet, og selv om det har vært i mindretall blant statistikere, har det "
"vunnet stadig større innpass de siste tiårene. Det finnes mange varianter av "
"bayesianisme, noe som gjør det vanskelig å si nøyaktig hva som er «det» "
"bayesianske synet. Den vanligste måten å tenke på subjektiv sannsynlighet på "
"er å definere sannsynligheten for en hendelse som **graden av tro** som en "
"intelligent og rasjonell aktør tillegger sannheten om denne hendelsen. Ut "
"fra dette perspektivet eksisterer ikke sannsynligheter i verden, men snarere "
"i tankene og antakelsene til mennesker og andre intelligente vesener."

#: ../../Ch07/Ch07_Probability_2.rst:168
msgid ""
"However, in order for this approach to work we need some way of "
"operationalising “degree of belief”. One way that you can do this is to "
"formalise it in terms of “rational gambling”, though there are many other "
"ways. Suppose that I believe that there’s a 60\\% probability of rain "
"tomorrow. If someone offers me a bet that if it rains tomorrow then I win "
"$5, but if it doesn’t rain I lose $5. Clearly, from my perspective, this is "
"a pretty good bet. On the other hand, if I think that the probability of "
"rain is only 40\\% then it’s a bad bet to take. So we can operationalise the "
"notion of a “subjective probability” in terms of what bets I’m willing to "
"accept."
msgstr ""
"For at denne tilnærmingen skal fungere, trenger vi imidlertid en måte å "
"operasjonalisere «grad av tro» på. En måte å gjøre dette på er å formalisere "
"det i form av «rasjonell gambling», men det finnes mange andre måter. Anta "
"at jeg tror at det er 60\\% sannsynlighet for regn i morgen. Hvis noen "
"tilbyr meg et veddemål om at hvis det regner i morgen, vinner jeg 5 dollar, "
"men hvis det ikke regner, taper jeg 5 dollar. Fra mitt perspektiv er dette "
"helt klart et ganske godt veddemål. Hvis jeg derimot tror at sannsynligheten "
"for regn bare er 40\\%, er det et dårlig veddemål. Vi kan altså "
"operasjonalisere begrepet «subjektiv sannsynlighet» i form av hvilke "
"veddemål jeg er villig til å akseptere."

#: ../../Ch07/Ch07_Probability_2.rst:179
msgid ""
"What are the advantages and disadvantages to the Bayesian approach? The main "
"advantage is that it allows you to assign probabilities to any event you "
"want to. You don’t need to be limited to those events that are repeatable. "
"The main disadvantage (to many people) is that we can’t be purely objective. "
"Specifying a probability requires us to specify an entity that has the "
"relevant degree of belief. This entity might be a human, an alien, a robot, "
"or even a statistician. But there has to be an intelligent agent out there "
"that believes in things. To many people this is uncomfortable, it seems to "
"make probability arbitrary. Whilst the Bayesian approach requires that the "
"agent in question be rational (i.e., obey the rules of probability), it does "
"allow everyone to have their own beliefs. I can believe the coin is fair and "
"you don’t have to, even though we’re both rational. The frequentist view "
"doesn’t allow any two observers to attribute different probabilities to the "
"same event. When that happens then at least one of them must be wrong. The "
"Bayesian view does not prevent this from occurring. Two observers with "
"different background knowledge can legitimately hold different beliefs about "
"the same event. In short, where the frequentist view is sometimes considered "
"to be too narrow (forbids lots of things that that we want to assign "
"probabilities to), the Bayesian view is sometimes thought to be too broad "
"(allows too many differences between observers)."
msgstr ""
"Hva er fordelene og ulempene med den bayesianske tilnærmingen? Den største "
"fordelen er at du kan tilordne sannsynligheter til alle hendelser du ønsker. "
"Du trenger ikke å være begrenset til de hendelsene som kan gjentas. Den "
"største ulempen (for mange) er at vi ikke kan være helt objektive. Når vi "
"skal angi en sannsynlighet, må vi spesifisere en enhet som har den relevante "
"graden av tro. Denne enheten kan være et menneske, et romvesen, en robot "
"eller til og med en statistiker. Men det må finnes en intelligent aktør der "
"ute som tror på ting. For mange mennesker er dette ubehagelig, det virker "
"som om sannsynlighet blir vilkårlig. Selv om den bayesianske tilnærmingen "
"krever at den aktuelle agenten er rasjonell (dvs. følger "
"sannsynlighetsreglene), tillater den at alle har sine egne oppfatninger. Jeg "
"kan tro at mynten er rettferdig, men det trenger ikke du å gjøre, selv om vi "
"begge er rasjonelle. Det frekventistiske synet tillater ikke at to "
"observatører tillegger samme hendelse ulike sannsynligheter. Når det skjer, "
"må minst én av dem ta feil. Det bayesianske synet forhindrer ikke at dette "
"kan skje. To observatører med ulik bakgrunnskunnskap kan legitimt ha ulike "
"oppfatninger om den samme hendelsen. Kort sagt, der det frekventistiske "
"synet av og til anses for å være for snevert (det forbyr mange ting som vi "
"ønsker å tilordne sannsynligheter til), anses det bayesianske synet av og "
"til for å være for bredt (det tillater for mange forskjeller mellom "
"observatører)."

#: ../../Ch07/Ch07_Probability_2.rst:202
msgid "What’s the difference? And who is right?"
msgstr "Hva er forskjellen? Og hvem har rett?"

#: ../../Ch07/Ch07_Probability_2.rst:204
msgid ""
"Now that you’ve seen each of these two views independently it’s useful to "
"make sure you can compare the two. Go back to the hypothetical robot soccer "
"game at the start of the section. What do you think a frequentist and a "
"Bayesian would say about these three statements? Which statement would a "
"frequentist say is the correct definition of probability? Which one would a "
"Bayesian opt for? Would some of these statements be meaningless to a "
"frequentist or a Bayesian? If you’ve understood the two perspectives you "
"should have some sense of how to answer those questions."
msgstr ""
"Nå som du har sett hver av disse to visningene uavhengig av hverandre, er "
"det nyttig å sørge for at du kan sammenligne de to. Gå tilbake til den "
"hypotetiske robotfotballkampen i begynnelsen av avsnittet. Hva tror du en "
"frekventist og en bayesianer ville sagt om disse tre utsagnene? Hvilket "
"utsagn ville en frekventist si er den riktige definisjonen av sannsynlighet? "
"Hvilken ville en bayesianer valgt? Ville noen av disse utsagnene være "
"meningsløse for en frekventist eller en bayesianer? Hvis du har forstått de "
"to perspektivene, bør du ha en viss forståelse av hvordan du skal svare på "
"disse spørsmålene."

#: ../../Ch07/Ch07_Probability_2.rst:214
msgid ""
"Okay, assuming you understand the difference then you might be wondering "
"which of them is *right*? Honestly, I don’t know that there is a right "
"answer. As far as I can tell there’s nothing mathematically incorrect about "
"the way frequentists think about sequences of events, and there’s nothing "
"mathematically incorrect about the way that Bayesians define the beliefs of "
"a rational agent. In fact, when you dig down into the details Bayesians and "
"frequentists actually agree about a lot of things. Many frequentist methods "
"lead to decisions that Bayesians agree a rational agent would make. Many "
"Bayesian methods have very good frequentist properties."
msgstr ""
"Ok, hvis du forstår forskjellen, lurer du kanskje på hvilken av dem som er "
"*riktig*? Ærlig talt, jeg vet ikke om det finnes et riktig svar. Så vidt jeg "
"kan se er det ikke noe matematisk feil med måten frekventister tenker om "
"hendelsesforløp, og det er ikke noe matematisk feil med måten bayesianere "
"definerer troen til en rasjonell aktør. Når man går ned i detaljene, er "
"bayesianere og frekventister faktisk enige om mange ting. Mange "
"frekventistiske metoder fører til beslutninger som bayesianere er enige i at "
"en rasjonell aktør ville tatt. Mange bayesianske metoder har svært gode "
"frekventistiske egenskaper."

#: ../../Ch07/Ch07_Probability_2.rst:225
msgid ""
"For the most part, I’m a pragmatist so I’ll use any statistical method that "
"I trust. As it turns out, that makes me prefer Bayesian methods for reasons "
"I’ll explain towards the end of the book. But I’m not fundamentally opposed "
"to frequentist methods. Not everyone is quite so relaxed. For instance, "
"consider Sir Ronald Fisher, one of the towering figures of 20th century "
"statistics and a vehement opponent to all things Bayesian, whose paper on "
"the mathematical foundations of statistics referred to Bayesian probability "
"as “an impenetrable jungle [that] arrests progress towards precision of "
"statistical concepts” (:ref:`Fisher, 1922b <Fisher_1922b>`). Or the "
"psychologist Paul Meehl, who suggests that relying on frequentist methods "
"could turn you into “a potent but sterile intellectual rake who leaves in "
"his merry path a long train of ravished maidens but no viable scientific "
"offspring” (:ref:`Meehl, 1967 <Meehl_1967>`; p. 114). The history of "
"statistics, as you might gather, is not devoid of entertainment."
msgstr ""
"Jeg er for det meste pragmatiker, så jeg bruker alle statistiske metoder jeg "
"har tillit til. Det viser seg at jeg foretrekker bayesianske metoder av "
"grunner jeg vil forklare mot slutten av boken. Men jeg er ikke grunnleggende "
"motstander av frekventistiske metoder. Ikke alle er like avslappet. Tenk for "
"eksempel på Sir Ronald Fisher, en av det 20. århundrets store skikkelser "
"innen statistikk og en innbitt motstander av alt som har med bayesiansk "
"metode å gjøre, som i sin artikkel om statistikkens matematiske grunnlag "
"omtalte bayesiansk sannsynlighet som «en ugjennomtrengelig jungel [som] "
"hindrer fremgangen mot presisjon i statistiske begreper» (:ref:`Fisher, "
"1922b <Fisher_1922b>`). Eller psykologen Paul Meehl, som antyder at det å "
"stole på frekventistiske metoder kan gjøre deg til «en potent, men steril "
"intellektuell rake som etterlater seg et langt tog av fortryllede jomfruer, "
"men ikke noe levedyktig vitenskapelig avkom» (:ref:`Meehl, 1967 "
"<Meehl_1967>`; s. 114). Statistikkens historie er, som du kanskje skjønner, "
"ikke blottet for underholdning."

#: ../../Ch07/Ch07_Probability_2.rst:241
msgid ""
"In any case, whilst I personally prefer the Bayesian view, the majority of "
"statistical analyses are based on the frequentist approach. My reasoning is "
"pragmatic. The goal of this book is to cover roughly the same territory as a "
"typical undergraduate stats class in psychology, and if you want to "
"understand the statistical tools used by most psychologists you’ll need a "
"good grasp of frequentist methods. I promise you that this isn’t wasted "
"effort. Even if you end up wanting to switch to the Bayesian perspective, "
"you really should read through at least one book on the “orthodox” "
"frequentist view. Besides, I won’t completely ignore the Bayesian "
"perspective. Every now and then I’ll add some commentary from a Bayesian "
"point of view, and I’ll revisit the topic in more depth in chapter :doc:`../"
"Ch16/Ch16_Bayes`."
msgstr ""
"Selv om jeg personlig foretrekker det bayesianske synet, er de fleste "
"statistiske analyser uansett basert på den frekventistiske tilnærmingen. "
"Begrunnelsen min er pragmatisk. Målet med denne boken er å dekke omtrent det "
"samme området som et typisk statistikkurs i psykologi, og hvis du ønsker å "
"forstå de statistiske verktøyene som brukes av de fleste psykologer, trenger "
"du en god forståelse av frekventistiske metoder. Jeg lover deg at dette ikke "
"er bortkastet innsats. Selv om du skulle ende opp med å ønske å gå over til "
"det bayesianske perspektivet, bør du lese gjennom minst én bok om det "
"«ortodokse» frekventistiske synet. Dessuten vil jeg ikke helt ignorere det "
"bayesianske perspektivet. Innimellom vil jeg legge til noen kommentarer fra "
"et bayesiansk synspunkt, og jeg vil komme tilbake til temaet i kapittel :doc:"
"`../Ch16/Ch16_Bayes`."

#: ../../Ch07/Ch07_Probability_2.rst:257
msgid ""
"This doesn’t mean that frequentists can’t make hypothetical statements, of "
"course. It’s just that if you want to make a statement about probability "
"then it must be possible to redescribe that statement in terms of a sequence "
"of potentially observable events, together with the relative frequencies of "
"different outcomes that appear within that sequence."
msgstr ""
"Dette betyr selvsagt ikke at frekventister ikke kan komme med hypotetiske "
"utsagn. Det er bare det at hvis man ønsker å si noe om sannsynlighet, må det "
"være mulig å omskrive utsagnet til en sekvens av potensielt observerbare "
"hendelser, sammen med de relative frekvensene av ulike utfall som opptrer i "
"denne sekvensen."

#: ../../Ch07/Ch07_Probability_3.rst:4
msgid "Basic probability theory"
msgstr "Grunnleggende sannsynlighetsteori"

#: ../../Ch07/Ch07_Probability_3.rst:6
msgid ""
"Ideological arguments between Bayesians and frequentists notwithstanding, it "
"turns out that people mostly agree on the rules that probabilities should "
"obey. There are lots of different ways of arriving at these rules. The most "
"commonly used approach is based on the work of Andrey Kolmogorov, one of the "
"great Soviet mathematicians of the 20th century. I won’t go into a lot of "
"detail, but I’ll try to give you a bit of a sense of how it works. And in "
"order to do so I’m going to have to talk about my trousers."
msgstr ""
"Til tross for ideologiske argumenter mellom bayesianere og frekventister, "
"viser det seg at folk stort sett er enige om hvilke regler sannsynligheter "
"bør følge. Det finnes mange forskjellige måter å komme frem til disse "
"reglene på. Den mest brukte tilnærmingen er basert på arbeidet til Andrej "
"Kolmogorov, en av de store sovjetiske matematikerne på 1900-tallet. Jeg skal "
"ikke gå i detalj, men jeg skal prøve å gi deg et inntrykk av hvordan det "
"fungerer. Og for å kunne gjøre det må jeg snakke om buksene mine."

#: ../../Ch07/Ch07_Probability_3.rst:16
msgid "Introducing probability distributions"
msgstr "Introduksjon til sannsynlighetsfordelinger"

#: ../../Ch07/Ch07_Probability_3.rst:18
msgid ""
"One of the disturbing truths about my life is that I only own 5 pairs of "
"trousers. Three pairs of jeans, the bottom half of a suit, and a pair of "
"tracksuit pants. Even sadder, I’ve given them names: I call them *X*\\ :sub:"
"`1`\\ , *X*\\ :sub:`2`\\ , *X*\\ :sub:`3`\\ , *X*\\ :sub:`4`  and *X*\\ :sub:"
"`5`\\ . I really have, that’s why they call me Mister Imaginative. Now, on "
"any given day, I pick out exactly one of pair of trousers to wear. Not even "
"I’m so stupid as to try to wear two pairs of trousers, and thanks to years "
"of training I never go outside without wearing trousers anymore. If I were "
"to describe this situation using the language of probability theory, I would "
"refer to each pair of trousers (i.e., each *X*) as an **elementary event**. "
"The key characteristic of elementary events is that every time we make an "
"observation (e.g., every time I put on a pair of trousers) then the outcome "
"will be one and only one of these events. Like I said, these days I always "
"wear exactly one pair of trousers so my trousers satisfy this constraint. "
"Similarly, the set of all possible events is called a **sample space**. "
"Granted, some people would call it a “wardrobe”, but that’s because they’re "
"refusing to think about my trousers in probabilistic terms. Sad."
msgstr ""
"En av de urovekkende sannhetene om livet mitt er at jeg bare eier fem par "
"bukser. Tre par jeans, den nederste halvdelen av en dress og et par "
"treningsbukser. Enda tristere er det at jeg har gitt dem navn: Jeg kaller "
"dem *X*\\ :sub:`1`\\ , *X*\\ :sub:`2`\\ , *X*\\ :sub:`3`\\ , *X*\\ :sub:`4` "
"og *X*\\ :sub:`5`\\ . Det har jeg virkelig, det er derfor de kaller meg "
"Mister Fantasifull. Nå velger jeg ut nøyaktig én bukse jeg skal ha på meg "
"hver dag. Ikke engang jeg er så dum at jeg prøver å ha på meg to par bukser, "
"og takket være mange års trening går jeg aldri ut uten bukse lenger. Hvis "
"jeg skulle beskrive denne situasjonen med sannsynlighetsregning, ville jeg "
"kalt hvert par bukser (altså hver *X*) for en **elementær hendelse**. Det "
"som kjennetegner elementære hendelser, er at hver gang vi gjør en "
"observasjon (f.eks. hver gang jeg tar på meg en bukse), så vil utfallet være "
"én og bare én av disse hendelsene. Som sagt, i disse dager har jeg alltid på "
"meg nøyaktig én bukse, så buksene mine tilfredsstiller denne begrensningen. "
"På samme måte kalles mengden av alle mulige hendelser for et **utvalgsrom** "
"(*sample space*). Noen vil riktignok kalle det en «garderobe», men det er "
"fordi de nekter å tenke på buksene mine i sannsynlighetstermer. Det er trist."

#: ../../Ch07/Ch07_Probability_3.rst:37
msgid ""
"Okay, now that we have a sample space (a wardrobe), which is built from lots "
"of possible elementary events (trousers), what we want to do is assign a "
"**probability** of one of these elementary events. For an event *X*, the "
"probability of that event *P*\\ (X) is a number that lies between 0 and 1. "
"The bigger the value of *P*\\ (X), the more likely the event is to occur. "
"So, for example, if *P*\\ (X) = 0 it means the event *X* is impossible (i."
"e., I never wear those trousers). On the other hand, if *P*\\ (X) = 1 it "
"means that event *X* is certain to occur (i.e., I always wear those "
"trousers). For probability values in the middle it means that I sometimes "
"wear those trousers. For instance, if *P*\\ (X) = 0.5 it means that I wear "
"those trousers half of the time."
msgstr ""
"Nå som vi har et utvalgsrom (en garderobe), som er bygd opp av mange mulige "
"elementære hendelser (bukser), ønsker vi å tilordne en **sannsynlighet** for "
"en av disse elementære hendelsene. For en hendelse *X* er sannsynligheten "
"for denne hendelsen *P*\\ (X) et tall som ligger mellom 0 og 1. Jo større "
"verdien av *P*\\ (X) er, desto mer sannsynlig er det at hendelsen "
"inntreffer. Hvis *P*\\ (X) = 0, betyr det for eksempel at hendelsen *X* er "
"umulig (f.eks. at jeg aldri går med de buksene). Hvis *P*\\ (X) = 1, betyr "
"det derimot at hendelsen *X* med sikkerhet vil inntreffe (f.eks. at jeg "
"alltid har på meg de buksene). For sannsynlighetsverdier i midten betyr det "
"at jeg av og til går med de buksene. Hvis *P*\\(X) = 0,5, betyr det for "
"eksempel at jeg bruker buksene halvparten av tiden."

#: ../../Ch07/Ch07_Probability_3.rst:50
msgid ""
"At this point, we’re almost done. The last thing we need to recognise is "
"that “something always happens”. Every time I put on trousers, I really do "
"end up wearing trousers (crazy, right?). What this somewhat trite statement "
"means, in probabilistic terms, is that the probabilities of the elementary "
"events need to add up to 1. This is known as the **law of total "
"probability**, not that any of us really care. More importantly, if these "
"requirements are satisfied then what we have is a **probability "
"distribution**. For example, this is an example of a probability "
"distribution:"
msgstr ""
"Nå er vi nesten ferdige. Det siste vi må innse er at «det alltid skjer noe». "
"Hver gang jeg tar på meg en bukse, ender jeg virkelig opp med å ha på meg en "
"bukse (sprøtt, ikke sant?). Det dette noe banale utsagnet betyr i "
"sannsynlighetsregning, er at sannsynligheten for de elementære hendelsene må "
"summere seg til 1. Dette er kjent som **loven om total sannsynlighet**, ikke "
"at noen av oss egentlig bryr oss om det. Enda viktigere er det at hvis disse "
"kravene er oppfylt, har vi en **sannsynlighetsfordeling**. Dette er for "
"eksempel et eksempel på en sannsynlighetsfordeling:"

#: ../../Ch07/Ch07_Probability_3.rst:61
msgid "Which trousers?"
msgstr "Hvilke bukser?"

#: ../../Ch07/Ch07_Probability_3.rst:61
msgid "Label"
msgstr "Etikett"

#: ../../Ch07/Ch07_Probability_3.rst:61
msgid "Probability"
msgstr "Sannsynlighet"

#: ../../Ch07/Ch07_Probability_3.rst:63
msgid "Blue jeans"
msgstr "Blå jeans"

#: ../../Ch07/Ch07_Probability_3.rst:63
msgid "*X*\\ :sub:`1`"
msgstr "*X*\\ :sub:`1`"

#: ../../Ch07/Ch07_Probability_3.rst:63
msgid "*P*\\ (X\\ :sub:`1`\\ ) = 0.5"
msgstr "*P*\\ (X\\ :sub:`1`\\ ) = 0.5"

#: ../../Ch07/Ch07_Probability_3.rst:65
msgid "Grey jeans"
msgstr "Grå jeans"

#: ../../Ch07/Ch07_Probability_3.rst:65
msgid "*X*\\ :sub:`2`"
msgstr "*X*\\ :sub:`2`"

#: ../../Ch07/Ch07_Probability_3.rst:65
msgid "*P*\\ (X\\ :sub:`2`\\ ) = 0.3"
msgstr "*P*\\ (X\\ :sub:`2`\\ ) = 0.3"

#: ../../Ch07/Ch07_Probability_3.rst:67
msgid "Black jeans"
msgstr "Sorte jeans"

#: ../../Ch07/Ch07_Probability_3.rst:67
msgid "*X*\\ :sub:`3`"
msgstr "*X*\\ :sub:`3`"

#: ../../Ch07/Ch07_Probability_3.rst:67
msgid "*P*\\ (X\\ :sub:`3`\\ ) = 0.1"
msgstr "*P*\\ (X\\ :sub:`3`\\ ) = 0.1"

#: ../../Ch07/Ch07_Probability_3.rst:69
msgid "Black suit"
msgstr "Svart dress"

#: ../../Ch07/Ch07_Probability_3.rst:69
msgid "*X*\\ :sub:`4`"
msgstr "*X*\\ :sub:`4`"

#: ../../Ch07/Ch07_Probability_3.rst:69
msgid "*P*\\ (X\\ :sub:`4`\\ ) = 0"
msgstr "*P*\\ (X\\ :sub:`4`\\ ) = 0"

#: ../../Ch07/Ch07_Probability_3.rst:71
msgid "Blue tracksuit"
msgstr "Blå treningsdress"

#: ../../Ch07/Ch07_Probability_3.rst:71
msgid "*X*\\ :sub:`5`"
msgstr "*X*\\ :sub:`5`"

#: ../../Ch07/Ch07_Probability_3.rst:71
msgid "*P*\\ (X\\ :sub:`5`\\ ) = 0.1"
msgstr "*P*\\ (X\\ :sub:`5`\\ ) = 0.1"

#: ../../Ch07/Ch07_Probability_3.rst:74
msgid ""
"Each of the events has a probability that lies between 0 and 1, and if we "
"add up the probability of all events they sum to 1. Awesome. We can even "
"draw a nice bar graph (see :doc:`../Ch05/Ch05_Graphics_3`) to visualise this "
"distribution, as shown in :numref:`fig-pantsDistribution`. And, at this "
"point, we’ve all achieved something. You’ve learned what a probability "
"distribution is, and I’ve finally managed to find a way to create a graph "
"that focuses entirely on my trousers. Everyone wins!"
msgstr ""
"Hver av hendelsene har en sannsynlighet som ligger mellom 0 og 1, og hvis vi "
"legger sammen sannsynligheten for alle hendelsene, blir summen 1. "
"Fantastisk! Vi kan til og med tegne et fint søylediagram (se :doc:`../Ch05/"
"Ch05_Graphics_3`) for å visualisere denne fordelingen, som vist i :numref:"
"`fig-pantsDistribution`. Og på dette punktet har vi alle oppnådd noe. Du har "
"lært hva en sannsynlighetsfordeling er, og jeg har endelig klart å finne en "
"måte å lage et diagram som fokuserer helt og holdent på buksene mine. Alle "
"vinner!"

#: ../../Ch07/Ch07_Probability_3.rst:88
msgid "“Trousers” probability distribution"
msgstr "Sannsynlighetsfordeling for «Bukser»"

#: ../../Ch07/Ch07_Probability_3.rst:88
msgid ""
"Visual depiction of the “trousers” probability distribution. There are five "
"“elementary events”, corresponding to the five pairs of trousers that I own. "
"Each event has some probability of occurring: this probability is a number "
"between 0 to 1. The sum of these probabilities is 1."
msgstr ""
"Visuell fremstilling av sannsynlighetsfordelingen for «bukser». Det finnes "
"fem «elementære hendelser», som tilsvarer de fem bukseparene jeg eier. Hver "
"hendelse har en viss sannsynlighet for å inntreffe: Denne sannsynligheten er "
"et tall mellom 0 og 1. Summen av disse sannsynlighetene er 1."

#: ../../Ch07/Ch07_Probability_3.rst:95
msgid ""
"The only other thing that I need to point out is that probability theory "
"allows you to talk about **non elementary events** as well as elementary "
"ones. The easiest way to illustrate the concept is with an example. In the "
"trousers example it’s perfectly legitimate to refer to the probability that "
"I wear jeans. In this scenario, the “Dani wears jeans” event is said to have "
"happened as long as the elementary event that actually did occur is one of "
"the appropriate ones. In this case “blue jeans”, “black jeans” or “grey "
"jeans”. In mathematical terms we defined the “jeans” event *E* to correspond "
"to the set of elementary events (X\\ :sub:`1`\\ , X\\ :sub:`2`\\ , X\\ :sub:"
"`3`\\ )`. If any of these elementary events occurs then *E* is also said to "
"have occurred. Having decided to write down the definition of the *E* this "
"way, it’s pretty straightforward to state what the probability *P*\\ (E) is: "
"we just add everything up. In this particular case"
msgstr ""
"Den eneste andre tingen jeg trenger å påpeke, er at sannsynlighetsteorien "
"gjør det mulig å snakke om **ikke-elementære hendelser** så vel som "
"elementære. Den enkleste måten å illustrere konseptet på er med et eksempel. "
"I bukseeksempelet er det helt legitimt å referere til sannsynligheten for at "
"jeg går i jeans. I dette scenariet sies det at hendelsen «Dani går med "
"jeans» har inntruffet så lenge den elementære hendelsen som faktisk "
"inntraff, er en av de passende. I dette tilfellet «blå jeans», «svarte "
"jeans» eller «grå jeans». I matematiske termer har vi definert «jeans»-"
"hendelsen *E* til å tilsvare mengden av elementære hendelser (X\\ :sub:"
"`1`\\ , X\\ :sub:`2`\\ , X\\ :sub:`3`\\ )`. Hvis noen av disse elementære "
"hendelsene inntreffer, sies det at *E* også har inntruffet. Når vi har "
"bestemt oss for å skrive ned definisjonen av *E* på denne måten, er det "
"ganske enkelt å angi hva sannsynligheten *P*\\ (E) er: Vi bare legger alt "
"sammen. I dette spesielle tilfellet"

#: ../../Ch07/Ch07_Probability_3.rst:110
msgid ""
"*P*\\ (E) = *P*\\ (X\\ :sub:`1`\\ ) + *P*\\ (X\\ :sub:`2`\\ ) + *P*\\ (X\\ :"
"sub:`3`\\ )"
msgstr ""
"*P*\\ (E) = *P*\\ (X\\ :sub:`1`\\ ) + *P*\\ (X\\ :sub:`2`\\ ) + *P*\\ (X\\ :"
"sub:`3`\\ )"

#: ../../Ch07/Ch07_Probability_3.rst:112
msgid ""
"and, since the probabilities of blue, grey and black jeans respectively are "
"0.5, 0.3 and 0.1, the probability that I wear jeans is equal to 0.9."
msgstr ""
"og siden sannsynligheten for henholdsvis blå, grå og svarte jeans er 0,5, "
"0,3 og 0,1, er sannsynligheten for at jeg bruker jeans lik 0,9."

#: ../../Ch07/Ch07_Probability_3.rst:115
msgid ""
"At this point you might be thinking that this is all terribly obvious and "
"simple and you’d be right. All we’ve really done is wrap some basic "
"mathematics around a few common sense intuitions. However, from these simple "
"beginnings it’s possible to construct some extremely powerful mathematical "
"tools. I’m definitely not going to go into the details in this book, but "
"what I will do is list, in :numref:`tab-probrules`, some of the other rules "
"that probabilities satisfy. These rules can be derived from the simple "
"assumptions that I’ve outlined above, but since we don’t actually use these "
"rules for anything in this book I won’t do so here."
msgstr ""
"Nå tenker du kanskje at alt dette er veldig opplagt og enkelt, og det har du "
"rett i. Alt vi egentlig har gjort, er å pakke inn litt grunnleggende "
"matematikk rundt noen intuisjoner basert på sunn fornuft. Men ut fra disse "
"enkle utgangspunktene er det mulig å konstruere noen ekstremt kraftige "
"matematiske verktøy. Jeg kommer definitivt ikke til å gå inn på detaljene i "
"denne boken, men det jeg vil gjøre, er å liste opp, i :numref:`tab-"
"probrules`, noen av de andre reglene som sannsynligheter tilfredsstiller. "
"Disse reglene kan utledes fra de enkle forutsetningene som jeg har skissert "
"ovenfor, men siden vi faktisk ikke bruker disse reglene til noe i denne "
"boken, vil jeg ikke gjøre det her."

#: ../../Ch07/Ch07_Probability_3.rst:125
msgid ""
"Some basic rules that probabilities must satisfy. You don’t really need to "
"know these rules in order to understand the analyses that we’ll talk about "
"later in the book, but they are important if you want to understand "
"probability theory a bit more deeply."
msgstr ""
"Noen grunnleggende regler som sannsynligheter må tilfredsstille. Du trenger "
"egentlig ikke å kunne disse reglene for å forstå analysene som vi skal "
"snakke om senere i boken, men de er viktige hvis du vil forstå "
"sannsynlighetsteorien litt dypere."

#: ../../Ch07/Ch07_Probability_3.rst:134
msgid "English"
msgstr "Engelsk"

#: ../../Ch07/Ch07_Probability_3.rst:134
msgid "Notation"
msgstr "Notasjon"

#: ../../Ch07/Ch07_Probability_3.rst:134
msgid "Formula"
msgstr "Formel"

#: ../../Ch07/Ch07_Probability_3.rst:136
msgid "not *A*"
msgstr "ikke *A*"

#: ../../Ch07/Ch07_Probability_3.rst:136
msgid "*P*\\ (¬ A)"
msgstr "*P*\\ (¬ A)"

#: ../../Ch07/Ch07_Probability_3.rst:136 ../../Ch07/Ch07_Probability_3.rst:138
#: ../../Ch07/Ch07_Probability_3.rst:140
msgid "="
msgstr "="

#: ../../Ch07/Ch07_Probability_3.rst:136
msgid "1 - *P*\\ (A)"
msgstr "1 - *P*\\ (A)"

#: ../../Ch07/Ch07_Probability_3.rst:138
msgid "*A* or *B*"
msgstr "*A* eller *B*"

#: ../../Ch07/Ch07_Probability_3.rst:138
msgid "*P*\\ (A ∪ B)"
msgstr "*P*\\ (A ∪ B)"

#: ../../Ch07/Ch07_Probability_3.rst:138
msgid "*P*\\ (A) + *P*\\ (B) - *P*\\ (A ∩ B)"
msgstr "*P*\\ (A) + *P*\\ (B) - *P*\\ (A ∩ B)"

#: ../../Ch07/Ch07_Probability_3.rst:140
msgid "*A* and *B*"
msgstr "*A* og *B*"

#: ../../Ch07/Ch07_Probability_3.rst:140
msgid "*P*\\ (A ∩ B)"
msgstr "*P*\\ (A ∩ B)"

#: ../../Ch07/Ch07_Probability_3.rst:140
msgid "*P*\\ (A|B) *P*\\ (B)"
msgstr "*P*\\ (A|B) *P*\\ (B)"

#: ../../Ch07/Ch07_Probability_4.rst:4
msgid "The binomial distribution"
msgstr "Binomialfordelingen"

#: ../../Ch07/Ch07_Probability_4.rst:6
msgid ""
"As you might imagine, probability distributions vary enormously and there’s "
"an enormous range of distributions out there. However, they aren’t all "
"equally important. In fact, the vast majority of the content in this book "
"relies on one of five distributions: the binomial distribution, the normal "
"distribution, the *t*-distribution, the χ²-distribution (chi-square) and the "
"*F*-distribution. Given this, what I’ll do over the next few sections is "
"provide a brief introduction to all five of these, paying special attention "
"to the binomial and the normal. I’ll start with the binomial distribution "
"since it’s the simplest of the five."
msgstr ""
"Som du kanskje kan tenke deg, varierer sannsynlighetsfordelinger enormt, og "
"det finnes et enormt utvalg av fordelinger der ute. Alle er imidlertid ikke "
"like viktige. Faktisk er det aller meste av innholdet i denne boken basert "
"på én av fem fordelinger: binomialfordelingen, normalfordelingen, *t*-"
"fordelingen, χ²-fordelingen (chi-kvadrat) og *F*-fordelingen. I de neste "
"avsnittene skal jeg derfor gi en kort innføring i alle disse fem, med "
"spesiell vekt på binomial- og normalfordelingen. Jeg begynner med "
"binomialfordelingen, siden den er den enkleste av de fem."

#: ../../Ch07/Ch07_Probability_4.rst:17
msgid "Introducing the binomial"
msgstr "Introduksjon av binomial"

#: ../../Ch07/Ch07_Probability_4.rst:19
msgid ""
"The theory of probability originated in the attempt to describe how games of "
"chance work, so it seems fitting that our discussion of the **binomial "
"distribution** should involve a discussion of rolling dice and flipping "
"coins. Let’s imagine a simple “experiment”. In my hot little hand I’m "
"holding 20 identical six-sided dice. On one face of each die there’s a "
"picture of a skull, the other five faces are all blank. If I proceed to roll "
"all 20 dice, what’s the probability that I’ll get exactly 4 skulls? Assuming "
"that the dice are fair, we know that the chance of any one die coming up "
"skulls is 1 in 6. To say this another way, the skull probability for a "
"single die is approximately 0.167. This is enough information to answer our "
"question, so let’s have a look at how it’s done."
msgstr ""
"Sannsynlighetsteorien har sin opprinnelse i forsøket på å beskrive hvordan "
"sjansespill fungerer, og det virker derfor passende at vår diskusjon om "
"**binomialfordelingen** involverer en diskusjon om terningkast og myntkast. "
"La oss tenke oss et enkelt «eksperiment». I min lille, varme hånd holder jeg "
"20 identiske sekssidige terninger. På den ene siden av hver terning er det "
"et bilde av en hodeskalle, mens de andre fem sidene er blanke. Hvis jeg "
"kaster alle 20 terningene, hva er sannsynligheten for at jeg får nøyaktig "
"fire hodeskaller? Hvis vi antar at terningene er rettferdige, vet vi at "
"sjansen for at en av terningene gir hodeskaller er 1 til 6. Sagt på en annen "
"måte: Sannsynligheten for hodeskaller for en enkelt terning er omtrent "
"0,167. Dette er nok informasjon til å svare på spørsmålet vårt, så la oss se "
"på hvordan det gjøres."

#: ../../Ch07/Ch07_Probability_4.rst:32
msgid ""
"Formulas for the binomial and normal distributions. We don’t really use "
"these formulas for anything in this book, but they’re pretty important for "
"more advanced work, so I thought it might be best to put them here in a "
"table, where they can’t get in the way of the text. In the equation for the "
"binomial, *X!* is the factorial function (i.e., multiply all whole numbers "
"from 1 to *X*), and for the normal distribution “exp” refers to the "
"exponential function, which we discussed in chapter :doc:`../Ch06/"
"Ch06_DataHandling`. If these equations don’t make a lot of sense to you, "
"don’t worry too much about them."
msgstr ""
"Formler for binomial- og normalfordelingen. Vi bruker egentlig ikke disse "
"formlene til noe som helst i denne boka, men de er ganske viktige for mer "
"avansert arbeid, så jeg tenkte det var best å sette dem inn her i en tabell, "
"der de ikke står i veien for teksten. I ligningen for binomialfordelingen er "
"*X!* faktorialfunksjonen (dvs. multipliser alle hele tall fra 1 til *X*), og "
"for normalfordelingen refererer «exp» til eksponentialfunksjonen, som vi "
"diskuterte i kapittel :doc:`../Ch06/Ch06_DataHandling`. Hvis disse "
"ligningene ikke gir så mye mening for deg, trenger du ikke å bekymre deg for "
"mye over dem."

#: ../../Ch07/Ch07_Probability_4.rst:44
msgid "Binomial"
msgstr "Binomial"

#: ../../Ch07/Ch07_Probability_4.rst:44
msgid "Normal"
msgstr "Normal"

#: ../../Ch07/Ch07_Probability_4.rst:46
msgid "|binomial|"
msgstr "|binomial|"

#: ../../Ch07/Ch07_Probability_4.rst:46
msgid "|normal|"
msgstr "|normal|"

#: ../../Ch07/Ch07_Probability_4.rst:49
msgid ""
"As usual, we’ll want to introduce some names and some notation. We’ll let "
"*N* denote the number of dice rolls in our experiment, which is often "
"referred to as the **size parameter** of our binomial distribution. We’ll "
"also use *θ* to refer to the the probability that a single die comes up "
"skulls, a quantity that is usually called the **success probability** of the "
"binomial.\\ [#]_ Finally, we’ll use *X* to refer to the results of our "
"experiment, namely the number of skulls I get when I roll the dice. Since "
"the actual value of *X* is due to chance we refer to it as a **random "
"variable**. In any case, now that we have all this terminology and notation "
"we can use it to state the problem a little more precisely. The quantity "
"that we want to calculate is the probability that *X* = 4 given that we know "
"that *θ* = 0.167 and *N* = 20. The general “form” of the thing I’m "
"interested in calculating could be written as"
msgstr ""
"Som vanlig vil vi introdusere noen navn og noen notasjoner. Vi lar *N* "
"betegne antall terningkast i eksperimentet vårt, som ofte omtales som "
"**størrelsesparameteren** i binomialfordelingen vår. Vi bruker også *θ* for "
"å referere til sannsynligheten for at en enkelt terning gir hodeskaller, en "
"størrelse som vanligvis kalles **suksess-sannsynligheten** for "
"binomialfordelingen.\\ [#]_ Til slutt bruker vi *X* for å referere til "
"resultatet av eksperimentet vårt, nemlig antall hodeskaller jeg får når jeg "
"kaster terningen. Siden den faktiske verdien av *X* skyldes tilfeldigheter, "
"kaller vi den en **tilfeldig variabel**. Nå som vi har all denne "
"terminologien og notasjonen på plass, kan vi bruke den til å formulere "
"problemet litt mer presist. Størrelsen vi ønsker å beregne, er "
"sannsynligheten for at *X* = 4, gitt at vi vet at *θ* = 0,167 og *N* = 20. "
"Den generelle «formen» for det jeg er interessert i å beregne, kan skrives "
"som"

#: ../../Ch07/Ch07_Probability_4.rst:65
msgid "*P*\\ (X | θ, N)"
msgstr "*P*\\ (X | θ, N)"

#: ../../Ch07/Ch07_Probability_4.rst:67
msgid ""
"and we’re interested in the special case where *X* = 4, *θ* = 0.167 and *N* "
"= 20. There’s only one more piece of notation I want to refer to before "
"moving on to discuss the solution to the problem. If I want to say that *X* "
"is generated randomly from a binomial distribution with parameters *θ* and "
"*N*, the notation I would use is as follows:"
msgstr ""
"og vi er interessert i spesialtilfellet der *X* = 4, *θ* = 0,167 og *N* = "
"20. Det er bare én notasjon til jeg vil vise til før jeg går videre til å "
"diskutere løsningen på problemet. Hvis jeg vil si at *X* er generert "
"tilfeldig fra en binomialfordeling med parametrene *θ* og *N*, vil jeg bruke "
"følgende notasjon:"

#: ../../Ch07/Ch07_Probability_4.rst:74
msgid "*X* ~ Binomial(θ, N)"
msgstr "*X* ~ Binomial(θ, N)"

#: ../../Ch07/Ch07_Probability_4.rst:76
msgid ""
"Yeah, yeah. I know what you’re thinking: notation, notation, notation. "
"Really, who cares? Very few readers of this book are here for the notation, "
"so I should probably move on and talk about how to use the binomial "
"distribution. I’ve included the formula for the binomial distribution in :"
"numref:`tab-distformulas`, since some readers may want to play with it "
"themselves, but since most people probably don’t care that much and because "
"we don’t need the formula in this book, I won’t talk about it in any detail. "
"Instead, I just want to show you what the binomial distribution looks like."
msgstr ""
"Ja, ja, ja, ja. Jeg vet hva du tenker: notasjon, notasjon, notasjon. Hvem "
"bryr seg egentlig? De færreste leserne av denne boken er her for notasjonen, "
"så jeg bør nok gå videre og snakke om hvordan man bruker "
"binomialfordelingen. Jeg har tatt med formelen for binomialfordelingen i :"
"numref:`tab-distformulas`, siden noen lesere kanskje vil leke seg med den "
"selv, men siden de fleste sannsynligvis ikke bryr seg så mye om det, og "
"fordi vi ikke trenger formelen i denne boken, skal jeg ikke snakke om den i "
"detalj. I stedet vil jeg bare vise deg hvordan binomialfordelingen ser ut."

#: ../../Ch07/Ch07_Probability_4.rst:92
msgid "Binomial distribution for *N* = 20 and θ = 1/6"
msgstr "Binomialfordeling for *N* = 20 og θ = 1/6"

#: ../../Ch07/Ch07_Probability_4.rst:92
msgid ""
"Binomial distribution with size parameter of *N* = 20 and an underlying "
"success probability of θ = 1/6. Each vertical bar depicts the probability of "
"one specific outcome (i.e., one possible value of X). Because this is a "
"probability distribution, each of the probabilities must be a number between "
"0 and 1, and the heights of the bars must sum to 1 as well."
msgstr ""
"Binomisk fordeling med størrelsesparameter *N* = 20 og en underliggende "
"sannsynlighet for suksess på θ = 1/6. Hver vertikale stolpe viser "
"sannsynligheten for ett spesifikt utfall (dvs. én mulig verdi av X). Fordi "
"dette er en sannsynlighetsfordeling, må hver av sannsynlighetene være et "
"tall mellom 0 og 1, og høyden på søylene må også summere seg til 1."

#: ../../Ch07/Ch07_Probability_4.rst:100
msgid ""
"To that end, :numref:`fig-binomSkulls20` plots the binomial probabilities "
"for all possible values of *X* for our dice rolling experiment, from *X* = 0 "
"(no skulls) all the way up to *X* = 20 (all skulls). Note that this is "
"basically a bar chart, and is no different to the “trousers probability” "
"plot I drew in :numref:`fig-pantsDistribution`. On the horizontal axis we "
"have all the possible events, and on the vertical axis we can read off the "
"probability of each of those events. So, the probability of rolling 4 skulls "
"out of 20 is about 0.20 (the actual answer is 0.2022036, as we’ll see in a "
"moment). In other words, you’d expect that to happen about 20\\% of the "
"times you repeated this experiment."
msgstr ""
"Derfor viser :numref:`fig-binomSkulls20` de binomiske sannsynlighetene for "
"alle mulige verdier av *X* for terningkast-eksperimentet vårt, fra *X* = 0 "
"(ingen hodeskaller) helt opp til *X* = 20 (alle hodeskaller). Merk at dette "
"i utgangspunktet er et søylediagram, og er ikke forskjellig fra "
"«buksesannsynlighetsplottet» jeg tegnet i :numref:`fig-pantsDistribution`. "
"På den horisontale aksen har vi alle mulige hendelser, og på den vertikale "
"aksen kan vi lese av sannsynligheten for hver av disse hendelsene. "
"Sannsynligheten for å kaste 4 hodeskaller av 20 er omtrent 0,20 (det "
"faktiske svaret er 0,2022036, som vi skal se om et øyeblikk). Med andre ord "
"kan du forvente at dette vil skje omtrent 20\\% av gangene du gjentar "
"eksperimentet."

#: ../../Ch07/Ch07_Probability_4.rst:111
msgid ""
"To give you a feel for how the binomial distribution changes when we alter "
"the values of *θ* and *N*, let’s suppose that instead of rolling dice I’m "
"actually flipping coins. This time around, my experiment involves flipping a "
"fair coin repeatedly and the outcome that I’m interested in is the number of "
"heads that I observe. In this scenario, the success probability is now *θ* = "
"1/2. Suppose I were to flip the coin *N* = 20 times. In this example, I’ve "
"changed the success probability but kept the size of the experiment the "
"same. What does this do to our binomial distribution? Well, as the left "
"panel of :numref:`fig-binomHeads` shows, the main effect of this is to shift "
"the whole distribution, as you’d expect. Okay, what if we flipped a coin *N* "
"= 100 times? Well, in that case we get what is shown in the right panel. The "
"distribution stays roughly in the middle but there’s a bit more variability "
"in the possible outcomes."
msgstr ""
"For å gi deg en følelse av hvordan binomialfordelingen endrer seg når vi "
"endrer verdiene for *θ* og *N*, la oss anta at jeg i stedet for å kaste "
"terning faktisk kaster mynt. Denne gangen innebærer eksperimentet at jeg "
"kaster en rettferdig mynt gjentatte ganger, og utfallet jeg er interessert "
"i, er antallet kron som jeg observerer. I dette scenariet er sannsynligheten "
"for suksess nå *θ* = 1/2. Anta at jeg kaster mynten *N* = 20 ganger. I dette "
"eksempelet har jeg endret sannsynligheten for å lykkes, men holdt størrelsen "
"på eksperimentet den samme. Hva gjør dette med binomialfordelingen vår? Som "
"det venstre panelet i :numref:`fig-binomHeads` viser, er hovedeffekten av "
"dette å forskyve hele fordelingen, som du ville forvente. Hva om vi kaster "
"en mynt *N* = 100 ganger? I så fall får vi det som er vist i høyre panel. "
"Fordelingen holder seg omtrent i midten, men det er litt mer variasjon i de "
"mulige utfallene."

#: ../../Ch07/Ch07_Probability_4.rst:132
msgid "Binomial distribution: θ = 1/2 and *N* = 20 (left) or *N* = 100 (right)"
msgstr ""
"Binomisk fordeling: θ = 1/2 og *N* = 20 (til venstre) eller *N* = 100 (til "
"høyre)"

#: ../../Ch07/Ch07_Probability_4.rst:132
msgid ""
"Two binomial distributions, involving a scenario in which I’m flipping a "
"fair coin, so the underlying success probability is θ = 1/2. In the left "
"panel, we assume I’m flipping the coin *N* = 20 times. In the right panel, "
"we assume that the coin is flipped *N* = 100 times."
msgstr ""
"To binomiske fordelinger, som involverer et scenario der jeg kaster en "
"rettferdig mynt, slik at den underliggende sannsynligheten for suksess er θ "
"= 1/2. I det venstre panelet antar vi at jeg kaster mynten *N* = 20 ganger. "
"I det høyre panelet antar vi at mynten kastes *N* = 100 ganger."

#: ../../Ch07/Ch07_Probability_4.rst:142
msgid ""
"Note that the term “success” is pretty arbitrary and doesn’t actually imply "
"that the outcome is something to be desired. If *θ* referred to the "
"probability that any one passenger gets injured in a bus crash I’d still "
"call it the success probability, but that doesn’t mean I want people to get "
"hurt in bus crashes!"
msgstr ""
"Merk at begrepet «suksess» er ganske vilkårlig og ikke innebærer at utfallet "
"faktisk er noe å ønske seg. Hvis *θ* refererte til sannsynligheten for at en "
"passasjer blir skadet i en bussulykke, ville jeg fortsatt kalt det suksess-"
"sannsynligheten, men det betyr ikke at jeg ønsker at folk skal bli skadet i "
"bussulykker!"

#: ../../Ch07/Ch07_Probability_5.rst:4
msgid "The normal distribution"
msgstr "Normalfordelingen"

#: ../../Ch07/Ch07_Probability_5.rst:6
msgid ""
"While the binomial distribution is conceptually the simplest distribution to "
"understand, it’s not the most important one. That particular honour goes to "
"the **normal distribution**, also referred to as “the bell curve” or a "
"“Gaussian distribution”. A normal distribution is described using two "
"parameters: the mean of the distribution µ and the standard deviation of the "
"distribution σ."
msgstr ""
"Selv om binomialfordelingen er den enkleste fordelingen å forstå, er den "
"ikke den viktigste. Den æren tilfaller **normalfordelingen**, også kalt "
"«klokkekurven» eller en «gaussisk fordeling». En normalfordeling beskrives "
"ved hjelp av to parametere: fordelingens gjennomsnitt µ og fordelingens "
"standardavvik σ."

#: ../../Ch07/Ch07_Probability_5.rst:13
msgid ""
"The notation that we sometimes use to say that a variable *X* is normally "
"distributed is as follows:"
msgstr ""
"Notasjonen som vi noen ganger bruker for å si at en variabel *X* er "
"normalfordelt, er som følger:"

#: ../../Ch07/Ch07_Probability_5.rst:16
msgid "X ~ Normal(µ, σ)"
msgstr "X ~ Normal(µ, σ)"

#: ../../Ch07/Ch07_Probability_5.rst:18
msgid ""
"Of course, that’s just notation. It doesn’t tell us anything interesting "
"about the normal distribution itself. As was the case with the binomial "
"distribution, I have included the formula for the normal distribution in "
"this book, because I think it’s important enough that everyone who learns "
"statistics should at least look at it, but since this is an introductory "
"text I don’t want to focus on it, so I’ve tucked it away in :numref:`tab-"
"distformulas`."
msgstr ""
"Det er selvfølgelig bare notasjon. Det forteller oss ikke noe interessant om "
"normalfordelingen i seg selv. I likhet med binomialfordelingen har jeg tatt "
"med formelen for normalfordelingen i denne boken, fordi jeg synes den er "
"såpass viktig at alle som lærer statistikk, i det minste bør se på den, men "
"siden dette er en innføringstekst, vil jeg ikke fokusere på den, så jeg har "
"gjemt den bort i :numref:`tab-distformulas`."

#: ../../Ch07/Ch07_Probability_5.rst:32
msgid "Normal distribution with mean μ = 0 and standard deviation σ = 1"
msgstr "Normalfordeling med gjennomsnitt μ = 0 og standardavvik σ = 1"

#: ../../Ch07/Ch07_Probability_5.rst:32
msgid ""
"The normal distribution with mean μ = 0 and standard deviation σ = 1. The x-"
"axis corresponds to the value of some variable, and the y-axis tells us "
"something about how likely we are to observe that value. However, notice "
"that the y-axis is labelled “Probability Density” and not “Probability”. "
"There is a subtle and somewhat frustrating characteristic of continuous "
"distributions that makes the y axis behave a bit oddly: the height of the "
"curve here isn’t actually the probability of observing a particular x value. "
"On the other hand, it is true that the heights of the curve tells you which "
"x values are more likely (the higher ones!; see :ref:`Probability density "
"<probability_density>` for all the annoying details)."
msgstr ""
"Normalfordelingen med gjennomsnitt μ = 0 og standardavvik σ = 1. X-aksen "
"tilsvarer verdien av en variabel, og y-aksen forteller oss noe om hvor "
"sannsynlig det er at vi observerer denne verdien. Legg imidlertid merke til "
"at y-aksen er merket sannsynlighetstetthet («Probability Density») og ikke "
"sannsynlighet («Probability»). Det er en subtil og litt frustrerende "
"egenskap ved kontinuerlige fordelinger som gjør at y-aksen oppfører seg litt "
"merkelig: Høyden på kurven her er faktisk ikke sannsynligheten for å "
"observere en bestemt x-verdi. På den annen side er det sant at høyden på "
"kurven forteller deg hvilke x-verdier som er mest sannsynlige (de høyeste!; "
"se :ref:`Sannsynlighetstetthet <probability_density>` for alle de "
"irriterende detaljene)."

#: ../../Ch07/Ch07_Probability_5.rst:45
msgid ""
"Instead of focusing on the maths, let’s try to get a sense for what it means "
"for a variable to be normally distributed. To that end, have a look at :"
"numref:`fig-standardNormal` which plots a normal distribution with mean µ = "
"0 and standard deviation σ = 1. You can see where the name “bell curve” "
"comes from; it looks a bit like a bell. Notice that, unlike the plots that I "
"drew to illustrate the binomial distribution, the picture of the normal "
"distribution in :numref:`fig-standardNormal` shows a smooth curve instead of "
"“histogram-like” bars. This isn’t an arbitrary choice, the normal "
"distribution is continuous whereas the binomial is discrete. For instance, "
"in the die rolling example from the last section it was possible to get 3 "
"skulls or 4 skulls, but impossible to get 3.9 skulls. The figures that I "
"drew in the previous section reflected this fact. In :numref:`fig-"
"binomSkulls20`, for instance, there’s a bar located at *X* = 3 and another "
"one at *X* = 4 but there’s nothing in between. Continuous quantities don’t "
"have this constraint. For instance, suppose we’re talking about the weather. "
"The temperature on a pleasant Spring day could be 23 degrees, 24 degrees, "
"23.9 degrees, or anything in between since temperature is a continuous "
"variable |continuous|. And so a normal distribution might be quite "
"appropriate for describing Spring temperatures.\\ [#]_"
msgstr ""
"I stedet for å fokusere på matematikken, kan vi prøve å få en følelse av hva "
"det vil si at en variabel er normalfordelt. Ta en titt på :numref:`fig-"
"standardNormal`, som plotter en normalfordeling med gjennomsnitt µ = 0 og "
"standardavvik σ = 1. Du kan se hvor navnet «bjellekurve» kommer fra; den ser "
"litt ut som en bjelle. Legg merke til at i motsetning til plottene jeg "
"tegnet for å illustrere binomialfordelingen, viser bildet av "
"normalfordelingen i :numref:`fig-standardNormal` en glatt kurve i stedet for "
"«histogramlignende» søyler. Dette er ikke et vilkårlig valg, "
"normalfordelingen er kontinuerlig, mens binomialfordelingen er diskret. I "
"terningeksempelet fra forrige avsnitt var det for eksempel mulig å få 3 "
"hodeskaller eller 4 hodeskaller, men umulig å få 3,9 hodeskaller. Figurene "
"jeg tegnet i forrige avsnitt, gjenspeilte dette faktumet. I :numref:`fig-"
"binomSkulls20`, for eksempel, er det en stolpe ved *X* = 3 og en annen ved "
"*X* = 4, men det er ingenting i mellom. Kontinuerlige størrelser har ikke "
"denne begrensningen. La oss for eksempel tenke oss at vi snakker om været. "
"Temperaturen på en fin vårdag kan være 23 grader, 24 grader, 23,9 grader "
"eller hva som helst midt imellom, siden temperaturen er en kontinuerlig "
"variabel |continuous|. Derfor kan en normalfordeling være ganske passende "
"for å beskrive vårtemperaturer.\\ [#]_"

#: ../../Ch07/Ch07_Probability_5.rst:252
msgid "continuous"
msgstr "continuous"

#: ../../Ch07/Ch07_Probability_5.rst:72
msgid "Normal distribution: σ = 1 and µ = 4 (solid) or µ = 7 (dashed)"
msgstr "Normalfordeling: σ = 1 og µ = 4 (heltrukket) eller µ = 7 (stiplet)"

#: ../../Ch07/Ch07_Probability_5.rst:72
msgid ""
"Illustration of what happens when you change the mean of a normal "
"distribution. The solid line depicts a normal distribution with a mean of μ "
"= 4. The dashed line shows a normal distribution with a mean of μ = 7. In "
"both cases, the standard deviation is σ = 1. Not surprisingly, the two "
"distributions have the same shape, but the dashed line is shifted to the "
"right."
msgstr ""
"Illustrasjon av hva som skjer når man endrer gjennomsnittet i en "
"normalfordeling. Den heltrukne linjen viser en normalfordeling med et "
"gjennomsnitt på μ = 4. Den stiplede linjen viser en normalfordeling med et "
"gjennomsnitt på μ = 7. I begge tilfeller er standardavviket σ = 1. Ikke "
"overraskende har de to fordelingene samme form, men den stiplede linjen er "
"forskjøvet mot høyre."

#: ../../Ch07/Ch07_Probability_5.rst:81
msgid ""
"With this in mind, let’s see if we can’t get an intuition for how the normal "
"distribution works. First, let’s have a look at what happens when we play "
"around with the parameters of the distribution. To that end, :numref:`fig-"
"meanShiftNormal` plots normal distributions that have different means but "
"have the same standard deviation. As you might expect, all of these "
"distributions have the same “width”. The only difference between them is "
"that they’ve been shifted to the left or to the right. In every other "
"respect they’re identical. In contrast, if we increase the standard "
"deviation while keeping the mean constant, the peak of the distribution "
"stays in the same place but the distribution gets wider, as you can see in :"
"numref:`fig-scaleShiftNormal`."
msgstr ""
"Med dette i bakhodet, la oss se om vi ikke kan få en intuisjon for hvordan "
"normalfordelingen fungerer. La oss først se på hva som skjer når vi leker "
"med parametrene til fordelingen. For å gjøre dette plotter :numref:`fig-"
"meanShiftNormal` normalfordelinger som har forskjellig gjennomsnitt, men "
"samme standardavvik. Som du kanskje forventer, har alle disse fordelingene "
"samme «bredde». Den eneste forskjellen mellom dem er at de er forskjøvet til "
"venstre eller til høyre. I alle andre henseender er de identiske. Hvis vi "
"derimot øker standardavviket mens gjennomsnittet holdes konstant, forblir "
"toppen av fordelingen på samme sted, men fordelingen blir bredere, som du "
"kan se i :numref:`fig-scaleShiftNormal`."

#: ../../Ch07/Ch07_Probability_5.rst:99
msgid "Normal distribution: µ = 5 and σ = 1 (solid) or σ = 2 (dashed)"
msgstr "Normalfordeling: µ = 5 og σ = 1 (heltrukken) eller σ = 2 (stiplet)"

#: ../../Ch07/Ch07_Probability_5.rst:99
msgid ""
"Illustration of what happens when you change the standard deviation of a "
"normal distribution. Both distributions plotted in this figure have a mean "
"of μ = 5, but they have different standard deviations. The solid line plots "
"a distribution with standard deviation σ = 1, and the dashed line shows a "
"distribution with standard deviation σ = 2. As a consequence, both "
"distributions are “centred” on the same spot, but the dashed line is wider "
"than the solid one."
msgstr ""
"Illustrasjon av hva som skjer når du endrer standardavviket til en "
"normalfordeling. Begge fordelingene i denne figuren har et gjennomsnitt på μ "
"= 5, men de har ulike standardavvik. Den heltrukne linjen viser en fordeling "
"med standardavviket σ = 1, og den stiplede linjen viser en fordeling med "
"standardavviket σ = 2. Begge fordelingene er altså «sentrert» på samme sted, "
"men den stiplede linjen er bredere enn den heltrukne."

#: ../../Ch07/Ch07_Probability_5.rst:109
msgid ""
"Notice, though, that when we widen the distribution the height of the peak "
"shrinks. This has to happen, in the same way that the heights of the bars "
"that we used to draw a discrete binomial distribution have to *sum* to 1, "
"the total *area under the curve* for the normal distribution must equal 1. "
"Before moving on, I want to point out one important characteristic of the "
"normal distribution. Irrespective of what the actual mean and standard "
"deviation are, 68.3\\% of the area falls within 1 standard deviation of the "
"mean. Similarly, 95.4\\% of the distribution falls within 2 standard "
"deviations of the mean, and 99.7\\% of the distribution is within 3 standard "
"deviations. This idea is illustrated in :numref:`fig-normAreaSD`."
msgstr ""
"Legg imidlertid merke til at når vi utvider fordelingen, krymper høyden på "
"toppen. Dette må skje, på samme måte som høyden på stolpene som vi brukte "
"til å tegne en diskret binomialfordeling må *summere* til 1, må det totale "
"*arealet under kurven* for normalfordelingen være lik 1. Før jeg går videre, "
"vil jeg påpeke en viktig egenskap ved normalfordelingen. Uavhengig av hva "
"det faktiske gjennomsnittet og standardavviket er, faller 68,3\\% av arealet "
"innenfor 1 standardavvik fra gjennomsnittet. På samme måte ligger 95,4\\% av "
"fordelingen innenfor 2 standardavvik fra gjennomsnittet, og 99,7\\% av "
"fordelingen ligger innenfor 3 standardavvik. Denne ideen er illustrert i :"
"numref:`fig-normAreaSD`."

#: ../../Ch07/Ch07_Probability_5.rst:127
msgid "Normal distribution: area under the curve for 1 and 2 SD"
msgstr "Normalfordeling: areal under kurven for 1 og 2 SD"

#: ../../Ch07/Ch07_Probability_5.rst:127
msgid ""
"The area under the curve tells you the probability that an observation falls "
"within a particular range. The solid lines plot normal distributions with "
"mean μ = 0 and standard deviation σ = 1. The shaded areas illustrate “areas "
"under the curve” for two important cases. In the left panel, we can see that "
"there is a 68.3\\% chance that an observation will fall within one standard "
"deviation of the mean. In the right panel, we see that there is a 95.4\\% "
"chance that an observation will fall within two standard deviations of the "
"mean."
msgstr ""
"Arealet under kurven forteller deg sannsynligheten for at en observasjon "
"faller innenfor et bestemt område. De heltrukne linjene viser "
"normalfordelinger med gjennomsnitt μ = 0 og standardavvik σ = 1. De "
"skraverte områdene illustrerer «arealene under kurven» for to viktige "
"tilfeller. I det venstre panelet ser vi at det er 68,3\\% sjanse for at en "
"observasjon vil falle innenfor ett standardavvik fra gjennomsnittet. I det "
"høyre panelet ser vi at det er 95,4\\% sjanse for at en observasjon vil "
"falle innenfor to standardavvik fra gjennomsnittet."

#: ../../Ch07/Ch07_Probability_5.rst:142
msgid "Area under the curve for 1 SD bordering the mean and at the tails"
msgstr ""
"Arealet under kurven for 1 SD på grensen til gjennomsnittet og ved halene"

#: ../../Ch07/Ch07_Probability_5.rst:142
msgid ""
"Two more examples of the “area under the curve” idea. There is a 15.9\\% "
"chance that an observation is one standard deviation below the mean or "
"smaller (left panel), and a 34.1\\% chance that the observation is somewhere "
"between one standard deviation below the mean and the mean (right panel). "
"Notice that if you add these two numbers together you get 15.9\\% + 34.1\\% "
"= 50\\%. For normally distributed data, there is a 50\\% chance that an "
"observation falls below the mean. And of course that also implies that there "
"is a 50\\% chance that it falls above the mean."
msgstr ""
"To eksempler til på ideen om «arealet under kurven». Det er 15,9\\% sjanse "
"for at en observasjon ligger ett standardavvik under gjennomsnittet eller "
"mindre (venstre panel), og 34,1\\% sjanse for at observasjonen ligger et "
"sted mellom ett standardavvik under gjennomsnittet og gjennomsnittet (høyre "
"panel). Legg merke til at hvis du legger sammen disse to tallene, får du "
"15,9\\% + 34,1\\% = 50\\%. For normalfordelte data er det 50\\% sjanse for "
"at en observasjon faller under gjennomsnittet. Og det innebærer selvfølgelig "
"også at det er 50\\% sjanse for at den faller over gjennomsnittet."

#: ../../Ch07/Ch07_Probability_5.rst:156
msgid "Probability density"
msgstr "Sannsynlighetstetthet"

#: ../../Ch07/Ch07_Probability_5.rst:158
msgid ""
"There’s something I’ve been trying to hide throughout my discussion of the "
"normal distribution, something that some introductory textbooks omit "
"completely. They might be right to do so. This “thing” that I’m hiding is "
"weird and counter-intuitive even by the admittedly distorted standards that "
"apply in statistics. Fortunately, it’s not something that you need to "
"understand at a deep level in order to do basic statistics. Rather, it’s "
"something that starts to become important later on when you move beyond the "
"basics. So, if it doesn’t make complete sense, don’t worry too much, but try "
"to make sure that you follow the gist of it."
msgstr ""
"Det er noe jeg har forsøkt å skjule gjennom hele diskusjonen av "
"normalfordelingen, noe som noen innføringsbøker utelater helt. Det gjør de "
"kanskje rett i. Denne «tingen» jeg skjuler, er underlig og kontraintuitiv, "
"selv etter de riktignok forvrengte standardene som gjelder i statistikk. "
"Heldigvis er det ikke noe du trenger å forstå på et dypt nivå for å kunne "
"gjøre grunnleggende statistikk. Det er snarere noe som begynner å bli viktig "
"senere, når du beveger deg utover det grunnleggende. Så hvis det ikke gir "
"helt mening, ikke tenk for mye på det, men prøv å forsikre deg om at du "
"forstår kjernen i det."

#: ../../Ch07/Ch07_Probability_5.rst:168
msgid ""
"Throughout my discussion of the normal distribution there’s been one or two "
"things that don’t quite make sense. Perhaps you noticed that the *y*-axis in "
"these figures is labelled “Probability Density” rather than “Density”. Maybe "
"you noticed that I used *p*\\ (X) instead of *P*\\ (X) when giving the "
"formula for the normal distribution."
msgstr ""
"Underveis i diskusjonen om normalfordelingen har det vært en eller to ting "
"som ikke helt gir mening. Kanskje har du lagt merke til at *y*-aksen i disse "
"figurene er merket sannsynlighetstetthet («Probability Density») i stedet "
"for tetthet («Density»). Kanskje du la merke til at jeg brukte *p*\\(X) i "
"stedet for *P*\\(X) da jeg oppga formelen for normalfordelingen."

#: ../../Ch07/Ch07_Probability_5.rst:174
msgid ""
"As it turns out, what is presented here isn’t actually a probability, it’s "
"something else. To understand what that something is you have to spend a "
"little time thinking about what it really *means* to say that *X* is a "
"continuous variable |continuous|. Let’s say we’re talking about the "
"temperature outside. The thermometer tells me it’s 23 degrees, but I know "
"that’s not really true. It’s not *exactly* 23 degrees. Maybe it’s \\23.1 "
"degrees, I think to myself. But I know that that’s not really true either "
"because it might actually be 23.09 degrees. But I know that… well, you get "
"the idea. The tricky thing with genuinely continuous quantities is that you "
"never really know exactly what they are."
msgstr ""
"Det viser seg at det som presenteres her, faktisk ikke er en sannsynlighet, "
"det er noe annet. For å forstå hva dette noe er, må du bruke litt tid på å "
"tenke over hva det egentlig *betyr* å si at *X* er en kontinuerlig variabel |"
"continuous|. La oss si at vi snakker om temperaturen ute. Termometeret viser "
"meg at det er 23 grader, men jeg vet at det egentlig ikke stemmer. Det er "
"ikke *nøyaktig* 23 grader. Kanskje det er \\23,1 grader, tenker jeg for meg "
"selv. Men jeg vet at det heller ikke er helt sant, for det kan faktisk være "
"23,09 grader. Men jeg vet at… vel, du skjønner hva jeg mener. Det vanskelige "
"med virkelig kontinuerlige størrelser er at du aldri helt vet nøyaktig hva "
"de er."

#: ../../Ch07/Ch07_Probability_5.rst:185
msgid ""
"Now think about what this implies when we talk about probabilities. Suppose "
"that tomorrow’s maximum temperature is sampled from a normal distribution "
"with mean 23 and standard deviation 1. What’s the probability that the "
"temperature will be *exactly* 23 degrees? The answer is “zero”, or possibly "
"“a number so close to zero that it might as well be zero”. Why is this? It’s "
"like trying to throw a dart at an infinitely small dart board. No matter how "
"good your aim, you’ll never hit it. In real life you’ll never get a value of "
"exactly 23. It’ll always be something like 23.1 or 22.99998 or suchlike. In "
"other words, it’s completely meaningless to talk about the probability that "
"the temperature is exactly 23 degrees. However, in everyday language if I "
"told you that it was 23 degrees outside and it turned out to be 22.9998 "
"degrees you probably wouldn’t call me a liar. Because in everyday language "
"“23 degrees” usually means something like “somewhere between \\22.5 and 23.5 "
"degrees”. And while it doesn’t feel very meaningful to ask about the "
"probability that the temperature is exactly 23 degrees, it does seem "
"sensible to ask about the probability that the temperature lies between 22.5 "
"and 23.5, or between 20 and 30, or any other range of temperatures."
msgstr ""
"Tenk nå på hva dette innebærer når vi snakker om sannsynligheter. Anta at "
"morgendagens maksimumstemperatur er samplet fra en normalfordeling med "
"gjennomsnitt 23 og standardavvik 1. Hva er sannsynligheten for at "
"temperaturen blir *eksakt* 23 grader? Svaret er «null», eller muligens «et "
"tall så nær null at det like gjerne kunne vært null». Hvorfor er det slik? "
"Det er som å prøve å kaste en pil på en uendelig liten dartskive. Uansett "
"hvor godt du sikter, vil du aldri treffe. I virkeligheten vil du aldri få en "
"verdi på nøyaktig 23. Det vil alltid være noe sånt som 23,1 eller 22,99998 "
"eller lignende. Det er med andre ord helt meningsløst å snakke om "
"sannsynligheten for at temperaturen er nøyaktig 23 grader. Men hvis jeg i "
"dagligtalen fortalte deg at det var 23 grader ute, og det viste seg å være "
"22,9998 grader, ville du sannsynligvis ikke kalt meg en løgner. For i "
"dagligspråket betyr «23 grader» vanligvis noe sånt som «et sted mellom "
"\\22,5 og 23,5 grader». Og selv om det ikke føles særlig meningsfullt å "
"spørre om sannsynligheten for at temperaturen er nøyaktig 23 grader, virker "
"det fornuftig å spørre om sannsynligheten for at temperaturen ligger mellom "
"22,5 og 23,5, eller mellom 20 og 30, eller et hvilket som helst annet "
"temperaturintervall."

#: ../../Ch07/Ch07_Probability_5.rst:205
msgid ""
"The point of this discussion is to make clear that when we’re talking about "
"continuous distributions it’s not meaningful to talk about the probability "
"of a specific value. However, what we *can* talk about is the probability "
"that the value lies within a particular range of values. To find out the "
"probability associated with a particular range what you need to do is "
"calculate the “area under the curve”. We’ve seen this concept already, in :"
"numref:`fig-normAreaSD` the shaded areas shown depict genuine probabilities "
"(e.g., in the left panel of :numref:`fig-normAreaSD` it shows the "
"probability of observing a value that falls within 1 standard deviation of "
"the mean)."
msgstr ""
"Poenget med denne diskusjonen er å gjøre det klart at når vi snakker om "
"kontinuerlige fordelinger, er det ikke meningsfullt å snakke om "
"sannsynligheten for en spesifikk verdi. Det vi derimot *kan* snakke om, er "
"sannsynligheten for at verdien ligger innenfor et bestemt verdiintervall. "
"For å finne ut sannsynligheten som er knyttet til et bestemt område, må du "
"beregne «arealet under kurven». Vi har allerede sett dette konseptet, i :"
"numref:`fig-normAreaSD` viser de skraverte områdene reelle sannsynligheter "
"(f.eks. viser det venstre panelet i :numref:`fig-normAreaSD` sannsynligheten "
"for å observere en verdi som faller innenfor 1 standardavvik fra "
"gjennomsnittet)."

#: ../../Ch07/Ch07_Probability_5.rst:216
msgid ""
"Okay, so that explains part of the story. I’ve explained a little bit about "
"how continuous probability distributions should be interpreted (i.e., area "
"under the curve is the key thing). But what does the formula for *p*\\ (x) "
"that I described earlier actually mean? Obviously, p*\\ (x) doesn’t describe "
"a probability, but what is it? The name for this quantity *p*\\ (x) is a "
"**probability density**, and in terms of the plots we’ve been drawing it "
"corresponds to the *height* of the curve. The densities themselves aren’t "
"meaningful in and of themselves, but they’re “rigged” to ensure that the "
"*area* under the curve is always interpretable as genuine probabilities. To "
"be honest, that’s about as much as you really need to know for now.\\ [#]_"
msgstr ""
"Ok, så det forklarer en del av historien. Jeg har forklart litt om hvordan "
"kontinuerlige sannsynlighetsfordelinger bør tolkes (dvs. at arealet under "
"kurven er det viktigste). Men hva betyr egentlig formelen for *p*\\(x) som "
"jeg beskrev tidligere? Det er klart at p*\\ (x) ikke beskriver en "
"sannsynlighet, men hva er det da? Navnet på denne størrelsen *p*\\ (x) er en "
"**sannsynlighetstetthet**, og i forhold til plottene vi har tegnet, "
"tilsvarer den *høyden* på kurven. Tetthetene i seg selv er ikke "
"meningsfulle, men de er «rigget» for å sikre at *arealet* under kurven "
"alltid kan tolkes som reelle sannsynligheter. For å være ærlig er det "
"omtrent så mye du trenger å vite for øyeblikket.\\ [#]_"

#: ../../Ch07/Ch07_Probability_5.rst:231
msgid ""
"In practice, the normal distribution is so handy that people tend to use it "
"even when the variable isn’t actually continuous. As long as there are "
"enough categories (e.g., Likert scale responses to a questionnaire), it’s "
"pretty standard practice to use the normal distribution as an approximation. "
"This works out much better in practice than you’d think."
msgstr ""
"I praksis er normalfordelingen så praktisk at folk har en tendens til å "
"bruke den selv når variabelen faktisk ikke er kontinuerlig. Så lenge det "
"finnes nok kategorier (f.eks. svar på Likert-skalaen i et spørreskjema), er "
"det ganske vanlig å bruke normalfordelingen som en tilnærming. Dette "
"fungerer mye bedre i praksis enn man skulle tro."

#: ../../Ch07/Ch07_Probability_5.rst:239
msgid ""
"For those readers who know a little calculus, I’ll give a slightly more "
"precise explanation. In the same way that probabilities are non-negative "
"numbers that must sum to 1, probability densities are non-negative numbers "
"that must integrate to 1 (where the integral is taken across all possible "
"values of *X*). To calculate the probability that *X* falls between *a* and "
"*b* we calculate the definite integral of the density function over the "
"corresponding range, :math:`\\int_a^b p(x) \\ dx`. If you don’t remember or "
"never learned calculus, don’t worry about this. It’s not needed for this "
"book."
msgstr ""
"For de leserne som kan litt regning, skal jeg gi en litt mer presis "
"forklaring. På samme måte som sannsynligheter er ikke-negative tall som må "
"summere til 1, er sannsynlighetstettheter ikke-negative tall som må "
"integreres til 1 (der integralet tas over alle mulige verdier av *X*). For å "
"beregne sannsynligheten for at *X* faller mellom *a* og *b*, beregner vi det "
"bestemte integralet av tetthetsfunksjonen over det tilsvarende området, :"
"math:`\\int_a^b p(x) \\ dx`. Hvis du ikke husker eller aldri har lært "
"kalkulus, trenger du ikke bekymre deg for dette. Det er ikke nødvendig for "
"denne boken."

#: ../../Ch07/Ch07_Probability_6.rst:4
msgid "Other useful distributions"
msgstr "Andre nyttige distribusjoner"

#: ../../Ch07/Ch07_Probability_6.rst:6
msgid ""
"The normal distribution is the distribution that statistics makes most use "
"of (for reasons to be discussed shortly), and the binomial distribution is a "
"very useful one for lots of purposes. But the world of statistics is filled "
"with probability distributions, some of which we’ll run into in passing. In "
"particular, the three that will appear in this book are the *t*-"
"distribution, the χ²-distribution and the *F*-distribution. I won’t give "
"formulas for any of these, or talk about them in too much detail, but I will "
"show you some pictures."
msgstr ""
"Normalfordelingen er den fordelingen som brukes mest i statistikken (av "
"grunner som vi skal komme tilbake til), og binomialfordelingen er en svært "
"nyttig fordeling til mange formål. Men statistikkens verden er full av "
"sannsynlighetsfordelinger, og noen av dem kommer vi til å støte på i "
"forbifarten. De tre vi kommer til å se nærmere på i denne boken, er *t*-"
"fordelingen, χ²-fordelingen og *F*-fordelingen. Jeg vil ikke gi formler for "
"noen av disse, eller snakke om dem i detalj, men jeg vil vise deg noen "
"bilder."

#: ../../Ch07/Ch07_Probability_6.rst:15
msgid ""
"The **t-distribution** is a continuous distribution that looks very similar "
"to a normal distribution, see :numref:`fig-tdist`. Note that the “tails” of "
"the *t*-distribution are “heavier” (i.e., extend further outwards) than the "
"tails of the normal distribution). That’s the important difference between "
"the two. This distribution tends to arise in situations where you think that "
"the data actually follow a normal distribution, but you don’t know the mean "
"or standard deviation. We’ll run into this distribution again in chapter :"
"doc:`../Ch11/Ch11_tTest`."
msgstr ""
"**t-fordelingen** er en kontinuerlig fordeling som ligner veldig på en "
"normalfordeling, se :numref:`fig-tdist`. Merk at «halene» til *t*-"
"fordelingen er «tyngre» (dvs. strekker seg lenger utover) enn halene til "
"normalfordelingen.) Det er den viktige forskjellen mellom de to. Denne "
"fordelingen oppstår gjerne i situasjoner der man tror at dataene faktisk "
"følger en normalfordeling, men der man ikke kjenner gjennomsnittet eller "
"standardavviket. Vi kommer til å støte på denne fordelingen igjen i "
"kapittel :doc:`../Ch11/Ch11_tTest`."

#: ../../Ch07/Ch07_Probability_6.rst:30
msgid "*t*-distribution with *df* = 3 in comparison to a normal distribution"
msgstr "*t*-fordeling med *df* = 3 sammenlignet med en normalfordeling"

#: ../../Ch07/Ch07_Probability_6.rst:30
msgid ""
"*t*-distribution with 3 degrees of freedom (solid line). It looks similar to "
"a normal distribution, but it’s not quite the same. For comparison purposes "
"I’ve plotted a standard normal distribution as the dashed line."
msgstr ""
"*t*-fordeling med 3 frihetsgrader (heltrukken linje). Den ligner på en "
"normalfordeling, men er ikke helt den samme. Til sammenligning har jeg "
"tegnet inn en standard normalfordeling som den stiplede linjen."

#: ../../Ch07/Ch07_Probability_6.rst:36
msgid ""
"The **χ²-distribution** is another distribution that turns up in lots of "
"different places. The situation in which we’ll see it is when doing :doc:`../"
"Ch10/Ch10_ChiSquare`, but it’s one of those things that actually pops up all "
"over the place. When you dig into the maths (and who doesn’t love doing "
"that?), it turns out that the main reason why the χ²-distribution turns up "
"all over the place is that if you have a bunch of variables that are "
"normally distributed, square their values and then add them up (a procedure "
"referred to as taking a “sum of squares”), this sum has a χ²-distribution. "
"You’d be amazed how often this fact turns out to be useful. Anyway, :numref:"
"`fig-chiSqDist` illustrates what a χ²-distribution looks like."
msgstr ""
"**χ²-fordelingen** er en annen fordeling som dukker opp mange forskjellige "
"steder. Situasjonen vi skal se den i, er når vi gjør :doc:`../Ch10/"
"Ch10_ChiSquare`, men det er en av de tingene som faktisk dukker opp over "
"alt. Når man setter seg inn i matematikken (og hvem elsker ikke å gjøre "
"det?), viser det seg at hovedgrunnen til at χ²-fordelingen dukker opp "
"overalt, er at hvis man har en haug med variabler som er normalfordelte, "
"kvadrerer verdiene deres og deretter legger dem sammen (en prosedyre som "
"kalles å ta en «kvadratsum»), så har denne summen en χ²-fordeling. Du vil "
"bli overrasket over hvor ofte dette faktumet viser seg å være nyttig. "
"Uansett, :numref:`fig-chiSqDist` illustrerer hvordan en χ²-fordeling ser ut."

#: ../../Ch07/Ch07_Probability_6.rst:54
msgid "χ²-distribution with *df* = 3"
msgstr "χ²-fordeling med *df* = 3"

#: ../../Ch07/Ch07_Probability_6.rst:54
msgid ""
"χ²-distribution with 3 degrees of freedom. Notice that the observed values "
"must always be greater than zero, and that the distribution is pretty "
"skewed. These are the key features of a χ²-distribution."
msgstr ""
"χ²-fordeling med 3 frihetsgrader. Legg merke til at de observerte verdiene "
"alltid må være større enn null, og at fordelingen er ganske skjev. Dette er "
"de viktigste kjennetegnene ved en χ²-fordeling."

#: ../../Ch07/Ch07_Probability_6.rst:60
msgid ""
"The **F-distribution** looks a bit like a χ²-distribution, and it arises "
"whenever you need to compare two χ²-distributions to one another. "
"Admittedly, this doesn’t exactly sound like something that any sane person "
"would want to do, but it turns out to be very important in real world data "
"analysis. Remember when I said that χ² turns out to be the key distribution "
"when we’re taking a “sum of squares”? Well, what that means is if you want "
"to compare two different “sums of squares”, you’re probably talking about "
"something that has an *F*-distribution. Of course, as yet I still haven’t "
"given you an example of anything that involves a sum of squares, but I will "
"in chapter :doc:`../Ch13/Ch13_ANOVA`. And that’s where we’ll run into the "
"*F*-distribution. Oh, and there’s a picture in :numref:`fig-Fdist`."
msgstr ""
"**F-fordelingen** ser litt ut som en χ²-fordeling, og den oppstår når du "
"trenger å sammenligne to χ²-fordelinger med hverandre. Dette høres riktignok "
"ikke akkurat ut som noe en fornuftig person ønsker å gjøre, men det viser "
"seg å være svært viktig i dataanalyse i den virkelige verden. Husker du da "
"jeg sa at χ² viser seg å være nøkkelfordelingen når vi tar en «kvadratsum«? "
"Vel, det betyr at hvis du vil sammenligne to forskjellige «kvadratsummer», "
"snakker du sannsynligvis om noe som har en *F*-fordeling. Jeg har "
"selvfølgelig ennå ikke gitt deg et eksempel på noe som involverer en "
"kvadratsum, men det skal jeg gjøre i kapittel :doc:`../Ch13/Ch13_ANOVA`. Og "
"det er der vi kommer til å støte på *F*-fordelingen. Åh, og det er et bilde "
"i :numref:`fig-Fdist`."

#: ../../Ch07/Ch07_Probability_6.rst:78
msgid "*F*-distribution with *df* = 3 and *df* = 5"
msgstr "*F*-fordeling med *df* = 3 og *df* = 5"

#: ../../Ch07/Ch07_Probability_6.rst:78
msgid ""
"*F*-distribution with 3 and 5 degrees of freedom. Qualitatively speaking, it "
"looks pretty similar to a χ²-distribution, but they’re not quite the same in "
"general."
msgstr ""
"*F*-fordeling med 3 og 5 frihetsgrader. Kvalitativt sett ligner den ganske "
"mye på en χ²-fordeling, men de er ikke helt like generelt."

#: ../../Ch07/Ch07_Probability_6.rst:84
msgid ""
"Okay, time to wrap this section up. We’ve seen three new distributions: *t*, "
"χ² and *F*. They’re all continuous distributions, and they’re all closely "
"related to the normal distribution. The main thing for our purposes is that "
"you grasp the basic idea that these distributions are all deeply related to "
"one another, and to the normal distribution. Later on in this book we’re "
"going to run into data that are normally distributed, or at least assumed to "
"be normally distributed. What I want you to understand right now is that, if "
"you make the assumption that your data are normally distributed, you "
"shouldn’t be surprised to see *t*-, χ²- and *F*-distributions popping up all "
"over the place when you start trying to do your data analysis."
msgstr ""
"På tide å avslutte denne delen. Vi har sett tre nye distribusjoner: *t*, χ² "
"og *F*. De er alle kontinuerlige fordelinger, og de er alle nært beslektet "
"med normalfordelingen. Det viktigste for vårt formål er at du forstår den "
"grunnleggende ideen om at disse fordelingene alle er nært beslektet med "
"hverandre og med normalfordelingen. Senere i denne boken kommer vi til å "
"støte på data som er normalfordelte, eller som i det minste antas å være "
"normalfordelte. Det jeg vil at du skal forstå nå, er at hvis du antar at "
"dataene dine er normalfordelte, bør du ikke bli overrasket over å se *t*-, "
"χ²- og *F*-fordelinger dukke opp over alt når du begynner å analysere "
"dataene dine."

#: ../../Ch07/Ch07_Probability_7.rst:4
msgid "Summary"
msgstr "Sammendrag"

#: ../../Ch07/Ch07_Probability_7.rst:6
msgid ""
"In this chapter we’ve talked about probability. We’ve talked about what "
"probability means and why statisticians can’t agree on what it means. We "
"talked about the rules that probabilities have to obey. And we introduced "
"the idea of a probability distribution and spent a good chunk of the chapter "
"talking about some of the more important probability distributions that "
"statisticians work with. The section by section breakdown looks like this:"
msgstr ""
"I dette kapittelet har vi snakket om sannsynlighet. Vi har snakket om hva "
"sannsynlighet betyr, og hvorfor statistikere ikke kan enes om hva det betyr. "
"Vi har snakket om reglene som sannsynligheter må følge. Vi har også "
"introdusert ideen om sannsynlighetsfordeling og brukt en god del av kapitlet "
"på å snakke om noen av de viktigste sannsynlighetsfordelingene som "
"statistikere jobber med. Inndelingen i de ulike delene ser slik ut:"

#: ../../Ch07/Ch07_Probability_7.rst:14
msgid ":doc:`Probability theory versus statistics <Ch07_Probability_1>`"
msgstr ":doc:`Sannsynlighetsteori versus statistikk <Ch07_Probability_1>`"

#: ../../Ch07/Ch07_Probability_7.rst:16
msgid ""
":doc:`Frequentist versus Bayesian views of probability <Ch07_Probability_2>`"
msgstr ""
":doc:`Frekventistisk versus bayesiansk syn på sannsynlighet "
"<Ch07_Probability_2>`"

#: ../../Ch07/Ch07_Probability_7.rst:18
msgid ":doc:`Basics of probability theory <Ch07_Probability_3>`"
msgstr ":doc:`Grunnleggende sannsynlighetsregning <Ch07_Probability_3>`"

#: ../../Ch07/Ch07_Probability_7.rst:20
msgid ""
":doc:`Binomial distribution <Ch07_Probability_4>`, :doc:`normal distribution "
"<Ch07_Probability_5>`, and :doc:`other useful distributions "
"<Ch07_Probability_6>`"
msgstr ""
":doc:`Binomialfordeling <Ch07_Probability_4>`, :doc:`normalfordeling "
"<Ch07_Probability_5>`, og :doc:`andre nyttige fordelinger "
"<Ch07_Probability_6>`"

#: ../../Ch07/Ch07_Probability_7.rst:24
msgid ""
"As you’d expect, my coverage is by no means exhaustive. Probability theory "
"is a large branch of mathematics in its own right, entirely separate from "
"its application to statistics and data analysis. As such, there are "
"thousands of books written on the subject and universities generally offer "
"multiple classes devoted entirely to probability theory. Even the “simpler” "
"task of documenting standard probability distributions is a big topic. I’ve "
"described five standard probability distributions in this chapter, but "
"sitting on my bookshelf I have a 47-chapter book called “Statistical "
"Distributions” (:ref:`Forbes et al., 2010 <Forbes_2010>`) that lists a *lot* "
"more than that. Fortunately for you, very little of this is necessary. "
"You’re unlikely to need to know dozens of statistical distributions when you "
"go out and do real world data analysis, and you definitely won’t need them "
"for this book, but it never hurts to know that there’s other possibilities "
"out there."
msgstr ""
"Som du kan forvente, er dekningen min på ingen måte uttømmende. "
"Sannsynlighetsteori er en stor gren av matematikken i seg selv, helt atskilt "
"fra statistikk og dataanalyse. Det er skrevet tusenvis av bøker om emnet, og "
"universitetene tilbyr som regel flere kurs som utelukkende er viet til "
"sannsynlighetsteori. Selv den «enklere» oppgaven med å dokumentere standard "
"sannsynlighetsfordelinger er et stort tema. Jeg har beskrevet fem standard "
"sannsynlighetsfordelinger i dette kapittelet, men i bokhyllen min har jeg en "
"bok med 47 kapitler som heter «Statistical Distributions» (:ref:`Forbes et "
"al., 2010 <Forbes_2010>`) som inneholder *mye* mer enn det. Heldigvis for "
"deg er det svært lite av dette som er nødvendig. Det er lite sannsynlig at "
"du trenger å kjenne til dusinvis av statistiske fordelinger når du skal ut "
"og analysere data i den virkelige verden, og du vil definitivt ikke trenge "
"dem for denne boken, men det skader aldri å vite at det finnes andre "
"muligheter der ute."

#: ../../Ch07/Ch07_Probability_7.rst:38
msgid ""
"Picking up on that last point, there’s a sense in which this whole chapter "
"is something of a digression. Many undergraduate psychology classes on "
"statistics skim over this content very quickly (I know mine did), and even "
"the more advanced classes will often “forget” to revisit the basic "
"foundations of the field. Most academic psychologists would not know the "
"difference between probability and density, and until recently very few "
"would have been aware of the difference between Bayesian and frequentist "
"probability. However, I think it’s important to understand these things "
"before moving onto the applications. For example, there are a lot of rules "
"about what you’re “allowed” to say when doing statistical inference and many "
"of these can seem arbitrary and weird. However, they start to make sense if "
"you understand that there is this Bayesian / frequentist distinction. "
"Similarly, in chapter :doc:`../Ch11/Ch11_tTest` we’re going to talk about "
"something called the *t*-test, and if you really want to have a grasp of the "
"mechanics of the *t*-test it really helps to have a sense of what a *t*-"
"distribution actually looks like. You get the idea, I hope."
msgstr ""
"For å ta opp det siste poenget, så er hele dette kapittelet på sett og vis "
"en digresjon. Mange psykologikurs på lavere grads nivå skummer raskt over "
"dette innholdet (jeg vet at mitt kurs gjorde det), og selv de mer avanserte "
"kursene «glemmer» ofte å gå tilbake til de grunnleggende fundamentene på "
"feltet. De fleste akademiske psykologer vet ikke forskjellen mellom "
"sannsynlighet og tetthet, og inntil nylig var det svært få som var klar over "
"forskjellen mellom bayesiansk og frekventistisk sannsynlighetsregning. Jeg "
"tror imidlertid det er viktig å forstå disse tingene før man går videre til "
"anvendelsene. Det finnes for eksempel mange regler for hva man har «lov» til "
"å si når man gjør statistiske slutninger, og mange av disse kan virke "
"vilkårlige og merkelige. De begynner imidlertid å gi mening hvis du forstår "
"at det finnes et skille mellom bayesianere og frekventister. På samme måte "
"skal vi i kapittel :doc:`../Ch11/Ch11_tTest` snakke om noe som kalles *t*-"
"testen, og hvis du virkelig vil forstå mekanismene i *t*-testen, hjelper det "
"å ha en følelse av hvordan en *t*-fordeling faktisk ser ut. Jeg håper du "
"skjønner hva jeg mener."
