msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-03-17 18:06+0100\n"
"PO-Revision-Date: 2025-03-31 16:01+0000\n"
"Last-Translator: Anonymous <noreply@weblate.org>\n"
"Language-Team: Norwegian Bokmål <https://hosted.weblate.org/projects/lsjdocs/"
"ch08/nb_NO/>\n"
"Language: nb\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"X-Generator: Weblate 5.11-dev\n"
"Generated-By: Babel 2.15.0\n"

#: ../../Ch08/Ch08_Estimation.rst:4
msgid "Estimating unknown quantities from a sample"
msgstr "Estimering av ukjente størrelser fra et utvalg"

#: ../../Ch08/Ch08_Estimation.rst:18
msgid ""
"At the start of the last chapter I highlighted the critical distinction "
"between *descriptive statistics* and *inferential statistics*. As discussed "
"in :doc:`../Ch04/Ch04_Descriptives`, the role of descriptive statistics is "
"to concisely summarise what we *do* know. In contrast, the purpose of "
"inferential statistics is to “learn what we do not know from what we do”. "
"Now that we have a foundation in probability theory we are in a good "
"position to think about the problem of statistical inference. What kinds of "
"things would we like to learn about? And how do we learn them? These are the "
"questions that lie at the heart of inferential statistics, and they are "
"traditionally divided into two “big ideas”: estimation and hypothesis "
"testing. The goal in this chapter is to introduce the first of these big "
"ideas, estimation theory, but I’m going to witter on about sampling theory "
"first because estimation theory doesn’t make sense until you understand "
"sampling. As a consequence, this chapter divides naturally into two parts :"
"doc:`Ch08_Estimation_1` through :doc:`Ch08_Estimation_3` are focused on "
"sampling theory, and :doc:`Ch08_Estimation_4` and :doc:`Ch08_Estimation_5` "
"make use of sampling theory to discuss how statisticians think about "
"estimation."
msgstr ""
"I begynnelsen av forrige kapittel understreket jeg det viktige skillet "
"mellom *deskriptivstatistikk* og *inferensstatistikk*. Som diskutert i :doc:`"
"../Ch04/Ch04_Descriptives`, er det deskriptivstatistikk sin rolle å "
"sammenfatte det vi *vet*. I motsetning til dette er formålet med "
"inferensstatistikk å «lære det vi ikke vet av det vi vet». Nå som vi har et "
"grunnlag i sannsynlighetsteori, har vi et godt utgangspunkt for å tenke på "
"problemet med statistisk inferens. Hva slags ting ønsker vi å lære om? Og "
"hvordan lærer vi om dem? Dette er spørsmålene som står i sentrum for "
"inferensstatistikk, og de deles tradisjonelt inn i to «store ideer»: "
"estimering og hypotesetesting. Målet med dette kapittelet er å introdusere "
"den første av disse store ideene, estimeringsteori, men jeg kommer til å "
"snakke om utvalgsteori først, fordi estimeringsteori ikke gir mening før du "
"forstår utvalg. Derfor deler dette kapittelet seg naturlig nok i to deler: "
":doc:`Ch08_Estimation_1` til :doc:`Ch08_Estimation_3` fokuserer på "
"utvalgsteori, og :doc:`Ch08_Estimation_4` og :doc:`Ch08_Estimation_5` bruker "
"utvalgsteori til å diskutere hvordan statistikere tenker om estimering."

#: ../../Ch08/Ch08_Estimation_1.rst:4
msgid "Samples, populations and sampling"
msgstr "Prøver, populasjoner og prøvetaking"

#: ../../Ch08/Ch08_Estimation_1.rst:6
msgid ""
"In the prelude to Part  I discussed the riddle of induction and highlighted "
"the fact that *all* learning requires you to make assumptions. Accepting "
"that this is true, our first task to come up with some fairly general "
"assumptions about data that make sense. This is where **sampling theory** "
"comes in. If probability theory is the foundations upon which all "
"statistical theory builds, sampling theory is the frame around which you can "
"build the rest of the house. Sampling theory plays a huge role in specifying "
"the assumptions upon which your statistical inferences rely. And in order to "
"talk about “making inferences” the way statisticians think about it we need "
"to be a bit more explicit about what it is that we’re drawing inferences "
"*from* (the sample) and what it is that we’re drawing inferences *about* "
"(the population)."
msgstr ""
"I innledningen til denne delen diskuterte jeg induksjonens gåte og "
"understreket det faktum at *all* læring krever at du gjør antakelser. Hvis "
"vi aksepterer at dette er sant, er vår første oppgave å komme opp med noen "
"ganske generelle antakelser om data som gir mening. Det er her "
"**utvalgsteori** kommer inn i bildet. Hvis sannsynlighetsteori er "
"fundamentet som all statistisk teori bygger på, er utvalgsteori rammen som "
"du kan bygge resten av huset rundt. Utvalgsteori spiller en stor rolle når "
"det gjelder å spesifisere forutsetningene som de statistiske slutningene "
"dine bygger på. Og for å kunne snakke om «å trekke slutninger» slik "
"statistikere tenker om det, må vi være litt mer eksplisitte når det gjelder "
"hva det er vi trekker slutninger *fra* (utvalget) og hva det er vi trekker "
"slutninger *om* (populasjonen)."

#: ../../Ch08/Ch08_Estimation_1.rst:20
msgid ""
"In almost every situation of interest what we have available to us as "
"researchers is a **sample** of data. We might have run experiment with some "
"number of participants, a polling company might have phoned some number of "
"people to ask questions about voting intentions, and so on. In this way the "
"data set available to us is finite and incomplete. We can’t possibly get "
"every person in the world to do our experiment, for example a polling "
"company doesn’t have the time or the money to ring up every voter in the "
"country. In our earlier discussion of :doc:`../Ch04/Ch04_Descriptives`, this "
"sample was the only thing we were interested in. Our only goal was to find "
"ways of describing, summarising and graphing that sample. This is about to "
"change."
msgstr ""
"I nesten alle situasjoner av interesse har vi som forskere et **utvalg** av "
"data til rådighet. Vi kan ha gjennomført et eksperiment med et visst antall "
"deltakere, et meningsmålingsfirma kan ha ringt et visst antall personer for "
"å stille spørsmål om stemmeintensjoner, og så videre. På denne måten er "
"datasettet vi har til rådighet, begrenset og ufullstendig. Vi kan umulig få "
"alle mennesker i hele verden til å delta i eksperimentet vårt, for eksempel "
"har ikke et meningsmålingsinstitutt tid eller penger til å ringe opp alle "
"velgere i landet. I vår tidligere diskusjon av :doc:`../Ch04/"
"Ch04_Descriptives` var dette utvalget det eneste vi var interessert i. Vårt "
"eneste mål var å finne måter å beskrive, oppsummere og visualisere dette "
"utvalget på. Dette er i ferd med å endre seg."

#: ../../Ch08/Ch08_Estimation_1.rst:32
msgid "Defining a population"
msgstr "Definere en populasjon"

#: ../../Ch08/Ch08_Estimation_1.rst:34
msgid ""
"A sample is a concrete thing. You can open up a data file and there’s the "
"data from your sample. A **population**, on the other hand, is a more "
"abstract idea. It refers to the set of all possible people, or all possible "
"observations, that you want to draw conclusions about and is generally "
"*much* bigger than the sample. In an ideal world the researcher would begin "
"the study with a clear idea of what the population of interest is, since the "
"process of designing a study and testing hypotheses with the data does "
"depend on the population about which you want to make statements."
msgstr ""
"En prøve er en konkret ting. Du kan åpne en datafil, og der finner du "
"dataene fra utvalget ditt. En **populasjon** er derimot et mer abstrakt "
"begrep. Den refererer til mengden av alle mulige personer, eller alle mulige "
"observasjoner, som du ønsker å trekke konklusjoner om, og er vanligvis *mye* "
"større enn utvalget. I en ideell verden ville forskeren begynne studien med "
"en klar idé om hva populasjonen av interesse er, siden prosessen med å "
"utforme en studie og teste hypoteser med dataene avhenger av populasjonen du "
"ønsker å uttale deg om."

#: ../../Ch08/Ch08_Estimation_1.rst:44
msgid ""
"Sometimes it’s easy to state the population of interest. For instance, in "
"the “polling company” example that opened the chapter the population "
"consisted of all voters enrolled at the time of the study, millions of "
"people. The sample was a set of 1000 people who all belong to that "
"population. In most studies the situation is much less straightforward. In a "
"typical psychological experiment determining the population of interest is a "
"bit more complicated. Suppose I run an experiment using 100 undergraduate "
"students as my participants. My goal, as a cognitive scientist, is to try to "
"learn something about how the mind works. So, which of the following would "
"count as “the population”:"
msgstr ""
"Noen ganger er det enkelt å angi populasjonen man er interessert i. I "
"eksemplet med «meningsmålingsinstituttet» som innledet kapitlet, besto "
"populasjonen av alle velgere som var registrert på undersøkelsestidspunktet, "
"altså millioner av mennesker. Utvalget var et sett på 1000 personer som alle "
"tilhørte denne populasjonen. I de fleste studier er situasjonen mye mindre "
"enkel. I et typisk psykologisk eksperiment er det litt mer komplisert å "
"bestemme populasjonen av interesse. Anta at jeg gjennomfører et eksperiment "
"med 100 studenter som deltakere. Målet mitt, som kognitiv forsker, er å "
"prøve å lære noe om hvordan hjernen fungerer. Hvilke av de følgende "
"personene vil telle som «populasjonen»:"

#: ../../Ch08/Ch08_Estimation_1.rst:55
msgid ""
"All of the undergraduate psychology students at the University of Adelaide?"
msgstr "Alle psykologistudentene ved University of Adelaide?"

#: ../../Ch08/Ch08_Estimation_1.rst:58
msgid "Undergraduate psychology students in general, anywhere in the world?"
msgstr "Psykologistudenter generelt, hvor som helst i verden?"

#: ../../Ch08/Ch08_Estimation_1.rst:60
msgid "Australians currently living?"
msgstr "Australiere som lever i dag?"

#: ../../Ch08/Ch08_Estimation_1.rst:62
msgid "Australians of similar ages to my sample?"
msgstr "Australiere i samme alder som mitt utvalg?"

#: ../../Ch08/Ch08_Estimation_1.rst:64
msgid "Anyone currently alive?"
msgstr "Er det noen som er i live nå?"

#: ../../Ch08/Ch08_Estimation_1.rst:66
msgid "Any human being, past, present or future?"
msgstr "Ethvert menneske, i fortid, nåtid eller fremtid?"

#: ../../Ch08/Ch08_Estimation_1.rst:68
msgid ""
"Any biological organism with a sufficient degree of intelligence operating "
"in a terrestrial environment?"
msgstr ""
"Enhver biologisk organisme med en tilstrekkelig grad av intelligens som "
"opererer i et jordisk miljø?"

#: ../../Ch08/Ch08_Estimation_1.rst:71
msgid "Any intelligent being?"
msgstr "Ethvert intelligent vesen?"

#: ../../Ch08/Ch08_Estimation_1.rst:73
msgid ""
"Each of these defines a real group of mind-possessing entities, all of which "
"might be of interest to me as a cognitive scientist, and it’s not at all "
"clear which one ought to be the true population of interest. As another "
"example, consider the Wellesley-Croker game that we discussed in the "
"prelude. The sample here is a specific sequence of 12 wins and 0 losses for "
"Wellesley. What is the population?"
msgstr ""
"Hver av disse definerer en reell gruppe av bevissthetsbesittende enheter, "
"som alle kan være av interesse for meg som kognitiv forsker, og det er slett "
"ikke klart hvilken av dem som burde være den egentlige populasjonen av "
"interesse. Et annet eksempel er Wellesley-Croker-spillet som vi diskuterte i "
"innledningen. Utvalget her er en spesifikk sekvens med 12 seire og 0 tap for "
"Wellesley. Hva er populasjonen?"

#: ../../Ch08/Ch08_Estimation_1.rst:80
msgid "All outcomes until Wellesley and Croker arrived at their destination?"
msgstr "Alle utfallene frem til Wellesley og Croker ankom bestemmelsesstedet?"

#: ../../Ch08/Ch08_Estimation_1.rst:82
msgid ""
"All outcomes if Wellesley and Croker had played the game for the rest of "
"their lives?"
msgstr ""
"Hva hadde skjedd om Wellesley og Croker hadde spilt spillet resten av livet?"

#: ../../Ch08/Ch08_Estimation_1.rst:85
msgid ""
"All outcomes if Wellseley and Croker lived forever and played the game until "
"the world ran out of hills?"
msgstr ""
"Hva ville skjedd hvis Wellseley og Croker levde evig og spilte spillet til "
"verden gikk tom for åser?"

#: ../../Ch08/Ch08_Estimation_1.rst:88
msgid ""
"All outcomes if we created an infinite set of parallel universes and the "
"Wellesely/Croker pair made guesses about the same 12 hills in each universe?"
msgstr ""
"Hva skjer hvis vi skaper et uendelig sett med parallelle universer, og "
"Wellesely/Croker-paret gjetter på de samme 12 åsene i hvert univers?"

#: ../../Ch08/Ch08_Estimation_1.rst:92
msgid "Again, it’s not obvious what the population is."
msgstr "Igjen, det er ikke åpenbart hva populasjonen er."

#: ../../Ch08/Ch08_Estimation_1.rst:95
msgid "Simple random samples"
msgstr "Enkle tilfeldige utvalg"

#: ../../Ch08/Ch08_Estimation_1.rst:97
msgid ""
"Irrespective of how I define the population, the critical point is that the "
"sample is a subset of the population and our goal is to use our knowledge of "
"the sample to draw inferences about the properties of the population. The "
"relationship between the two depends on the *procedure* by which the sample "
"was selected. This procedure is referred to as a **sampling method** and it "
"is important to understand why it matters."
msgstr ""
"Uansett hvordan jeg definerer populasjonen, er det avgjørende poenget at "
"utvalget er en delmengde av populasjonen, og målet vårt er å bruke "
"kunnskapen om utvalget til å trekke slutninger om egenskapene til "
"populasjonen. Forholdet mellom de to avhenger av *prosedyren* utvalget ble "
"trukket etter. Denne prosedyren kalles en **utvalgsmetode**, og det er "
"viktig å forstå hvorfor den er viktig."

#: ../../Ch08/Ch08_Estimation_1.rst:104
msgid ""
"To keep things simple, let’s imagine that we have a bag containing 10 chips. "
"Each chip has a unique letter printed on it so we can distinguish between "
"the 10 chips. The chips come in two colours, black and white. This set of "
"chips is the population of interest and it is depicted graphically on the "
"left of :numref:`fig-srs1`. As you can see from looking at the picture there "
"are 4 black chips and 6 white chips, but of course in real life we wouldn’t "
"know that unless we looked in the bag. Now imagine you run the following "
"“experiment”: you shake up the bag, close your eyes, and pull out 4 chips "
"without putting any of them back into the bag. First out comes the *a* chip "
"(black), then the *c* chip (white), then *j* (white) and then finally *b* "
"(black). If you wanted you could then put all the chips back in the bag and "
"repeat the experiment, as depicted on the right hand side of :numref:`fig-"
"srs1`. Each time you get different results but the procedure is identical in "
"each case. The fact that the same procedure can lead to different results "
"each time we refer to as a *random* process.\\ [#]_ However, because we "
"shook the bag before pulling any chips out, it seems reasonable to think "
"that every chip has the same chance of being selected. A procedure in which "
"every member of the population has the same chance of being selected is "
"called a **simple random sample**. The fact that we did *not* put the chips "
"back in the bag after pulling them out means that you can’t observe the same "
"thing twice, and in such cases the observations are said to have been "
"sampled **without replacement**."
msgstr ""
"For å gjøre det enkelt kan vi tenke oss at vi har en pose som inneholder 10 "
"sjetonger. Hver brikke har en unik bokstav trykt på seg, slik at vi kan "
"skille mellom de 10 brikkene. Brikkene finnes i to farger, svart og hvit. "
"Dette settet med brikker er populasjonen vi er interessert i, og det er "
"avbildet grafisk til venstre i :numref:`fig-srs1`. Som du kan se på bildet, "
"er det 4 svarte og 6 hvite sjetonger, men i virkeligheten ville vi "
"selvfølgelig ikke visst det med mindre vi så i posen. Forestill deg nå at du "
"gjør følgende «eksperiment»: Du rister posen, lukker øynene og trekker ut "
"fire sjetonger uten å legge noen av dem tilbake i posen. Først kommer *a*-"
"brikken (svart), deretter *c*-brikken (hvit), så *j* (hvit) og til slutt *b* "
"(svart). Hvis du vil, kan du deretter legge alle brikkene tilbake i posen og "
"gjenta eksperimentet, som vist på høyre side av :numref:`fig-srs1`. Hver "
"gang får du forskjellige resultater, men fremgangsmåten er identisk i hvert "
"tilfelle. Det at samme prosedyre kan føre til ulike resultater hver gang, "
"kaller vi en *tilfeldig* prosess.\\ [#]_ Men siden vi ristet posen før vi "
"trakk ut noen brikker, virker det rimelig å tro at hver brikke har samme "
"sjanse for å bli valgt. En prosedyre der alle i populasjonen har samme "
"sjanse for å bli valgt ut, kalles et **enkelt tilfeldig utvalg**. Det at vi "
"*ikke* la sjetongene tilbake i posen etter å ha trukket dem ut, betyr at man "
"ikke kan observere det samme to ganger, og i slike tilfeller sier man at "
"observasjonene er tatt ut **uten erstatning**."

#: ../../Ch08/Ch08_Estimation_1.rst:129 ../../Ch08/Ch08_Estimation_1.rst:133
msgid "Simple random sampling WITHOUT replacement from a finite population"
msgstr "Enkelt tilfeldig utvalg UTEN erstatning fra en begrenset populasjon"

#: ../../Ch08/Ch08_Estimation_1.rst:137
msgid ""
"To help make sure you understand the importance of the sampling procedure, "
"consider an alternative way in which the experiment could have been run. "
"Suppose that my 5-year old son had opened the bag and decided to pull out "
"four black chips without putting any of them back in the bag. This *biased* "
"sampling scheme is depicted in :numref:`fig-brs`. Now consider the "
"evidential value of seeing 4 black chips and 0 white chips. Clearly it "
"depends on the sampling scheme, does it not? If you know that the sampling "
"scheme is biased to select only black chips then a sample that consists of "
"only black chips doesn’t tell you very much about the population! For this "
"reason statisticians really like it when a data set can be considered a "
"simple random sample, because it makes the data analysis *much* easier."
msgstr ""
"For å sikre at du forstår viktigheten av prøvetakingsprosedyren, kan du "
"tenke deg en alternativ måte eksperimentet kunne ha blitt utført på. Anta at "
"min 5 år gamle sønn hadde åpnet posen og bestemt seg for å trekke ut fire "
"svarte sjetonger uten å legge noen av dem tilbake i posen. Denne *ikke-"
"objektive* utvalgsordningen er avbildet i :numref:`fig-brs`. Se nå på "
"bevisverdien av å se 4 svarte og 0 hvite sjetonger. Det er klart at det "
"avhenger av prøvetakingsplanen, ikke sant? Hvis du vet at utvalgsplanen ikke "
"er t slik at bare svarte brikker velges ut, sier ikke et utvalg som bare "
"består av svarte brikker særlig mye om populasjonen! Av denne grunn liker "
"statistikere det veldig godt når et datasett kan betraktes som et enkelt "
"tilfeldig utvalg, fordi det gjør dataanalysen *mye* enklere."

#: ../../Ch08/Ch08_Estimation_1.rst:151 ../../Ch08/Ch08_Estimation_1.rst:155
msgid "Biased sampling WITHOUT replacement from a finite population"
msgstr ""
"Skjevhet (*bias*) i utvalget UTEN erstatning fra en begrenset populasjon"

#: ../../Ch08/Ch08_Estimation_1.rst:159
msgid ""
"A third procedure is worth mentioning. This time around we close our eyes, "
"shake the bag, and pull out a chip. This time, however, we record the "
"observation and then put the chip back in the bag. Again we close our eyes, "
"shake the bag, and pull out a chip. We then repeat this procedure until we "
"have 4 chips. Data sets generated in this way are still simple random "
"samples, but because we put the chips back in the bag immediately after "
"drawing them it is referred to as a sample **with replacement**. The "
"difference between this situation and the first one is that it is possible "
"to observe the same population member multiple times, as illustrated in "
"numref:`fig-srs2`."
msgstr ""
"En tredje prosedyre er verdt å nevne. Denne gangen lukker vi øynene, rister "
"posen og trekker ut en brikke. Denne gangen noterer vi observasjonen og "
"legger deretter brikken tilbake i posen. Igjen lukker vi øynene, rister "
"posen og trekker ut en brikke. Så gjentar vi denne prosedyren til vi har "
"fire brikker. Datasettene som genereres på denne måten, er fortsatt enkle "
"tilfeldige utvalg, men fordi vi legger brikkene tilbake i posen umiddelbart "
"etter at vi har trukket dem ut, kalles det et utvalg **med erstatning**. "
"Forskjellen mellom denne situasjonen og den første er at det er mulig å "
"observere det samme populasjonsmedlemmet flere ganger, som illustrert i "
"numref:`fig-srs2`."

#: ../../Ch08/Ch08_Estimation_1.rst:171 ../../Ch08/Ch08_Estimation_1.rst:175
msgid "Simple random sampling WITH replacement from a finite population"
msgstr "Enkelt tilfeldig utvalg MED erstatning fra en begrenset populasjon"

#: ../../Ch08/Ch08_Estimation_1.rst:179
msgid ""
"In my experience, most psychology experiments tend to be sampling without "
"replacement, because the same person is not allowed to participate in the "
"experiment twice. However, most statistical theory is based on the "
"assumption that the data arise from a simple random sample *with* "
"replacement. In real life this very rarely matters. If the population of "
"interest is large (e.g., has more than 10 entities!) the difference between "
"sampling with- and without- replacement is too small to be concerned with. "
"The difference between simple random samples and biased samples, on the "
"other hand, is not such an easy thing to dismiss."
msgstr ""
"Min erfaring er at de fleste psykologieksperimenter har en tendens til å "
"være stikkprøver uten erstatning, fordi samme person ikke får delta i "
"eksperimentet to ganger. Det meste av statistisk teori er imidlertid basert "
"på en antakelse om at dataene stammer fra et enkelt tilfeldig utvalg *med* "
"erstatning. I virkeligheten er dette svært sjelden tilfelle. Hvis "
"populasjonen man er interessert i, er stor (f.eks. har mer enn 10 enheter!), "
"er forskjellen mellom utvalg med og uten utskifting for liten til at man "
"trenger å bry seg om det. Forskjellen mellom enkle tilfeldige utvalg og "
"utvalg som ikke er representativt (*biased*) er derimot ikke så lett å "
"avfeie."

#: ../../Ch08/Ch08_Estimation_1.rst:190
msgid "Most samples are not simple random samples"
msgstr "De fleste utvalg er ikke enkle tilfeldige utvalg"

#: ../../Ch08/Ch08_Estimation_1.rst:192
msgid ""
"As you can see from looking at the list of possible populations that I "
"showed above, it is almost impossible to obtain a simple random sample from "
"most populations of interest. When I run experiments I’d consider it a minor "
"miracle if my participants turned out to be a random sampling of the "
"undergraduate psychology students at Adelaide university, even though this "
"is by far the narrowest population that I might want to generalise to. A "
"thorough discussion of other types of sampling schemes is beyond the scope "
"of this book, but to give you a sense of what’s out there I’ll list a few of "
"the more important ones."
msgstr ""
"Som du kan se av listen over mulige populasjoner som jeg viste ovenfor, er "
"det nesten umulig å få et tilfeldig utvalg fra de fleste populasjoner av "
"interesse. Når jeg gjennomfører eksperimenter, ville jeg sett på det som et "
"lite mirakel om deltakerne mine viste seg å være et tilfeldig utvalg av "
"psykologistudentene ved universitetet i Adelaide, selv om dette er den klart "
"smaleste populasjonen jeg ønsker å generalisere til. En grundig diskusjon av "
"andre typer utvalgsordninger ligger utenfor rammen av denne boken, men for å "
"gi deg en pekepinn på hva som finnes der ute, skal jeg liste opp noen av de "
"viktigste."

#: ../../Ch08/Ch08_Estimation_1.rst:202
msgid ""
"*Stratified sampling*. Suppose your population is (or can be) divided into "
"several different sub-populations, or *strata*. Perhaps you’re running a "
"study at several different sites, for example. Instead of trying to sample "
"randomly from the population as a whole, you instead try to collect a "
"separate random sample from each of the strata. Stratified sampling is "
"sometimes easier to do than simple random sampling, especially when the "
"population is already divided into the distinct strata. It can also be more "
"efficient than simple random sampling, especially when some of the sub-"
"populations are rare. For instance, when studying schizophrenia it would be "
"much better to divide the population into two\\ [#]_ strata (schizophrenic "
"and not-schizophrenic) and then sample an equal number of people from each "
"group. If you selected people randomly you would get so few schizophrenic "
"people in the sample that your study would be useless. This specific kind of "
"of stratified sampling is referred to as *oversampling* because it makes a "
"deliberate attempt to over-represent rare groups."
msgstr ""
"*Stratifisert utvalg*. Anta at populasjonen din er (eller kan deles inn i) "
"flere ulike delpopulasjoner, eller *strata*. Kanskje du for eksempel skal "
"gjennomføre en studie på flere forskjellige steder. I stedet for å prøve å "
"trekke et tilfeldig utvalg fra populasjonen som helhet, prøver du i stedet å "
"samle inn et separat tilfeldig utvalg fra hvert av strataene. Stratifisert "
"utvalg er noen ganger enklere å gjennomføre enn enkle tilfeldige utvalg, "
"spesielt når populasjonen allerede er delt inn i de ulike strataene. Det kan "
"også være mer effektivt enn enkle tilfeldige utvalg, særlig når noen av "
"delpopulasjonene er sjeldne. Når man for eksempel studerer schizofreni, vil "
"det være mye bedre å dele populasjonen inn i to strata\\ [#]_ (schizofrene "
"og ikke-schizofrene) og deretter ta et like stort antall personer fra hver "
"gruppe. Hvis du hadde valgt ut folk tilfeldig, ville du fått så få "
"schizofrene personer i utvalget at studien ville vært ubrukelig. Denne typen "
"stratifisert utvalg kalles *oversampling* fordi man bevisst forsøker å "
"overrepresentere sjeldne grupper."

#: ../../Ch08/Ch08_Estimation_1.rst:220
msgid ""
"*Snowball sampling* is a technique that is especially useful when sampling "
"from a “hidden” or hard to access population and is especially common in "
"social sciences. For instance, suppose the researchers want to conduct an "
"opinion poll among transgender people. The research team might only have "
"contact details for a few trans folks, so the survey starts by asking them "
"to participate (stage 1). At the end of the survey the participants are "
"asked to provide contact details for other people who might want to "
"participate. In stage 2 those new contacts are surveyed. The process "
"continues until the researchers have sufficient data. The big advantage to "
"snowball sampling is that it gets you data in situations that might "
"otherwise be impossible to get any. On the statistical side, the main "
"disadvantage is that the sample is highly non-random, and non-random in ways "
"that are difficult to address. On the real life side, the disadvantage is "
"that the procedure can be unethical if not handled well, because hidden "
"populations are often hidden for a reason. I chose transgender people as an "
"example here to highlight this issue. If you weren’t careful you might end "
"up outing people who don’t want to be outed (very, very bad form), and even "
"if you don’t make that mistake it can still be intrusive to use people’s "
"social networks to study them. It’s certainly very hard to get people’s "
"informed consent *before* contacting them, yet in many cases the simple act "
"of contacting them and saying “hey we want to study you” can be hurtful. "
"Social networks are complex things, and just because you can use them to get "
"data doesn’t always mean you should."
msgstr ""
"*Snowball sampling* er en teknikk som er spesielt nyttig når man skal ta "
"utvalg fra en «skjult» eller vanskelig tilgjengelig populasjon, og er særlig "
"vanlig i samfunnsvitenskapen. Tenk deg for eksempel at forskerne ønsker å "
"gjennomføre en meningsmåling blant transpersoner. Forskerteamet har kanskje "
"bare kontaktinformasjon til noen få transpersoner, så undersøkelsen starter "
"med å be dem om å delta (trinn 1). På slutten av undersøkelsen blir "
"deltakerne bedt om å oppgi kontaktinformasjon til andre personer som kunne "
"tenke seg å delta. I trinn 2 blir disse nye kontaktene kartlagt. Prosessen "
"fortsetter til forskerne har tilstrekkelig med data. Den store fordelen med "
"snøballutvalg er at man får data i situasjoner der det ellers ville vært "
"umulig å få tak i data. Den største ulempen på den statistiske siden er at "
"utvalget er svært ikke-tilfeldig, og ikke-tilfeldig på måter som det er "
"vanskelig å gjøre noe med. I det virkelige liv er ulempen at prosedyren kan "
"være uetisk hvis den ikke håndteres på en god måte, fordi skjulte "
"populasjoner ofte er skjulte av en grunn. Jeg valgte transpersoner som "
"eksempel her for å belyse dette problemet. Hvis man ikke er forsiktig, kan "
"man ende opp med å outa folk som ikke ønsker å bli outet (veldig, veldig "
"dårlig stil), og selv om man ikke gjør den feilen, kan det fortsatt være "
"påtrengende å bruke folks sosiale nettverk til å studere dem. Det er svært "
"vanskelig å få folks informerte samtykke *før* man kontakter dem, men i "
"mange tilfeller kan bare det å kontakte dem og si «hei, vi vil gjerne "
"studere deg» være sårende. Sosiale nettverk er komplekse størrelser, og bare "
"fordi du kan bruke dem til å innhente data, betyr ikke det alltid at du bør "
"gjøre det."

#: ../../Ch08/Ch08_Estimation_1.rst:246
msgid ""
"*Convenience sampling* is more or less what it sounds like. The samples are "
"chosen in a way that is convenient to the researcher, and not selected at "
"random from the population of interest. Snowball sampling is one type of "
"convenience sampling, but there are many others. A common example in "
"psychology are studies that rely on undergraduate psychology students. These "
"samples are generally non-random in two respects. First, reliance on "
"undergraduate psychology students automatically means that your data are "
"restricted to a single sub-population. Second, the students usually get to "
"pick which studies they participate in, so the sample is a self selected "
"subset of psychology students and not a randomly selected subset. In real "
"life most studies are convenience samples of one form or another. This is "
"sometimes a severe limitation, but not always."
msgstr ""
"*Bekvemmelighetsutvalg* er mer eller mindre det det høres ut som. Utvalgene "
"velges ut på en måte som er praktisk for forskeren, og velges ikke tilfeldig "
"fra den populasjonen man er interessert i. Snøballutvalg er én type "
"bekvemmelighetsutvalg, men det finnes mange andre. Et vanlig eksempel innen "
"psykologi er studier som baserer seg på psykologistudenter på lavere grad. "
"Disse utvalgene er generelt ikke tilfeldige på to måter. For det første "
"betyr det å basere seg på psykologistudenter automatisk at dataene dine er "
"begrenset til en enkelt delpopulasjon. For det andre får studentene "
"vanligvis velge hvilke studier de vil delta i, slik at utvalget er en "
"selvvalgt delmengde av psykologistudenter og ikke en tilfeldig utvalgt "
"delmengde. I det virkelige liv er de fleste studier bekvemmelighetsutvalg av "
"en eller annen form. Dette er noen ganger en alvorlig begrensning, men ikke "
"alltid."

#: ../../Ch08/Ch08_Estimation_1.rst:261
msgid "How much does it matter if you don’t have a simple random sample?"
msgstr "Hvor mye har det å si om du ikke har et enkelt tilfeldig utvalg?"

#: ../../Ch08/Ch08_Estimation_1.rst:263
msgid ""
"Okay, so real world data collection tends not to involve nice simple random "
"samples. Does that matter? A little thought should make it clear to you that "
"it *can* matter if your data are not a simple random sample. Just think "
"about the difference between :numref:`fig-srs1` and :numref:`fig-brs`. "
"However, it’s not quite as bad as it sounds. Some types of biased samples "
"are entirely unproblematic. For instance, when using a stratified sampling "
"technique you actually *know* what the bias is because you created it "
"deliberately, often to *increase* the effectiveness of your study, and there "
"are statistical techniques that you can use to adjust for the biases you’ve "
"introduced (not covered in this book!). So in those situations it’s not a "
"problem."
msgstr ""
"Ok, så datainnsamling i den virkelige verden involverer vanligvis ikke "
"enkle, tilfeldige utvalg. Spiller det noen rolle? En liten tanke bør gjøre "
"det klart for deg at det *kan* ha noe å si om dataene dine ikke er et enkelt "
"tilfeldig utvalg. Bare tenk på forskjellen mellom :numref:`fig-srs1` og "
":numref:`fig-brs`. Det er imidlertid ikke så ille som det høres ut. Noen "
"typer utvalg som ikke er representativt er helt uproblematiske. Når du for "
"eksempel bruker en stratifisert utvalgsteknikk, *vet* du faktisk hva "
"skjevheten er fordi du har skapt den med vilje, ofte for å *øke* "
"effektiviteten i studien, og det finnes statistiske teknikker du kan bruke "
"for å justere for skjevhetene du har introdusert (ikke dekket i denne boken!)"
". Så i slike situasjoner er det ikke noe problem."

#: ../../Ch08/Ch08_Estimation_1.rst:276
msgid ""
"More generally though, it’s important to remember that random sampling is a "
"means to an end, and not the end in itself. Let’s assume you’ve relied on a "
"convenience sample, and as such you can assume it’s biased. A bias in your "
"sampling method is only a problem if it causes you to draw the wrong "
"conclusions. When viewed from that perspective, I’d argue that we don’t need "
"the sample to be randomly generated in *every* respect, we only need it to "
"be random with respect to the psychologically-relevant phenomenon of "
"interest. Suppose I’m doing a study looking at working memory capacity. In "
"study 1, I actually have the ability to sample randomly from all human "
"beings currently alive, with one exception: I can only sample people born on "
"a Monday. In study 2, I am able to sample randomly from the Australian "
"population. I want to generalise my results to the population of all living "
"humans. Which study is better? The answer, obviously, is study 1. Why? "
"Because we have no reason to think that being “born on a Monday” has any "
"interesting relationship to working memory capacity. In contrast, I can "
"think of several reasons why “being Australian” might matter. Australia is a "
"wealthy, industrialised country with a very well-developed education system. "
"People growing up in that system will have had life experiences much more "
"similar to the experiences of the people who designed the tests for working "
"memory capacity. This shared experience might easily translate into similar "
"beliefs about how to “take a test”, a shared assumption about how "
"psychological experimentation works, and so on. These things might actually "
"matter. For instance, “test taking” style might have taught the Australian "
"participants how to direct their attention exclusively on fairly abstract "
"test materials much more than people who haven’t grown up in a similar "
"environment. This could therefore lead to a misleading picture of what "
"working memory capacity is."
msgstr ""
"Mer generelt er det imidlertid viktig å huske at tilfeldige utvalg er et "
"middel til å nå et mål, og ikke målet i seg selv. La oss anta at du har "
"basert deg på et bekvemmelighetsutvalg, og at det derfor ikke er "
"representativt. En skjevhet i utvalgsmetoden din er bare et problem hvis den "
"fører til at du trekker feil konklusjoner. Sett fra det perspektivet vil jeg "
"hevde at vi ikke trenger at utvalget er tilfeldig generert i *alle* "
"henseender, vi trenger bare at det er tilfeldig med hensyn til det "
"psykologisk relevante fenomenet vi er interessert i. Anta at jeg gjør en "
"studie som ser på arbeidsminnekapasitet. I studie 1 har jeg faktisk "
"muligheten til å ta et tilfeldig utvalg av alle nålevende mennesker, med ett "
"unntak: Jeg kan bare velge personer som er født på en mandag. I studie 2 kan "
"jeg ta et tilfeldig utvalg fra den australske befolkningen. Jeg ønsker å "
"generalisere resultatene mine til populasjonen av alle nålevende mennesker. "
"Hvilken studie er best? Svaret er åpenbart studie 1. Hvorfor er det slik? "
"Fordi vi ikke har noen grunn til å tro at det å være «født på en mandag» har "
"noen interessant sammenheng med arbeidshukommelseskapasitet. Derimot kan jeg "
"tenke meg flere grunner til at «å være australsk» kan ha noe å si. Australia "
"er et velstående, industrialisert land med et svært velutviklet "
"utdanningssystem. Folk som vokser opp i dette systemet, vil ha hatt "
"livserfaringer som ligner mye mer på erfaringene til de som har utformet "
"testene for arbeidsminnekapasitet. Denne felles erfaringen kan lett gi seg "
"utslag i lignende oppfatninger om hvordan man «tar en test», en felles "
"antakelse om hvordan psykologiske eksperimenter fungerer, og så videre. "
"Disse tingene kan faktisk ha betydning. For eksempel kan «testtakingsstilen» "
"ha lært de australske deltakerne å rette oppmerksomheten utelukkende mot "
"ganske abstrakt testmateriale i mye større grad enn personer som ikke har "
"vokst opp i et lignende miljø. Dette kan derfor føre til et misvisende bilde "
"av hva arbeidsminnekapasitet er."

#: ../../Ch08/Ch08_Estimation_1.rst:306
msgid ""
"There are two points hidden in this discussion. First, when designing your "
"own studies, it’s important to think about what population you care about "
"and try hard to sample in a way that is appropriate to that population. In "
"practice, you’re usually forced to put up with a “sample of convenience” (e."
"g., psychology lecturers sample psychology students because that’s the least "
"expensive way to collect data, and our coffers aren’t exactly overflowing "
"with gold), but if so you should at least spend some time thinking about "
"what the dangers of this practice might be. Second, if you’re going to "
"criticise someone else’s study because they’ve used a sample of convenience "
"rather than laboriously sampling randomly from the entire human population, "
"at least have the courtesy to offer a specific theory as to *how* this might "
"have distorted the results."
msgstr ""
"Det er to poenger som ligger skjult i denne diskusjonen. For det første er "
"det viktig å tenke på hvilken populasjon man er interessert i når man "
"utformer sine egne studier, og forsøke å gjøre utvalget på en måte som er "
"tilpasset denne populasjonen. I praksis er man som regel nødt til å finne "
"seg i et «bekvemmelighetsutvalg» (f.eks. velger psykologilærere ut "
"psykologistudenter fordi det er den rimeligste måten å samle inn data på, og "
"kistene våre flyter ikke akkurat over av gull), men i så fall bør man i det "
"minste bruke litt tid på å tenke over hvilke farer denne praksisen kan "
"innebære. For det andre, hvis du skal kritisere andres studier fordi de har "
"brukt et bekvemmelighetsutvalg i stedet for å ta et tilfeldig utvalg fra "
"hele befolkningen, bør du i det minste være høflig nok til å komme med en "
"spesifikk teori om *hvordan* dette kan ha forvrengt resultatene."

#: ../../Ch08/Ch08_Estimation_1.rst:321
msgid "Population parameters and sample statistics"
msgstr "Populasjonsparametere og utvalgsstatistikk"

#: ../../Ch08/Ch08_Estimation_1.rst:323
msgid ""
"Okay. Setting aside the thorny methodological issues associated with "
"obtaining a random sample, let’s consider a slightly different issue. Up to "
"this point we have been talking about populations the way a scientist might. "
"To a psychologist a population might be a group of people. To an ecologist a "
"population might be a group of bears. In most cases the populations that "
"scientists care about are concrete things that actually exist in the real "
"world. Statisticians, however, are a funny lot. On the one hand, they *are* "
"interested in real world data and real science in the same way that "
"scientists are. On the other hand, they also operate in the realm of pure "
"abstraction in the way that mathematicians do. As a consequence, statistical "
"theory tends to be a bit abstract in how a population is defined. In much "
"the same way that psychological researchers operationalise our abstract "
"theoretical ideas in terms of concrete measurements (section :doc:`../Ch02/"
"Ch02_StudyDesign_1`), statisticians operationalise the concept of a "
"“population” in terms of mathematical objects that they know how to work "
"with. You’ve already come across these objects in chapter :doc:`../Ch07/"
"Ch07_Probability`. They’re called probability distributions."
msgstr ""
"La oss se bort fra de vanskelige metodiske spørsmålene knyttet til det å ta "
"et tilfeldig utvalg, og heller se på et litt annet spørsmål. Frem til nå har "
"vi snakket om populasjoner på samme måte som en forsker. For en psykolog kan "
"en populasjon være en gruppe mennesker. For en økolog kan en populasjon være "
"en gruppe bjørner. I de fleste tilfeller er populasjonene som forskere bryr "
"seg om, konkrete ting som faktisk eksisterer i den virkelige verden. "
"Statistikere er imidlertid en merkelig gruppe. På den ene siden *er* de "
"interessert i data fra den virkelige verden og ekte vitenskap på samme måte "
"som forskere. På den annen side opererer de også i den rene "
"abstraksjonsverdenen, slik matematikere gjør. Som en konsekvens av dette har "
"statistisk teori en tendens til å være litt abstrakt når det gjelder hvordan "
"en populasjon defineres. På samme måte som psykologiske forskere "
"operasjonaliserer våre abstrakte teoretiske ideer i form av konkrete "
"målinger (se :doc:`../Ch02/Ch02_StudyDesign_1`), operasjonaliserer "
"statistikere begrepet «populasjon» i form av matematiske objekter som de vet "
"hvordan de skal arbeide med. Du har allerede støtt på disse objektene i "
"kapittel :doc:`../Ch07/Ch07_Probability`. De kalles "
"sannsynlighetsfordelinger."

#: ../../Ch08/Ch08_Estimation_1.rst:341
msgid ""
"The idea is quite simple. Let’s say we’re talking about IQ scores. To a "
"psychologist the population of interest is a group of actual humans who have "
"IQ scores. A statistician “simplifies” this by operationally defining the "
"population as the probability distribution depicted in the left panel of :"
"numref:`fig-IQ_Pop_Smp`. IQ tests are designed so that the average IQ is "
"100, the standard deviation of IQ scores is 15, and the distribution of IQ "
"scores is normal. These values are referred to as the **population "
"parameters** because they are characteristics of the entire population. That "
"is, we say that the population mean µ is 100 and the population standard "
"deviation σ is 15."
msgstr ""
"Ideen er ganske enkel. La oss si at vi snakker om IQ-skårer. For en psykolog "
"er populasjonen av interesse en gruppe faktiske mennesker som har IQ-skårer. "
"En statistiker «forenkler» dette ved å definere populasjonen operasjonelt "
"som sannsynlighetsfordelingen som er avbildet i venstre panel av :numref"
":`fig-IQ_Pop_Smp`. IQ-tester er utformet slik at gjennomsnittlig IQ er 100, "
"standardavviket for IQ-skårer er 15, og fordelingen av IQ-skårer følger en "
"normalfordeling. Disse verdiene kalles **populasjonsparametere** fordi de er "
"kjennetegn ved hele populasjonen. Det vil si at vi sier at "
"populasjonsgjennomsnittet µ er 100 og populasjonsstandardavviket σ er 15."

#: ../../Ch08/Ch08_Estimation_1.rst:354
msgid "Population distribution of IQ and two samples with N=100 and N=10,000"
msgstr "Populasjonsfordeling av IQ og to utvalg med N=100 og N=10 000"

#: ../../Ch08/Ch08_Estimation_1.rst:358
msgid ""
"The population distribution of IQ scores (left panel) and two samples drawn "
"randomly from it: In the middle panel, we have a sample of 100 observations, "
"and in the right panel, we have a sample of 10,000 observations."
msgstr ""
"Populasjonsfordelingen av IQ-skårer (venstre panel) og to utvalg trukket "
"tilfeldig fra denne: I det midterste panelet har vi et utvalg på 100 "
"observasjoner, og i det høyre panelet har vi et utvalg på 10 000 "
"observasjoner."

#: ../../Ch08/Ch08_Estimation_1.rst:364
msgid ""
"Now suppose I run an experiment. I select 100 people at random and "
"administer an IQ test, giving me a simple random sample from the population. "
"My sample would consist of a collection of numbers like this:"
msgstr ""
"Anta nå at jeg kjører et eksperiment. Jeg velger ut 100 tilfeldige personer "
"og gjennomfører en IQ-test, slik at jeg får et enkelt tilfeldig utvalg fra "
"populasjonen. Utvalget mitt vil bestå av en samling tall som dette:"

#: ../../Ch08/Ch08_Estimation_1.rst:373
msgid ""
"Each of these IQ scores is sampled from a normal distribution with mean 100 "
"and standard deviation 15. So if I plot a histogram of the sample I get "
"something like the one shown in the middle panel of :numref:`fig-"
"IQ_Pop_Smp`. As you can see, the histogram is *roughly* the right shape but "
"it’s a very crude approximation to the true population distribution shown in "
"the left panel of :numref:`fig-IQ_Pop_Smp`. When I calculate the mean of my "
"sample, I get a number that is fairly close to the population mean 100 but "
"not identical. In this case, it turns out that the people in my sample have "
"a mean IQ of 98.5, and the standard deviation of their IQ scores is 15.9. "
"These **sample statistics** are properties of my data set, and although they "
"are fairly similar to the true population values they are not the same. In "
"general, sample statistics are the things you can calculate from your data "
"set and the population parameters are the things you want to learn about. "
"Later on in this chapter I’ll talk about how you can estimate population "
"parameters using your sample statistics (:doc:`Ch08_Estimation_4`) and how "
"to work out how confident you are in your estimates (:doc:"
"`Ch08_Estimation_5`) but before we get to that there’s a few more ideas in "
"sampling theory that you need to know about."
msgstr ""
"Hver av disse IQ-skårene er hentet fra en normalfordeling med gjennomsnitt "
"100 og standardavvik 15. Så hvis jeg plotter et histogram av utvalget, får "
"jeg noe sånt som det som er vist i det midterste panelet i :numref:`fig-"
"IQ_Pop_Smp`. Som du kan se, har histogrammet *fullstendig* riktig form, men "
"det er en svært grov tilnærming til den sanne populasjonsfordelingen som "
"vises i venstre panel i :numref:`fig-IQ_Pop_Smp`. Når jeg beregner "
"gjennomsnittet av utvalget mitt, får jeg et tall som ligger ganske nær "
"populasjonsgjennomsnittet, men som ikke er identisk. I dette tilfellet viser "
"det seg at personene i utvalget mitt har en gjennomsnittlig IQ på 98,5, og "
"at standardavviket for IQ-skårene deres er 15,9. Disse "
"**utvalgsstatistikkene** er egenskaper ved datasettet mitt, og selv om de er "
"ganske like de sanne populasjonsverdiene, er de ikke de samme. Generelt sett "
"er utvalgsstatistikk det du kan beregne ut fra datasettet ditt, mens "
"populasjonsparametrene er det du ønsker å lære mer om. Senere i dette "
"kapittelet skal jeg snakke om hvordan du kan estimere populasjonsparametere "
"ved hjelp av utvalgsstatistikken (:doc:`Ch08_Estimation_4`) og hvordan du "
"kan finne ut hvor sikker du er på estimatene dine (:doc:`Ch08_Estimation_5`)"
", men før vi kommer til det, er det noen flere ideer innen utvalgsteori som "
"du trenger å kjenne til."

#: ../../Ch08/Ch08_Estimation_1.rst:394
msgid ""
"The proper mathematical definition of randomness is extraordinarily "
"technical, and way beyond the scope of this book. We’ll be non-technical "
"here and say that a process has an element of randomness to it whenever it "
"is possible to repeat the process and get different answers each time."
msgstr ""
"Den egentlige matematiske definisjonen av tilfeldighet er svært teknisk, og "
"langt utenfor rammen av denne boken. Her skal vi være ikke-tekniske og si at "
"en prosess har et element av tilfeldighet i seg når det er mulig å gjenta "
"prosessen og få forskjellige svar hver gang."

#: ../../Ch08/Ch08_Estimation_1.rst:401
msgid ""
"Nothing in life is that simple. There’s not an obvious division of people "
"into binary categories like “schizophrenic” and “not schizophrenic”. But "
"this isn’t a clinical psychology text so please forgive me a few "
"simplifications here and there."
msgstr ""
"Ingenting i livet er så enkelt. Det finnes ikke en åpenbar inndeling av "
"mennesker i binære kategorier som «schizofren» og «ikke schizofren». Men "
"dette er ikke en tekst om klinisk psykologi, så tilgi meg for noen "
"forenklinger her og der."

#: ../../Ch08/Ch08_Estimation_2.rst:4
msgid "The law of large numbers"
msgstr "De store talls lov"

#: ../../Ch08/Ch08_Estimation_2.rst:6
msgid ""
"In the previous section I showed you the results of one fictitious IQ "
"experiment with a sample size of *N* = 100. The results were somewhat "
"encouraging as the true population mean is 100 and the sample mean of 98.5 "
"is a pretty reasonable approximation to it. In many scientific studies that "
"level of precision is perfectly acceptable, but in other situations you need "
"to be a lot more precise. If we want our sample statistics to be much closer "
"to the population parameters, what can we do about it?"
msgstr ""
"I forrige avsnitt viste jeg deg resultatene av et fiktivt IQ-eksperiment med "
"en utvalgsstørrelse på *N* = 100. Resultatene var ganske oppmuntrende, siden "
"det sanne populasjonsgjennomsnittet er 100, og utvalgsgjennomsnittet på 98,5 "
"er en ganske rimelig tilnærming til dette. I mange vitenskapelige studier er "
"et slikt presisjonsnivå helt akseptabelt, men i andre situasjoner må man "
"være mye mer presis. Hva kan vi gjøre hvis vi ønsker at utvalgsstatistikken "
"vår skal ligge mye nærmere populasjonsparametrene?"

#: ../../Ch08/Ch08_Estimation_2.rst:15
msgid ""
"The obvious answer is to collect more data. Suppose that we ran a much "
"larger experiment, this time measuring the IQs of 10,000 people. We can "
"simulate the results of this experiment using jamovi. The |IQsim|_ data set "
"is a jamovi data file. In this file I have generated 10,000 random numbers "
"sampled from a normal distribution for a population with ``mean = 100`` and "
"``sd = 15``. This was done by computing a new variable using the ``= "
"NORM(100,15)`` function. A histogram and density plot shows that this larger "
"sample is a much better approximation to the true population distribution "
"than the smaller one. This is reflected in the sample statistics. The mean "
"IQ for the larger sample turns out to be 99.68 and the standard deviation is "
"14.90. These values are now very close to the true population, as :numref:"
"`fig-IQsim` demonstrates."
msgstr ""
"Det åpenbare svaret er å samle inn mer data. Anta at vi kjørte et mye større "
"eksperiment, der vi denne gangen målte IQ-en til 10 000 personer. Vi kan "
"simulere resultatene av dette eksperimentet ved hjelp av jamovi. Datasettet "
"|IQsim|_ er en jamovi-datafil. I denne filen har jeg generert 10 000 "
"tilfeldige tall fra en normalfordeling for en populasjon med ``mean = 100`` "
"og ``sd = 15``. Dette ble gjort ved å beregne en ny variabel ved hjelp av "
"funksjonen ``= NORM(100, 15)``. Et histogram og et tetthetsplott viser at "
"dette større utvalget er en mye bedre tilnærming til den sanne "
"populasjonsfordelingen enn det mindre utvalget. Dette gjenspeiles i "
"utvalgsstatistikken. Gjennomsnittlig IQ for det større utvalget viser seg å "
"være 99,68, og standardavviket er 14,90. Disse verdiene ligger nå svært nær "
"den sanne populasjonen, som :numref:`fig-IQsim` viser."

#: ../../Ch08/Ch08_Estimation_2.rst:30 ../../Ch08/Ch08_Estimation_2.rst:34
msgid "Random sample drawn from a normal distribution using jamovi"
msgstr "Tilfeldig utvalg trukket fra en normalfordeling ved hjelp av jamovi"

#: ../../Ch08/Ch08_Estimation_2.rst:38
msgid ""
"I feel a bit silly saying this, but the thing I want you to take away from "
"this is that large samples generally give you better information. I feel "
"silly saying it because it’s so bloody obvious that it shouldn’t need to be "
"said. In fact, it’s such an obvious point that when Jacob Bernoulli, one of "
"the founders of probability theory, formalised this idea back in 1713 he was "
"kind of a jerk about it. Here’s how he described the fact that we all share "
"this intuition:"
msgstr ""
"Det føles litt dumt å si dette, men det jeg vil at du skal ta med deg fra "
"dette, er at store utvalg generelt gir deg bedre informasjon. Det føles dumt "
"å si det, for det er så innlysende at det ikke burde være nødvendig å si "
"det. Faktisk er det så opplagt at da Jacob Bernoulli, en av grunnleggerne av "
"sannsynlighetsteorien, formaliserte denne ideen i 1713, var han litt av en "
"idiot. Slik beskrev han det faktum at vi alle deler denne intuisjonen:"

#: ../../Ch08/Ch08_Estimation_2.rst:46
msgid ""
"*For even the most stupid of men, by some instinct of nature, by himself and "
"without any instruction (which is a remarkable thing), is convinced that the "
"more observations have been made, the less danger there is of wandering from "
"one’s goal* (:ref:`Stigler, 1986 <Stigler_1986>`)."
msgstr ""
"*For selv den dummeste av alle mennesker er overbevist om at jo flere "
"observasjoner som er gjort, jo mindre fare er det for å komme bort fra målet*"
" (:ref:`Stigler, 1986 <Stigler_1986>`)."

#: ../../Ch08/Ch08_Estimation_2.rst:52
msgid ""
"Okay, so the passage comes across as a bit condescending (not to mention "
"sexist), but his main point is correct. It really does feel obvious that "
"more data will give you better answers. The question is, why is this so? Not "
"surprisingly, this intuition that we all share turns out to be correct, and "
"statisticians refer to it as the **law of large numbers**. The law of large "
"numbers is a mathematical law that applies to many different sample "
"statistics but the simplest way to think about it is as a law about "
"averages. The sample mean is the most obvious example of a statistic that "
"relies on averaging (because that’s what the mean is… an average), so let’s "
"look at that. When applied to the sample mean what the law of large numbers "
"states is that as the sample gets larger, the sample mean tends to get "
"closer to the true population mean. Or, to say it a little bit more "
"precisely, as the sample size “approaches” infinity (written as *N* → ∞), "
"the sample mean approaches the population mean (*X̄* → µ).\\ [#]_"
msgstr ""
"Ok, passasjen virker litt nedlatende (for ikke å snakke om sexistisk), men "
"hovedpoenget hans er riktig. Det føles egentlig åpenbart at mer data vil gi "
"deg bedre svar. Spørsmålet er hvorfor det er slik. Ikke overraskende viser "
"det seg at denne intuisjonen, som vi alle deler, er riktig, og statistikere "
"refererer til den som **loven om store tall**. Loven om store tall er en "
"matematisk lov som gjelder for mange forskjellige utvalgsstatistikker, men "
"den enkleste måten å tenke på den på, er som en lov om gjennomsnitt. "
"Utvalgsgjennomsnittet er det mest åpenbare eksempelet på en statistikk som "
"baserer seg på gjennomsnittsberegning (fordi det er det gjennomsnittet er… "
"en middelverdi), så la oss se på det. Når det gjelder gjennomsnittet i et "
"utvalg, sier loven om store tall at når utvalget blir større, har "
"gjennomsnittet i utvalget en tendens til å nærme seg det sanne "
"populasjonsgjennomsnittet. Eller, for å si det litt mer presist: Når "
"utvalgsstørrelsen «nærmer seg» uendelig (skrevet som *N* → ∞), vil "
"utvalgsgjennomsnittet nærme seg populasjonsgjennomsnittet (*X̄* → µ).\\ [#]_"

#: ../../Ch08/Ch08_Estimation_2.rst:67
msgid ""
"I don’t intend to subject you to a proof that the law of large numbers is "
"true, but it’s one of the most important tools for statistical theory. The "
"law of large numbers is the thing we can use to justify our belief that "
"collecting more and more data will eventually lead us to the truth. For any "
"particular data set the sample statistics that we calculate from it will be "
"wrong, but the law of large numbers tells us that if we keep collecting more "
"data those sample statistics will tend to get closer and closer to the true "
"population parameters."
msgstr ""
"Jeg har ikke tenkt å underkaste deg et bevis for at de store talls lov er "
"sann, men den er et av de viktigste verktøyene for statistisk teori. Loven "
"om store tall er det vi kan bruke for å rettferdiggjøre vår tro på at "
"innsamling av stadig flere data til slutt vil føre oss til sannheten. For et "
"bestemt datasett vil utvalgsstatistikken vi beregner ut fra det, være feil, "
"men loven om store tall forteller oss at hvis vi fortsetter å samle inn "
"flere data, vil utvalgsstatistikken ha en tendens til å komme nærmere og "
"nærmere de sanne populasjonsparameterne."

#: ../../Ch08/Ch08_Estimation_2.rst:79
msgid ""
"Technically, the law of large numbers pertains to any sample statistic that "
"can be described as an average of independent quantities. That’s certainly "
"true for the sample mean. However, it’s also possible to write many other "
"sample statistics as averages of one form or another. The variance of a "
"sample, for instance, can be rewritten as a kind of average and so is "
"subject to the law of large numbers. The minimum value of a sample, however, "
"cannot be written as an average of anything and is therefore not governed by "
"the law of large numbers."
msgstr ""
"Teknisk sett gjelder loven om store tall for all utvalgsstatistikk som kan "
"beskrives som et gjennomsnitt av uavhengige størrelser. Det gjelder absolutt "
"for gjennomsnittet i et utvalg. Det er imidlertid også mulig å skrive mange "
"andre utvalgsstatistikker som gjennomsnitt i en eller annen form. Variansen "
"til et utvalg kan for eksempel omskrives som et slags gjennomsnitt og er "
"dermed underlagt de store talls lov. Minimumsverdien av et utvalg kan "
"imidlertid ikke skrives som et gjennomsnitt av noe som helst og er derfor "
"ikke underlagt loven om store tall."

#: ../../Ch08/Ch08_Estimation_3.rst:4
msgid "Sampling distributions and the central limit theorem"
msgstr "Utvalgsfordelinger og sentralgrenseteoremet"

#: ../../Ch08/Ch08_Estimation_3.rst:6
msgid ""
"The law of large numbers is a very powerful tool but it’s not going to be "
"good enough to answer all our questions. Among other things, all it gives us "
"is a “long run guarantee”. In the long run, if we were somehow able to "
"collect an infinite amount of data, then the law of large numbers guarantees "
"that our sample statistics will be correct. But as John Maynard Keynes "
"famously argued in economics, a long run guarantee is of little use in real "
"life."
msgstr ""
"De store talls lov er et veldig kraftfullt verktøy, men det er ikke godt nok "
"til å besvare alle spørsmålene våre. Blant annet gir den oss bare en «"
"garanti på lang sikt». Hvis vi på en eller annen måte kunne samle inn en "
"uendelig mengde data, ville loven om store tall på lang sikt garantere at "
"utvalgsstatistikken vår ville være korrekt. Men som John Maynard Keynes så "
"berømt hevdet i økonomifaget, er en langsiktig garanti til liten nytte i det "
"virkelige liv."

#: ../../Ch08/Ch08_Estimation_3.rst:14
msgid ""
"*[The] long run is a misleading guide to current affairs. In the long run we "
"are all dead. Economists set themselves too easy, too useless a task, if in "
"tempestuous seasons they can only tell us, that when the storm is long past, "
"the ocean is flat again* (:ref:`Keynes, 1923 <Keynes_1923>`)."
msgstr ""
"*[Det] lange løp er en misvisende rettesnor for dagens situasjon. I det "
"lange løp er vi alle døde. Økonomene setter seg selv en altfor enkel, altfor "
"unyttig oppgave, hvis de i stormfulle årstider bare kan fortelle oss at når "
"stormen for lengst er over, er havet flatt igjen* (:ref:`Keynes, 1923 "
"<Keynes_1923>`)."

#: ../../Ch08/Ch08_Estimation_3.rst:20
msgid ""
"As in economics, so too in psychology and statistics. It is not enough to "
"know that we will *eventually* arrive at the right answer when calculating "
"the sample mean. Knowing that an infinitely large data set will tell me the "
"exact value of the population mean is cold comfort when my *actual* data set "
"has a sample size of *N* = 100. In real life, then, we must know something "
"about the behaviour of the sample mean when it is calculated from a more "
"modest data set!"
msgstr ""
"Som i økonomi, så også i psykologi og statistikk. Det er ikke nok å vite at "
"vi *til slutt* vil komme frem til det riktige svaret når vi beregner "
"utvalgsgjennomsnittet. Å vite at et uendelig stort datasett vil fortelle meg "
"den eksakte verdien av populasjonsgjennomsnittet, er en mager trøst når mitt "
"*virkelige* datasett har en utvalgsstørrelse på *N* = 100. I virkeligheten "
"må vi altså vite noe om hvordan utvalgsgjennomsnittet oppfører seg når det "
"beregnes ut fra et mer beskjedent datasett!"

#: ../../Ch08/Ch08_Estimation_3.rst:31
msgid "Sampling distribution of the mean"
msgstr "Utvalgsfordeling av gjennomsnittet"

#: ../../Ch08/Ch08_Estimation_3.rst:33
msgid ""
"With this in mind, let’s abandon the idea that our studies will have sample "
"sizes of 10,000 and consider instead a very modest experiment indeed. This "
"time around we’ll sample *N* = 5 people and measure their IQ scores. As "
"before, I can simulate this experiment in jamovi ``= NORM(100,15)`` "
"function, but I only need 5 participant IDs this time, not 10,000. These are "
"the five numbers that jamovi generated:"
msgstr ""
"Med dette i bakhodet kan vi forlate tanken om at studiene våre skal ha "
"utvalgsstørrelser på 10 000, og i stedet vurdere et svært beskjedent "
"eksperiment. Denne gangen tar vi et utvalg på *N* = 5 personer og måler IQ-"
"skårene deres. Som før kan jeg simulere dette eksperimentet i jamovi ``= "
"NORM(100, 15)``-funksjonen, men denne gangen trenger jeg bare 5 deltaker-ID-"
"er, ikke 10 000. Dette er de fem tallene som jamovi genererte:"

#: ../../Ch08/Ch08_Estimation_3.rst:44
msgid ""
"The mean IQ in this sample turns out to be exactly 95. Not surprisingly, "
"this is much less accurate than the previous experiment. Now imagine that I "
"decided to **replicate** the experiment. That is, I repeat the procedure as "
"closely as possible and I randomly sample 5 new people and measure their IQ. "
"Again, jamovi allows me to simulate the results of this procedure, and "
"generates these five numbers:"
msgstr ""
"Den gjennomsnittlige IQ-en i dette utvalget viser seg å være nøyaktig 95. "
"Ikke overraskende er dette mye mindre nøyaktig enn det forrige "
"eksperimentet. Tenk deg nå at jeg bestemmer meg for å **replikere** "
"eksperimentet. Det vil si at jeg gjentar prosedyren så nøye som mulig, og at "
"jeg tilfeldig velger ut fem nye personer og måler IQ-en deres. Igjen lar "
"jamovi meg simulere resultatene av denne prosedyren, og genererer disse fem "
"tallene:"

#: ../../Ch08/Ch08_Estimation_3.rst:55
msgid ""
"This time around, the mean IQ in my sample is 101. If I repeat the "
"experiment 10 times I obtain the results shown in :numref:`tab-"
"replications`, and as you can see the sample mean varies from one "
"replication to the next."
msgstr ""
"Denne gangen er den gjennomsnittlige IQ-en i utvalget mitt 101. Hvis jeg "
"gjentar eksperimentet 10 ganger, får jeg resultatene som vises i :numref"
":`tab-replications`, og som du kan se, varierer gjennomsnittet i utvalget "
"fra en replikasjon til den neste."

#: ../../Ch08/Ch08_Estimation_3.rst:59
msgid ""
"Ten replications of the IQ experiment, each with a sample size of *N* =5"
msgstr ""
"Ti gjentakelser av IQ-eksperimentet, hver med en utvalgsstørrelse på *N* =5"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 1"
msgstr "Person 1"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 2"
msgstr "Person 2"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 3"
msgstr "Person 3"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 4"
msgstr "Person 4"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 5"
msgstr "Person 5"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Sample Mean"
msgstr "Utvalg Gjennomsnitt"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "Replication 1"
msgstr "Replikasjon 1"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "90"
msgstr "90"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "82"
msgstr "82"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "94"
msgstr "94"

#: ../../Ch08/Ch08_Estimation_3.rst:65 ../../Ch08/Ch08_Estimation_3.rst:71
msgid "99"
msgstr "99"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "110"
msgstr "110"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "95.0"
msgstr "95.0"

#: ../../Ch08/Ch08_Estimation_3.rst:67
msgid "Replication 2"
msgstr "Replikasjon 2"

#: ../../Ch08/Ch08_Estimation_3.rst:67
msgid "78"
msgstr "78"

#: ../../Ch08/Ch08_Estimation_3.rst:67
msgid "88"
msgstr "88"

#: ../../Ch08/Ch08_Estimation_3.rst:67 ../../Ch08/Ch08_Estimation_3.rst:69
msgid "111"
msgstr "111"

#: ../../Ch08/Ch08_Estimation_3.rst:67 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "117"
msgstr "117"

#: ../../Ch08/Ch08_Estimation_3.rst:67
msgid "101.0"
msgstr "101.0"

#: ../../Ch08/Ch08_Estimation_3.rst:69
msgid "Replication 3"
msgstr "Replikasjon 3"

#: ../../Ch08/Ch08_Estimation_3.rst:69
msgid "122"
msgstr "122"

#: ../../Ch08/Ch08_Estimation_3.rst:69
msgid "91"
msgstr "91"

#: ../../Ch08/Ch08_Estimation_3.rst:69 ../../Ch08/Ch08_Estimation_3.rst:71
#: ../../Ch08/Ch08_Estimation_3.rst:73 ../../Ch08/Ch08_Estimation_3.rst:77
msgid "98"
msgstr "98"

#: ../../Ch08/Ch08_Estimation_3.rst:69 ../../Ch08/Ch08_Estimation_3.rst:81
msgid "86"
msgstr "86"

#: ../../Ch08/Ch08_Estimation_3.rst:69
msgid "101.6"
msgstr "101.6"

#: ../../Ch08/Ch08_Estimation_3.rst:71
msgid "Replication 4"
msgstr "Replikasjon 4"

#: ../../Ch08/Ch08_Estimation_3.rst:71
msgid "96"
msgstr "96"

#: ../../Ch08/Ch08_Estimation_3.rst:71 ../../Ch08/Ch08_Estimation_3.rst:81
msgid "119"
msgstr "119"

#: ../../Ch08/Ch08_Estimation_3.rst:71 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "107"
msgstr "107"

#: ../../Ch08/Ch08_Estimation_3.rst:71
msgid "103.8"
msgstr "103.8"

#: ../../Ch08/Ch08_Estimation_3.rst:73
msgid "Replication 5"
msgstr "Replikasjon 5"

#: ../../Ch08/Ch08_Estimation_3.rst:73 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "105"
msgstr "105"

#: ../../Ch08/Ch08_Estimation_3.rst:73
msgid "113"
msgstr "113"

#: ../../Ch08/Ch08_Estimation_3.rst:73
msgid "103"
msgstr "103"

#: ../../Ch08/Ch08_Estimation_3.rst:73
msgid "104.4"
msgstr "104.4"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "Replication 6"
msgstr "Replikasjon 6"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "81"
msgstr "81"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "89"
msgstr "89"

#: ../../Ch08/Ch08_Estimation_3.rst:75 ../../Ch08/Ch08_Estimation_3.rst:77
msgid "93"
msgstr "93"

#: ../../Ch08/Ch08_Estimation_3.rst:75 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "85"
msgstr "85"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "114"
msgstr "114"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "92.4"
msgstr "92.4"

#: ../../Ch08/Ch08_Estimation_3.rst:77
msgid "Replication 7"
msgstr "Replikasjon 7"

#: ../../Ch08/Ch08_Estimation_3.rst:77 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "100"
msgstr "100"

#: ../../Ch08/Ch08_Estimation_3.rst:77 ../../Ch08/Ch08_Estimation_3.rst:81
msgid "108"
msgstr "108"

#: ../../Ch08/Ch08_Estimation_3.rst:77
msgid "133"
msgstr "133"

#: ../../Ch08/Ch08_Estimation_3.rst:77
msgid "106.4"
msgstr "106.4"

#: ../../Ch08/Ch08_Estimation_3.rst:79
msgid "Replication 8"
msgstr "Replikasjon 8"

#: ../../Ch08/Ch08_Estimation_3.rst:79
msgid "102.8"
msgstr "102.8"

#: ../../Ch08/Ch08_Estimation_3.rst:81
msgid "Replication 9"
msgstr "Replikasjon 9"

#: ../../Ch08/Ch08_Estimation_3.rst:81
msgid "73"
msgstr "73"

#: ../../Ch08/Ch08_Estimation_3.rst:81
msgid "116"
msgstr "116"

#: ../../Ch08/Ch08_Estimation_3.rst:81
msgid "100.4"
msgstr "100.4"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "Replication 10"
msgstr "Replikasjon 10"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "95"
msgstr "95"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "126"
msgstr "126"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "112"
msgstr "112"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "120"
msgstr "120"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "76"
msgstr "76"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "105.8"
msgstr "105.8"

#: ../../Ch08/Ch08_Estimation_3.rst:86
msgid ""
"Now suppose that I decided to keep going in this fashion, replicating this "
"“five IQ scores” experiment over and over again. Every time I replicate the "
"experiment I write down the sample mean. Over time, I’d be amassing a new "
"data set, in which every experiment generates a single data point. The first "
"10 observations from my data set are the sample means listed in :numref:`tab-"
"replications`, so my data set starts out like this:"
msgstr ""
"Anta nå at jeg bestemmer meg for å fortsette på denne måten, og gjenta dette "
"«fem IQ-skårer»-eksperimentet om og om igjen. Hver gang jeg gjentar "
"eksperimentet, skriver jeg ned gjennomsnittet for utvalget. Over tid vil jeg "
"samle et nytt datasett, der hvert eksperiment genererer ett enkelt "
"datapunkt. De første 10 observasjonene fra datasettet mitt er "
"utvalgsgjennomsnittene som er oppført i :numref:`tab-replications`, så "
"datasettet mitt starter slik:"

#: ../../Ch08/Ch08_Estimation_3.rst:98
msgid ""
"What if I continued like this for 10,000 replications, and then drew a "
"histogram. Well that’s exactly what I did, and you can see the results in :"
"numref:`fig-samplingDist4`. As this picture illustrates, the average of 5 IQ "
"scores is usually between 90 and 110. But more importantly, what it "
"highlights is that if we replicate an experiment over and over again, what "
"we end up with is a *distribution* of sample means! This distribution has a "
"special name in statistics, it’s called the **sampling distribution of the "
"mean**."
msgstr ""
"Hva om jeg fortsatte slik i 10 000 replikasjoner, og deretter tegnet et "
"histogram? Det var akkurat det jeg gjorde, og du kan se resultatene i :numref"
":`fig-samplingDist4`. Som dette bildet illustrerer, ligger gjennomsnittet av "
"5 IQ-skårer vanligvis mellom 90 og 110. Men enda viktigere er det at hvis vi "
"gjentar et eksperiment om og om igjen, ender vi opp med en *fordeling* av "
"utvalgsgjennomsnitt! Denne fordelingen har et spesielt navn i statistikken, "
"den kalles **utvalgsfordelingen av gjennomsnittet**."

#: ../../Ch08/Ch08_Estimation_3.rst:109
msgid "Sampling distribution: Mean for the “five IQ scores experiment”"
msgstr "Utvalgsfordeling: Gjennomsnitt for «eksperimentet med fem IQ-skårer»"

#: ../../Ch08/Ch08_Estimation_3.rst:113
msgid ""
"The sampling distribution of the mean for the “five IQ scores experiment”: "
"If you sample 5 people at random and calculate their average IQ you’ll "
"almost certainly get a number between 80 and 120, even though there are "
"quite a lot of individuals who have IQs above 120 or below 80. For "
"comparison, the black line plots the population distribution of IQ scores."
msgstr ""
"Utvalgsfordelingen av gjennomsnittet for «eksperimentet med fem IQ-skårer»: "
"Hvis du tar et tilfeldig utvalg på 5 personer og beregner gjennomsnitts-IQ-"
"en deres, vil du nesten helt sikkert få et tall mellom 80 og 120, selv om "
"det er ganske mange personer som har en IQ over 120 eller under 80. Til "
"sammenligning viser den svarte linjen fordelingen av IQ-skårer i "
"befolkningen."

#: ../../Ch08/Ch08_Estimation_3.rst:121
msgid ""
"Sampling distributions are another important theoretical idea in statistics, "
"and they’re crucial for understanding the behaviour of small samples. For "
"instance, when I ran the very first “five IQ scores” experiment, the sample "
"mean turned out to be 95. What the sampling distribution in :numref:`fig-"
"samplingDist4` tells us, though, is that the “five IQ scores” experiment is "
"not very accurate. If I repeat the experiment, the sampling distribution "
"tells me that I can expect to see a sample mean anywhere between 80 and 120."
msgstr ""
"Utvalgsfordelinger er en annen viktig teoretisk idé innen statistikk, og de "
"er avgjørende for å forstå hvordan små utvalg oppfører seg. Da jeg for "
"eksempel kjørte det aller første eksperimentet med «fem IQ-skårer», viste "
"det seg at utvalgsgjennomsnittet var 95. Utvalgsfordelingen i :numref:`fig-"
"samplingDist4` forteller oss imidlertid at eksperimentet med «fem IQ-skårer» "
"ikke er særlig nøyaktig. Hvis jeg gjentar eksperimentet, forteller "
"utvalgsfordelingen meg at jeg kan forvente å se et utvalgsgjennomsnitt et "
"sted mellom 80 og 120."

#: ../../Ch08/Ch08_Estimation_3.rst:131
msgid "Sampling distributions exist for any sample statistic!"
msgstr "Det finnes utvalgsfordelinger for enhver utvalgsstatistikk!"

#: ../../Ch08/Ch08_Estimation_3.rst:133
msgid ""
"One thing to keep in mind when thinking about sampling distributions is that "
"*any* sample statistic you might care to calculate has a sampling "
"distribution. For example, suppose that each time I replicated the “five IQ "
"scores” experiment I wrote down the largest IQ score in the experiment. This "
"would give me a data set that started out like this:"
msgstr ""
"En ting du må huske på når du tenker på utvalgsfordelinger, er at *alle* "
"utvalgsstatistikker du måtte ønske å beregne, har en utvalgsfordeling. Anta "
"for eksempel at jeg hver gang jeg replikerte eksperimentet med «fem IQ-"
"skårer», skrev ned den største IQ-skåren i eksperimentet. Dette ville gitt "
"meg et datasett som startet slik:"

#: ../../Ch08/Ch08_Estimation_3.rst:143
msgid ""
"Doing this over and over again would give me a very different sampling "
"distribution, namely the *sampling distribution of the maximum*. The "
"sampling distribution of the maximum of 5 IQ scores is shown in :numref:`fig-"
"samplingDistMax`. Not surprisingly, if you pick 5 people at random and then "
"find the person with the highest IQ score, they’re going to have an above "
"average IQ. Most of the time you’ll end up with someone whose IQ is measured "
"in the 100 to 140 range."
msgstr ""
"Hvis jeg gjør dette om og om igjen, vil jeg få en helt annen "
"utvalgsfordeling, nemlig *utvalgsfordelingen for maksimum*. "
"Utvalgsfordelingen for maksimum av 5 IQ-skårer er vist i :numref:`fig-"
"samplingDistMax`. Det er ikke overraskende at hvis du velger fem tilfeldige "
"personer og deretter finner personen med den høyeste IQ-scoren, kommer "
"vedkommende til å ha en IQ over gjennomsnittet. Som oftest vil du ende opp "
"med en person som har en IQ på mellom 100 og 140."

#: ../../Ch08/Ch08_Estimation_3.rst:153
msgid "Sampling distribution: Maximum for the “five IQ scores experiment”"
msgstr "Utvalgsfordeling: Maksimum for «eksperimentet med fem IQ-skårer»"

#: ../../Ch08/Ch08_Estimation_3.rst:157
msgid ""
"The sampling distribution of the maximum for the “five IQ scores "
"experiment”: If you sample 5 people at random and select the one with the "
"highest IQ score you’ll probably see someone with an IQ between 100 and 140."
msgstr ""
"Utvalgsfordelingen av maksimum for «eksperimentet med fem IQ-skårer»: Hvis "
"du tar et tilfeldig utvalg på 5 personer og velger den med høyest IQ-score, "
"vil du sannsynligvis finne noen med en IQ mellom 100 og 140."

#: ../../Ch08/Ch08_Estimation_3.rst:166
msgid "The central limit theorem"
msgstr "Den sentrale grenseteoremet"

#: ../../Ch08/Ch08_Estimation_3.rst:168
msgid ""
"At this point I hope you have a pretty good sense of what sampling "
"distributions are, and in particular what the sampling distribution of the "
"mean is. In this section I want to talk about how the sampling distribution "
"of the mean changes as a function of sample size. Intuitively, you already "
"know part of the answer. If you only have a few observations, the sample "
"mean is likely to be quite inaccurate. If you replicate a small experiment "
"and recalculate the mean you’ll get a very different answer. In other words, "
"the sampling distribution is quite wide. If you replicate a large experiment "
"and recalculate the sample mean you’ll probably get the same answer you got "
"last time, so the sampling distribution will be very narrow. You can see "
"this visually in :numref:`fig-samplingDistDiffN`, showing that the bigger "
"the sample size, the narrower the sampling distribution gets. We can "
"quantify this effect by calculating the standard deviation of the sampling "
"distribution, which is referred to as the **standard error**. The standard "
"error of a statistic is often denoted SE, and since we’re usually interested "
"in the standard error of the sample *mean*, we often use the acronym SEM. As "
"you can see just by looking at the picture, as the sample size *N* "
"increases, the SEM decreases."
msgstr ""
"Nå håper jeg at du har en ganske god forståelse av hva utvalgsfordelinger "
"er, og spesielt hva utvalgsfordelingen til gjennomsnittet er. I denne delen "
"vil jeg snakke om hvordan utvalgsfordelingen til gjennomsnittet endrer seg "
"som en funksjon av utvalgsstørrelsen. Intuitivt vet du allerede en del av "
"svaret. Hvis du bare har noen få observasjoner, er det sannsynlig at "
"utvalgsgjennomsnittet blir ganske unøyaktig. Hvis du gjentar et lite "
"eksperiment og beregner gjennomsnittet på nytt, vil du få et helt annet "
"svar. Utvalgsfordelingen er med andre ord ganske bred. Hvis du gjentar et "
"stort eksperiment og beregner gjennomsnittet på nytt, vil du sannsynligvis "
"få det samme svaret som forrige gang, og utvalgsfordelingen vil derfor være "
"svært smal. Du kan se dette visuelt i :numref:`fig-samplingDistDiffN`, som "
"viser at jo større utvalget er, desto smalere blir utvalgsfordelingen. Vi "
"kan kvantifisere denne effekten ved å beregne standardavviket til "
"utvalgsfordelingen, som kalles **standardfeilen**. Standardfeilen til en "
"statistikk betegnes ofte SE, og siden vi vanligvis er interessert i "
"standardfeilen til utvalgets *gjennomsnitt*, bruker vi ofte akronymet SEM. "
"Som du kan se bare ved å se på bildet, synker SEM når utvalgsstørrelsen *N* "
"øker."

#: ../../Ch08/Ch08_Estimation_3.rst:190
msgid "Shape of the sampling distribution in dependence of the sample size"
msgstr "Utvalgsfordelingens form avhenger av utvalgsstørrelsen"

#: ../../Ch08/Ch08_Estimation_3.rst:194
msgid ""
"Illustration of the how sampling distribution of the mean depends on sample "
"size. In each panel I generated 10,000 samples of IQ data and calculated the "
"mean IQ observed within each of these data sets. The histograms in these "
"plots show the distribution of these means (i.e., the sampling distribution "
"of the mean). Each individual IQ score was drawn from a normal distribution "
"with mean 100 and standard deviation 15, which is shown as the solid black "
"line. In the left panel, each data set contained only a single observation, "
"so the mean of each sample is just one person’s IQ score. As a consequence, "
"the sampling distribution of the mean is of course identical to the "
"population distribution of IQ scores. However, when we raise the sample size "
"to 2 (middle panel) the mean of any one sample tends to be closer to the "
"population mean than a one person’s IQ score, and so the histogram (i.e., "
"the sampling distribution) is a bit narrower than the population "
"distribution. By the time we raise the sample size to 10 (right panel), we "
"can see that the distribution of sample means tend to be fairly tightly "
"clustered around the true population mean."
msgstr ""
"Illustrasjon av hvordan utvalgsfordelingen av gjennomsnittet avhenger av "
"utvalgsstørrelsen. I hvert panel har jeg generert 10 000 utvalg av IQ-data "
"og beregnet den gjennomsnittlige IQ-en som ble observert i hvert av disse "
"datasettene. Histogrammene i disse plottene viser fordelingen av disse "
"gjennomsnittene (dvs. utvalgsfordelingen av gjennomsnittet). Hver enkelt IQ-"
"skår ble trukket fra en normalfordeling med gjennomsnitt 100 og "
"standardavvik 15, som er vist som den heltrukne, svarte linjen. I panelet "
"til venstre inneholder hvert datasett bare én enkelt observasjon, så "
"gjennomsnittet for hvert utvalg er bare én persons IQ-skår. Som en "
"konsekvens av dette er utvalgsfordelingen av gjennomsnittet selvsagt "
"identisk med populasjonsfordelingen av IQ-skårer. Når vi øker "
"utvalgsstørrelsen til 2 (midterste panel), har imidlertid gjennomsnittet for "
"hvert enkelt utvalg en tendens til å ligge nærmere populasjonsgjennomsnittet "
"enn én persons IQ-skår, slik at histogrammet (dvs. utvalgsfordelingen) blir "
"litt smalere enn populasjonsfordelingen. Når vi øker utvalgsstørrelsen til "
"10 (høyre panel), kan vi se at fordelingen av utvalgsgjennomsnitt har en "
"tendens til å være ganske tett samlet rundt det sanne "
"populasjonsgjennomsnittet."

#: ../../Ch08/Ch08_Estimation_3.rst:213
msgid ""
"Okay, so that’s one part of the story. However, there’s something I’ve been "
"glossing over so far. All my examples up to this point have been based on "
"the “IQ scores” experiments, and because IQ scores are roughly normally "
"distributed I’ve assumed that the population distribution is normal. What if "
"it isn’t normal? What happens to the sampling distribution of the mean? The "
"remarkable thing is this, no matter what shape your population distribution "
"is, as *N* increases the sampling distribution of the mean starts to look "
"more like a normal distribution. To give you a sense of this I ran some "
"simulations. To do this, I started with the “ramped” distribution shown in "
"the histogram in :numref:`fig-cltDemo` (top-left panel). As you can see by "
"comparing the triangular shaped histogram to the bell curve plotted by the "
"black line, the population distribution doesn’t look very much like a normal "
"distribution at all. Next, I simulated the results of a large number of "
"experiments. In each experiment I took *N* = 2 samples from this "
"distribution, and then calculated the sample mean. :numref:`fig-cltDemo` "
"(top-right panel) plots the histogram of these sample means (i.e., the "
"sampling distribution of the mean for *N* = 2). This time, the histogram "
"produces a ∩-shaped distribution. It’s still not normal, but it’s a lot "
"closer to the black line than the population distribution in :numref:`fig-"
"cltDemo` (top-left panel). When I increase the sample size to *N* = 4, the "
"sampling distribution of the mean is very close to normal (:numref:`fig-"
"cltDemo`, bottom-left panel), and by the time we reach a sample size of *N* "
"= 8 (:numref:`fig-cltDemo`; bottom- right panel) it’s almost perfectly "
"normal. In other words, as long as your sample size isn’t tiny, the sampling "
"distribution of the mean will be approximately normal no matter what your "
"population distribution looks like!"
msgstr ""
"Ok, så det er en del av historien. Det er imidlertid noe jeg har gått glipp "
"av så langt. Alle eksemplene mine så langt har vært basert på eksperimentene "
"med «IQ-skårer», og fordi IQ-skår er noenlunde normalfordelte, har jeg "
"antatt at populasjonen er normalfordelt. Hva om den ikke er normalfordelt? "
"Hva skjer da med utvalgsfordelingen av gjennomsnittet? Det "
"bemerkelsesverdige er at uansett hvilken form populasjonsfordelingen din "
"har, vil utvalgsfordelingen av gjennomsnittet begynne å ligne mer på en "
"normalfordeling når *N* øker. For å gi deg en fornemmelse av dette har jeg "
"kjørt noen simuleringer. For å gjøre dette startet jeg med den «rampeformede»"
" fordelingen som vises i histogrammet i :numref:`fig-cltDemo` (panelet "
"øverst til venstre). Som du kan se ved å sammenligne det trekantformede "
"histogrammet med klokkekurven som er tegnet inn med den svarte linjen, ser "
"ikke populasjonsfordelingen ut som en normalfordeling i det hele tatt. "
"Deretter simulerte jeg resultatene av et stort antall eksperimenter. I hvert "
"eksperiment tok jeg *N* = 2 utvalg fra denne fordelingen, og beregnet "
"deretter utvalgsgjennomsnittet. :numref:`fig-cltDemo` (panelet øverst til "
"høyre) viser histogrammet til disse utvalgsgjennomsnittene (dvs. "
"utvalgsfordelingen til gjennomsnittet for *N* = 2). Denne gangen gir "
"histogrammet en ∩-formet fordeling. Den er fortsatt ikke normalfordelt, men "
"den er mye nærmere den svarte linjen enn populasjonsfordelingen i :numref"
":`fig-cltDemo` (panelet øverst til venstre). Når jeg øker utvalgsstørrelsen "
"til *N* = 4, er utvalgsfordelingen til gjennomsnittet svært nær en "
"normalfordeling (:numref:`fig-cltDemo`, nederste venstre panel), og når vi "
"når en utvalgsstørrelse på *N* = 8 (:numref:`fig-cltDemo`; nederste høyre "
"panel), er den nesten helt normalfordelt. Med andre ord, så lenge "
"utvalgsstørrelsen ikke er bitteliten, vil utvalgsfordelingen av "
"gjennomsnittet være tilnærmet normalfordelt, uansett hvordan "
"populasjonsfordelingen ser ut!"

#: ../../Ch08/Ch08_Estimation_3.rst:242
msgid "Demonstration of the central limit theorem"
msgstr "Demonstrasjon av sentralgrenseteoremet"

#: ../../Ch08/Ch08_Estimation_3.rst:246
msgid ""
"Demonstration of the central limit theorem: In the top-left panel, we have a "
"non-normal population distribution, and the remaining panels show the "
"sampling distribution of the mean for samples of size 2 (top-right), 4 "
"(bottom-left) and 8 (bottom-right) for data drawn from the distribution in "
"the top-left panel. As you can see, even though the original population "
"distribution is non-normal the sampling distribution of the mean becomes "
"pretty close to normal by the time you have a sample of even 4 observations."
msgstr ""
"Demonstrasjon av sentralgrenseteoremet: I panelet øverst til venstre har vi "
"en populasjonsfordeling som er ikke normalfordelt, og de resterende panelene "
"viser utvalgsfordelingen av gjennomsnittet for utvalg av størrelse 2 (øverst "
"til høyre), 4 (nederst til venstre) og 8 (nederst til høyre) for data hentet "
"fra fordelingen i panelet øverst til venstre. Som du kan se, blir "
"fordelingen av gjennomsnittet i stikkprøven er ganske nær en normalfordeling "
"selv om den opprinnelige populasjonsfordelingen ikke er normalfordelt, når "
"du har en stikkprøve på til og med fire observasjoner."

#: ../../Ch08/Ch08_Estimation_3.rst:256
msgid ""
"On the basis of these figures, it seems like we have evidence for all of the "
"following claims about the sampling distribution of the mean."
msgstr ""
"På grunnlag av disse tallene ser det ut til at vi har bevis for alle de "
"følgende påstandene om utvalgsfordelingen av gjennomsnittet."

#: ../../Ch08/Ch08_Estimation_3.rst:259
msgid ""
"The mean of the sampling distribution is the same as the mean of the "
"population"
msgstr ""
"Gjennomsnittet av utvalgsfordelingen er det samme som gjennomsnittet av "
"populasjonen"

#: ../../Ch08/Ch08_Estimation_3.rst:262
msgid ""
"The standard deviation of the sampling distribution (i.e., the standard "
"error) gets smaller as the sample size increases"
msgstr ""
"Standardavviket til utvalgsfordelingen (dvs. standardfeilen) blir mindre "
"etter hvert som utvalgsstørrelsen øker"

#: ../../Ch08/Ch08_Estimation_3.rst:265
msgid ""
"The shape of the sampling distribution becomes normal as the sample size "
"increases"
msgstr ""
"Formen på utvalgsfordelingen tilnærmer seg en normalfordeling når "
"utvalgsstørrelsen øker"

#: ../../Ch08/Ch08_Estimation_3.rst:268
msgid ""
"As it happens, not only are all of these statements true, there is a very "
"famous theorem in statistics that proves all three of them, known as the "
"**central limit theorem**. Among other things, the central limit theorem "
"tells us that if the population distribution has mean µ and standard "
"deviation σ, then the sampling distribution of the mean also has mean µ and "
"the standard error of the mean is"
msgstr ""
"Ikke bare er alle disse utsagnene sanne, det finnes også en svært berømt "
"setning i statistikk som beviser alle tre, kjent som "
"**sentralgrenseteoremet**. Sentralgrenseteoremet forteller oss blant annet "
"at hvis populasjonsfordelingen har gjennomsnitt µ og standardavvik σ, så har "
"utvalgsfordelingen av gjennomsnittet også gjennomsnitt µ, og standardfeilen "
"til gjennomsnittet er"

#: ../../Ch08/Ch08_Estimation_3.rst:276
msgid ""
"\\mbox{SEM} = \\frac{\\sigma}{ \\sqrt{N} }\n"
"\n"
msgstr ""
"\\mbox{SEM} = \\frac{\\sigma}{ \\sqrt{N} }\n"
"\n"

#: ../../Ch08/Ch08_Estimation_3.rst:278
msgid ""
"Because we divide the population standard deviation σ by the square root of "
"the sample size *N*, the SEM gets smaller as the sample size increases. It "
"also tells us that the shape of the sampling distribution becomes normal.\\ "
"[#]_"
msgstr ""
"Fordi vi dividerer populasjonens standardavvik σ med kvadratroten av "
"utvalgsstørrelsen *N*, blir SEM mindre når utvalgsstørrelsen øker. Det "
"forteller oss også at formen på utvalgsfordelingen blir normalfordelt.\\ [#]_"

#: ../../Ch08/Ch08_Estimation_3.rst:283
msgid ""
"This result is useful for all sorts of things. It tells us why large "
"experiments are more reliable than small ones, and because it gives us an "
"explicit formula for the standard error it tells us *how much* more reliable "
"a large experiment is. It tells us why the normal distribution is, well, "
"*normal*. In real experiments, many of the things that we want to measure "
"are actually averages of lots of different quantities (e.g., arguably, "
"“general” intelligence as measured by IQ is an average of a large number of "
"“specific” skills and abilities), and when that happens, the averaged "
"quantity should follow a normal distribution. Because of this mathematical "
"law, the normal distribution pops up over and over again in real data."
msgstr ""
"Dette resultatet er nyttig for alle mulige ting. Det forteller oss hvorfor "
"store eksperimenter er mer reliabel enn små, og fordi det gir oss en "
"eksplisitt formel for standardfeilen, forteller det oss *hvor mye* mer "
"reliabel et stort eksperiment er. Den forteller oss hvorfor "
"normalfordelingen er, vel, *normal*. I virkelige eksperimenter er mange av "
"de tingene vi ønsker å måle, faktisk gjennomsnittet av mange forskjellige "
"størrelser (f.eks. er «generell» intelligens, målt ved IQ, et gjennomsnitt "
"av et stort antall «spesifikke» ferdigheter og evner), og når det skjer, bør "
"gjennomsnittsstørrelsen følge en normalfordeling. På grunn av denne "
"matematiske loven dukker normalfordelingen opp igjen og igjen i reelle data."

#: ../../Ch08/Ch08_Estimation_3.rst:298
msgid ""
"As usual, I’m being a bit sloppy here. The central limit theorem is a bit "
"more general than this section implies. Like most introductory stats texts "
"I’ve discussed one situation where the central limit theorem holds: when "
"you’re taking an average across lots of independent events drawn from the "
"same distribution. However, the central limit theorem is much broader than "
"this. There’s a whole class of things called “*U*-statistics” for instance, "
"all of which satisfy the central limit theorem and therefore become normally "
"distributed for large sample sizes. The mean is one such statistic, but it’s "
"not the only one."
msgstr ""
"Som vanlig slurver jeg litt her. Sentralgrenseteoremet er litt mer generelt "
"enn dette avsnittet gir inntrykk av. I likhet med de fleste innføringsbøker "
"i statistikk har jeg diskutert én situasjon der sentralgrenseteoremet holder:"
" når du tar et gjennomsnitt over mange uavhengige hendelser som er trukket "
"fra samme fordeling. Sentralgrenseteoremet er imidlertid mye bredere enn "
"dette. Det finnes for eksempel en hel klasse av ting som kalles "
"«*U*-statistikk», som alle tilfredsstiller sentralgrenseteoremet og derfor "
"blir normalfordelte for store stikkprøver. Gjennomsnittet er en slik "
"statistikk, men det er ikke den eneste."

#: ../../Ch08/Ch08_Estimation_4.rst:4
msgid "Estimating population parameters"
msgstr "Estimering av populasjonsparametere"

#: ../../Ch08/Ch08_Estimation_4.rst:6
msgid ""
"In all the IQ examples in the previous sections we actually knew the "
"population parameters ahead of time. As every undergraduate gets taught in "
"their very first lecture on the measurement of intelligence, IQ scores are "
"*defined* to have mean 100 and standard deviation 15. However, this is a bit "
"of a lie. How do we know that IQ scores have a true population mean of 100? "
"Well, we know this because the people who designed the tests have "
"administered them to very large samples, and have then “rigged” the scoring "
"rules so that their sample has mean 100. That’s not a bad thing of course, "
"it’s an important part of designing a psychological measurement. However, "
"it’s important to keep in mind that this theoretical mean of 100 only "
"attaches to the population that the test designers used to design the tests. "
"Good test designers will actually go to some lengths to provide “test norms” "
"that can apply to lots of different populations (e.g., different age groups, "
"nationalities etc)."
msgstr ""
"I alle IQ-eksemplene i de foregående avsnittene kjente vi faktisk til "
"populasjonsparametrene på forhånd. Som alle studenter får vite i sin aller "
"første forelesning om intelligensmåling, er IQ-skårer *definert* til å ha et "
"gjennomsnitt på 100 og et standardavvik på 15. Dette er imidlertid litt av "
"en løgn. Hvordan vet vi at IQ-skårer har et sant populasjonsgjennomsnitt på "
"100? Det vet vi fordi de som har utviklet testene, har administrert dem på "
"svært store utvalg, og deretter «rigget» skåringsreglene slik at utvalget "
"deres har et gjennomsnitt på 100. Det er selvfølgelig ikke noe negativt, det "
"er en viktig del av det å utforme en psykologisk måling. Det er imidlertid "
"viktig å huske på at dette teoretiske gjennomsnittet på 100 bare gjelder for "
"den populasjonen som testdesignerne har brukt til å utforme testene. Gode "
"testdesignere vil faktisk strekke seg langt for å lage «testnormer» som kan "
"gjelde for mange ulike populasjoner (f.eks. ulike aldersgrupper, "
"nasjonaliteter osv.)."

#: ../../Ch08/Ch08_Estimation_4.rst:22
msgid ""
"This is very handy, but of course almost every research project of interest "
"involves looking at a different population of people to those used in the "
"test norms. For instance, suppose you wanted to measure the effect of low "
"level lead poisoning on cognitive functioning in Port Pirie, a South "
"Australian industrial town with a lead smelter. Perhaps you decide that you "
"want to compare IQ scores among people in Port Pirie to a comparable sample "
"in Whyalla, a South Australian industrial town with a steel refinery.\\ [#]_ "
"Regardless of which town you’re thinking about, it doesn’t make a lot of "
"sense simply to *assume* that the true population mean IQ is 100. No-one "
"has, to my knowledge, produced sensible norming data that can automatically "
"be applied to South Australian industrial towns. We’re going to have to "
"**estimate** the population parameters from a sample of data. So how do we "
"do this?"
msgstr ""
"Dette er veldig praktisk, men nesten alle forskningsprosjekter av interesse "
"innebærer selvsagt at man ser på en annen populasjon enn den som brukes i "
"testnormene. Tenk deg for eksempel at du ønsker å måle effekten av "
"blyforgiftning på kognitive funksjoner i Port Pirie, en sør-australsk "
"industriby med et blysmelteverk. Kanskje du bestemmer deg for at du vil "
"sammenligne IQ-skårer blant folk i Port Pirie med et sammenlignbart utvalg i "
"Whyalla, en sør-australsk industriby med et stålraffineri.\\ [#]_ Uansett "
"hvilken by du tenker på, gir det ikke mye mening å bare *anta* at den sanne "
"gjennomsnittlige IQ-en i befolkningen er 100. Ingen har, så vidt jeg vet, "
"produsert fornuftige normeringsdata som automatisk kan brukes på sør-"
"australske industribyer. Vi er nødt til å **estimere** "
"befolkningsparametrene fra et utvalg av data. Så hvordan gjør vi dette?"

#: ../../Ch08/Ch08_Estimation_4.rst:37
msgid "Estimating the population mean"
msgstr "Estimering av populasjonsgjennomsnittet"

#: ../../Ch08/Ch08_Estimation_4.rst:39
msgid ""
"Suppose we go to Port Pirie and 100 of the locals are kind enough to sit "
"through an IQ test. The average IQ score among these people turns out to be "
"*X̄* = 98.5. So what is the true mean IQ for the entire population of Port "
"Pirie? Obviously, we don’t know the answer to that question. It could be "
"97.2, but it could also be 103.5. Our sampling isn’t exhaustive so we cannot "
"give a definitive answer. Nevertheless, if I was forced at gunpoint to give "
"a “best guess” I’d have to say 98.5. That’s the essence of statistical "
"estimation: giving a best guess."
msgstr ""
"Anta at vi drar til Port Pirie, og at 100 av de lokale er så vennlige å "
"stille opp på en IQ-test. Den gjennomsnittlige IQ-skåren blant disse "
"menneskene viser seg å være *X̄* = 98,5. Så hva er den sanne gjennomsnitts-IQ-"
"en for hele befolkningen i Port Pirie? Det vet vi selvsagt ikke svaret på. "
"Den kan være 97,2, men den kan også være 103,5. Utvalget vårt er ikke "
"uttømmende, så vi kan ikke gi et definitivt svar. Likevel, hvis jeg ble "
"tvunget til å gi en «best mulg gjetning», ville jeg måtte si 98,5. Det er "
"det som er essensen i statistisk estimering: å gi en beste gjetning."

#: ../../Ch08/Ch08_Estimation_4.rst:48
msgid ""
"In this example estimating the unknown poulation parameter is "
"straightforward. I calculate the sample mean and I use that as my **estimate "
"of the population mean**. It’s pretty simple, and in the next section I’ll "
"explain the statistical justification for this intuitive answer. However, "
"for the moment what I want to do is make sure you recognise that the sample "
"statistic and the estimate of the population parameter are conceptually "
"different things. A sample statistic is a description of your data, whereas "
"the estimate is a guess about the population. With that in mind, "
"statisticians often different notation to refer to them. For instance, if "
"the true population mean is denoted µ, then we would use :math:`\\hat\\mu` "
"to refer to our estimate of the population mean. In contrast, the sample "
"mean is denoted *X̄* or sometimes *m* or *M*. However, in simple random "
"samples the estimate of the population mean is identical to the sample mean. "
"If I observe a sample mean of *X̄* = 98.5 then my estimate of the population "
"mean is also :math:`\\hat\\mu` = 98.5. To help keep the notation clear, "
"here’s a handy table:"
msgstr ""
"I dette eksempelet er det enkelt å estimere den ukjente "
"populasjonsparameteren. Jeg beregner gjennomsnittet i utvalget, og bruker "
"det som **estimat av populasjonsgjennomsnittet**. Det er ganske enkelt, og i "
"neste avsnitt skal jeg forklare den statistiske begrunnelsen for dette "
"intuitive svaret. Men for øyeblikket vil jeg sørge for at du er klar over at "
"utvalgsstatistikken og estimatet av populasjonsparameteren er to konseptuelt "
"forskjellige ting. En utvalgsstatistikk er en beskrivelse av dataene dine, "
"mens estimatet er en gjetning om populasjonen. Med dette i bakhodet bruker "
"statistikere ofte ulike notasjoner for å referere til dem. Hvis for eksempel "
"det sanne populasjonsgjennomsnittet betegnes µ, bruker vi :math:`\\hat\\mu` "
"for å referere til vårt estimat av populasjonsgjennomsnittet. I motsetning "
"til dette betegnes utvalgsgjennomsnittet *X̄* eller noen ganger *m* eller *M*"
". I enkle tilfeldige utvalg er imidlertid estimatet av "
"populasjonsgjennomsnittet identisk med utvalgsgjennomsnittet. Hvis jeg "
"observerer et utvalgsgjennomsnitt på *X̄* = 98,5, er estimatet mitt av "
"populasjonsgjennomsnittet også :math:`\\hat\\mu` = 98,5. Her er en praktisk "
"tabell for å holde notasjonen klar:"

#: ../../Ch08/Ch08_Estimation_4.rst:67 ../../Ch08/Ch08_Estimation_4.rst:265
msgid "Symbol"
msgstr "Symbol"

#: ../../Ch08/Ch08_Estimation_4.rst:68 ../../Ch08/Ch08_Estimation_4.rst:265
msgid "What is it?"
msgstr "Hva er det?"

#: ../../Ch08/Ch08_Estimation_4.rst:69 ../../Ch08/Ch08_Estimation_4.rst:265
msgid "Do we know what it is?"
msgstr "Vet vi hva det er?"

#: ../../Ch08/Ch08_Estimation_4.rst:70
msgid "*X̄*"
msgstr "*X̄*"

#: ../../Ch08/Ch08_Estimation_4.rst:71
msgid "Sample mean"
msgstr "Gjennomsnittlig utvalg"

#: ../../Ch08/Ch08_Estimation_4.rst:72 ../../Ch08/Ch08_Estimation_4.rst:267
#: ../../Ch08/Ch08_Estimation_4.rst:278
msgid "Yes, calculated from the raw data"
msgstr "Ja, beregnet fra rådataene"

#: ../../Ch08/Ch08_Estimation_4.rst:73
msgid "µ"
msgstr "µ"

#: ../../Ch08/Ch08_Estimation_4.rst:74
msgid "True population mean"
msgstr "Populasjonens sanne gjennomsnitt"

#: ../../Ch08/Ch08_Estimation_4.rst:75 ../../Ch08/Ch08_Estimation_4.rst:270
#: ../../Ch08/Ch08_Estimation_4.rst:281
msgid "Almost never known for sure"
msgstr "Det vet man nesten aldri med sikkerhet"

#: ../../Ch08/Ch08_Estimation_4.rst:76
msgid ":math:`\\hat{\\mu}`"
msgstr ":math:`\\hat{\\mu}`"

#: ../../Ch08/Ch08_Estimation_4.rst:77
msgid "Estimate of the population mean"
msgstr "Estimat av populasjonsgjennomsnittet"

#: ../../Ch08/Ch08_Estimation_4.rst:78
msgid "Yes, identical to the sample mean in simple random samples"
msgstr "Ja, identisk med gjennomsnittet i enkle tilfeldige utvalg"

#: ../../Ch08/Ch08_Estimation_4.rst:82
msgid "Estimating the population standard deviation"
msgstr "Estimering av standardavviket i populasjonen"

#: ../../Ch08/Ch08_Estimation_4.rst:84
msgid ""
"So far, estimation seems pretty simple, and you might be wondering why I "
"forced you to read through all that stuff about sampling theory. In the case "
"of the mean our estimate of the population parameter (i.e. :math:"
"`\\hat\\mu`) turned out to be identical to the corresponding sample "
"statistic (i.e. *X̄*). However, that’s not always true. To see this, let’s "
"have a think about how to construct an **estimate of the population standard "
"deviation**, which we’ll denote :math:`\\hat\\sigma`. What shall we use as "
"our estimate in this case? Your first thought might be that we could do the "
"same thing we did when estimating the mean, and just use the sample "
"statistic as our estimate. That’s almost the right thing to do, but not "
"quite."
msgstr ""
"Så langt virker estimeringen ganske enkel, og du lurer kanskje på hvorfor "
"jeg tvang deg til å lese alt det der om utvalgsteori. I tilfellet med "
"gjennomsnittet viste det seg at estimatet vårt av populasjonsparameteren ("
"dvs. :math:`\\hat\\mu`) var identisk med den tilsvarende utvalgsstatistikken "
"(dvs. *X̄*). Det er imidlertid ikke alltid sant. For å se dette, la oss tenke "
"litt på hvordan vi kan konstruere et **estimat av populasjonens "
"standardavvik**, som vi kaller :math:`\\hat\\sigma`. Hva skal vi bruke som "
"estimat i dette tilfellet? Din første tanke er kanskje at vi kan gjøre det "
"samme som vi gjorde da vi estimerte gjennomsnittet, og bare bruke "
"utvalgsstatistikken som estimat. Det er nesten det riktige å gjøre, men ikke "
"helt."

#: ../../Ch08/Ch08_Estimation_4.rst:95
msgid ""
"Here’s why. Suppose I have a sample that contains a single observation. For "
"this example, it helps to consider a sample where you have no intuitions at "
"all about what the true population values might be, so let’s use something "
"completely fictitious. Suppose the observation in question measures the "
"*cromulence* of my shoes. It turns out that my shoes have a cromulence of "
"20. So here’s my sample:"
msgstr ""
"Her er hvorfor. Anta at jeg har et utvalg som inneholder én enkelt "
"observasjon. I dette eksempelet er det nyttig å tenke seg et utvalg der du "
"ikke har noen som helst intuisjon om hva de sanne populasjonsverdiene kan "
"være, så la oss bruke noe helt fiktivt. Anta at observasjonen måler "
"*kromulensen* til skoene mine. Det viser seg at skoene mine har en kromulens "
"på 20. Så her er utvalget mitt:"

#: ../../Ch08/Ch08_Estimation_4.rst:102
msgid "``20``"
msgstr "``20``"

#: ../../Ch08/Ch08_Estimation_4.rst:104
msgid ""
"This is a perfectly legitimate sample, even if it does have a sample size of "
"*N* = 1. It has a sample mean of 20 and because every observation in this "
"sample is equal to the sample mean (obviously!) it has a sample standard "
"deviation of 0. As a description of the *sample* this seems quite right, the "
"sample contains a single observation and therefore there is no variation "
"observed within the sample. A sample standard deviation of *s* = 0 is the "
"right answer here. But as an estimate of the *population* standard deviation "
"it feels completely insane, right? Admittedly, you and I don’t know anything "
"at all about what “cromulence” is, but we know something about data. The "
"only reason that we don’t see any variability in the *sample* is that the "
"sample is too small to display any variation! So, if you have a sample size "
"of *N* = 1 it *feels* like the right answer is just to say “no idea at all”."
msgstr ""
"Dette er et helt legitimt utvalg, selv om det har en utvalgsstørrelse på *N* "
"= 1. Det har et utvalgsgjennomsnitt på 20, og fordi hver observasjon i dette "
"utvalget er lik utvalgsgjennomsnittet (selvsagt!), har det et "
"utvalgsstandardavvik på 0. Som en beskrivelse av *utvalget* virker dette "
"helt riktig, utvalget inneholder én enkelt observasjon, og det er derfor "
"ingen variasjon i utvalget. Et utvalgsstandardavvik på *s* = 0 er det "
"riktige svaret her. Men som et estimat av *populasjonens* standardavvik "
"føles det helt vanvittig, ikke sant? Du og jeg vet riktignok ikke noe som "
"helst om hva “*cromulence*” er, men vi vet noe om data. Den eneste grunnen "
"til at vi ikke ser noen variasjon i *utvalget*, er at utvalget er for lite "
"til å vise noen variasjon! Så hvis du har en utvalgsstørrelse på *N* = 1, "
"føles det som om det riktige svaret er å si «ingen anelse i det hele tatt»."

#: ../../Ch08/Ch08_Estimation_4.rst:118
msgid ""
"Notice that you *don’t* have the same intuition when it comes to the sample "
"mean and the population mean. If forced to make a best guess about the "
"population mean it doesn’t feel completely insane to guess that the "
"population mean is 20. Sure, you probably wouldn’t feel very confident in "
"that guess because you have only the one observation to work with, but it’s "
"still the best guess you can make."
msgstr ""
"Legg merke til at du *ikke* har samme intuisjon når det gjelder "
"utvalgsgjennomsnittet og populasjonsgjennomsnittet. Hvis du blir tvunget til "
"å gjette på populasjonsgjennomsnittet, føles det ikke helt galskap å gjette "
"at populasjonsgjennomsnittet er 20. Riktignok ville du sannsynligvis ikke "
"føle deg veldig sikker på den gjetningen fordi du bare har én observasjon å "
"jobbe med, men det er likevel den beste gjetningen du kan gjøre."

#: ../../Ch08/Ch08_Estimation_4.rst:125
msgid ""
"Let’s extend this example a little. Suppose I now make a second observation. "
"My data set now has *N* = 2 observations of the cromulence of shoes, and the "
"complete sample now looks like this:"
msgstr ""
"La oss utvide dette eksempelet litt. Anta at jeg nå gjør en ny observasjon. "
"Datasettet mitt har nå *N* = 2 observasjoner av skokromulansen, og det "
"komplette utvalget ser nå slik ut:"

#: ../../Ch08/Ch08_Estimation_4.rst:129
msgid "``20, 22``"
msgstr "``20, 22``"

#: ../../Ch08/Ch08_Estimation_4.rst:131
msgid ""
"This time around, our sample is *just* large enough for us to be able to "
"observe some variability: two observations is the bare minimum number needed "
"for any variability to be observed! For our new data set, the sample mean is "
"*X̄* = 21, and the sample standard deviation is *s* = 1. What intuitions do "
"we have about the population? Again, as far as the population mean goes, the "
"best guess we can possibly make is the sample mean. If forced to guess we’d "
"probably guess that the population mean cromulence is 21. What about the "
"standard deviation? This is a little more complicated. The sample standard "
"deviation is only based on two observations, and if you’re at all like me "
"you probably have the intuition that, with only two observations we haven’t "
"given the population “enough of a chance” to reveal its true variability to "
"us. It’s not just that we suspect that the estimate is *wrong*, after all "
"with only two observations we expect it to be wrong to some degree. The "
"worry is that the error is *systematic*. Specifically, we suspect that the "
"sample standard deviation is likely to be smaller than the population "
"standard deviation."
msgstr ""
"Denne gangen er utvalget vårt *rett og slett* stort nok til at vi kan "
"observere en viss variasjon: To observasjoner er det minste antallet som "
"trengs for at vi skal kunne observere noen variasjon! For det nye datasettet "
"vårt er utvalgsgjennomsnittet *X̄* = 21, og utvalgsstandardavviket er *s* = "
"1. Hvilke intuisjoner har vi om populasjonen? Igjen, når det gjelder "
"populasjonsgjennomsnittet, er utvalgsgjennomsnittet den beste gjetningen vi "
"kan gjøre. Hvis vi blir tvunget til å gjette, vil vi sannsynligvis gjette at "
"populasjonens gjennomsnittskromulens er 21. Hva med standardavviket? Dette "
"er litt mer komplisert. Standardavviket er kun basert på to observasjoner, "
"og hvis du er litt som meg, har du sannsynligvis en intuisjon om at vi med "
"bare to observasjoner ikke har gitt populasjonen «nok muligheter» til å "
"avsløre dens sanne variabilitet for oss. Det er ikke bare det at vi "
"mistenker at estimatet er *feil*, for med bare to observasjoner forventer vi "
"tross alt at det til en viss grad er feil. Bekymringen er at feilen er "
"*systematisk*. Nærmere bestemt mistenker vi at standardavviket i utvalget "
"sannsynligvis er mindre enn standardavviket i populasjonen."

#: ../../Ch08/Ch08_Estimation_4.rst:147
msgid ""
"This intuition feels right, but it would be nice to demonstrate this "
"somehow. There are in fact mathematical proofs that confirm this intuition, "
"but unless you have the right mathematical background they don’t help very "
"much. Instead, what I’ll do is simulate the results of some experiments. "
"With that in mind, let’s return to our IQ studies. Suppose the true "
"population mean IQ is 100 and the standard deviation is 15. First I’ll "
"conduct an experiment in which I measure *N* = 2 IQ scores and I’ll "
"calculate the sample standard deviation. If I do this over and over again, "
"and plot a histogram of these sample standard deviations, what I have is the "
"*sampling distribution of the standard deviation*. I’ve plotted this "
"distribution in :numref:`fig-samplingDistSampleSD`. Even though the true "
"population standard deviation is 15 the average of the *sample* standard "
"deviations is only 8.5. Notice that this is a very different result to what "
"we found in :numref:`fig-samplingDistDiffN` (middle panel) when we plotted "
"the sampling distribution of the mean, where the population mean is 100 and "
"the average of the sample means is also 100."
msgstr ""
"Denne intuisjonen føles riktig, men det hadde vært fint å kunne bevise dette "
"på en eller annen måte. Det finnes faktisk matematiske bevis som bekrefter "
"denne intuisjonen, men med mindre du har den rette matematiske bakgrunnen, "
"hjelper de ikke så mye. I stedet vil jeg simulere resultatene av noen "
"eksperimenter. Med det i bakhodet, la oss gå tilbake til IQ-studiene våre. "
"Anta at den sanne gjennomsnittlige IQ-en i befolkningen er 100 og "
"standardavviket er 15. Først gjennomfører jeg et eksperiment der jeg måler "
"*N* = 2 IQ-skårer og beregner standardavviket i utvalget. Hvis jeg gjør "
"dette om og om igjen, og plotter et histogram over disse "
"utvalgsstandardavvikene, har jeg *utvalgsfordelingen av standardavviket*. "
"Jeg har plottet denne fordelingen i :numref:`fig-samplingDistSampleSD`. Selv "
"om det sanne standardavviket i populasjonen er 15, er gjennomsnittet av "
"standardavvikene i *utvalget* bare 8,5. Legg merke til at dette er et helt "
"annet resultat enn det vi fant i :numref:`fig-samplingDistDiffN` (midtre "
"panel) da vi plottet utvalgsfordelingen av gjennomsnittet, der "
"populasjonsgjennomsnittet er 100 og gjennomsnittet av utvalgsgjennomsnittet "
"også er 100."

#: ../../Ch08/Ch08_Estimation_4.rst:166
msgid "Sampling distrib. of the std. dev. for a “two IQ scores” experiment"
msgstr "Utvalgsfordeling av std. dev. for et eksperiment med «to IQ-scorer»"

#: ../../Ch08/Ch08_Estimation_4.rst:170
msgid ""
"Sampling distribution of the sample standard deviation for a “two IQ scores” "
"experiment. The true population standard deviation is 15 (dashed line), but "
"as you can see from the histogram the vast majority of experiments will "
"produce a much smaller sample standard deviation than this. On average, this "
"experiment would produce a sample standard deviation of only 8.5, well below "
"the true value! In other words, the sample standard deviation is a biased "
"estimate of the population standard deviation."
msgstr ""
"Utvalgsfordeling av standardavviket for et eksperiment med «to IQ-skårer». "
"Det sanne populasjonsstandardavviket er 15 (stiplet linje), men som du kan "
"se av histogrammet, vil de aller fleste eksperimenter gi et mye mindre "
"utvalgsstandardavvik enn dette. I gjennomsnitt vil dette eksperimentet gi et "
"utvalgsstandardavvik på bare 8,5, altså langt under den sanne verdien! "
"Utvalgsstandardavviket er med andre ord ikke et objektivt estimat av "
"populasjonsstandardavviket."

#: ../../Ch08/Ch08_Estimation_4.rst:180
msgid ""
"Now let’s extend the simulation. Instead of restricting ourselves to the "
"situation where *N* = 2, let’s repeat the exercise for sample sizes from 1 "
"to 10. If we plot the average sample mean and average sample standard "
"deviation as a function of sample size, you get the results shown in :numref:"
"`fig-biasMeanSD`. On the left hand side I’ve plotted the average sample mean "
"and on the right hand side I’ve plotted the average standard deviation. The "
"two plots are quite different: *on average*, the average sample mean is "
"equal to the population mean. It is an **unbiased estimator**, which is "
"essentially the reason why your best estimate for the population mean is the "
"sample mean.\\ [#]_ The plot on the right is quite different: on average, "
"the sample standard deviation *s* is *smaller* than the population standard "
"deviation σ. It is a **biased estimator**. In other words, if we want to "
"make a “best guess” :math:`\\hat\\sigma` about the value of the population "
"standard deviation σ we should make sure our guess is a little bit larger "
"than the sample standard deviation *s*."
msgstr ""
"La oss nå utvide simuleringen. I stedet for å begrense oss til situasjonen "
"der *N* = 2, kan vi gjenta øvelsen for utvalgsstørrelser fra 1 til 10. Hvis "
"vi plotter det gjennomsnittlige utvalgsgjennomsnittet og det "
"gjennomsnittlige standardavviket som en funksjon av utvalgsstørrelsen, får "
"du resultatene som vises i :numref:`fig-biasMeanSD`. På venstre side har jeg "
"plottet det gjennomsnittlige utvalgsgjennomsnittet, og på høyre side har jeg "
"plottet det gjennomsnittlige standardavviket. De to plottene er ganske "
"forskjellige: *I gjennomsnitt* er det gjennomsnittlige utvalgsgjennomsnittet "
"lik populasjonsgjennomsnittet. Det er en **objektiv estimator** (*unbiased*)"
", noe som egentlig er grunnen til at det beste estimatet for "
"populasjonsgjennomsnittet er gjennomsnittet i stikkprøven.\\ [#]_ Plottet "
"til høyre er helt annerledes: I gjennomsnitt er standardavviket i "
"stikkprøven *s* *mindre* enn populasjonsstandardavviket σ. Det **ikke** er "
"en **objektiv estimator** (*biased*). Med andre ord, hvis vi ønsker å gjøre "
"en «best mulig gjetning» :math:`\\hat\\sigma` om verdien av "
"populasjonsstandardavviket σ, bør vi sørge for at gjetningen vår er litt "
"større enn utvalgsstandardavviket *s*."

#: ../../Ch08/Ch08_Estimation_4.rst:198
msgid "Sample size: Mean (un-biased) and standard deviation (biased)"
msgstr ""
"Utvalgsstørrelse: Gjennomsnitt (objektiv) og standardavvik (ikke objektiv)"

#: ../../Ch08/Ch08_Estimation_4.rst:202
msgid ""
"Illustration of the fact that the sample mean is an unbiased estimator of "
"the population mean (left panel), but the sample standard deviation is a "
"biased estimator of the population standard deviation (right panel). For the "
"figure, I generated 10,000 simulated data sets with 1 observation each, "
"10,000 more with 2 observations, and so on up to a sample size of 10. Each "
"data set consisted of fake IQ data, that is the data were normally "
"distributed with a true population mean of 100 and standard deviation 15. On "
"average, the sample means turn out to be 100, regardless of sample size "
"(left panel). However, the sample standard deviations turn out to be "
"systematically too small (right panel), especially for small sample sizes."
msgstr ""
"Illustrasjon av det faktum at utvalgsgjennomsnittet er en objektiv estimator "
"av populasjonsgjennomsnittet (venstre panel), men at utvalgsstandardavviket "
"ikke er en objektiv estimator av populasjonsstandardavviket (høyre panel). "
"Til figuren genererte jeg 10 000 simulerte datasett med 1 observasjon hver, "
"10 000 flere med 2 observasjoner, og så videre opp til en utvalgsstørrelse "
"på 10. Hvert datasett besto av falske IQ-data, det vil si at dataene var "
"normalfordelte med et sant populasjonsgjennomsnitt på 100 og et "
"standardavvik på 15. I gjennomsnitt viser utvalgsgjennomsnittet seg å være "
"100, uavhengig av utvalgsstørrelse (venstre panel). Standardavvikene i "
"utvalget viser seg imidlertid å være systematisk for små (høyre panel), "
"spesielt for små utvalgsstørrelser."

#: ../../Ch08/Ch08_Estimation_4.rst:215
msgid ""
"The fix to this systematic bias turns out to be very simple. Here’s how it "
"works. Before tackling the standard deviation let’s look at the variance. If "
"you recall from :doc:`../Ch04/Ch04_Descriptives_2`, the sample variance is "
"defined to be the average of the squared deviations from the sample mean. "
"That is:"
msgstr ""
"Løsningen på denne systematiske skjevheten viser seg å være svært "
"enkel. Her er hvordan den fungerer. Før vi tar for oss standardavviket, la "
"oss se på variansen. Hvis du husker fra :doc:`../Ch04/Ch04_Descriptives_2`, "
"er utvalgets varians definert som gjennomsnittet av de kvadrerte avvikene "
"fra utvalgsgjennomsnittet. Det vil si at:"

#: ../../Ch08/Ch08_Estimation_4.rst:221
msgid ""
"s^2 = \\frac{1}{N} \\sum_{i=1}^N (X_i - \\bar{X})^2\n"
"\n"
msgstr ""
"s^2 = \\frac{1}{N} \\sum_{i=1}^N (X_i - \\bar{X})^2\n"
"\n"

#: ../../Ch08/Ch08_Estimation_4.rst:223
msgid ""
"The sample variance *s*\\² is a biased estimator of the population variance "
"σ². But as it turns out, we only need to make a tiny tweak to transform this "
"into an unbiased estimator. All we have to do is divide by *N* - 1 rather "
"than by *N*. If we do that, we obtain the following formula:"
msgstr ""
"Utvalgsvariansen *s*\\² ikke er en objektiv estimator av "
"populasjonsvariansen σ². Men det viser seg at vi bare trenger å gjøre en "
"liten justering for å gjøre dette om til en objektiv estimator. Alt vi "
"trenger å gjøre, er å dividere med *N* - 1 i stedet for med *N*. Hvis vi "
"gjør det, får vi følgende formel:"

#: ../../Ch08/Ch08_Estimation_4.rst:228
msgid ""
"\\hat\\sigma^2 = \\frac{1}{N-1} \\sum_{i=1}^N (X_i - \\bar{X})^2\n"
"\n"
msgstr ""
"\\hat\\sigma^2 = \\frac{1}{N-1} \\sum_{i=1}^N (X_i - \\bar{X})^2\n"
"\n"

#: ../../Ch08/Ch08_Estimation_4.rst:230
msgid ""
"This is an unbiased estimator of the population variance σ². Moreover, this "
"finally answers the question we raised in :doc:`../Ch04/"
"Ch04_Descriptives_2`. Why did jamovi give us slightly different answers for "
"variance? It’s because jamovi calculates :math:`\\hat\\sigma^2` not *s*\\², "
"that’s why. A similar story applies for the standard deviation. If we divide "
"by *N* - 1 rather than *N* our estimate of the population standard deviation "
"becomes:"
msgstr ""
"Dette er en objektiv estimator av populasjonsvariansen σ². Dessuten gir "
"dette endelig svar på spørsmålet vi reiste i :doc:`../Ch04/"
"Ch04_Descriptives_2`. Hvorfor ga jamovi oss litt forskjellige svar for "
"variansen? Det er fordi jamovi beregner :math:`\\hat\\sigma^2` og ikke *s*\\²"
", det er grunnen. En lignende historie gjelder for standardavviket. Hvis vi "
"dividerer med *N* - 1 i stedet for *N*, blir vårt estimat av standardavviket "
"i populasjonen:"

#: ../../Ch08/Ch08_Estimation_4.rst:237
msgid ""
"\\hat\\sigma = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (X_i - \\bar{X})^2}\n"
"\n"
msgstr ""
"\\hat\\sigma = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (X_i - \\bar{X})^2}\n"
"\n"

#: ../../Ch08/Ch08_Estimation_4.rst:239
msgid ""
"and when we use jamovi’s built in standard deviation function, what it’s "
"doing is calculating :math:`\\hat\\sigma`, not *s*.\\ [#]_"
msgstr ""
"og når vi bruker jamovis innebygde standardavviksfunksjon, beregner den "
":math:`\\hat\\sigma`, ikke *s*.\\ [#]_"

#: ../../Ch08/Ch08_Estimation_4.rst:242
msgid ""
"One final point. In practice, a lot of people tend to refer to :math:"
"`\\hat{\\sigma}` (i.e., the formula where we divide by *N* - 1) as the "
"*sample* standard deviation. Technically, this is incorrect. The *sample* "
"standard deviation should be equal to *s* (i.e., the formula where we divide "
"by *N*). These aren’t the same thing, either conceptually or numerically. "
"One is a property of the sample, the other is an estimated characteristic of "
"the population. However, in almost every real life application what we "
"actually care about is the estimate of the population parameter, and so "
"people always report :math:`\\hat\\sigma` rather than *s*. This is the right "
"number to report, of course. It’s just that people tend to get a little bit "
"imprecise about terminology when they write it up, because “sample standard "
"deviation” is shorter than “estimated population standard deviation”. It’s "
"no big deal, and in practice I do the same thing everyone else does. "
"Nevertheless, I think it’s important to keep the two *concepts* separate. "
"It’s never a good idea to confuse “known properties of your sample” with "
"“guesses about the population from which it came”. The moment you start "
"thinking that *s* and :math:`\\hat\\sigma` are the same thing, you start "
"doing exactly that."
msgstr ""
"Et siste poeng. I praksis har mange en tendens til å referere til :math:`"
"\\hat{\\sigma}` (dvs. formelen der vi dividerer med *N* - 1) som "
"*utvalgsstandardavviket*. Teknisk sett er dette feil. Standardavviket for "
"*utvalget* skal være lik *s* (dvs. formelen der vi dividerer med *N*). Dette "
"er ikke det samme, verken konseptuelt eller numerisk. Det ene er en egenskap "
"ved utvalget, det andre er en estimert egenskap ved populasjonen. Men i "
"nesten alle virkelige anvendelser er det estimatet av populasjonsparameteren "
"vi er interessert i, og derfor rapporterer folk alltid :math:`\\hat\\sigma` "
"i stedet for *s*. Dette er selvfølgelig det riktige tallet å rapportere. Det "
"er bare det at folk har en tendens til å bli litt upresise med terminologien "
"når de skriver det opp, fordi «utvalgsstandardavvik» er kortere enn «"
"estimert populasjonsstandardavvik». Det er ikke så farlig, og i praksis gjør "
"jeg det samme som alle andre. Likevel synes jeg det er viktig å holde de to "
"*begrepene* adskilt. Det er aldri lurt å blande sammen «kjente egenskaper "
"ved utvalget ditt» med «gjetninger om populasjonen det kommer fra». I det "
"øyeblikket du begynner å tro at *s* og :math:`\\hat\\sigma` er det samme, "
"begynner du å gjøre akkurat det."

#: ../../Ch08/Ch08_Estimation_4.rst:261
msgid ""
"To finish this section off, here’s another couple of tables to help keep "
"things clear."
msgstr ""
"For å avslutte denne delen, her er et par tabeller til for å gjøre det hele "
"mer oversiktlig."

#: ../../Ch08/Ch08_Estimation_4.rst:267
msgid "*s*"
msgstr "*s*"

#: ../../Ch08/Ch08_Estimation_4.rst:267
msgid "Sample standard deviation"
msgstr "Standardavvik for utvalget"

#: ../../Ch08/Ch08_Estimation_4.rst:270
msgid "σ"
msgstr "σ"

#: ../../Ch08/Ch08_Estimation_4.rst:270
msgid "Population standard deviation"
msgstr "Standardavvik i populasjonen"

#: ../../Ch08/Ch08_Estimation_4.rst:273
msgid ":math:`\\hat{\\sigma}`"
msgstr ":math:`\\hat{\\sigma}`"

#: ../../Ch08/Ch08_Estimation_4.rst:273
msgid "Estimate of the population standard deviation"
msgstr "Estimat av standardavviket i populasjonen"

#: ../../Ch08/Ch08_Estimation_4.rst:273
msgid "Yes, but not the same as the sample standard deviation"
msgstr "Ja, men ikke det samme som standardavviket i utvalget"

#: ../../Ch08/Ch08_Estimation_4.rst:278
msgid "*s*\\²"
msgstr "*s*\\²"

#: ../../Ch08/Ch08_Estimation_4.rst:278
msgid "Sample variance"
msgstr "Eksempel på varians"

#: ../../Ch08/Ch08_Estimation_4.rst:281
msgid "σ²"
msgstr "σ²"

#: ../../Ch08/Ch08_Estimation_4.rst:281
msgid "Population variance"
msgstr "Populasjonsvarians"

#: ../../Ch08/Ch08_Estimation_4.rst:284
msgid ":math:`\\hat{\\sigma}^2`"
msgstr ":math:`\\hat{\\sigma}^2`"

#: ../../Ch08/Ch08_Estimation_4.rst:284
msgid "Estimate of the population variance"
msgstr "Estimat av populasjonsvariansen"

#: ../../Ch08/Ch08_Estimation_4.rst:284
msgid "Yes, but not the same as the sample variance"
msgstr "Ja, men ikke det samme som utvalgsvariansen"

#: ../../Ch08/Ch08_Estimation_4.rst:291
msgid ""
"Please note that if you were *actually* interested in this question you "
"would need to be a *lot* more careful than I’m being here. You *can’t* just "
"compare IQ scores in Whyalla to Port Pirie and assume that any differences "
"are due to lead poisoning. Even if it were true that the only differences "
"between the two towns corresponded to the different refineries (and it "
"isn’t, not by a long shot), you need to account for the fact that people "
"already *believe* that lead pollution causes cognitive deficits. If you "
"recall back to chapter :doc:`../Ch02/Ch02_StudyDesign`, this means that "
"there are different demand effects for the Port Pirie sample than for the "
"Whyalla sample. In other words, you might end up with an illusory group "
"difference in your data, caused by the fact that people *think* that there "
"is a real difference. I find it pretty implausible to think that the locals "
"wouldn’t be well aware of what you were trying to do if a bunch of "
"researchers turned up in Port Pirie with lab coats and IQ tests, and even "
"less plausible to think that a lot of people would be pretty resentful of "
"you for doing it. Those people won’t be as co-operative in the tests. Other "
"people in Port Pirie might be *more* motivated to do well because they don’t "
"want their home town to look bad. The motivational effects that would apply "
"in Whyalla are likely to be weaker, because people don’t have any concept of "
"“iron ore poisoning” in the same way that they have a concept for “lead "
"poisoning”. Psychology is *hard*."
msgstr ""
"Vær oppmerksom på at hvis du var * faktisk * interessert i dette spørsmålet, "
"måtte du være * mye * mer forsiktig enn jeg er her. Du *kan* ikke bare "
"sammenligne IQ-skårer i Whyalla med Port Pirie og anta at eventuelle "
"forskjeller skyldes blyforgiftning. Selv om det skulle være sant at de "
"eneste forskjellene mellom de to byene skyldtes de ulike raffineriene (og "
"det er det ikke, langt ifra), må du ta hensyn til at folk allerede *tror* at "
"blyforurensning forårsaker kognitive underskudd. Hvis du husker tilbake til "
"kapittel :doc:`../Ch02/Ch02_StudyDesign`, betyr dette at det er forskjellige "
"*demand effects* for Port Pirie-utvalget enn for Whyalla-utvalget. Med "
"andre ord kan du ende opp med en illusorisk gruppeforskjell i dataene dine, "
"forårsaket av at folk *tror* at det er en reell forskjell. Jeg synes det er "
"ganske usannsynlig å tro at lokalbefolkningen ikke ville være klar over hva "
"du prøvde å gjøre hvis en gjeng forskere dukket opp i Port Pirie med "
"laboratoriefrakker og IQ-tester, og enda mindre sannsynlig å tro at mange "
"ville være ganske misfornøyde med at du gjorde det. Disse menneskene vil "
"ikke være like samarbeidsvillige i testene. Andre mennesker i Port Pirie kan "
"være *mer* motiverte til å gjøre det bra fordi de ikke vil at hjembyen deres "
"skal se dårlig ut. Motivasjonseffektene som vil gjelde i Whyalla, vil "
"sannsynligvis være svakere, fordi folk ikke har noe begrep om "
"«jernmalmforgiftning» på samme måte som de har et begrep om «blyforgiftning»"
". Psykologi er *vanskelig*."

#: ../../Ch08/Ch08_Estimation_4.rst:314
msgid ""
"I should note that I’m hiding something here. Unbiasedness is a desirable "
"characteristic for an estimator, but there are other things that matter "
"besides bias. However, it’s beyond the scope of this book to discuss this in "
"any detail. I just want to draw your attention to the fact that there’s some "
"hidden complexity here."
msgstr ""
"Jeg bør merke meg at jeg skjuler noe her. Objektivitet er en ønskelig "
"egenskap for en estimator, men det er andre ting som betyr noe i tillegg til "
"objektivitet. Det ligger imidlertid utenfor denne bokens rammer å diskutere "
"dette i detalj. Jeg vil bare gjøre deg oppmerksom på at det er noe skjult "
"kompleksitet her."

#: ../../Ch08/Ch08_Estimation_4.rst:321
msgid ""
"Okay, I’m hiding something else here. In a bizarre and counter-intuitive "
"twist, since :math:`\\hat\\sigma^2` is an unbiased estimator of σ², you’d "
"assume that taking the square root would be fine and :math:`\\hat\\sigma` "
"would be an unbiased estimator of σ. Right? Weirdly, it’s not. There’s "
"actually a subtle, tiny bias in :math:`\\hat\\sigma`. This is just bizarre: :"
"math:`\\hat\\sigma^2` is an unbiased estimate of the population variance σ², "
"but when you take the square root, it turns out that :math:`\\hat\\sigma` is "
"a biased estimator of the population standard deviation σ. Weird, weird, "
"weird, right? So, why is :math:`\\hat\\sigma` biased? The technical answer "
"is “because non-linear transformations (e.g., the square root) don’t commute "
"with expectation”, but that just sounds like gibberish to everyone who "
"hasn’t taken a course in mathematical statistics. Fortunately, it doesn’t "
"matter for practical purposes. The bias is small, and in real life everyone "
"uses :math:`\\hat\\sigma` and it works just fine. Sometimes mathematics is "
"just annoying."
msgstr ""
"Jeg skjuler noe annet her. Siden :math:`\\hat\\sigma^2` er en objektiv "
"estimator av σ², skulle man anta at det er greit å ta kvadratroten, og at "
":math:`\\hat\\sigma` ville være en objektiv estimator av σ. Ikke sant? "
"Merkelig nok er det ikke det. Det er faktisk en subtil, liten skjevhet "
"i :math:`\\hat\\sigma`. Dette er helt bisart: :math:`\\hat\\sigma^2`"
" er et objektiv estimat av populasjonsvariansen σ², men når du tar "
"kvadratroten, viser det seg at :math:`\\hat\\sigma` ikke er en objektiv "
"estimator av populasjonsstandardavviket σ. Merkelig, ikke sant? Så hvorfor "
"er :math:`\\hat\\sigma` ikke objektiv? Det tekniske svaret er «fordi ikke-"
"lineære transformasjoner (f.eks. kvadratroten) kan endre verdiene i strid "
"med forventningen», men det høres bare ut som tullprat for alle som ikke har "
"tatt et kurs i matematisk statistikk. Heldigvis spiller det ingen rolle for "
"praktiske formål. Skjevheten er liten, og i det virkelige liv bruker alle "
":math:`\\hat\\sigma`, og det fungerer helt fint. Noen ganger er matematikk "
"bare irriterende."

#: ../../Ch08/Ch08_Estimation_5.rst:4
msgid "Estimating a confidence interval"
msgstr "Estimering av et konfidensintervall"

#: ../../Ch08/Ch08_Estimation_5.rst:0
msgid "*Statistics means never having to say you’re certain*"
msgstr "*Statistikk betyr at du aldri trenger å si at du er sikker*"

#: ../../Ch08/Ch08_Estimation_5.rst:10
msgid "Unknown origin\\ [#]_"
msgstr "Ukjent opprinnelse\\ [#]_"

#: ../../Ch08/Ch08_Estimation_5.rst:12
msgid ""
"Up to this point in this chapter, I’ve outlined the basics of sampling "
"theory which statisticians rely on to make guesses about population "
"parameters on the basis of a sample of data. As this discussion illustrates, "
"one of the reasons we need all this sampling theory is that every data set "
"leaves us with a some of uncertainty, so our estimates are never going to be "
"perfectly accurate. The thing that has been missing from this discussion is "
"an attempt to *quantify* the amount of uncertainty that attaches to our "
"estimate. It’s not enough to be able guess that, say, the mean IQ of "
"undergraduate psychology students is 115 (yes, I just made that number up). "
"We also want to be able to say something that expresses the degree of "
"certainty that we have in our guess. For example, it would be nice to be "
"able to say that there is a 95\\% chance that the true mean lies between 109 "
"and 121. The name for this is a **confidence interval** for the mean."
msgstr ""
"Så langt i dette kapittelet har jeg skissert det grunnleggende om "
"utvalgsteori, som statistikere bruker for å gjøre gjetninger om "
"populasjonsparametere på grunnlag av et utvalg av data. Som denne "
"diskusjonen illustrerer, er en av grunnene til at vi trenger all denne "
"utvalgsteorien, at alle datasett etterlater oss med en viss usikkerhet, slik "
"at estimatene våre aldri kommer til å være helt nøyaktige. Det som har "
"manglet i denne diskusjonen, er et forsøk på å *kvantifisere* hvor stor "
"usikkerhet som er knyttet til estimatet vårt. Det er ikke nok å kunne gjette "
"at, la oss si, den gjennomsnittlige IQ-en til psykologistudenter er 115 (ja, "
"det tallet fant jeg nettopp på). Vi ønsker også å kunne si noe som uttrykker "
"graden av sikkerhet vi har i gjetningen vår. Det ville for eksempel være "
"fint å kunne si at det er 95\\% sjanse for at det sanne gjennomsnittet "
"ligger mellom 109 og 121. Dette kalles et **konfidensintervall** for "
"gjennomsnittet."

#: ../../Ch08/Ch08_Estimation_5.rst:26
msgid ""
"Armed with an understanding of sampling distributions, constructing a "
"confidence interval for the mean is actually pretty easy. Here’s how it "
"works. Suppose the true population mean is µ and the standard deviation is "
"σ. I’ve just finished running my study that has *N* participants, and the "
"mean IQ among those participants is *X̄*. We know from our discussion of :ref:"
"`the central limit theorem <central_limit_theorem>` that the sampling "
"distribution of the mean is approximately normal. We also know from our "
"discussion of the :doc:`normal distribution <../Ch07/Ch07_Probability_5>`, "
"that there is a 95\\% chance that a normally-distributed quantity will fall "
"within about two standard deviations of the true mean."
msgstr ""
"Med en forståelse av utvalgsfordelinger er det faktisk ganske enkelt å "
"konstruere et konfidensintervall for gjennomsnittet. Dette er hvordan det "
"fungerer. Anta at det sanne populasjonsgjennomsnittet er µ og "
"standardavviket er σ. Jeg har nettopp avsluttet studien min som har *N* "
"deltakere, og gjennomsnittlig IQ blant disse deltakerne er *X̄*. Vi vet fra "
"vår diskusjon av :ref:`det sentrale grenseteoremet <central_limit_theorem>` "
"at utvalgsfordelingen av gjennomsnittet er tilnærmet normalfordelt. Vi vet "
"også fra vår diskusjon av :doc:`normalfordelingen <../Ch07/"
"Ch07_Probability_5>`, at det er 95\\% sjanse for at en normalfordelt "
"størrelse vil ligge innenfor omtrent to standardavvik fra det sanne "
"gjennomsnittet."

#: ../../Ch08/Ch08_Estimation_5.rst:37
msgid ""
"To be more precise, the more correct answer is that there is a 95\\% chance "
"that a normally-distributed quantity will fall within 1.96 standard "
"deviations of the true mean. Next, recall that the standard deviation of the "
"sampling distribution is referred to as the standard error, and the standard "
"error of the mean is written as SEM. When we put all these pieces together, "
"we learn that there is a 95\\% probability that the sample mean *X̄* that we "
"have actually observed lies within 1.96 standard errors of the population "
"mean."
msgstr ""
"For å være mer presis, er det mer korrekte svaret at det er 95\\% sjanse for "
"at en normalfordelt størrelse vil falle innenfor 1,96 standardavvik fra det "
"sanne gjennomsnittet. Husk deretter at standardavviket til "
"utvalgsfordelingen kalles standardfeilen, og standardfeilen til "
"gjennomsnittet skrives SEM. Når vi setter sammen alle disse bitene, finner "
"vi ut at det er 95\\% sannsynlighet for at utvalgsgjennomsnittet *X̄* som vi "
"faktisk har observert, ligger innenfor 1,96 standardfeil fra "
"populasjonsgjennomsnittet."

#: ../../Ch08/Ch08_Estimation_5.rst:45
msgid "Mathematically, we write this as:"
msgstr "Matematisk skriver vi dette som:"

#: ../../Ch08/Ch08_Estimation_5.rst:47
msgid "µ – 1.96 × SEM ≤ *X̄* ≤ µ + (1.96 × SEM)"
msgstr "µ – 1.96 × SEM ≤ *X̄* ≤ µ + (1.96 × SEM)"

#: ../../Ch08/Ch08_Estimation_5.rst:49
msgid ""
"where the SEM is equal to :math:`\\sigma / \\sqrt{N}` and we can be 95\\% "
"confident that this is true. However, that’s not answering the question that "
"we’re actually interested in. The equation above tells us what we should "
"expect about the sample mean given that we know what the population "
"parameters are. What we *want* is to have this work the other way around. We "
"want to know what we should believe about the population parameters, given "
"that we have observed a particular sample. However, it’s not too difficult "
"to do this. Using a little high school algebra, a sneaky way to rewrite our "
"equation is like this:"
msgstr ""
"der SEM er lik :math:`\\sigma / \\sqrt{N}`, og vi kan være 95\\% sikre på at "
"dette er sant. Det er imidlertid ikke svaret på spørsmålet vi egentlig er "
"interessert i. Ligningen ovenfor forteller oss hva vi kan forvente om "
"utvalgsgjennomsnittet gitt at vi vet hva populasjonsparametrene er. Det vi "
"*ønsker* er å få dette til å fungere omvendt. Vi ønsker å vite hva vi bør "
"tro om populasjonsparametrene, gitt at vi har observert et bestemt utvalg. "
"Det er imidlertid ikke så vanskelig å gjøre dette. Ved hjelp av litt algebra "
"fra videregående skole kan vi omskrive ligningen vår på en snedig måte:"

#: ../../Ch08/Ch08_Estimation_5.rst:58
msgid "*X̄* − (1.96 × SEM) ≤ µ ≤ *X̄* + (1.96 × SEM)"
msgstr "*X̄* - (1,96 × SEM) ≤ µ ≤ *X̄* + (1,96 × SEM)"

#: ../../Ch08/Ch08_Estimation_5.rst:60
msgid ""
"What this is telling is is that the range of values has a 95\\% probability "
"of containing the population mean µ. We refer to this range as a **95\\% "
"confidence interval**, denoted *CI*\\ :sub:`95`\\ . In short, as long as *N* "
"is sufficiently large (large enough for us to believe that the sampling "
"distribution of the mean is normal), then we can write this as our formula "
"for the 95\\% confidence interval:"
msgstr ""
"Det dette forteller oss, er at det er 95\\% sannsynlighet for at "
"verdiintervallet inneholder populasjonsgjennomsnittet µ. Vi kaller dette "
"intervallet et **95\\%-konfidensintervall**, med betegnelsen *KI*\\ :sub:`95`"
" (eller: *CI*\\ :sub:`95`\\). Kort sagt, så lenge *N* er tilstrekkelig stor ("
"stor nok til at vi tror at utvalgsfordelingen til gjennomsnittet er "
"normalfordelt), kan vi skrive dette som vår formel for 95\\"
"%-konfidensintervall:"

#: ../../Ch08/Ch08_Estimation_5.rst:67
msgid ""
"\\mbox{CI}_{95} = \\bar{X} \\pm \\left( 1.96 \\times \\frac{\\sigma}"
"{\\sqrt{N}} \\right)\n"
"\n"
msgstr ""
"\\mbox{CI}_{95} = \\bar{X} \\pm \\left( 1.96 \\times \\frac{\\sigma}{\\sqrt"
"{N}} \\right)\n"
"\n"

#: ../../Ch08/Ch08_Estimation_5.rst:69
msgid ""
"Of course, there’s nothing special about the number 1.96. It just happens to "
"be the multiplier you need to use if you want a 95\\% confidence interval. "
"If I’d wanted a 70\\% confidence interval, I would have used 1.04 as the "
"magic number rather than 1.96."
msgstr ""
"Tallet 1,96 er selvsagt ikke noe spesielt. Det er bare tilfeldigvis "
"multiplikatoren du må bruke hvis du vil ha et 95\\%-konfidensintervall. Hvis "
"jeg hadde ønsket et 70\\%-konfidensintervall, ville jeg ha brukt 1,04 som "
"det magiske tallet i stedet for 1,96."

#: ../../Ch08/Ch08_Estimation_5.rst:75
msgid "A slight mistake in the formula"
msgstr "En liten feil i formelen"

#: ../../Ch08/Ch08_Estimation_5.rst:77
msgid ""
"As usual, I lied. The formula that I’ve given above for the 95\\% confidence "
"interval is approximately correct, but I glossed over an important detail in "
"the discussion. Notice my formula requires you to use the standard error of "
"the mean, *SEM*, which in turn requires you to use the true population "
"standard deviation σ. Yet, in :doc:`Ch08_Estimation_4` I stressed the fact "
"that we don’t actually *know* the true population parameters. Because we "
"don’t know the true value of σ we have to use an estimate of the population "
"standard deviation :math:`\\hat{\\sigma}` instead. This is pretty "
"straightforward to do, but this has the consequence that we need to use the "
"percentiles of the *t*-distribution rather than the normal distribution to "
"calculate our magic number, and the answer depends on the sample size. When "
"*N* is very large, we get pretty much the same value using the *t*-"
"distribution or the normal distribution: 1.96. But when *N* is small we get "
"a much bigger number when we use the *t*-distribution: 2.26."
msgstr ""
"Som vanlig løy jeg. Formelen jeg har gitt ovenfor for 95\\%-"
"konfidensintervall er tilnærmet korrekt, men jeg glemte en viktig detalj i "
"diskusjonen. Legg merke til at formelen min krever at du bruker "
"standardfeilen til gjennomsnittet, *SEM*, som igjen krever at du bruker det "
"sanne populasjonsstandardavviket σ. I :doc:`Ch08_Estimation_4` understreket "
"jeg imidlertid det faktum at vi faktisk ikke *kjenner* de sanne "
"populasjonsparametrene. Fordi vi ikke kjenner den sanne verdien av σ, må vi "
"i stedet bruke et estimat av populasjonsstandardavviket :math:`\\hat{\\sigma"
"}`. Dette er ganske enkelt å gjøre, men konsekvensen er at vi må bruke "
"persentilene i *t*-fordelingen i stedet for normalfordelingen for å beregne "
"det magiske tallet vårt, og svaret avhenger av utvalgsstørrelsen. Når *N* er "
"veldig stort, får vi omtrent samme verdi ved å bruke *t*-fordelingen eller "
"normalfordelingen: 1.96. Men når *N* er liten, får vi et mye større tall når "
"vi bruker *t*-fordelingen: 2,26."

#: ../../Ch08/Ch08_Estimation_5.rst:92
msgid ""
"There’s nothing too mysterious about what’s happening here. Bigger values "
"mean that the confidence interval is wider, indicating that we’re more "
"uncertain about what the true value of µ actually is. When we use the *t*-"
"distribution instead of the normal distribution we get bigger numbers, "
"indicating that we have more uncertainty. And why do we have that extra "
"uncertainty? Well, because our estimate of the population standard "
"deviation :math:`\\hat\\sigma` might be wrong! If it’s wrong, it implies "
"that we’re a bit less sure about what our sampling distribution of the mean "
"actually looks like, and this uncertainty ends up getting reflected in a "
"wider confidence interval."
msgstr ""
"Det er ikke noe mystisk ved det som skjer her. Større verdier betyr at "
"konfidensintervallet er bredere, noe som indikerer at vi er mer usikre på "
"hva den sanne verdien av µ faktisk er. Når vi bruker *t*-fordelingen i "
"stedet for normalfordelingen, får vi større tall, noe som indikerer at vi er "
"mer usikre. Og hvorfor har vi denne ekstra usikkerheten? Jo, fordi estimatet "
"vårt av standardavviket i populasjonen :math:`\\hat\\sigma` kan være feil! "
"Hvis det er feil, betyr det at vi er litt mindre sikre på hvordan "
"utvalgsfordelingen av gjennomsnittet faktisk ser ut, og denne usikkerheten "
"ender opp med å gjenspeiles i et bredere konfidensintervall."

#: ../../Ch08/Ch08_Estimation_5.rst:103
msgid "Interpreting a confidence interval"
msgstr "Tolkning av et konfidensintervall"

#: ../../Ch08/Ch08_Estimation_5.rst:105
msgid ""
"The hardest thing about confidence intervals is understanding what they "
"*mean*. Whenever people first encounter confidence intervals, the first "
"instinct is almost always to say that “there is a 95\\% probability that the "
"true mean lies inside the confidence interval”. It’s simple and it seems to "
"capture the common sense idea of what it means to say that I am “95\\% "
"confident”. Unfortunately, it’s not quite right. The intuitive definition "
"relies very heavily on your own personal *beliefs* about the value of the "
"population mean. I say that I am 95\\% confident because those are my "
"beliefs. In everyday life that’s perfectly okay, but if you remember back "
"to :doc:`../Ch07/Ch07_Probability_2`, you’ll notice that talking about "
"personal belief and confidence is a Bayesian idea. However, confidence "
"intervals are *not* Bayesian tools. Like everything else in this chapter, "
"confidence intervals are *frequentist* tools, and if you are going to use "
"frequentist methods then it’s not appropriate to attach a Bayesian "
"interpretation to them. If you use frequentist methods, you must adopt "
"frequentist interpretations!"
msgstr ""
"Det vanskeligste med konfidensintervaller er å forstå hva de *betyr*. Når "
"folk først støter på konfidensintervaller, er det første instinktet nesten "
"alltid å si at «det er 95\\% sannsynlighet for at det sanne gjennomsnittet "
"ligger innenfor konfidensintervallet». Det er enkelt, og det ser ut til å "
"fange opp den sunne fornuftsoppfatningen av hva det vil si å si at jeg er «"
"95\\% sikker». Dessverre er det ikke helt riktig. Den intuitive definisjonen "
"er svært avhengig av dine egne personlige *oppfatninger* om verdien av "
"populasjonsgjennomsnittet. Jeg sier at jeg er 95\\% sikker fordi det er det "
"jeg tror. I hverdagen er det helt greit, men hvis du husker tilbake til "
":doc:`../Ch07/Ch07_Probability_2`, vil du legge merke til at det å snakke om "
"personlig tro og tillit er en bayesiansk idé. Konfidensintervaller er "
"imidlertid *ikke* bayesianske verktøy. Som alt annet i dette kapitlet er "
"konfidensintervaller *frekventistiske* verktøy, og hvis du skal bruke "
"frekventistiske metoder, er det ikke hensiktsmessig å legge en bayesiansk "
"tolkning til dem. Hvis du bruker frekventistiske metoder, må du bruke "
"frekventistiske tolkninger!"

#: ../../Ch08/Ch08_Estimation_5.rst:121
msgid ""
"Okay, so if that’s not the right answer, what is? Remember what we said "
"about frequentist probability. The only way we are allowed to make "
"“probability statements” is to talk about a sequence of events, and to count "
"up the frequencies of different kinds of events. From that perspective, the "
"nterpretation of a 95\\% confidence interval must have something to do with "
"replication. Specifically, if we replicated the experiment over and over "
"again and computed a 95\\% confidence interval for each replication, then "
"95\\% of those *intervals* would contain the true mean. More generally, 95\\"
"% of all confidence intervals constructed using this procedure should "
"contain the true population mean. This idea is illustrated in :numref:`fig-"
"confIntSmp`, which shows 50 confidence intervals constructed for a “measure "
"10 IQ scores” experiment (top panel) and another 50 confidence intervals for "
"a “measure 25 IQ scores” experiment (bottom panel). A bit fortuitously, "
"across the 100 replications that I simulated, it turned out that exactly 95 "
"of them contained the true mean."
msgstr ""
"Hvis ikke det er det riktige svaret, hva er det da? Husk hva vi sa om "
"frekventistisk sannsynlighet. Den eneste måten vi har lov til å komme med "
"«sannsynlighetsuttalelser» på, er å snakke om en sekvens av hendelser, og å "
"telle opp hyppighetene av ulike typer hendelser. Ut fra dette perspektivet "
"må tolkningen av et 95\\%-konfidensintervall ha noe med replikasjon å gjøre. "
"Hvis vi replikerer eksperimentet om og om igjen og beregner et 95\\% "
"konfidensintervall for hver replikasjon, vil 95\\% av disse *intervallene* "
"inneholde det sanne gjennomsnittet. Mer generelt vil 95\\% av alle "
"konfidensintervallene som er konstruert ved hjelp av denne prosedyren, "
"inneholde det sanne populasjonsgjennomsnittet. Denne ideen er illustrert i "
":numref:`fig-confIntSmp`, som viser 50 konfidensintervaller konstruert for "
"et «mål 10 IQ-skårer»-eksperiment (øverste panel) og ytterligere 50 "
"konfidensintervaller for et «mål 25 IQ-skårer»-eksperiment (nederste panel). "
"Litt tilfeldig viste det seg at nøyaktig 95 av de 100 replikasjonene jeg "
"simulerte, inneholdt det sanne gjennomsnittet."

#: ../../Ch08/Ch08_Estimation_5.rst:138
msgid "Confidence intervals for IQ-samples with N=10 (top) and N=25 (bottom)"
msgstr "Konfidensintervaller for IQ-utvalg med N=10 (øverst) og N=25 (nederst)"

#: ../../Ch08/Ch08_Estimation_5.rst:142
msgid ""
"95\\% confidence intervals. The top panel shows 50 simulated replications of "
"an experiment in which we measure the IQs of 10 people. The dot marks the "
"location of the sample mean and the line shows the 95\\% confidence "
"interval. In total 47 of the 50 confidence intervals do contain the true "
"mean (i.e., 100), but the three intervals marked with asterisks do not. The "
"bottom panel shows a similar simulation, but this time, we simulate "
"replications of an experiment that measures the IQs of 25 people."
msgstr ""
"95\\%-konfidensintervall. Det øverste panelet viser 50 simulerte "
"replikasjoner av et eksperiment der vi måler IQ-en til 10 personer. Prikken "
"markerer plasseringen av utvalgsgjennomsnittet, og linjen viser 95\\% "
"konfidensintervallet. Totalt 47 av de 50 konfidensintervallene inneholder "
"det sanne gjennomsnittet (dvs. 100), men de tre intervallene som er markert "
"med stjerner, gjør ikke det. Det nederste panelet viser en lignende "
"simulering, men denne gangen simulerer vi replikasjoner av et eksperiment "
"som måler IQ-en til 25 personer."

#: ../../Ch08/Ch08_Estimation_5.rst:152
msgid ""
"The critical difference here is that the Bayesian claim makes a probability "
"statement about the population mean (i.e., it refers to our uncertainty "
"about the population mean), which is not allowed under the frequentist "
"interpretation of probability because you can’t “replicate” a population! In "
"the frequentist claim, the population mean is fixed and no probabilistic "
"claims can be made about it. Confidence intervals, however, are repeatable "
"so we can replicate experiments. Therefore a frequentist is allowed to talk "
"about the probability that the *confidence interval* (a random variable) "
"contains the true mean, but is not allowed to talk about the probability "
"that the *true population mean* (not a repeatable event) falls within the "
"confidence interval."
msgstr ""
"Den avgjørende forskjellen her er at den bayesianske påstanden fremsetter en "
"sannsynlighetspåstand om populasjonsgjennomsnittet (dvs. at den refererer "
"til vår usikkerhet om populasjonsgjennomsnittet), noe som ikke er tillatt "
"under den frekventistiske tolkningen av sannsynlighet, fordi man ikke kan "
"«replisere» en populasjon! I den frekventistiske påstanden er "
"populasjonsgjennomsnittet fast, og man kan ikke si noe probabilistisk om "
"det. Konfidensintervallene er imidlertid repeterbare, så vi kan gjenta "
"eksperimenter. Derfor har en frekventist lov til å snakke om sannsynligheten "
"for at *konfidensintervallet* (en tilfeldig variabel) inneholder det sanne "
"gjennomsnittet, men har ikke lov til å snakke om sannsynligheten for at det *"
"sanne populasjonsgjennomsnittet* (ikke en repeterbar hendelse) faller "
"innenfor konfidensintervallet."

#: ../../Ch08/Ch08_Estimation_5.rst:163
msgid ""
"I know that this seems a little pedantic, but it does matter. It matters "
"because the difference in interpretation leads to a difference in the "
"mathematics. There is a Bayesian alternative to confidence intervals, known "
"as *credible intervals*. In most situations credible intervals are quite "
"similar to confidence intervals, but in other cases they are drastically "
"different. As promised, though, I’ll talk more about the Bayesian "
"perspective in chapter :doc:`../Ch16/Ch16_Bayes`."
msgstr ""
"Jeg vet at dette virker litt pedantisk, men det har noe å si. Det er viktig "
"fordi forskjellen i tolkning fører til en forskjell i matematikken. Det "
"finnes et bayesiansk alternativ til konfidensintervaller, kalt *troverdige "
"intervaller*. I de fleste situasjoner er troverdige intervaller ganske like "
"konfidensintervallene, men i andre tilfeller er de drastisk forskjellige. "
"Som lovet skal jeg imidlertid snakke mer om det bayesianske perspektivet i "
"kapittel :doc:`../Ch16/Ch16_Bayes`."

#: ../../Ch08/Ch08_Estimation_5.rst:172
msgid "Calculating confidence intervals in jamovi"
msgstr "Beregning av konfidensintervaller i jamovi"

#: ../../Ch08/Ch08_Estimation_5.rst:174
msgid ""
"jamovi provides a simple way to calculate confidence intervals for the mean "
"as part of the functionality of ``Descriptives``. Just set the check box "
"``Confidence interval for Mean``."
msgstr ""
"jamovi tilbyr en enkel måte å beregne konfidensintervaller for "
"gjennomsnittet på som en del av funksjonaliteten til ``Descriptives``. Bare "
"merk av i avmerkingsboksen ``Confidence interval for Mean``."

#: ../../Ch08/Ch08_Estimation_5.rst:178
msgid ""
"95\\% confidence intervals are the de facto standard in psychology. So, for "
"example, if I load the |IQsim|_ data set (our simulated large sample data "
"with N=10,000), and check ``Confidence interval for Mean`` under "
"``Descriptives``, we obtain a mean IQ score of 99.683 with a 95\\% CI from "
"99.391 to 99.975."
msgstr ""
"95\\%-konfidensintervaller (KI) er de facto-standarden i psykologi. Hvis jeg "
"for eksempel laster inn datasettet |IQsim|_ (våre simulerte data fra et "
"stort utvalg med N = 10 000) og kryss av ``Confidence interval for Mean`` "
"under ``Descriptives``, får vi en gjennomsnittlig IQ-skår på 99,683 med et "
"95\\%-KI fra 99,391 til 99,975."

#: ../../Ch08/Ch08_Estimation_5.rst:183
msgid ""
"When it comes to plotting confidence intervals for the mean in jamovi, this "
"is not (yet) available as part of the ``Descriptives`` options. However, "
"when we get onto learning about specific statistical tests, for example in "
"chapter :doc:`../Ch13/Ch13_ANOVA`, we will see that we can plot confidence "
"intervals as part of the data analysis. That’s pretty cool, so we’ll show "
"you how to do that later on."
msgstr ""
"Når det gjelder plotting av konfidensintervaller for gjennomsnittet i "
"jamovi, er dette (ennå) ikke tilgjengelig som en del av ``Descriptives``-"
"opsjonene. Men når vi skal lære om spesifikke statistiske tester, for "
"eksempel i kapittel :doc:`../Ch13/Ch13_ANOVA`, vil vi se at vi kan plotte "
"konfidensintervaller som en del av dataanalysen. Det er ganske kult, så vi "
"skal vise deg hvordan du gjør det senere."

#: ../../Ch08/Ch08_Estimation_5.rst:193
msgid ""
"This quote appears on a great many t-shirts and websites, and even gets a "
"mention in a few academic papers (e.g., https://doi."
"org/10.1080/10691898.2002.11910681), but I’ve never found the original "
"source."
msgstr ""
"Sitatet dukker opp på svært mange t-skjorter og nettsider, og blir til og "
"med nevnt i noen akademiske artikler (f.eks. https://doi.org/10.1080/"
"10691898.2002.11910681), men jeg har aldri funnet originalkilden."

#: ../../Ch08/Ch08_Estimation_6.rst:4
msgid "Summary"
msgstr "Sammendrag"

#: ../../Ch08/Ch08_Estimation_6.rst:6
msgid ""
"In this chapter I’ve covered two main topics. The first half of the chapter "
"talks about sampling theory, and the second half talks about how we can use "
"sampling theory to construct estimates of the population parameters. The "
"section breakdown looks like this:"
msgstr ""
"I dette kapittelet har jeg dekket to hovedtemaer. Første halvdel av "
"kapittelet handler om utvalgsteori, og andre halvdel handler om hvordan vi "
"kan bruke utvalgsteori til å konstruere estimater av populasjonsparametrene. "
"Seksjonsinndelingen ser slik ut:"

#: ../../Ch08/Ch08_Estimation_6.rst:11
msgid ""
":doc:`Basic ideas about samples, sampling and populations "
"<Ch08_Estimation_1>`"
msgstr ""
":doc:`Grunnleggende ideer om utvalg, utvalg og populasjoner "
"<Ch08_Estimation_1>`"

#: ../../Ch08/Ch08_Estimation_6.rst:14
msgid ""
":doc:`Statistical theory of sampling: the law of large numbers "
"<Ch08_Estimation_2>`"
msgstr ""
":doc:`Statistisk teori om utvalg: loven om store tall <Ch08_Estimation_2>`"

#: ../../Ch08/Ch08_Estimation_6.rst:17
msgid ":doc:`Ch08_Estimation_3`"
msgstr ":doc:`Ch08_Estimation_3`"

#: ../../Ch08/Ch08_Estimation_6.rst:19
msgid ":doc:`Ch08_Estimation_4`"
msgstr ":doc:`Ch08_Estimation_4`"

#: ../../Ch08/Ch08_Estimation_6.rst:21
msgid ":doc:`Ch08_Estimation_5`"
msgstr ":doc:`Ch08_Estimation_5`"

#: ../../Ch08/Ch08_Estimation_6.rst:23
msgid ""
"As always, there’s a lot of topics related to sampling and estimation that "
"aren’t covered in this chapter, but for an introductory psychology class "
"this is fairly comprehensive I think. For most applied researchers you won’t "
"need much more theory than this. One big question that I haven’t touched on "
"in this chapter is what you do when you don’t have a simple random sample. "
"There is a lot of statistical theory you can draw on to handle this "
"situation, but it’s well beyond the scope of this book."
msgstr ""
"Som alltid er det mange emner knyttet til utvalg og estimering som ikke "
"dekkes i dette kapittelet, men for et introduksjonskurs i psykologi tror jeg "
"dette er ganske omfattende. For de fleste anvendte forskere vil du ikke "
"trenge mye mer teori enn dette. Et stort spørsmål som jeg ikke har berørt i "
"dette kapittelet, er hva du gjør når du ikke har et enkelt tilfeldig utvalg. "
"Det finnes mye statistisk teori du kan benytte deg av for å håndtere denne "
"situasjonen, men det ligger langt utenfor rammen av denne boken."
