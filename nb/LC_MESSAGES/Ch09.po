#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Learning statistics with jamovi\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-17 16:23+0100\n"
"PO-Revision-Date: 2024-08-13 16:56+0000\n"
"Last-Translator: Sebastian Jentschke <sebastian.jentschke@uib.no>\n"
"Language-Team: Norwegian Bokmål <https://hosted.weblate.org/projects/lsjdocs/"
"ch09/nb_NO/>\n"
"Language: nb\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"X-Generator: Weblate 5.7-dev\n"
"Generated-By: Babel 2.10.3\n"

#: ../../Ch09/Ch09_HypothesisTesting.rst:4
msgid "Hypothesis testing"
msgstr "Hypotesetesting"

#: ../../Ch09/Ch09_HypothesisTesting.rst:0
msgid ""
"*The process of induction is the process of assuming the simplest law that "
"can be made to harmonize with our experience. This process, however, has no "
"logical foundation but only a psychological one. It is clear that there are "
"no grounds for believing that the simplest course of events will really "
"happen. It is an hypothesis that the sun will rise tomorrow: and this means "
"that we do not know whether it will rise*."
msgstr ""
"*Induksjonsprosessen er prosessen med å anta den enkleste loven som kan "
"bringes til å harmonere med vår erfaring. Denne prosessen har imidlertid "
"ikke noe logisk fundament, men kun et psykologisk. Det er klart at det ikke "
"finnes noen grunn til å tro at det enkleste hendelsesforløpet virkelig vil "
"skje. Det er en hypotese at solen vil stå opp i morgen, og det betyr at vi "
"ikke vet om den vil stå opp*."

#: ../../Ch09/Ch09_HypothesisTesting.rst:32
msgid "Ludwig Wittgenstein\\ [#]_"
msgstr "Ludwig Wittgenstein\\ [#]_"

#: ../../Ch09/Ch09_HypothesisTesting.rst:34
msgid ""
"In the last chapter I discussed the ideas behind estimation, which is one of "
"the two “big ideas” in inferential statistics. It’s now time to turn our "
"attention to the other big idea, which is *hypothesis testing*. In its most "
"abstract form, hypothesis testing is really a very simple idea. The "
"researcher has some theory about the world and wants to determine whether or "
"not the data actually support that theory. However, the details are messy "
"and most people find the theory of hypothesis testing to be the most "
"frustrating part of statistics. The structure of the chapter is as follows. "
"First, I’ll describe how hypothesis testing works in a fair amount of "
"detail, using a simple running example to show you how a hypothesis test is "
"“built”. I’ll try to avoid being too dogmatic while doing so, and focus "
"instead on the underlying logic of the testing procedure.\\ [#]_ Afterwards, "
"I’ll spend a bit of time talking about the various dogmas, rules and "
"heresies that surround the theory of hypothesis testing."
msgstr ""
"I forrige kapittel diskuterte jeg ideene bak estimering, som er en av de to "
"«store ideene» innen inferensiell statistikk. Nå er det på tide å vende "
"oppmerksomheten mot den andre store ideen, nemlig *hypotesetesting*. I sin "
"mest abstrakte form er hypotesetesting egentlig en veldig enkel idé. "
"Forskeren har en teori om verden og ønsker å finne ut om dataene faktisk "
"støtter denne teorien eller ikke. Detaljene er imidlertid rotete, og de "
"fleste synes at teorien om hypotesetesting er den mest frustrerende delen av "
"statistikkfaget. Kapittelet er strukturert på følgende måte. Først beskriver "
"jeg hvordan hypotesetesting fungerer i detalj, og bruker et enkelt løpende "
"eksempel for å vise hvordan en hypotesetest er «bygget opp». Jeg vil forsøke "
"å unngå å være for dogmatisk, og i stedet fokusere på den underliggende "
"logikken i testprosedyren.\\ [#]_ Deretter vil jeg bruke litt tid på å "
"snakke om de ulike dogmene, reglene og kjetteriene som omgir teorien om "
"hypotesetesting."

#: ../../Ch09/Ch09_HypothesisTesting.rst:53
msgid ""
"The quote comes from Wittgenstein’s (1922) text, *Tractatus Logico-"
"Philosphicus*."
msgstr ""
"Sitatet er hentet fra Wittgensteins tekst *Tractatus Logico-Philosphicus* "
"(1922)."

#: ../../Ch09/Ch09_HypothesisTesting.rst:57
msgid ""
"A technical note. The description below differs subtly from the standard "
"description given in a lot of introductory texts. The orthodox theory of "
"null hypothesis testing emerged from the work of Sir Ronald Fisher and Jerzy "
"Neyman in the early 20th century; but Fisher and Neyman actually had very "
"different views about how it should work. The standard treatment of "
"hypothesis testing that most texts use is a hybrid of the two approaches. "
"The treatment here is a little more Neyman-style than the orthodox view, "
"especially as regards the meaning of the *p*-value."
msgstr ""
"En teknisk merknad. Beskrivelsen nedenfor skiller seg noe fra "
"standardbeskrivelsen som gis i mange introduksjonstekster. Den ortodokse "
"teorien om nullhypotesetesting stammer fra arbeidet til Sir Ronald Fisher og "
"Jerzy Neyman på begynnelsen av 1900-tallet, men Fisher og Neyman hadde "
"faktisk svært ulike oppfatninger om hvordan hypotesetesting skulle fungere. "
"Standardbehandlingen av hypotesetesting som de fleste lærebøker bruker, er "
"en hybrid av de to tilnærmingene. Behandlingen her er litt mer Neyman-aktig "
"enn det ortodokse synet, særlig når det gjelder betydningen av *p*-verdien."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:4
msgid "A menagerie of hypotheses"
msgstr "Et menasjeri av hypoteser"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:6
msgid ""
"Eventually we all succumb to madness. For me, that day will arrive once I’m "
"finally promoted to full professor. Safely ensconced in my ivory tower, "
"happily protected by tenure, I will finally be able to take leave of my "
"senses (so to speak) and indulge in that most thoroughly unproductive line "
"of psychological research, the search for extrasensory perception (ESP).\\ "
"[#]_"
msgstr ""
"Til slutt bukker vi alle under for galskapen. For meg vil den dagen komme "
"når jeg endelig blir forfremmet til professor. Trygt plassert i mitt "
"elfenbenstårn, lykkelig beskyttet av en fast stilling, vil jeg endelig kunne "
"ta permisjon fra sansene (for å si det sånn) og hengi meg til den mest "
"uproduktive delen av psykologisk forskning, jakten på ekstrasensorisk "
"persepsjon (ESP).\\ [#]_"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:13
msgid ""
"Let’s suppose that this glorious day has come. My first study is a simple "
"one in which I seek to test whether clairvoyance exists. Each participant "
"sits down at a table and is shown a card by an experimenter. The card is "
"black on one side and white on the other. The experimenter takes the card "
"away and places it on a table in an adjacent room. The card is placed black "
"side up or white side up completely at random, with the randomisation "
"occurring only after the experimenter has left the room with the "
"participant. A second experimenter comes in and asks the participant which "
"side of the card is now facing upwards. It’s purely a one-shot experiment. "
"Each person sees only one card and gives only one answer, and at no stage is "
"the participant actually in contact with someone who knows the right answer. "
"My data set, therefore, is very simple. I have asked the question of *N* "
"people and some number *X* of these people have given the correct response. "
"To make things concrete, let’s suppose that I have tested *N* = 100 people "
"and *X* = 62 of these got the answer right. A surprisingly large number, "
"sure, but is it large enough for me to feel safe in claiming I’ve found "
"evidence for ESP? This is the situation where hypothesis testing comes in "
"useful. However, before we talk about how to *test* hypotheses, we need to "
"be clear about what we mean by hypotheses."
msgstr ""
"La oss anta at denne strålende dagen er kommet. Min første studie er en "
"enkel studie der jeg forsøker å teste om klarsynthet eksisterer. Hver "
"deltaker setter seg ned ved et bord og får vist et kort av en "
"eksperimentator. Kortet er svart på den ene siden og hvitt på den andre. "
"Forsøkslederen tar kortet og legger det på et bord i et tilstøtende rom. "
"Kortet plasseres med den svarte siden opp eller den hvite siden opp helt "
"tilfeldig, og randomiseringen skjer først etter at forsøkslederen har "
"forlatt rommet sammen med deltakeren. En annen eksperimentator kommer inn og "
"spør deltakeren hvilken side av kortet som nå vender oppover. Det er et rent "
"one-shot-eksperiment. Hver person ser bare ett kort og gir bare ett svar, og "
"ikke på noe tidspunkt er deltakeren i kontakt med noen som vet det riktige "
"svaret. Datasettet mitt er derfor veldig enkelt. Jeg har stilt spørsmålet "
"til *N* personer, og et visst antall *X* av disse personene har gitt riktig "
"svar. For å gjøre det konkret, la oss anta at jeg har testet *N* = 100 "
"personer, og at *X* = 62 av disse har svart riktig. Et overraskende stort "
"antall, javisst, men er det stort nok til at jeg kan føle meg trygg på at "
"jeg har funnet bevis for ESP? Det er i denne situasjonen hypotesetesting "
"kommer til nytte. Men før vi snakker om hvordan man *tester* hypoteser, må "
"vi ha klart for oss hva vi mener med hypoteser."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:35
msgid "Research hypotheses versus statistical hypotheses"
msgstr "Forskningshypoteser versus statistiske hypoteser"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:37
msgid ""
"The first distinction that you need to keep clear in your mind is between "
"research hypotheses and statistical hypotheses. In my ESP study my overall "
"scientific goal is to demonstrate that clairvoyance exists. In this "
"situation I have a clear research goal: I am hoping to discover evidence for "
"ESP. In other situations I might actually be a lot more neutral than that, "
"so I might say that my research goal is to determine whether or not "
"clairvoyance exists. Regardless of how I want to portray myself, the basic "
"point that I’m trying to convey here is that a research hypothesis involves "
"making a substantive, testable scientific claim. If you are a psychologist "
"then your research hypotheses are fundamentally *about* psychological "
"constructs. Any of the following would count as **research hypotheses**:"
msgstr ""
"Det første skillet du må holde klart for deg, er mellom forskningshypoteser "
"og statistiske hypoteser. I min ESP-studie er mitt overordnede "
"vitenskapelige mål å påvise at klarsynthet eksisterer. I denne situasjonen "
"har jeg et klart forskningsmål: Jeg håper å finne bevis for ESP. I andre "
"situasjoner er jeg kanskje mye mer nøytral enn som så, og da kan jeg si at "
"mitt forskningsmessige mål er å finne ut om klarsynthet eksisterer eller "
"ikke. Uansett hvordan jeg vil fremstille meg selv, er det grunnleggende "
"poenget jeg prøver å formidle her, at en forskningshypotese innebærer å "
"komme med en substansiell, testbar vitenskapelig påstand. Hvis du er "
"psykolog, handler forskningshypotesene dine i bunn og grunn *om* "
"psykologiske konstruksjoner. Alle de følgende hypotesene regnes som "
"**forskningshypoteser**:"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:50
msgid ""
"*Listening to music reduces your ability to pay attention to other things.* "
"This is a claim about the causal relationship between two psychologically "
"meaningful concepts (listening to music and paying attention to things), so "
"it’s a perfectly reasonable research hypothesis."
msgstr ""
"*Musikklytting reduserer evnen til å være oppmerksom på andre ting* Dette er "
"en påstand om årsakssammenhengen mellom to psykologisk meningsfulle begreper "
"(musikklytting og oppmerksomhet), så det er en helt rimelig "
"forskningshypotese."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:56
msgid ""
"*Intelligence is related to personality*. Like the last one, this is a "
"relational claim about two psychological constructs (intelligence and "
"personality), but the claim is weaker: correlational not causal."
msgstr ""
"*Intelligens er relatert til personlighet*. I likhet med den forrige er "
"dette en relasjonell påstand om to psykologiske konstrukter (intelligens og "
"personlighet), men påstanden er svakere: korrelasjonell, ikke kausal."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:60
msgid ""
"*Intelligence is speed of information processing*. This hypothesis has a "
"quite different character. It’s not actually a relational claim at all. It’s "
"an ontological claim about the fundamental character of intelligence (and "
"I’m pretty sure it’s wrong). It’s worth expanding on this one actually. It’s "
"usually easier to think about how to construct experiments to test research "
"hypotheses of the form “does X affect Y?” than it is to address claims like "
"“what is X?” And in practice what usually happens is that you find ways of "
"testing relational claims that follow from your ontological ones. For "
"instance, if I believe that intelligence *is* speed of information "
"processing in the brain, my experiments will often involve looking for "
"relationships between measures of intelligence and measures of speed. As a "
"consequence most everyday research questions do tend to be relational in "
"nature, but they’re almost always motivated by deeper ontological questions "
"about the state of nature."
msgstr ""
"*Intelligens er hastigheten på informasjonsbehandling*. Denne hypotesen har "
"en helt annen karakter. Den er faktisk ikke en relasjonell påstand i det "
"hele tatt. Det er en ontologisk påstand om intelligensens grunnleggende "
"karakter (og jeg er ganske sikker på at den er feil). Det er faktisk verdt å "
"utdype dette. Det er vanligvis lettere å tenke på hvordan man skal "
"konstruere eksperimenter for å teste forskningshypoteser av typen «påvirker "
"X Y?» enn det er å svare på påstander av typen «hva er X?». Og i praksis "
"skjer det som regel at man finner måter å teste relasjonelle påstander som "
"følger av de ontologiske påstandene. Hvis jeg for eksempel tror at "
"intelligens *er* hastigheten på informasjonsbehandlingen i hjernen, vil "
"eksperimentene mine ofte innebære å lete etter sammenhenger mellom mål på "
"intelligens og mål på hastighet. Som en konsekvens av dette har de fleste "
"hverdagslige forskningsspørsmål en tendens til å være relasjonelle, men de "
"er nesten alltid motivert av dypere ontologiske spørsmål om naturens "
"tilstand."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:76
msgid ""
"Notice that in practice, my research hypotheses could overlap a lot. My "
"ultimate goal in the ESP experiment might be to test an ontological claim "
"like “ESP exists”, but I might operationally restrict myself to a narrower "
"hypothesis like “Some people can ‘see’ objects in a clairvoyant fashion”. "
"That said, there are some things that really don’t count as proper research "
"hypotheses in any meaningful sense:"
msgstr ""
"Legg merke til at forskningshypotesene mine i praksis kan overlappe mye. Det "
"endelige målet mitt med ESP-eksperimentet kan være å teste en ontologisk "
"påstand som «ESP eksisterer», men jeg kan operativt begrense meg til en "
"snevrere hypotese som «Noen mennesker kan ‹se› objekter på en klarsynt "
"måte». Når det er sagt, er det noen ting som virkelig ikke kan regnes som "
"egentlige forskningshypoteser i noen meningsfull forstand:"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:83
msgid ""
"*Love is a battlefield*. This is too vague to be testable. Whilst it’s okay "
"for a research hypothesis to have a degree of vagueness to it, it has to be "
"possible to operationalise your theoretical ideas. Maybe I’m just not "
"creative enough to see it, but I can’t see how this can be converted into "
"any concrete research design. If that’s true then this isn’t a scientific "
"research hypothesis, it’s a pop song. That doesn’t mean it’s not "
"interesting. A lot of deep questions that humans have fall into this "
"category. Maybe one day science will be able to construct testable theories "
"of love, or to test to see if God exists, and so on. But right now we can’t, "
"and I wouldn’t bet on ever seeing a satisfying scientific approach to either."
msgstr ""
"*Kjærlighet er en slagmark*. Dette er for vagt til å kunne testes. Selv om "
"det er greit at en forskningshypotese er vag, må det være mulig å "
"operasjonalisere de teoretiske ideene dine. Kanskje er jeg bare ikke kreativ "
"nok til å se det, men jeg kan ikke se hvordan dette kan konverteres til noe "
"konkret forskningsdesign. I så fall er ikke dette en vitenskapelig "
"forskningshypotese, det er en popsang. Det betyr ikke at det ikke er "
"interessant. Mange dype spørsmål som mennesker har, faller inn under denne "
"kategorien. Kanskje vil vitenskapen en dag være i stand til å konstruere "
"testbare teorier om kjærlighet, eller til å teste om Gud eksisterer, og så "
"videre. Men akkurat nå kan vi ikke det, og jeg vil ikke vedde på at vi noen "
"gang vil få se en tilfredsstillende vitenskapelig tilnærming til noen av "
"delene."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:95
msgid ""
"*The first rule of tautology club is the first rule of tautology club*. This "
"is not a substantive claim of any kind. It’s true by definition. No "
"conceivable state of nature could possibly be inconsistent with this claim. "
"We say that this is an unfalsifiable hypothesis, and as such it is outside "
"the domain of science. Whatever else you do in science your claims must have "
"the possibility of being wrong."
msgstr ""
"*Tautologiklubbens første regel er tautologiklubbens første regel*. Dette er "
"ikke en substansiell påstand av noe slag. Den er sann per definisjon. Ingen "
"tenkelig naturtilstand kan være uforenlig med denne påstanden. Vi sier at "
"dette er en ufalsifiserbar hypotese, og som sådan ligger den utenfor "
"vitenskapens domene. Uansett hva du ellers gjør i vitenskapen, må påstandene "
"dine ha muligheten for å være feil."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:103
msgid ""
"*More people in my experiment will say “yes” than “no”*. This one fails as a "
"research hypothesis because it’s a claim about the data set, not about the "
"psychology (unless of course your actual research question is whether people "
"have some kind of “yes” bias!). Actually, this hypothesis is starting to "
"sound more like a statistical hypothesis than a research hypothesis."
msgstr ""
"*I mitt eksperiment vil flere si «ja» enn «nei»*. Denne mislykkes som "
"forskningshypotese fordi det er en påstand om datasettet, ikke om "
"psykologien (med mindre det egentlige forskningsspørsmålet ditt er om folk "
"har en eller annen form for «ja»-skjevhet!) Faktisk begynner denne hypotesen "
"å høres mer ut som en statistisk hypotese enn en forskningshypotese."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:110
msgid ""
"As you can see, research hypotheses can be somewhat messy at times and "
"ultimately they are *scientific* claims. **Statistical hypotheses** are "
"neither of these two things. Statistical hypotheses must be mathematically "
"precise and they must correspond to specific claims about the "
"characteristics of the data generating mechanism (i.e., the “population”). "
"Even so, the intent is that statistical hypotheses bear a clear relationship "
"to the substantive research hypotheses that you care about! For instance, in "
"my ESP study my research hypothesis is that some people are able to see "
"through walls or whatever. What I want to do is to “map” this onto a "
"statement about how the data were generated. So let’s think about what that "
"statement would be. The quantity that I’m interested in within the "
"experiment is *P*\\ (“correct”), the true-but-unknown probability with which "
"the participants in my experiment answer the question correctly. Let’s use "
"the Greek letter *θ* (theta) to refer to this probability. Here are four "
"different statistical hypotheses:"
msgstr ""
"Som du ser, kan forskningshypoteser til tider være noe rotete, og til "
"syvende og sist er de *vitenskapelige* påstander. **Statistiske hypoteser** "
"er ingen av disse to tingene. Statistiske hypoteser må være matematisk "
"presise, og de må svare til spesifikke påstander om egenskapene til den "
"datagenererende mekanismen (dvs. «populasjonen»). Likevel er hensikten at de "
"statistiske hypotesene skal ha en klar sammenheng med de substansielle "
"forskningshypotesene som du er opptatt av! I ESP-studien min er for eksempel "
"forskningshypotesen min at noen mennesker er i stand til å se gjennom vegger "
"eller lignende. Det jeg ønsker å gjøre, er å «tilordne» dette til en "
"uttalelse om hvordan dataene ble generert. Så la oss tenke på hva en slik "
"uttalelse vil være. Størrelsen jeg er interessert i i eksperimentet, er "
"*P*\\ («riktig»), den sanne, men ukjente sannsynligheten for at deltakerne i "
"eksperimentet mitt svarer riktig på spørsmålet. La oss bruke den greske "
"bokstaven *θ* (theta) for å referere til denne sannsynligheten. Her er fire "
"ulike statistiske hypoteser:"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:127
msgid ""
"If ESP doesn’t exist and if my experiment is well designed then my "
"participants are just guessing. So I should expect them to get it right half "
"of the time and so my statistical hypothesis is that the true probability of "
"choosing correctly is *θ* = 0.5\\ ."
msgstr ""
"Hvis ESP ikke eksisterer, og hvis eksperimentet mitt er godt designet, "
"gjetter deltakerne mine bare. Da bør jeg forvente at de har rett halvparten "
"av gangene, og min statistiske hypotese er derfor at den sanne "
"sannsynligheten for å velge riktig er *θ* = 0,5\\ ."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:132
msgid ""
"Alternatively, suppose ESP does exist and participants can see the card. If "
"that’s true people will perform better than chance and the statistical "
"hypothesis is that *θ* > 0.5\\ ."
msgstr ""
"Alternativt kan vi anta at ESP eksisterer, og at deltakerne kan se kortet. "
"Hvis det er sant, vil folk prestere bedre enn tilfeldighetene, og den "
"statistiske hypotesen er at *θ* > 0,5\\ ."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:136
msgid ""
"A third possibility is that ESP does exist, but the colours are all reversed "
"and people don’t realise it (okay, that’s wacky, but you never know). If "
"that’s how it works then you’d expect people’s performance to be *below* "
"chance. This would correspond to a statistical hypothesis that *θ* < 0.5\\ ."
msgstr ""
"En tredje mulighet er at ESP eksisterer, men at alle fargene er snudd på "
"hodet og at folk ikke er klar over det (ok, det er sprøtt, men man vet "
"aldri). Hvis det er slik det fungerer, vil man forvente at folks "
"prestasjoner ligger *under* tilfeldighetene. Dette ville tilsvare en "
"statistisk hypotese om at *θ* < 0,5\\ ."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:142
msgid ""
"Finally, suppose ESP exists but I have no idea whether people are seeing the "
"right colour or the wrong one. In that case the only claim I could make "
"about the data would be that the probability of making the correct answer is "
"*not* equal to 0.5. This corresponds to the statistical hypothesis that *θ* "
"≠ 0.5\\ ."
msgstr ""
"Til slutt, anta at ESP eksisterer, men at jeg ikke aner om folk ser riktig "
"eller feil farge. I så fall vil den eneste påstanden jeg kan komme med om "
"dataene, være at sannsynligheten for å svare riktig *ikke* er lik 0,5. Dette "
"tilsvarer den statistiske hypotesen om at *θ* ≠ 0,5\\ ."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:148
msgid ""
"All of these are legitimate examples of a statistical hypothesis because "
"they are statements about a population parameter and are meaningfully "
"related to my experiment."
msgstr ""
"Alle disse er legitime eksempler på en statistisk hypotese, fordi de er "
"utsagn om en populasjonsparameter og er meningsfullt relatert til "
"eksperimentet mitt."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:152
msgid ""
"What this discussion makes clear, I hope, is that when attempting to "
"construct a statistical hypothesis test the researcher actually has two "
"quite distinct hypotheses to consider. First, he or she has a research "
"hypothesis (a claim about psychology), and this then corresponds to a "
"statistical hypothesis (a claim about the data generating population). In my "
"ESP example these might be:"
msgstr ""
"Jeg håper at denne diskusjonen gjør det klart at forskeren som forsøker å "
"konstruere en statistisk hypotesetest, faktisk har to helt forskjellige "
"hypoteser å ta hensyn til. For det første har han eller hun en "
"forskningshypotese (en påstand om psykologi), og denne korresponderer så med "
"en statistisk hypotese (en påstand om den datagenererende populasjonen). I "
"mitt ESP-eksempel kan disse være:"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:160
msgid "Dani’s **research** hypothesis:"
msgstr "Danis **forskningshypotese**:"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:160
msgid "“ESP exists”"
msgstr "«ESP eksisterer»"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:162
msgid "Dani’s **statistical** hypothesis:"
msgstr "Danis **statistiske** hypotese:"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:162
msgid "*θ* ≠ 0.5"
msgstr "*θ* ≠ 0.5"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:165
msgid ""
"And a key thing to recognise is this. *A statistical hypothesis test is a "
"test of the statistical hypothesis, not the research hypothesis*. If your "
"study is badly designed then the link between your research hypothesis and "
"your statistical hypothesis is broken. To give a silly example, suppose that "
"my ESP study was conducted in a situation where the participant can actually "
"see the card reflected in a window. If that happens I would be able to find "
"very strong evidence that *θ* ≠ 0.5, but this would tell us nothing about "
"whether “ESP exists”."
msgstr ""
"Og en viktig ting å være klar over er dette. *En statistisk hypotesetest er "
"en test av den statistiske hypotesen, ikke av forskningshypotesen*. Hvis "
"studien din er dårlig utformet, er koblingen mellom forskningshypotesen og "
"den statistiske hypotesen brutt. For å gi et tåpelig eksempel: Anta at ESP-"
"studien min ble gjennomført i en situasjon der deltakeren faktisk kan se "
"kortet reflektert i et vindu. I så fall ville jeg kunne finne svært sterke "
"bevis for at *θ* ≠ 0,5, men dette ville ikke si noe om hvorvidt «ESP "
"eksisterer»."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:175
msgid "Null hypotheses and alternative hypotheses"
msgstr "Null- og alternativhypoteser"

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:177
msgid ""
"So far, so good. I have a research hypothesis that corresponds to what I "
"want to believe about the world, and I can map it onto a statistical "
"hypothesis that corresponds to what I want to believe about how the data "
"were generated. It’s at this point that things get somewhat counter-"
"intuitive for a lot of people. Because what I’m about to do is invent a new "
"statistical hypothesis (the “null” hypothesis, H\\ :sub:`0`\\ ) that "
"corresponds to the exact opposite of what I want to believe, and then focus "
"exclusively on that almost to the neglect of the thing I’m actually "
"interested in (which is now called the “alternative” hypothesis, H\\ :sub:"
"`1`\\ ). In our ESP example, the null hypothesis is that *θ* = 0.5, since "
"that’s what we’d expect if ESP *didn’t* exist. My hope, of course, is that "
"ESP is totally real and so the *alternative* to this null hypothesis is *θ* "
"≠ 0.5. In essence, what we’re doing here is dividing up the possible values "
"of *θ* into two groups: those values that I really hope aren’t true (the "
"null), and those values that I’d be happy with if they turn out to be right "
"(the alternative). Having done so, the important thing to recognise is that "
"the goal of a hypothesis test is *not* to show that the alternative "
"hypothesis is (probably) true. The goal is to show that the null hypothesis "
"is (probably) false. Most people find this pretty weird."
msgstr ""
"Så langt, så bra. Jeg har en forskningshypotese som samsvarer med det jeg "
"ønsker å tro om verden, og jeg kan overføre den til en statistisk hypotese "
"som samsvarer med det jeg ønsker å tro om hvordan dataene ble generert. Det "
"er på dette punktet at ting blir noe kontraintuitivt for mange mennesker. "
"For det jeg er i ferd med å gjøre, er å finne opp en ny statistisk hypotese "
"(nullhypotesen, H\\ :sub:`0`\\ ) som tilsvarer det stikk motsatte av det jeg "
"ønsker å tro, og deretter fokusere utelukkende på den, nesten på bekostning "
"av det jeg faktisk er interessert i (som nå kalles «alternativhypotesen», "
"H\\ :sub:`1`\\ ). I vårt ESP-eksempel er nullhypotesen at *θ* = 0,5, siden "
"det er det vi ville forvente hvis ESP *ikke* eksisterte. Mitt håp er "
"selvfølgelig at ESP er helt reelt, og at *alternativhypotesen* til denne "
"nullhypotesen er *θ* ≠ 0,5. Det vi gjør her, er å dele de mulige verdiene av "
"*θ* inn i to grupper: de verdiene som jeg virkelig håper ikke er sanne "
"(nullhypotesen), og de verdiene som jeg er fornøyd med hvis de viser seg å "
"være riktige (alternativhypotesen). Når dette er gjort, er det viktig å være "
"klar over at målet med en hypotesetest *ikke* er å vise at "
"alternativhypotesen (sannsynligvis) er sann. Målet er å vise at "
"nullhypotesen (sannsynligvis) er usann. De fleste synes dette er ganske rart."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:199
msgid ""
"The best way to think about it, in my experience, is to imagine that a "
"hypothesis test is a criminal trial,\\ [#]_ *the trial of the null "
"hypothesis*. The null hypothesis is the defendant, the researcher is the "
"prosecutor, and the statistical test itself is the judge. Just like a "
"criminal trial, there is a presumption of innocence. The null hypothesis is "
"*deemed* to be true unless you, the researcher, can prove beyond a "
"reasonable doubt that it is false. You are free to design your experiment "
"however you like (within reason, obviously!) and your goal when doing so is "
"to maximise the chance that the data will yield a conviction for the crime "
"of being false. The catch is that the statistical test sets the rules of the "
"trial and those rules are designed to protect the null hypothesis, "
"specifically to ensure that if the null hypothesis is actually true the "
"chances of a false conviction are guaranteed to be low. This is pretty "
"important. After all, the null hypothesis doesn’t get a lawyer, and given "
"that the researcher is trying desperately to prove it to be false *someone* "
"has to protect it."
msgstr ""
"Den beste måten å tenke på det på, etter min erfaring, er å forestille seg "
"at en hypotesetest er en rettssak,\\ [#]_ *rettssaken om nullhypotesen*. "
"Nullhypotesen er den tiltalte, forskeren er aktor, og selve den statistiske "
"testen er dommeren. Akkurat som i en rettssak er det en uskyldspresumsjon. "
"Nullhypotesen *anses* for å være sann, med mindre du som forsker kan bevise "
"utover enhver rimelig tvil at den er usann. Du står fritt til å utforme "
"eksperimentet ditt som du vil (innenfor rimelighetens grenser, selvsagt!), "
"og målet ditt er å maksimere sjansen for at dataene vil gi en fellende dom "
"for forbrytelsen å være falsk. Haken er at den statistiske testen setter "
"reglene for forsøket, og disse reglene er utformet for å beskytte "
"nullhypotesen, spesielt for å sikre at hvis nullhypotesen faktisk er sann, "
"er sjansen for en falsk domfellelse garantert lav. Dette er ganske viktig. "
"Nullhypotesen får tross alt ingen advokat, og siden forskeren desperat "
"prøver å bevise at den er usann, må *noen* beskytte den."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:219
msgid ""
"My apologies to anyone who actually believes in this stuff, but on my "
"reading of the literature on ESP it’s just not reasonable to think this is "
"real. To be fair, though, some of the studies are rigorously designed, so "
"it’s actually an interesting area for thinking about psychological research "
"design. And of course it’s a free country so you can spend your own time and "
"effort proving me wrong if you like, but I wouldn’t think that’s a terribly "
"practical use of your intellect."
msgstr ""
"Jeg beklager overfor alle som faktisk tror på dette, men når jeg leser "
"litteraturen om ESP, er det ikke rimelig å tro at dette er virkelig. Men for "
"å være ærlig er noen av studiene strengt designet, så det er faktisk et "
"interessant område for å tenke på psykologisk forskningsdesign. Og det er "
"selvfølgelig et fritt land, så du kan bruke din egen tid og krefter på å "
"bevise at jeg tar feil hvis du vil, men jeg tror ikke det er en veldig "
"praktisk bruk av intellektet ditt."

#: ../../Ch09/Ch09_HypothesisTesting_01.rst:229
msgid ""
"This analogy only works if you’re from an adversarial legal system like UK/"
"US/Australia. As I understand these things, the French inquisitorial system "
"is quite different."
msgstr ""
"Denne analogien fungerer bare hvis du kommer fra et kontradiktorisk "
"rettssystem som Storbritannia/USA/Australia. Slik jeg har forstått det, er "
"det franske inkvisitoriske systemet ganske annerledes."

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:4
msgid "Two types of errors"
msgstr "To typer feil"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:6
msgid ""
"Before going into details about how a statistical test is constructed it’s "
"useful to understand the philosophy behind it. I hinted at it when pointing "
"out the similarity between a null hypothesis test and a criminal trial, but "
"I should now be explicit. Ideally, we would like to construct our test so "
"that we never make any errors. Unfortunately, since the world is messy, this "
"is never possible. Sometimes you’re just really unlucky. For instance, "
"suppose you flip a coin 10 times in a row and it comes up heads all 10 "
"times. That feels like very strong evidence for a conclusion that the coin "
"is biased, but of course there’s a 1 in 1024 chance that this would happen "
"even if the coin was totally fair. In other words, in real life we *always* "
"have to accept that there’s a chance that we made a mistake. As a "
"consequence the goal behind statistical hypothesis testing is not to "
"*eliminate* errors, but to *minimise* them."
msgstr ""
"Før jeg går i detalj om hvordan en statistisk test er konstruert, er det "
"nyttig å forstå filosofien bak. Jeg antydet det da jeg påpekte likheten "
"mellom en nullhypotesetest og en straffeprosess, men nå bør jeg være "
"eksplisitt. Ideelt sett ønsker vi å konstruere testen vår slik at vi aldri "
"gjør noen feil. Dessverre er dette aldri mulig, siden verden er rotete. Noen "
"ganger er man bare veldig uheldig. Tenk deg for eksempel at du kaster en "
"mynt ti ganger på rad, og den slår kron alle ti gangene. Det føles som et "
"veldig sterkt bevis for at mynten er skjev, men det er selvfølgelig en "
"sjanse på 1 til 1024 for at dette ville skjedd selv om mynten var helt "
"rettferdig. Med andre ord, i det virkelige liv må vi *alltid* akseptere at "
"det er en sjanse for at vi har gjort en feil. Målet med statistisk "
"hypotesetesting er derfor ikke å *eliminere* feil, men å *minimere* dem."

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:21
msgid ""
"At this point, we need to be a bit more precise about what we mean by "
"“errors”. First, let’s state the obvious. It is either the case that the "
"null hypothesis is true or that it is false, and our test will either retain "
"the null hypothesis or reject it.\\ [#]_ So, as the table below illustrates, "
"after we run the test and make our choice one of four things might have "
"happened:"
msgstr ""
"På dette punktet må vi være litt mer presise når det gjelder hva vi mener "
"med «feil». La oss først slå fast det åpenbare. Enten er nullhypotesen sann, "
"eller så er den falsk, og testen vår vil enten beholde nullhypotesen eller "
"forkaste den.\\ [#]_ Som tabellen nedenfor illustrerer, kan én av fire ting "
"ha skjedd etter at vi har kjørt testen og gjort vårt valg:"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:29
#: ../../Ch09/Ch09_HypothesisTesting_02.rst:69
msgid "retain H\\ :sub:`0`"
msgstr "beholde H\\ :sub:`0`"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:29
#: ../../Ch09/Ch09_HypothesisTesting_02.rst:69
msgid "reject H\\ :sub:`0`"
msgstr "avvise H\\ :sub:`0`"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:31
#: ../../Ch09/Ch09_HypothesisTesting_02.rst:71
msgid "**H\\ :sub:`0` is true**"
msgstr "**H\\ :sub:`0` is true**"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:31
#: ../../Ch09/Ch09_HypothesisTesting_02.rst:33
msgid "correct decision"
msgstr "riktig avgjørelse"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:31
msgid "error (type I)"
msgstr "feil (type I)"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:33
#: ../../Ch09/Ch09_HypothesisTesting_02.rst:74
msgid "**H\\ :sub:`0` is false**"
msgstr "**H\\ :sub:`0` is false**"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:33
msgid "error (type II)"
msgstr "feil (type II)"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:36
msgid ""
"As a consequence there are actually *two* different types of error here. If "
"we reject a null hypothesis that is actually true then we have made a **type "
"I error**. On the other hand, if we retain the null hypothesis when it is in "
"fact false then we have made a **type II error**."
msgstr ""
"Som en konsekvens av dette er det faktisk *to* forskjellige typer feil her. "
"Hvis vi forkaster en nullhypotese som faktisk er sann, har vi gjort en "
"**type-I-feil**. Hvis vi derimot beholder nullhypotesen selv om den faktisk "
"er usann, har vi gjort en **type-II-feil**."

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:41
msgid ""
"Remember how I said that statistical testing was kind of like a criminal "
"trial? Well, I meant it. A criminal trial requires that you establish "
"“beyond a reasonable doubt” that the defendant did it. All of the evidential "
"rules are (in theory, at least) designed to ensure that there’s (almost) no "
"chance of wrongfully convicting an innocent defendant. The trial is designed "
"to protect the rights of a defendant, as the English jurist William "
"Blackstone famously said, it is “better that ten guilty persons escape than "
"that one innocent suffer.” In other words, a criminal trial doesn’t treat "
"the two types of error in the same way. Punishing the innocent is deemed to "
"be much worse than letting the guilty go free. A statistical test is pretty "
"much the same. The single most important design principle of the test is to "
"*control* the probability of a type I error, to keep it below some fixed "
"probability. This probability, which is denoted α, is called the "
"**significance level** of the test. And I’ll say it again, because it is so "
"central to the whole set-up, a hypothesis test is said to have significance "
"level α if the type I error rate is no larger than α."
msgstr ""
"Husker du at jeg sa at statistisk testing var litt som en rettssak? Vel, jeg "
"mente det. I en straffesak må det være «hevet over enhver rimelig tvil» at "
"den tiltalte har gjort det. Alle bevisreglene er (i hvert fall i teorien) "
"utformet for å sikre at det (nesten) ikke er noen sjanse for å få en "
"uskyldig tiltalt dømt på feilaktig grunnlag. Rettssaken er utformet for å "
"beskytte tiltaltes rettigheter, og som den engelske juristen William "
"Blackstone sa, er det «bedre at ti skyldige slipper unna enn at én uskyldig "
"lider». I en straffesak behandles med andre ord ikke de to typene feil på "
"samme måte. Å straffe den uskyldige anses som mye verre enn å la den "
"skyldige gå fri. En statistisk test er stort sett det samme. Det viktigste "
"designprinsippet for testen er å *kontrollere* sannsynligheten for en type-I-"
"feil, slik at den holdes under en viss fastsatt sannsynlighet. Denne "
"sannsynligheten, som betegnes α, kalles testens **signifikansnivå**. Og jeg "
"sier det igjen, fordi det er så sentralt i hele opplegget: En hypotesetest "
"sies å ha signifikansnivå α hvis type-I-feilraten ikke er større enn α."

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:60
msgid ""
"So, what about the type II error rate? Well, we’d also like to keep those "
"under control too, and we denote this probability by β. However, it’s much "
"more common to refer to the **power** of the test, that is the probability "
"with which we reject a null hypothesis when it really is false, which is 1 - "
"β. To help keep this straight, here’s the same table again but with the "
"relevant numbers added:"
msgstr ""
"Hva så med type-II-feilraten? Vi ønsker også å holde disse under kontroll, "
"og vi betegner denne sannsynligheten med β. Det er imidlertid mye vanligere "
"å referere til testens **styrke**, det vil si sannsynligheten for at vi "
"forkaster en nullhypotese når den virkelig er falsk, som er 1 - β. For å "
"gjøre det lettere å holde orden på dette, her er den samme tabellen igjen, "
"men med de relevante tallene lagt til:"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:0
msgid "1 - α"
msgstr "1 - α"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:0
msgid "(probability of correct retention)"
msgstr "(sannsynlighet for korrekt oppbevaring)"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:0
msgid "α"
msgstr "α"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:0
msgid "(type I error rate)"
msgstr "(type-I-feilrate)"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:0
msgid "β"
msgstr "β"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:0
msgid "(type II error rate)"
msgstr "(type-II-feilrate)"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:0
msgid "1 - β"
msgstr "1 - β"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:0
msgid "(power of the test)"
msgstr "(testens styrke)"

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:78
msgid ""
"A “powerful” hypothesis test is one that has a small value of β, while still "
"keeping α fixed at some (small) desired level. By convention, scientists "
"make use of three different α levels: *.05*, *.01* and *.001*. Notice the "
"asymmetry here; the tests are designed to *ensure* that the α level is kept "
"small but there’s no corresponding guarantee regarding β. We’d certainly "
"*like* the type II error rate to be small and we try to design tests that "
"keep it small, but this is typically secondary to the overwhelming need to "
"control the type I error rate. As Blackstone might have said if he were a "
"statistician, it is “better to retain 10 false null hypotheses than to "
"reject a single true one”. To be honest, I don’t know that I agree with this "
"philosophy. There are situations where I think it makes sense, and "
"situations where I think it doesn’t, but that’s neither here nor there. It’s "
"how the tests are built."
msgstr ""
"En «kraftig» hypotesetest er en test som har en liten verdi på β, samtidig "
"som α holdes fast på et (lite) ønsket nivå. Forskere bruker vanligvis tre "
"ulike α-nivåer: *,05*, *,01* og *,001*. Legg merke til asymmetrien her; "
"testene er utformet for å *sikre* at α-nivået holdes lavt, men det finnes "
"ingen tilsvarende garanti for β. Vi *ønsker* absolutt at type-II-feilraten "
"skal være lav, og vi prøver å utforme tester som holder den lav, men dette "
"er vanligvis sekundært i forhold til det overveldende behovet for å "
"kontrollere type-I-feilraten. Som Blackstone ville ha sagt hvis han var "
"statistiker, er det «bedre å beholde 10 falske nullhypoteser enn å forkaste "
"en eneste sann». For å være ærlig vet jeg ikke om jeg er enig i denne "
"filosofien. Det finnes situasjoner der jeg tror det gir mening, og "
"situasjoner der jeg tror det ikke gjør det, men det er verken her eller der. "
"Det er slik testene er bygget opp."

#: ../../Ch09/Ch09_HypothesisTesting_02.rst:97
msgid ""
"An aside regarding the language you use to talk about hypothesis testing. "
"First, one thing you really want to avoid is the word “prove”. A statistical "
"test really doesn’t *prove* that a hypothesis is true or false. Proof "
"implies certainty and, as the saying goes, statistics means never having to "
"say you’re certain. On that point almost everyone would agree. However, "
"beyond that there’s a fair amount of confusion. Some people argue that "
"you’re only allowed to make statements like “rejected the null”, “failed to "
"reject the null”, or possibly “retained the null”. According to this line of "
"thinking you can’t say things like “accept the alternative” or “accept the "
"null”. Personally I think this is too strong. In my opinion, this conflates "
"null hypothesis testing with Karl Popper’s falsificationist view of the "
"scientific process. Whilst there are similarities between falsificationism "
"and null hypothesis testing, they aren’t equivalent. However, whilst I "
"personally think it’s fine to talk about accepting a hypothesis (on the "
"proviso that “acceptance” doesn’t actually mean that it’s necessarily true, "
"especially in the case of the null hypothesis), many people will disagree. "
"And more to the point, you should be aware that this particular weirdness "
"exists so that you’re not caught unawares by it when writing up your own "
"results."
msgstr ""
"En parentes om språket du bruker når du snakker om hypotesetesting. For det "
"første er det en ting du virkelig bør unngå, og det er ordet «bevise». En "
"statistisk test *beviser* egentlig ikke at en hypotese er sann eller usann. "
"Bevis innebærer sikkerhet, og som det sies, betyr statistikk at man aldri "
"trenger å si at man er sikker. På det punktet vil nesten alle være enige. "
"Men utover det er det en god del forvirring. Noen hevder at man bare har lov "
"til å komme med utsagn som «kunne forkaste nullhypotesen», «ikke kunne "
"forkaste nullhypotesen» eller eventuelt «må beholde nullhypotesen». Ifølge "
"denne tankegangen kan man ikke si ting som «kunne akseptere "
"alternativhypotesen» eller «kunne akseptere nullhypotesen». Personlig synes "
"jeg dette er for sterkt. Etter min mening blander dette sammen "
"nullhypotesetesting med Karl Poppers falsifikasjonistiske syn på den "
"vitenskapelige prosessen. Selv om det finnes likheter mellom "
"falsifikasjonisme og nullhypotesetesting, er de ikke ekvivalente. Selv om "
"jeg personlig synes det er greit å snakke om å akseptere en hypotese (med "
"forbehold om at «aksept» ikke betyr at den nødvendigvis er sann, særlig når "
"det gjelder nullhypotesen), er det mange som er uenige i dette. Og i tillegg "
"bør du være klar over at denne merkeligheten eksisterer, slik at du ikke "
"blir overrasket over den når du skriver om dine egne resultater."

#: ../../Ch09/Ch09_HypothesisTesting_03.rst:4
msgid "Test statistics and sampling distributions"
msgstr "Teststatistikk og utvalgsfordelinger"

#: ../../Ch09/Ch09_HypothesisTesting_03.rst:6
msgid ""
"At this point we need to start talking specifics about how a hypothesis test "
"is constructed. To that end, let’s return to the ESP example. Let’s ignore "
"the actual data that we obtained, for the moment, and think about the "
"structure of the experiment. Regardless of what the actual numbers are, the "
"*form* of the data is that *X* out of *N* people correctly identified the "
"colour of the hidden card. Moreover, let’s suppose for the moment that the "
"null hypothesis really is true, that ESP doesn’t exist and the true "
"probability that anyone picks the correct colour is exactly *θ* = 0.5. What "
"would we *expect* the data to look like? Well, obviously we’d expect the "
"proportion of people who make the correct response to be pretty close to 50\\"
"%. Or, to phrase this in more mathematical terms, we’d say that *X* / *N* is "
"approximately \\0.5. Of course, we wouldn’t expect this fraction to be "
"*exactly* \\0.5. If, for example, we tested *N* = 100 people and *X* = 53 of "
"them got the question right, we’d probably be forced to concede that the "
"data are quite consistent with the null hypothesis. On the other hand, if "
"*X* = 99 of our participants got the question right then we’d feel pretty "
"confident that the null hypothesis is wrong. Similarly, if only *X* = 3 "
"people got the answer right we’d be similarly confident that the null was "
"wrong. Let’s be a little more technical about this. We have a quantity *X* "
"that we can calculate by looking at our data. After looking at the value of "
"*X* we make a decision about whether to believe that the null hypothesis is "
"correct, or to reject the null hypothesis in favour of the alternative. The "
"name for this thing that we calculate to guide our choices is a **test "
"statistic**."
msgstr ""
"På dette punktet må vi begynne å snakke mer spesifikt om hvordan en "
"hypotesetest er konstruert. La oss derfor gå tilbake til ESP-eksempelet. La "
"oss for øyeblikket se bort fra de faktiske dataene vi fikk, og heller tenke "
"på strukturen i eksperimentet. Uavhengig av hva de faktiske tallene er, er "
"*formen* på dataene at *X* av *N* personer identifiserte fargen på det "
"skjulte kortet korrekt. La oss videre anta at nullhypotesen virkelig er "
"sann, at ESP ikke eksisterer, og at den sanne sannsynligheten for at noen "
"velger riktig farge er nøyaktig *θ* = 0,5. Hvordan ville vi *forventet* at "
"dataene skulle se ut? Vel, vi forventer selvsagt at andelen personer som "
"svarer riktig, er ganske nær 50\\%. Eller, for å uttrykke dette i mer "
"matematiske termer, vi vil si at *X* / *N* er omtrent \\0,5. Vi forventer "
"selvfølgelig ikke at denne brøken skal være *nøyaktig* \\0,5. Hvis vi for "
"eksempel testet *N* = 100 personer, og *X* = 53 av dem svarte riktig på "
"spørsmålet, må vi nok innrømme at dataene stemmer ganske godt overens med "
"nullhypotesen. Hvis derimot *X* = 99 av deltakerne våre hadde rett på "
"spørsmålet, ville vi føle oss ganske sikre på at nullhypotesen er feil. "
"Tilsvarende, hvis bare *X* = 3 personer svarte riktig på spørsmålet, ville "
"vi være like sikre på at nullhypotesen var feil. La oss være litt mer "
"tekniske om dette. Vi har en størrelse *X* som vi kan beregne ved å se på "
"dataene våre. Etter å ha sett på verdien av *X* tar vi en beslutning om "
"hvorvidt vi skal tro at nullhypotesen er riktig, eller om vi skal forkaste "
"nullhypotesen til fordel for alternativhypotesen. Navnet på det vi beregner "
"for å styre valgene våre, er **teststatistikk**."

#: ../../Ch09/Ch09_HypothesisTesting_03.rst:33
msgid ""
"Having chosen a test statistic, the next step is to state precisely which "
"values of the test statistic would cause us to reject the null hypothesis, "
"and which values would cause us to keep it. In order to do so we need to "
"determine what the **sampling distribution of the test statistic** would be "
"if the null hypothesis were actually true (we talked about sampling "
"distributions earlier in :ref:`Sampling distribution of the mean "
"<sampling_distribution_of_the_mean>`). Why do we need this? Because this "
"distribution tells us exactly what values of *X* our null hypothesis would "
"lead us to expect. And, therefore, we can use this distribution as a tool "
"for assessing how closely the null hypothesis agrees with our data."
msgstr ""
"Når vi har valgt en teststatistikk, er neste trinn å angi nøyaktig hvilke "
"verdier av teststatistikken som ville fått oss til å forkaste nullhypotesen, "
"og hvilke verdier som ville fått oss til å beholde den. For å gjøre dette må "
"vi finne ut hva **samplingsfordelingen til teststatistikken** ville vært "
"hvis nullhypotesen faktisk var sann (vi snakket om samplingsfordelinger "
"tidligere i :ref:`Samplingsfordeling av gjennomsnittet "
"<sampling_distribution_of_the_mean>`). Hvorfor trenger vi dette? Fordi denne "
"fordelingen forteller oss nøyaktig hvilke verdier av *X* nullhypotesen vår "
"ville føre til at vi forventer. Og derfor kan vi bruke denne fordelingen som "
"et verktøy for å vurdere hvor godt nullhypotesen stemmer overens med dataene "
"våre."

#: ../../Ch09/Ch09_HypothesisTesting_03.rst:46
msgid "Sampling distribution when the null hypothesis is true"
msgstr "Utvalgsfordeling når nullhypotesen er sann"

#: ../../Ch09/Ch09_HypothesisTesting_03.rst:50
msgid ""
"The sampling distribution for our test statistic X when the null hypothesis "
"is true. For our ESP scenario this is a binomial distribution. Not "
"surprisingly, since the null hypothesis says that the probability of a "
"correct response is θ = 0.5, the sampling distribution says that the most "
"likely value is 50 (out of 100) correct responses. Most of the probability "
"mass lies between 40 and 60."
msgstr ""
"Utvalgsfordelingen for teststatistikken X når nullhypotesen er sann. For "
"vårt ESP-scenario er dette en binomisk fordeling. Ikke overraskende, siden "
"nullhypotesen sier at sannsynligheten for et riktig svar er θ = 0,5, sier "
"utvalgsfordelingen at den mest sannsynlige verdien er 50 (av 100) riktige "
"svar. Mesteparten av sannsynlighetsmassen ligger mellom 40 og 60."

#: ../../Ch09/Ch09_HypothesisTesting_03.rst:59
msgid ""
"How do we actually determine the sampling distribution of the test "
"statistic? For a lot of hypothesis tests this step is actually quite "
"complicated, and later on in the book you’ll see me being slightly evasive "
"about it for some of the tests (some of them I don’t even understand "
"myself). However, sometimes it’s very easy. And, fortunately for us, our ESP "
"example provides us with one of the easiest cases. Our population parameter "
"*θ* is just the overall probability that people respond correctly when asked "
"the question, and our test statistic *X* is the *count* of the number of "
"people who did so out of a sample size of *N*. We’ve seen a distribution "
"like this before, in section :doc:`../Ch07/Ch07_Probability_4`, and that’s "
"exactly what the binomial distribution describes! So, to use the notation "
"and terminology that I introduced in that section, we would say that the "
"null hypothesis predicts that *X* is binomially distributed, which is "
"written:"
msgstr ""
"Hvordan bestemmer vi egentlig utvalgsfordelingen til teststatistikken? For "
"mange hypotesetester er dette trinnet faktisk ganske komplisert, og senere i "
"boken vil du se at jeg er litt unnvikende når det gjelder noen av testene "
"(noen av dem forstår jeg ikke engang selv). Noen ganger er det imidlertid "
"veldig enkelt. Og heldigvis for oss har vi i ESP-eksempelet vårt et av de "
"enkleste tilfellene. Populasjonsparameteren *θ* er bare den generelle "
"sannsynligheten for at folk svarer riktig når de blir stilt spørsmålet, og "
"teststatistikken *X* er *antallet* av personer som svarte riktig ut av et "
"utvalg på *N*. Vi har sett en slik fordeling før, i avsnitt :doc:`../Ch07/"
"Ch07_Probability_4`, og det er akkurat det binomialfordelingen beskriver! Så "
"for å bruke notasjonen og terminologien som jeg introduserte i det "
"avsnittet, vil vi si at nullhypotesen predikerer at *X* er binomialfordelt, "
"noe som skrives:"

#: ../../Ch09/Ch09_HypothesisTesting_03.rst:73
msgid "*X* ~ Binomial(θ, N)"
msgstr "*X* ~ Binomial(θ, N)"

#: ../../Ch09/Ch09_HypothesisTesting_03.rst:75
msgid ""
"Since the null hypothesis states that *θ* = 0.5 and our experiment has *N* = "
"100 people, we have the sampling distribution we need. This sampling "
"distribution is plotted in :numref:`fig-samplingDist`. No surprises really, "
"the null hypothesis says that *X* = 50 is the most likely outcome, and it "
"says that we’re almost certain to see somewhere between 40 and 60 correct "
"responses."
msgstr ""
"Siden nullhypotesen sier at *θ* = 0,5 og eksperimentet vårt har *N* = 100 "
"personer, har vi den utvalgsfordelingen vi trenger. Denne utvalgsfordelingen "
"er plottet i :numref:`fig-samplingDist`. Nullhypotesen sier at *X* = 50 er "
"det mest sannsynlige utfallet, og den sier at vi nesten helt sikkert vil se "
"et sted mellom 40 og 60 riktige svar."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:4
msgid "Making decisions"
msgstr "Å ta beslutninger"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:6
msgid ""
"Okay, we’re very close to being finished. We’ve constructed a test statistic "
"(*X*) and we chose this test statistic in such a way that we’re pretty "
"confident that if *X* is close to *N* / 2 then we should retain the null, "
"and if not we should reject it. The question that remains is this. Exactly "
"which values of the test statistic should we associate with the null "
"hypothesis, and exactly which values go with the alternative hypothesis? In "
"my ESP study, for example, I’ve observed a value of *X* = 62. What decision "
"should I make? Should I choose to believe the null hypothesis or the "
"alternative hypothesis?"
msgstr ""
"Ok, vi er nesten ferdige. Vi har konstruert en teststatistikk (*X*), og vi "
"valgte denne teststatistikken på en slik måte at vi er ganske sikre på at "
"hvis *X* er nær *N* / 2, bør vi beholde nullhypotesen, og hvis ikke bør vi "
"forkaste det. Spørsmålet som gjenstår er dette. Nøyaktig hvilke verdier av "
"teststatistikken skal vi knytte til nullhypotesen, og nøyaktig hvilke "
"verdier skal vi knytte til alternativhypotesen? I ESP-studien min har jeg "
"for eksempel observert en verdi på *X* = 62. Hvilken beslutning bør jeg ta? "
"Skal jeg velge å tro på nullhypotesen eller alternativhypotesen?"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:18
msgid "Critical regions and critical values"
msgstr "Kritiske områder og kritiske verdier"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:20
msgid ""
"To answer this question we need to introduce the concept of a **critical "
"region** for the test statistic *X*. The critical region of the test "
"corresponds to those values of *X* that would lead us to reject null "
"hypothesis (which is why the critical region is also sometimes called the "
"rejection region). How do we find this critical region? Well, let’s consider "
"what we know:"
msgstr ""
"For å svare på dette spørsmålet må vi introdusere begrepet **kritisk "
"region** for teststatistikken *X*. Testens kritiske region tilsvarer de "
"verdiene av *X* som vil føre til at vi forkaster nullhypotesen (derfor "
"kalles den kritiske regionen også forkastningsregionen). Hvordan finner vi "
"denne kritiske regionen? La oss ta utgangspunkt i det vi vet:"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:27
msgid ""
"*X* should be very big or very small in order to reject the null hypothesis."
msgstr ""
"*X* bør være veldig stor eller veldig liten for å forkaste nullhypotesen."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:30
msgid ""
"If the null hypothesis is true, the sampling distribution of *X* is "
"Binomial(0.5, N)."
msgstr ""
"Hvis nullhypotesen er sann, er utvalgsfordelingen til *X* Binomial(0,5, N)."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:33
msgid ""
"If α = 0.05, the critical region must cover 5\\% of this sampling "
"distribution."
msgstr ""
"Hvis α = 0,05, må det kritiske området dekke 5\\% av denne "
"utvalgsfordelingen."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:36
msgid ""
"It’s important to make sure you understand this last point. The critical "
"region corresponds to those values of *X* for which we would reject the null "
"hypothesis, and the sampling distribution in question describes the "
"probability that we would obtain a particular value of *X* if the null "
"hypothesis were actually true. Now, let’s suppose that we chose a critical "
"region that covers 20\\% of the sampling distribution, and suppose that the "
"null hypothesis is actually true. What would be the probability of "
"incorrectly rejecting the null? The answer is of course 20\\%. And, "
"therefore, we would have built a test that had an α level of 0.2. If we want "
"α = 0.05, the critical region is only *allowed* to cover 5\\% of the "
"sampling distribution of our test statistic."
msgstr ""
"Det er viktig at du forstår dette siste punktet. Den kritiske regionen "
"tilsvarer de verdiene av *X* som vi ville forkastet nullhypotesen for, og "
"den aktuelle utvalgsfordelingen beskriver sannsynligheten for at vi ville "
"fått en bestemt verdi av *X* hvis nullhypotesen faktisk var sann. La oss nå "
"anta at vi velger en kritisk region som dekker 20\\% av utvalgsfordelingen, "
"og at nullhypotesen faktisk er sann. Hva er sannsynligheten for at vi "
"feilaktig forkaster nullhypotesen? Svaret er selvfølgelig 20\\%. Og derfor "
"ville vi ha laget en test som hadde et α-nivå på 0,2. Hvis vi ønsker α = "
"0,05, *tillates* den kritiske regionen bare å dekke 5\\% av "
"utvalgsfordelingen til teststatistikken vår."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:51
msgid "Critical region associated with a two-sided test"
msgstr "Kritisk område forbundet med en tosidig test"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:55
msgid ""
"The critical region associated with the hypothesis test for the ESP study, "
"for a hypothesis test with a significance level of α = 0.05. The plot shows "
"the sampling distribution of X under the null hypothesis (i.e., same as :"
"numref:`fig-samplingDist`). The grey bars correspond to those values of X "
"for which we would retain the null hypothesis. The blue (darker shaded) bars "
"show the critical region, those values of X for which we would reject the "
"null. Because the alternative hypothesis is two-sided (i.e., allows both θ < "
"0.5 and θ > 0.5), the critical region covers both tails of the distribution. "
"To ensure an α level of 0.05, we need to ensure that each of the two regions "
"encompasses 2.5\\% of the sampling distribution."
msgstr ""
"Den kritiske regionen knyttet til hypotesetesten for ESP-studien, for en "
"hypotesetest med et signifikansnivå på α = 0,05. Plottet viser "
"utvalgsfordelingen til X under nullhypotesen (dvs. det samme som :numref:"
"`fig-samplingDist`). De grå søylene tilsvarer de verdiene av X som vi ville "
"beholdt nullhypotesen for. De blå (mørkere skraverte) søylene viser det "
"kritiske området, det vil si de verdiene av X der vi forkaster "
"nullhypotesen. Fordi alternativhypotesen er tosidig (dvs. at den tillater "
"både θ < 0,5 og θ > 0,5), dekker den kritiske regionen begge halene av "
"fordelingen. For å sikre et α-nivå på 0,05 må vi sørge for at hver av de to "
"regionene omfatter 2,5\\% av utvalgsfordelingen."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:68
msgid ""
"As it turns out those three things uniquely solve the problem. Our critical "
"region consists of the most *extreme values*, known as the **tails** of the "
"distribution. This is illustrated in :numref:`fig-rejectionRegion1`. If we "
"want α = 0.05 then our critical regions correspond to *X* ≤ 40` and *X* ≥ 60."
"\\ [#]_ That is, if the number of people saying “true” is between 41 and 59, "
"then we should retain the null hypothesis. If the number is between 0 to 40, "
"or between 60 to 100, then we should reject the null hypothesis. The numbers "
"40 and 60 are often referred to as the **critical values** since they define "
"the edges of the critical region."
msgstr ""
"Det viser seg at disse tre tingene løser problemet på en unik måte. Vår "
"kritiske region består av de mest *ekstreme verdiene*, kjent som **halene** "
"av fordelingen. Dette er illustrert i :numref:`fig-rejectionRegion1`. Hvis "
"vi ønsker α = 0,05, tilsvarer våre kritiske regioner *X* ≤ 40` og *X* ≥ 60."
"\\ [#]_ Det vil si at hvis antallet personer som sier «sant» ligger mellom "
"41 og 59, bør vi beholde nullhypotesen. Hvis tallet ligger mellom 0 og 40, "
"eller mellom 60 og 100, bør vi forkaste nullhypotesen. Tallene 40 og 60 "
"omtales ofte som de **kritiske verdiene**, siden de definerer kantene av det "
"kritiske området."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:78
msgid "At this point, our hypothesis test is essentially complete:"
msgstr "På dette tidspunktet er hypotesetesten vår i hovedsak fullført:"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:80
msgid "we choose an α level (e.g., α = 0.05;"
msgstr "velger vi et α-nivå (f.eks. α = 0,05;"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:82
msgid ""
"(2) come up with some test statistic (e.g., *X*) that does a good job (in "
"some meaningful sense) of comparing H\\ :sub:`0` to H\\ :sub:`1`;"
msgstr ""
"(2) finne en teststatistikk (f.eks. *X*) som gjør en god jobb (i en eller "
"annen meningsfull forstand) med å sammenligne H\\ :sub:`0` med H\\ :sub:`1`;"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:86
msgid ""
"(3) figure out the sampling distribution of the test statistic on the "
"assumption that the null hypothesis is true (in this case, binomial); and "
"then"
msgstr ""
"(3) finne ut utvalgsfordelingen til teststatistikken under forutsetning av "
"at nullhypotesen er sann (i dette tilfellet binomisk); og deretter"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:90
msgid ""
"(4) calculate the critical region that produces an appropriate α level (0-40 "
"and 60-100)."
msgstr ""
"(4) beregne det kritiske området som gir et passende α-nivå (0-40 og 60-100)."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:93
msgid ""
"All that we have to do now is calculate the value of the test statistic for "
"the real data (e.g., *X* = 62) and then compare it to the critical values to "
"make our decision. Since 62 is greater than the critical value of 60 we "
"would reject the null hypothesis. Or, to phrase it slightly differently, we "
"say that the test has produced a statistically **significant** result."
msgstr ""
"Alt vi trenger å gjøre nå, er å beregne verdien av teststatistikken for de "
"reelle dataene (f.eks. *X* = 62) og deretter sammenligne den med de kritiske "
"verdiene for å ta en beslutning. Siden 62 er større enn den kritiske verdien "
"på 60, vil vi forkaste nullhypotesen. Eller, for å si det på en litt annen "
"måte, vi sier at testen har gitt et statistisk **signifikant** resultat."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:101
msgid "A note on statistical “significance”"
msgstr "En merknad om statistisk «signifikans»"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:0
msgid ""
"*Like other occult techniques of divination, the statistical method has a "
"private jargon deliberately contrived to obscure its methods from non-"
"practitioners*."
msgstr ""
"* I likhet med andre okkulte spådomsteknikker har den statistiske metoden en "
"privat sjargong som bevisst er konstruert for å skjule metodene for ikke-"
"utøvere*."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:109
msgid "Attributed to G. O. Ashley\\ [#]_"
msgstr "Tilskrives G. O. Ashley\\ [#]_"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:111
msgid ""
"A very brief digression is in order at this point, regarding the word "
"“significant”. The concept of statistical significance is actually a very "
"simple one, but has a very unfortunate name. If the data allow us to reject "
"the null hypothesis, we say that “the result is *statistically "
"significant*”, which is often shortened to “the result is significant”. This "
"terminology is rather old and dates back to a time when “significant” just "
"meant something like “indicated”, rather than its modern meaning which is "
"much closer to “important”. As a result, a lot of modern readers get very "
"confused when they start learning statistics because they think that a "
"“significant result” must be an important one. It doesn’t mean that at all. "
"All that “statistically significant” means is that the data allowed us to "
"reject a null hypothesis. Whether or not the result is actually important in "
"the real world is a very different question, and depends on all sorts of "
"other things."
msgstr ""
"Her er det på sin plass med en kort digresjon om ordet «signifikant». "
"Begrepet statistisk signifikans er egentlig veldig enkelt, men har et svært "
"uheldig navn. Hvis dataene tillater oss å forkaste nullhypotesen, sier vi at "
"«resultatet er *statistisk signifikant*», noe som ofte forkortes til "
"«resultatet er signifikant». Denne terminologien er ganske gammel og stammer "
"fra en tid da «signifikant» bare betydde noe sånt som «indikerer at», i "
"stedet for den moderne betydningen, som er mye nærmere «betydelig». Derfor "
"blir mange moderne lesere veldig forvirret når de begynner å lære "
"statistikk, fordi de tror at et «signifikant resultat» må være et viktig "
"resultat. Det betyr ikke det i det hele tatt. Det eneste «statistisk "
"signifikant» betyr, er at dataene gjorde det mulig å forkaste en "
"nullhypotese. Hvorvidt resultatet faktisk er viktig i den virkelige verden, "
"er et helt annet spørsmål, og avhenger av en rekke andre ting."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:129
msgid "The difference between one-sided and two-sided tests"
msgstr "Forskjellen mellom ensidige og tosidige tester"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:131
msgid ""
"There’s one more thing I want to point out about the hypothesis test that "
"I’ve just constructed. If we take a moment to think about the statistical "
"hypotheses I’ve been using,"
msgstr ""
"Det er én ting til jeg vil påpeke om hypotesetesten som jeg nettopp har "
"konstruert. Hvis vi tar oss tid til å tenke på de statistiske hypotesene jeg "
"har brukt,"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:135
msgid "H\\ :sub:`0`: *θ* = 0.5"
msgstr "H\\ :sub:`0`: *θ* = 0.5"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:137
msgid "H\\ :sub:`1`: *θ* ≠ 0.5"
msgstr "H\\ :sub:`1`: *θ* ≠ 0.5"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:139
msgid ""
"we notice that the alternative hypothesis covers *both* the possibility that "
"*θ* < 0.5 and the possibility that *θ* > 0.5. This makes sense if I really "
"think that ESP could produce either better-than-chance performance *or* "
"worse-than-chance performance (and there are some people who think that). In "
"statistical language this is an example of a **two-sided test**. It’s called "
"this because the alternative hypothesis covers the area on both “sides” of "
"the null hypothesis, and as a consequence the critical region of the test "
"covers both tails of the sampling distribution (2.5\\% on either side if α = "
"0.05), as illustrated earlier in :numref:`fig-rejectionRegion1`."
msgstr ""
"legger vi merke til at alternativhypotesen dekker *både* muligheten for at "
"*θ* < 0,5 og muligheten for at *θ* > 0,5. Dette gir mening hvis jeg virkelig "
"tror at ESP kan gi enten bedre resultater enn sjansen *eller* dårligere "
"resultater enn sjansen (og det er det noen som tror). I statistisk språkbruk "
"er dette et eksempel på en **tosidig test**. Den kalles dette fordi "
"alternativhypotesen dekker området på begge «sider» av nullhypotesen, og som "
"en konsekvens dekker testens kritiske region begge halene av "
"utvalgsfordelingen (2,5\\% på hver side hvis α = 0,05), som illustrert "
"tidligere i :numref:`fig-rejectionRegion1`."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:150
msgid ""
"However, that’s not the only possibility. I might only be willing to believe "
"in ESP if it produces better than chance performance. If so, then my "
"alternative hypothesis would only covers the possibility that *θ* > 0.5, and "
"as a consequence the null hypothesis now becomes *θ* ≤ 0.5"
msgstr ""
"Men det er ikke den eneste muligheten. Jeg er kanskje bare villig til å tro "
"på ESP hvis det gir bedre resultater enn tilfeldighetene. I så fall vil min "
"alternativhypotese bare dekke muligheten for at *θ* > 0,5, og følgelig blir "
"nullhypotesen nå *θ* ≤ 0,5"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:156
msgid "H\\ :sub:`1`: *θ* ≤ 0.5"
msgstr "H\\ :sub:`1`: *θ* ≤ 0.5"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:158
msgid "H\\ :sub:`1`: *θ* > 0.5"
msgstr "H\\ :sub:`1`: *θ* > 0.5"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:160
msgid ""
"When this happens, we have what’s called a **one-sided test** and the "
"critical region only covers one tail of the sampling distribution. This is "
"illustrated in :numref:`fig-rejectionRegion2`."
msgstr ""
"Når dette skjer, har vi det som kalles en **ensidig test**, og den kritiske "
"regionen dekker bare den ene halen av utvalgsfordelingen. Dette er "
"illustrert i :numref:`fig-rejectionRegion2`."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:166
msgid "Critical region associated with a one-sided test"
msgstr "Kritisk område forbundet med en ensidig test"

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:170
msgid ""
"The critical region for a one-sided test. In this case, the alternative "
"hypothesis is that θ = 0.5 so we would only reject the null hypothesis for "
"large values of X. As a consequence, the critical region only covers the "
"upper tail of the sampling distribution, specifically the upper 5\\% of the "
"distribution. Contrast this to the two-sided version in :numref:`fig-"
"rejectionRegion1`."
msgstr ""
"Den kritiske regionen for en ensidig test. I dette tilfellet er "
"alternativhypotesen at θ = 0,5, så vi vil bare forkaste nullhypotesen for "
"store verdier av X. Som en konsekvens av dette dekker den kritiske regionen "
"bare den øvre halen av utvalgsfordelingen, nærmere bestemt de øvre 5\\% av "
"fordelingen. Sammenlign dette med den tosidige versjonen i :numref:`fig-"
"rejectionRegion1`."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:182
msgid ""
"Strictly speaking, the test I just constructed has α = 0.057, which is a bit "
"too generous. However, if I’d chosen 39 and 61 to be the boundaries for the "
"critical region then the critical region only covers 3.5\\% of the "
"distribution. I figured that it makes more sense to use 40 and 60 as my "
"critical values, and be willing to tolerate a 5.7\\% type I error rate, "
"since that’s as close as I can get to a value of α = 0.05."
msgstr ""
"Strengt tatt har testen jeg nettopp konstruerte α = 0,057, noe som er litt "
"for sjenerøst. Men hvis jeg hadde valgt 39 og 61 som grenser for den "
"kritiske regionen, ville den kritiske regionen bare dekket 3,5\\% av "
"fordelingen. Jeg tenkte at det er mer fornuftig å bruke 40 og 60 som "
"kritiske verdier, og være villig til å tolerere en type-I-feilrate på 5,7\\"
"%, siden det er så nærme jeg kan komme en verdi på α = 0,05."

#: ../../Ch09/Ch09_HypothesisTesting_04.rst:191
msgid ""
"The internet seems fairly convinced that Ashley said this, though I can’t "
"for the life of me find anyone willing to give a source for the claim."
msgstr ""
"Internett virker ganske overbevist om at Ashley sa dette, selv om jeg ikke "
"kan finne noen som er villig til å oppgi en kilde for påstanden."

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:4
msgid "The *p*-value of a test"
msgstr "*p*-verdien av en test"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:6
msgid ""
"In one sense, our hypothesis test is complete. We’ve constructed a test "
"statistic, figured out its sampling distribution if the null hypothesis is "
"true, and then constructed the critical region for the test. Nevertheless, "
"I’ve actually omitted the most important number of all, **the p-value**. It "
"is to this topic that we now turn. There are two somewhat different ways of "
"interpreting a *p*-value, one proposed by Sir Ronald Fisher and the other by "
"Jerzy Neyman. Both versions are legitimate, though they reflect very "
"different ways of thinking about hypothesis tests. Most introductory "
"textbooks tend to give Fisher’s version only, but I think that’s a bit of a "
"shame. To my mind, Neyman’s version is cleaner and actually better reflects "
"the logic of the null hypothesis test. You might disagree though, so I’ve "
"included both. I’ll start with Neyman’s version."
msgstr ""
"På én måte er hypotesetesten vår komplett. Vi har konstruert en "
"teststatistikk, funnet ut hvordan den fordeler seg hvis nullhypotesen er "
"sann, og deretter konstruert den kritiske regionen for testen. Likevel har "
"jeg faktisk utelatt det viktigste tallet av alle, nemlig **p-verdien**. Det "
"er dette vi nå skal se nærmere på. Det finnes to litt forskjellige måter å "
"tolke en *p*-verdi på, den ene foreslått av Sir Ronald Fisher og den andre "
"av Jerzy Neyman. Begge versjonene er legitime, selv om de gjenspeiler svært "
"ulike måter å tenke om hypotesetester på. De fleste innføringsbøker har en "
"tendens til å kun gi Fishers versjon, men det synes jeg er litt synd. Etter "
"min mening er Neymans versjon renere og gjenspeiler faktisk logikken i "
"nullhypotesetesten bedre. Men du er kanskje uenig, så jeg har tatt med "
"begge. Jeg begynner med Neymans versjon."

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:21
msgid "A softer view of decision making"
msgstr "Et mykere syn på beslutningstaking"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:23
msgid ""
"One problem with the hypothesis testing procedure that I’ve described is "
"that it makes no distinction at all between a result that is “barely "
"significant” and those that are “highly significant”. For instance, in my "
"ESP study the data I obtained only just fell inside the critical region, so "
"I did get a significant effect but it was a pretty near thing. In contrast, "
"suppose that I’d run a study in which *X* = 97 out of my *N* = 100 "
"participants got the answer right. This would obviously be significant too "
"but by a much larger margin, such that there’s really no ambiguity about "
"this at all. The procedure that I have already described makes no "
"distinction between the two. If I adopt the standard convention of allowing "
"α = 0.05 as my acceptable Type I error rate, then both of these are "
"significant results."
msgstr ""
"Et problem med hypotesetestingen jeg har beskrevet, er at den ikke skiller "
"mellom resultater som er «knapt signifikante» og de som er «svært "
"signifikante». I ESP-studien min falt dataene jeg fikk inn bare så vidt "
"innenfor det kritiske området, så jeg fikk riktignok en signifikant effekt, "
"men det var ganske nære på. Anta derimot at jeg hadde gjennomført en studie "
"der *X* = 97 av *N* = 100 deltakere fikk rett svar. Dette ville selvsagt "
"også være signifikant, men med en mye større margin, slik at det egentlig "
"ikke er noen tvetydighet om dette i det hele tatt. Prosedyren som jeg "
"allerede har beskrevet, skiller ikke mellom de to. Hvis jeg bruker "
"standardkonvensjonen om å tillate α = 0,05 som min akseptable type-I-"
"feilrate, er begge disse resultatene signifikante."

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:36
msgid ""
"This is where the *p*-value comes in handy. To understand how it works, "
"let’s suppose that we ran lots of hypothesis tests on the same data set, but "
"with a different value of α in each case. When we do that for my original "
"ESP data what we’d get is something like this:"
msgstr ""
"Det er her *p*-verdien kommer til nytte. For å forstå hvordan det fungerer, "
"la oss anta at vi kjørte mange hypotesetester på det samme datasettet, men "
"med en annen verdi av α i hvert tilfelle. Når vi gjør det for de "
"opprinnelige ESP-dataene mine, vil vi få noe sånt som dette:"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:43
msgid "Value of α"
msgstr "Verdien av α"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:43
msgid "0.05"
msgstr "0.05"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:43
msgid "0.04"
msgstr "0.04"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:43
msgid "0.03"
msgstr "0.03"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:43
msgid "0.02"
msgstr "0.02"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:43
msgid "0.01"
msgstr "0.01"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:45
msgid "Reject the null?"
msgstr "Avvise null?"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:45
msgid "Yes"
msgstr "Ja"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:45
msgid "No"
msgstr "Nei"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:48
msgid ""
"When we test the ESP data (*X* = 62 successes out of *N* = 100 "
"observations), using α levels of 0.03 and above, we’d always find ourselves "
"rejecting the null hypothesis. For α levels of 0.02 and below we always end "
"up retaining the null hypothesis. Therefore, somewhere between 0.02 and 0.03 "
"there must be a smallest value of α that would allow us to reject the null "
"hypothesis for this data. This is the *p*-value. As it turns out the ESP "
"data has *p* = 0.021. In short,"
msgstr ""
"Når vi tester ESP-dataene (*X* = 62 suksesser av *N* = 100 observasjoner), "
"og bruker α-nivåer på 0,03 og høyere, vil vi alltid forkaste nullhypotesen. "
"For α-nivåer på 0,02 og lavere ender vi alltid opp med å beholde "
"nullhypotesen. Et sted mellom 0,02 og 0,03 må det derfor finnes en minste "
"verdi av α som gjør at vi kan forkaste nullhypotesen for disse dataene. "
"Dette er *p*-verdien. Det viser seg at ESP-dataene har *p* = 0,021. Kort "
"oppsummert,"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:57
msgid ""
"*p* is defined to be the smallest Type I error rate (α) that you have to be "
"willing to tolerate if you want to reject the null hypothesis."
msgstr ""
"*p* er definert som den minste type-I-feilraten (α) som du må være villig "
"til å tolerere hvis du vil forkaste nullhypotesen."

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:61
msgid ""
"If it turns out that *p* describes an error rate that you find intolerable, "
"then you must retain the null. If you’re comfortable with an error rate "
"equal to *p*, then it’s okay to reject the null hypothesis in favour of your "
"preferred alternative."
msgstr ""
"Hvis det viser seg at *p* beskriver en feilrate som du synes er uakseptabel, "
"må du beholde nullhypotesen. Hvis du er komfortabel med en feilrate lik *p*, "
"er det greit å forkaste nullhypotesen til fordel for alternativhypotesen."

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:66
msgid ""
"In effect, *p* is a summary of all the possible hypothesis tests that you "
"could have run, taken across all possible α values. And as a consequence it "
"has the effect of “softening” our decision process. For those tests in which "
"*p* ≤ α you would have rejected the null hypothesis, whereas for those tests "
"in which *p* > α you would have retained the null. In my ESP study I "
"obtained *X* = 62 and as a consequence I’ve ended up with *p* = 0.021. So "
"the error rate I have to tolerate is 2.1\\%. In contrast, suppose my "
"experiment had yielded *X* = 97. What happens to my *p*-value now? This time "
"it’s shrunk to *p* = 1.36 · 10\\ :sup:`25`, which is a tiny, tiny\\ [#]_ "
"Type I error rate. For this second case I would be able to reject the null "
"hypothesis with a lot more confidence, because I only have to be “willing” "
"to tolerate a type I error rate of about 1 in 10 trillion trillion in order "
"to justify my decision to reject."
msgstr ""
"*p* er i realiteten en oppsummering av alle de mulige hypotesetestene du "
"kunne ha kjørt, fordelt på alle mulige α-verdier. Og som en konsekvens av "
"dette «myker» det opp beslutningsprosessen vår. For de testene der *p* ≤ α "
"ville du ha forkastet nullhypotesen, mens for de testene der *p* > α ville "
"du ha beholdt nullhypotesen. I ESP-studien min fikk jeg *X* = 62, og som en "
"konsekvens av dette endte jeg opp med *p* = 0,021. Feilprosenten jeg må "
"tolerere, er altså 2,1\\%. Anta derimot at eksperimentet mitt hadde gitt *X* "
"= 97. Hva skjer med *p*-verdien min nå? Denne gangen er den krympet til *p* "
"= 1,36 - 10\\ :sup:`25`, som er en bitteliten\\ [#]_ type-I-feilrate. I "
"dette andre tilfellet vil jeg kunne forkaste nullhypotesen med mye større "
"sikkerhet, fordi jeg bare trenger å være «villig» til å tolerere en type-I-"
"feilrate på ca. 1 av 10 billioner billioner for å kunne rettferdiggjøre min "
"beslutning om å forkaste."

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:83
msgid "The probability of extreme data"
msgstr "Sannsynligheten for ekstreme data"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:85
msgid ""
"The second definition of the *p*-value comes from Sir Ronald Fisher, and "
"it’s actually this one that you tend to see in most introductory statistics "
"textbooks. Notice how, when I constructed the critical region, it "
"corresponded to the *tails* (i.e., extreme values) of the sampling "
"distribution? That’s not a coincidence, almost all “good” tests have this "
"characteristic (good in the sense of minimising our type II error rate, β). "
"The reason for that is that a good critical region almost always corresponds "
"to those values of the test statistic that are least likely to be observed "
"if the null hypothesis is true. If this rule is true, then we can define the "
"*p*-value as the probability that we would have observed a test statistic "
"that is at least as extreme as the one we actually did get. In other words, "
"if the data are extremely implausible according to the null hypothesis, then "
"the null hypothesis is probably wrong."
msgstr ""
"Den andre definisjonen av *p*-verdien kommer fra Sir Ronald Fisher, og det "
"er faktisk denne man finner i de fleste innføringsbøker i statistikk. La du "
"merke til at da jeg konstruerte den kritiske regionen, korresponderte den "
"med *halene* (dvs. ekstremverdiene) i utvalgsfordelingen? Det er ikke "
"tilfeldig, nesten alle «gode» tester har denne egenskapen (gode i den "
"forstand at de minimerer type-II-feilraten vår, β). Grunnen til det er at en "
"god kritisk region nesten alltid tilsvarer de verdiene av teststatistikken "
"som det er minst sannsynlig å observere hvis nullhypotesen er sann. Hvis "
"denne regelen stemmer, kan vi definere *p*-verdien som sannsynligheten for "
"at vi ville ha observert en teststatistikk som er minst like ekstrem som den "
"vi faktisk fikk. Med andre ord, hvis dataene er ekstremt usannsynlige i "
"henhold til nullhypotesen, er nullhypotesen sannsynligvis feil."

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:101
msgid "A common mistake"
msgstr "En vanlig feil"

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:103
msgid ""
"Okay, so you can see that there are two rather different but legitimate ways "
"to interpret the *p*-value, one based on Neyman’s approach to hypothesis "
"testing and the other based on Fisher’s. Unfortunately, there is a third "
"explanation that people sometimes give, especially when they’re first "
"learning statistics, and it is *absolutely and completely wrong*. This "
"mistaken approach is to refer to the *p*-value as “the probability that the "
"null hypothesis is true”. It’s an intuitively appealing way to think, but "
"it’s wrong in two key respects. First, null hypothesis testing is a "
"frequentist tool and the frequentist approach to probability does *not* "
"allow you to assign probabilities to the null hypothesis. According to this "
"view of probability, the null hypothesis is either true or it is not, it "
"cannot have a “5\\% chance” of being true. Second, even within the Bayesian "
"approach, which does let you assign probabilities to hypotheses, the *p*-"
"value would not correspond to the probability that the null is true. This "
"interpretation is entirely inconsistent with the mathematics of how the *p*-"
"value is calculated. Put bluntly, despite the intuitive appeal of thinking "
"this way, there is no justification for interpreting a *p*-value this way. "
"Never do it."
msgstr ""
"Som du ser, finnes det altså to ganske forskjellige, men legitime måter å "
"tolke *p*-verdien på, den ene basert på Neymans tilnærming til "
"hypotesetesting, og den andre basert på Fishers. Dessverre finnes det en "
"tredje forklaring som folk av og til gir, særlig når de begynner å lære "
"statistikk, og den er *absolutt og fullstendig feil*. Denne feilaktige "
"tilnærmingen er å referere til *p*-verdien som «sannsynligheten for at "
"nullhypotesen er sann». Det er en intuitivt tiltalende måte å tenke på, men "
"det er feil på to viktige punkter. For det første er nullhypotesetesting et "
"frekventistisk verktøy, og den frekventistiske tilnærmingen til "
"sannsynlighet gjør det *ikke* mulig å tilordne sannsynligheter til "
"nullhypotesen. Ifølge dette synet på sannsynlighet er nullhypotesen enten "
"sann eller usann, den kan ikke ha en «5\\% sjanse» for å være sann. For det "
"andre vil *p*-verdien ikke tilsvare sannsynligheten for at nullhypotesen er "
"sann, selv innenfor den bayesianske tilnærmingen, som lar deg tilordne "
"sannsynligheter til hypoteser. Denne tolkningen er helt uforenlig med "
"matematikken bak hvordan *p*-verdien beregnes. For å si det rett ut: Til "
"tross for den intuitive appellen ved å tenke på denne måten, finnes det "
"ingen begrunnelse for å tolke en *p*-verdi på denne måten. Aldri gjør det."

#: ../../Ch09/Ch09_HypothesisTesting_05.rst:126
msgid ""
"That’s *p* = 0.000000000000000000000000136 for folks that don’t like "
"scientific notation!"
msgstr ""
"Det er *p* = 0,000000000000000000000000136 for folk som ikke liker "
"vitenskapelig notasjon!"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:4
msgid "Reporting the results of a hypothesis test"
msgstr "Rapportere resultatene av en hypotesetest"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:6
msgid ""
"When writing up the results of a hypothesis test there’s usually several "
"pieces of information that you need to report, but it varies a fair bit from "
"test to test. Throughout the rest of the book I’ll spend a little time "
"talking about how to report the results of different tests (see subsection :"
"ref:`How to report the results of the test <how_to_report_tests>` for a "
"particularly detailed example), so that you can get a feel for how it’s "
"usually done. However, regardless of what test you’re doing, the one thing "
"that you always have to do is say something about the *p*-value and whether "
"or not the outcome was significant."
msgstr ""
"Når du skal skrive resultatene av en hypotesetest, er det vanligvis flere "
"typer informasjon du må rapportere, men det varierer en god del fra test til "
"test. I resten av boken vil jeg bruke litt tid på å snakke om hvordan du kan "
"rapportere resultatene av ulike tester (se underavsnittet :ref:`Hvordan "
"rapportere resultatene av testen <how_to_report_tests>` for et spesielt "
"detaljert eksempel), slik at du kan få en følelse av hvordan det vanligvis "
"gjøres. Uansett hvilken test du gjør, må du imidlertid alltid si noe om *p*-"
"verdien og om resultatet var signifikant eller ikke."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:16
msgid ""
"The fact that you have to do this is unsurprising, it’s the whole point of "
"doing the test. What might be surprising is the fact that there is some "
"contention over exactly how you’re supposed to do it. Leaving aside those "
"people who completely disagree with the entire framework underpinning null "
"hypothesis testing, there’s a certain amount of tension that exists "
"regarding whether or not to report the exact *p*-value that you obtained, or "
"if you should state only that *p* < α for a significance level that you "
"chose in advance (e.g., *p* < 0.05)."
msgstr ""
"At du må gjøre dette er ikke overraskende, det er hele poenget med testen. "
"Det som kanskje er overraskende, er det faktum at det er uenighet om "
"nøyaktig hvordan du skal gjøre det. Hvis vi ser bort fra de som er helt "
"uenige i hele rammeverket som ligger til grunn for nullhypotesetesting, er "
"det en viss spenning knyttet til om du skal rapportere den eksakte *p*-"
"verdien du har fått, eller om du bare skal oppgi at *p* < α for et "
"signifikansnivå du har valgt på forhånd (f.eks. *p* < 0,05)."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:26
msgid "The issue"
msgstr "Problemstillingen"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:28
msgid ""
"To see why this is an issue, the key thing to recognise is that *p*-values "
"are *terribly* convenient. In practice, the fact that we can compute a *p*-"
"value means that we don’t actually have to specify any α level at all in "
"order to run the test. Instead, what you can do is calculate your *p*-value "
"and interpret it directly. If you get *p* = 0.062, then it means that you’d "
"have to be willing to tolerate a Type I error rate of 6.2\\% to justify "
"rejecting the null. If you personally find 6.2\\% intolerable then you "
"retain the null. Therefore, the argument goes, why don’t we just report the "
"actual *p*-value and let the reader make up their own minds about what an "
"acceptable Type I error rate is? This approach has the big advantage of "
"“softening” the decision making process. In fact, if you accept the Neyman "
"definition of the *p*-value, that’s the whole point of the *p*-value. We no "
"longer have a fixed significance level of α = 0.05 as a bright line "
"separating “accept” from “reject” decisions, and this removes the rather "
"pathological problem of being forced to treat *p* = 0.051 in a fundamentally "
"different way to *p* = 0.049."
msgstr ""
"For å forstå hvorfor dette er et problem, er det viktig å være klar over at "
"*p*-verdier er *forferdelig* praktiske. I praksis betyr det faktum at vi kan "
"beregne en *p*-verdi, at vi faktisk ikke trenger å spesifisere noe α-nivå "
"for å kjøre testen. I stedet kan du beregne *p*-verdien og tolke den "
"direkte. Hvis du får *p* = 0,062, betyr det at du må være villig til å "
"tolerere en type-I-feilrate på 6,2\\% for å rettferdiggjøre forkastelse av "
"nullhypotesen. Hvis du personlig synes at 6,2\\% er uakseptabelt, beholder "
"du nullhypotesen. Derfor, sier man, hvorfor ikke bare rapportere den "
"faktiske *p*-verdien og la leseren selv gjøre seg opp en mening om hva som "
"er en akseptabel type-I-feilrate? Denne tilnærmingen har den store fordelen "
"at den «myker opp» beslutningsprosessen. Hvis du aksepterer Neymans "
"definisjon av *p*-verdien, er det faktisk hele poenget med *p*-verdien. Vi "
"har ikke lenger et fast signifikansnivå på α = 0,05 som en skarp grense "
"mellom «akseptere»- og «forkaste»-beslutninger, og dette fjerner det ganske "
"patologiske problemet med å bli tvunget til å behandle *p* = 0,051 på en "
"fundamentalt annerledes måte enn *p* = 0,049."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:47
msgid ""
"This flexibility is both the advantage and the disadvantage to the *p*-"
"value. The reason why a lot of people don’t like the idea of reporting an "
"exact *p*-value is that it gives the researcher a bit *too much* freedom. In "
"particular, it lets you change your mind about what error tolerance you’re "
"willing to put up with *after* you look at the data. For instance, consider "
"my ESP experiment. Suppose I ran my test and ended up with a *p*-value of "
"0.09. Should I accept or reject? Now, to be honest, I haven’t yet bothered "
"to think about what level of Type I error I’m “really” willing to accept. I "
"don’t have an opinion on that topic. But I *do* have an opinion about "
"whether or not ESP exists, and I *definitely* have an opinion about whether "
"my research should be published in a reputable scientific journal. And "
"amazingly, now that I’ve looked at the data I’m starting to think that a 9\\"
"% error rate isn’t so bad, especially when compared to how annoying it would "
"be to have to admit to the world that my experiment has failed. So, to avoid "
"looking like I just made it up after the fact, I now say that my α is 0.1, "
"with the argument that a 10\\% type I error rate isn’t too bad and at that "
"level my test is significant! I win."
msgstr ""
"Denne fleksibiliteten er både fordelen og ulempen med *p*-verdien. Grunnen "
"til at mange ikke liker tanken på å rapportere en eksakt *p*-verdi, er at "
"det gir forskeren litt *for mye* frihet. Spesielt lar det deg ombestemme deg "
"om hvilken feiltoleranse du er villig til å akseptere *etter* at du har sett "
"på dataene. Tenk for eksempel på ESP-eksperimentet mitt. Anta at jeg kjørte "
"testen min og endte opp med en *p*-verdi på 0,09. Skal jeg akseptere eller "
"forkaste? For å være ærlig har jeg ennå ikke tenkt på hvilket nivå av type-I-"
"feil jeg «egentlig» er villig til å akseptere. Jeg har ingen mening om det "
"temaet. Men jeg *har* en mening om hvorvidt ESP eksisterer eller ikke, og "
"jeg *har* definitivt en mening om hvorvidt forskningen min bør publiseres i "
"et anerkjent vitenskapelig tidsskrift. Og nå som jeg har sett på dataene, "
"begynner jeg å tenke at en feilprosent på 9\\% ikke er så ille, spesielt "
"sammenlignet med hvor irriterende det ville være å måtte innrømme overfor "
"verden at eksperimentet mitt har mislyktes. Så for å unngå å se ut som om "
"jeg bare fant det opp i ettertid, sier jeg nå at α er 0,1, med argumentet om "
"at en type-I-feilrate på 10\\% ikke er så ille, og på det nivået er testen "
"min signifikant! Jeg vinner."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:66
msgid ""
"In other words, the worry here is that I might have the best of intentions, "
"and be the most honest of people, but the temptation to just “shade” things "
"a little bit here and there is really, really strong. As anyone who has ever "
"run an experiment can attest, it’s a long and difficult process and you "
"often get *very* attached to your hypotheses. It’s hard to let go and admit "
"the experiment didn’t find what you wanted it to find. And that’s the danger "
"here. If we use the “raw” *p*-value, people will start interpreting the data "
"in terms of what they *want* to believe, not what the data are actually "
"saying and, if we allow that, why are we even bothering to do science at "
"all? Why not let everyone believe whatever they like about anything, "
"regardless of what the facts are? Okay, that’s a bit extreme, but that’s "
"where the worry comes from. According to this view, you really *must* "
"specify your α value in advance and then only report whether the test was "
"significant or not. It’s the only way to keep ourselves honest."
msgstr ""
"Bekymringen her er med andre ord at jeg kan ha de beste intensjoner og være "
"den ærligste av mennesker, men fristelsen til å «nyansere» ting litt her og "
"der er veldig, veldig sterk. Alle som noen gang har gjennomført et "
"eksperiment, kan skrive under på at det er en lang og vanskelig prosess, og "
"at man ofte blir *veldig* knyttet til hypotesene sine. Det er vanskelig å gi "
"slipp og innrømme at eksperimentet ikke fant det du ville at det skulle "
"finne. Og det er det som er faren her. Hvis vi bruker den «rå» *p*-verdien, "
"vil folk begynne å tolke dataene ut fra hva de *ønsker* å tro, ikke ut fra "
"hva dataene faktisk sier, og hvis vi tillater det, hvorfor gidder vi i det "
"hele tatt å drive med vitenskap? Hvorfor ikke la alle tro hva de vil om hva "
"som helst, uavhengig av hva som er fakta? Ok, det er litt ekstremt, men det "
"er der bekymringen kommer fra. Ifølge dette synet *må* du virkelig "
"spesifisere α-verdien din på forhånd, og deretter bare rapportere om testen "
"var signifikant eller ikke. Det er den eneste måten å holde oss ærlige på."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:83
msgid "Two proposed solutions"
msgstr "To forslag til løsninger"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:85
msgid ""
"In practice, it’s pretty rare for a researcher to specify a single α level "
"ahead of time. Instead, the convention is that scientists rely on three "
"standard significance levels: 0.05, 0.01 and .001. When reporting your "
"results, you indicate which (if any) of these significance levels allow you "
"to reject the null hypothesis. This is summarised in :numref:`tab-"
"pvaltable`. This allows us to soften the decision rule a little bit, since "
"*p* < 0.01 implies that the data meet a stronger evidential standard than "
"*p* < 0.05 would. Nevertheless, since these levels are fixed in advance by "
"convention, it does prevent people choosing their α level after looking at "
"the data."
msgstr ""
"I praksis er det ganske sjelden at en forsker spesifiserer ett enkelt α-nivå "
"på forhånd. I stedet er det vanlig at forskere bruker tre standard "
"signifikansnivåer: 0,05, 0,01 og 0,001. Når du rapporterer resultatene dine, "
"angir du hvilke (om noen) av disse signifikansnivåene som gjør at du kan "
"forkaste nullhypotesen. Dette oppsummeres i :numref:`tab-pvaltable`. Dette "
"gjør det mulig for oss å myke opp beslutningsregelen litt, siden *p* < 0,01 "
"innebærer at dataene oppfyller en sterkere bevisstandard enn *p* < 0,05 "
"ville gjort. Siden disse nivåene er fastsatt på forhånd ved konvensjon, "
"forhindrer det likevel at folk velger α-nivå etter å ha sett på dataene."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:97
msgid ""
"A commonly adopted convention for reporting *p* values: in many places it is "
"conventional to report one of four different things (e.g., *p* < 0.05) as "
"shown below. I’ve included the “significance stars” notation (i.e., a \\* "
"indicates *p* < 0.05) because you sometimes see this notation produced by "
"statistical software. It’s also worth noting that some people will write *n."
"s.* (not significant) rather than *p* > 0.05."
msgstr ""
"En vanlig konvensjon for rapportering av *p*-verdier: Mange steder er det "
"vanlig å rapportere en av fire forskjellige ting (f.eks. *p* < 0,05), som "
"vist nedenfor. Jeg har tatt med notasjonen «signifikansstjerner» (dvs. at en "
"\\* indikerer *p* < 0,05) fordi man noen ganger ser denne notasjonen i "
"statistikkprogrammer. Det er også verdt å merke seg at noen vil skrive *n.s."
"* (ikke signifikant) i stedet for *p* > 0,05."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:107
msgid "Usual notation"
msgstr "Vanlig notasjon"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:107
msgid "Signif. stars"
msgstr "Signif. stjerner"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:107
msgid "English translation"
msgstr "Engelsk oversettelse"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:107
msgid "The null is…"
msgstr "Nullpunktet er…"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:110
msgid "*p* > 0.05"
msgstr "*p* > 0.05"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:110
msgid "The test wasn’t significant."
msgstr "Testen var ikke signifikant."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:110
msgid "Retained"
msgstr "Beholdes"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:112
msgid "*p* < 0.05"
msgstr "*p* < 0.05"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:112
msgid "\\*"
msgstr "\\*"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:112
msgid "The test was significant at α = 0.05; but not at α =.01 or α = 0.001."
msgstr ""
"Testen var signifikant ved α = 0,05, men ikke ved α = 0,01 eller α = 0,001."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:112
#: ../../Ch09/Ch09_HypothesisTesting_06.rst:116
#: ../../Ch09/Ch09_HypothesisTesting_06.rst:120
msgid "Rejected"
msgstr "Avvist"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:116
msgid "*p* < 0.01"
msgstr "*p* < 0.01"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:116
msgid "\\*\\*"
msgstr "\\*\\*"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:116
msgid ""
"The test was significant at α = 0.05 and α = 0.01; but not at α = 0.001."
msgstr ""
"Testen var signifikant ved α = 0,05 og α = 0,01, men ikke ved α = 0,001."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:120
msgid "*p* < 0.001"
msgstr "*p* < 0.001"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:120
msgid "\\*\\*\\*"
msgstr "\\*\\*\\*"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:120
msgid "The test was significant at all levels"
msgstr "Testen var signifikant på alle nivåer"

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:124
msgid ""
"Nevertheless, quite a lot of people still prefer to report exact *p*-values. "
"To many people, the advantage of allowing the reader to make up their own "
"mind about how to interpret *p* = 0.06 outweighs any disadvantages. In "
"practice, however, even among those researchers who prefer exact *p*-values "
"it is quite common to just write *p* < 0.001 instead of reporting an exact "
"value for small *p*. This is in part because a lot of software doesn’t "
"actually print out the *p*-value when it’s that small (e.g., SPSS just "
"writes *p* = 0.000 whenever *p* < 0.001), and in part because a very small "
"*p*-value can be kind of misleading. The human mind sees a number like "
"0.0000000001 and it’s hard to suppress the gut feeling that the evidence in "
"favour of the alternative hypothesis is a near certainty. In practice "
"however, this is usually wrong. Life is a big, messy, complicated thing, and "
"every statistical test ever invented relies on simplifications, "
"approximations and assumptions. As a consequence, it’s probably not "
"reasonable to walk away from *any* statistical analysis with a feeling of "
"confidence stronger than *p* < 0.001 implies. In other words, *p* < 0.001 is "
"really code for “as far as *this test* is concerned, the evidence is "
"overwhelming.”"
msgstr ""
"Likevel er det fortsatt ganske mange som foretrekker å rapportere eksakte "
"*p*-verdier. For mange veier fordelen med at leseren selv kan gjøre seg opp "
"en mening om hvordan *p* = 0,06 skal tolkes, tyngre enn ulempene. I praksis "
"er det imidlertid ganske vanlig, selv blant de forskerne som foretrekker "
"eksakte *p*-verdier, å bare skrive *p* < 0,001 i stedet for å rapportere en "
"eksakt verdi for små *p*. Dette skyldes delvis at mange dataprogrammer ikke "
"skriver ut *p*-verdien når den er så liten (SPSS skriver f.eks. bare *p* = "
"0,000 når *p* < 0,001), og delvis at en svært liten *p*-verdi kan være litt "
"misvisende. Når vi mennesker ser et tall som 0,0000000001, er det vanskelig "
"å undertrykke magefølelsen om at evidens for alternativhypotesen er så godt "
"som sikre. I praksis er dette imidlertid vanligvis feil. Livet er stort, "
"rotete og komplisert, og alle statistiske tester som noensinne er oppfunnet, "
"bygger på forenklinger, tilnærminger og antakelser. Derfor er det "
"sannsynligvis ikke rimelig å gå fra *enhver* statistisk analyse med en "
"følelse av tillit som er sterkere enn *p* < 0,001 tilsier. Med andre ord er "
"*p* < 0,001 egentlig en kode for «når det gjelder *denne testen*, er "
"bevisene overveldende»."

#: ../../Ch09/Ch09_HypothesisTesting_06.rst:144
msgid ""
"In light of all this, you might be wondering exactly what you should do. "
"There’s a fair bit of contradictory advice on the topic, with some people "
"arguing that you should report the exact *p*-value, and other people arguing "
"that you should use the tiered approach illustrated in :numref:`tab-"
"pvaltable`. As a result, the best advice I can give is to suggest that you "
"look at papers/reports written in your field and see what the convention "
"seems to be. If there doesn’t seem to be any consistent pattern, then use "
"whichever method you prefer."
msgstr ""
"I lys av alt dette lurer du kanskje på hva du bør gjøre. Det finnes en god "
"del motstridende råd om emnet, der noen hevder at du bør rapportere den "
"eksakte *p*-verdien, mens andre mener at du bør bruke den nivådelte "
"tilnærmingen som er illustrert i :numref:`tab-pvaltable`. Det beste rådet "
"jeg kan gi, er derfor å foreslå at du ser på artikler/rapporter som er "
"skrevet på ditt felt, og ser hva som ser ut til å være konvensjonen. Hvis "
"det ikke ser ut til å være noe konsistent mønster, kan du bruke den metoden "
"du foretrekker."

#: ../../Ch09/Ch09_HypothesisTesting_07.rst:4
msgid "Running the hypothesis test in practice"
msgstr "Utførelse av hypotesetesten i praksis"

#: ../../Ch09/Ch09_HypothesisTesting_07.rst:6
msgid ""
"At this point some of you might be wondering if this is a “real” hypothesis "
"test, or just a toy example that I made up. It’s real. In the previous "
"discussion I built the test from first principles, thinking that it was the "
"simplest possible problem that you might ever encounter in real life. "
"However, this test already exists. It’s called the *binomial test*, and it’s "
"implemented by jamovi as one of the statistical analyses available when you "
"hit the ``Frequencies`` button. To test the null hypothesis that the "
"response probability is one-half ``p = 0.5``,\\ [#]_ and using data in which "
"``x = 62`` of ``n = 100`` people made the correct response, available in the "
"|binomialtest|_ data set, we get the results shown in :numref:`fig-"
"binomialtest`."
msgstr ""
"Nå lurer kanskje noen av dere på om dette er en «ekte» hypotesetest, eller "
"om det bare er et lekeeksempel jeg har funnet på. Den er ekte. I den forrige "
"diskusjonen bygde jeg testen ut fra de første prinsippene, og tenkte at det "
"var det enkleste problemet man kunne støte på i det virkelige liv. Men denne "
"testen finnes allerede. Den kalles *binomialtest*, og den er implementert av "
"jamovi som en av de statistiske analysene som er tilgjengelige når du "
"trykker på ``Frequencies``-knappen. For å teste nullhypotesen om at "
"svarsannsynligheten er halvparten av ``p = 0.5``,\\ [#]_ og ved å bruke data "
"der ``x = 62`` av ``n = 100`` personer svarte riktig, tilgjengelig i "
"datasettet |binomialtest|_, får vi resultatene vist i :numref:`fig-"
"binomialtest`."

#: ../../Ch09/Ch09_HypothesisTesting_07.rst:20
#: ../../Ch09/Ch09_HypothesisTesting_07.rst:24
msgid "Binomial test analysis and results in jamovi"
msgstr "Binomisk testanalyse og resultater i jamovi"

#: ../../Ch09/Ch09_HypothesisTesting_07.rst:28
msgid ""
"Right now, this output looks pretty unfamiliar to you, but you can see that "
"it’s telling you more or less the right things. Specifically, the *p*-value "
"of 0.02 is less than the usual choice of α = 0.05, so you can reject the "
"null. We’ll talk a lot more about how to read this sort of output as we go "
"along, and after a while you’ll hopefully find it quite easy to read and "
"understand."
msgstr ""
"Akkurat nå ser dette resultatet ganske uvant ut for deg, men du kan se at "
"det forteller deg mer eller mindre de riktige tingene. Spesielt *p*-verdien "
"på 0,02 er mindre enn det vanlige valget av α = 0,05, så du kan forkaste "
"nullhypotesen. Vi kommer til å snakke mye mer om hvordan du leser denne "
"typen resultater etter hvert, og etter hvert vil du forhåpentligvis synes at "
"det er ganske enkelt å lese og forstå."

#: ../../Ch09/Ch09_HypothesisTesting_07.rst:38
msgid ""
"Note that the ``p`` here has nothing to do with a *p*-value. The ``p`` "
"argument in the jamovi binomial test corresponds to the probability of "
"making a correct response, according to the null hypothesis. In other words, "
"it’s the *θ* value."
msgstr ""
"Merk at ``p`` her ikke har noe med en *p*-verdi å gjøre. Argumentet ``p`` i "
"jamovi-binomialtesten tilsvarer sannsynligheten for å gi et riktig svar i "
"henhold til nullhypotesen. Det er med andre ord *θ*-verdien."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:4
msgid "Effect size, sample size and power"
msgstr "Effektstørrelse, utvalgsstørrelse og styrke"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:6
msgid ""
"In previous sections I’ve emphasised the fact that the major design "
"principle behind statistical hypothesis testing is that we try to control "
"our Type I error rate. When we fix α = 0.05 we are attempting to ensure that "
"only 5\\% of true null hypotheses are incorrectly rejected. However, this "
"doesn’t mean that we don’t care about Type II errors. In fact, from the "
"researcher’s perspective, the error of failing to reject the null when it is "
"actually false is an extremely annoying one. With that in mind, a secondary "
"goal of hypothesis testing is to try to minimise β, the Type II error rate, "
"although we don’t usually *talk* in terms of minimising Type II errors. "
"Instead, we talk about maximising the *power* of the test. Since power is "
"defined as 1 - β, this is the same thing."
msgstr ""
"I de foregående avsnittene har jeg understreket at det viktigste "
"designprinsippet bak statistisk hypotesetesting er at vi prøver å "
"kontrollere type-I-feilraten. Når vi setter α = 0,05, forsøker vi å sikre at "
"bare 5\\% av de sanne nullhypotesene forkastes feilaktig. Dette betyr "
"imidlertid ikke at vi ikke bryr oss om type-II-feil. Fra forskerens "
"perspektiv er det faktisk en ekstremt irriterende feil å ikke forkaste "
"nullhypotesen når den faktisk er falsk. Med dette i bakhodet er et sekundært "
"mål med hypotesetesting å forsøke å minimere β, type-II-feilraten, selv om "
"vi vanligvis ikke *snakker* om å minimere type-II-feil. I stedet snakker vi "
"om å maksimere testens *styrke*. Siden effekten er definert som 1 - β, er "
"dette det samme."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:19
msgid "The power function"
msgstr "Effektfunksjonen"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:23
msgid "Sampling distribution under the alternative hypothesis, θ = 0.55"
msgstr "Utvalgsfordeling under alternativhypotesen, θ = 0,55"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:27
msgid ""
"Sampling distribution under the alternative hypothesis for a population "
"parameter value of θ = 0.55. A reasonable proportion of the distribution "
"lies in the rejection region."
msgstr ""
"Utvalgsfordeling under alternativhypotesen for en populasjonsparameterverdi "
"på θ = 0,55. En rimelig andel av fordelingen ligger i forkastningsområdet."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:33
msgid ""
"Let’s take a moment to think about what a Type II error actually is. A Type "
"II error occurs when the alternative hypothesis is true, but we are "
"nevertheless unable to reject the null hypothesis. Ideally, we’d be able to "
"calculate a single number β that tells us the Type II error rate, in the "
"same way that we can set α = 0.05 for the Type I error rate. Unfortunately, "
"this is a lot trickier to do. To see this, notice that in my ESP study the "
"alternative hypothesis actually corresponds to lots of possible values of "
"*θ*. In fact, the alternative hypothesis corresponds to every value of *θ* "
"*except* 0.5. Let’s suppose that the true probability of someone choosing "
"the correct response is 55\\% (i.e., *θ* = 0.55). If so, then the *true* "
"sampling distribution for *X* is not the same one that the null hypothesis "
"predicts, as the most likely value for *X* is now 55 out of 100. Not only "
"that, the whole sampling distribution has now shifted, as shown in :numref:"
"`fig-rejectionRegion3`. The critical regions, of course, do not change. By "
"definition the critical regions are based on what the null hypothesis "
"predicts. What we’re seeing in this figure is the fact that when the null "
"hypothesis is wrong, a much larger proportion of the sampling distribution "
"distribution falls in the critical region. And of course that’s what should "
"happen. The probability of rejecting the null hypothesis is larger when the "
"null hypothesis is actually false! However *θ* = 0.55 is not the only "
"possibility consistent with the alternative hypothesis. Let’s instead "
"suppose that the true value of *θ* is actually 0.70. What happens to the "
"sampling distribution when this occurs? The answer, shown in :numref:`fig-"
"rejectionRegion4`, is that almost the entirety of the sampling distribution "
"has now moved into the critical region. Therefore, if *θ* = 0.70, the "
"probability of us correctly rejecting the null hypothesis (i.e., the power "
"of the test) is much larger than if *θ* = 0.55. In short, while *θ* = 0.55 "
"and *θ* = 0.70 are both part of the alternative hypothesis, the Type II "
"error rate is different."
msgstr ""
"La oss bruke et øyeblikk på å tenke over hva en type-II-feil egentlig er. En "
"type-II-feil oppstår når alternativhypotesen er sann, men vi likevel ikke "
"klarer å forkaste nullhypotesen. Ideelt sett skulle vi kunne beregne et "
"enkelt tall β som forteller oss type-II-feilraten, på samme måte som vi kan "
"sette α = 0,05 for type-I-feilraten. Dessverre er dette mye vanskeligere å "
"gjøre. For å se dette, legg merke til at i ESP-studien min tilsvarer "
"alternativhypotesen faktisk mange mulige verdier av *θ*. Faktisk tilsvarer "
"alternativhypotesen alle verdier av *θ* *unntatt* 0,5. La oss anta at den "
"sanne sannsynligheten for at noen velger riktig svar er 55\\% (dvs. *θ* = "
"0,55). I så fall er den *sanne* utvalgsfordelingen for *X* ikke den samme "
"som nullhypotesen predikerer, ettersom den mest sannsynlige verdien for *X* "
"nå er 55 av 100. Ikke bare det, hele utvalgsfordelingen har nå forskjøvet "
"seg, som vist i :numref:`fig-rejectionRegion3`. De kritiske regionene endres "
"selvfølgelig ikke. Per definisjon er de kritiske regionene basert på hva "
"nullhypotesen predikerer. Det vi ser i denne figuren, er at når "
"nullhypotesen er feil, faller en mye større andel av utvalgsfordelingen i "
"den kritiske regionen. Og det er selvfølgelig det som skal skje. "
"Sannsynligheten for å forkaste nullhypotesen er større når nullhypotesen "
"faktisk er falsk! Men *θ* = 0,55 er ikke den eneste muligheten som er "
"forenlig med alternativhypotesen. La oss i stedet anta at den sanne verdien "
"av *θ* faktisk er 0,70. Hva skjer med utvalgsfordelingen når dette "
"inntreffer? Svaret, som vises i :numref:`fig-rejectionRegion4`, er at nesten "
"hele utvalgsfordelingen nå har beveget seg inn i den kritiske regionen. Hvis "
"*θ* = 0,70, er sannsynligheten for at vi forkaster nullhypotesen korrekt "
"(dvs. testens styrke) mye større enn hvis *θ* = 0,55. Kort sagt, selv om *θ* "
"= 0,55 og *θ* = 0,70 begge er en del av alternativhypotesen, er type-II-"
"feilraten forskjellig."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:64
msgid "Sampling distribution under the alternative hypothesis, θ = 0.70"
msgstr "Utvalgsfordeling under alternativhypotesen θ = 0,70"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:68
msgid ""
"Sampling distribution under the alternative hypothesis for a population "
"parameter value of θ = 0.70. Almost all of the distribution lies in the "
"rejection region."
msgstr ""
"Utvalgsfordeling under alternativhypotesen for en populasjonsparameterverdi "
"på θ = 0,70. Nesten hele fordelingen ligger i forkastningsområdet."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:74
msgid ""
"What all this means is that the power of a test (i.e., 1 - β) depends on the "
"true value of *θ*. To illustrate this, I’ve calculated the expected "
"probability of rejecting the null hypothesis for all values of *θ*, and "
"plotted it in :numref:`fig-powerTheta`. This plot describes what is usually "
"called the **power function** of the test. It’s a nice summary of how good "
"the test is, because it actually tells you the power (1 - β) for all "
"possible values of *θ*. As you can see, when the true value of *θ* is very "
"close to 0.5, the power of the test drops very sharply, but when it is "
"further away, the power is large."
msgstr ""
"Alt dette betyr at testens styrke (dvs. 1 - β) avhenger av den sanne verdien "
"av *θ*. For å illustrere dette har jeg beregnet den forventede "
"sannsynligheten for å forkaste nullhypotesen for alle verdier av *θ*, og "
"plottet den i :numref:`fig-powerTheta`. Dette plottet beskriver det som "
"vanligvis kalles testens **power-funksjon**. Det er en fin oppsummering av "
"hvor god testen er, fordi den faktisk forteller deg styrken (1 - β) for alle "
"mulige verdier av *θ*. Som du kan se, faller testens styrke kraftig når den "
"sanne verdien av *θ* er svært nær 0,5, men når den ligger lenger unna, er "
"styrken stor."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:87
#: ../../Ch09/Ch09_HypothesisTesting_08.rst:224
msgid "Probability to reject the null hypothesis as function of θ"
msgstr "Sannsynligheten for å forkaste nullhypotesen som funksjon av θ"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:91
msgid ""
"The probability that we will reject the null hypothesis, plotted as a "
"function of the true value of θ. Obviously, the test is more powerful "
"(greater chance of correct rejection) if the true value of θ is very "
"different from the value that the null hypothesis specifies (i.e., θ = 0.5). "
"Notice that when θ actually is equal to 0.5 (plotted as a black dot), the "
"null hypothesis is in fact true and rejecting the null hypothesis in this "
"instance would be a Type I error."
msgstr ""
"Sannsynligheten for at vi forkaster nullhypotesen, plottet som en funksjon "
"av den sanne verdien av θ. Det er klart at testen er kraftigere (større "
"sjanse for korrekt forkastelse) hvis den sanne verdien av θ er svært "
"forskjellig fra den verdien som nullhypotesen angir (dvs. θ = 0,5). Legg "
"merke til at når θ faktisk er lik 0,5 (plottet som en svart prikk), er "
"nullhypotesen faktisk sann, og forkastelse av nullhypotesen vil i dette "
"tilfellet være en type-I-feil."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:102
msgid "Effect size"
msgstr "Effektstørrelse"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:0
msgid ""
"*Since all models are wrong the scientist must be alert to what is "
"importantly wrong. It is inappropriate to be concerned with mice when there "
"are tigers abroad*"
msgstr ""
"*Siden alle modeller er feil, må forskeren være oppmerksom på hva som er "
"viktige feil. Det er upassende å være opptatt av mus når det finnes tigre i "
"utlandet*"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:110
msgid ":ref:`George Box (1976) <Box_1976>`"
msgstr ":ref:`George Box (1976) <Box_1976>`"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:112
msgid ""
"The plot shown in :numref:`fig-powerTheta` captures a fairly basic point "
"about hypothesis testing. If the true state of the world is very different "
"from what the null hypothesis predicts then your power will be very high, "
"but if the true state of the world is similar to the null (but not "
"identical) then the power of the test is going to be very low. Therefore, "
"it’s useful to be able to have some way of quantifying how “similar” the "
"true state of the world is to the null hypothesis. A statistic that does "
"this is called a measure of **effect size** (:ref:`Cohen, 1988 "
"<Cohen_1988>`, :ref:`Ellis, 2010 <Ellis_2010>`)."
msgstr ""
"Plottet som vises i :numref:`fig-powerTheta`, viser et ganske grunnleggende "
"poeng om hypotesetesting. Hvis den sanne tilstanden i verden er svært "
"forskjellig fra det nullhypotesen forutsier, vil styrken være svært høy, men "
"hvis den sanne tilstanden i verden er lik nullhypotesen (men ikke identisk), "
"vil testens styrke være svært lav. Derfor er det nyttig å ha en måte å "
"kvantifisere hvor «lik» den sanne tilstanden i verden er nullhypotesen. En "
"statistikk som gjør dette, kalles et mål på **effektstørrelse** (:ref:"
"`Cohen, 1988 <Cohen_1988>`, :ref:`Ellis, 2010 <Ellis_2010>`)."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:121
msgid ""
"Effect size is defined slightly differently in different contexts (and so "
"this section just talks in general terms) but the qualitative idea that it "
"tries to capture is always the same. How big is the difference between the "
"*true* population parameters and the parameter values that are assumed by "
"the null hypothesis? In our ESP example, if we let *θ*\\ :sub:`0` = 0.5 "
"denote the value assumed by the null hypothesis and let *θ* denote the true "
"value, then a simple measure of effect size could be something like the "
"difference between the true value and null (i.e., *θ* - *θ*\\ :sub:`0`), or "
"possibly just the magnitude of this difference, abs(*θ* - *θ*\\ :sub:`0`)."
msgstr ""
"Effektstørrelse defineres litt ulikt i ulike sammenhenger (og i dette "
"avsnittet snakker vi derfor bare i generelle termer), men den kvalitative "
"ideen som den forsøker å fange opp, er alltid den samme. Hvor stor er "
"forskjellen mellom de *sanne* populasjonsparametrene og de parameterverdiene "
"som nullhypotesen forutsetter? Hvis vi i ESP-eksempelet vårt lar *θ*\\ :sub:"
"`0` = 0,5 betegne verdien som nullhypotesen antar, og lar *θ* betegne den "
"sanne verdien, kan et enkelt mål på effektstørrelse være noe sånt som "
"forskjellen mellom den sanne verdien og nullverdien (dvs. *θ* - *θ*\\ :sub:"
"`0`), eller eventuelt bare størrelsen på denne forskjellen, abs(*θ* - *θ*\\ :"
"sub:`0`)."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:132
msgid ""
"A crude guide to understanding the relationship between statistical "
"significance and effect sizes. Basically, if you don’t have a significant "
"result then the effect size is pretty meaningless because you don’t have any "
"evidence that it’s even real. On the other hand, if you do have a "
"significant effect but your effect size is small then there’s a pretty good "
"chance that your result (although real) isn’t all that interesting. However, "
"this guide is very crude. It depends a lot on what exactly you’re studying. "
"Small effects can be of massive practical importance in some situations. So "
"don’t take this table too seriously. It’s a rough guide at best."
msgstr ""
"En enkel guide til å forstå forholdet mellom statistisk signifikans og "
"effektstørrelser. I utgangspunktet er det slik at hvis du ikke har et "
"signifikant resultat, er effektstørrelsen ganske meningsløs, fordi du ikke "
"har noe bevis for at den er reell. På den annen side, hvis du har en "
"signifikant effekt, men effektstørrelsen er liten, er det stor sjanse for at "
"resultatet ditt (selv om det er reelt) ikke er så interessant. Denne "
"veiledningen er imidlertid svært grov. Det avhenger mye av hva du studerer. "
"Små effekter kan være av enorm praktisk betydning i noen situasjoner. Så "
"ikke ta denne tabellen for alvorlig. Den er i beste fall en grov guide."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:144
msgid "big effect size"
msgstr "stor effektstørrelse"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:144
msgid "small effect size"
msgstr "liten effektstørrelse"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:146
msgid "significant result"
msgstr "betydelig resultat"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:146
msgid "difference is real, and of practical importance"
msgstr "forskjellen er reell, og av praktisk betydning"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:146
msgid "difference is real, but might not be interesting"
msgstr "forskjellen er reell, men kanskje ikke interessant"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:149
msgid "non-significant result"
msgstr "ikke-signifikant resultat"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:149
msgid "no effect observed"
msgstr "ingen effekt observert"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:152
msgid ""
"Why calculate effect size? Let’s assume that you’ve run your experiment, "
"collected the data, and gotten a significant effect when you ran your "
"hypothesis test. Isn’t it enough just to say that you’ve gotten a "
"significant effect? Surely that’s the *point* of hypothesis testing? Well, "
"sort of. Yes, the point of doing a hypothesis test is to try to demonstrate "
"that the null hypothesis is wrong, but that’s hardly the only thing we’re "
"interested in. If the null hypothesis claimed that *θ* = 0.50 and we show "
"that it’s wrong, we’ve only really told half of the story. Rejecting the "
"null hypothesis implies that we believe that *θ* ≠ 0.50, but there’s a big "
"difference between *θ* = 0.51 and *θ* = 0.80. If we find that *θ* = 0.80, "
"then not only have we found that the null hypothesis is wrong, it appears to "
"be *very* wrong. On the other hand, suppose we’ve successfully rejected the "
"null hypothesis, but it looks like the true value of *θ* is only 0.51 (this "
"would only be possible with a very large study). Sure, the null hypothesis "
"is wrong but it’s not at all clear that we actually *care* because the "
"effect size is so small. In the context of my ESP study we might still care "
"since any demonstration of real psychic powers would actually be pretty cool,"
"\\ [#]_ but in other contexts a 1\\% difference usually isn’t very "
"interesting, even if it is a real difference. For instance, suppose we’re "
"looking at differences in high school exam scores between males and females "
"and it turns out that the female scores are 1\\% higher on average than the "
"males. If I’ve got data from thousands of students then this difference will "
"almost certainly be *statistically significant*, but regardless of how small "
"the *p*-value is it’s just not very interesting. You’d hardly want to go "
"around proclaiming a crisis in boys education on the basis of such a tiny "
"difference would you? It’s for this reason that it is becoming more standard "
"(slowly, but surely) to report some kind of standard measure of effect size "
"along with the the results of the hypothesis test. The hypothesis test "
"itself tells you whether you should believe that the effect you have "
"observed is real (i.e., not just due to chance), whereas the effect size "
"tells you whether or not you should care."
msgstr ""
"Hvorfor beregne effektstørrelse? La oss anta at du har gjennomført "
"eksperimentet ditt, samlet inn data og fått en signifikant effekt da du "
"kjørte hypotesetesten din. Holder det ikke bare å si at du har fått en "
"signifikant effekt? Det er vel det som er *poenget* med hypotesetesting? "
"Vel, på en måte. Ja, poenget med å gjøre en hypotesetest er å prøve å påvise "
"at nullhypotesen er feil, men det er neppe det eneste vi er interessert i. "
"Hvis nullhypotesen sier at *θ* = 0,50, og vi viser at den er feil, har vi "
"egentlig bare fortalt halvparten av historien. Å forkaste nullhypotesen "
"innebærer at vi tror at *θ* ≠ 0,50, men det er stor forskjell mellom *θ* = "
"0,51 og *θ* = 0,80. Hvis vi finner at *θ* = 0,80, har vi ikke bare funnet ut "
"at nullhypotesen er feil, den ser ut til å være *svært* feil. Anta derimot "
"at vi har forkastet nullhypotesen, men at det ser ut til at den sanne "
"verdien av *θ* bare er 0,51 (dette ville bare være mulig med en svært stor "
"studie). Nullhypotesen er feil, men det er slett ikke sikkert at vi faktisk "
"*bryr oss* om det, siden effektstørrelsen er så liten. I forbindelse med ESP-"
"studien min kan vi fortsatt bry oss, siden enhver demonstrasjon av ekte "
"synske evner faktisk ville vært ganske kult,\\ [#]_ men i andre sammenhenger "
"er en forskjell på 1\\% vanligvis ikke særlig interessant, selv om det er en "
"reell forskjell. Anta for eksempel at vi ser på forskjeller i "
"eksamenskarakterer mellom menn og kvinner på videregående skole, og det "
"viser seg at kvinnene i gjennomsnitt har 1\\% høyere poengsum enn mennene. "
"Hvis jeg har data fra tusenvis av elever, vil denne forskjellen nesten helt "
"sikkert være *statistisk signifikant*, men uansett hvor liten *p*-verdien "
"er, er det ikke særlig interessant. Du vil neppe gå rundt og proklamere en "
"krise i gutteutdanningen på grunnlag av en så liten forskjell, vil du vel? "
"Det er av denne grunn at det (sakte, men sikkert) begynner å bli mer vanlig "
"å rapportere et slags standardmål for effektstørrelse sammen med resultatene "
"av hypotesetesten. Selve hypotesetesten forteller deg om du bør tro at "
"effekten du har observert, er reell (dvs. ikke bare skyldes tilfeldigheter), "
"mens effektstørrelsen forteller deg om du bør bry deg eller ikke."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:188
msgid "Increasing the power of your study"
msgstr "Øke effekten av studien din"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:190
msgid ""
"Not surprisingly, scientists are fairly obsessed with maximising the power "
"of their experiments. We want our experiments to work and so we want to "
"maximise the chance of rejecting the null hypothesis if it is false (and of "
"course we usually want to believe that it is false!). As we’ve seen, one "
"factor that influences power is the effect size. So the first thing you can "
"do to increase your power is to increase the effect size. In practice, what "
"this means is that you want to design your study in such a way that the "
"effect size gets magnified. For instance, in my ESP study I might believe "
"that psychic powers work best in a quiet, darkened room with fewer "
"distractions to cloud the mind. Therefore I would try to conduct my "
"experiments in just such an environment. If I can strengthen people’s ESP "
"abilities somehow then the true value of *θ* will go up\\ [#]_ and therefore "
"my effect size will be larger. In short, clever experimental design is one "
"way to boost power, because it can alter the effect size."
msgstr ""
"Ikke overraskende er forskere ganske besatt av å maksimere styrken i "
"eksperimentene sine. Vi vil at eksperimentene våre skal fungere, og derfor "
"ønsker vi å maksimere sjansen for å forkaste nullhypotesen hvis den er falsk "
"(og selvfølgelig ønsker vi som regel å tro at den er falsk!). Som vi har "
"sett, er effektstørrelsen en faktor som påvirker styrken. Så det første du "
"kan gjøre for å øke styrken, er å øke effektstørrelsen. I praksis betyr "
"dette at du bør utforme studien på en slik måte at effektstørrelsen blir "
"større. I ESP-studien min kan jeg for eksempel tro at overnaturlige evner "
"fungerer best i et stille, mørkt rom med færre distraksjoner som kan "
"forstyrre tankene. Derfor vil jeg prøve å gjennomføre eksperimentene mine i "
"nettopp et slikt miljø. Hvis jeg på en eller annen måte kan styrke folks ESP-"
"evner, vil den sanne verdien av *θ* gå opp\\ [#]_, og dermed vil "
"effektstørrelsen min bli større. Kort sagt er et smart eksperimentelt design "
"en måte å øke effekten på, fordi det kan endre effektstørrelsen."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:206
msgid ""
"Unfortunately, it’s often the case that even with the best of experimental "
"designs you may have only a small effect. Perhaps, for example, ESP really "
"does exist but even under the best of conditions it’s very very weak. Under "
"those circumstances your best bet for increasing power is to increase the "
"sample size. In general, the more observations that you have available, the "
"more likely it is that you can discriminate between two hypotheses. If I ran "
"my ESP experiment with 10 participants and 7 of them correctly guessed the "
"colour of the hidden card you wouldn’t be terribly impressed. But if I ran "
"it with 10,000 participants, and 7,000 of them got the answer right, you "
"would be much more likely to think I had discovered something. In other "
"words, power increases with the sample size. This is illustrated in :numref:"
"`fig-powerN`, which shows the power of the test for a true parameter of *θ* "
"= 0.70 for all sample sizes *N* from 1 to 100, where I’m assuming that the "
"null hypothesis predicts that *θ*\\ :sub:`0` = 0.5."
msgstr ""
"Dessverre er det ofte slik at selv med de beste eksperimentelle designene "
"kan du bare få en liten effekt. Det kan for eksempel være at ESP virkelig "
"eksisterer, men selv under de beste forutsetninger er den svært svak. Under "
"slike omstendigheter er det beste alternativet for å øke effekten å øke "
"utvalgsstørrelsen. Jo flere observasjoner du har til rådighet, desto mer "
"sannsynlig er det at du kan skille mellom to hypoteser. Hvis jeg kjørte ESP-"
"eksperimentet mitt med 10 deltakere, og 7 av dem gjettet riktig farge på det "
"skjulte kortet, ville du ikke bli veldig imponert. Men hvis jeg kjørte det "
"med 10 000 deltakere, og 7 000 av dem hadde rett, ville du være mye mer "
"tilbøyelig til å tro at jeg hadde oppdaget noe. Med andre ord øker styrken "
"med utvalgsstørrelsen. Dette er illustrert i :numref:`fig-powerN`, som viser "
"testens styrke for en sann parameter på *θ* = 0,70 for alle "
"utvalgsstørrelser *N* fra 1 til 100, der jeg antar at nullhypotesen "
"predikerer at *θ*\\ :sub:`0` = 0,5."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:228
msgid ""
"The power of our test plotted as a function of the sample size N. In this "
"case, the true value of θ is 0.7 but the null hypothesis is that θ = 0.5. "
"Overall, larger *N* means greater power (the small zig-zags in this function "
"occur because of some odd interactions between θ, α and the fact that the "
"binomial distribution is discrete, it doesn’t matter for any serious "
"purpose)."
msgstr ""
"Testens styrke plottet som en funksjon av utvalgsstørrelsen N. I dette "
"tilfellet er den sanne verdien av θ 0,7, men nullhypotesen er at θ = 0,5. "
"Generelt betyr større *N* større styrke (de små sikksakkene i denne "
"funksjonen oppstår på grunn av noen merkelige interaksjoner mellom θ, α og "
"det faktum at binomialfordelingen er diskret, men det spiller ingen rolle "
"for noe seriøst formål)."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:237
msgid ""
"Because power is important, whenever you’re contemplating running an "
"experiment it would be pretty useful to know how much power you’re likely to "
"have. It’s never possible to know for sure since you can’t possibly know "
"what your real effect size is. However, it’s often (well, sometimes) "
"possible to guess how big it should be. If so, you can guess what sample "
"size you need! This idea is called **power analysis**, and if it’s feasible "
"to do it then it’s very helpful. It can tell you something about whether you "
"have enough time or money to be able to run the experiment successfully. "
"It’s increasingly common to see people arguing that power analysis should be "
"a required part of experimental design, so it’s worth knowing about. I don’t "
"discuss power analysis in this book, however. This is partly for a boring "
"reason and partly for a substantive one. The boring reason is that I haven’t "
"had time to write about power analysis yet. The substantive one is that I’m "
"still a little suspicious of power analysis. Speaking as a researcher, I "
"have very rarely found myself in a position to be able to do one. It’s "
"either the case that (a) my experiment is a bit non-standard and I don’t "
"know how to define effect size properly, or (b) I literally have so little "
"idea about what the effect size will be that I wouldn’t know how to "
"interpret the answers. Not only that, after extensive conversations with "
"someone who does stats consulting for a living (my wife, as it happens), I "
"can’t help but notice that in practice the *only* time anyone ever asks her "
"for a power analysis is when she’s helping someone write a grant "
"application. In other words, the only time any scientist ever seems to want "
"a power analysis in real life is when they’re being forced to do it by "
"bureaucratic process. It’s not part of anyone’s day to day work. In short, "
"I’ve always been of the view that whilst power is an important concept, "
"power *analysis* is not as useful as people make it sound, except in the "
"rare cases where (a) someone has figured out how to calculate power for your "
"actual experimental design and (b) you have a pretty good idea what the "
"effect size is likely to be.\\ [#]_ Maybe other people have had better "
"experiences than me, but I’ve personally never been in a situation where "
"both (a) and (b) were true. Maybe I’ll be convinced otherwise in the future, "
"and probably a future version of this book would include a more detailed "
"discussion of power analysis, but for now this is about as much as I’m "
"comfortable saying about the topic."
msgstr ""
"Fordi effekt er viktig, vil det alltid være nyttig å vite hvor stor effekt "
"du sannsynligvis har når du vurderer å gjennomføre et eksperiment. Det er "
"aldri mulig å vite det helt sikkert, siden du umulig kan vite hva den reelle "
"effektstørrelsen er. Men det er ofte (vel, noen ganger) mulig å gjette hvor "
"stor den bør være. I så fall kan du gjette hvilken utvalgsstørrelse du "
"trenger! Dette kalles **power-analyse**, og hvis det er mulig å gjøre det, "
"er det svært nyttig. Den kan fortelle deg noe om hvorvidt du har nok tid "
"eller penger til å kunne gjennomføre eksperimentet på en vellykket måte. Det "
"blir stadig vanligere å se folk som argumenterer for at power-analyse bør "
"være en obligatorisk del av forsøksdesignet, så det er verdt å kjenne til. "
"Jeg diskuterer imidlertid ikke effektanalyse i denne boken. Det er delvis av "
"en kjedelig grunn, og delvis av en substansiell grunn. Den kjedelige grunnen "
"er at jeg ikke har hatt tid til å skrive om power-analyse ennå. Den "
"vesentlige grunnen er at jeg fortsatt er litt skeptisk til maktanalyse. Som "
"forsker har jeg svært sjelden vært i en posisjon der jeg har kunnet gjøre en "
"slik analyse. Enten er det slik at (a) eksperimentet mitt er litt "
"ustandardisert og jeg ikke vet hvordan jeg skal definere effektstørrelsen "
"riktig, eller (b) jeg har bokstavelig talt så liten anelse om hva "
"effektstørrelsen vil være at jeg ikke vet hvordan jeg skal tolke svarene. "
"Ikke nok med det, etter lange samtaler med en som lever av å drive med "
"statistikkrådgivning (kona mi, forresten), kan jeg ikke unngå å legge merke "
"til at i praksis er den *eneste* gangen noen noensinne ber henne om en "
"effektanalyse, når hun hjelper noen med å skrive en søknad. Med andre ord, "
"den eneste gangen noen forskere ser ut til å ønske seg en maktanalyse i det "
"virkelige liv, er når de blir tvunget til å gjøre det av byråkratiske "
"prosesser. Det er ikke en del av noens daglige arbeid. Kort sagt har jeg "
"alltid vært av den oppfatning at selv om power er et viktig begrep, er power "
"*analyse* ikke så nyttig som folk får det til å høres ut som, bortsett fra i "
"de sjeldne tilfellene der (a) noen har funnet ut hvordan man beregner power "
"for det faktiske forsøksdesignet, og (b) du har en ganske god idé om hva "
"effektstørrelsen sannsynligvis vil være.\\ [#]_ Kanskje andre har bedre "
"erfaringer enn meg, men jeg har personlig aldri vært i en situasjon der både "
"(a) og (b) stemte. Kanskje blir jeg overbevist om noe annet i fremtiden, og "
"sannsynligvis vil en fremtidig versjon av denne boken inneholde en mer "
"detaljert diskusjon av effektanalyse, men foreløpig er dette omtrent så mye "
"jeg er komfortabel med å si om emnet."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:277
msgid ""
"Although in practice a very small effect size is worrying because even very "
"minor methodological flaws might be responsible for the effect, and in "
"practice no experiment is perfect so there are always methodological issues "
"to worry about."
msgstr ""
"Selv om en svært liten effektstørrelse i praksis er bekymringsfull, fordi "
"selv små metodiske feil kan være ansvarlige for effekten, og i praksis er "
"ingen eksperimenter perfekte, så det er alltid metodiske problemer å bekymre "
"seg for."

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:283
msgid ""
"Notice that the true population parameter *θ* doesn’t necessarily correspond "
"to an immutable fact of nature. In this context *θ* is just the true "
"probability that people would correctly guess the colour of the card in the "
"other room. As such the population parameter can be influenced by all sorts "
"of things. Of course, this is all on the assumption that ESP actually exists!"
msgstr ""
"Legg merke til at den sanne populasjonsparameteren *θ* ikke nødvendigvis "
"tilsvarer et uforanderlig faktum i naturen. I denne sammenhengen er *θ* bare "
"den sanne sannsynligheten for at folk vil gjette riktig farge på kortet i "
"det andre rommet. Populasjonsparameteren kan altså påvirkes av alle mulige "
"ting. Alt dette forutsetter selvfølgelig at ESP faktisk eksisterer!"

#: ../../Ch09/Ch09_HypothesisTesting_08.rst:291
msgid ""
"One possible exception to this is when researchers study the effectiveness "
"of a new medical treatment and they specify in advance what an important "
"effect size would be to detect, for example over and above any existing "
"treatment. In this way some information about the potential value of a new "
"treatment can be obtained."
msgstr ""
"Et mulig unntak fra dette er når forskere undersøker effekten av en ny "
"medisinsk behandling, og de på forhånd spesifiserer hva som er en viktig "
"effektstørrelse å oppdage, for eksempel i forhold til eksisterende "
"behandling. På denne måten kan man få noe informasjon om den potensielle "
"verdien av en ny behandling."

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:4
msgid "Some issues to consider"
msgstr "Noen spørsmål å ta stilling til"

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:6
msgid ""
"What I’ve described to you in this chapter is the orthodox framework for "
"null hypothesis significance testing (NHST). Understanding how NHST works is "
"an absolute necessity because it has been the dominant approach to "
"inferential statistics ever since it came to prominence in the early 20th "
"century. It’s what the vast majority of working scientists rely on for their "
"data analysis, so even if you hate it you need to know it. However, the "
"approach is not without problems. There are a number of quirks in the "
"framework, historical oddities in how it came to be, theoretical disputes "
"over whether or not the framework is right, and a lot of practical traps for "
"the unwary. I’m not going to go into a lot of detail on this topic, but I "
"think it’s worth briefly discussing a few of these issues."
msgstr ""
"Det jeg har beskrevet i dette kapittelet, er det ortodokse rammeverket for "
"signifikanstesting av nullhypoteser (NHST). Det er helt nødvendig å forstå "
"hvordan NHST fungerer, fordi det har vært den dominerende tilnærmingen til "
"inferensiell statistikk helt siden den ble kjent på begynnelsen av 1900-"
"tallet. Det er denne tilnærmingen de aller fleste forskere benytter seg av "
"når de analyserer data, så selv om du hater den, må du kunne den. "
"Tilnærmingen er imidlertid ikke uten problemer. Det er en rekke særegenheter "
"i rammeverket, historiske merkverdigheter i hvordan det ble til, teoretiske "
"tvister om hvorvidt rammeverket er riktig eller ikke, og mange praktiske "
"feller for den uforsiktige. Jeg skal ikke gå i detalj på dette temaet, men "
"jeg synes det er verdt å diskutere noen av disse problemene kort."

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:20
msgid "Neyman versus Fisher"
msgstr "Neyman mot Fisher"

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:22
msgid ""
"The first thing you should be aware of is that orthodox NHST is actually a "
"mash-up of two rather different approaches to hypothesis testing, one "
"proposed by Sir Ronald Fisher and the other proposed by Jerzy Neyman (see :"
"ref:`Lehmann, 2011 <Lehmann_2011>` for a historical summary). The history is "
"messy because Fisher and Neyman were real people whose opinions changed over "
"time, and at no point did either of them offer “the definitive statement” of "
"how we should interpret their work many decades later. That said, here’s a "
"quick summary of what I take these two approaches to be."
msgstr ""
"Det første du bør være klar over, er at ortodoks NHST faktisk er en blanding "
"av to ganske forskjellige tilnærminger til hypotesetesting, den ene "
"foreslått av Sir Ronald Fisher og den andre foreslått av Jerzy Neyman (se :"
"ref:`Lehmann, 2011 <Lehmann_2011>` for et historisk sammendrag). Historien "
"er rotete fordi Fisher og Neyman var virkelige mennesker hvis meninger "
"endret seg over tid, og ingen av dem kom på noe tidspunkt med «den "
"definitive uttalelsen» om hvordan vi skulle tolke arbeidet deres mange tiår "
"senere. Når det er sagt, her er en rask oppsummering av hva jeg oppfatter "
"disse to tilnærmingene som."

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:31
msgid ""
"First, let’s talk about Fisher’s approach. As far as I can tell, Fisher "
"assumed that you only had the one hypothesis (the null) and that what you "
"want to do is find out if the null hypothesis is inconsistent with the data. "
"From his perspective, what you should do is check to see if the data are "
"“sufficiently unlikely” according to the null. In fact, if you remember back "
"to our earlier discussion, that’s how Fisher defines the *p*-value. "
"According to Fisher, if the null hypothesis provided a very poor account of "
"the data then you could safely reject it. But, since you don’t have any "
"other hypotheses to compare it to, there’s no way of “accepting the "
"alternative” because you don’t necessarily have an explicitly stated "
"alternative. That’s more or less all there is to it."
msgstr ""
"La oss først snakke om Fishers tilnærming. Så vidt jeg kan se, antok Fisher "
"at du bare hadde én hypotese (nullhypotesen), og at det du ønsker å gjøre, "
"er å finne ut om nullhypotesen er inkonsistent med dataene. Fra hans "
"perspektiv er det du bør gjøre, å sjekke om dataene er «tilstrekkelig "
"usannsynlige» i henhold til nullhypotesen. Hvis du husker tilbake til vår "
"tidligere diskusjon, er det faktisk slik Fisher definerer *p*-verdien. "
"Ifølge Fisher kan du trygt forkaste nullhypotesen hvis den gir en svært "
"dårlig beskrivelse av dataene. Men siden du ikke har noen andre hypoteser å "
"sammenligne med, kan du ikke «akseptere alternativhypotesen», fordi du ikke "
"nødvendigvis har angitt en eksplisitt alternativhypotese. Det er mer eller "
"mindre alt som er å si."

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:44
msgid ""
"In contrast, Neyman thought that the point of hypothesis testing was as a "
"guide to action and his approach was somewhat more formal than Fisher’s. His "
"view was that there are multiple things that you could *do* (accept the null "
"or accept the alternative) and the point of the test was to tell you which "
"one the data support. From this perspective, it is critical to specify your "
"alternative hypothesis properly. If you don’t know what the alternative "
"hypothesis is, then you don’t know how powerful the test is, or even which "
"action makes sense. His framework genuinely requires a competition between "
"different hypotheses. For Neyman, the *p*-value didn’t directly measure the "
"probability of the data (or data more extreme) under the null, it was more "
"of an abstract description about which “possible tests” were telling you to "
"accept the null, and which “possible tests” were telling you to accept the "
"alternative."
msgstr ""
"Neyman mente derimot at poenget med hypotesetesting var å veilede til "
"handling, og hans tilnærming var noe mer formell enn Fishers. Han mente at "
"det er flere ting du kan *gjøre* (godta nullhypotesen eller godta "
"alternativhypotesen), og at poenget med testen er å fortelle deg hvilken av "
"dem dataene støtter. Ut fra dette perspektivet er det avgjørende å "
"spesifisere alternativhypotesen på riktig måte. Hvis du ikke vet hva "
"alternativhypotesen er, vet du ikke hvor kraftig testen er, eller hvilken "
"handling som er fornuftig. Rammeverket hans krever virkelig en konkurranse "
"mellom ulike hypoteser. For Neyman målte ikke *p*-verdien direkte "
"sannsynligheten for dataene (eller mer ekstreme data) under nullhypotesen, "
"den var mer en abstrakt beskrivelse av hvilke «mulige tester» som fortalte "
"deg at du skulle akseptere nullhypotesen, og hvilke «mulige tester» som "
"fortalte deg at du skulle akseptere alternativhypotesen."

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:59
msgid ""
"As you can see, what we have today is an odd mishmash of the two. We talk "
"about having both a null hypothesis and an alternative (Neyman), but "
"usually\\ [#]_ define the *p*-value in terms of extreme data (Fisher), but "
"we still have α values (Neyman). Some of the statistical tests have "
"explicitly specified alternatives (Neyman) but others are quite vague about "
"it (Fisher). And, according to some people at least, we’re not allowed to "
"talk about accepting the alternative (Fisher). It’s a mess, but I hope this "
"at least explains why it’s a mess."
msgstr ""
"Som du ser, er det vi har i dag en merkelig blanding av de to. Vi snakker om "
"å ha både en null- og en alternativhypotese (Neyman), men definerer "
"vanligvis\\ [#]_ *p*-verdien i form av ekstreme data (Fisher), men vi har "
"fortsatt α-verdier (Neyman). Noen av de statistiske testene har eksplisitt "
"spesifiserte alternativhypoteser (Neyman), mens andre er ganske vage "
"(Fisher). Og, i hvert fall ifølge noen, har vi ikke lov til å snakke om å "
"akseptere alternativhypotesen (Fisher). Det er et rot, men jeg håper dette i "
"det minste forklarer hvorfor det er et rot."

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:70
msgid "Bayesians versus frequentists"
msgstr "Bayesianere versus frekventister"

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:72
msgid ""
"Earlier on in this chapter I was quite emphatic about the fact that you "
"*cannot* interpret the *p*-value as the probability that the null hypothesis "
"is true. NHST is fundamentally a frequentist tool (see chapter :doc:`../Ch07/"
"Ch07_Probability`) and as such it does not allow you to assign probabilities "
"to hypotheses. The null hypothesis is either true or it is not. The Bayesian "
"approach to statistics interprets probability as a degree of belief, so it’s "
"totally okay to say that there is a 10\\% chance that the null hypothesis is "
"true. That’s just a reflection of the degree of confidence that you have in "
"this hypothesis. You aren’t allowed to do this within the frequentist "
"approach. Remember, if you’re a frequentist, a probability can only be "
"defined in terms of what happens after a large number of independent "
"replications (i.e., a long run frequency). If this is your interpretation of "
"probability, talking about the “probability” that the null hypothesis is "
"true is complete gibberish: a null hypothesis is either true or it is false. "
"There’s no way you can talk about a long run frequency for this statement. "
"To talk about “the probability of the null hypothesis” is as meaningless as "
"“the colour of freedom”. It doesn’t have one!"
msgstr ""
"Tidligere i dette kapittelet har jeg understreket at du *ikke* kan tolke *p*-"
"verdien som sannsynligheten for at nullhypotesen er sann. NHST er i bunn og "
"grunn et frekventistisk verktøy (se kapittel :doc:`../Ch07/"
"Ch07_Probability`), og som sådan lar det deg ikke tildele hypoteser "
"sannsynligheter. Nullhypotesen er enten sann eller usann. Den bayesianske "
"tilnærmingen til statistikk tolker sannsynlighet som en grad av tro, så det "
"er helt i orden å si at det er 10\\% sjanse for at nullhypotesen er sann. "
"Det er bare et uttrykk for graden av tillit du har til denne hypotesen. "
"Dette har du ikke lov til å gjøre innenfor den frekventistiske tilnærmingen. "
"Husk at hvis du er frekventist, kan en sannsynlighet bare defineres ut fra "
"hva som skjer etter et stort antall uavhengige replikasjoner (dvs. en "
"langtidsfrekvens). Hvis dette er din tolkning av sannsynlighet, er det "
"fullstendig tull å snakke om «sannsynligheten» for at nullhypotesen er sann: "
"En nullhypotese er enten sann eller usann. Det er umulig å snakke om en "
"langsiktig frekvens for denne påstanden. Å snakke om «sannsynligheten for "
"nullhypotesen» er like meningsløst som «frihetens farge». De finnes ikke!"

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:90
msgid ""
"Most importantly, this *isn’t* a purely ideological matter. If you decide "
"that you are a Bayesian and that you’re okay with making probability "
"statements about hypotheses, you have to follow the Bayesian rules for "
"calculating those probabilities. I’ll talk more about this in chapter :doc:"
"`../Ch16/Ch16_Bayes`, but for now what I want to point out to you is the *p*-"
"value is a *terrible* approximation to the probability that H\\ :sub:`0` is "
"true. If what you want to know is the probability of the null, then the *p*-"
"value is not what you’re looking for!"
msgstr ""
"Viktigst av alt er at dette *ikke* er et rent ideologisk spørsmål. Hvis du "
"bestemmer deg for at du er bayesianer og at du synes det er greit å si noe "
"om sannsynligheten for hypoteser, må du følge de bayesianske reglene for å "
"beregne disse sannsynlighetene. Jeg skal snakke mer om dette i kapittel :doc:"
"`../Ch16/Ch16_Bayes`, men foreløpig vil jeg bare påpeke at *p*-verdien er en "
"*forferdelig* tilnærming til sannsynligheten for at H\\ :sub:`0` er sann. "
"Hvis det du vil vite er sannsynligheten for null, så er ikke *p*-verdien det "
"du er ute etter!"

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:100
msgid "Traps"
msgstr "Feller"

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:102
msgid ""
"As you can see, the theory behind hypothesis testing is a mess, and even now "
"there are arguments in statistics about how it “should” work. However, "
"disagreements among statisticians are not our real concern here. Our real "
"concern is practical data analysis. And while the “orthodox” approach to "
"null hypothesis significance testing has many drawbacks, even an unrepentant "
"Bayesian like myself would agree that they can be useful if used "
"responsibly. Most of the time they give sensible answers and you can use "
"them to learn interesting things. Setting aside the various ideologies and "
"historical confusions that we’ve discussed, the fact remains that the "
"biggest danger in all of statistics is *thoughtlessness*. I don’t mean "
"stupidity, I literally mean thoughtlessness. The rush to interpret a result "
"without spending time thinking through what each test actually says about "
"the data, and checking whether that’s consistent with how you’ve interpreted "
"it. That’s where the biggest trap lies."
msgstr ""
"Som du ser, er teorien bak hypotesetesting et rot, og selv i dag er det "
"uenighet i statistikken om hvordan den «bør» fungere. Uenigheter blant "
"statistikere er imidlertid ikke det vi egentlig er opptatt av her. Det vi "
"virkelig er opptatt av, er praktisk dataanalyse. Og selv om den «ortodokse» "
"tilnærmingen til signifikanstesting av nullhypoteser har mange ulemper, vil "
"selv en uforbederlig bayesianer som meg være enig i at de kan være nyttige "
"hvis de brukes på en ansvarlig måte. Som oftest gir de fornuftige svar, og "
"du kan bruke dem til å lære interessante ting. Hvis vi ser bort fra de ulike "
"ideologiene og historiske forvirringene vi har diskutert, gjenstår det "
"faktum at den største faren i all statistikk er * tankeløshet*. Jeg mener "
"ikke dumhet, jeg mener bokstavelig talt tankeløshet. Det å tolke et resultat "
"i all hast uten å bruke tid på å tenke gjennom hva hver test faktisk sier om "
"dataene, og sjekke om det stemmer overens med hvordan du har tolket dem. Det "
"er der den største fellen ligger."

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:118
msgid ""
"To give an example of this, consider the following example (:ref:`Gelman & "
"Stern, 2006 <Gelman_2006>`). Suppose I’m running my ESP study and I’ve "
"decided to analyse the data separately for the male participants and the "
"female participants. Of the male participants, 33 out of 50 guessed the "
"colour of the card correctly. This is a significant effect (*p* = 0.03). Of "
"the female participants, 29 out of 50 guessed correctly. This is not a "
"significant effect (p = 0.32). Upon observing this, it is extremely tempting "
"for people to start wondering why there is a difference between males and "
"females in terms of their psychic abilities. However, this is wrong. If you "
"think about it, we haven’t *actually* run a test that explicitly compares "
"males to females. All we have done is compare males to chance (binomial test "
"was significant) and compared females to chance (binomial test was non "
"significant). If we want to argue that there is a real difference between "
"the males and the females, we should probably run a test of the null "
"hypothesis that there is no difference! We can do that using a different "
"hypothesis test,\\ [#]_ but when we do that it turns out that we have no "
"evidence that males and females are significantly different (*p* = 0.54). "
"*Now* do you think that there’s anything fundamentally different between the "
"two groups? Of course not. What’s happened here is that the data from both "
"groups (male and female) are pretty borderline. By pure chance one of them "
"happened to end up on the magic side of the *p* = 0.05 line, and the other "
"one didn’t. That doesn’t actually imply that males and females are "
"different. This mistake is so common that you should always be wary of it. "
"The difference between significant and not-significant is *not* evidence of "
"a real difference. If you want to say that there’s a difference between two "
"groups, then you have to test for that difference!"
msgstr ""
"For å gi et eksempel på dette kan vi se på følgende eksempel (:ref:`Gelman & "
"Stern, 2006 <Gelman_2006>`). Anta at jeg gjennomfører ESP-studien min og har "
"bestemt meg for å analysere dataene separat for de mannlige og de kvinnelige "
"deltakerne. Av de mannlige deltakerne gjettet 33 av 50 riktig farge på "
"kortet. Dette er en signifikant effekt (*p* = 0,03). Av de kvinnelige "
"deltakerne gjettet 29 av 50 riktig. Dette er ikke en signifikant effekt (p = "
"0,32). Når man observerer dette, er det svært fristende å begynne å lure på "
"hvorfor det er forskjell på menn og kvinners overnaturlige evner. Dette er "
"imidlertid feil. Hvis du tenker deg om, har vi *faktisk* ikke kjørt en test "
"som eksplisitt sammenligner menn med kvinner. Alt vi har gjort er å "
"sammenligne menn med tilfeldigheter (binomisk test var signifikant) og "
"sammenlignet kvinner med tilfeldigheter (binomisk test var ikke "
"signifikant). Hvis vi ønsker å argumentere for at det er en reell forskjell "
"mellom menn og kvinner, bør vi sannsynligvis kjøre en test av nullhypotesen "
"om at det ikke er noen forskjell! Det kan vi gjøre ved hjelp av en annen "
"hypotesetest,\\ [#]_ men når vi gjør det, viser det seg at vi ikke har noe "
"bevis for at menn og kvinner er signifikant forskjellige (*p* = 0,54). *Tror "
"du nå* at det er noe fundamentalt forskjellig mellom de to gruppene? Nei, "
"selvfølgelig ikke. Det som har skjedd her, er at dataene fra begge gruppene "
"(menn og kvinner) er ganske grensetilfelle. Ved en ren tilfeldighet havnet "
"en av dem på den magiske siden av *p* = 0,05-linjen, mens den andre ikke "
"gjorde det. Det betyr ikke at menn og kvinner er forskjellige. Denne feilen "
"er så vanlig at du alltid bør være på vakt mot den. Forskjellen mellom "
"signifikant og ikke-signifikant er *ikke* bevis på en reell forskjell. Hvis "
"du vil si at det er en forskjell mellom to grupper, må du teste for denne "
"forskjellen!"

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:145
msgid ""
"The example above is just that, an example. I’ve singled it out because it’s "
"such a common one, but the bigger picture is that data analysis can be "
"tricky to get right. Think about what it is you want to test, why you want "
"to test it, and whether or not the answers that your test gives could "
"possibly make any sense in the real world."
msgstr ""
"Eksemplet ovenfor er nettopp det, et eksempel. Jeg har valgt å trekke det "
"frem fordi det er så vanlig, men det store bildet er at dataanalyse kan være "
"vanskelig å gjøre riktig. Tenk over hva du ønsker å teste, hvorfor du ønsker "
"å teste det, og om svarene som testen gir, kan gi noen mening i den "
"virkelige verden."

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:154
msgid ""
"Although this book describes both Neyman’s and Fisher’s definition of the "
"*p*-value, most don’t. Most introductory textbooks will only give you the "
"Fisher version."
msgstr ""
"Selv om denne boken beskriver både Neymans og Fishers definisjon av *p*-"
"verdien, gjør de fleste det ikke. De fleste innføringsbøker gir deg bare "
"Fisher-versjonen."

#: ../../Ch09/Ch09_HypothesisTesting_09.rst:159
msgid ""
"In this case, the Pearson :doc:`χ²-test of independence <../Ch10/"
"Ch10_ChiSquare_2>`"
msgstr ""
"I dette tilfellet vil Pearson :doc:`χ²-test av uavhengighet <../Ch10/"
"Ch10_ChiSquare_2>`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:4
msgid "Summary"
msgstr "Sammendrag"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:6
msgid ""
"Null hypothesis testing is one of the most ubiquitous elements to "
"statistical theory. The vast majority of scientific papers report the "
"results of some hypothesis test or another. As a consequence it is almost "
"impossible to get by in science without having at least a cursory "
"understanding of what a *p*-value means, making this one of the most "
"important chapters in the book. As usual, I’ll end the chapter with a quick "
"recapitulation of the key ideas that we’ve talked about:"
msgstr ""
"Nullhypotesetesting er et av de mest utbredte elementene i statistisk teori. "
"De aller fleste vitenskapelige artikler rapporterer resultatene av en eller "
"annen hypotesetest. Som en konsekvens av dette er det nesten umulig å klare "
"seg i vitenskapen uten å ha i det minste en overfladisk forståelse av hva en "
"*p*-verdi betyr, noe som gjør dette til et av de viktigste kapitlene i "
"boken. Som vanlig avslutter jeg kapittelet med en rask oppsummering av de "
"viktigste ideene vi har snakket om:"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:14
msgid ""
":doc:`Research hypotheses and statistical hypotheses, Null and alternative "
"hypotheses <Ch09_HypothesisTesting_01>`"
msgstr ""
":doc:`Forskningshypoteser og statistiske hypoteser; Null- og "
"alternativhypoteser <Ch09_HypothesisTesting_01>`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:17
msgid ":doc:`Type I and Type II errors <Ch09_HypothesisTesting_02>`"
msgstr ":doc:`Type-I- og type-II-feil <Ch09_HypothesisTesting_02>`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:19
msgid ":doc:`Ch09_HypothesisTesting_03`"
msgstr ":doc:`Ch09_HypothesisTesting_03`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:21
msgid ""
":doc:`Hypothesis testing as a decision making process "
"<Ch09_HypothesisTesting_04>`"
msgstr ""
":doc:`Hypotesetesting som en beslutningsprosess <Ch09_HypothesisTesting_04>`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:24
msgid ":doc:`*p*-values as “soft” decisions <Ch09_HypothesisTesting_05>`"
msgstr ":doc:`*p*-verdier som «myke» beslutninger <Ch09_HypothesisTesting_05>`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:26
msgid ""
":doc:`Writing up the results of a hypothesis test "
"<Ch09_HypothesisTesting_06>`"
msgstr ""
":doc:`Skrive opp resultatene av en hypotesetest <Ch09_HypothesisTesting_06>`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:29
msgid ":doc:`Ch09_HypothesisTesting_07`"
msgstr ":doc:`Ch09_HypothesisTesting_07`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:31
msgid ":doc:`Ch09_HypothesisTesting_08`"
msgstr ":doc:`Ch09_HypothesisTesting_08`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:33
msgid ""
":doc:`Some issues to consider regarding hypothesis testing "
"<Ch09_HypothesisTesting_09>`"
msgstr ""
":doc:`Noen spørsmål å ta hensyn til ved hypotesetesting "
"<Ch09_HypothesisTesting_09>`"

#: ../../Ch09/Ch09_HypothesisTesting_10.rst:36
msgid ""
"Later in the book, in chapter :doc:`../Ch16/Ch16_Bayes`, I’ll revisit the "
"theory of null hypothesis tests from a Bayesian perspective and introduce a "
"number of new tools that you can use if you aren’t particularly fond of the "
"orthodox approach. But for now, though, we’re done with the abstract "
"statistical theory, and we can start discussing specific data analysis tools."
msgstr ""
"Senere i boken, i kapittel :doc:`../Ch16/Ch16_Bayes`, vil jeg gå gjennom "
"teorien om nullhypotesetester fra et bayesiansk perspektiv og introdusere en "
"rekke nye verktøy som du kan bruke hvis du ikke er spesielt glad i den "
"ortodokse tilnærmingen. Men nå er vi ferdige med den abstrakte statistiske "
"teorien, og vi kan begynne å diskutere konkrete verktøy for dataanalyse."
