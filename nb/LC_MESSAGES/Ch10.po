msgid ""
msgstr ""
"Project-Id-Version: Learning statistics with jamovi\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-06-12 11:37+0200\n"
"PO-Revision-Date: 2025-07-02 12:44+0000\n"
"Last-Translator: Anonymous <noreply@weblate.org>\n"
"Language-Team: Norwegian Bokmål <https://hosted.weblate.org/projects/lsjdocs/"
"ch10/nb_NO/>\n"
"Language: nb\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"X-Generator: Weblate 5.13-dev\n"
"Generated-By: Babel 2.10.3\n"

#: ../../Ch10/Ch10_ChiSquare.rst:4
msgid "Categorical data analysis"
msgstr "Analyse av kategoriale data"

#: ../../Ch10/Ch10_ChiSquare.rst:19
msgid ""
"Now that we’ve covered the basic theory behind hypothesis testing, it’s time "
"to start looking at specific tests that are commonly used in psychology. So "
"where should we start? Not every textbook agrees on where to start, but I’m "
"going to start with “χ² tests” (“Categorical data analysis”, this chapter) "
"and “*t*-tests” (chapter :doc:`../Ch11/Ch11_tTest`). Both of these tools are "
"very frequently used in scientific practice, and whilst they’re not as "
"powerful as “regression” (chapter :doc:`../Ch12/Ch12_Regression`) and "
"“Analysis of Variance” (chapters :doc:`../Ch13/Ch13_ANOVA` and :doc:`../Ch14/"
"Ch14_ANOVA2`) they’re much easier to understand. Finally, there is :doc:`../"
"Ch15/Ch15_FactorAnalysis` that aims to describe the  variability among "
"observed, correlated variables in terms of a lower number of unobserved "
"variables called factors or latent Variables."
msgstr ""
"Nå som vi har gjennomgått den grunnleggende teorien bak hypotesetesting, er "
"det på tide å begynne å se nærmere på spesifikke tester som ofte brukes i "
"psykologien. Så hvor skal vi begynne? Ikke alle lærebøker er enige om hvor "
"vi skal begynne, men jeg kommer til å starte med «χ²-tester» («Analyse av "
"kategoriale data», dette kapittelet) og «*t*-tester» (kapittel :doc:`../Ch11/"
"Ch11_tTest`). Begge disse verktøyene brukes svært ofte i vitenskapelig "
"praksis, og selv om de ikke er like potent som «regresjon» (kapittel :doc:"
"`../Ch12/Ch12_Regression`) og «variansanalyse» (kapitlene :doc:`../Ch13/"
"Ch13_ANOVA` og :doc:`../Ch14/Ch14_ANOVA2`), er de mye enklere å forstå. Til "
"slutt er det :doc:`../Ch15/Ch15_FactorAnalysis` som tar sikte på å beskrive "
"variasjonen blant observerte, korrelerte variabler i form av et lavere "
"antall uobserverte variabler kalt faktorer eller latente variabler."

#: ../../Ch10/Ch10_ChiSquare.rst:32
msgid ""
"The term “categorical data” in the title of this chapter is just another "
"name for “nominal scale data” |nominal|. It’s nothing that we haven’t "
"already discussed, it’s just that in the context of data analysis people "
"tend to use the term “categorical data” rather than “nominal scale data”. I "
"don’t know why. In any case, **categorical data analysis** refers to a "
"collection of tools that you can use when your data are nominal scale |"
"nominal|. Those tools are often called “χ² tests” (pronounced “chi-square”, "
"sometimes “chi-squared”). They determine whether there is a statistically "
"significant difference between expected and observed frequencies and whether "
"the observations follows a χ² frequency distribution. However, there are a "
"lot of different tools that can be used for categorical data analysis, and "
"this chapter covers only a few of the more common ones."
msgstr ""
"Begrepet «kategoriale data» i tittelen på dette kapittelet er bare et annet "
"navn for «data på nominalnivå» |nominal|. Det er ikke noe vi ikke allerede "
"har diskutert, men i forbindelse med dataanalyse har folk en tendens til å "
"bruke begrepet «kategoriale data» i stedet for «data på nominalnivå». Jeg "
"vet ikke helt hvorfor. Uansett, **analyse av kategoriale data** refererer "
"til en samling verktøy som du kan bruke når dataene dine er på nominalnivå |"
"nominal|. Disse verktøyene kalles ofte «χ²-tester» (uttales «kjikvadrat»; "
"*chi square*). De avgjør om det er en statistisk signifikant forskjell "
"mellom forventede og observerte frekvenser, og om observasjonene følger en "
"χ²-frekvensfordeling. Det finnes imidlertid mange ulike verktøy som kan "
"brukes til analyse av kategoriale data, og dette kapittelet tar bare for seg "
"noen få av de vanligste."

#: ../../Ch10/Ch10_ChiSquare.rst:47 ../../Ch10/Ch10_ChiSquare_1.rst:733
#: ../../Ch10/Ch10_ChiSquare_2.rst:327
msgid "nominal"
msgstr "nominal"

#: ../../Ch10/Ch10_ChiSquare_1.rst:4
msgid "The χ² (chi-square) goodness-of-fit test"
msgstr "χ²-test (kjikvadrat) for fordeling"

#: ../../Ch10/Ch10_ChiSquare_1.rst:6
msgid ""
"The χ² goodness-of-fit test is one of the oldest hypothesis tests around. It "
"was invented by :ref:`Karl Pearson (1900) <Pearson_1900>`, with some "
"corrections made later by :ref:`Sir Ronald Fisher (1922a) <Fisher_1922a>`. "
"It tests whether an observed frequency distribution of a nominal variable |"
"nominal| matches an expected frequency distribution. For example, suppose a "
"group of patients has been undergoing an experimental treatment and have had "
"their health assessed to see whether their condition has improved, stayed "
"the same or worsened. A goodness-of-fit test could be used to determine "
"whether the numbers in each category - improved, no change, worsened - match "
"the numbers that would be expected given the standard treatment option. "
"Let’s think about this some more, with some psychology."
msgstr ""
"χ²-testen er en av de eldste hypotesetestene som finnes. Den ble oppfunnet "
"av :ref:`Karl Pearson (1900) <Pearson_1900>`, med noen senere rettelser av :"
"ref:`Sir Ronald Fisher (1922a) <Fisher_1922a>`. Den tester om en observert "
"frekvensfordeling av en variabel på nominalnivå |nominal| stemmer overens "
"med en forventet frekvensfordeling. Anta for eksempel at en gruppe pasienter "
"har gjennomgått en eksperimentell behandling og har fått helsen sin vurdert "
"for å se om tilstanden deres har blitt bedre, uendret eller forverret seg. "
"En «goodness-of-fit»-test kan brukes til å avgjøre om tallene i hver "
"kategori - forbedret, ingen endring, forverret - samsvarer med tallene som "
"ville vært forventet gitt standard-behandlingsalternativ. La oss tenke litt "
"mer på dette, med litt psykologi."

#: ../../Ch10/Ch10_ChiSquare_1.rst:19
msgid "The cards data"
msgstr "Kortenes data"

#: ../../Ch10/Ch10_ChiSquare_1.rst:21
msgid ""
"Over the years there have been many studies showing that humans find it "
"difficult to simulate randomness. Try as we might to “act” random, we "
"*think* in terms of patterns and structure and so, when asked to “do "
"something at random”, what people actually do is anything but random. As a "
"consequence, the study of human randomness (or non-randomness, as the case "
"may be) opens up a lot of deep psychological questions about how we think "
"about the world. With this in mind, let’s consider a very simple study. "
"Suppose I asked people to imagine a shuffled deck of cards, and mentally "
"pick one card from this imaginary deck “at random”. After they’ve chosen one "
"card I ask them to mentally select a second one. For both choices what we’re "
"going to look at is the suit (hearts, clubs, spades or diamonds) that people "
"chose. After asking, say, *N* =200 people to do this, I’d like to look at "
"the data and figure out whether or not the cards that people pretended to "
"select were really random. The data are contained in the |randomness|_ data "
"set in which, when you open it up in jamovi and take a look at the "
"spreadsheet view, you will see three variables. These are: an ``id`` "
"variable that assigns a unique identifier to each participant, and the two "
"variables ``choice_1`` and ``choice_2`` that indicate the card suits that "
"people chose."
msgstr ""
"I årenes løp har det blitt gjennomført mange studier som viser at mennesker "
"har vanskelig for å simulere tilfeldigheter. Selv om vi prøver å «opptre» "
"tilfeldig, *tenker* vi i mønstre og strukturer, og når vi blir bedt om å "
"«gjøre noe tilfeldig», er det vi faktisk gjør alt annet enn tilfeldig. Som "
"en konsekvens av dette åpner studiet av menneskelig tilfeldighet (eller ikke-"
"tilfeldighet, alt etter som) opp for mange dype psykologiske spørsmål om "
"hvordan vi tenker om verden. Med dette i bakhodet, la oss se på en veldig "
"enkel studie. Anta at jeg ber folk forestille seg en kortstokk som er "
"blandet, og mentalt velge ett kort fra denne imaginære kortstokken "
"«tilfeldig». Etter at de har valgt ett kort, ber jeg dem om å mentalt velge "
"et annet kort. For begge valgene skal vi se på hvilken farge (hjerter, "
"kløver, spar eller ruter) folk valgte. Etter å ha bedt, la oss si, *N* =200 "
"personer om å gjøre dette, vil jeg gjerne se på dataene og finne ut om "
"kortene som folk lot som om de valgte, virkelig var tilfeldige eller ikke. "
"Dataene finnes i datasettet |randomness|_, og når du åpner det i jamovi og "
"tar en titt på regnearkvisningen, vil du se tre variabler. Disse er: en "
"``id``-variabel som tilordner en unik identifikator til hver deltaker, og de "
"to variablene ``choice_1`` og ``choice_2`` som angir hvilke kortfarger folk "
"valgte."

#: ../../Ch10/Ch10_ChiSquare_1.rst:40
msgid ""
"For the moment, let’s just focus on the first choice that people made. We’ll "
"use the ``Frequency tables`` option under ``Exploration`` → ``Descriptives`` "
"to count the number of times that we observed people choosing each suit. "
"This is what we get:"
msgstr ""
"For øyeblikket fokuserer vi bare på det første valget som folk gjorde. Vi "
"bruker ``Frequency tables`` under ``Exploration`` → ``Descriptives`` for å "
"telle antall ganger vi har observert at folk har valgt hver farge. Dette er "
"hva vi får:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:50
msgid ""
"That little frequency table is quite helpful. Looking at it, there’s a bit "
"of a hint that people *might* be more likely to select hearts than clubs, "
"but it’s not completely obvious just from looking at it whether that’s "
"really true, or if this is just due to chance. So we’ll probably have to do "
"some kind of statistical analysis to find out, which is what I’m going to "
"talk about in the next section."
msgstr ""
"Den lille frekvenstabellen er ganske nyttig. Når man ser på den, får man et "
"lite hint om at det *kan* være mer sannsynlig at folk velger hjerter enn "
"kløver, men det er ikke helt åpenbart bare ved å se på den om det virkelig "
"stemmer, eller om dette bare skyldes tilfeldigheter. Så vi må sannsynligvis "
"gjøre en eller annen form for statistisk analyse for å finne ut av det, og "
"det er det jeg skal snakke om i neste avsnitt."

#: ../../Ch10/Ch10_ChiSquare_1.rst:57
msgid ""
"Excellent. From this point on, we’ll treat this table as the data that we’re "
"looking to analyse. However, since I’m going to have to talk about this data "
"in mathematical terms (sorry!) it might be a good idea to be clear about "
"what the notation is. In mathematical notation, we shorten the human-"
"readable word “observed” to the letter *O*, and we use subscripts to denote "
"the position of the observation. So the second observation in our table is "
"written as *O*\\ :sub:`2` in maths. The relationship between the English "
"descriptions and the mathematical symbols are illustrated below:"
msgstr ""
"Utmerket. Fra nå av skal vi behandle denne tabellen som de dataene vi ønsker "
"å analysere. Men siden jeg er nødt til å snakke om disse dataene i "
"matematiske termer (beklager!), kan det være en god idé å være klar over hva "
"notasjonen er. I matematisk notasjon forkorter vi det lettleste ordet "
"«observert» til bokstaven *O*, og vi bruker subscripts for å angi "
"observasjonens posisjon. Den andre observasjonen i tabellen vår skrives "
"altså som *O*\\ :sub:`2` i matematikk. Forholdet mellom de engelske "
"beskrivelsene og de matematiske symbolene er illustrert nedenfor:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:67
msgid "label"
msgstr "etikett"

#: ../../Ch10/Ch10_ChiSquare_1.rst:67
msgid "index, *i*"
msgstr "indeks, *i*"

#: ../../Ch10/Ch10_ChiSquare_1.rst:67
msgid "math. symbol"
msgstr "matematisk symbol"

#: ../../Ch10/Ch10_ChiSquare_1.rst:67
msgid "the value"
msgstr "verdien"

#: ../../Ch10/Ch10_ChiSquare_1.rst:69
msgid "clubs (♣)"
msgstr "klubber (♣)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:69 ../../Ch10/Ch10_ChiSquare_1.rst:185
#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "1"
msgstr "1"

#: ../../Ch10/Ch10_ChiSquare_1.rst:69 ../../Ch10/Ch10_ChiSquare_1.rst:183
msgid "*O*\\ :sub:`1`"
msgstr "*O*\\ :sub:`1`"

#: ../../Ch10/Ch10_ChiSquare_1.rst:69 ../../Ch10/Ch10_ChiSquare_1.rst:183
msgid "35"
msgstr "35"

#: ../../Ch10/Ch10_ChiSquare_1.rst:71
msgid "diamonds (♢)"
msgstr "diamanter (♢)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:71 ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "2"
msgstr "2"

#: ../../Ch10/Ch10_ChiSquare_1.rst:71
msgid "*O*\\ :sub:`2`"
msgstr "*O*\\ :sub:`2`"

#: ../../Ch10/Ch10_ChiSquare_1.rst:71 ../../Ch10/Ch10_ChiSquare_1.rst:183
msgid "51"
msgstr "51"

#: ../../Ch10/Ch10_ChiSquare_1.rst:73
msgid "hearts (♡)"
msgstr "hearts (♡)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:73 ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "3"
msgstr "3"

#: ../../Ch10/Ch10_ChiSquare_1.rst:73
msgid "*O*\\ :sub:`3`"
msgstr "*O*\\ :sub:`3`"

#: ../../Ch10/Ch10_ChiSquare_1.rst:73 ../../Ch10/Ch10_ChiSquare_1.rst:183
msgid "64"
msgstr "64"

#: ../../Ch10/Ch10_ChiSquare_1.rst:75
msgid "spades (♠)"
msgstr "spades (♠)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:75 ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "4"
msgstr "4"

#: ../../Ch10/Ch10_ChiSquare_1.rst:75
msgid "*O*\\ :sub:`4`"
msgstr "*O*\\ :sub:`4`"

#: ../../Ch10/Ch10_ChiSquare_1.rst:75 ../../Ch10/Ch10_ChiSquare_1.rst:181
#: ../../Ch10/Ch10_ChiSquare_1.rst:183
msgid "50"
msgstr "50"

#: ../../Ch10/Ch10_ChiSquare_1.rst:78
msgid ""
"Hopefully that’s pretty clear. It’s also worth noting that mathematicians "
"prefer to talk about general rather than specific things, so you’ll also see "
"the notation *O*\\ :sub:`i`\\, which refers to the number of observations "
"that fall within the *i*-th category (where *i* could be 1, 2, 3 or 4). "
"Finally, if we want to refer to the set of all observed frequencies, "
"statisticians group all observed values into a vector,\\ [#]_ which I’ll "
"refer to as *O*."
msgstr ""
"Forhåpentligvis er det ganske klart. Det er også verdt å merke seg at "
"matematikere foretrekker å snakke om generelle fremfor spesifikke ting, så "
"du vil også se notasjonen *O*\\ :sub:`i`\\, som refererer til antall "
"observasjoner som faller innenfor den *i*-tredje kategorien (der *i* kan "
"være 1, 2, 3 eller 4). Hvis vi ønsker å referere til mengden av alle "
"observerte frekvenser, grupperer statistikere alle observerte verdier i en "
"vektor,\\ [#]_ som jeg vil referere til som *O*."

#: ../../Ch10/Ch10_ChiSquare_1.rst:85
msgid ""
"O = (*O*\\ :sub:`1`\\, *O*\\ :sub:`2`\\, *O*\\ :sub:`3`\\, *O*\\ :sub:`4`\\)"
msgstr ""
"O = (*O*\\ :sub:`1`\\, *O*\\ :sub:`2`\\, *O*\\ :sub:`3`\\, *O*\\ :sub:`4`\\)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:87
msgid ""
"Again, this is nothing new or interesting. It’s just notation. If I say that "
"*O* = (35, 51, 64, 50) all I’m doing is describing the table of observed "
"frequencies (i.e., ``observed``), but I’m referring to it using mathematical "
"notation."
msgstr ""
"Igjen, dette er ikke noe nytt eller interessant. Det er bare notasjon. Hvis "
"jeg sier at *O* = (35, 51, 64, 50), beskriver jeg bare tabellen over "
"observerte frekvenser (dvs. ``observed``), men jeg refererer til den ved "
"hjelp av matematisk notasjon."

#: ../../Ch10/Ch10_ChiSquare_1.rst:93
msgid "The null hypothesis and the alternative hypothesis"
msgstr "Nullhypotesen og den alternative hypotesen"

#: ../../Ch10/Ch10_ChiSquare_1.rst:95
msgid ""
"As the last section indicated, our research hypothesis is that “people don’t "
"choose cards randomly”. What we’re going to want to do now is translate this "
"into some statistical hypotheses and then construct a statistical test of "
"those hypotheses. The test that I’m going to describe to you is **Pearson’s "
"χ² (chi-square) goodness-of-fit test**, and as is so often the case we have "
"to begin by carefully constructing our null hypothesis. In this case, it’s "
"pretty easy. First, let’s state the null hypothesis in words:"
msgstr ""
"Som forrige avsnitt indikerte, er forskningshypotesen vår at «folk ikke "
"velger kort tilfeldig». Det vi skal gjøre nå, er å oversette dette til noen "
"statistiske hypoteser og deretter gjennomføre en statistisk test av disse "
"hypotesene. Testen jeg skal beskrive for deg, er **Pearsons χ² (kjikvadrat)-"
"test**, og som så ofte før må vi begynne med å lage nullhypotesen vår nøye. "
"I dette tilfellet er det ganske enkelt. La oss først formulere nullhypotesen "
"i ord:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:103 ../../Ch10/Ch10_ChiSquare_1.rst:136
msgid "H\\ :sub:`0`: All four suits are chosen with equal probability"
msgstr "H\\ :sub:`0`: Alle fire fargene velges med like stor sannsynlighet"

#: ../../Ch10/Ch10_ChiSquare_1.rst:105
msgid ""
"Now, because this is statistics, we have to be able to say the same thing in "
"a mathematical way. To do this, let’s use the notation *P*\\ :sub:`j`\\ to "
"refer to the true probability that the *j*-th suit is chosen. If the null "
"hypothesis is true, then each of the four suits has a 25\\% chance of being "
"selected. In other words, our null hypothesis claims that *P*\\ :sub:`1` = "
"0.25, *P*\\ :sub:`2` = 0.25, *P*\\ :sub:`3` = 0.25 and finally that *P*\\ :"
"sub:`4` = 0.25. However, in the same way that we can group our observed "
"frequencies into a vector *O* that summarises the entire data set, we can "
"use *P* to refer to the probabilities that correspond to our null "
"hypothesis. So if I let the vector P = (*P*\\ :sub:`1`\\, *P*\\ :sub:`2`\\, "
"*P*\\ :sub:`3`\\, *P*\\ :sub:`4`\\) refer to the collection of probabilities "
"that describe our null hypothesis, then we have:"
msgstr ""
"Siden dette er statistikk, må vi kunne si det samme på en matematisk måte. "
"For å gjøre dette bruker vi notasjonen *P*\\ :sub:`j`\\ for å referere til "
"den sanne sannsynligheten for at den *j*-tredje fargen blir valgt. Hvis "
"nullhypotesen er sann, har hver av de fire fargene 25\\% sjanse for å bli "
"valgt. Med andre ord sier nullhypotesen vår at *P*\\ :sub:`1` = 0,25, *P*\\ :"
"sub:`2` = 0,25, *P*\\ :sub:`3` = 0,25 og til slutt at *P*\\ :sub:`4` = 0,25. "
"Men på samme måte som vi kan gruppere de observerte frekvensene våre i en "
"vektor *O* som oppsummerer hele datasettet, kan vi bruke *P* til å referere "
"til sannsynlighetene som svarer til nullhypotesen vår. Så hvis jeg lar "
"vektoren P = (*P*\\ :sub:`1`\\, *P*\\ :sub:`2`\\, *P*\\ :sub:`3`\\, *P*\\ :"
"sub:`4`\\) referere til samlingen av sannsynligheter som beskriver "
"nullhypotesen vår, så har vi:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:118 ../../Ch10/Ch10_ChiSquare_1.rst:141
msgid "H\\ :sub:`0`: *P* = (0.25, 0.25, 0.25, 0.25)"
msgstr "H\\ :sub:`0`: *P* = (0.25, 0.25, 0.25, 0.25)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:120
msgid ""
"In this particular instance, our null hypothesis corresponds to a vector of "
"probabilities *P* in which all of the probabilities are equal to one "
"another. But this doesn’t have to be the case. For instance, if the "
"experimental task was for people to imagine they were drawing from a deck "
"that had twice as many clubs as any other suit, then the null hypothesis "
"would correspond to something like *P* = (0.4, 0.2, 0.2, 0.2). As long as "
"the probabilities are all positive numbers, and they all sum to 1, then it’s "
"a perfectly legitimate choice for the null hypothesis. However, the most "
"common use of the goodness-of-fit test is to test a null hypothesis that all "
"of the categories are equally likely, so we’ll stick to that for our example."
msgstr ""
"I dette tilfellet tilsvarer nullhypotesen vår en vektor av sannsynligheter "
"*P* der alle sannsynlighetene er lik hverandre. Men dette trenger ikke å "
"være tilfelle. Hvis eksperimentet for eksempel gikk ut på at folk skulle "
"forestille seg at de trakk fra en kortstokk som inneholdt dobbelt så mange "
"kløver som noen annen farge, ville nullhypotesen tilsvare noe sånt som *P* = "
"(0,4, 0,2, 0,2, 0,2, 0,2). Så lenge alle sannsynlighetene er positive tall, "
"og summen av dem er 1, er dette et helt legitimt valg for nullhypotesen. Den "
"vanligste bruken av goodness-of-fit-testen er imidlertid å teste en "
"nullhypotese om at alle kategoriene er like sannsynlige, så vi holder oss "
"til det i vårt eksempel."

#: ../../Ch10/Ch10_ChiSquare_1.rst:131
msgid ""
"What about our alternative hypothesis, H\\ :sub:`1`? All we’re really "
"interested in is demonstrating that the probabilities involved aren’t all "
"identical (that is, people’s choices weren’t completely random). As a "
"consequence, the “human friendly” versions of our hypotheses look like this:"
msgstr ""
"Hva med vår alternative hypotese, H\\ :sub:`1`? Det eneste vi egentlig er "
"interessert i, er å vise at de involverte sannsynlighetene ikke alle er "
"identiske (det vil si at folks valg ikke var helt tilfeldige). Som en "
"konsekvens av dette ser de «menneskevennlige» versjonene av hypotesene våre "
"slik ut:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:137
msgid ""
"H\\ :sub:`1`: At least one of the suit-choice probabilities *isn’t* 0.25"
msgstr "H\\ :sub:`1`: Minst én av fargevalgsannsynlighetene *er* ikke 0,25"

#: ../../Ch10/Ch10_ChiSquare_1.rst:139
msgid "and the “mathematician friendly” version is:"
msgstr "og den «matematikervennlige» versjonen er:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:142
msgid "H\\ :sub:`1`: *P* ≠ (0.25, 0.25, 0.25, 0.25)"
msgstr "H\\ :sub:`1`: *P* ≠ (0.25, 0.25, 0.25, 0.25)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:145
msgid "The “goodness-of-fit” test statistic"
msgstr "Teststatistikken for «goodness-of-fit»"

#: ../../Ch10/Ch10_ChiSquare_1.rst:147
msgid ""
"At this point, we have our observed frequencies *O* and a collection of "
"probabilities *P* corresponding to the null hypothesis that we want to test. "
"What we now want to do is construct a test of the null hypothesis. As "
"always, if we want to test H\\ :sub:`0` against H\\ :sub:`1`, we’re going to "
"need a test statistic. The basic trick that a goodness-of-fit test uses is "
"to construct a test statistic that measures how “close” the data are to the "
"null hypothesis. If the data don’t resemble what you’d “expect” to see if "
"the null hypothesis were true, then it probably isn’t true. Okay, if the "
"null hypothesis were true, what would we expect to see? Or, to use the "
"correct terminology, what are the **expected frequencies**. There are *N* = "
"200 observations, and (if the null is true) the probability of any one of "
"them choosing a heart is *P*\\ :sub:`3` = \\0.25, so I guess we’re expecting "
"200 · 0.25 = 50 hearts, right? Or, more specifically, if we let *E*\\ :sub:"
"`i` refer to “the number of category *i* responses that we’re expecting if "
"the null is true”, then:"
msgstr ""
"På dette tidspunktet har vi de observerte frekvensene *O* og en samling "
"sannsynligheter *P* som svarer til nullhypotesen vi ønsker å teste. Det vi "
"nå ønsker å gjøre, er å gjennomføre en test av nullhypotesen. Som alltid, "
"hvis vi ønsker å teste H\\ :sub:`0` mot H\\ :sub:`1`, trenger vi en "
"teststatistikk. Det grunnleggende trikset som brukes i en goodness-of-fit-"
"test, er å velge en teststatistikk som måler hvor «nær» dataene er "
"nullhypotesen. Hvis dataene ikke ligner på det du ville «forvente» å se hvis "
"nullhypotesen var sann, er den sannsynligvis ikke sann. Hvis nullhypotesen "
"var sann, hva ville vi da forvente å se? Eller, for å bruke riktig "
"terminologi, hva er de **forventede frekvensene**. Det er *N* = 200 "
"observasjoner, og (hvis nullhypotesen er sann) er sannsynligheten for at "
"noen av dem velger et hjerte *P*\\ :sub:`3` = \\0,25, så jeg antar at vi "
"forventer 200 - 0,25 = 50 hjerter, ikke sant? Eller, mer spesifikt, hvis vi "
"lar *E*\\ :sub:`i` referere til «antall svar i kategori *i* som vi forventer "
"hvis nullhypotesen er sant», så:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:162
msgid "*E*\\ :sub:`i` = *N* · *P*\\ :sub:`i`"
msgstr "*E*\\ :sub:`i` = *N* · *P*\\ :sub:`i`"

#: ../../Ch10/Ch10_ChiSquare_1.rst:164
msgid ""
"This is pretty easy to calculate.If there are 200 observations that can fall "
"into four categories, and we think that all four categories are equally "
"likely, then on average we’d expect to see 50 observations in each category, "
"right?"
msgstr ""
"Hvis det er 200 observasjoner som kan falle inn under fire kategorier, og vi "
"tror at alle fire kategoriene er like sannsynlige, så vil vi i gjennomsnitt "
"forvente å se 50 observasjoner i hver kategori, ikke sant?"

#: ../../Ch10/Ch10_ChiSquare_1.rst:168
msgid ""
"Now, how do we translate this into a test statistic? Clearly, what we want "
"to do is compare the *expected* number of observations in each category "
"(*E*\\ :sub:`i`\\) with the *observed* number of observations in that "
"category (*O*\\ :sub:`i`\\). And on the basis of this comparison we ought to "
"be able to come up with a good test statistic. To start with, let’s "
"calculate the difference between what the null hypothesis expected us to "
"find and what we actually did find. That is, we calculate the “observed "
"minus expected” difference score, *O*\\ :sub:`i` - *E*\\ :sub:`i`. This is "
"illustrated in the following table:"
msgstr ""
"Hvordan oversetter vi dette til en teststatistikk? Det vi ønsker å gjøre, er "
"selvsagt å sammenligne det *forventede* antallet observasjoner i hver "
"kategori (*E*\\ :sub:`i`\\) med det *observerte* antallet observasjoner i "
"den samme kategorien (*O*\\ :sub:`i`\\). Og på grunnlag av denne "
"sammenligningen bør vi kunne finne frem til en god teststatistikk. Til å "
"begynne med beregner vi forskjellen mellom hva nullhypotesen forventet at vi "
"skulle finne, og hva vi faktisk fant. Det vil si at vi beregner «observert "
"minus forventet» differansescore, *O*\\ :sub:`i` - *E*\\ :sub:`i`. Dette er "
"illustrert i tabellen nedenfor:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:179 ../../Ch10/Ch10_ChiSquare_1.rst:488
msgid "♣"
msgstr "♣"

#: ../../Ch10/Ch10_ChiSquare_1.rst:179 ../../Ch10/Ch10_ChiSquare_1.rst:488
msgid "♢"
msgstr "♢"

#: ../../Ch10/Ch10_ChiSquare_1.rst:179 ../../Ch10/Ch10_ChiSquare_1.rst:488
msgid "♡"
msgstr "♡"

#: ../../Ch10/Ch10_ChiSquare_1.rst:179 ../../Ch10/Ch10_ChiSquare_1.rst:488
msgid "♠"
msgstr "♠"

#: ../../Ch10/Ch10_ChiSquare_1.rst:181 ../../Ch10/Ch10_ChiSquare_1.rst:490
msgid "expected frequency"
msgstr "forventet frekvens"

#: ../../Ch10/Ch10_ChiSquare_1.rst:181 ../../Ch10/Ch10_ChiSquare_1.rst:490
msgid "*E*\\ :sub:`i`"
msgstr "*E*\\ :sub:`i`"

#: ../../Ch10/Ch10_ChiSquare_1.rst:183
msgid "observed frequency"
msgstr "observert frekvens"

#: ../../Ch10/Ch10_ChiSquare_1.rst:185
msgid "difference score"
msgstr "differansescore"

#: ../../Ch10/Ch10_ChiSquare_1.rst:185
msgid "*E*\\ :sub:`i` - *O*\\ :sub:`1`"
msgstr "*E*\\ :sub:`i` - *O*\\ :sub:`1`"

#: ../../Ch10/Ch10_ChiSquare_1.rst:185
msgid "-15"
msgstr "-15"

#: ../../Ch10/Ch10_ChiSquare_1.rst:185
msgid "14"
msgstr "14"

#: ../../Ch10/Ch10_ChiSquare_1.rst:185
msgid "0"
msgstr "0"

#: ../../Ch10/Ch10_ChiSquare_1.rst:188
msgid ""
"So, based on our calculations, it’s clear that people chose more hearts and "
"fewer clubs than the null hypothesis predicted. However, a moment’s thought "
"suggests that these raw differences aren’t quite what we’re looking for. "
"Intuitively, it feels like it’s just as bad when the null hypothesis "
"predicts too few observations (which is what happened with hearts) as it is "
"when it predicts too many (which is what happened with clubs). So it’s a bit "
"weird that we have a negative number for clubs and a positive number for "
"hearts. One easy way to fix this is to square everything, so that we now "
"calculate the squared differences, (*O*\\ :sub:`i` - *O*\\ :sub:`i`\\)². As "
"before, we can do this by hand:"
msgstr ""
"Basert på våre beregninger er det tydelig at folk valgte flere hjerterstikk "
"og færre kløverstikk enn nullhypotesen forutså. En liten tanke antyder "
"imidlertid at disse rå forskjellene ikke er helt det vi er ute etter. "
"Intuitivt føles det som om det er like ille når nullhypotesen predikerer for "
"få observasjoner (som var det som skjedde med hjerter) som når den "
"predikerer for mange (som var det som skjedde med kløver). Derfor er det "
"litt rart at vi har et negativt tall for kløver og et positivt tall for "
"hjerter. En enkel måte å fikse dette på er å kvadrere alt, slik at vi nå "
"beregner de kvadrerte differansene, (*O*\\ :sub:`i` - *O*\\ :sub:`i`\\)². "
"Som før kan vi gjøre dette for hånd:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:205
msgid ""
"Now we’re making progress. What we’ve got now is a collection of numbers "
"that are big whenever the null hypothesis makes a bad prediction (clubs and "
"hearts), but are small whenever it makes a good one (diamonds and spades). "
"Next, for some technical reasons that I’ll explain in a moment, let’s also "
"divide all these numbers by the expected frequency *E*\\ :sub:`i`\\, so "
"we’re actually calculating :math:`\\frac{(E_i-O_i)^2}{E_i}`\\. Since *E*\\ :"
"sub:`i` = 50 for all categories in our example, it’s not a very interesting "
"calculation, but let’s do it anyway:"
msgstr ""
"Nå gjør vi fremskritt. Nå har vi en samling tall som er store når "
"nullhypotesen gir en dårlig prediksjon (kløver og hjerter), men små når den "
"gir en god prediksjon (ruter og spar). Av tekniske grunner, som jeg skal "
"forklare om et øyeblikk, dividerer vi også alle disse tallene med den "
"forventede frekvensen *E*\\ :sub:`i`\\, slik at vi faktisk beregner :math:"
"`\\frac{(E_i-O_i)^2}{E_i}`\\. Siden *E*\\ :sub:`i` = 50 for alle kategoriene "
"i eksempelet vårt, er det ikke en veldig interessant beregning, men la oss "
"gjøre det likevel:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:220
msgid ""
"In effect, what we’ve got here are four different “error” scores, each one "
"telling us how big a “mistake” the null hypothesis made when we tried to use "
"it to predict our observed frequencies. So, in order to convert this into a "
"useful test statistic, one thing we could do is just add these numbers up. "
"The result is called the **goodness-of-fit** statistic, conventionally "
"referred to either as χ² (chi-square) or GOF. We can calculate it as follows:"
msgstr ""
"I realiteten har vi her fire ulike «feil»-skårer. Hver og en forteller oss "
"hvor stor «feil» ble gjort da vi prøvde å bruke nullhypotesen til å forutsi "
"de observerte frekvensene. For å konvertere dette til en nyttig "
"teststatistikk, kan vi for eksempel bare legge sammen disse tallene. "
"Resultatet kalles **goodness-of-fit**-statistikken, vanligvis referert til "
"som χ² (kjikvadrat) eller GOF. Vi kan beregne den på følgende måte:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:231
msgid "This gives us a value of ``8.44``."
msgstr "Dette gir oss en verdi på ``8.44``."

#: ../../Ch10/Ch10_ChiSquare_1.rst:233
msgid ""
"If we let *k* refer to the total number of categories (i.e., *k* = 4  for "
"our cards data), then the χ² statistic is given by:"
msgstr ""
"Hvis vi lar *k* referere til det totale antallet kategorier (dvs. *k* = 4 "
"for våre kortdata), er χ²-statistikken gitt ved:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:236
msgid ""
"\\chi^2 = \\sum_{i=1}^k \\frac{(O_i - E_i)^2}{E_i}\n"
"\n"
msgstr ""
"\\chi^2 = \\sum_{i=1}^k \\frac{(O_i - E_i)^2}{E_i}\n"
"\n"

#: ../../Ch10/Ch10_ChiSquare_1.rst:238
msgid ""
"Intuitively, it’s clear that if χ² is small, then the observed data *O*\\ :"
"sub:`i` are very close to what the null hypothesis predicted *E*\\ :sub:"
"`i`\\, so we’re going to need a large χ² statistic in order to reject the "
"null."
msgstr ""
"Intuitivt er det klart at hvis χ² er liten, ligger de observerte dataene "
"*O*\\ :sub:`i` veldig nær det nullhypotesen forutsa *E*\\ :sub:`i`\\, så vi "
"trenger en stor χ²-statistikk for å forkaste nullhypotesen."

#: ../../Ch10/Ch10_ChiSquare_1.rst:243
msgid ""
"As we’ve seen from our calculations, in our cards data set we’ve got a value "
"of χ² = 8.44. So now the question becomes is this a big enough value to "
"reject the null?"
msgstr ""
"Som vi har sett fra beregningene våre, har vi i kortdatasettet vårt en verdi "
"på χ² = 8,44. Så nå blir spørsmålet om dette er en stor nok verdi til å "
"forkaste nullhypotesen?"

#: ../../Ch10/Ch10_ChiSquare_1.rst:248
msgid "The sampling distribution of the GOF statistic"
msgstr "Utvalgsfordelingen til GOF-statistikken"

#: ../../Ch10/Ch10_ChiSquare_1.rst:250
msgid ""
"To determine whether or not a particular value of χ² is large enough to "
"justify rejecting the null hypothesis, we’re going to need to figure out "
"what the sampling distribution for χ² would be if the null hypothesis were "
"true. So that’s what I’m going to do in this section. I’ll show you in a "
"fair amount of detail how this sampling distribution is constructed, and "
"then, in the next section, use it to build up a hypothesis test. If you want "
"to cut to the chase and are willing to take it on faith that the sampling "
"distribution is a **χ²-distribution** with *k* - 1 degrees of freedom, you "
"can skip the rest of this section. However, if you want to understand *why* "
"the goodness-of-fit test works the way it does, read on."
msgstr ""
"For å avgjøre om en bestemt verdi av χ² er stor nok til å rettferdiggjøre "
"forkastelse av nullhypotesen, må vi finne ut hva utvalgsfordelingen for χ² "
"ville vært hvis nullhypotesen var sann. Så det er det jeg skal gjøre i dette "
"avsnittet. Jeg skal vise deg ganske detaljert hvordan denne "
"utvalgsfordelingen er konstruert, og i neste avsnitt skal jeg bruke den til "
"å bygge opp en hypotesetest. Hvis du vil gå rett på sak og er villig til å "
"tro på at utvalgsfordelingen er en **χ²-fordeling** med *k* - 1 "
"frihetsgrader, kan du hoppe over resten av denne delen. Hvis du derimot "
"ønsker å forstå *hvorfor* goodness-of-fit-testen fungerer som den gjør, bør "
"du lese videre."

#: ../../Ch10/Ch10_ChiSquare_1.rst:261
msgid ""
"Okay, let’s suppose that the null hypothesis is actually true. If so, then "
"the true probability that an observation falls in the *i*-th category is "
"*P*\\ :sub:`i`\\. After all, that’s pretty much the definition of our null "
"hypothesis. Let’s think about what this actually means. This is kind of like "
"saying that “nature” makes the decision about whether or not the observation "
"ends up in category *i* by flipping a weighted coin (i.e., one where the "
"probability of getting a head is *P*\\ :sub:`j`\\). And therefore we can "
"think of our observed frequency *O*\\ :sub:`i` by imagining that nature "
"flipped *N* of these coins (one for each observation in the data set), and "
"exactly *O*\\ :sub:`i` of them came up heads. Obviously, this is a pretty "
"weird way to think about the experiment. But what it does (I hope) is remind "
"you that we’ve actually seen this scenario before. It’s exactly the same set "
"up that gave rise to the :doc:`binomial distribution <../Ch07/"
"Ch07_Probability_4>`. In other words, if the null hypothesis is true, then "
"it follows that our observed frequencies were generated by sampling from a "
"binomial distribution:"
msgstr ""
"La oss anta at nullhypotesen faktisk er sann. I så fall er den sanne "
"sannsynligheten for at en observasjon faller i den *i*-te kategorien *P*\\ :"
"sub:`i`\\. Det er jo omtrent definisjonen av nullhypotesen vår. La oss tenke "
"over hva dette egentlig betyr. Det er omtrent som å si at «naturen» tar "
"avgjørelsen om hvorvidt observasjonen havner i kategori *i* eller ikke ved å "
"kaste en vektet mynt (dvs. en mynt der sannsynligheten for å få krone er "
"*P*\\ :sub:`j`\\). Derfor kan vi tenke på den observerte frekvensen *O*\\ :"
"sub:`i` ved å forestille oss at naturen kastet *N* av disse myntene (én for "
"hver observasjon i datasettet), og at nøyaktig *O*\\ :sub:`i` av dem ble "
"kron. Dette er selvsagt en ganske merkelig måte å tenke på eksperimentet på. "
"Men det minner deg (håper jeg) på at vi faktisk har sett dette scenarioet "
"før. Det er nøyaktig det samme oppsettet som ga opphav til :doc:"
"`binomialfordelingen <../Ch07/Ch07_Probability_4>`. Med andre ord, hvis "
"nullhypotesen er sann, følger det at våre observerte frekvenser ble generert "
"ved sampling fra en binomialfordeling:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:278
msgid "*O*\\ :sub:`i` ~ Binomial(*P*\\ :sub:`i`\\, N)"
msgstr "*O*\\ :sub:`i` ~ Binomial(*P*\\ :sub:`i`\\, N)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:280
msgid ""
"Now, if you remember from our discussion of :ref:`the central limit theorem "
"<central_limit_theorem>` the binomial distribution starts to look pretty "
"much identical to the normal distribution, especially when *N* is large and "
"when *P*\\ :sub:`i` isn’t *too* close to 0 or 1. In other words as long as "
"*N* · *P*\\ :sub:`i` is large enough. Or, to put it another way, when the "
"expected frequency *E*\\ :sub:`i` is large enough then the theoretical "
"distribution of *O*\\ :sub:`i` is approximately normal. Better yet, if "
"*O*\\ :sub:`i` is normally distributed, then so is :math:`(O_i - E_i)/"
"\\sqrt{E_i}`. Since *E*\\ :sub:`i` is a fixed value, subtracting off *E*\\ :"
"sub:`i` and dividing by :math:`\\sqrt{E_i}` changes the mean and standard "
"deviation of the normal distribution but that’s all it does. Okay, so now "
"let’s have a look at what our goodness-of-fit statistic actually *is*. What "
"we’re doing is taking a bunch of things that are normally-distributed, "
"squaring them, and adding them up. Wait. We’ve seen that before too! As we "
"discussed in :doc:`../Ch07/Ch07_Probability_6`, when you take a bunch of "
"things that have a standard normal distribution (i.e., mean 0 and standard "
"deviation 1), square them and then add them up, the resulting quantity has a "
"χ²-distribution. So now we know that the null hypothesis predicts that the "
"sampling distribution of the goodness-of-fit statistic is a χ²-distribution. "
"Cool."
msgstr ""
"Hvis du husker fra diskusjonen om :ref:`det sentrale grenseteoremet "
"<central_limit_theorem>`, begynner binomialfordelingen å se ganske identisk "
"ut med normalfordelingen, spesielt når *N* er stor og når *P*\\ :sub:`i` "
"ikke er *for* nær 0 eller 1. Med andre ord så lenge *N* - *P*\\ :sub:`i` er "
"stor nok. Eller, for å si det på en annen måte, når den forventede "
"frekvensen *E*\\ :sub:`i` er stor nok, er den teoretiske fordelingen av "
"*O*\\ :sub:`i` tilnærmet normalfordelt. Enda bedre: Hvis *O*\\ :sub:`i` er "
"normalfordelt, så er også :math:`(O_i - E_i)/\\sqrt{E_i}` normalfordelt. "
"Siden *E*\\ :sub:`i` er en fast verdi, vil det å trekke fra *E*\\ :sub:`i` "
"og dividere med :math:`\\sqrt{E_i}` endre gjennomsnittet og standardavviket "
"til normalfordelingen, men det er alt det gjør. Ok, så la oss nå ta en titt "
"på hva goodness-of-fit-statistikken vår faktisk *er*. Det vi gjør, er å ta "
"en haug med ting som er normalfordelte, kvadrere dem og legge dem sammen. "
"Vent litt… Det har vi også sett før! Som vi diskuterte i :doc:`../Ch07/"
"Ch07_Probability_6`, når du tar en haug med ting som har en standard "
"normalfordeling (dvs. gjennomsnitt 0 og standardavvik 1), kvadrerer dem og "
"deretter legger dem sammen, har den resulterende mengden en χ²-fordeling. Så "
"nå vet vi at nullhypotesen predikerer at utvalgsfordelingen til goodness-of-"
"fit-statistikken er en χ²-fordeling. Det er kult."

#: ../../Ch10/Ch10_ChiSquare_1.rst:300
msgid ""
"There’s one last detail to talk about, namely the degrees of freedom. If you "
"remember back to :doc:`../Ch07/Ch07_Probability_6`, I said that if the "
"number of things you’re adding up is *k*, then the degrees of freedom for "
"the resulting χ²-distribution is *k*. Yet, what I said at the start of this "
"section is that the actual degrees of freedom for the χ²-goodness-of-fit "
"test is *k* - 1. What’s up with that? The answer here is that what we’re "
"supposed to be looking at is the number of genuinely *independent* things "
"that are getting added together. And, as I’ll go on to talk about in the "
"next section, even though there are *k* things that we’re adding only *k* - "
"1 of them are truly independent, and so the degrees of freedom is actually "
"only *k* - 1. That’s the topic of the next section.\\ [#]_"
msgstr ""
"Det er en siste detalj å snakke om, nemlig frihetsgradene. Hvis du husker "
"tilbake til :doc:`../Ch07/Ch07_Probability_6`, så sa jeg at hvis antallet "
"ting du legger sammen er *k*, så er frihetsgradene for den resulterende χ²-"
"fordelingen *k*. Men det jeg sa i begynnelsen av dette avsnittet, er at de "
"faktiske frihetsgradene for χ²-test for fordeling er *k* - 1. Hva er det som "
"skjer? Svaret her er at det vi skal se på, er antallet genuint *uavhengige* "
"ting som blir lagt sammen. Og, som jeg skal snakke om i neste avsnitt, selv "
"om det er *k* ting vi legger sammen, er det bare *k* - 1 av dem som virkelig "
"er uavhengige, og dermed er frihetsgradene faktisk bare *k* - 1. Det er "
"temaet for neste avsnitt.\\ [#]_"

#: ../../Ch10/Ch10_ChiSquare_1.rst:313
msgid "Degrees of freedom"
msgstr "Grader av frihet"

#: ../../Ch10/Ch10_ChiSquare_1.rst:315
msgid ""
"When I introduced the χ²-distribution in :doc:`../Ch07/Ch07_Probability_6`, "
"I was a bit vague about what “**degrees of freedom**” actually *means*. "
"Obviously, it matters. Looking at :numref:`fig-chiSqDists`,  you can see "
"that if we change the degrees of freedom then the χ²-distribution changes "
"shape quite substantially. But what exactly *is* it? Again, when I "
"introduced the distribution and explained its relationship to the normal "
"distribution, I did offer an answer: it’s the number of “normally "
"distributed variables” that I’m squaring and adding together. But, for most "
"people, that’s kind of abstract and not entirely helpful. What we really "
"need to do is try to understand degrees of freedom in terms of our data. So "
"here goes."
msgstr ""
"Da jeg introduserte χ²-fordelingen i :doc:`../Ch07/Ch07_Probability_6`, var "
"jeg litt uklar på hva «**frihetsgrader**» egentlig *betyr*. Det er åpenbart "
"at det betyr noe. Hvis du ser på :numref:`fig-chiSqDists`, kan du se at hvis "
"vi endrer frihetsgradene, endrer χ²-fordelingen form ganske mye. Men hva "
"*er* den egentlig? Igjen, da jeg introduserte fordelingen og forklarte dens "
"forhold til normalfordelingen, ga jeg et svar: Det er antallet "
"«normalfordelte variabler» som jeg kvadrerer og legger sammen. Men for folk "
"flest er det litt abstrakt og ikke helt til hjelp. Det vi egentlig trenger å "
"gjøre, er å prøve å forstå frihetsgradene i forhold til dataene våre. Så her "
"kommer det."

#: ../../Ch10/Ch10_ChiSquare_1.rst:328
msgid "χ² distributions with different degrees of freedom"
msgstr "χ²-fordelinger med ulike frihetsgrader"

#: ../../Ch10/Ch10_ChiSquare_1.rst:332
msgid ""
"χ² (chi-square) distributions with different values for the “degrees of "
"freedom”"
msgstr "χ² (kjikvadrat)-fordelinger med ulike verdier for «frihetsgrader»"

#: ../../Ch10/Ch10_ChiSquare_1.rst:337
msgid ""
"The basic idea behind degrees of freedom is quite simple. You calculate it "
"by counting up the number of distinct “quantities” that are used to describe "
"your data and then subtracting off all of the “constraints” that those data "
"must satisfy.\\ [#]_ This is a bit vague, so let’s use our cards data as a "
"concrete example. We describe our data using four numbers, *O*\\ :sub:`1`\\, "
"*O*\\ :sub:`2`\\, *O*\\ :sub:`3` and *O*\\ :sub:`4` corresponding to the "
"observed frequencies of the four different categories (hearts, clubs, "
"diamonds, spades). These four numbers are the *random outcomes* of our "
"experiment. But my experiment actually has a fixed constraint built into it: "
"the sample size *N*.\\ [#]_ That is, if we know how many people chose "
"hearts, how many chose diamonds and how many chose clubs, then we’d be able "
"to figure out exactly how many chose spades. In other words, although our "
"data are described using four numbers, they only actually correspond to 4 - "
"1 = 3 degrees of freedom. A slightly different way of thinking about it is "
"to notice that there are four *probabilities* that we’re interested in "
"(again, corresponding to the four different categories), but these "
"probabilities must sum to one, which imposes a constraint. Therefore the "
"degrees of freedom is 4 - 1 = 3. Regardless of whether you want to think "
"about it in terms of the observed frequencies or in terms of the "
"probabilities, the answer is the same. In general, when running the χ² (chi-"
"square) goodness-of-fit test for an experiment involving *k* groups, then "
"the degrees of freedom will be *k* - 1."
msgstr ""
"Den grunnleggende ideen bak frihetsgrader er ganske enkel. Du beregner den "
"ved å telle opp antall forskjellige «mengder» som brukes til å beskrive "
"dataene dine, og deretter trekker du fra alle "
"«begrensningene» (*constraints*) som disse dataene må tilfredsstille.\\ [#]_ "
"Vi beskriver dataene våre ved hjelp av fire tall, *O*\\ :sub:`1`\\, *O*\\ :"
"sub:`2`\\, *O*\\ :sub:`3` og *O*\\ :sub:`4`, som tilsvarer de observerte "
"frekvensene av de fire ulike kategoriene (hjerter, kløver, ruter og spar). "
"Disse fire tallene er de *tilfeldige utfallene* av eksperimentet vårt. Men "
"eksperimentet mitt har faktisk en fast begrensning innebygd i seg: "
"utvalgsstørrelsen *N*.\\ [#]_ Det vil si at hvis vi vet hvor mange som "
"valgte hjerter, hvor mange som valgte ruter og hvor mange som valgte kløver, "
"vil vi kunne finne ut nøyaktig hvor mange som valgte spar. Med andre ord, "
"selv om dataene våre beskrives ved hjelp av fire tall, tilsvarer de faktisk "
"bare 4 - 1 = 3 frihetsgrader. En litt annen måte å tenke på det på er å "
"legge merke til at det er fire *sannsynligheter* vi er interessert i (som "
"igjen tilsvarer de fire ulike kategoriene), men disse sannsynlighetene må "
"summere til én, noe som innebærer en begrensning. Frihetsgradene er derfor 4 "
"- 1 = 3. Uansett om du vil tenke på det i form av de observerte frekvensene "
"eller i form av sannsynlighetene, er svaret det samme. Generelt vil "
"frihetsgradene være *k* - 1 når du kjører χ²-testen (kjikvadrat) for et "
"eksperiment som involverer *k* grupper."

#: ../../Ch10/Ch10_ChiSquare_1.rst:360
msgid "Testing the null hypothesis"
msgstr "Testing av nullhypotesen"

#: ../../Ch10/Ch10_ChiSquare_1.rst:362
msgid ""
"The final step in the process of constructing our hypothesis test is to "
"figure out what the rejection region is. That is, what values of χ² would "
"lead us to reject the null hypothesis. As we saw earlier, large values of χ² "
"imply that the null hypothesis has done a poor job of predicting the data "
"from our experiment, whereas small values of χ² imply that it’s actually "
"done pretty well. Therefore, a pretty sensible strategy would be to say "
"there is some critical value such that if χ² is bigger than the critical "
"value we reject the null, but if χ² is smaller than this value we retain the "
"null. In other words, to use the language we introduced in chapter :doc:`../"
"Ch09/Ch09_HypothesisTesting` the χ²-goodness-of-fit test is always a **one-"
"sided test**. Right, so all we have to do is figure out what this critical "
"value is. And it’s pretty straightforward. If we want our test to have "
"significance level of α = 0.05 (that is, we are willing to tolerate a Type I "
"error rate of 5\\%), then we have to choose our critical value so that there "
"is only a 5\\% chance that χ² could get to be that big if the null "
"hypothesis is true. This is illustrated in :numref:`fig-chiSqTest`."
msgstr ""
"Det siste trinnet i prosessen med å gjennomføre en hypotesetest vår er å "
"finne ut hva forkastningsområdet er. Det vil si hvilke verdier av χ² som vil "
"føre til at vi forkaster nullhypotesen. Som vi så tidligere, innebærer store "
"verdier av χ² at nullhypotesen har gjort en dårlig jobb med å predikere "
"dataene fra eksperimentet vårt, mens små verdier av χ² innebærer at den "
"faktisk har gjort det ganske bra. En ganske fornuftig strategi ville derfor "
"være å si at det finnes en kritisk verdi som er slik at hvis χ² er større "
"enn den kritiske verdien, forkaster vi nullhypotesen, men hvis χ² er mindre "
"enn denne verdien, beholder vi nullhypotesen. Med andre ord, for å bruke "
"språket vi introduserte i kapittel :doc:`../Ch09/Ch09_HypothesisTesting`, er "
"χ²-goodness-of-fit-testen alltid en **ensidig test**. Så alt vi trenger å "
"gjøre, er å finne ut hva den kritiske verdien er. Og det er ganske enkelt. "
"Hvis vi ønsker at testen vår skal ha et signifikansnivå på α = 0,05 (det vil "
"si at vi er villige til å tolerere en type-I-feilrate på 5\\%), må vi velge "
"den kritiske verdien slik at det bare er 5\\% sjanse for at χ² kan bli så "
"stor hvis nullhypotesen er sann. Dette er illustrert i :numref:`fig-"
"chiSqTest`."

#: ../../Ch10/Ch10_ChiSquare_1.rst:381
msgid "Hypothesis testing works for the χ² GOF test"
msgstr "Hypotesetesting fungerer for χ² GOF-testen"

#: ../../Ch10/Ch10_ChiSquare_1.rst:385
msgid ""
"Illustration of how the hypothesis testing works for the χ² (chi-square) "
"goodness-of-fit test"
msgstr ""
"Illustrasjon av hvordan hypotesetestingen fungerer for χ²-testen (kjikvadrat)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:390
msgid ""
"Ah but, I hear you ask, how do I find the critical value of a χ²-"
"distribution with *k* - 1 degrees of freedom? Many many years ago when I "
"first took a psychology statistics class we used to look up these critical "
"values in a book of critical value tables, like the one in :numref:`tab-"
"chisquared_critvalues`. We can see that the critical value for a χ²-"
"distribution with 3 degrees of freedom, and *p* = 0.05 is 7.815."
msgstr ""
"Men, spør du, hvordan finner jeg den kritiske verdien til en χ²-fordeling "
"med *k* - 1 frihetsgrader? For mange år siden, da jeg tok statistikk i "
"psykologi for første gang, pleide vi å slå opp disse kritiske verdiene i en "
"bok med tabeller over kritiske verdier, som den i :numref:`tab-"
"chisquared_critvalues`. Vi kan se at den kritiske verdien for en χ²-"
"fordeling med 3 frihetsgrader og *p* = 0,05 er 7,815."

#: ../../Ch10/Ch10_ChiSquare_1.rst:399
msgid "Table of critical values for the χ² (chi-square) distribution"
msgstr "Tabell over kritiske verdier for χ²-fordelingen (kjikvadrat)"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "df"
msgstr "df"

#: ../../Ch10/Ch10_ChiSquare_1.rst:403
msgid "Probability"
msgstr "Sannsynlighet"

#: ../../Ch10/Ch10_ChiSquare_1.rst:405
msgid "non-significant"
msgstr "ikke-signifikant"

#: ../../Ch10/Ch10_ChiSquare_1.rst:405
msgid "significant"
msgstr "betydelig"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "0.95"
msgstr "0.95"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "0.90"
msgstr "0.90"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "0.70"
msgstr "0.70"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "0.50"
msgstr "0.50"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "0.30"
msgstr "0.30"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "0.10"
msgstr "0.10"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "0.05"
msgstr "0.05"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "0.01"
msgstr "0.01"

#: ../../Ch10/Ch10_ChiSquare_1.rst:407
msgid "0.001"
msgstr "0.001"

#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "0.004"
msgstr "0.004"

#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "0.016"
msgstr "0.016"

#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "0.148"
msgstr "0.148"

#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "0.455"
msgstr "0.455"

#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "1.074"
msgstr "1.074"

#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "2.706"
msgstr "2.706"

#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "3.841"
msgstr "3.841"

#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "6.635"
msgstr "6.635"

#: ../../Ch10/Ch10_ChiSquare_1.rst:409
msgid "10.828"
msgstr "10.828"

#: ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "0.103"
msgstr "0.103"

#: ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "0.211"
msgstr "0.211"

#: ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "0.713"
msgstr "0.713"

#: ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "1.386"
msgstr "1.386"

#: ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "2.408"
msgstr "2.408"

#: ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "4.605"
msgstr "4.605"

#: ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "5.991"
msgstr "5.991"

#: ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "9.210"
msgstr "9.210"

#: ../../Ch10/Ch10_ChiSquare_1.rst:411
msgid "13.816"
msgstr "13.816"

#: ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "0.352"
msgstr "0.352"

#: ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "0.584"
msgstr "0.584"

#: ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "1.424"
msgstr "1.424"

#: ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "2.366"
msgstr "2.366"

#: ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "3.665"
msgstr "3.665"

#: ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "6.251"
msgstr "6.251"

#: ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "7.815"
msgstr "7.815"

#: ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "11.345"
msgstr "11.345"

#: ../../Ch10/Ch10_ChiSquare_1.rst:413
msgid "16.266"
msgstr "16.266"

#: ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "0.711"
msgstr "0.711"

#: ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "1.064"
msgstr "1.064"

#: ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "2.195"
msgstr "2.195"

#: ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "3.357"
msgstr "3.357"

#: ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "4.878"
msgstr "4.878"

#: ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "7.779"
msgstr "7.779"

#: ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "9.488"
msgstr "9.488"

#: ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "13.277"
msgstr "13.277"

#: ../../Ch10/Ch10_ChiSquare_1.rst:415
msgid "18.467"
msgstr "18.467"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417 ../../Ch10/Ch10_ChiSquare_7.rst:48
msgid "5"
msgstr "5"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417
msgid "1.145"
msgstr "1.145"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417
msgid "1.610"
msgstr "1.610"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417
msgid "3.000"
msgstr "3.000"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417
msgid "4.351"
msgstr "4.351"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417
msgid "6.064"
msgstr "6.064"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417
msgid "9.236"
msgstr "9.236"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417
msgid "11.070"
msgstr "11.070"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417
msgid "15.086"
msgstr "15.086"

#: ../../Ch10/Ch10_ChiSquare_1.rst:417
msgid "20.515"
msgstr "20.515"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "6"
msgstr "6"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "1.635"
msgstr "1.635"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "2.204"
msgstr "2.204"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "3.828"
msgstr "3.828"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "5.348"
msgstr "5.348"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "7.231"
msgstr "7.231"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "10.645"
msgstr "10.645"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "12.592"
msgstr "12.592"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "16.812"
msgstr "16.812"

#: ../../Ch10/Ch10_ChiSquare_1.rst:419
msgid "22.458"
msgstr "22.458"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "7"
msgstr "7"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "2.167"
msgstr "2.167"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "2.833"
msgstr "2.833"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "4.671"
msgstr "4.671"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "6.346"
msgstr "6.346"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "8.383"
msgstr "8.383"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "12.017"
msgstr "12.017"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "14.067"
msgstr "14.067"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "18.475"
msgstr "18.475"

#: ../../Ch10/Ch10_ChiSquare_1.rst:421
msgid "24.322"
msgstr "24.322"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "8"
msgstr "8"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "2.733"
msgstr "2.733"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "3.490"
msgstr "3.490"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "5.527"
msgstr "5.527"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "7.344"
msgstr "7.344"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "9.524"
msgstr "9.524"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "13.362"
msgstr "13.362"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "15.507"
msgstr "15.507"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "20.090"
msgstr "20.090"

#: ../../Ch10/Ch10_ChiSquare_1.rst:423
msgid "26.124"
msgstr "26.124"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "9"
msgstr "9"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "3.325"
msgstr "3.325"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "4.168"
msgstr "4.168"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "6.393"
msgstr "6.393"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "8.343"
msgstr "8.343"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "10.656"
msgstr "10.656"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "14.684"
msgstr "14.684"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "16.919"
msgstr "16.919"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "21.666"
msgstr "21.666"

#: ../../Ch10/Ch10_ChiSquare_1.rst:425
msgid "27.877"
msgstr "27.877"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427 ../../Ch10/Ch10_ChiSquare_7.rst:20
#: ../../Ch10/Ch10_ChiSquare_7.rst:48
msgid "10"
msgstr "10"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427
msgid "3.940"
msgstr "3.940"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427
msgid "4.865"
msgstr "4.865"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427
msgid "7.267"
msgstr "7.267"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427
msgid "9.342"
msgstr "9.342"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427
msgid "11.781"
msgstr "11.781"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427
msgid "15.987"
msgstr "15.987"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427
msgid "18.307"
msgstr "18.307"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427
msgid "23.209"
msgstr "23.209"

#: ../../Ch10/Ch10_ChiSquare_1.rst:427
msgid "29.588"
msgstr "29.588"

#: ../../Ch10/Ch10_ChiSquare_1.rst:430
msgid ""
"So, if our calculated χ² statistic is bigger than the critical value of "
"7.815, then we can reject the null hypothesis (remember that the null "
"hypothesis, H\\ :sub:`0`, is that all four suits are chosen with equal "
"probability). Since we actually already calculated that before (i.e., χ² = "
"8.44) we can reject the null hypothesis. And that’s it, basically. You now "
"know “Pearson’s χ² test for the goodness-of-fit”. Lucky you."
msgstr ""
"Så hvis den beregnede χ²-statistikken vår er større enn den kritiske verdien "
"på 7,815, kan vi forkaste nullhypotesen (husk at nullhypotesen, H\\ :sub:"
"`0`, er at alle de fire fargene er valgt med like stor sannsynlighet). Siden "
"vi faktisk allerede har regnet ut dette tidligere (dvs. χ² = 8,44), kan vi "
"forkaste nullhypotesen. Og det var i grunnen alt. Du kjenner nå «Pearsons χ²-"
"test for fordeling» (*χ² goodness-of-fit*). Heldig for deg."

#: ../../Ch10/Ch10_ChiSquare_1.rst:438 ../../Ch10/Ch10_ChiSquare_2.rst:240
msgid "Doing the test in jamovi"
msgstr "Gjør testen i jamovi"

#: ../../Ch10/Ch10_ChiSquare_1.rst:440
msgid ""
"Not surprisingly, jamovi provides an analysis that will do these "
"calculations for you. From the main ``Analyses`` toolbar select "
"``Frequencies`` → ``One Sample Proportion Tests`` → ``N Outcomes``. Then in "
"the options panel that appears move the variable you want to analyse "
"(``choice_1`` across into the ``Variable`` box. Also, click on the "
"``Expected counts`` check box so that these are shown on the results table. "
"When you have done all this, you should see the analysis results in jamovi "
"as in :numref:`fig-chisquared_analysis1`. No surprise then that jamovi "
"provides the same expected counts and statistics that we calculated by hand "
"above, with a χ² value of 8.44 with *df* = 3 and *p* =0.038. Note that we "
"don’t need to look up a critical *p*-value threshold value any more, as "
"jamovi gives us the actual *p*-value of the calculated χ² for *df* = 3."
msgstr ""
"Ikke overraskende tilbyr jamovi en analyse som gjør disse beregningene for "
"deg. Fra hovedverktøylinjen ``Analyses`` velger du ``Frequencies`` → ``One "
"Sample Proportion Tests`` → ``N Outcomes``. I analysepanelet som vises, "
"flytter du variabelen du vil analysere (``choice_1`` over i ``Variable``-"
"boksen. Klikk også på avmerkingsboksen ``Expected counts``, slik at disse "
"vises i resultattabellen. Når du har gjort alt dette, bør du se "
"analyseresultatene i jamovi som i :numref:`fig-chisquared_analysis1`. Ikke "
"overraskende gir jamovi de samme forventede tallene og statistikken som vi "
"beregnet for hånd ovenfor, med en χ²-verdi på 8,44 med *df* = 3 og *p* = "
"0,038. Legg merke til at vi ikke lenger trenger å slå opp en kritisk *p*-"
"verdi, ettersom jamovi gir oss den faktiske *p*-verdien av den beregnede χ²-"
"verdien for *df* = 3."

#: ../../Ch10/Ch10_ChiSquare_1.rst:455
msgid "χ² One Sample Proportion Test in jamovi"
msgstr "χ²-test for fordeling (*Goodness of fit*) i jamovi"

#: ../../Ch10/Ch10_ChiSquare_1.rst:459
msgid ""
"χ² One Sample Proportion Test in jamovi, with table showing both observed "
"and expected frequencies and proportions"
msgstr ""
"χ²-test for fordeling (*Goodness of fit*) i jamovi, med tabell som viser "
"både observerte og forventede frekvenser og andeler"

#: ../../Ch10/Ch10_ChiSquare_1.rst:465
msgid "Specifying a different null hypothesis"
msgstr "Spesifisere en annen nullhypotese"

#: ../../Ch10/Ch10_ChiSquare_1.rst:467
msgid ""
"At this point you might be wondering what to do if you want to run a "
"goodness-of-fit test but your null hypothesis is *not* that all categories "
"are equally likely. For instance, let’s suppose that someone had made the "
"theoretical prediction that people should choose red cards 60\\% of the "
"time, and black cards 40\\% of the time (I’ve no idea why you’d predict "
"that), but had no other preferences. If that were the case, the null "
"hypothesis would be to expect 30\\% of the choices to be hearts, 30\\% to be "
"diamonds, 20\\% to be spades and 20\\% to be clubs. In other words we would "
"expect hearts and diamonds to appear 1.5 times more often than spades and "
"clubs (the ratio 30\\% : 20\\% is the same as 1.5 : 1). This seems like a "
"silly theory to me, and it’s pretty easy to test this explicitly specified "
"null hypothesis with the data in our jamovi analysis. In the analysis window "
"(labelled ``Proportion Test (N Outcomes)`` in :numref:`fig-"
"chisquared_analysis1` you can expand the options for ``Expected "
"Proportions``. When you do this, there are options for entering different "
"ratio values for the variable you have selected, in our case this is "
"``choice_1``. Change the ratio to reflect the new null hypothesis, as in :"
"numref:`fig-chisquared_analysis2`, and see how the results change."
msgstr ""
"Nå lurer du kanskje på hva du skal gjøre hvis du ønsker å kjøre en goodness-"
"of-fit-test, men nullhypotesen din er *ikke* at alle kategorier er like "
"sannsynlige. La oss for eksempel anta at noen hadde gjort den teoretiske "
"forutsigelsen at folk ville velge røde kort i 60\\% av tilfellene, og svarte "
"kort i 40\\% av tilfellene (jeg aner ikke hvorfor du skulle forutsi det), "
"men at de ikke hadde noen andre preferanser. I så fall ville nullhypotesen "
"være at 30\\% av valgene ville være hjerter, 30\\% ruter, 20\\% spar og 20\\"
"% kløver. Med andre ord ville vi forvente at hjerter og ruter opptrer 1,5 "
"ganger oftere enn spar og kløver (forholdet 30\\% : 20\\% er det samme som "
"1,5 : 1). Dette virker som en tåpelig teori, og det er ganske enkelt å teste "
"denne eksplisitt spesifiserte nullhypotesen med dataene i jamovi-analysen "
"vår. I analysevinduet (merket ``Proportion Test (N Outcomes)`` i :numref:"
"`fig-chisquared_analysis1`) kan du utvide alternativene for ``Expected "
"Proportions``. Når du gjør dette, har du mulighet til å angi ulike "
"forholdstall for variabelen du har valgt, i vårt tilfelle er dette "
"``choice_1``. Endre forholdstallet slik at det gjenspeiler den nye "
"nullhypotesen, som i :numref:`fig-chisquared_analysis2`, og se hvordan "
"resultatene endres."

#: ../../Ch10/Ch10_ChiSquare_1.rst:485
msgid "The expected counts are now:"
msgstr "De forventede tallene er nå:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:490 ../../Ch10/Ch10_ChiSquare_7.rst:20
msgid "40"
msgstr "40"

#: ../../Ch10/Ch10_ChiSquare_1.rst:490
msgid "60"
msgstr "60"

#: ../../Ch10/Ch10_ChiSquare_1.rst:493
msgid ""
"and the χ² statistic is 4.74, *df* = 3, *p* = 0.192. Now, the results of our "
"updated hypotheses and the expected frequencies are different from what they "
"were last time. As a consequence our χ² test statistic is different, and our "
"*p*-value is different too. Annoyingly, the *p*-value is 0.192, so we can’t "
"reject the null hypothesis (look back at section :doc:`../Ch09/"
"Ch09_HypothesisTesting_05` to remind yourself why). Sadly, despite the fact "
"that the null hypothesis corresponds to a very silly theory, these data "
"don’t provide enough evidence against it."
msgstr ""
"og χ²-statistikken er 4,74, *df* = 3, *p* = 0,192. Nå er resultatene av våre "
"oppdaterte hypoteser og de forventede frekvensene forskjellige fra hva de "
"var forrige gang. Som en konsekvens av dette er χ²-teststatistikken vår "
"annerledes, og *p*-verdien er også annerledes. Irriterende nok er *p*-"
"verdien 0,192, så vi kan ikke forkaste nullhypotesen (se tilbake til "
"avsnitt :doc:`../Ch09/Ch09_HypothesisTesting_05` for å minne deg selv på "
"hvorfor). Til tross for at nullhypotesen tilsvarer en veldig tåpelig teori, "
"gir disse dataene dessverre ikke nok bevis mot den."

#: ../../Ch10/Ch10_ChiSquare_1.rst:504
msgid "Changing expected proportions in the χ² One Sample Proportion Test"
msgstr "Endring av forventede proporsjoner i χ² One Sample Proportion Test"

#: ../../Ch10/Ch10_ChiSquare_1.rst:508
msgid ""
"Changing the expected proportions in the χ² One Sample Proportion Test in "
"jamovi"
msgstr ""
"Endring av de forventede proporsjonene i χ² One Sample Proportion Test i "
"jamovi"

#: ../../Ch10/Ch10_ChiSquare_1.rst:516
msgid "How to report the results of the test"
msgstr "Slik rapporterer du resultatene av testen"

#: ../../Ch10/Ch10_ChiSquare_1.rst:518
msgid ""
"So now you know how the test works, and you know how to do the test using a "
"wonderful jamovi flavoured magic computing box. The next thing you need to "
"know is how to write up the results. After all, there’s no point in "
"designing and running an experiment and then analysing the data if you don’t "
"tell anyone about it! So let’s now talk about what you need to do when "
"reporting your analysis. Let’s stick with our card-suits example. If I "
"wanted to write this result up for a paper or something, then the "
"conventional way to report this would be to write something like this:"
msgstr ""
"Nå vet du hvordan testen fungerer, og du vet hvordan du utfører testen ved "
"hjelp av en magisk databoks med jamovi-smak. Det neste du trenger å vite, er "
"hvordan du skal skrive ned resultatene. Det er jo ingen vits i å utforme og "
"gjennomføre et eksperiment og deretter analysere dataene hvis du ikke "
"forteller noen om det! Så la oss nå snakke om hva du må gjøre når du skal "
"rapportere analysen din. La oss holde oss til eksemplet med kortdraktene "
"våre. Hvis jeg ønsket å skrive om dette resultatet i en artikkel eller "
"lignende, ville den konvensjonelle måten å rapportere dette på være å skrive "
"noe sånt som dette:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:527
msgid ""
"Of the 200 participants in the experiment, 64 selected hearts for their "
"first choice, 51 selected diamonds, 50 selected spades, and 35 selected "
"clubs. A χ²-goodness-of-fit test was conducted to test whether the choice "
"probabilities were identical for all four suits. The results were "
"significant (χ²(3) = 8.44, *p* < 0.05), suggesting that people did not "
"select suits purely at random."
msgstr ""
"Av de 200 deltakerne i eksperimentet valgte 64 hjerter som førstevalg, 51 "
"valgte ruter, 50 valgte spar og 35 valgte kløver. En χ²-goodness-of-fit-test "
"ble utført for å teste om valgsannsynlighetene var identiske for alle de "
"fire fargene. Resultatene var signifikante (χ²(3) = 8,44, *p* < 0,05), noe "
"som tyder på at folk ikke valgte farger helt tilfeldig."

#: ../../Ch10/Ch10_ChiSquare_1.rst:534
msgid ""
"This is pretty straightforward and hopefully it seems pretty unremarkable. "
"That said, there’s a few things that you should note about this description:"
msgstr ""
"Dette er ganske enkelt, og forhåpentligvis virker det ganske uanselig. Når "
"det er sagt, er det et par ting du bør merke deg ved denne beskrivelsen:"

#: ../../Ch10/Ch10_ChiSquare_1.rst:537
msgid ""
"*The statistical test is preceded by the descriptive statistics*. That is, I "
"told the reader something about what the data look like before going on to "
"do the test. In general, this is good practice. Always remember that your "
"reader doesn’t know your data anywhere near as well as you do. So, unless "
"you describe it to them properly, the statistical tests won’t make any sense "
"to them and they’ll get frustrated and cry."
msgstr ""
"*Den statistiske testen innledes med deskriptivstatistikk*. Det vil si at "
"jeg har fortalt leseren noe om hvordan dataene ser ut før jeg går videre til "
"å utføre testen. Generelt er dette god praksis. Husk alltid at leseren ikke "
"kjenner dataene dine på langt nær like godt som deg. Så hvis du ikke "
"beskriver dem ordentlig, vil de statistiske testene ikke gi noen mening for "
"dem, og de vil bli frustrerte og gråte."

#: ../../Ch10/Ch10_ChiSquare_1.rst:544
msgid ""
"*The description tells you what the null hypothesis being tested is*. To be "
"honest, writers don’t always do this but it’s often a good idea in those "
"situations where some ambiguity exists, or when you can’t rely on your "
"readership being intimately familiar with the statistical tools that you’re "
"using. Quite often the reader might not know (or remember) all the details "
"of the test that your using, so it’s a kind of politeness to “remind” them! "
"As far as the goodness-of-fit test goes, you can usually rely on a "
"scientific audience knowing how it works (since it’s covered in most intro "
"stats classes). However, it’s still a good idea to be explicit about stating "
"the null hypothesis (briefly!) because the null hypothesis can be different "
"depending on what you’re using the test for. For instance, in the cards "
"example my null hypothesis was that all the four suit probabilities were "
"identical (i.e., *P*\\ :sub:`1` = *P*\\ :sub:`2` = *P*\\ :sub:`3` = *P*\\ :"
"sub:`4` = 0.25), but there’s nothing special about that hypothesis. I could "
"just as easily have tested the null hypothesis that *P*\\ :sub:`1` = \\0.7 "
"and *P*\\ :sub:`2` = *P*\\ :sub:`3` = *P*\\ :sub:`4` = 0.1 using a goodness-"
"of-fit test. So it’s helpful to the reader if you explain to them what your "
"null hypothesis was. Also, notice that I described the null hypothesis in "
"words, not in maths. That’s perfectly acceptable. You can describe it in "
"maths if you like, but since most readers find words easier to read than "
"symbols, most writers tend to describe the null using words if they can."
msgstr ""
"*Beskrivelsen forteller deg hva nullhypotesen som testes er*. For å være "
"ærlig er det ikke alltid forfattere gjør dette, men det er ofte en god idé i "
"de situasjonene der det er uklarheter, eller når du ikke kan stole på at "
"leserne er godt kjent med de statistiske verktøyene du bruker. Ofte er det "
"ikke sikkert at leseren kjenner til (eller husker) alle detaljene i testen "
"du bruker, så det er en slags høflighetsvisdom å «minne» dem på det! Når det "
"gjelder goodness-of-fit-testen, kan du vanligvis stole på at et "
"vitenskapelig publikum vet hvordan den fungerer (siden den er dekket i de "
"fleste innføringskurs i statistikk). Det er likevel lurt å være eksplisitt "
"med hensyn til nullhypotesen (kort!), fordi nullhypotesen kan være "
"forskjellig avhengig av hva du bruker testen til. I korteneksempelet var "
"nullhypotesen min at alle de fire fargesannsynlighetene var identiske (dvs. "
"*P*\\ :sub:`1` = *P*\\ :sub:`2` = *P*\\ :sub:`3` = *P*\\ :sub:`4` = 0,25), "
"men det er ikke noe spesielt med den hypotesen. Jeg kunne like gjerne ha "
"testet nullhypotesen om at *P*\\ :sub:`1` = \\0,7 og *P*\\ :sub:`2` = *P*\\ :"
"sub:`3` = *P*\\ :sub:`4` = 0,1 ved hjelp av en goodness-of-fit-test. Det er "
"derfor nyttig for leseren hvis du forklarer hva nullhypotesen din var. Legg "
"også merke til at jeg beskrev nullhypotesen med ord, ikke med matematikk. "
"Det er helt akseptabelt. Du kan beskrive den med matematikk hvis du vil, men "
"siden de fleste lesere synes ord er lettere å lese enn symboler, pleier de "
"fleste forfattere å beskrive nullhypotesen med ord hvis de kan."

#: ../../Ch10/Ch10_ChiSquare_1.rst:567
msgid ""
"*A “stat block” is included*. When reporting the results of the test itself, "
"I didn’t just say that the result was significant, I included a “stat "
"block” (i.e., the dense mathematical-looking part in the parentheses) which "
"reports all the “key” statistical information. For the χ²-goodness-of-fit "
"test, the information that gets reported is the test statistic (that the "
"goodness-of-fit statistic was 8.44), the information about the distribution "
"used in the test (χ² with 3 degrees of freedom which is usually shortened to "
"“χ²(3)”), and then the information about whether the result was significant "
"(in this case *p* < 0.05). The particular information that needs to go into "
"the stat block is different for every test, and so each time I introduce a "
"new test I’ll show you what the stat block should look like.\\ [#]_ However, "
"the general principle is that you should always provide enough information "
"so that the reader could check the test results themselves if they really "
"wanted to."
msgstr ""
"*En «statistikkblokk» er inkludert*. Da jeg rapporterte resultatene av selve "
"testen, sa jeg ikke bare at resultatet var signifikant, jeg inkluderte en "
"«statistikkblokk» (dvs. den tette matematisk utseende delen i parentesen) "
"som rapporterer all den «viktigste» statistiske informasjonen. For χ²-test "
"for fordeling er informasjonen som rapporteres, teststatistikken (at "
"teststatistikk var 8,44), informasjonen om fordelingen som ble brukt i "
"testen (χ² med 3 frihetsgrader, som vanligvis forkortes til «χ²(3)»), og "
"deretter informasjonen om hvorvidt resultatet var signifikant (i dette "
"tilfellet *p* < 0,05). Hvilken informasjon som skal inn i statistikkblokken, "
"er forskjellig fra test til test, så hver gang jeg introduserer en ny test, "
"vil jeg vise hvordan statistikkblokken bør se ut.\\ [#]_ Det generelle "
"prinsippet er at du alltid bør gi nok informasjon til at leseren selv kan "
"sjekke testresultatene hvis han eller hun virkelig ønsker det."

#: ../../Ch10/Ch10_ChiSquare_1.rst:582
msgid ""
"*The results are interpreted*. In addition to indicating that the result was "
"significant, I provided an interpretation of the result (i.e., that people "
"didn’t choose randomly). This is also a kindness to the reader, because it "
"tells them something about what they should believe about what’s going on in "
"your data. If you don’t include something like this, it’s really hard for "
"your reader to understand what’s going on.\\ [#]_"
msgstr ""
"*Resultatene er tolket*. I tillegg til å indikere at resultatet var "
"signifikant, ga jeg en tolkning av resultatet (dvs. at folk ikke valgte "
"tilfeldig). Dette er også en vennlighet overfor leseren, fordi det forteller "
"dem noe om hva de bør tro om hva som foregår i dataene dine. Hvis du ikke "
"inkluderer noe slikt, er det veldig vanskelig for leseren å forstå hva som "
"foregår.\\ [#]_"

#: ../../Ch10/Ch10_ChiSquare_1.rst:589
msgid ""
"As with everything else, your overriding concern should be that you "
"*explain* things to your reader. Always remember that the point of reporting "
"your results is to communicate to another human being. I cannot tell you "
"just how many times I’ve seen the results section of a report or a thesis or "
"even a scientific article that is just gibberish, because the writer has "
"focused solely on making sure they’ve included all the numbers and forgotten "
"to actually communicate with the human reader."
msgstr ""
"Som med alt annet bør du først og fremst være opptatt av at du *forklarer* "
"ting for leseren. Husk alltid at poenget med å rapportere resultatene dine "
"er å kommunisere til et annet menneske. Jeg vet ikke hvor mange ganger jeg "
"har sett resultatdelen av en rapport, en avhandling eller til og med en "
"vitenskapelig artikkel som bare er volapyk, fordi forfatteren utelukkende "
"har fokusert på å få med alle tallene og glemt å kommunisere med den "
"menneskelige leseren."

#: ../../Ch10/Ch10_ChiSquare_1.rst:598
msgid "A comment on statistical notation"
msgstr "En kommentar til statistisk notasjon"

#: ../../Ch10/Ch10_ChiSquare_1.rst:0
msgid "*Satan delights equally in statistics and in quoting scripture*"
msgstr "*Satan gleder seg like mye over statistikk som over å sitere bibelen*"

#: ../../Ch10/Ch10_ChiSquare_1.rst:0
msgid "– H.G. Wells"
msgstr "- H.G. Wells"

#: ../../Ch10/Ch10_ChiSquare_1.rst:603
msgid ""
"If you’ve been reading very closely, and are as much of a mathematical "
"pedant as I am, there is one thing about the way I wrote up the χ²-test in "
"the last section that might be bugging you a little bit. There’s something "
"that feels a bit wrong with writing “χ²(3) = 8.44”, you might be thinking. "
"After all, it’s the goodness-of-fit statistic that is equal to 8.44, so "
"shouldn’t I have written χ² = 8.44` or maybe GOF = 8.44? This seems to be "
"conflating the *sampling distribution* (i.e., χ² with *df* = 3) with the "
"*test statistic* (i.e., χ²). Odds are you figured it was a typo, since χ and "
"*X* look pretty similar. Oddly, it’s not. Writing χ²(3) = 8.44 is "
"essentially a highly condensed way of writing “the sampling distribution of "
"the test statistic is χ²(3), and the value of the test statistic is 8.44”."
msgstr ""
"Hvis du har lest nøye med, og er en like stor matematisk pedant som meg, er "
"det én ting ved måten jeg skrev opp χ²-testen i forrige avsnitt som kanskje "
"irriterer deg litt. Det er noe som føles litt feil med å skrive «χ²(3) = "
"8,44», tenker du kanskje. Det er jo tross alt goodness-of-fit-statistikken "
"som er lik 8,44, så burde jeg ikke ha skrevet χ² = 8,44` eller kanskje GOF = "
"8,44? Dette ser ut til å være en sammenblanding av *utvalgsfordelingen* "
"(dvs. χ² med *df* = 3) med *teststatistikken* (dvs. χ²). Du trodde sikkert "
"at det var en skrivefeil, siden χ og *X* ser ganske like ut. Merkelig nok er "
"det ikke det. Å skrive χ²(3) = 8,44 er egentlig en svært forkortet måte å "
"skrive «utvalgsfordeling til teststatistikken er χ²(3), og verdien av "
"teststatistikken er 8,44»."

#: ../../Ch10/Ch10_ChiSquare_1.rst:615
msgid ""
"In one sense, this is kind of stupid. There are *lots* of different test "
"statistics out there that turn out to have a χ²-sampling-distribution. The "
"χ²-statistic that we’ve used for our goodness-of-fit test is only one of "
"many (albeit one of the most commonly encountered ones). In a sensible, "
"perfectly organised world we’d *always* have a separate name for the test "
"statistic and the sampling distribution. That way, the stat block itself "
"would tell you exactly what it was that the researcher had calculated. "
"Sometimes this happens. For instance, the test statistic used in the Pearson "
"goodness-of-fit test is written χ², but there’s a closely related test known "
"as the *G*-test (:ref:`Sokal & Rohlf, 2011 <Sokal_2011>`),\\ [#]_ in which "
"the test statistic is written as *G*. As it happens, the Pearson goodness-of-"
"fit test and the *G*-test both test the same null hypothesis, and the "
"sampling distribution is exactly the same (i.e., a χ²-distribution  with *k* "
"- 1 degrees of freedom). If I’d done a *G*-test for the cards data rather "
"than a goodness-of-fit test, then I’d have ended up with a test statistic of "
"*G* = 8.65, which is slightly different from the χ² = 8.44 value that I got "
"earlier and which produces a slightly smaller *p*-value of *p* = 0.034. "
"Suppose that the convention was to report the test statistic, then the "
"sampling distribution, and then the *p*-value. If that were true, then these "
"two situations would produce different stat blocks: my original result would "
"be written χ² = 8.44, χ²(3), *p* = 0.038, whereas the new version using the "
"*G*-test would be written as *G* = 8.65, χ²(3),*p* = 0.034. However, using "
"the condensed reporting standard, the original result is written χ²(3) = "
"8.44, *p* = 0.038, and the new one is written χ²(3) = 8.65,*p* = 0.034, and "
"so it’s actually unclear which test I actually ran."
msgstr ""
"På én måte er dette litt dumt. Det finnes *masser* av ulike teststatistikker "
"der ute som viser seg å ha en χ²-sampling-fordeling. χ²-statistikken som vi "
"har brukt for å teste tilpasningsevnen vår, er bare én av mange (om enn en "
"av de vanligste). I en fornuftig, perfekt organisert verden ville vi "
"*alltid* ha et eget navn for teststatistikken og utvalgsfordelingen. På den "
"måten ville statistikkblokken i seg selv fortalt deg nøyaktig hva det var "
"forskeren hadde beregnet. Noen ganger skjer dette. For eksempel skrives "
"teststatistikken som brukes i Pearsons goodness-of-fit-test χ², men det "
"finnes en nært beslektet test som kalles *G*-testen (:ref:`Sokal & Rohlf, "
"2011 <Sokal_2011>`),\\ [#]_ der teststatistikken skrives som *G*. Pearsons "
"goodness-of-fit-test og *G*-testen tester nemlig begge den samme "
"nullhypotesen, og utvalgsfordelingen er nøyaktig den samme (dvs. en χ²-"
"fordeling med *k* - 1 frihetsgrader). Hvis jeg hadde gjort en *G*-test for "
"kortdataene i stedet for en goodness-of-fit-test, ville jeg ha endt opp med "
"en teststatistikk på *G* = 8,65, som er litt forskjellig fra χ² = 8,44-"
"verdien jeg fikk tidligere, og som gir en litt mindre *p*-verdi på *p* = "
"0,034. Anta at konvensjonen var å rapportere teststatistikken, deretter "
"utvalgsfordelingen og til slutt *p*-verdien. I så fall ville disse to "
"situasjonene gitt forskjellige statistikkblokker: Det opprinnelige "
"resultatet mitt ville blitt skrevet χ² = 8,44, χ²(3), *p* = 0,038, mens den "
"nye versjonen med *G*-testen ville blitt skrevet som *G* = 8,65, χ²(3),*p* = "
"0,034. Ved bruk av den kondenserte rapporteringsstandarden skrives "
"imidlertid det opprinnelige resultatet χ²(3) = 8,44, *p* = 0,038, og det nye "
"skrives χ²(3) = 8,65,*p* = 0,034, og dermed er det faktisk uklart hvilken "
"test jeg faktisk kjørte."

#: ../../Ch10/Ch10_ChiSquare_1.rst:641
msgid ""
"So why don’t we live in a world in which the contents of the stat block "
"uniquely specifies what tests were ran? The deep reason is that life is "
"messy. We (as users of statistical tools) want it to be nice and neat and "
"organised. We want it to be *designed*, as if it were a product, but that’s "
"not how life works. Statistics is an intellectual discipline just as much as "
"any other one, and as such it’s a massively distributed, partly-"
"collaborative and partly-competitive project that no-one really understands "
"completely. The things that you and I use as data analysis tools weren’t "
"created by an Act of the Gods of Statistics. They were invented by lots of "
"different people, published as papers in academic journals, implemented, "
"corrected and modified by lots of other people, and then explained to "
"students in textbooks by someone else. As a consequence, there’s a *lot* of "
"test statistics that don’t even have names, and as a consequence they’re "
"just given the same name as the corresponding sampling distribution. As "
"we’ll see later, any test statistic that follows a χ² distribution is "
"commonly called a “χ²-statistic”, anything that follows a *t*-distribution "
"is called a “*t*-statistic”, and so on. But, as the χ² versus *G* example "
"illustrates, two different things with the same sampling distribution are "
"still, well, different."
msgstr ""
"Så hvorfor lever vi ikke i en verden der innholdet i stat-blokken entydig "
"angir hvilke tester som ble kjørt? Den dypeste grunnen er at livet er "
"rotete. Vi (som brukere av statistiske verktøy) ønsker at det skal være pent "
"og ryddig og organisert. Vi vil at det skal være *designet*, som om det var "
"et produkt, men det er ikke slik livet fungerer. Statistikk er en "
"intellektuell disiplin like mye som alle andre, og som sådan er det et "
"massivt distribuert, delvis samarbeidende og delvis konkurrerende prosjekt "
"som ingen egentlig forstår helt. De tingene du og jeg bruker som verktøy for "
"dataanalyse, ble ikke skapt av statistikkgudene. De ble oppfunnet av mange "
"forskjellige mennesker, publisert som artikler i akademiske tidsskrifter, "
"implementert, korrigert og modifisert av mange andre mennesker, og deretter "
"forklart til studenter i lærebøker av noen andre. Som en konsekvens av dette "
"er det *mange* teststatistikker som ikke engang har navn, og som en "
"konsekvens av dette blir de bare gitt samme navn som den tilsvarende "
"utvalgsfordelingen. Som vi skal se senere, kalles en teststatistikk som "
"følger en χ²-fordeling ofte for en «χ²-statistikk», alt som følger en *t*-"
"fordeling kalles for en «*t*-statistikk», og så videre. Men som χ² versus "
"*G*-eksempelet illustrerer, er to forskjellige ting med samme "
"utvalgsfordeling fortsatt, vel, forskjellige."

#: ../../Ch10/Ch10_ChiSquare_1.rst:660
msgid ""
"As a consequence, it’s sometimes a good idea to be clear about what the "
"actual test was that you ran, especially if you’re doing something unusual. "
"If you just say “χ²-test” it’s not actually clear what test you’re talking "
"about. Although, since the two most common χ² tests are the goodness-of-fit "
"test and the :doc:`test of independence (or association) "
"<Ch10_ChiSquare_2>`, most readers with stats training can probably guess. "
"Nevertheless, it’s something to be aware of."
msgstr ""
"Derfor er det noen ganger lurt å være tydelig på hva den faktiske testen du "
"kjørte var, spesielt hvis du gjør noe uvanlig. Hvis du bare sier «χ²-test», "
"er det ikke klart hvilken test du egentlig snakker om. Men siden de to "
"vanligste χ²-testene er test for fordeling og :doc:`test for uavhengighet "
"(eller assosiasjon) <Ch10_ChiSquare_2>`, kan nok de fleste lesere med "
"statistikkopplæring gjette seg til det. Likevel er det noe å være oppmerksom "
"på."

#: ../../Ch10/Ch10_ChiSquare_1.rst:671
msgid "A vector is a sequence of data elements of the same basic type"
msgstr "En vektor er en sekvens av dataelementer av samme grunntype"

#: ../../Ch10/Ch10_ChiSquare_1.rst:674
msgid ""
"If you rewrite the equation for the goodness-of-fit statistic as a sum over "
"*k* - 1 independent things you get the “proper” sampling distribution, which "
"is χ²-distribution with *k* - 1 degrees of freedom. It’s beyond the scope of "
"an introductory book to show the maths in that much detail. All I wanted to "
"do is give you a sense of why the goodness-of-fit statistic is associated "
"with the χ²-distribution."
msgstr ""
"Hvis du omskriver ligningen for goodness-of-fit-statistikken som en sum over "
"*k* - 1 uavhengige ting, får du den «riktige» utvalgsfordelingen, som er χ²-"
"fordelingen med *k* - 1 frihetsgrader. Det er utenfor rammen av en "
"introduksjonsbok å vise matematikken så detaljert. Alt jeg ønsket å gjøre, "
"var å gi deg en forståelse av hvorfor goodness-of-fit-statistikken er "
"knyttet til χ²-fordelingen."

#: ../../Ch10/Ch10_ChiSquare_1.rst:682
msgid ""
"I feel obliged to point out that this is an over-simplification. It works "
"nicely for quite a few situations, but every now and then we’ll come across "
"degrees of freedom values that aren’t whole numbers. Don’t let this worry "
"you too much; when you come across this just remind yourself that “degrees "
"of freedom” is actually a bit of a messy concept, and that the nice simple "
"story that I’m telling you here isn’t the whole story. For an introductory "
"class it’s usually best to stick to the simple story, but I figure it’s best "
"to warn you to expect this simple story to fall apart. If I didn’t give you "
"this warning you might start getting confused when you see *df* = 3.4 or "
"something, (incorrectly) thinking that you had misunderstood something that "
"I’ve taught you rather than (correctly) realising that there’s something "
"that I haven’t told you."
msgstr ""
"Jeg føler meg forpliktet til å påpeke at dette er en forenkling. Den "
"fungerer fint i ganske mange situasjoner, men av og til vil vi støte på "
"frihetsgrader som ikke er hele tall. Ikke la dette bekymre deg for mye; når "
"du støter på dette, er det bare å minne deg selv på at «frihetsgrader» "
"faktisk er et litt rotete konsept, og at den fine, enkle historien jeg "
"forteller deg her, ikke er hele historien. For en introduksjonskurs er det "
"vanligvis best å holde seg til den enkle historien, men jeg synes det er "
"best å advare deg om at denne enkle historien kan falle fra hverandre. Hvis "
"jeg ikke hadde gitt dere denne advarselen, ville dere kanskje blitt "
"forvirret når dere ser *df* = 3,4 eller noe sånt, og (feilaktig) trodd at "
"dere hadde misforstått noe av det jeg har lært dere, i stedet for (riktig) å "
"innse at det er noe jeg ikke har fortalt dere."

#: ../../Ch10/Ch10_ChiSquare_1.rst:696
msgid ""
"In practice, the sample size isn’t always fixed. For example, we might run "
"the experiment over a fixed period of time and the number of people "
"participating depends on how many people show up. That doesn’t matter for "
"the current purposes."
msgstr ""
"I praksis er utvalgsstørrelsen ikke alltid fast. Vi kan for eksempel kjøre "
"eksperimentet over en bestemt tidsperiode, og antallet deltakere avhenger av "
"hvor mange som møter opp. Det spiller ingen rolle for dette formålet."

#: ../../Ch10/Ch10_ChiSquare_1.rst:702
msgid ""
"Well, sort of. The conventions for how statistics should be reported tend to "
"differ somewhat from discipline to discipline. I’ve tended to stick with how "
"things are done in psychology, since that’s what I do. But the general "
"principle of providing enough information to the reader to allow them to "
"check your results is pretty universal, I think."
msgstr ""
"Vel, på en måte. Konvensjonene for hvordan statistikk skal rapporteres, har "
"en tendens til å variere noe fra fagfelt til fagfelt. Jeg har holdt meg til "
"hvordan ting gjøres i psykologi, siden det er det jeg driver med. Men det "
"generelle prinsippet om å gi leseren nok informasjon til at de kan sjekke "
"resultatene dine, tror jeg er ganske universelt."

#: ../../Ch10/Ch10_ChiSquare_1.rst:709
msgid ""
"To some people, this advice might sound odd, or at least in conflict with "
"the “usual” advice on how to write a technical report. Very typically, "
"students are told that the “results” section of a report is for describing "
"the data and reporting statistical analysis, and the “discussion” section is "
"for providing interpretation. That’s true as far as it goes, but I think "
"people often interpret it way too literally. The way I usually approach it "
"is to provide a quick and simple interpretation of the data in the results "
"section, so that my reader understands what the data are telling us. Then, "
"in the discussion, I try to tell a bigger story about how my results fit "
"with the rest of the scientific literature. In short, don’t let the "
"“interpretation goes in the discussion” advice turn your results section "
"into incomprehensible garbage. Being understood by your reader is *much* "
"more important."
msgstr ""
"For noen kan dette rådet høres merkelig ut, eller i det minste være i strid "
"med de «vanlige» rådene om hvordan man skriver en teknisk rapport. Vanligvis "
"får studenter beskjed om at «resultat»-delen av en rapport er til for å "
"beskrive dataene og rapportere statistiske analyser, mens «diskusjon»-delen "
"er til for å gi en tolkning. Det er for så vidt sant, men jeg tror folk ofte "
"tolker det altfor bokstavelig. Jeg pleier å gi en rask og enkel tolkning av "
"dataene i resultatdelen, slik at leseren forstår hva dataene forteller oss. "
"I diskusjonsdelen prøver jeg deretter å fortelle en større historie om "
"hvordan resultatene mine passer med resten av den vitenskapelige "
"litteraturen. Kort sagt, ikke la rådet om at «tolkningen kommer i "
"diskusjonen» gjøre resultatdelen din til uforståelig søppel. Det er *mye* "
"viktigere å bli forstått av leseren."

#: ../../Ch10/Ch10_ChiSquare_1.rst:724
msgid ""
"Complicating matters, the *G*-test is a special case of a whole class of "
"tests that are known as *likelihood ratio tests* (LRT). I don’t cover LRTs "
"in this book, but they are quite handy things to know about."
msgstr ""
"For å komplisere saken er *G*-testen et spesialtilfelle av en hel klasse av "
"tester som kalles *likelihood ratio-tester* (LRT). Jeg tar ikke for meg LRT-"
"er i denne boken, men de er ganske nyttige å kjenne til."

#: ../../Ch10/Ch10_ChiSquare_2.rst:4
msgid "The χ² (chi-square) test of independence (or association)"
msgstr "χ²-testen (kjikvadrat) for uavhengighet (eller assosiasjon)"

#: ../../Ch10/Ch10_ChiSquare_2.rst:9 ../../Ch10/Ch10_ChiSquare_2.rst:17
#: ../../Ch10/Ch10_ChiSquare_2.rst:23
msgid "GUARDBOT 1:"
msgstr "GUARDBOT 1:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:9
msgid "Halt!"
msgstr "Holdt!"

#: ../../Ch10/Ch10_ChiSquare_2.rst:11 ../../Ch10/Ch10_ChiSquare_2.rst:19
msgid "GUARDBOT 2:"
msgstr "GUARDBOT 2:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:11
msgid "Be you robot or human?"
msgstr "Er du robot eller menneske?"

#: ../../Ch10/Ch10_ChiSquare_2.rst:13
msgid "LEELA:"
msgstr "LEELA:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:13
msgid "Robot… we be."
msgstr "Robot… det er vi."

#: ../../Ch10/Ch10_ChiSquare_2.rst:15
msgid "FRY:"
msgstr "FRY:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:15
msgid "Uh, yup! Just two robots out roboting it up! Eh?"
msgstr "Uh, jepp! Bare to roboter som er ute og robotiserer! Hva?"

#: ../../Ch10/Ch10_ChiSquare_2.rst:17
msgid "Administer the test."
msgstr "Administrer testen."

#: ../../Ch10/Ch10_ChiSquare_2.rst:19
msgid ""
"Which of the following would you most prefer? A: A puppy, B: A pretty flower "
"from your sweetie, or C: A large properly-formatted data file?"
msgstr ""
"Hva av følgende foretrekker du mest? A: En valp, B: En vakker blomst fra "
"kjæresten din, eller C: En stor, riktig formatert datafil?"

#: ../../Ch10/Ch10_ChiSquare_2.rst:23
msgid "Choose!"
msgstr "Velg!"

#: ../../Ch10/Ch10_ChiSquare_2.rst:26
msgid "Futurama, “Fear of a Bot Planet”"
msgstr "Futurama, «*Fear of a Bot Planet*»"

#: ../../Ch10/Ch10_ChiSquare_2.rst:28
msgid ""
"The other day I was watching an animated documentary examining the quaint "
"customs of the natives of the planet *Chapek 9*. Apparently, in order to "
"gain access to their capital city a visitor must prove that they’re a robot, "
"not a human. In order to determine whether or not a visitor is human, the "
"natives ask whether the visitor prefers puppies, flowers, or large, properly "
"formatted data files. “Pretty clever,” I thought to myself “but what if "
"humans and robots have the same preferences? That probably wouldn’t be a "
"very good test then, would it?” As it happens, I got my hands on the testing "
"data that the civil authorities of *Chapek 9* used to check this. It turns "
"out that what they did was very simple. They found a bunch of robots and a "
"bunch of humans and asked them what they preferred. I saved their data in "
"the |chapek9|_ data set, which we can now load into jamovi. As well as the "
"``ID`` variable that identifies individual people, there are two nominal "
"text variables |nominal|, ``species`` and ``choice``. In total there are 180 "
"entries in the data set, one for each person (counting both robots and "
"humans as “people”) who was asked to make a choice. Specifically, there are "
"93 humans and 87 robots, and overwhelmingly the preferred choice is the data "
"file. You can check this yourself by asking jamovi for ``Frequency Tables``, "
"under the ``Exploration`` → ``Descriptives`` button. However, this summary "
"does not address the question we’re interested in. To do that, we need a "
"more detailed description of the data. What we want to do is look at the "
"``choices`` broken down *by* ``species``. That is, we need to cross-tabulate "
"the data (see :doc:`../Ch06/Ch06_DataHandling_1`). In jamovi we do this "
"using the ``Frequencies`` → ``Contingency Tables`` →  ``Independent "
"Samples`` analysis, and we should get a table something like this:"
msgstr ""
"Her om dagen så jeg på en animert dokumentar om de eiendommelige skikkene "
"til de innfødte på planeten *Chapek 9*. For å få adgang til hovedstaden må "
"en besøkende bevise at han eller hun er en robot og ikke et menneske. For å "
"avgjøre om en besøkende er et menneske eller ikke, spør de innfødte om den "
"besøkende foretrekker valper, blomster eller store, korrekt formaterte "
"datafiler. «Ganske smart», tenkte jeg, «men hva om mennesker og roboter har "
"de samme preferansene? Da ville det vel ikke være en særlig god test?» "
"Tilfeldigvis fikk jeg tak i testdataene som de sivile myndighetene i *Chapek "
"9* brukte for å sjekke dette. Det viser seg at det de gjorde var veldig "
"enkelt. De fant en haug med roboter og en haug med mennesker og spurte dem "
"hva de foretrakk. Jeg lagret dataene deres i datasettet |chapek9|_, som vi "
"nå kan laste inn i jamovi. I tillegg til variabelen ``ID`` som identifiserer "
"individuelle personer, er det to nominelle tekstvariabler |nominal|, "
"``species`` og ``choice``. Totalt er det 180 oppføringer i datasettet, én "
"for hver person (både roboter og mennesker regnes som «personer») som ble "
"bedt om å ta et valg. Det er 93 mennesker og 87 roboter, og det er en "
"overveldende majoritet som foretrekker datafilen. Du kan sjekke dette selv "
"ved å be jamovi om ``Frequency Tables``, under ``Exploration`` → "
"``Descriptives``-knappen. Dette sammendraget svarer imidlertid ikke på det "
"spørsmålet vi er interessert i. Til det trenger vi en mer detaljert "
"beskrivelse av dataene. Det vi ønsker å gjøre, er å se på valgene "
"(``choices``)fordelt *på* arter (``species``). Det vil si at vi må "
"krysstabulere dataene (se :doc:`../Ch06/Ch06_DataHandling_1`). I jamovi gjør "
"vi dette ved hjelp av analysen ``Frequencies`` → ``Contingency Tables`` → "
"``Independent Samples``, og vi bør få en tabell omtrent som denne:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:54 ../../Ch10/Ch10_ChiSquare_2.rst:83
msgid "Robot"
msgstr "Robot"

#: ../../Ch10/Ch10_ChiSquare_2.rst:54 ../../Ch10/Ch10_ChiSquare_2.rst:83
msgid "Human"
msgstr "Menneskelig"

#: ../../Ch10/Ch10_ChiSquare_2.rst:54 ../../Ch10/Ch10_ChiSquare_2.rst:83
#: ../../Ch10/Ch10_ChiSquare_6.rst:42 ../../Ch10/Ch10_ChiSquare_7.rst:18
#: ../../Ch10/Ch10_ChiSquare_7.rst:46 ../../Ch10/Ch10_ChiSquare_7.rst:63
msgid "Total"
msgstr "Totalt"

#: ../../Ch10/Ch10_ChiSquare_2.rst:56 ../../Ch10/Ch10_ChiSquare_2.rst:85
msgid "**Puppy**"
msgstr "**Valp**"

#: ../../Ch10/Ch10_ChiSquare_2.rst:56 ../../Ch10/Ch10_ChiSquare_2.rst:58
msgid "13"
msgstr "13"

#: ../../Ch10/Ch10_ChiSquare_2.rst:56
msgid "15"
msgstr "15"

#: ../../Ch10/Ch10_ChiSquare_2.rst:56
msgid "28"
msgstr "28"

#: ../../Ch10/Ch10_ChiSquare_2.rst:58 ../../Ch10/Ch10_ChiSquare_2.rst:87
msgid "**Flower**"
msgstr "**Blomst**"

#: ../../Ch10/Ch10_ChiSquare_2.rst:58 ../../Ch10/Ch10_ChiSquare_7.rst:20
#: ../../Ch10/Ch10_ChiSquare_7.rst:52
msgid "30"
msgstr "30"

#: ../../Ch10/Ch10_ChiSquare_2.rst:58
msgid "43"
msgstr "43"

#: ../../Ch10/Ch10_ChiSquare_2.rst:60 ../../Ch10/Ch10_ChiSquare_2.rst:89
msgid "**Data**"
msgstr "**Data**"

#: ../../Ch10/Ch10_ChiSquare_2.rst:60
msgid "44"
msgstr "44"

#: ../../Ch10/Ch10_ChiSquare_2.rst:60 ../../Ch10/Ch10_ChiSquare_7.rst:50
msgid "65"
msgstr "65"

#: ../../Ch10/Ch10_ChiSquare_2.rst:60
msgid "109"
msgstr "109"

#: ../../Ch10/Ch10_ChiSquare_2.rst:62 ../../Ch10/Ch10_ChiSquare_2.rst:91
#: ../../Ch10/Ch10_ChiSquare_6.rst:48 ../../Ch10/Ch10_ChiSquare_7.rst:24
#: ../../Ch10/Ch10_ChiSquare_7.rst:52 ../../Ch10/Ch10_ChiSquare_7.rst:69
msgid "**Total**"
msgstr "**Totalt**"

#: ../../Ch10/Ch10_ChiSquare_2.rst:62
msgid "87"
msgstr "87"

#: ../../Ch10/Ch10_ChiSquare_2.rst:62
msgid "93"
msgstr "93"

#: ../../Ch10/Ch10_ChiSquare_2.rst:62
msgid "180"
msgstr "180"

#: ../../Ch10/Ch10_ChiSquare_2.rst:65
msgid ""
"From this, it’s quite clear that the vast majority of the humans chose the "
"data file, whereas the robots tended to be a lot more even in their "
"preferences. Leaving aside the question of *why* the humans might be more "
"likely to choose the data file for the moment (which does seem quite odd, "
"admittedly), our first order of business is to determine if the discrepancy "
"between human choices and robot choices in the data set is statistically "
"significant."
msgstr ""
"Det er tydelig at de aller fleste menneskene valgte datafilen, mens robotene "
"hadde en tendens til å være mye jevnere i sine preferanser. Hvis vi ser bort "
"fra spørsmålet om *hvorfor* det er mer sannsynlig at menneskene velger "
"datafilen (som riktignok virker ganske merkelig), er det første vi må gjøre "
"å finne ut om avviket mellom menneskenes og robotenes valg i datasettet er "
"statistisk signifikant."

#: ../../Ch10/Ch10_ChiSquare_2.rst:74
msgid "Constructing our hypothesis test"
msgstr "Gjennomføre en hypotesetest"

#: ../../Ch10/Ch10_ChiSquare_2.rst:76
msgid ""
"How do we analyse this data? Specifically, since my *research* hypothesis is "
"that “humans and robots answer the question in different ways”, how can I "
"construct a test of the *null* hypothesis that “humans and robots answer the "
"question the same way”? As before, we begin by establishing some notation to "
"describe the data:"
msgstr ""
"Hvordan analyserer vi disse dataene? Nærmere bestemt, siden min "
"*forskningshypotese* er at «mennesker og roboter svarer på spørsmålet på "
"forskjellige måter», hvordan kan jeg gjennomføre en test av *nullhypotesen* "
"at «mennesker og roboter svarer på spørsmålet på samme måte»? Som tidligere "
"begynner vi med å etablere noen notasjoner for å beskrive dataene:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:85 ../../Ch10/Ch10_ChiSquare_6.rst:44
msgid "*O*\\ :sub:`11`"
msgstr "*O*\\ :sub:`11`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:85 ../../Ch10/Ch10_ChiSquare_6.rst:44
msgid "*O*\\ :sub:`12`"
msgstr "*O*\\ :sub:`12`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:85 ../../Ch10/Ch10_ChiSquare_6.rst:44
msgid "*R*\\ :sub:`1`"
msgstr "*R*\\ :sub:`1`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:87 ../../Ch10/Ch10_ChiSquare_6.rst:46
msgid "*O*\\ :sub:`21`"
msgstr "*O*\\ :sub:`21`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:87 ../../Ch10/Ch10_ChiSquare_6.rst:46
msgid "*O*\\ :sub:`22`"
msgstr "*O*\\ :sub:`22`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:87 ../../Ch10/Ch10_ChiSquare_6.rst:46
msgid "*R*\\ :sub:`2`"
msgstr "*R*\\ :sub:`2`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:89
msgid "*O*\\ :sub:`31`"
msgstr "*O*\\ :sub:`31`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:89
msgid "*O*\\ :sub:`32`"
msgstr "*O*\\ :sub:`32`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:89
msgid "*R*\\ :sub:`3`"
msgstr "*R*\\ :sub:`3`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:91 ../../Ch10/Ch10_ChiSquare_6.rst:48
msgid "*C*\\ :sub:`1`"
msgstr "*C*\\ :sub:`1`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:91 ../../Ch10/Ch10_ChiSquare_6.rst:48
msgid "*C*\\ :sub:`2`"
msgstr "*C*\\ :sub:`2`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:91 ../../Ch10/Ch10_ChiSquare_6.rst:48
msgid "*N*"
msgstr "*N*"

#: ../../Ch10/Ch10_ChiSquare_2.rst:94
msgid ""
"In this notation we say that *O*\\ :sub:`ij` is a count (observed frequency) "
"of the number of respondents that are of species *j* (robots or human) who "
"gave answer *i* (puppy, flower or data) when asked to make a choice. The "
"total number of observations is written *N*, as usual. Finally, I’ve used "
"*R*\\ :sub:`i` to denote the row totals (e.g., *R*\\ :sub:`2` is the total "
"number of creatures who chose the flower), and *C*\\ :sub:`j` to denote the "
"column totals (e.g., *C*\\ :sub:`1` is the total number of robots).\\ [#]_"
msgstr ""
"I denne notasjonen sier vi at *O*\\ :sub:`ij` er en opptelling (observert "
"frekvens) av antall respondenter som er av arten *j* (robot eller menneske) "
"og som svarte *i* (valp, blomst eller data) da de ble bedt om å ta et valg. "
"Det totale antallet observasjoner skrives *N*, som vanlig. Til slutt har jeg "
"brukt *R*\\ :sub:`i` for å angi radtotaler (f.eks. *R*\\ :sub:`2` er det "
"totale antallet skapninger som valgte blomsten), og *C*\\ :sub:`j` for å "
"angi kolonnesummene (f.eks. *C*\\ :sub:`1` er det totale antallet roboter)."
"\\ [#]_"

#: ../../Ch10/Ch10_ChiSquare_2.rst:103
msgid ""
"So now let’s think about what the null hypothesis says. If robots and humans "
"are responding in the same way to the question, it means that the "
"probability that “a robot says puppy” is the same as the probability that “a "
"human says puppy”, and so on for the other two possibilities. So, if we use "
"*P*\\ :sub:`ij` to denote “the probability that a member of species *j* "
"gives response *i*” then our null hypothesis is that:"
msgstr ""
"Så la oss nå tenke på hva nullhypotesen sier. Hvis roboter og mennesker "
"svarer på samme måte på spørsmålet, betyr det at sannsynligheten for at «en "
"robot sier valp» er den samme som sannsynligheten for at «et menneske sier "
"valp», og så videre for de to andre mulighetene. Så hvis vi bruker *P*\\ :"
"sub:`ij` for å betegne «sannsynligheten for at et medlem av arten *j* gir "
"svaret *i*», så er nullhypotesen vår at:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:112
msgid "H\\ :sub:`0`:"
msgstr "H\\ :sub:`0`:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:112
msgid "All of the following are true:"
msgstr "Alle de følgende påstandene er sanne:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:114
msgid "*P*\\ :sub:`11` = *P*\\ :sub:`12` (same probability of saying “puppy”),"
msgstr ""
"*P*\\ :sub:`11` = *P*\\ :sub:`12` (samme sannsynlighet for å si «valp»),"

#: ../../Ch10/Ch10_ChiSquare_2.rst:117
msgid ""
"*P*\\ :sub:`21` = *P*\\ :sub:`22` (same probability of saying “flower”), and"
msgstr ""
"*P*\\ :sub:`21` = *P*\\ :sub:`22` (samme sannsynlighet for å si «blomst»), og"

#: ../../Ch10/Ch10_ChiSquare_2.rst:120
msgid "*P*\\ :sub:`31` = *P*\\ :sub:`32` (same probability of saying “data”)."
msgstr ""
"*P*\\ :sub:`31` = *P*\\ :sub:`32` (samme sannsynlighet for å si «data»)."

#: ../../Ch10/Ch10_ChiSquare_2.rst:124
msgid ""
"And actually, since the null hypothesis is claiming that the true choice "
"probabilities don’t depend on the species of the person making the choice, "
"we can let *P*\\ :sub:`i` refer to this probability, e.g., *P*\\ :sub:`1` is "
"the true probability of choosing the puppy."
msgstr ""
"Og siden nullhypotesen hevder at de sanne valgsannsynlighetene ikke avhenger "
"av arten til personen som tar valget, kan vi la *P*\\ :sub:`i` referere til "
"denne sannsynligheten, f.eks. er *P*\\ :sub:`1` den sanne sannsynligheten "
"for å velge valpen."

#: ../../Ch10/Ch10_ChiSquare_2.rst:129
msgid ""
"Next, in much the same way that we did with the goodness-of-fit test, what "
"we need to do is calculate the expected frequencies. That is, for each of "
"the observed counts *O*\\ :sub:`ij`, we need to figure out what the null "
"hypothesis would tell us to expect. Let’s denote this expected frequency by "
"*E*\\ :sub:`ij`. This time, it’s a little bit trickier. If there are a total "
"of *C*\\ :sub:`j` people that belong to species *j*, and the true "
"probability of anyone (regardless of species) choosing option *i* is *P*\\ :"
"sub:`i`, then the expected frequency is just:"
msgstr ""
"På samme måte som vi gjorde med goodness-of-fit-testen, må vi nå beregne de "
"forventede frekvensene. Det vil si at vi for hvert av de observerte "
"antallene *O*\\ :sub:`ij` må finne ut hva nullhypotesen skulle tilsi at vi "
"kunne forvente. La oss betegne denne forventede frekvensen med *E*\\ :sub:"
"`ij`. Denne gangen er det litt vanskeligere. Hvis det er totalt *C*\\ :sub:"
"`j` personer som tilhører art *j*, og den sanne sannsynligheten for at noen "
"(uavhengig av art) velger alternativ *i* er *P*\\ :sub:`i`, så er den "
"forventede frekvensen nettopp:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:138
msgid "*E*\\ :sub:`ij` = *C*\\ :sub:`j` · *P*\\ :sub:`i`"
msgstr "*E*\\ :sub:`ij` = *C*\\ :sub:`j` · *P*\\ :sub:`i`"

#: ../../Ch10/Ch10_ChiSquare_2.rst:140
msgid ""
"Now, this is all very well and good, but we have a problem. Unlike the "
"situation we had with the goodness-of-fit test, the null hypothesis doesn’t "
"actually specify a particular value for *P*\\ :sub:`i`. It’s something we "
"have to :doc:`estimate from the data <../Ch08/Ch08_Estimation>`! "
"Fortunately, this is pretty easy to do. If 28 out of 180 people selected the "
"flowers, then a natural estimate for the probability of choosing flowers is "
"28 / 180, which is approximately 0.16. If we phrase this in mathematical "
"terms, what we’re saying is that our estimate for the probability of "
"choosing option *i* is just the row total divided by the total sample size:"
msgstr ""
"Dette er vel og bra, men vi har et problem. I motsetning til situasjonen vi "
"hadde med goodness-of-fit-testen, spesifiserer nullhypotesen faktisk ikke en "
"bestemt verdi for *P*\\ :sub:`i`. Det er noe vi må :doc:`estimere ut fra "
"dataene <../Ch08/Ch08_Estimation>`! Heldigvis er dette ganske enkelt å "
"gjøre. Hvis 28 av 180 personer valgte blomstene, er et naturlig estimat for "
"sannsynligheten for å velge blomster 28 / 180, som er omtrent 0,16. Hvis vi "
"uttrykker dette i matematiske termer, sier vi at estimatet vårt for "
"sannsynligheten for å velge alternativ *i* bare er den totale raden delt på "
"den totale utvalgsstørrelsen:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:151
msgid ""
"\\hat{P}_i = \\frac{R_i}{N}\n"
"\n"
msgstr ""
"\\hat{P}_i = \\frac{R_i}{N}\n"
"\n"

#: ../../Ch10/Ch10_ChiSquare_2.rst:153
msgid ""
"Therefore, our expected frequency can be written as the product (i.e. "
"multiplication) of the row total and the column total, divided by the total "
"number of observations:\\ [#]_"
msgstr ""
"Derfor kan vår forventede frekvens skrives som produktet (dvs. "
"multiplikasjonen) av radtotalen og kolonnesummen, dividert med det totale "
"antallet observasjoner:\\ [#]_"

#: ../../Ch10/Ch10_ChiSquare_2.rst:157
msgid "Ê\\ :sub:`ij` = (R\\ :sub:`i` · C\\ :sub:`j`) / *N*"
msgstr "Ê\\ :sub:`ij` = (R\\ :sub:`i` · C\\ :sub:`j`) / *N*"

#: ../../Ch10/Ch10_ChiSquare_2.rst:159
msgid ""
"Now that we’ve figured out how to calculate the expected frequencies, it’s "
"straightforward to define a test statistic, following the exact same "
"strategy that we used in the goodness-of-fit test. In fact, it’s pretty much "
"the *same* statistic."
msgstr ""
"Nå som vi har funnet ut hvordan vi beregner de forventede frekvensene, er "
"det enkelt å definere en teststatistikk, etter nøyaktig samme strategi som "
"vi brukte i goodness-of-fit-testen. Faktisk er det stort sett *samme* "
"statistikk."

#: ../../Ch10/Ch10_ChiSquare_2.rst:164
msgid ""
"For a contingency table with *r* rows and *c* columns, the equation that "
"defines our χ² statistic is"
msgstr ""
"For en krysstabell med *r* rader og *c* kolonner, er ligningen som definerer "
"χ²-statistikken vår"

#: ../../Ch10/Ch10_ChiSquare_2.rst:167
msgid ""
"\\chi^2 = \\sum_{i=1}^r\\sum_{j=1}^c \\frac{({E}_{ij} - O_{ij})^2}{{E}"
"_{ij}}\n"
"\n"
msgstr ""
"\\chi^2 = \\sum_{i=1}^r\\sum_{j=1}^c \\frac{({E}_{ij} - O_{ij})^2}{{E}_{ij}}"
"\n"
"\n"

#: ../../Ch10/Ch10_ChiSquare_2.rst:169
msgid ""
"The only difference is that I have to include two summation signs (i.e., Σ) "
"to indicate that we’re summing over both rows and columns."
msgstr ""
"Den eneste forskjellen er at jeg må ta med to summeringstegn (Σ) for å "
"indikere at vi summerer over både rader og kolonner."

#: ../../Ch10/Ch10_ChiSquare_2.rst:172
msgid ""
"As before, large values of χ² indicate that the null hypothesis provides a "
"poor description of the data, whereas small values of χ² suggest that it "
"does a good job of accounting for the data. Therefore, just like last time, "
"we want to reject the null hypothesis if χ² is too large."
msgstr ""
"Som tidligere indikerer store verdier av χ² at nullhypotesen gir en dårlig "
"beskrivelse av dataene, mens små verdier av χ² tyder på at den gjør en god "
"jobb med å gjøre rede for dataene. Derfor vil vi, akkurat som forrige gang, "
"forkaste nullhypotesen hvis χ² er for stor."

#: ../../Ch10/Ch10_ChiSquare_2.rst:178
msgid ""
"Not surprisingly, this statistic is χ² distributed. All we need to do is "
"figure out how many degrees of freedom are involved, which actually isn’t "
"too hard. As I mentioned before, you can (usually) think of the degrees of "
"freedom as being equal to the number of data points that you’re analysing, "
"minus the number of constraints. A contingency table with *r* rows and *c* "
"columns contains a total of *r* · *c* observed frequencies, so that’s the "
"total number of observations. What about the constraints? Here, it’s "
"slightly trickier. The answer is always the same"
msgstr ""
"Ikke overraskende er denne statistikken χ²-fordelt. Alt vi trenger å gjøre "
"er å finne ut hvor mange frihetsgrader som er involvert, noe som faktisk "
"ikke er så vanskelig. Som jeg nevnte tidligere, kan du (vanligvis) tenke på "
"at frihetsgradene er lik antall datapunkter du analyserer, minus antall "
"constraints. En krysstabell med *r* rader og *c* kolonner inneholder totalt "
"*r* - *c* observerte frekvenser, så det er det totale antallet "
"observasjoner. Hva med begrensningene? Her er det litt vanskeligere. Svaret "
"er alltid det samme"

#: ../../Ch10/Ch10_ChiSquare_2.rst:188
msgid "*df* = (*r* - 1)(*c* - 1)"
msgstr "*df* = (*r* - 1)(*c* - 1)"

#: ../../Ch10/Ch10_ChiSquare_2.rst:190
msgid ""
"but the explanation for *why* the degrees of freedom takes this value is "
"different depending on the experimental design. For the sake of argument, "
"let’s suppose that we had honestly intended to survey exactly 87 robots and "
"93 humans (column totals fixed by the experimenter), but left the row totals "
"free to vary (row totals are random variables). Let’s think about the "
"constraints that apply here. Well, since we deliberately fixed the column "
"totals by Act of Experimenter, we have *c* constraints right there. But, "
"there’s actually more to it than that. Remember how our null hypothesis had "
"some free parameters (i.e., we had to estimate the *P*\\ :sub:`i` values)? "
"Those matter too. I won’t explain why in this book, but every free parameter "
"in the null hypothesis is rather like an additional constraint. So, how many "
"of those are there? Well, since these probabilities have to sum to 1, "
"there’s only *r* - 1 of these. So our total degrees of freedom is:"
msgstr ""
"men forklaringen på *hvorfor* frihetsgradene tar denne verdien er "
"forskjellig avhengig av forsøksdesignet. La oss for eksempel anta at vi "
"hadde tenkt å undersøke nøyaktig 87 roboter og 93 mennesker (kolonnesummene "
"er fastsatt av eksperimentlederen), men at vi lot radesummene variere fritt "
"(radesummene er tilfeldige variabler). La oss tenke på hvilke begrensninger "
"som gjelder her. Siden vi bevisst fastsatte kolonnesummene ved hjelp av Act "
"of Experimenter, har vi *c* begrensninger akkurat der. Men det er faktisk "
"mer enn det. Husker du at nullhypotesen vår hadde noen frie parametere (dvs. "
"at vi måtte estimere *P*\\ :sub:`i`-verdiene)? De spiller også en rolle. Jeg "
"skal ikke forklare hvorfor i denne boken, men hver eneste frie parameter i "
"nullhypotesen er som en ekstra begrensning. Så hvor mange slike finnes det? "
"Vel, siden disse sannsynlighetene må summere til 1, er det bare *r* - 1 av "
"disse. Så våre totale frihetsgrader er:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:205
msgid ""
"\\begin{array}{rcl}\n"
"df &=& \\mbox{(number of observations)} - \\mbox{(number of constraints)} \\"
"\\\n"
"&=& (rc) - (c + (r-1)) \\\\\n"
"&=& rc - c - r + 1 \\\\\n"
"&=& (r - 1)(c - 1)\n"
"\\end{array}"
msgstr ""
"\\begin{array}{rcl}\n"
"df &=& \\mbox{(antall observasjoner)} - \\mbox{(antall begrensninger)} \\\\\n"
"&=& (rc) - (c + (r-1)) \\\\\n"
"&=& rc - c - r + 1 \\\\\n"
"&=& (r - 1)(c - 1)\n"
"\\end{array}"

#: ../../Ch10/Ch10_ChiSquare_2.rst:214
msgid ""
"Alternatively, suppose that the only thing that the experimenter fixed was "
"the total sample size *N*. That is, we quizzed the first 180 people that we "
"saw and it just turned out that 87 were robots and 93 were humans. This time "
"around our reasoning would be slightly different, but would still lead us to "
"the same answer. Our null hypothesis still has *r* - 1 free parameters "
"corresponding to the choice probabilities, but it now *also* has *c* - 1 "
"free parameters corresponding to the species probabilities, because we’d "
"also have to estimate the probability that a randomly sampled person turns "
"out to be a robot.\\ [#]_ Finally, since we did actually fix the total "
"number of observations *N*, that’s one more constraint. So, now we have *rc* "
"observations, and (*c* - 1) + (*r* - 1) + 1 constraints. What does that give?"
msgstr ""
"Alternativt kan vi tenke oss at det eneste eksperimentlederen fastsatte, var "
"den totale utvalgsstørrelsen *N*. Det vil si at vi spurte de første 180 "
"personene vi så, og det bare viste seg at 87 var roboter og 93 var "
"mennesker. Denne gangen ville resonnementet vårt vært litt annerledes, men "
"det ville likevel ført oss til det samme svaret. Nullhypotesen vår har "
"fortsatt *r* - 1 frie parametere som tilsvarer valgsannsynlighetene, men den "
"har nå *også* *c* - 1 frie parametere som tilsvarer artssannsynlighetene, "
"fordi vi også må estimere sannsynligheten for at en tilfeldig utvalgt person "
"viser seg å være en robot.\\ [#]_ Til slutt, siden vi faktisk fastsatte det "
"totale antallet observasjoner *N*, er det en begrensning til. Så nå har vi "
"*rc* observasjoner og (*c* - 1) + (*r* - 1) + 1 begrensninger. Hva gir det?"

#: ../../Ch10/Ch10_ChiSquare_2.rst:228
msgid ""
"\\begin{array}{rcl}\n"
"df &=& \\mbox{(number of observations)} - \\mbox{(number of constraints)} \\"
"\\\n"
"&=& rc - ( (c-1) + (r-1) + 1) \\\\\n"
"&=& rc - c - r + 1 \\\\\n"
"&=& (r - 1)(c - 1)\n"
"\\end{array}"
msgstr ""
"\\begin{array}{rcl}\n"
"df &=& \\mbox{(antall observasjoner)} - \\mbox{(antall begrensninger)} \\\\\n"
"&=& rc - ( (c-1) + (r-1) + 1) \\\\\n"
"&=& rc - c - r + 1 \\\\\n"
"&=& (r - 1)(c - 1)\n"
"\\end{array}"

#: ../../Ch10/Ch10_ChiSquare_2.rst:237
msgid "Amazing."
msgstr "Fantastisk."

#: ../../Ch10/Ch10_ChiSquare_2.rst:242
msgid ""
"Okay, now that we know how the test works let’s have a look at how it’s done "
"in jamovi. As tempting as it is to lead you through the tedious calculations "
"so that you’re forced to learn it the long way, I figure there’s no point. I "
"already showed you how to do it the long way for the goodness-of-fit test in "
"the last section, and since the test of independence isn’t conceptually any "
"different, you won’t learn anything new by doing it the long way. So instead "
"I’ll go straight to showing you the easy way. After you have run the test in "
"jamovi (``Frequencies`` - ``Contingency Tables`` - ``Independent Samples``), "
"all you have to do is look underneath the contingency table in the jamovi "
"results window and there is the χ² statistic for you. This shows a χ² "
"statistic value of 10.72, with 2 d.f. and *p*-value = 0.005."
msgstr ""
"Ok, nå som vi vet hvordan testen fungerer, la oss ta en titt på hvordan den "
"gjøres i jamovi. Selv om det er fristende å lede deg gjennom de kjedelige "
"utregningene slik at du blir tvunget til å lære det på den lange veien, "
"tenker jeg at det ikke er noe poeng. Jeg har allerede vist deg hvordan du "
"gjør det på den lange måten for goodness-of-fit-testen i forrige avsnitt, og "
"siden uavhengighetstesten ikke er konseptuelt annerledes, vil du ikke lære "
"noe nytt ved å gjøre det på den lange måten. Så i stedet går jeg rett til å "
"vise deg den enkle måten. Etter at du har kjørt testen i jamovi "
"(``Frequencies`` - ``Contingency Tables`` - ``Independent Samples``), er alt "
"du trenger å gjøre å se under krysstabellen i jamovi-resultatvinduet, og der "
"ligger χ²-statistikken for deg. Denne viser en χ²-statistikkverdi på 10,72, "
"med 2 d.f. og *p*-verdi = 0,005."

#: ../../Ch10/Ch10_ChiSquare_2.rst:256
msgid ""
"That was easy, wasn’t it! You can also ask jamovi to show you the expected "
"counts - just click on the check box for ``Expected Counts`` in the "
"``Cells`` options and the expected counts will appear in the contingency "
"table. And whilst you are doing that, an effect size measure would be "
"helpful. We’ll choose ``Phi and Cramer’s V``, and you can specify this from "
"a check box in the ``Statistics`` options, and it gives a value for Cramer’s "
"V of 0.24. We will talk about this some more in just a moment."
msgstr ""
"Det var enkelt, ikke sant! Du kan også be jamovi om å vise deg de forventede "
"antallene - bare klikk på avmerkingsboksen for ``Expected Counts`` i "
"``Cells``-alternativene, så vises de forventede antallene i krysstabellen. "
"Og mens du holder på med dette, kan det være nyttig å måle effektstørrelsen. "
"Vi velger ``Phi and Cramer’s V``, og du kan spesifisere dette i en "
"avmerkingsboks i ``Statistics``-alternativene, og det gir en verdi for "
"Cramer's V på 0,24. Vi skal snakke litt mer om dette om et øyeblikk."

#: ../../Ch10/Ch10_ChiSquare_2.rst:264
msgid "This output gives us enough information to write up the result:"
msgstr "Denne utgaven gir oss nok informasjon til å skrive opp resultatet:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:266
msgid ""
"Pearson’s χ² revealed a significant association between species and choice "
"(χ²\\ (2) = 10.7, *p* < 0.01). Robots appeared to be more likely to say that "
"they prefer flowers, but the humans were more likely to say they prefer data."
msgstr ""
"Pearsons χ² viste en signifikant sammenheng mellom art og valg (χ²\\ (2) = "
"10,7, *p* < 0,01). Robotene så ut til å være mer tilbøyelige til å si at de "
"foretrekker blomster, men menneskene var mer tilbøyelige til å si at de "
"foretrekker data."

#: ../../Ch10/Ch10_ChiSquare_2.rst:271
msgid ""
"Notice that, once again, I provided a little bit of interpretation to help "
"the human reader understand what’s going on with the data. Later on in my "
"discussion section I’d provide a bit more context. To illustrate the "
"difference, here’s what I’d probably say later on:"
msgstr ""
"Legg merke til at jeg nok en gang har lagt inn litt tolkning for å hjelpe "
"leseren med å forstå hva som skjer med dataene. Senere i diskusjonsdelen "
"ville jeg gitt litt mer kontekst. For å illustrere forskjellen, her er hva "
"jeg sannsynligvis ville sagt senere:"

#: ../../Ch10/Ch10_ChiSquare_2.rst:276
msgid ""
"The fact that humans appeared to have a stronger preference for raw data "
"files than robots is somewhat counter-intuitive. However, in context it "
"makes some sense, as the civil authority on Chapek 9 has an unfortunate "
"tendency to kill and dissect humans when they are identified. As such it "
"seems most likely that the human participants did not respond honestly to "
"the question, so as to avoid potentially undesirable consequences. This "
"should be considered to be a substantial methodological weakness."
msgstr ""
"Det faktum at mennesker ser ut til å ha en sterkere preferanse for "
"rådatafiler enn roboter, er noe kontraintuitivt. Men i sammenhengen gir det "
"en viss mening, ettersom den sivile myndigheten på Chapek 9 har en uheldig "
"tendens til å drepe og dissekere mennesker når de blir identifisert. Det "
"virker derfor mest sannsynlig at de menneskelige deltakerne ikke svarte "
"ærlig på spørsmålet, for å unngå potensielt uønskede konsekvenser. Dette må "
"anses som en vesentlig metodisk svakhet."

#: ../../Ch10/Ch10_ChiSquare_2.rst:285
msgid ""
"This could be classified as a rather extreme example of a reactivity effect, "
"I suppose. Obviously, in this case the problem is severe enough that the "
"study is more or less worthless as a tool for understanding the difference "
"preferences among humans and robots. However, I hope this illustrates the "
"difference between getting a statistically significant result (our null "
"hypothesis is rejected in favour of the alternative), and finding something "
"of scientific value (the data tell us nothing of interest about our research "
"hypothesis due to a big methodological flaw)."
msgstr ""
"Dette kan vel klassifiseres som et ganske ekstremt eksempel på en "
"reaktivitetseffekt. I dette tilfellet er problemet åpenbart såpass alvorlig "
"at studien er mer eller mindre verdiløs som et verktøy for å forstå "
"forskjellene i preferanser mellom mennesker og roboter. Jeg håper imidlertid "
"at dette illustrerer forskjellen mellom å få et statistisk signifikant "
"resultat (nullhypotesen forkastes til fordel for alternativet), og å finne "
"noe av vitenskapelig verdi (dataene forteller oss ingenting av interesse om "
"forskningshypotesen vår på grunn av en stor metodologisk feil)."

#: ../../Ch10/Ch10_ChiSquare_2.rst:296
msgid "Postscript"
msgstr "Etterskrift"

#: ../../Ch10/Ch10_ChiSquare_2.rst:298
msgid ""
"I later found out the data were made up, and I’d been watching cartoons "
"instead of doing work."
msgstr ""
"Senere fant jeg ut at dataene var oppdiktet, og at jeg hadde sett på "
"tegnefilm i stedet for å jobbe."

#: ../../Ch10/Ch10_ChiSquare_2.rst:304
msgid ""
"A technical note. The way I’ve described the test pretends that the column "
"totals are fixed (i.e., the researcher intended to survey 87 robots and 93 "
"humans) and the row totals are random (i.e., it just turned out that 28 "
"people chose the puppy). To use the terminology from my mathematical "
"statistics textbook (:ref:`Hogg et al., 2005 <Hogg_2005>`), I should "
"technically refer to this situation as a χ²-test of homogeneity and reserve "
"the term χ²-test of independence for the situation where both the row and "
"column totals are random outcomes of the experiment. In the initial drafts "
"of this book that’s exactly what I did. However, it turns out that these two "
"tests are identical, and so I’ve collapsed them together."
msgstr ""
"En teknisk merknad. Måten jeg har beskrevet testen på, later som om "
"kolonnesummene er faste (dvs. at forskeren hadde tenkt å spørre 87 roboter "
"og 93 mennesker), og at radesummene er tilfeldige (dvs. at det bare viste "
"seg at 28 personer valgte valpen). For å bruke terminologien fra læreboken "
"min i matematisk statistikk (:ref:`Hogg et al., 2005 <Hogg_2005>`), burde "
"jeg teknisk sett referere til denne situasjonen som en χ²-test av "
"homogenitet og reservere begrepet χ²-test for uavhengighet for situasjonen "
"der både rad- og kolonnesummene er tilfeldige utfall av eksperimentet. I de "
"første utkastene til denne boken var det akkurat det jeg gjorde. Det viser "
"seg imidlertid at disse to testene er identiske, og jeg har derfor slått dem "
"sammen."

#: ../../Ch10/Ch10_ChiSquare_2.rst:316
msgid ""
"Technically, *E*\\ :sub:`ij` here is an estimate, so I should probably write "
"it *Ê*\\ :sub:`ij`\\. But since no-one else does, I won’t either."
msgstr ""
"Teknisk sett er *E*\\ :sub:`ij` her et estimat, så jeg burde nok skrive det "
"*Ê*\\ :sub:`ij`\\. Men siden ingen andre gjør det, gjør ikke jeg det heller."

#: ../../Ch10/Ch10_ChiSquare_2.rst:320
msgid "A problem many of us worry about in real life."
msgstr "Et problem mange av oss bekymrer oss for i det virkelige liv."

#: ../../Ch10/Ch10_ChiSquare_3.rst:4
msgid "The continuity correction"
msgstr "Kontinuitetskorreksjonen"

#: ../../Ch10/Ch10_ChiSquare_3.rst:6
msgid ""
"Okay, time for a little bit of a digression. I’ve been lying to you a little "
"bit so far. There’s a tiny change that you need to make to your calculations "
"whenever you only have 1 degree of freedom. It’s called the “continuity "
"correction”, or sometimes the **Yates correction**. Remember what I pointed "
"out earlier: the χ² test is based on an approximation, specifically on the "
"assumption that the binomial distribution starts to look like a normal "
"distribution for large *N*. One problem with this is that it often doesn’t "
"quite work, especially when you’ve only got 1 degree of freedom (e.g., when "
"you’re doing a test of independence on a 2 × 2 contingency table). The main "
"reason for this is that the true sampling distribution for the χ²-statistic "
"is actually discrete (because you’re dealing with categorical data!) but the "
"χ² distribution is continuous. This can introduce systematic problems. "
"Specifically, when *N* is small and when *df* = 1, the goodness-of-fit "
"statistic tends to be “too big”, meaning that you actually have a bigger α "
"value than you think (or, equivalently, the *p*-values are a bit too small)."
msgstr ""
"På tide med en liten digresjon. Jeg har løyet litt for deg så langt. Det er "
"en liten endring du må gjøre i beregningene dine når du bare har én "
"frihetsgrad. Det kalles «kontinuitetskorreksjon», eller noen ganger **Yates-"
"korreksjon**. Husk hva jeg påpekte tidligere: χ²-testen er basert på en "
"tilnærming, nærmere bestemt på antakelsen om at binomialfordelingen begynner "
"å se ut som en normalfordeling for store *N*. Et problem med dette er at det "
"ofte ikke fungerer helt, spesielt når du bare har én frihetsgrad (f.eks. når "
"du gjør en test for uavhengighet på en 2 × 2-krysstabell). Hovedårsaken til "
"dette er at den sanne utvalgsfordelingen for χ²-statistikken faktisk er "
"diskret (fordi du har å gjøre med kategoriale data!), mens χ²-fordelingen er "
"kontinuerlig. Dette kan introdusere systematiske problemer. Når *N* er liten "
"og *df* = 1, har goodness-of-fit-statistikken en tendens til å være «for "
"stor», noe som betyr at du faktisk har en større α-verdi enn du tror (eller, "
"tilsvarende, at *p*-verdiene er litt for små)."

#: ../../Ch10/Ch10_ChiSquare_3.rst:25
msgid ""
":ref:`Yates (1934) <Yates_1934>` suggested a simple fix, in which you "
"redefine the goodness-of-fit statistic as:"
msgstr ""
":ref:`Yates (1934) <Yates_1934>` foreslo en enkel løsning, der du "
"omdefinerer goodness-of-fit-statistikken som:"

#: ../../Ch10/Ch10_ChiSquare_3.rst:28
msgid ""
"\\chi^2 = \\sum_{i} \\frac{(|E_i - O_i| - 0.5)^2}{E_i}\n"
"\n"
msgstr ""
"\\chi^2 = \\sum_{i} \\frac{(|E_i - O_i| - 0.5)^2}{E_i}\n"
"\n"

#: ../../Ch10/Ch10_ChiSquare_3.rst:30
msgid "Basically, he just subtracts off 0.5 everywhere."
msgstr "Han trekker rett og slett fra 0,5 overalt."

#: ../../Ch10/Ch10_ChiSquare_3.rst:32
msgid ""
"As far as I can tell from reading Yates’ paper, the correction is basically "
"a hack. It’s not derived from any principled theory. Rather, it’s based on "
"an examination of the behaviour of the test, and observing that the "
"corrected version seems to work better. You can specify this correction in "
"jamovi from a check box in the ``Statistics`` options, where it is called "
"``χ² continuity correction``."
msgstr ""
"Så vidt jeg kan se etter å ha lest Yates' artikkel, er korreksjonen i bunn "
"og grunn et hack. Den er ikke utledet fra noen prinsipiell teori. Den er "
"snarere basert på en undersøkelse av hvordan testen oppfører seg, og en "
"observasjon av at den korrigerte versjonen ser ut til å fungere bedre. Du "
"kan spesifisere denne korreksjonen i jamovi ved å merke av i en boks i "
"``Statistics``-alternativene, der den kalles ``χ² continuity correction``."

#: ../../Ch10/Ch10_ChiSquare_4.rst:4
msgid "Effect size"
msgstr "Effektstørrelse"

#: ../../Ch10/Ch10_ChiSquare_4.rst:6
msgid ""
"As we discussed earlier in section :doc:`../Ch09/Ch09_HypothesisTesting_08`, "
"it’s becoming commonplace to ask researchers to report some measure of "
"effect size. So, let’s suppose that you’ve run your χ²-test, which turns out "
"to be significant. So you now know that there is some association between "
"your variables (independence test) or some deviation from the specified "
"probabilities (goodness-of-fit test). Now you want to report a measure of "
"effect size. That is, given that there is an association or deviation, how "
"strong is it?"
msgstr ""
"Som vi diskuterte tidligere i avsnitt :doc:`../Ch09/"
"Ch09_HypothesisTesting_08`, er det blitt vanlig å be forskere om å "
"rapportere et mål på effektstørrelse. La oss anta at du har kjørt χ²-testen "
"din, som viser seg å være signifikant. Nå vet du at det er en viss "
"sammenheng mellom variablene dine (uavhengighetstest) eller et visst avvik "
"fra de spesifiserte sannsynlighetene (goodness-of-fit-test). Nå ønsker du å "
"rapportere et mål på effektstørrelsen. Det vil si, gitt at det finnes en "
"sammenheng eller et avvik, hvor sterk er den?"

#: ../../Ch10/Ch10_ChiSquare_4.rst:15
msgid ""
"There are several different measures that you can choose to report, and "
"several different tools that you can use to calculate them. I won’t discuss "
"all of them but will instead focus on the most commonly reported measures of "
"effect size."
msgstr ""
"Det finnes flere ulike mål du kan velge å rapportere, og flere ulike verktøy "
"du kan bruke til å beregne dem. Jeg vil ikke gå inn på alle disse, men i "
"stedet fokusere på de mest vanlige effektstørrelsesmålene."

#: ../../Ch10/Ch10_ChiSquare_4.rst:20
msgid ""
"By default, the two measures that people tend to report most frequently are "
"the ϕ statistic and the somewhat superior version, known as Cramér’s *V*."
msgstr ""
"De to målene som folk oftest rapporterer, er ϕ-statistikken og den noe bedre "
"versjonen, kjent som Cramérs *V*."

#: ../../Ch10/Ch10_ChiSquare_4.rst:24
msgid ""
"Mathematically, they’re very simple. To calculate the ϕ statistic, you just "
"divide your χ² value by the sample size, and take the square root:"
msgstr ""
"Matematisk sett er de veldig enkle. For å beregne ϕ-statistikken dividerer "
"du bare χ²-verdien med utvalgsstørrelsen, og tar kvadratroten:"

#: ../../Ch10/Ch10_ChiSquare_4.rst:28
msgid ""
"\\phi = \\sqrt{\\frac{\\chi^2}{N}}\n"
"\n"
msgstr ""
"\\phi = \\sqrt{\\frac{\\chi^2}{N}}\n"
"\n"

#: ../../Ch10/Ch10_ChiSquare_4.rst:30
msgid ""
"The idea here is that the ϕ statistic is supposed to range between 0 (no "
"association at all) and 1 (perfect association), but it doesn’t always do "
"this when your contingency table is bigger than 2 × 2, which is a total "
"pain. For bigger tables it’s actually possible to obtain ϕ > 1, which is "
"pretty unsatisfactory. So, to correct for this, people usually prefer to "
"report the *V* statistic proposed by :ref:`Cramer (1946) <Cramer_1946>`. "
"It’s a pretty simple adjustment to ϕ. If you’ve got a contingency table with "
"*r* rows and *c* columns, then define *k* = min(*r*, *c*) to be the smaller "
"of the two values. If so, then **Cramér’s V** statistic is:"
msgstr ""
"Tanken her er at ϕ-statistikken skal ligge mellom 0 (ingen sammenheng i det "
"hele tatt) og 1 (perfekt sammenheng), men det gjør den ikke alltid når "
"krysstabellen din er større enn 2 × 2, noe som er veldig irriterende. For "
"større tabeller er det faktisk mulig å få ϕ > 1, noe som er ganske "
"utilfredsstillende. For å korrigere for dette foretrekker folk vanligvis å "
"rapportere *V*-statistikken foreslått av :ref:`Cramer (1946) <Cramer_1946>`. "
"Det er en ganske enkel justering av ϕ. Hvis du har en tilfeldighetstabell "
"med *r* rader og *c* kolonner, kan du definere *k* = min(*r*, *c*) til å "
"være den minste av de to verdiene. I så fall er **Cramérs V**-statistikk:"

#: ../../Ch10/Ch10_ChiSquare_4.rst:40
msgid ""
"V = \\sqrt{\\frac{\\chi^2}{N(k-1)}}\n"
"\n"
msgstr ""
"V = \\sqrt{\\frac{\\chi^2}{N(k-1)}}\n"
"\n"

#: ../../Ch10/Ch10_ChiSquare_4.rst:42
msgid ""
"And you’re done. This seems to be a fairly popular measure, presumably "
"because it’s easy to calculate, and it gives answers that aren’t completely "
"silly. With Cramer’s V, you know that the value really does range from 0 (no "
"association at all) to 1 (perfect association)."
msgstr ""
"Og så er du ferdig. Dette ser ut til å være et ganske populært mål, "
"antakelig fordi det er enkelt å beregne, og fordi det gir svar som ikke er "
"helt tåpelige. Med Cramers V vet du at verdien faktisk varierer fra 0 (ingen "
"sammenheng i det hele tatt) til 1 (perfekt sammenheng)."

#: ../../Ch10/Ch10_ChiSquare_5.rst:4
msgid "Assumptions of the test(s)"
msgstr "Forutsetninger for testen(e)"

#: ../../Ch10/Ch10_ChiSquare_5.rst:6
msgid ""
"All statistical tests make assumptions, and it’s usually a good idea to "
"check that those assumptions are met. For the χ²-tests discussed so far in "
"this chapter, the assumptions are:"
msgstr ""
"Alle statistiske tester har forutsetninger, og det er vanligvis en god idé å "
"sjekke at disse forutsetningene er oppfylt. For χ²-testene som er diskutert "
"så langt i dette kapittelet, er forutsetningene følgende:"

#: ../../Ch10/Ch10_ChiSquare_5.rst:10
msgid ""
"*Expected frequencies are sufficiently large*. Remember how in the previous "
"section we saw that the χ² sampling distribution emerges because the "
"binomial distribution is pretty similar to a normal distribution? Well, like "
"we discussed in chapter :doc:`../Ch07/Ch07_Probability` this is only true "
"when the number of observations is sufficiently large. What that means in "
"practice is that all of the expected frequencies need to be reasonably big. "
"How big is reasonably big? Opinions differ, but the default assumption seems "
"to be that you generally would like to see all your expected frequencies "
"larger than about 5, though for larger tables you would probably be okay if "
"at least 80\\% of the the expected frequencies are above 5 and none of them "
"are below 1. However, from what I’ve been able to discover (:ref:`Cochran, "
"1954 <Cochran_1954>`), these seem to have been proposed as rough guidelines, "
"not hard and fast rules, and they seem to be somewhat conservative (:ref:"
"`Larntz, 1978 <Larntz_1978>`)."
msgstr ""
"*Forventede frekvenser er tilstrekkelig store*. Husker du hvordan vi i "
"forrige avsnitt så at χ²-fordelingen i utvalg oppstår fordi "
"binomialfordelingen er ganske lik en normalfordeling? Vel, som vi diskuterte "
"i kapittel :doc:`../Ch07/Ch07_Probability`, gjelder dette bare når antallet "
"observasjoner er tilstrekkelig stort. I praksis betyr det at alle de "
"forventede frekvensene må være rimelig store. Hvor store er rimelig store? "
"Det er delte meninger om dette, men standardantakelsen ser ut til å være at "
"alle forventede frekvenser bør være større enn ca. 5, selv om det for større "
"tabeller sannsynligvis vil være greit hvis minst 80\\% av de forventede "
"frekvensene er over 5 og ingen av dem er under 1. Etter det jeg har klart å "
"finne ut (:ref:`Cochran, 1954 <Cochran_1954>`), ser det imidlertid ut til at "
"disse ble foreslått som grove retningslinjer, ikke harde og faste regler, og "
"de ser ut til å være noe konservative (:ref:`Larntz, 1978 <Larntz_1978>`)."

#: ../../Ch10/Ch10_ChiSquare_5.rst:25
msgid ""
"*Data are independent of one another*. One somewhat hidden assumption of the "
"χ²-test is that you have to genuinely believe that the observations are "
"independent. Here’s what I mean. Suppose I’m interested in proportion of "
"babies born at a particular hospital that are boys. I walk around the "
"maternity wards and observe 20 girls and only 10 boys. Seems like a pretty "
"convincing difference, right? But later on, it turns out that I’d actually "
"walked into the same ward 10 times and in fact I’d only seen 2 girls and 1 "
"boy. Not as convincing, is it? My original 30 *observations* were massively "
"non-independent, and were only in fact equivalent to 3 independent "
"observations. Obviously this is an extreme (and extremely silly) example, "
"but it illustrates the basic issue. Non-independence “stuffs things up”. "
"Sometimes it causes you to falsely reject the null, as the silly hospital "
"example illustrates, but it can go the other way too. To give a slightly "
"less stupid example, let’s consider what would happen if I’d done the cards "
"experiment slightly differently Instead of asking 200 people to try to "
"imagine sampling one card at random, suppose I asked 50 people to select 4 "
"cards. One possibility would be that *everyone* selects one heart, one club, "
"one diamond and one spade (in keeping with the “representativeness "
"heuristic”; :ref:`Tversky & Kahneman, 1974 <Tversky_1974>`). This is highly "
"non-random behaviour from people, but in this case I would get an observed "
"frequency of 50 for all four suits. For this example the fact that the "
"observations are non-independent (because the four cards that you pick will "
"be related to each other) actually leads to the opposite effect, falsely "
"retaining the null."
msgstr ""
"*Data er uavhengige av hverandre*. En litt skjult forutsetning for χ²-testen "
"er at du virkelig må tro at observasjonene er uavhengige. Her er hva jeg "
"mener. Anta at jeg er interessert i andelen av barna som fødes på et bestemt "
"sykehus som er gutter. Jeg går rundt på fødeavdelingene og observerer 20 "
"jenter og bare 10 gutter. Det virker som en ganske overbevisende forskjell, "
"ikke sant? Men senere viser det seg at jeg faktisk hadde gått inn på den "
"samme avdelingen 10 ganger, og at jeg faktisk bare hadde sett 2 jenter og 1 "
"gutt. Ikke like overbevisende, er det vel? De opprinnelige 30 "
"*observasjonene* mine var svært lite uavhengige, og tilsvarte faktisk bare "
"tre uavhengige observasjoner. Dette er selvsagt et ekstremt (og ekstremt "
"tåpelig) eksempel, men det illustrerer det grunnleggende problemet. "
"Manglende uavhengighet «roter til ting». Noen ganger fører det til at du "
"feilaktig forkaster nullhypotesen, slik det tåpelige sykehuseksempelet "
"illustrerer, men det kan også gå den andre veien. For å gi et litt mindre "
"dumt eksempel, la oss se på hva som ville skjedd hvis jeg hadde gjort "
"korteksperimentet på en litt annen måte. I stedet for å be 200 personer om å "
"prøve å forestille seg at de skulle velge ett kort tilfeldig, kan vi tenke "
"oss at jeg ba 50 personer om å velge fire kort. En mulighet er at *alle* "
"velger én hjerter, én kløver, én ruter og én spar (i tråd med "
"«representativitetsheuristikken»; :ref:`Tversky & Kahneman, 1974 "
"<Tversky_1974>`). Dette er høyst ikke-tilfeldig atferd fra mennesker, men i "
"dette tilfellet ville jeg fått en observert frekvens på 50 for alle fire "
"fargene. I dette eksemplet fører det faktum at observasjonene ikke er "
"uavhengige (fordi de fire kortene du velger, vil være relatert til hverandre)"
" faktisk til den motsatte effekten, slik at nullhypotesen feilaktig "
"opprettholdes."

#: ../../Ch10/Ch10_ChiSquare_5.rst:52
msgid ""
"If you happen to find yourself in a situation where independence is "
"violated, it may be possible to use the McNemar test (which we’ll discuss) "
"or the Cochran test (which we won’t). Similarly, if your expected cell "
"counts are too small, check out the Fisher exact test. It is to these topics "
"that we now turn."
msgstr ""
"Hvis du befinner deg i en situasjon der uavhengigheten er brutt, kan det "
"være mulig å bruke McNemar-testen (som vi skal diskutere) eller Cochran-"
"testen (som vi ikke skal diskutere). På samme måte kan du bruke Fishers "
"eksakte test hvis det forventede celletallet er for lavt. Det er disse "
"temaene vi nå skal se nærmere på."

#: ../../Ch10/Ch10_ChiSquare_6.rst:4
msgid "The Fisher exact test"
msgstr "Fisher eksakt test"

#: ../../Ch10/Ch10_ChiSquare_6.rst:6
msgid ""
"What should you do if your cell counts are too small, but you’d still like "
"to test the null hypothesis that the two variables are independent? One "
"answer would be “collect more data”, but that’s far too glib. There are a "
"lot of situations in which it would be either infeasible or unethical do "
"that. If so, statisticians have a kind of moral obligation to provide "
"scientists with better tests. In this instance, :ref:`Fisher (1922a) "
"<Fisher_1922a>` kindly provided the right answer to the question. To "
"illustrate the basic idea let’s suppose that we’re analysing data from a "
"field experiment looking at the emotional status of people who have been "
"accused of Witchcraft, some of whom are currently being burned at the stake."
"\\ [#]_ Unfortunately for the scientist (but rather fortunately for the "
"general populace), it’s actually quite hard to find people in the process of "
"being set on fire, so the cell counts are awfully small in some cases. A "
"contingency table of the |salem|_ data set illustrates the point:"
msgstr ""
"Hva gjør du hvis celletellingene dine er for små, men du likevel ønsker å "
"teste nullhypotesen om at de to variablene er uavhengige? Ett svar ville "
"være «samle inn mer data», men det er altfor lettvint. Det finnes mange "
"situasjoner der det enten vil være umulig eller uetisk å gjøre det. I så "
"fall har statistikere en slags moralsk forpliktelse til å gi forskerne bedre "
"tester. I dette tilfellet har :ref:`Fisher (1922a) <Fisher_1922a>` gitt det "
"riktige svaret på spørsmålet. For å illustrere den grunnleggende ideen, la "
"oss anta at vi analyserer data fra et felteksperiment der vi ser på den "
"emosjonelle statusen til mennesker som har blitt anklaget for hekseri, "
"hvorav noen for tiden blir brent på bålet.\\ [#]_ Dessverre for forskeren "
"(men heldigvis for befolkningen) er det faktisk ganske vanskelig å finne "
"folk som er i ferd med å bli brent på bålet, så celletallene er fryktelig "
"små i noen tilfeller. En krysstabell av datasettet |salem|_ illustrerer "
"poenget:"

#: ../../Ch10/Ch10_ChiSquare_6.rst:28
msgid ""
"Looking at this data, you’d be hard pressed not to suspect that people not "
"on fire are more likely to be happy than people on fire. However, the χ²-"
"test makes this very hard to test because of the small sample size. So, "
"speaking as someone who doesn’t want to be set on fire, I’d *really* like to "
"be able to get a better answer than this. This is where **Fisher’s exact "
"test** (:ref:`Fisher, 1922a <Fisher_1922a>`) comes in very handy."
msgstr ""
"Når man ser på disse dataene, er det vanskelig å ikke mistenke at folk som "
"ikke er i brann, har større sannsynlighet for å være lykkelige enn folk som "
"er i brann. Men χ²-testen gjør dette svært vanskelig å teste på grunn av den "
"lille utvalgsstørrelsen. Så, som en som ikke ønsker å bli satt fyr på, vil "
"jeg *virkelig* gjerne ha et bedre svar enn dette. Det er her **Fishers "
"eksakte test** (:ref:`Fisher, 1922a <Fisher_1922a>`) kommer veldig godt med."

#: ../../Ch10/Ch10_ChiSquare_6.rst:35
msgid ""
"The Fisher exact test works somewhat differently to the χ²-test (or in fact "
"any of the other hypothesis tests that I talk about in this book) insofar as "
"it doesn’t have a test statistic, but it calculates the *p*-value "
"“directly”. I’ll explain the basics of how the test works for a 2 × 2 "
"contingency table. As before, let’s have some notation:"
msgstr ""
"Fisher eksakt test fungerer noe annerledes enn χ²-testen (eller faktisk noen "
"av de andre hypotesetestene jeg snakker om i denne boken), i og med at den "
"ikke har en teststatistikk, men beregner *p*-verdien «direkte». Jeg skal "
"forklare det grunnleggende om hvordan testen fungerer for en 2 × 2-"
"krysstabell. Som før, la oss ha litt notasjon:"

#: ../../Ch10/Ch10_ChiSquare_6.rst:42
msgid "Happy"
msgstr "Lykkelig"

#: ../../Ch10/Ch10_ChiSquare_6.rst:42
msgid "Sad"
msgstr "Trist"

#: ../../Ch10/Ch10_ChiSquare_6.rst:44
msgid "**Set on fire**"
msgstr "**Satt fyr på**"

#: ../../Ch10/Ch10_ChiSquare_6.rst:46
msgid "**Not set on fire**"
msgstr "**Ikke satt fyr på**"

#: ../../Ch10/Ch10_ChiSquare_6.rst:51
msgid ""
"In order to construct the test Fisher treats both the row and column totals "
"(*R*\\ :sub:`1`\\, *R*\\ :sub:`2`, *C*\\ :sub:`1` and *C*\\ :sub:`2`\\) as "
"known, fixed quantities and then calculates the probability that we would "
"have obtained the observed frequencies that we did (*O*\\ :sub:`11`\\, "
"*O*\\ :sub:`12`\\, *O*\\ :sub:`21` and *O*\\ :sub:`22`\\) given those "
"totals. In the notation that we developed in chapter :doc:`../Ch07/"
"Ch07_Probability` this is written:"
msgstr ""
"For å gjennomføre testen behandler Fisher både rad- og kolonnesummene "
"(*R*\\ :sub:`1`\\, *R*\\ :sub:`2`, *C*\\ :sub:`1` og *C*\\ :sub:`2`\\) som "
"kjente, faste størrelser, og beregner deretter sannsynligheten for at vi "
"ville ha fått de observerte frekvensene vi fikk (*O*\\ :sub:`11`\\, *O*\\ :"
"sub:`12`\\, *O*\\ :sub:`21` og *O*\\ :sub:`22`\\) gitt disse summene. I "
"notasjonen som vi utviklet i kapittel :doc:`../Ch07/Ch07_Probability` "
"skrives dette:"

#: ../../Ch10/Ch10_ChiSquare_6.rst:60
msgid ""
"*P*\\(*O*\\ :sub:`11`, *O*\\ :sub:`12`, *O*\\ :sub:`21`, *O*\\ :sub:`22` | "
"*R*\\ :sub:`1`, *R*\\ :sub:`2`, *C*\\ :sub:`1`, *C*\\ :sub:`2`)"
msgstr ""
"*P*\\(*O*\\ :sub:`11`, *O*\\ :sub:`12`, *O*\\ :sub:`21`, *O*\\ :sub:`22` | "
"*R*\\ :sub:`1`, *R*\\ :sub:`2`, *C*\\ :sub:`1`, *C*\\ :sub:`2`)"

#: ../../Ch10/Ch10_ChiSquare_6.rst:62
msgid ""
"and as you might imagine, it’s a slightly tricky exercise to figure out what "
"this probability is. But it turns out that this probability is described by "
"a distribution known as the *hypergeometric distribution*. What we have to "
"do to calculate our *p*-value is calculate the probability of observing this "
"particular table *or a table that is “more extreme”*.\\ [#]_ Back in the "
"1920s, computing this sum was daunting even in the simplest of situations, "
"but these days it’s pretty easy as long as the tables aren’t too big and the "
"sample size isn’t too large. The conceptually tricky issue is to figure out "
"what it means to say that one contingency table is more “extreme” than "
"another. The easiest solution is to say that the table with the lowest "
"probability is the most extreme. This then gives us the *p*-value."
msgstr ""
"og som du kanskje kan tenke deg, er det en litt vanskelig øvelse å finne ut "
"hva denne sannsynligheten er. Men det viser seg at denne sannsynligheten "
"beskrives av en fordeling som kalles den *hypergeometriske fordelingen*. Det "
"vi må gjøre for å beregne *p*-verdien vår, er å beregne sannsynligheten for "
"å observere akkurat denne tabellen *eller en tabell som er «mer ekstrem»*.\\ "
"[#]_ På 1920-tallet var det å beregne denne summen skremmende selv i de "
"enkleste situasjoner, men i dag er det ganske enkelt så lenge tabellene ikke "
"er for store og utvalgsstørrelsen ikke er for stor. Det konseptuelt "
"vanskelige problemet er å finne ut hva det vil si å si at en krysstabell er "
"mer «ekstrem» enn en annen. Den enkleste løsningen er å si at tabellen med "
"den laveste sannsynligheten er den mest ekstreme. Dette gir oss da *p*-"
"verdien."

#: ../../Ch10/Ch10_ChiSquare_6.rst:75
msgid ""
"You can specify this test in jamovi from a check box in the ``Statistics`` "
"options of the ``Contingency Tables`` analysis. When you do this with the |"
"salem|_ data set, the ``Fisher's exact test`` statistic is shown in the "
"results. The main thing we’re interested in here is the *p*-value, which in "
"this case is small enough (*p* = 0.036) to justify rejecting the null "
"hypothesis that people on fire are just as happy as people not on fire (see :"
"numref:`fig-Fisher`)."
msgstr ""
"Du kan spesifisere denne testen i jamovi fra en avmerkingsboks i "
"``Statistics``-opsjonene i ``Contingency Tables``-analysen. Når du gjør "
"dette med datasettet |salem|_, vises statistikken for ``Fisher's exact "
"test`` i resultatene. Det viktigste vi er interessert i her, er *p*-verdien, "
"som i dette tilfellet er liten nok (*p* = 0,036) til å rettferdiggjøre "
"forkastelse av nullhypotesen om at folk i brann er like lykkelige som folk "
"som ikke er i brann (se :numref:`fig-Fisher`)."

#: ../../Ch10/Ch10_ChiSquare_6.rst:85
msgid "``Fisher's exact test`` output in jamovi"
msgstr "Utgave fra ``Fisher's exact test`` i jamovi"

#: ../../Ch10/Ch10_ChiSquare_6.rst:89
msgid ""
"``Fisher's exact test`` output in jamovi. Ignore the ``Value`` and just "
"refer to the *p*-value"
msgstr ""
"Utgave fra ``Fisher's exact test`` i jamovi. Ignorer ``Value`` og referer "
"bare til *p*-verdien"

#: ../../Ch10/Ch10_ChiSquare_6.rst:97
msgid ""
"This example is based on a joke article published in the *Journal of "
"Irreproducible Results*."
msgstr ""
"Dette eksemplet er basert på en spøk publisert i *Journal of Irreproducible "
"Results*."

#: ../../Ch10/Ch10_ChiSquare_6.rst:101
msgid ""
"Not surprisingly, the Fisher exact test is motivated by Fisher’s "
"interpretation of a *p*-value, not Neyman’s! See section :doc:`../Ch09/"
"Ch09_HypothesisTesting_05`."
msgstr ""
"Ikke overraskende er Fisher eksakt test motivert av Fishers tolkning av en "
"*p*-verdi, ikke Neymans! Se avsnitt :doc:`../Ch09/Ch09_HypothesisTesting_05`."

#: ../../Ch10/Ch10_ChiSquare_7.rst:4
msgid "The McNemar test"
msgstr "McNemar-testen"

#: ../../Ch10/Ch10_ChiSquare_7.rst:6
msgid ""
"Suppose you’ve been hired to work for the *Australian Generic Political "
"Party* (AGPP), and part of your job is to find out how effective the AGPP "
"political advertisements are. So you decide to put together a sample of *N* "
"= 100 people and ask them to watch the AGPP ads. Before they see anything, "
"you ask them if they intend to vote for the AGPP, and then after showing the "
"ads you ask them again to see if anyone has changed their minds. Obviously, "
"if you’re any good at your job, you’d also do a whole lot of other things "
"too, but let’s consider just this one simple experiment. One way to describe "
"your data is via the following contingency table:"
msgstr ""
"Anta at du har blitt ansatt for å jobbe for *Australian Generic Political "
"Party* (AGPP), og at en del av jobben din er å finne ut hvor effektive AGPPs "
"politiske annonser er. Så du bestemmer deg for å sette sammen et utvalg på "
"*N* = 100 personer og ber dem se på AGPP-reklamene. Før de ser noe som "
"helst, spør du dem om de har tenkt å stemme på AGPP, og etter å ha vist "
"annonsene spør du dem igjen for å se om noen har ombestemt seg. Hvis du er "
"god i jobben din, ville du selvsagt også gjort mye annet, men la oss se på "
"dette enkle eksperimentet. En måte å beskrive dataene dine på, er ved hjelp "
"av følgende tilfeldighetstabell:"

#: ../../Ch10/Ch10_ChiSquare_7.rst:18
msgid "Before"
msgstr "Før"

#: ../../Ch10/Ch10_ChiSquare_7.rst:18
msgid "After"
msgstr "Etter"

#: ../../Ch10/Ch10_ChiSquare_7.rst:20
msgid "**Yes**"
msgstr "**Ja**"

#: ../../Ch10/Ch10_ChiSquare_7.rst:22
msgid "**No**"
msgstr "**Nei**"

#: ../../Ch10/Ch10_ChiSquare_7.rst:22 ../../Ch10/Ch10_ChiSquare_7.rst:52
msgid "70"
msgstr "70"

#: ../../Ch10/Ch10_ChiSquare_7.rst:22 ../../Ch10/Ch10_ChiSquare_7.rst:50
msgid "90"
msgstr "90"

#: ../../Ch10/Ch10_ChiSquare_7.rst:22
msgid "160"
msgstr "160"

#: ../../Ch10/Ch10_ChiSquare_7.rst:24 ../../Ch10/Ch10_ChiSquare_7.rst:52
msgid "100"
msgstr "100"

#: ../../Ch10/Ch10_ChiSquare_7.rst:24
msgid "200"
msgstr "200"

#: ../../Ch10/Ch10_ChiSquare_7.rst:27
msgid ""
"At first pass, you might think that this situation lends itself to the "
"Pearson :doc:`χ² test of independence <Ch10_ChiSquare_2>`. However, a little "
"bit of thought reveals that we’ve got a problem. We have 100 participants "
"but 200 observations. This is because each person has provided us with an "
"answer in *both* the before column and the after column. What this means is "
"that the 200 observations aren’t independent of each other. If voter A says "
"“yes” the first time and voter B says “no”, then you’d expect that voter A "
"is more likely to say “yes” the second time than voter B! The consequence of "
"this is that the usual χ² test won’t give trustworthy answers due to the "
"violation of the independence assumption. Now, if this were a really "
"uncommon situation, I wouldn’t be bothering to waste your time talking about "
"it. But it’s not uncommon at all. This is a *standard* repeated measures "
"design, and none of the tests we’ve considered so far can handle it. Eek."
msgstr ""
"Ved første øyekast skulle man kanskje tro at denne situasjonen egner seg for "
"Pearson :doc:`χ² test of independence <Ch10_ChiSquare_2>`. Litt ettertanke "
"avslører imidlertid at vi har et problem. Vi har 100 deltakere, men 200 "
"observasjoner. Dette skyldes at hver person har gitt oss et svar i *både* "
"før-kolonnen og etter-kolonnen. Det betyr at de 200 observasjonene ikke er "
"uavhengige av hverandre. Hvis velger A sier «ja» første gang og velger B "
"sier «nei», så skulle man forvente at det er mer sannsynlig at velger A sier "
"«ja» andre gang enn at velger B gjør det! Konsekvensen av dette er at den "
"vanlige χ²-testen ikke vil gi pålitelige svar på grunn av brudd på "
"forutsetningen om uavhengighet. Hvis dette hadde vært en veldig uvanlig "
"situasjon, hadde jeg ikke giddet å kaste bort tiden din på å snakke om det. "
"Men det er ikke uvanlig i det hele tatt. Dette er en *standard* design med "
"gjentatte målinger, og ingen av testene vi har vurdert så langt, kan "
"håndtere det. Jøss."

#: ../../Ch10/Ch10_ChiSquare_7.rst:41
msgid ""
"The solution to the problem was published by :ref:`McNemar (1947) "
"<McNemar_1947>`. The trick is to start by tabulating your data in a slightly "
"different way:"
msgstr ""
"Løsningen på problemet ble publisert av :ref:`McNemar (1947) "
"<McNemar_1947>`. Trikset er å begynne med å tabulere dataene dine på en litt "
"annen måte:"

#: ../../Ch10/Ch10_ChiSquare_7.rst:46 ../../Ch10/Ch10_ChiSquare_7.rst:63
msgid "Before: Yes"
msgstr "Før: Ja"

#: ../../Ch10/Ch10_ChiSquare_7.rst:46 ../../Ch10/Ch10_ChiSquare_7.rst:63
msgid "Before: No"
msgstr "Før: Nei"

#: ../../Ch10/Ch10_ChiSquare_7.rst:48 ../../Ch10/Ch10_ChiSquare_7.rst:65
msgid "**After: Yes**"
msgstr "**Etter: Ja**"

#: ../../Ch10/Ch10_ChiSquare_7.rst:50 ../../Ch10/Ch10_ChiSquare_7.rst:67
msgid "**After: No**"
msgstr "**Etter: Nei**"

#: ../../Ch10/Ch10_ChiSquare_7.rst:50
msgid "25"
msgstr "25"

#: ../../Ch10/Ch10_ChiSquare_7.rst:55
msgid ""
"This is exactly the same data, but it’s been rewritten so that each of our "
"100 participants appears in only one cell. Because we’ve written our data "
"this way the independence assumption is now satisfied, and this is a "
"contingency table that we *can* use to construct a χ²-goodness-of-fit "
"statistic. However, as we’ll see, we need to do it in a slightly non-"
"standard way. To see what’s going on, it helps to label the entries in our "
"table a little differently:"
msgstr ""
"Dette er nøyaktig de samme dataene, men de er omskrevet slik at hver av våre "
"100 deltakere bare vises i én celle. Fordi vi har skrevet dataene våre på "
"denne måten, er forutsetningen om uavhengighet nå oppfylt, og dette er en "
"krysstabell som vi *kan* bruke til å lage en statistikk for χ²-test for "
"fordeling. Som vi skal se, må vi imidlertid gjøre det på en litt uvanlig "
"måte. For å se hva som skjer, hjelper det å merke oppføringene i tabellen "
"litt annerledes:"

#: ../../Ch10/Ch10_ChiSquare_7.rst:65
msgid "*a*"
msgstr "*a*"

#: ../../Ch10/Ch10_ChiSquare_7.rst:65
msgid "*b*"
msgstr "*b*"

#: ../../Ch10/Ch10_ChiSquare_7.rst:65
msgid "*a* + *b*"
msgstr "*a* + *b*"

#: ../../Ch10/Ch10_ChiSquare_7.rst:67
msgid "*c*"
msgstr "*c*"

#: ../../Ch10/Ch10_ChiSquare_7.rst:67
msgid "*d*"
msgstr "*d*"

#: ../../Ch10/Ch10_ChiSquare_7.rst:67
msgid "*c* + *d*"
msgstr "*c* + *d*"

#: ../../Ch10/Ch10_ChiSquare_7.rst:69
msgid "*a* + *c*"
msgstr "*a* + *c*"

#: ../../Ch10/Ch10_ChiSquare_7.rst:69
msgid "*b* + *d*"
msgstr "*b* + *d*"

#: ../../Ch10/Ch10_ChiSquare_7.rst:69
msgid "*n*"
msgstr "*n*"

#: ../../Ch10/Ch10_ChiSquare_7.rst:72
msgid ""
"Next, let’s think about what our null hypothesis is: it’s that the “before” "
"test and the “after” test have the same proportion of people saying “Yes, I "
"will vote for AGPP”. Because of the way that we have rewritten the data, it "
"means that we’re now testing the hypothesis that the *row totals* and "
"*column totals* come from the same distribution. Thus, the null hypothesis "
"in McNemar’s test is that we have “marginal homogeneity”. That is, the row "
"totals and column totals have the same distribution: *P*\\ :sub:`a` + *P*\\ :"
"sub:`b` = *P*\\ :sub:`a` \\+ *P*\\ :sub:`c` and similarly that *P*\\ :sub:"
"`c` + *P*\\ :sub:`d` = *P*\\ :sub:`b` + *P*\\ :sub:`d`\\. Notice that this "
"means that the null hypothesis actually simplifies to *P*\\ :sub:`b` = "
"*P*\\ :sub:`c`\\. In other words, as far as the McNemar test is concerned, "
"it’s only the off-diagonal entries in this table (i.e., *b* and *c*) that "
"matter! After noticing this, the **McNemar test of marginal homogeneity** is "
"no different to a usual χ² test. After applying the Yates correction, our "
"test statistic becomes:"
msgstr ""
"La oss nå tenke over hva nullhypotesen vår er: Den er at «før»-testen og "
"«etter»-testen har samme andel personer som sier «Ja, jeg vil stemme på "
"AGPP». På grunn av måten vi har omskrevet dataene på, betyr det at vi nå "
"tester hypotesen om at *radtotaler* og *kolonnesummer* kommer fra samme "
"fordeling. Nullhypotesen i McNemars test er dermed at vi har «marginal "
"homogenitet». Det vil si at radtotalene og kolonnesummene har samme "
"fordeling: *P*\\ :sub:`a` + *P*\\ :sub:`b` = *P*\\ :sub:`a` \\+ *P*\\ :sub:"
"`c` og tilsvarende at *P*\\ :sub:`c` + *P*\\ :sub:`d` = *P*\\ :sub:`b` + "
"*P*\\ :sub:`d`\\. Legg merke til at dette betyr at nullhypotesen faktisk "
"forenkles til *P*\\ :sub:`b` = *P*\\ :sub:`c`\\. Med andre ord, når det "
"gjelder McNemar-testen, er det bare de off-diagonale oppføringene i denne "
"tabellen (dvs. *b* og *c*) som betyr noe! Etter å ha lagt merke til dette, "
"er **McNemar-testen for marginal homogenitet** ikke forskjellig fra en "
"vanlig χ²-test. Etter å ha brukt Yates-korreksjonen blir teststatistikken "
"vår:"

#: ../../Ch10/Ch10_ChiSquare_7.rst:87
msgid ""
"\\chi^2 = \\frac{(|b-c| - 0.5)^2}{b+c}\n"
"\n"
msgstr ""
"\\chi^2 = \\frac{(|b-c| - 0.5)^2}{b+c}\n"
"\n"

#: ../../Ch10/Ch10_ChiSquare_7.rst:89
msgid "or, to revert to the notation that we used earlier in this chapter:"
msgstr ""
"eller, for å gå tilbake til notasjonen vi brukte tidligere i dette "
"kapittelet:"

#: ../../Ch10/Ch10_ChiSquare_7.rst:91
msgid ""
"\\chi^2 = \\frac{(|O_{12}-O_{21}| - 0.5)^2}{O_{12} + O_{21}}\n"
"\n"
msgstr ""
"\\chi^2 = \\frac{(|O_{12}-O_{21}| - 0.5)^2}{O_{12} + O_{21}}\n"
"\n"

#: ../../Ch10/Ch10_ChiSquare_7.rst:93
msgid ""
"and this statistic has a χ² distribution (approximately) with *df* = 1. "
"However, remember that just like the other χ² tests it’s only an "
"approximation, so you need to have reasonably large expected cell counts for "
"it to work."
msgstr ""
"og denne statistikken har en χ²-fordeling (tilnærmet) med *df* = 1. Husk "
"imidlertid at akkurat som de andre χ²-testene er dette bare en tilnærming, "
"så du må ha et rimelig stort forventet antall celler for at den skal fungere."

#: ../../Ch10/Ch10_ChiSquare_7.rst:98
msgid "Doing the McNemar test in jamovi"
msgstr "Gjør McNemar-testen i jamovi"

#: ../../Ch10/Ch10_ChiSquare_7.rst:100
msgid ""
"Now that you know what the McNemar test is all about, lets actually run one. "
"The |agpp|_ data set contains the raw data that I discussed previously. It "
"contains three variables, an ``id`` variable that labels each participant in "
"the dataset (we’ll see why that’s useful in a moment), a ``response_before`` "
"variable that records the person’s answer when they were asked the question "
"the first time, and a ``response_after`` variable that shows the answer that "
"they gave when asked the same question a second time. Notice that each "
"participant appears only once in this data set. Go to ``Analyses`` → "
"``Frequencies`` → ``Contingency Tables`` → ``Paired Samples`` in jamovi, and "
"move ``response_before`` into the ``Rows`` box, and ``response_after`` into "
"the ``Columns`` box. You will then get a contingency table in the results "
"panel, with the statistic for the McNemar test just below it (see :numref:"
"`fig-McNemar`):"
msgstr ""
"Nå som du vet hva McNemar-testen handler om, kan vi faktisk kjøre en. "
"Datasettet |agpp|_ inneholder rådataene som jeg diskuterte tidligere. Det "
"inneholder tre variabler, en ``id``-variabel som merker hver deltaker i "
"datasettet (vi skal se hvorfor det er nyttig om et øyeblikk), en "
"``response_before``-variabel som registrerer personens svar da de ble stilt "
"spørsmålet første gang, og en ``response_after``-variabel som viser svaret "
"de ga da de ble stilt det samme spørsmålet en gang til. Legg merke til at "
"hver deltaker bare forekommer én gang i dette datasettet. Gå til "
"``Analyses`` → ``Frequencies`` → ``Contingency Tables`` → ``Paired Samples`` "
"i jamovi, og flytt ``response_before`` til ``Rows``-boksen, og "
"``response_after`` til ``Columns``-boksen. Du vil da få en krysstabell i "
"resultatpanelet, med statistikken for McNemar-testen rett under (se :numref:"
"`fig-McNemar`):"

#: ../../Ch10/Ch10_ChiSquare_7.rst:116 ../../Ch10/Ch10_ChiSquare_7.rst:120
msgid "McNemar test output in jamovi"
msgstr "Resultat fra McNemar-test i jamovi"

#: ../../Ch10/Ch10_ChiSquare_7.rst:124
msgid ""
"And we’re done. We’ve just run a McNemar’s test to determine if people were "
"just as likely to vote AGPP after the ads as they were before hand. The test "
"was significant (χ²(1) = 12.03, *p* < 0.001), suggesting that they were not. "
"And, in fact it looks like the ads had a negative effect: people were less "
"likely to vote AGPP after seeing the ads. Which makes a lot of sense when "
"you consider the quality of a typical political advertisement."
msgstr ""
"Og vi er ferdige. Vi har nettopp kjørt en McNemars test for å finne ut om "
"folk var like tilbøyelige til å stemme på AGPP etter annonsene som de var "
"før. Testen var signifikant (χ²(1) = 12,03, *p* < 0,001), noe som tyder på "
"at de ikke var det. Og det ser faktisk ut som om annonsene hadde en negativ "
"effekt: Folk var mindre tilbøyelige til å stemme på AGPP etter å ha sett "
"annonsene. Det gir god mening når man tar i betraktning kvaliteten på en "
"typisk politisk annonse."

#: ../../Ch10/Ch10_ChiSquare_7.rst:132
msgid "What’s the difference between McNemar and independence?"
msgstr "Hva er forskjellen mellom McNemar og uavhengighet?"

#: ../../Ch10/Ch10_ChiSquare_7.rst:134
msgid ""
"Let’s go all the way back to the beginning of the chapter and look at the |"
"cards|_ data set again. If you recall, the actual experimental design that I "
"described involved people making *two* choices. Because we have information "
"about the first choice and the second choice that everyone made, we can "
"construct the following contingency table that cross-tabulates the first "
"choice against the second choice."
msgstr ""
"La oss gå helt tilbake til begynnelsen av kapittelet og se på datasettet |"
"cards|_ igjen. Hvis du husker det, involverte det faktiske forsøksdesignet "
"jeg beskrev, at folk foretok *to* valg. Fordi vi har informasjon om det "
"første valget og det andre valget som alle gjorde, kan vi lage følgende "
"krysstabell som viser det første valget mot det andre valget."

#: ../../Ch10/Ch10_ChiSquare_7.rst:150
msgid ""
"Suppose I wanted to know whether the choice you make the second time is "
"dependent on the choice you made the first time. This is where a test of "
"independence is useful, and what we’re trying to do is see if there’s some "
"relationship between the rows and columns of this table."
msgstr ""
"Sett at jeg ville vite om valget du tar andre gang, er avhengig av valget du "
"tok første gang. Det er her en test for uavhengighet er nyttig, og det vi "
"prøver å gjøre, er å se om det er noen sammenheng mellom radene og kolonnene "
"i denne tabellen."

#: ../../Ch10/Ch10_ChiSquare_7.rst:155
msgid ""
"Alternatively, suppose I wanted to know if *on average*, the frequencies of "
"suit choices were different the second time than the first time. In that "
"situation, what I’m really trying to see is if the row totals are different "
"from the column totals. That’s when you use the McNemar test."
msgstr ""
"Alternativt kan jeg tenke meg at jeg ønsker å vite om frekvensen av "
"fargevalg *i gjennomsnitt* var annerledes andre gang enn første gang. I en "
"slik situasjon er det jeg egentlig prøver å se om radtotalene er "
"forskjellige fra kolonnesummene. Det er da du bruker McNemar-testen."

#: ../../Ch10/Ch10_ChiSquare_7.rst:160
msgid ""
"The different statistics produced by these different analyses are shown in :"
"numref:`fig-ind_paired`. Notice that the results are different! These aren’t "
"the same test."
msgstr ""
"De ulike statistikkene som produseres av disse ulike analysene, vises i :"
"numref:`fig-ind_paired`. Legg merke til at resultatene er forskjellige! "
"Dette er ikke den samme testen."

#: ../../Ch10/Ch10_ChiSquare_7.rst:166 ../../Ch10/Ch10_ChiSquare_7.rst:170
msgid "Independent vs. Paired (McNemar) test output in jamovi"
msgstr "Uavhengig vs. parvis (McNemar) testutgang i jamovi"

#: ../../Ch10/Ch10_ChiSquare_8.rst:4
msgid "Summary"
msgstr "Sammendrag"

#: ../../Ch10/Ch10_ChiSquare_8.rst:6
msgid "The key ideas discussed in this chapter are:"
msgstr "De viktigste ideene som diskuteres i dette kapittelet er:"

#: ../../Ch10/Ch10_ChiSquare_8.rst:8
msgid ""
":doc:`Ch10_ChiSquare_1` is used when you have a table of observed "
"frequencies of different categories, and the null hypothesis gives you a set "
"of “known” probabilities to compare them to."
msgstr ""
":doc:`Ch10_ChiSquare_1` brukes når du har en tabell med observerte "
"frekvenser av ulike kategorier, og nullhypotesen gir deg et sett med "
"«kjente» sannsynligheter å sammenligne dem med."

#: ../../Ch10/Ch10_ChiSquare_8.rst:12
msgid ""
":doc:`The χ² (chi-square) test of independence <Ch10_ChiSquare_2>` is used "
"when you have a contingency table (cross-tabulation) of two categorical "
"variables. The null hypothesis is that there is no relationship or "
"association between the variables."
msgstr ""
":doc:`χ²-test (kjikvadrat) for uavhengighet <Ch10_ChiSquare_2>` brukes når "
"du har en krysstabell med to kategoriale variabler. Nullhypotesen er at det "
"ikke er noen sammenheng mellom variablene."

#: ../../Ch10/Ch10_ChiSquare_8.rst:17
msgid ""
":doc:`Ch10_ChiSquare_4` for a contingency table can be measured in several "
"ways. In particular we noted the Cramér’s *V* statistic."
msgstr ""
":doc:`Ch10_ChiSquare_4` for en krysstabell kan måles på flere måter. Vi har "
"spesielt lagt merke til Cramérs *V*-statistikk."

#: ../../Ch10/Ch10_ChiSquare_8.rst:20
msgid ""
"Both versions of the Pearson test rely on two :doc:`assumptions "
"<Ch10_ChiSquare_5>`: that the expected frequencies are sufficiently large, "
"and that the observations are independent. The :doc:`Fisher exact test "
"<Ch10_ChiSquare_6>` can be used when the expected frequencies are small. "
"The :doc:`McNemar test <Ch10_ChiSquare_7>` can be used for some kinds of "
"violations of independence."
msgstr ""
"Begge versjonene av Pearson-testen bygger på to :doc:`forutsetninger "
"<Ch10_ChiSquare_5>`: at de forventede frekvensene er tilstrekkelig store, og "
"at observasjonene er uavhengige. Den :doc:`Fisher exact test "
"<Ch10_ChiSquare_6>` kan brukes når de forventede frekvensene er små. :doc:"
"`McNemar-testen <Ch10_ChiSquare_7>` kan brukes for noen typer brudd på "
"uavhengighet."

#: ../../Ch10/Ch10_ChiSquare_8.rst:27
msgid ""
"If you’re interested in learning more about categorical data analysis a good "
"first choice would be :ref:`Agresti (2018) <Agresti_2018>` which, as the "
"title suggests, provides an *Introduction to Categorical Data Analysis*. If "
"the introductory book isn’t enough for you (or can’t solve the problem "
"you’re working on) you could consider :ref:`Agresti (2012) <Agresti_2012>`, "
"*Categorical Data Analysis*. The latter is a more advanced text, so it’s "
"probably not wise to jump straight from this book to that one."
msgstr ""
"Hvis du er interessert i å lære mer om analyse av kategoriale data, vil et "
"godt førstevalg være :ref:`Agresti (2018) <Agresti_2018>` som, som tittelen "
"antyder, gir en «Introduction to Categorical Data Analysis». Hvis "
"introduksjonsboken ikke er nok for deg (eller ikke kan løse problemet du "
"jobber med), kan du vurdere :ref:`Agresti (2012) <Agresti_2012>`, "
"«Categorical Data Analysis». Sistnevnte er en mer avansert tekst, så det er "
"nok ikke så lurt å hoppe rett fra denne boken til den."
