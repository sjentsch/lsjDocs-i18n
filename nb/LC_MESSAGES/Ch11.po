#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-06-12 11:37+0200\n"
"PO-Revision-Date: 2025-03-31 16:02+0000\n"
"Last-Translator: Sebastian Jentschke <sebastian.jentschke@uib.no>\n"
"Language-Team: Norwegian Bokmål <https://hosted.weblate.org/projects/lsjdocs/"
"ch11/nb_NO/>\n"
"Language: nb\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"Generated-By: Babel 2.17.0\n"

#: ../../Ch11/Ch11_tTest.rst:4
msgid "Comparing two means"
msgstr "Sammenligning av to gjennomsnitt"

#: ../../Ch11/Ch11_tTest.rst:21
msgid ""
"In chapter :doc:`../Ch10/Ch10_ChiSquare` we covered the situation when your "
"outcome variable is nominal scale |nominal| and your predictor variable is "
"also nominal scale |nominal|. Lots of real world situations have that "
"character, and so you’ll find that χ²-tests in particular are quite widely "
"used. However, you’re much more likely to find yourself in a situation where "
"your outcome variable is interval scale or higher |continuous|, and what "
"you’re interested in is whether the average value of the outcome variable is "
"higher in one group or another. For instance, a psychologist might want to "
"know if anxiety levels are higher among parents than non-parents, or if "
"working memory capacity is reduced by listening to music (relative to not "
"listening to music). In a medical context we might want to know if a new "
"drug increases or decreases blood pressure. An agricultural scientist might "
"want to know whether adding phosphorus to Australian native plants will kill "
"them.\\ [#]_ In all these situations our outcome variable is a fairly "
"continuous |continuous|, interval or ratio scale variable, and our predictor "
"is a binary “grouping” variable |nominal|. In other words, we want to "
"compare the means of the two groups."
msgstr ""
"I kapittel :doc:`../Ch10/Ch10_ChiSquare` tok vi for oss situasjonen der "
"utfallsvariabelen er på nominalnivå |nominal| og prediktorvariabelen også er "
"på nominalnivå |nominal|. Mange situasjoner i den virkelige verden har denne "
"karakteren, og derfor vil du oppdage at spesielt χ²-tester er ganske mye "
"brukt. Det er imidlertid mye mer sannsynlig at du befinner deg i en "
"situasjon der utfallsvariabelen din er på intervallskala eller høyere |"
"continuous|, og det du er interessert i, er om gjennomsnittsverdien av "
"utfallsvariabelen er høyere i den ene eller andre gruppen. En psykolog kan "
"for eksempel være interessert i å vite om angstnivået er høyere blant "
"foreldre enn blant ikke-foreldre, eller om arbeidshukommelseskapasiteten "
"reduseres av å lytte til musikk (i forhold til å ikke lytte til musikk). I "
"medisinsk sammenheng vil vi kanskje vite om et nytt legemiddel øker eller "
"senker blodtrykket. En landbruksforsker vil kanskje vite om tilførsel av "
"fosfor til innfødte planter i Australia vil drepe dem.\\ [#]_ I alle disse "
"situasjonene er utfallsvariabelen vår en ganske kontinuerlig |continuous|, "
"intervall- eller forholdstallvariabel, og prediktoren vår er en binær "
"«grupperingsvariabel» |nominal|. Vi ønsker med andre ord å sammenligne "
"gjennomsnittene for de to gruppene."

#: ../../Ch11/Ch11_tTest.rst:69 ../../Ch11/Ch11_tTest_03.rst:476
#: ../../Ch11/Ch11_tTest_05.rst:233 ../../Ch11/Ch11_tTest_09.rst:142
msgid "nominal"
msgstr "nominal"

#: ../../Ch11/Ch11_tTest.rst:66 ../../Ch11/Ch11_tTest_03.rst:473
#: ../../Ch11/Ch11_tTest_05.rst:230 ../../Ch11/Ch11_tTest_09.rst:139
msgid "continuous"
msgstr "continuous"

#: ../../Ch11/Ch11_tTest.rst:39
msgid ""
"The standard answer to the problem of comparing means is to use a *t*-test, "
"of which there are several varieties depending on exactly what question you "
"want to solve. As a consequence, the majority of this chapter focuses on "
"different types of *t*-test: :doc:`one sample t-tests <Ch11_tTest_02>` are "
"discussed first, followed by two different flavours of the independent "
"samples *t*-test: The :doc:`Student test <Ch11_tTest_03>` assumes that the "
"groups have the same standard deviation, the :doc:`Welch test "
"<Ch11_tTest_04>` does not. Afterwards, :doc:`paired samples t-tests "
"<Ch11_tTest_05>` are discussed. We’ll then talk about :doc:`one-sided tests "
"<Ch11_tTest_06>` and, after that, we’ll talk a bit about Cohen’s *d*, which "
"is the standard measure of :doc:`effect size <Ch11_tTest_07>` for a *t*-"
"test. The later sections of the chapter focus on the assumptions of the *t*-"
"tests, especially :doc:`normality <Ch11_tTest_08>` and possible :doc:"
"`remedies <Ch11_tTest_09>` if they are violated. However, before discussing "
"any of these useful things, we’ll start with a discussion of the *z*-test."
msgstr ""
"Standardløsningen på problemet med å sammenligne gjennomsnitt er å bruke en "
"*t*-test, som det finnes flere varianter av, avhengig av nøyaktig hvilket "
"spørsmål du ønsker å løse. Derfor fokuserer mesteparten av dette kapittelet "
"på ulike typer *t*-tester: :doc:`t-test med ett utvalg <Ch11_tTest_02>` "
"omtales først, etterfulgt av to ulike varianter av uavhengig *t*-test: :doc:"
"`Students *t*-test <Ch11_tTest_03>` forutsetter at gruppene har samme "
"standardavvik, mens :doc:`Welch-test <Ch11_tTest_04>` ikke gjør det. Etterpå "
"diskuteres :doc:`paret t-test <Ch11_tTest_05>`. Deretter snakker vi om :doc:"
"`ensidige tester <Ch11_tTest_06>`, og etter det snakker vi litt om Cohens "
"*d*, som er standardmålet for :doc:`effektstørrelse <Ch11_tTest_07>` for en "
"*t*-test. De senere delene av kapittelet fokuserer på forutsetningene for "
"*t*-tester, spesielt :doc:`normalfordeling <Ch11_tTest_08>` og mulige :doc:"
"`reparasjoner <Ch11_tTest_09>` hvis de brytes. Men før vi diskuterer noen av "
"disse nyttige tingene, begynner vi med en diskusjon av *z*-testen."

#: ../../Ch11/Ch11_tTest.rst:58
msgid ""
"Informal experimentation in my garden suggests that yes, it does. Australian "
"natives are adapted to low phosphorus levels relative to everywhere else on "
"Earth, so if you’ve bought a house with a bunch of exotics and you want to "
"plant natives, keep them separate; nutrients to European plants are poison "
"to Australian ones."
msgstr ""
"Uformelle eksperimenter i hagen min antyder at ja, det gjør det. Australske "
"innfødte er tilpasset lave fosfornivåer i forhold til overalt ellers på "
"jorden, så hvis du har kjøpt et hus med en haug med eksotiske planter og du "
"vil plante innfødte, må du holde dem atskilt; næringsstoffer til europeiske "
"planter er gift for australske planter."

#: ../../Ch11/Ch11_tTest_01.rst:4
msgid "The one-sample *z*-test"
msgstr "*z*-testen med ett utvalg"

#: ../../Ch11/Ch11_tTest_01.rst:6
msgid ""
"In this section I’ll describe one of the most useless tests in all of "
"statistics: the **z-test**. Seriously – this test is almost never used in "
"real life. Its only real purpose is that, when teaching statistics, it’s a "
"very convenient stepping stone along the way towards the *t*-test, which is "
"probably the most (over)used tool in all statistics."
msgstr ""
"I dette avsnittet skal jeg beskrive en av de mest ubrukelige testene i all "
"statistikk: **z-testen**. Seriøst - denne testen brukes nesten aldri i det "
"virkelige liv. Dens eneste virkelige formål er at den er et veldig praktisk "
"springbrett på veien mot *t*-testen, som sannsynligvis er det mest "
"(over)brukte verktøyet i all statistikk."

#: ../../Ch11/Ch11_tTest_01.rst:14
msgid "The inference problem that the test addresses"
msgstr "Inferensproblemet som testen tar for seg"

#: ../../Ch11/Ch11_tTest_01.rst:16
msgid ""
"To introduce the idea behind the *z*-test, let’s use a simple example. A "
"friend of mine, Dr Zeppo, grades his introductory statistics class on a "
"curve. Let’s suppose that the average grade in his class is 67.5, and the "
"standard deviation is 9.5. Of his many hundreds of students, it turns out "
"that 20 of them also take psychology classes. Out of curiosity, I find "
"myself wondering if the psychology students tend to get the same grades as "
"everyone else (i.e., the mean of 67.5) or do they tend to score higher or "
"lower? He emails me the |zeppo|_ data set, which I use to look at the "
"``grades`` of those students, in the jamovi spreadsheet view,"
msgstr ""
"La oss bruke et enkelt eksempel for å introdusere ideen bak *z*-testen. En "
"venn av meg, Dr. Zeppo, setter karakterer i innføringskurset i statistikk "
"etter en kurve. La oss anta at gjennomsnittskarakteren i klassen hans er "
"67,5, og at standardavviket er 9,5. Av de mange hundre studentene hans viser "
"det seg at 20 av dem også tar psykologi. Av ren nysgjerrighet lurer jeg på "
"om psykologistudentene har en tendens til å få de samme karakterene som alle "
"andre (dvs. gjennomsnittet på 67,5), eller om de har en tendens til å score "
"høyere eller lavere? Han sender meg datasettet |zeppo|_ per e-post, som jeg "
"bruker til å se på karakterene (``grades``) til disse studentene i jamovi-"
"regnearkvisningen,"

#: ../../Ch11/Ch11_tTest_01.rst:30
msgid ""
"and then calculate the mean in ``Exploration`` → ``Descriptives``. The mean "
"value is 72.3."
msgstr ""
"og beregner deretter gjennomsnittet i ``Exploration`` → ``Descriptives``. "
"Gjennomsnittsverdien er 72,3."

#: ../../Ch11/Ch11_tTest_01.rst:33
msgid ""
"Hmm. It *might* be that the psychology students are scoring a bit higher "
"than normal. That sample mean of *X̄* = 72.3 is a fair bit higher than the "
"hypothesised population mean of µ = 67.5 but, on the other hand, a sample "
"size of *N* = 20 isn’t all that big. Maybe it’s pure chance."
msgstr ""
"Det *kan* være at psykologistudentene skårer litt høyere enn normalt. "
"Utvalgsgjennomsnittet på *X̄* = 72,3 er en god del høyere enn det antatte "
"populasjonsgjennomsnittet på µ = 67,5, men på den annen side er en "
"utvalgsstørrelse på *N* = 20 ikke så stor. Kanskje er det ren tilfeldighet."

#: ../../Ch11/Ch11_tTest_01.rst:38
msgid ""
"To answer the question, it helps to be able to write down what it is that I "
"think I know. Firstly, I know that the sample mean is *X̄* = 72.3. If I’m "
"willing to assume that the psychology students have the same standard "
"deviation as the rest of the class then I can say that the population "
"standard deviation is σ = \\9.5. I’ll also assume that since Dr Zeppo is "
"grading to a curve, the psychology student grades are normally distributed."
msgstr ""
"For å svare på spørsmålet hjelper det å kunne skrive ned hva jeg tror jeg "
"vet. For det første vet jeg at utvalgsgjennomsnittet er *X̄* = 72,3. Hvis jeg "
"er villig til å anta at psykologistudentene har samme standardavvik som "
"resten av klassen, kan jeg si at standardavviket i populasjonen er σ = "
"\\9,5. Jeg antar også at siden dr. Zeppo setter karakterer etter en kurve, "
"er psykologistudentenes karakterer normalfordelte."

#: ../../Ch11/Ch11_tTest_01.rst:45
msgid ""
"Next, it helps to be clear about what I want to learn from the data. In this "
"case my research hypothesis relates to the *population* mean µ for the "
"psychology student grades, which is unknown. Specifically, I want to know if "
"µ = 67.5 or not. Given that this is what I know, can we devise a hypothesis "
"test to solve our problem? The data, along with the hypothesised "
"distribution from which they are thought to arise, are shown in :numref:`fig-"
"zeppo`. Not entirely obvious what the right answer is, is it? For this, we "
"are going to need some statistics."
msgstr ""
"Deretter hjelper det å ha klart for seg hva jeg ønsker å lære av dataene. I "
"dette tilfellet er forskningshypotesen min knyttet til *populasjonens* "
"gjennomsnitt µ for psykologistudentenes karakterer, som er ukjent. Nærmere "
"bestemt ønsker jeg å vite om µ = 67,5 eller ikke. Gitt at dette er det jeg "
"vet, kan vi lage en hypotesetest for å løse problemet vårt? Dataene, sammen "
"med den hypotetiske fordelingen de antas å stamme fra, er vist i :numref:"
"`fig-zeppo`. Det er ikke helt opplagt hva som er det riktige svaret, er det "
"vel? Til dette trenger vi litt statistikk."

#: ../../Ch11/Ch11_tTest_01.rst:56
msgid "Theoretical and empirical distribution of student grades"
msgstr "Teoretisk og empirisk fordeling av studentkarakterer"

#: ../../Ch11/Ch11_tTest_01.rst:60
msgid ""
"The theoretical distribution (solid line) from which the psychology student "
"grades (bars) are supposed to have been generated."
msgstr ""
"Den teoretiske fordelingen (heltrukken linje) som psykologistudentenes "
"karakterer (søyler) antas å ha blitt generert fra."

#: ../../Ch11/Ch11_tTest_01.rst:66
msgid "Constructing the hypothesis test"
msgstr "Gjennomføring av hypotesetesten"

#: ../../Ch11/Ch11_tTest_01.rst:68
msgid ""
"The first step in constructing a hypothesis test is to be clear about what "
"the null and alternative hypotheses are. This isn’t too hard to do. Our null "
"hypothesis, H\\ :sub:`0`, is that the true population mean µ for psychology "
"student grades is 67.5\\%, and our alternative hypothesis is that the "
"population mean *isn’t* 67.5\\%. If we write this in mathematical notation, "
"these hypotheses become:"
msgstr ""
"Det første trinnet i å gjennomføre en hypotesetest er å ha klart for seg hva "
"som er nullhypotesen og alternativhypotesen. Dette er ikke så vanskelig å "
"gjøre. Nullhypotesen vår, H\\ :sub:`0`, er at det sanne "
"populasjonsgjennomsnittet µ for psykologistudentenes karakterer er 67,5\\%, "
"og alternativhypotesen vår er at populasjonsgjennomsnittet *ikke* er 67,5\\"
"%. Hvis vi skriver dette i matematisk notasjon, blir disse hypotesene:"

#: ../../Ch11/Ch11_tTest_01.rst:75
msgid "H\\ :sub:`0`: µ = 67.5"
msgstr "H\\ :sub:`0`: µ = 67.5"

#: ../../Ch11/Ch11_tTest_01.rst:76
msgid "H\\ :sub:`1`: µ ≠ 67.5"
msgstr "H\\ :sub:`1`: µ ≠ 67.5"

#: ../../Ch11/Ch11_tTest_01.rst:78
msgid ""
"though to be honest this notation doesn’t add much to our understanding of "
"the problem, it’s just a compact way of writing down what we’re trying to "
"learn from the data. The null hypotheses H\\ :sub:`0` and the alternative "
"hypothesis H\\ :sub:`1` for our test are both illustrated in :numref:`fig-"
"ztesthyp`. In addition to providing us with these hypotheses, the scenario "
"outlined above provides us with a fair amount of background knowledge that "
"might be useful. Specifically, there are two special pieces of information "
"that we can add:"
msgstr ""
"selv om denne notasjonen ærlig talt ikke tilfører mye til vår forståelse av "
"problemet, det er bare en kompakt måte å skrive ned det vi prøver å lære av "
"dataene på. Nullhypotesene H\\ :sub:`0` og alternativhypotesen H\\ :sub:`1` "
"for vår test er begge illustrert i :numref:`fig-ztesthyp`. I tillegg til å "
"gi oss disse hypotesene, gir scenariet som er skissert ovenfor oss en god "
"del bakgrunnskunnskap som kan være nyttig. Det er særlig to spesielle "
"opplysninger vi kan legge til:"

#: ../../Ch11/Ch11_tTest_01.rst:87
msgid "The psychology grades are normally distributed."
msgstr "Psykologikarakterene er normalfordelte."

#: ../../Ch11/Ch11_tTest_01.rst:89
msgid "The true standard deviation of these scores σ is known to be 9.5."
msgstr ""
"Det sanne standardavviket for disse poengene σ er kjent for å være 9,5."

#: ../../Ch11/Ch11_tTest_01.rst:92
msgid ""
"For the moment, we’ll act as if these are absolutely trustworthy facts. In "
"real life, this kind of absolutely trustworthy background knowledge doesn’t "
"exist, and so if we want to rely on these facts we’ll just have make the "
"*assumption* that these things are true. However, since these assumptions "
"may or may not be warranted, we might need to check them. For now though, "
"we’ll keep things simple."
msgstr ""
"Inntil videre later vi som om dette er absolutt pålitelige fakta. I "
"virkeligheten finnes ikke denne typen absolutt troverdig bakgrunnskunnskap, "
"så hvis vi ønsker å stole på disse faktaene, må vi bare gjøre en *antakelse* "
"om at disse tingene er sanne. Men siden disse antakelsene kan være "
"berettigede eller uberettigede, kan det hende vi må sjekke dem. Inntil "
"videre holder vi det enkelt."

#: ../../Ch11/Ch11_tTest_01.rst:101
msgid ""
"One-sample *z*-test: Illustration of the null and alternative hypotheses"
msgstr ""
"*z*-test med ett utvalg: Illustrasjon av nullhypotesen og alternativhypotesen"

#: ../../Ch11/Ch11_tTest_01.rst:105
msgid ""
"Graphical illustration of the null and alternative hypotheses assumed by the "
"one sample *z*-test (the two sided version, that is). The null and "
"alternative hypotheses both assume that the population distribution is "
"normal, and additionally assumes that the population standard deviation is "
"known (fixed at some value σ\\ :sub:`0`\\). The null hypothesis (left) is "
"that the population mean μ is equal to some specified value μ\\ :sub:`0`. "
"The alternative hypothesis is that the population mean differs from this "
"value, μ ≠ μ\\ :sub:`0`."
msgstr ""
"Grafisk illustrasjon av nullhypotesen og alternativhypotesen i *z*-testen "
"for ett utvalg (den tosidige versjonen). Nullhypotesen og "
"alternativhypotesen forutsetter begge at populasjonen er normalfordelt, og i "
"tillegg forutsettes det at populasjonens standardavvik er kjent (fastsatt "
"til en verdi σ\\ :sub:`0`\\). Nullhypotesen (til venstre) er at "
"populasjonsgjennomsnittet μ er lik en spesifisert verdi μ\\ :sub:`0`. "
"Alternativhypotesen er at populasjonsgjennomsnittet avviker fra denne "
"verdien, μ ≠ μ\\ :sub:`0`."

#: ../../Ch11/Ch11_tTest_01.rst:116
msgid ""
"The next step is to figure out what we would be a good choice for a "
"diagnostic test statistic, something that would help us discriminate between "
"H\\ :sub:`0` and H\\ :sub:`1`. Given that the hypotheses all refer to the "
"population mean µ, you’d feel pretty confident that the sample mean *X̄* "
"would be a pretty useful place to start. What we could do is look at the "
"difference between the sample mean *X̄* and the value that the null "
"hypothesis predicts for the population mean. In our example that would mean "
"we calculate *X̄* - 67.5. More generally, if we let µ\\ :sub:`0` refer to the "
"value that the null hypothesis claims is our population mean, then we’d want "
"to calculate"
msgstr ""
"Neste trinn er å finne ut hva som ville være et godt valg for en diagnostisk "
"teststatistikk, noe som ville hjelpe oss å skille mellom H\\ :sub:`0` og "
"H\\ :sub:`1`. Gitt at hypotesene alle refererer til "
"populasjonsgjennomsnittet µ, vil du føle deg ganske sikker på at "
"utvalgsgjennomsnittet *X̄* vil være et ganske nyttig sted å starte. Det vi "
"kan gjøre, er å se på forskjellen mellom utvalgsgjennomsnittet *X̄* og den "
"verdien som nullhypotesen predikerer for populasjonsgjennomsnittet. I vårt "
"eksempel ville det bety at vi beregner *X̄* - 67,5. Mer generelt, hvis vi lar "
"µ\\ :sub:`0` referere til verdien som nullhypotesen hevder er "
"populasjonsgjennomsnittet vårt, vil vi beregne"

#: ../../Ch11/Ch11_tTest_01.rst:128
msgid "*X̄* - µ\\ :sub:`0`"
msgstr "*X̄* - µ\\ :sub:`0`"

#: ../../Ch11/Ch11_tTest_01.rst:130
msgid ""
"If this quantity equals or is very close to 0, things are looking good for "
"the null hypothesis. If this quantity is a long way away from 0, then it’s "
"looking less likely that the null hypothesis is worth retaining. But how far "
"away from zero should it be for us to reject H\\ :sub:`0`?"
msgstr ""
"Hvis denne størrelsen er lik eller svært nær 0, ser det bra ut for "
"nullhypotesen. Hvis denne størrelsen er langt unna 0, ser det mindre "
"sannsynlig ut at nullhypotesen er verdt å beholde. Men hvor langt unna null "
"bør den være for at vi skal forkaste H\\ :sub:`0`?"

#: ../../Ch11/Ch11_tTest_01.rst:136
msgid ""
"To figure that out we need to be a bit more sneaky, and we’ll need to rely "
"on those two pieces of background knowledge that I wrote down previously; "
"namely that the raw data are normally distributed and that we know the value "
"of the population standard deviation σ. If the null hypothesis is actually "
"true, and the true mean is µ\\ :sub:`0`, then these facts together mean that "
"we know the complete population distribution of the data: a normal "
"distribution with mean µ\\ :sub:`0` and standard deviation σ. Adopting the "
"notation from section :doc:`../Ch07/Ch07_Probability_5`, a statistician "
"might write this as:"
msgstr ""
"For å finne ut av det må vi være litt mer lure, og vi må basere oss på de to "
"bakgrunnsopplysningene jeg skrev ned tidligere, nemlig at rådataene er "
"normalfordelte og at vi kjenner verdien av populasjonens standardavvik σ. "
"Hvis nullhypotesen faktisk er sann, og det sanne gjennomsnittet er µ\\ :sub:"
"`0`, betyr disse faktaene til sammen at vi kjenner den fullstendige "
"populasjonsfordelingen av dataene: en normalfordeling med gjennomsnittet "
"µ\\ :sub:`0` og standardavviket σ. Hvis vi bruker notasjonen fra avsnitt :"
"doc:`../Ch07/Ch07_Probability_5`, kan en statistiker skrive dette som:"

#: ../../Ch11/Ch11_tTest_01.rst:145
msgid "X ~ Normal(µ\\ :sub:`0`, σ²)"
msgstr "X ~ Normal(µ\\ :sub:`0`, σ²)"

#: ../../Ch11/Ch11_tTest_01.rst:147
msgid ""
"Okay, if that’s true, then what can we say about the distribution of *X̄*? "
"Well, as we discussed earlier (see :ref:`The central limit theorem "
"<central_limit_theorem>`), the sampling distribution of the mean *X̄* is also "
"normal, and has mean µ. But the standard deviation of this sampling "
"distribution *SE(X̄)*, which is called the *standard error of the mean*, is"
msgstr ""
"Hvis det er sant, hva kan vi da si om fordelingen av *X̄*? Vel, som vi "
"diskuterte tidligere (se :ref:`Sentralgrenseteoremet "
"<central_limit_theorem>`), er utvalgsfordelingen av gjennomsnittet *X̄* også "
"normal, og har gjennomsnitt µ. Men standardavviket til denne "
"utvalgsfordelingen *SE(X̄)*, som kalles *standardfeilen til gjennomsnittet*, "
"er"

#: ../../Ch11/Ch11_tTest_01.rst:153
msgid ""
"SE(X̄) = \\frac{\\sigma}{\\sqrt{N}}\n"
"\n"
msgstr ""
"SE(X̄) = \\frac{\\sigma}{\\sqrt{N}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_01.rst:155
msgid ""
"In other words, if the null hypothesis is true then the sampling "
"distribution of the mean can be written as follows:"
msgstr ""
"Med andre ord, hvis nullhypotesen er sann, kan utvalgsfordelingen av "
"gjennomsnittet skrives som følger:"

#: ../../Ch11/Ch11_tTest_01.rst:158
msgid "*X̄* ~ Normal(µ\\ :sub:`0`, *SE(X̄)*)"
msgstr "*X̄* ~ Normal(µ\\ :sub:`0`, *SE(X̄)*)"

#: ../../Ch11/Ch11_tTest_01.rst:160
msgid ""
"Now comes the trick. What we can do is convert the sample mean *X̄* into a :"
"doc:`standard score <../Ch04/Ch04_Descriptives_5>`. This is conventionally "
"written as *z*, but for now I’m going to refer to it as *z*\\ :sub:`X̄` (the "
"reason for using this expanded notation is to help you remember that we’re "
"calculating a standardised version of a sample mean, *not* a standardised "
"version of a single observation, which is what a *z*-score usually refers "
"to). When we do so the *z*-score for our sample mean is:"
msgstr ""
"Nå kommer trikset. Det vi kan gjøre, er å konvertere utvalgsgjennomsnittet "
"*X̄* til en :doc:`standardskår <../Ch04/Ch04_Descriptives_5>`. Dette skrives "
"vanligvis som *z*, men heretter vil jeg referere til det som *z*\\ :sub:`X̄` "
"(grunnen til at vi bruker denne utvidede notasjonen, er for å hjelpe deg å "
"huske at vi beregner en standardisert versjon av et utvalgsgjennomsnitt, "
"*ikke* en standardisert versjon av en enkelt observasjon, som er det en *z*-"
"skår vanligvis refererer til). Når vi gjør dette, blir *z*-scoren for "
"utvalgsgjennomsnittet vårt:"

#: ../../Ch11/Ch11_tTest_01.rst:168
msgid ""
"z_{\\bar{X}} = \\frac{\\bar{X} - \\mu_0}{SE(X̄)}\n"
"\n"
msgstr ""
"z_{\\bar{X}} = \\frac{\\bar{X} - \\mu_0}{SE(X̄)}\n"
"\n"

#: ../../Ch11/Ch11_tTest_01.rst:170
msgid "or, equivalently:"
msgstr "eller, tilsvarende:"

#: ../../Ch11/Ch11_tTest_01.rst:172
msgid ""
"z_{\\bar{X}} =  \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{N}}\n"
"\n"
msgstr ""
"z_{\\bar{X}} =  \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{N}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_01.rst:174
msgid ""
"This *z*-score is our test statistic. The nice thing about using this as our "
"test statistic is that like all *z*-scores, it has a standard normal "
"distribution:"
msgstr ""
"Denne *z*-scoren er teststatistikken vår. Det fine med å bruke denne som "
"teststatistikk er at den, i likhet med alle *z*-skårer, har en standard "
"normalfordeling:"

#: ../../Ch11/Ch11_tTest_01.rst:178
msgid "*z*\\ :sub:`*X̄*` ~ Normal(0, 1)"
msgstr "*z*\\ :sub:`*X̄*` ~ Normal(0, 1)"

#: ../../Ch11/Ch11_tTest_01.rst:180
msgid ""
"(again, see section :doc:`../Ch04/Ch04_Descriptives_5` if you’ve forgotten "
"why this is true). In other words, regardless of what scale the original "
"data are on, the *z*-statistic itself always has the same interpretation: "
"it’s equal to the number of standard errors that separate the observed "
"sample mean *X̄* from the population mean µ\\ :sub:`0` predicted by the null "
"hypothesis. Better yet, regardless of what the population parameters for the "
"raw scores actually are, the 5\\% critical regions for the *z*-test are "
"always the same, as illustrated in :numref:`fig-ztest`. And what this meant, "
"way back in the days where people did all their statistics by hand, is that "
"someone could publish a table like this:"
msgstr ""
"(igjen, se avsnitt :doc:`../Ch04/Ch04_Descriptives_5` hvis du har glemt "
"hvorfor dette er sant). Med andre ord, uansett hvilken skala de opprinnelige "
"dataene er på, har *z*-statistikken i seg selv alltid samme tolkning: Den er "
"lik antallet standardfeil som skiller det observerte utvalgsgjennomsnittet "
"*X̄* fra populasjonsgjennomsnittet µ\\ :sub:`0` som nullhypotesen forutsier. "
"Enda bedre er det at uavhengig av hva populasjonsparametrene for råskårene "
"faktisk er, er de 5\\% kritiske områdene for *z*-testen alltid de samme, som "
"illustrert i :numref:`fig-ztest`. Og det dette betydde, den gang folk gjorde "
"all statistikk for hånd, var at noen kunne publisere en tabell som denne:"

#: ../../Ch11/Ch11_tTest_01.rst:192
msgid "desired α level"
msgstr "ønsket α-nivå"

#: ../../Ch11/Ch11_tTest_01.rst:192
msgid "two-sided test"
msgstr "tosidig test"

#: ../../Ch11/Ch11_tTest_01.rst:192
msgid "one-sided test"
msgstr "ensidig test"

#: ../../Ch11/Ch11_tTest_01.rst:194
msgid "0.1"
msgstr "0.1"

#: ../../Ch11/Ch11_tTest_01.rst:194 ../../Ch11/Ch11_tTest_01.rst:196
msgid "1.644854"
msgstr "1.644854"

#: ../../Ch11/Ch11_tTest_01.rst:194
msgid "1.281552"
msgstr "1.281552"

#: ../../Ch11/Ch11_tTest_01.rst:196
msgid "0.05"
msgstr "0.05"

#: ../../Ch11/Ch11_tTest_01.rst:196
msgid "1.959964"
msgstr "1.959964"

#: ../../Ch11/Ch11_tTest_01.rst:198
msgid "0.01"
msgstr "0.01"

#: ../../Ch11/Ch11_tTest_01.rst:198
msgid "2.575829"
msgstr "2.575829"

#: ../../Ch11/Ch11_tTest_01.rst:198
msgid "2.326348"
msgstr "2.326348"

#: ../../Ch11/Ch11_tTest_01.rst:200
msgid "0.001"
msgstr "0.001"

#: ../../Ch11/Ch11_tTest_01.rst:200
msgid "3.290527"
msgstr "3.290527"

#: ../../Ch11/Ch11_tTest_01.rst:200
msgid "3.090232"
msgstr "3.090232"

#: ../../Ch11/Ch11_tTest_01.rst:203
msgid ""
"This, in turn, meant that researchers could calculate their *z*-statistic by "
"hand and then look up the critical value in a text book."
msgstr ""
"Det betydde i sin tur at forskerne kunne regne ut *z*-statistikken for hånd "
"og deretter slå opp den kritiske verdien i en lærebok."

#: ../../Ch11/Ch11_tTest_01.rst:209
msgid "Rejection regions for the two- and one-sided *z*-tests"
msgstr "Avvisningsregioner for tosidige og ensidige *z*-tester"

#: ../../Ch11/Ch11_tTest_01.rst:213
msgid ""
"Rejection regions for the two-sided *z*-test (left panel) and the one-sided "
"*z*-test (right panel)"
msgstr ""
"Avvisningsregioner for den tosidige *z*-testen (venstre panel) og den "
"ensidige *z*-testen (høyre panel)"

#: ../../Ch11/Ch11_tTest_01.rst:219
msgid "A worked example, by hand"
msgstr "Et bearbeidet eksempel, for hånd"

#: ../../Ch11/Ch11_tTest_01.rst:221
msgid ""
"Now, as I mentioned earlier, the *z*-test is almost never used in practice. "
"It’s so rarely used in real life that the basic installation of jamovi "
"doesn’t have a built in function for it. However, the test is so incredibly "
"simple that it’s really easy to do one manually. Let’s go back to the |zeppo|"
"_ data set. The first thing I need to do is calculate the sample mean for "
"the ``grades`` variable, which I’ve already done (72.3). We already have the "
"known population standard deviation (σ = 9.5), and the value of the "
"population mean that the null hypothesis specifies (µ\\ :sub:`0` = 67.5), "
"and we know the sample size (*N* = 20)."
msgstr ""
"Som jeg nevnte tidligere, blir *z*-testen nesten aldri brukt i praksis. Den "
"brukes så sjelden i det virkelige liv at grunninstallasjonen av jamovi ikke "
"har en innebygd funksjon for den. Testen er imidlertid så utrolig enkel at "
"det er veldig lett å gjøre den manuelt. La oss gå tilbake til datasettet |"
"zeppo|_. Det første jeg må gjøre er å beregne utvalgsgjennomsnittet for "
"variabelen ``grades``, noe jeg allerede har gjort (72,3). Vi har allerede "
"det kjente standardavviket i populasjonen (σ = 9,5), og verdien av "
"populasjonsgjennomsnittet som nullhypotesen spesifiserer (µ\\ :sub:`0` = "
"67,5), og vi kjenner utvalgsstørrelsen (*N* = 20)."

#: ../../Ch11/Ch11_tTest_01.rst:231
msgid ""
"Next, let’s calculate the (true) standard error of the mean (easily done "
"with a calculator):"
msgstr ""
"La oss deretter beregne den (sanne) standardfeilen til gjennomsnittet "
"(enkelt gjort med en kalkulator):"

#: ../../Ch11/Ch11_tTest_01.rst:240
msgid "And finally, we calculate our *z*-score:"
msgstr "Til slutt beregner vi *z*-poengsummen vår:"

#: ../../Ch11/Ch11_tTest_01.rst:248
msgid ""
"At this point, we would traditionally look up the value 2.26 in our table of "
"critical values. Our original hypothesis was two-sided (we didn’t really "
"have any theory about whether psych students would be better or worse at "
"statistics than other students) so our hypothesis test is two-sided (or two-"
"tailed) also. Looking at the little table that I showed earlier, we can see "
"that 2.26 is bigger than the critical value of 1.96 that would be required "
"to be significant at α = 0.05, but smaller than the value of 2.58 that would "
"be required to be significant at a level of α = 0.01. Therefore, we can "
"conclude that we have a significant effect, which we might write up by "
"saying something like this:"
msgstr ""
"På dette tidspunktet ville vi tradisjonelt sett slått opp verdien 2,26 i "
"tabellen over kritiske verdier. Den opprinnelige hypotesen vår var tosidig "
"(vi hadde egentlig ingen teori om hvorvidt psykologistudenter ville være "
"bedre eller dårligere i statistikk enn andre studenter), så hypotesetesten "
"vår er også tosidig (eller tohalet). Hvis vi ser på den lille tabellen jeg "
"viste tidligere, kan vi se at 2,26 er større enn den kritiske verdien på "
"1,96 som kreves for å være signifikant ved α = 0,05, men mindre enn verdien "
"på 2,58 som kreves for å være signifikant ved et nivå på α = 0,01. Derfor "
"kan vi konkludere med at vi har en signifikant effekt, som vi kan skrive opp "
"ved å si noe sånt som dette:"

#: ../../Ch11/Ch11_tTest_01.rst:260
msgid ""
"With a mean grade of 72.3 in the sample of psychology students, and assuming "
"a true population standard deviation of 9.5, we can conclude that the "
"psychology students have significantly different statistics scores to the "
"class average (*z* = 2.26, *N* = 20, *p* < 0.05)."
msgstr ""
"Med en gjennomsnittskarakter på 72,3 i utvalget av psykologistudenter, og "
"forutsatt et standardavvik i populasjonen på 9,5, kan vi konkludere med at "
"psykologistudentene har signifikant forskjellige statistikkpoengsummer enn "
"gjennomsnittet i klassen (*z* = 2,26, *N* = 20, *p* < 0,05)."

#: ../../Ch11/Ch11_tTest_01.rst:268
msgid "Assumptions of the *z*-test"
msgstr "Forutsetninger for *z*-testen"

#: ../../Ch11/Ch11_tTest_01.rst:270
msgid ""
"As I’ve said before, all statistical tests make assumptions. Some tests make "
"reasonable assumptions, while other tests do not. The test I’ve just "
"described, the one sample *z*-test, makes three basic assumptions. These are:"
msgstr ""
"Som jeg har sagt tidligere, gjør alle statistiske tester forutsetninger. "
"Noen tester har rimelige forutsetninger, mens andre ikke har det. Testen jeg "
"nettopp har beskrevet, *z*-testen med ett utvalg, har tre grunnleggende "
"forutsetninger. Disse er:"

#: ../../Ch11/Ch11_tTest_01.rst:274
msgid ""
"*Normality*. As usually described, the *z*-test assumes that the true "
"population distribution is normal.\\ [#]_ This is often a pretty reasonable "
"assumption, and it’s also an assumption that we can check if we feel worried "
"about it (see section :doc:`Ch11_tTest_08`)."
msgstr ""
"*Normalfordeling*. Som *z*-testen vanligvis beskrives, forutsetter den at "
"populasjonsfordelingen tilsvarer en normalfordeling.\\ [#]_ Dette er ofte en "
"ganske rimelig antakelse, og det er også en forutsetning som vi kan sjekke "
"hvis vi føler oss bekymret for den (se avsnitt :doc:`Ch11_tTest_08`)."

#: ../../Ch11/Ch11_tTest_01.rst:279
msgid ""
"*Independence*. The second assumption of the test is that the observations "
"in your data set are not correlated with each other, or related to each "
"other in some funny way. This isn’t as easy to check statistically, it "
"relies a bit on good experimental design. An obvious (and stupid) example of "
"something that violates this assumption is a data set where you “copy” the "
"same observation over and over again in your data file so that you end up "
"with a massive “sample size”, which consists of only one genuine "
"observation. More realistically, you have to ask yourself if it’s really "
"plausible to imagine that each observation is a completely random sample "
"from the population that you’re interested in. In practice this assumption "
"is never met, but we try our best to design studies that minimise the "
"problems of correlated data."
msgstr ""
"*Uavhengighet*. Den andre forutsetningen for testen er at observasjonene i "
"datasettet ditt ikke er korrelert med hverandre, eller relatert til "
"hverandre på en eller annen merkelig måte. Dette er ikke like lett å sjekke "
"statistisk, det er litt avhengig av et godt eksperimentelt design. Et "
"åpenbart (og dumt) eksempel på noe som bryter med denne forutsetningen, er "
"et datasett der du «kopierer» den samme observasjonen om og om igjen i "
"datafilen din, slik at du ender opp med en enorm «utvalgsstørrelse», som "
"bare består av én ekte observasjon. Mer realistisk sett må du spørre deg "
"selv om det virkelig er plausibelt å forestille seg at hver observasjon er "
"et helt tilfeldig utvalg fra populasjonen du er interessert i. I praksis er "
"denne forutsetningen aldri oppfylt, men vi gjør vårt beste for å utforme "
"studier som minimerer problemene med korrelerte data."

#: ../../Ch11/Ch11_tTest_01.rst:293
msgid ""
"*Known standard deviation*. The third assumption of the *z*-test is that the "
"true standard deviation of the population is known to the researcher. This "
"is just stupid. In no real world data analysis problem do you know the "
"standard deviation σ of some population but are completely ignorant about "
"the mean µ. In other words, this assumption is *always* wrong."
msgstr ""
"*Kjent standardavvik*. Den tredje forutsetningen for *z*-testen er at det "
"sanne standardavviket i populasjonen er kjent for forskeren. Dette er bare "
"dumt. I ingen dataanalyseproblemer i den virkelige verden kjenner du "
"standardavviket σ i en populasjon, men er fullstendig uvitende om "
"gjennomsnittet µ. Med andre ord er denne forutsetningen er *aldri* gitt."

#: ../../Ch11/Ch11_tTest_01.rst:301
msgid ""
"In view of the stupidity of assuming that σ is known, let’s see if we can "
"live without it. This takes us out of the dreary domain of the *z*-test, and "
"into the magical kingdom of the *t*-test, with unicorns and fairies and "
"leprechauns!"
msgstr ""
"Siden det er så dumt å anta at σ er kjent, la oss se om vi kan leve uten "
"den. Dette tar oss ut av *z*-testens kjedelige domene og inn i *t*-testens "
"magiske rike, med enhjørninger, feer og nisser!"

#: ../../Ch11/Ch11_tTest_01.rst:309
msgid ""
"Actually this is too strong. Strictly speaking requires the *z* test only "
"that the sampling distribution of the mean is normally distributed. If the "
"population is normal then it necessarily follows that the sampling "
"distribution of the mean is also normal. However, as we saw when talking "
"about the central limit theorem, it’s quite possible (even commonplace) for "
"the sampling distribution to be normal even if the population distribution "
"itself is non-normal. However, in light of the sheer ridiculousness of the "
"assumption that the true standard deviation is known, there really isn’t "
"much point in going into details on this front!"
msgstr ""
"Egentlig er dette for sterkt. Strengt tatt krever *z*-testen bare at "
"utvalgsfordelingen av gjennomsnittet er normalfordelt. Hvis populasjonen er "
"normalfordelt, følger det nødvendigvis at utvalgsfordelingen av "
"gjennomsnittet også er normalfordelt. Men som vi så da vi snakket om "
"sentralgrenseteoremet, er det fullt mulig (til og med vanlig) at "
"utvalgsfordelingen er tilnærmet normalfordelt selv om populasjonsfordelingen "
"i seg selv ikke tilsvarer en normalfordeling. Men i lys av det latterlige i "
"antakelsen om at det sanne standardavviket er kjent, er det egentlig ikke så "
"mye vits i å gå i detaljer på denne fronten!"

#: ../../Ch11/Ch11_tTest_02.rst:4
msgid "The one-sample *t*-test"
msgstr "En *t*-test med ett utvalg"

#: ../../Ch11/Ch11_tTest_02.rst:6
msgid ""
"After some thought, I decided that it might not be safe to assume that the "
"psychology student grades necessarily have the same standard deviation as "
"the other students in Dr Zeppo’s class. After all, if I’m entertaining the "
"hypothesis that they don’t have the same mean, then why should I believe "
"that they absolutely have the same standard deviation? In view of this, I "
"should really stop assuming that I know the true value of σ. This violates "
"the assumptions of my *z*-test, so in one sense I’m back to square one. "
"However, it’s not like I’m completely bereft of options. After all, I’ve "
"still got my raw data, and those raw data give me an *estimate* of the "
"population standard deviation, which is 9.52. In other words, while I can’t "
"say that I know that σ = 9.5, I *can* say that :math:`\\hat\\sigma` = 9.52."
msgstr ""
"Etter å ha tenkt meg litt om, kom jeg frem til at det kanskje ikke er trygt "
"å anta at psykologistudentenes karakterer nødvendigvis har samme "
"standardavvik som de andre studentene i Dr. Zeppos klasse. Hvis jeg tross "
"alt har en hypotese om at de ikke har samme gjennomsnitt, hvorfor skal jeg "
"da tro at de absolutt har samme standardavvik? I lys av dette bør jeg slutte "
"å anta at jeg kjenner den sanne verdien av σ. Dette bryter med "
"forutsetningene for *z*-testen min, så på en måte er jeg tilbake til "
"utgangspunktet. Det er imidlertid ikke slik at jeg er helt uten "
"alternativer. Jeg har tross alt fortsatt rådataene mine, og disse rådataene "
"gir meg et *estimat* av standardavviket i populasjonen, som er 9,52. Med "
"andre ord, selv om jeg ikke kan si at jeg vet at σ = 9,5, *kan* jeg si at :"
"math:`\\hat\\sigma` = 9,52."

#: ../../Ch11/Ch11_tTest_02.rst:20
msgid ""
"Okay, cool. The obvious thing that you might think to do is run a *z*-test, "
"but using the estimated standard deviation of 9.52 instead of relying on my "
"assumption that the true standard deviation is 9.5. And you probably "
"wouldn’t be surprised to hear that this would still give us a significant "
"result. This approach is close, but it’s not *quite* correct. Because we are "
"now relying on an *estimate* of the population standard deviation we need to "
"make some adjustment for the fact that we have some uncertainty about what "
"the true population standard deviation actually is. Maybe our data are just "
"a fluke …maybe the true population standard deviation is 11, for instance. "
"But if that were actually true, and we ran the *z*-test assuming σ = 11, "
"then the result would end up being *non-significant*. That’s a problem, and "
"it’s one we’re going to have to address."
msgstr ""
"Ok, greit. Det opplagte du kanskje tenker å gjøre, er å kjøre en *z*-test, "
"men ved å bruke det estimerte standardavviket på 9,52 i stedet for å basere "
"deg på min antakelse om at det sanne standardavviket er 9,5. Og du vil nok "
"ikke bli overrasket over å høre at dette fortsatt vil gi oss et signifikant "
"resultat. Denne tilnærmingen er nær, men den er ikke *helt* korrekt. Fordi "
"vi nå baserer oss på et *estimat* av standardavviket i populasjonen, må vi "
"justere for det faktum at vi har en viss usikkerhet om hva det sanne "
"standardavviket i populasjonen faktisk er. Kanskje er dataene våre bare et "
"lykketreff …kanskje er det sanne standardavviket i befolkningen 11, for "
"eksempel. Men hvis det faktisk var sant, og vi kjørte *z*-testen under "
"forutsetning av σ = 11, ville resultatet ende opp med å bli *ikke-"
"signifikant*. Det er et problem, og det er noe vi må ta tak i."

#: ../../Ch11/Ch11_tTest_02.rst:36
msgid ""
"Illustration: Null and alternative hypotheses by the one-sample *t*-test"
msgstr ""
"Illustrasjon: Nullhypotese og alternativhypotese ved *t*-test med ett utvalg"

#: ../../Ch11/Ch11_tTest_02.rst:40
msgid ""
"Graphical illustration of the null and alternative hypotheses assumed by the "
"(two-sided) one-sample *t*-test. Note the similarity to the *z*-test :numref:"
"`fig-ztesthyp`. The null hypothesis is that the population mean μ is equal "
"to some specified value μ\\ :sub:`0`\\, and the alternative hypothesis is "
"that it is not. Like the *z*-test, we assume that the data are normally "
"distributed, but we do not assume that the population standard deviation σ "
"is known in advance."
msgstr ""
"Grafisk illustrasjon av nullhypotesen og alternativhypotesen i (tosidig) *t*-"
"test med ett utvalg. Legg merke til likheten med *z*-testen :numref:`fig-"
"ztesthyp`. Nullhypotesen er at populasjonsgjennomsnittet μ er lik en "
"spesifisert verdi μ\\ :sub:`0`\\, og alternativhypotesen er at det ikke er "
"det. I likhet med *z*-testen antar vi at dataene er normalfordelte, men vi "
"antar ikke at populasjonens standardavvik σ er kjent på forhånd."

#: ../../Ch11/Ch11_tTest_02.rst:51
msgid "Introducing the *t*-test"
msgstr "Vi introduserer *t*-testen"

#: ../../Ch11/Ch11_tTest_02.rst:53
msgid ""
"This ambiguity is annoying, and it was resolved in 1908 by a guy called "
"William Sealy Gosset (:ref:`Student, 1908 <Student_1908>`), who was working "
"as a chemist for the Guinness brewery at the time (:ref:`Box, 1987 "
"<Box_1987>`). Because Guinness took a dim view of its employees publishing "
"statistical analysis (apparently they felt it was a trade secret), he "
"published the work under the pseudonym “A Student” and, to this day, the "
"full name of the *t*-test is actually **Student’s *t*-test**. The key thing "
"that Gosset figured out is how we should accommodate the fact that we aren’t "
"completely sure what the true standard deviation is.\\ [#]_ The answer is "
"that it subtly changes the sampling distribution. In the *t*-test our test "
"statistic, now called a *t*-statistic, is calculated in exactly the same way "
"I mentioned above. If our null hypothesis is that the true mean is µ, but "
"our sample has mean *X̄* and our estimate of the population standard "
"deviation is :math:`\\hat{\\sigma}`, then our *t*-statistic is:"
msgstr ""
"Denne tvetydigheten er irriterende, og den ble løst i 1908 av en fyr ved "
"navn William Sealy Gosset (:ref:`Student, 1908 <Student_1908>`), som på den "
"tiden jobbet som kjemiker for Guinness-bryggeriet (:ref:`Box, 1987 "
"<Box_1987>`). Fordi Guinness ikke likte at deres ansatte publiserte "
"statistiske analyser (de mente visstnok at det var en "
"forretningshemmelighet), publiserte han arbeidet under pseudonymet «A "
"Student», og den dag i dag er det fulle navnet på *t*-testen faktisk "
"**Students *t*-test**. Det viktigste Gosset fant ut, er hvordan vi skal ta "
"hensyn til det faktum at vi ikke er helt sikre på hva det sanne "
"standardavviket er.\\ [#]_ Svaret er at det endrer utvalgsfordelingen på en "
"subtil måte. I *t*-testen beregnes teststatistikken vår, som nå kalles *t*-"
"statistikk, på nøyaktig samme måte som jeg nevnte ovenfor. Hvis "
"nullhypotesen vår er at det sanne gjennomsnittet er µ, men utvalget vårt har "
"gjennomsnittet *X̄* og vårt estimat av standardavviket i populasjonen er :"
"math:`\\hat{\\sigma}`, så er *t*-statistikken vår:"

#: ../../Ch11/Ch11_tTest_02.rst:67
msgid ""
"t = \\frac{\\bar{X} - \\mu}{\\hat{\\sigma}/\\sqrt{N} }\n"
"\n"
msgstr ""
"t = \\frac{\\bar{X} - \\mu}{\\hat{\\sigma}/\\sqrt{N} }\n"
"\n"

#: ../../Ch11/Ch11_tTest_02.rst:69
msgid ""
"The only thing that has changed in the equation is that instead of using the "
"known true value σ, we use the estimate :math:`\\hat{\\sigma}`. And if this "
"estimate has been constructed from *N* observations, then the sampling "
"distribution turns into a *t*-distribution with *N* - 1 **degrees of "
"freedom** (df). The *t*-distribution is very similar to the normal "
"distribution, but has “heavier” tails, as discussed earlier in :doc:`../Ch07/"
"Ch07_Probability_6` and illustrated in :numref:`fig-ttestdist`. Notice, "
"though, that as *df* gets larger, the *t*-distribution starts to look "
"identical to the standard normal distribution. This is as it should be: if "
"you have a sample size of *N* = 70,000,000 then your “estimate” of the "
"standard deviation would be pretty much perfect, right? So, you should "
"expect that for large *N*, the *t*-test would behave exactly the same way as "
"a *z*-test. And that’s exactly what happens!"
msgstr ""
"Det eneste som er endret i ligningen, er at i stedet for å bruke den kjente "
"sanne verdien σ, bruker vi estimatet :math:`\\hat{\\sigma}`. Og hvis dette "
"estimatet baserer seg på *N* observasjoner, blir utvalgsfordelingen til en "
"*t*-fordeling med *N* - 1 **frihetsgrader** (df). *t*-fordelingen er svært "
"lik normalfordelingen, men har «tyngre» haler, som diskutert tidligere i :"
"doc:`../Ch07/Ch07_Probability_6` og illustrert i :numref:`fig-ttestdist`. "
"Legg imidlertid merke til at når *df* blir større, begynner *t*-fordelingen "
"å se identisk ut med standard normalfordeling. Dette er som det skal være: "
"Hvis du har en utvalgsstørrelse på *N* = 70 000 000, vil «estimatet» ditt av "
"standardavviket være så godt som perfekt, ikke sant? Så du burde forvente at "
"for store *N* ville *t*-testen oppføre seg nøyaktig på samme måte som en *z*-"
"test. Og det er akkurat det som skjer!"

#: ../../Ch11/Ch11_tTest_02.rst:84
msgid "*t*-distribution with *df* = 2 and *df* = 10"
msgstr "*t*-fordeling med *df* = 2 og *df* = 10"

#: ../../Ch11/Ch11_tTest_02.rst:88
msgid ""
"The *t*-distribution with 2 degrees of freedom (left panel) and 10 degrees "
"of freedom (right panel), with a standard normal distribution (i.e., mean = "
"0 and std. dev. = 1) plotted as dotted lines for comparison purposes. Notice "
"that the *t*-distribution has heavier tails (leptokurtic: higher kurtosis) "
"than the normal distribution; this effect is quite exaggerated when the "
"degrees of freedom are very small, but negligible for larger values. In "
"other words, for large *df* the *t*-distribution is essentially identical to "
"a normal distribution."
msgstr ""
"*t*-fordelingen med 2 frihetsgrader (venstre panel) og 10 frihetsgrader "
"(høyre panel), med en standard normalfordeling (dvs. gjennomsnitt = 0 og "
"std. dev. = 1) plottet som stiplede linjer for sammenligningsformål. Legg "
"merke til at *t*-fordelingen har tyngre haler (leptokurtisk: høyere kurtose) "
"enn normalfordelingen; denne effekten er ganske overdrevet når "
"frihetsgradene er svært små, men ubetydelig for større verdier. Med andre "
"ord, for store *df* er *t*-fordelingen i hovedsak identisk med en "
"normalfordeling."

#: ../../Ch11/Ch11_tTest_02.rst:100 ../../Ch11/Ch11_tTest_03.rst:261
#: ../../Ch11/Ch11_tTest_05.rst:166
msgid "Doing the test in jamovi"
msgstr "Gjør testen i jamovi"

#: ../../Ch11/Ch11_tTest_02.rst:102
msgid ""
"As you might expect, the mechanics of the *t*-test are almost identical to "
"the mechanics of the *z*-test. So there’s not much point in going through "
"the tedious exercise of showing you how to do the calculations using low "
"level commands. It’s pretty much identical to the calculations that we did "
"earlier, except that we use the estimated standard deviation and then we "
"test our hypothesis using the *t*-distribution rather than the normal "
"distribution. And so instead of going through the calculations in tedious "
"detail for a second time, I’ll jump straight to showing you how *t*-tests "
"are actually done. jamovi comes with a dedicated analysis for *t*-tests that "
"is very flexible (it can run lots of different kinds of *t*-tests). It’s "
"pretty straightforward to use; all you need to do is specify ``Analyses`` → "
"``T-Tests`` → ``One Sample T-Test``, move the variable you are interested in "
"(``X``) across into the ``Variables`` box, and type in the mean value for "
"the null hypothesis (``67.5``) in the ``Hypothesis`` → ``Test value`` box. "
"Easy enough (see :numref:`fig-ttest_one`, which, amongst other things that "
"we will get to in a moment, gives you a *t*statistic = 2.25, with 19 degrees "
"of freedom and an associated *p*-value of 0.036."
msgstr ""
"Som du kanskje forventer, er mekanikken i *t*-testen nesten identisk med "
"mekanikken i *z*-testen. Det er derfor ikke så mye vits i å gå gjennom den "
"kjedelige øvelsen med å vise deg hvordan du gjør beregningene ved hjelp av "
"kommandoer på lavt nivå. Det er stort sett identisk med beregningene vi "
"gjorde tidligere, bortsett fra at vi bruker det estimerte standardavviket, "
"og så tester vi hypotesen vår ved hjelp av *t*-fordelingen i stedet for "
"normalfordelingen. I stedet for å gå gjennom utregningene i langtekkelig "
"detalj en gang til, skal jeg gå rett til å vise deg hvordan *t*-tester "
"faktisk utføres. jamovi leveres med en egen analyse for *t*-tester som er "
"svært fleksibel (den kan kjøre mange forskjellige typer *t*-tester). Den er "
"ganske enkel å bruke; alt du trenger å gjøre er å spesifisere ``Analyses`` → "
"``T-Tests`` → ``One Sample T-Test``, flytte variabelen du er interessert i "
"(``X``) over i ``Variables``-boksen, og skrive inn gjennomsnittsverdien for "
"nullhypotesen (``67.5``) i ``Hypothesis`` → ``Test value``-boksen. Enkelt "
"nok (se :numref:`fig-ttest_one`, som blant annet gir deg en *t*-statistikk = "
"2,25, med 19 frihetsgrader og en tilhørende *p*-verdi på 0,036."

#: ../../Ch11/Ch11_tTest_02.rst:122 ../../Ch11/Ch11_tTest_02.rst:126
msgid "Conducting an One-sample *t*-test in jamovi"
msgstr "Gjennomføring av en *t*-test med ett utvalg i jamovi"

#: ../../Ch11/Ch11_tTest_02.rst:130
msgid ""
"Also reported are two other things you might care about: the 95\\% "
"confidence interval and a measure of effect size (we’ll talk more about "
"effect sizes later). So that seems straightforward enough. Now what do we "
"*do* with this output? Well, since we’re pretending that we actually care "
"about my toy example, we’re overjoyed to discover that the result is "
"statistically significant (i.e. *p*-value below 0.05). We could report the "
"result by saying something like this:"
msgstr ""
"Det rapporteres også to andre ting du kanskje er interessert i: 95\\%-"
"konfidensintervall og et mål på effektstørrelsen (vi skal snakke mer om "
"effektstørrelser senere). Så det virker enkelt nok. Hva *gjør* vi nå med "
"disse resultatene? Vel, siden vi later som om vi faktisk bryr oss om "
"lekeeksempelet mitt, blir vi overlykkelige over å oppdage at resultatet er "
"statistisk signifikant (dvs. *p*-verdi under 0,05). Vi kan rapportere "
"resultatet ved å si noe sånt som dette:"

#: ../../Ch11/Ch11_tTest_02.rst:138
msgid ""
"With a mean grade of 72.3, the psychology students scored slightly higher "
"than the average grade of 67.5 (*t*\\(19) = 2.25, *p* < 0.05); the mean "
"difference was 4.80 and the 95\\% confidence interval was from 0.34 to 9.26."
msgstr ""
"Med en gjennomsnittskarakter på 72,3 skåret psykologistudentene litt høyere "
"enn gjennomsnittskarakteren på 67,5 (*t*\\(19) = 2,25, *p* < 0,05); "
"gjennomsnittsforskjellen var 4,80 og konfidensintervallet på 95\\% var fra "
"0,34 til 9,26."

#: ../../Ch11/Ch11_tTest_02.rst:143
msgid ""
"where *t*\\(19) is shorthand notation for a *t*-statistic that has 19 "
"degrees of freedom. That said, it’s often the case that people don’t report "
"the confidence interval, or do so using a much more compressed form than "
"I’ve done here. For instance, it’s not uncommon to see the confidence "
"interval included as part of the stat block after reporting the mean "
"difference, like this:"
msgstr ""
"hvor *t*\\(19) er en forkortelse for en *t*-statistikk som har 19 "
"frihetsgrader. Når det er sagt, er det ofte slik at folk ikke rapporterer "
"konfidensintervallet, eller gjør det i en mye mer komprimert form enn jeg "
"har gjort her. For eksempel er det ikke uvanlig å se konfidensintervallet "
"inkludert som en del av statistikkblokken etter rapportering av "
"gjennomsnittsforskjellen, slik som dette:"

#: ../../Ch11/Ch11_tTest_02.rst:150
msgid "*t*\\(19) = 2.25, *p* = 0.036, CI\\ :sub:`95` = [0.34, 9.26]"
msgstr "*t*\\(19) = 2.25, *p* = 0.036, CI\\ :sub:`95` = [0.34, 9.26]"

#: ../../Ch11/Ch11_tTest_02.rst:152
msgid ""
"With that much jargon crammed into half a line, you know it must be really "
"smart.\\ [#]_"
msgstr ""
"Med så mye sjargong stappet inn på en halv linje, vet du at det må være "
"veldig smart.\\ [#]_"

#: ../../Ch11/Ch11_tTest_02.rst:158
msgid "Assumptions of the one sample *t*-test"
msgstr "Forutsetninger for *t*-test med ett utvalg"

#: ../../Ch11/Ch11_tTest_02.rst:160
msgid ""
"Okay, so what assumptions does the one-sample *t*-test make? Well, since the "
"*t*-test is basically a *z*-test with the assumption of known standard "
"deviation removed, you shouldn’t be surprised to see that it makes the same "
"assumptions as the *z*-test, minus the one about the known standard "
"deviation. That is"
msgstr ""
"Ok, så hvilke forutsetninger gjør *t*-test med ett utvalg? Vel, siden *t*-"
"testen i bunn og grunn er en *z*-test der forutsetningen om kjent "
"standardavvik er fjernet, bør du ikke bli overrasket over å se at den legger "
"til grunn de samme forutsetningene som *z*-testen, minus forutsetningen om "
"kjent standardavvik. Det vil si"

#: ../../Ch11/Ch11_tTest_02.rst:167
msgid ""
"*Normality*. We’re still assuming that the population distribution is normal,"
"\\ [#]_ and as noted earlier, there are standard tools that you can use to "
"check to see if this assumption is met (section :doc:`Ch11_tTest_08`), and "
"other tests you can do in it’s place if this assumption is violated "
"(section :doc:`Ch11_tTest_09`)."
msgstr ""
"*Normalfordeling*. Vi antar fortsatt at populasjonsfordelingen tilsvarer en "
"normalfordeling,\\ [#]_ og som nevnt tidligere finnes det standardverktøy "
"som du kan bruke til å sjekke om denne forutsetningen er oppfylt (avsnitt :"
"doc:`Ch11_tTest_08`), og andre tester du kan gjøre i stedet hvis denne "
"forutsetningen brytes (avsnitt :doc:`Ch11_tTest_09`)."

#: ../../Ch11/Ch11_tTest_02.rst:173
msgid ""
"*Independence*. Once again, we have to assume that the observations in our "
"sample are generated independently of one another. See the earlier "
"discussion about the *z*-test for specifics (section :ref:`Assumptions of "
"the *z*-test <assumptions_z_test>`)."
msgstr ""
"*Uavhengighet*. Igjen må vi anta at observasjonene i utvalget vårt er "
"generert uavhengig av hverandre. Se den tidligere diskusjonen om *z*-testen "
"for detaljer (avsnitt :ref:`Forutsetninger for *z*-testen "
"<assumptions_z_test>`)."

#: ../../Ch11/Ch11_tTest_02.rst:178
msgid ""
"Overall, these two assumptions aren’t terribly unreasonable, and as a "
"consequence the one-sample *t*-test is pretty widely used in practice as a "
"way of comparing a sample mean against a hypothesised population mean."
msgstr ""
"Alt i alt er ikke disse to forutsetningene veldig urimelige, og som en "
"konsekvens av dette er *t*-test for ett utvalg ganske mye brukt i praksis "
"som en måte å sammenligne et utvalgsgjennomsnitt med et antatt "
"populasjonsgjennomsnitt."

#: ../../Ch11/Ch11_tTest_02.rst:186
msgid ""
"Well, sort of. As I understand the history, Gosset only provided a partial "
"solution; the general solution to the problem was provided by Sir Ronald "
"Fisher."
msgstr ""
"Vel, på en måte. Slik jeg har forstått historien, leverte Gosset bare en "
"delløsning; den generelle løsningen på problemet ble levert av Sir Ronald "
"Fisher."

#: ../../Ch11/Ch11_tTest_02.rst:191
msgid ""
"More seriously, I tend to think the reverse is true. I get very suspicious "
"of technical reports that fill their results sections with nothing except "
"the numbers. It might just be that I’m an arrogant jerk, but I often feel "
"like an author that makes no attempt to explain and interpret their analysis "
"to the reader either doesn’t understand it themselves, or is being a bit "
"lazy. Your readers are smart, but not infinitely patient. Don’t annoy them "
"if you can help it."
msgstr ""
"Mer alvorlig er det at jeg har en tendens til å tro at det motsatte er "
"tilfelle. Jeg blir veldig mistenksom overfor tekniske rapporter som ikke "
"fyller resultatdelen med annet enn tall. Det kan være at jeg bare er en "
"arrogant dust, men jeg føler ofte at en forfatter som ikke gjør noe forsøk "
"på å forklare og tolke analysen sin for leseren, enten ikke forstår den "
"selv, eller er litt lat. Leserne dine er smarte, men ikke uendelig "
"tålmodige. Ikke irriter dem hvis du kan unngå det."

#: ../../Ch11/Ch11_tTest_02.rst:200
msgid ""
"A technical comment. In the same way that we can weaken the assumptions of "
"the *z*-test so that we’re only talking about the sampling distribution, we "
"*can* weaken the *t*-test assumptions so that we don’t have to assume "
"normality of the population. However, for the *t*-test it’s trickier to do "
"this. As before, we can replace the assumption of population normality with "
"an assumption that the sampling distribution of *X̄* is normal. However, "
"remember that we’re also relying on a sample estimate of the standard "
"deviation, and so we also require the sampling distribution of :math:"
"`\\hat{\\sigma}` to be χ². That makes things nastier, and this version is "
"rarely used in practice. Fortunately, if the population distribution is "
"normal, then both of these two assumptions are met."
msgstr ""
"En teknisk kommentar. På samme måte som vi kan svekke forutsetningene for "
"*z*-testen slik at vi bare snakker om utvalgsfordelingen, *kan* vi svekke "
"forutsetningene for *t*-testen slik at vi ikke trenger å forutsette en "
"normalfordeling i populasjonen. For *t*-testen er det imidlertid "
"vanskeligere å gjøre dette. Som før kan vi erstatte forutsetningen om "
"normalfordeling i populasjonen med en antakelse om at fordelingen i "
"stikkprøven til *X̄* er tilnærmet en normalfordeling. Husk imidlertid at vi "
"også er avhengige av et utvalgsestimat av standardavviket, og derfor krever "
"vi også at utvalgsfordelingen av :math:`\\hat{\\sigma}` er χ². Det gjør det "
"hele verre, og denne versjonen brukes sjelden i praksis. Hvis populasjonen "
"er normalfordelt, er heldigvis begge disse to forutsetningene oppfylt."

#: ../../Ch11/Ch11_tTest_03.rst:4
msgid "The independent samples *t*-test (Student test)"
msgstr "Uavhengig *t*-test (Students *t*-test)"

#: ../../Ch11/Ch11_tTest_03.rst:6
msgid ""
"Although the one sample *t*-test has its uses, it’s not the most typical "
"example of a *t*-test.\\ [#]_ A much more common situation arises when "
"you’ve got two different groups of observations. In psychology, this tends "
"to correspond to two different groups of participants, where each group "
"corresponds to a different condition in your study. For each person in the "
"study you measure some outcome variable of interest, and the research "
"question that you’re asking is whether or not the two groups have the same "
"population mean. This is the situation that the independent samples *t*-test "
"is designed for."
msgstr ""
"Selv om *t*-test med ett utvalg har sine bruksområder, er den ikke det mest "
"typiske eksempelet på en *t*-test.\\ [#]_ En mye vanligere situasjon oppstår "
"når du har to forskjellige grupper av observasjoner. I psykologien tilsvarer "
"dette gjerne to forskjellige grupper av deltakere, der hver gruppe tilsvarer "
"en forskjellig betingelse i studien din. For hver person i studien måler du "
"en eller annen utfallsvariabel av interesse, og forskningsspørsmålet du "
"stiller, er om de to gruppene har samme populasjonsgjennomsnitt eller ikke. "
"Dette er situasjonen som uavhengig *t*-test (independent samples *t*-test) "
"er utformet for."

#: ../../Ch11/Ch11_tTest_03.rst:17 ../../Ch11/Ch11_tTest_05.rst:24
msgid "The data"
msgstr "Dataene"

#: ../../Ch11/Ch11_tTest_03.rst:19
msgid ""
"Suppose we have 33 students taking Dr Harpo’s statistics lectures, and Dr "
"Harpo doesn’t grade to a curve. Actually, Dr Harpo’s grading is a bit of a "
"mystery, so we don’t really know anything about what the average grade is "
"for the class as a whole. There are two tutors for the class, Anastasia and "
"Bernadette. There are *N*\\ :sub:`1` = 15 students in Anastasia’s tutorials, "
"and *N*\\ :sub:`2` = 18 in Bernadette’s tutorials. The research question I’m "
"interested in is whether Anastasia or Bernadette is a better tutor, or if it "
"doesn’t make much of a difference. Dr Harpo sends me the |harpo|_ data set "
"with the course grades. file. As usual, I’ll load the file into jamovi and "
"have a look at what variables it contains - there are three variables, "
"``ID``, ``grade`` and ``tutor``. The ``grade`` variable contains each "
"student’s grade, but it is not imported into jamovi with the correct "
"measurement level attribute, so I need to change this so it is regarded as a "
"continuous variable |continuous| (see :ref:`Changing measurement levels "
"<variable_editor>`). The ``tutor`` variable is a factor |nominal| that "
"indicates who each student’s tutor was - either Anastasia or Bernadette."
msgstr ""
"Anta at vi har 33 studenter som følger Dr. Harpos statistikkforelesninger, "
"og at Dr. Harpo ikke setter karakterer etter en kurve. Faktisk er doktor "
"Harpos karaktersetting litt av et mysterium, så vi vet egentlig ikke noe om "
"hva gjennomsnittskarakteren er for klassen som helhet. Det er to lærere i "
"klassen, Anastasia og Bernadette. Det er *N*\\ :sub:`1` = 15 studenter i "
"Anastasias veiledning, og *N*\\ :sub:`2` = 18 i Bernadettes veiledning. "
"Forskningsspørsmålet jeg er interessert i, er om Anastasia eller Bernadette "
"er en bedre veileder, eller om det ikke utgjør noen stor forskjell. Dr. "
"Harpo sender meg datasettet |harpo|_ med kurskarakterene. filen. Som vanlig "
"laster jeg filen inn i jamovi og ser på hvilke variabler den inneholder - "
"det er tre variabler, ``ID``, ``grade`` og ``tutor``. Variabelen ``grade`` "
"inneholder hver students karakter, men den importeres ikke til jamovi med "
"riktig målenivåattributt, så jeg må endre dette slik at den blir sett på som "
"en kontinuerlig variabel |continuous| (se :ref:`Endring av målenivåer "
"<variable_editor>`). Variabelen ``tutor`` er en faktor |nominal| som angir "
"hvem som var læreren til hver student - enten Anastasia eller Bernadette."

#: ../../Ch11/Ch11_tTest_03.rst:36
msgid ""
"We can calculate means and standard deviations, using the ``Exploration`` → "
"``Descriptives`` analysis, and here’s a nice little summary table:"
msgstr ""
"Vi kan beregne gjennomsnitt og standardavvik ved hjelp av analysen "
"``Exploration`` → ``Descriptives``, og her er en fin liten "
"oppsummeringstabell:"

#: ../../Ch11/Ch11_tTest_03.rst:40
msgid "mean"
msgstr "gjennomsnitt"

#: ../../Ch11/Ch11_tTest_03.rst:40
msgid "std. dev."
msgstr "std.-avvik"

#: ../../Ch11/Ch11_tTest_03.rst:40
msgid "N"
msgstr "N"

#: ../../Ch11/Ch11_tTest_03.rst:42
msgid "**Anastasia’s students**"
msgstr "**Anastasias studenter**"

#: ../../Ch11/Ch11_tTest_03.rst:42
msgid "74.53"
msgstr "74.53"

#: ../../Ch11/Ch11_tTest_03.rst:42
msgid "9.00"
msgstr "9.00"

#: ../../Ch11/Ch11_tTest_03.rst:42
msgid "15"
msgstr "15"

#: ../../Ch11/Ch11_tTest_03.rst:44
msgid "**Bernadette’s students**"
msgstr "**Bernadettes studenter**"

#: ../../Ch11/Ch11_tTest_03.rst:44
msgid "69.06"
msgstr "69.06"

#: ../../Ch11/Ch11_tTest_03.rst:44
msgid "5.77"
msgstr "5.77"

#: ../../Ch11/Ch11_tTest_03.rst:44
msgid "18"
msgstr "18"

#: ../../Ch11/Ch11_tTest_03.rst:47
msgid ""
"To give you a more detailed sense of what’s going on here, I’ve plotted "
"histograms (not in jamovi, but using R) showing the distribution of grades "
"for both tutors (:numref:`fig-harpohist`), as well as a simpler plot showing "
"the means and corresponding confidence intervals for both groups of students "
"(:numref:`fig-ttestci`)."
msgstr ""
"For å gi deg en mer detaljert følelse av hva som skjer her, har jeg plottet "
"histogrammer (ikke i jamovi, men ved hjelp av R) som viser fordelingen av "
"karakterer for begge lærerne (:numref:`fig-harpohist`), samt et enklere "
"plott som viser gjennomsnittet og tilhørende konfidensintervaller for begge "
"studentgruppene (:numref:`fig-ttestci`)."

#: ../../Ch11/Ch11_tTest_03.rst:55
msgid "Histogram with grades in Anastasia’s and Bernadette’s classes"
msgstr "Histogram med karakterer i Anastasias og Bernadettes klasser"

#: ../../Ch11/Ch11_tTest_03.rst:59
msgid ""
"Histograms showing the distribution of grades for students in Anastasia’s "
"(left panel) and in Bernadette’s (right panel) classes. Visually, these "
"suggest that students in Anastasia’s class may be getting slightly better "
"grades on average, though they also seem a bit more variable."
msgstr ""
"Histogrammer som viser fordelingen av karakterer for studenter i Anastasias "
"(venstre panel) og Bernadettes (høyre panel) klasser. Visuelt sett tyder "
"disse på at studentene i Anastasias klasse kanskje får litt bedre karakterer "
"i gjennomsnitt, selv om de også ser ut til å være litt mer varierende."

#: ../../Ch11/Ch11_tTest_03.rst:66
msgid "Mean grades (with error bars) in Anastasia’s and Bernadette’s classes"
msgstr ""
"Gjennomsnittskarakterer (med feilsøyler) i Anastasias og Bernadettes klasser"

#: ../../Ch11/Ch11_tTest_03.rst:70
msgid ""
"The plots show the mean grade for students in Anastasia’s and Bernadette’s "
"tutorials. Error bars depict 95\\% confidence intervals around the mean. "
"Visually, it does look like there’s a real difference between the groups, "
"though it’s hard to say for sure."
msgstr ""
"Diagrammene viser gjennomsnittskarakteren for studentene i Anastasias og "
"Bernadettes opplæringsprogrammer. Feilstolpene viser 95\\%-"
"konfidensintervall rundt gjennomsnittet. Visuelt ser det ut som om det er en "
"reell forskjell mellom gruppene, selv om det er vanskelig å si noe sikkert."

#: ../../Ch11/Ch11_tTest_03.rst:78
msgid "Introducing the test"
msgstr "Introduksjon til testen"

#: ../../Ch11/Ch11_tTest_03.rst:80
msgid ""
"The **independent samples t-test** comes in two different forms, Student’s "
"and Welch’s. The original Student *t*-test, which is the one I’ll describe "
"in this section, is the simpler of the two but relies on much more "
"restrictive assumptions than the Welch *t*-test. Assuming for the moment "
"that you want to run a two-sided test, the goal is to determine whether two "
"“independent samples” of data are drawn from populations with the same mean "
"(the null hypothesis) or different means (the alternative hypothesis). When "
"we say “independent” samples, what we really mean here is that there’s no "
"special relationship between observations in the two samples. This probably "
"doesn’t make a lot of sense right now, but it will be clearer when we come "
"to talk about the paired samples *t*-test later on. For now, let’s just "
"point out that if we have an experimental design where participants are "
"randomly allocated to one of two groups, and we want to compare the two "
"groups’ mean performance on some outcome measure, then an independent "
"samples *t*-test (rather than a paired samples *t*-test) is what we’re after."
msgstr ""
"**Uavhenig t-test** finnes i to ulike former, Students og Welchs. Den "
"opprinnelige Students *t*-test, som er den jeg vil beskrive i dette "
"avsnittet, er den enkleste av de to, men bygger på mye mer restriktive "
"forutsetninger enn Welch-*t*-test. Hvis vi for øyeblikket antar at du ønsker "
"å kjøre en tosidig test, er målet å finne ut om to «uavhengige utvalg» av "
"data er hentet fra populasjoner med samme gjennomsnitt (nullhypotesen) eller "
"forskjellige gjennomsnitt (alternativhypotesen). Når vi sier «uavhengige» "
"utvalg, mener vi egentlig at det ikke er noe spesielt forhold mellom "
"observasjonene i de to utvalgene. Dette gir nok ikke så mye mening akkurat "
"nå, men det vil bli klarere når vi senere skal snakke om paret *t*-test. La "
"oss foreløpig bare påpeke at hvis vi har et eksperimentelt design der "
"deltakerne er tilfeldig fordelt til én av to grupper, og vi ønsker å "
"sammenligne de to gjennomsnittlige prestasjoner til to grupper på et eller "
"annet utfallsmål, så er det en uavhengig *t*-test (snarere enn en paret *t*-"
"test) vi er ute etter."

#: ../../Ch11/Ch11_tTest_03.rst:98
msgid ""
"Okay, so let’s let µ\\ :sub:`1` denote the true population mean for group 1 "
"(e.g., Anastasia’s students), and µ\\ :sub:`2` will be the true population "
"mean for group 2 (e.g., Bernadette’s students),\\ [#]_ and as usual we’ll "
"let *X̄*\\ :sub:`1` and *X̄*\\ :sub:`2` denote the observed sample means for "
"both of these groups. Our null hypothesis states that the two population "
"means are identical (µ\\ :sub:`1` = µ\\ :sub:`1`) and the alternative to "
"this is that they are not (µ\\ :sub:`1` ≠ µ\\ :sub:`1`). Written in "
"mathematical-ese, this is:"
msgstr ""
"La oss la µ\\ :sub:`1` betegne det sanne populasjonsgjennomsnittet for "
"gruppe 1 (f.eks. Anastasias studenter), og µ\\ :sub:`2` vil være det sanne "
"populasjonsgjennomsnittet for gruppe 2 (f.eks. Bernadettes studenter),\\ "
"[#]_ og som vanlig lar vi *X̄*\\ :sub:`1` og *X̄*\\ :sub:`2` betegne de "
"observerte utvalgsgjennomsnittene for begge disse gruppene. Nullhypotesen "
"vår sier at de to populasjonsgjennomsnittene er identiske (µ\\ :sub:`1` = "
"µ\\ :sub:`1`), og alternativet til dette er at de ikke er det (µ\\ :sub:`1` "
"≠ µ\\ :sub:`1`). Skrevet på matematisk språk er dette:"

#: ../../Ch11/Ch11_tTest_03.rst:107
msgid "H\\ :sub:`0`: µ\\ :sub:`1` = µ\\ :sub:`2`"
msgstr "H\\ :sub:`0`: µ\\ :sub:`1` = µ\\ :sub:`2`"

#: ../../Ch11/Ch11_tTest_03.rst:108
msgid "H\\ :sub:`1`: µ\\ :sub:`1` ≠ µ\\ :sub:`2`"
msgstr "H\\ :sub:`1`: µ\\ :sub:`1` ≠ µ\\ :sub:`2`"

#: ../../Ch11/Ch11_tTest_03.rst:112
msgid "Illustration: Null and alternative hypotheses, indep. samples *t*-test"
msgstr "Illustrasjon: Null- og alternativhypoteser, uavhengig *t*-test"

#: ../../Ch11/Ch11_tTest_03.rst:116
msgid ""
"Graphical illustration of the null and alternative hypotheses assumed by the "
"Student *t*-test for Independent Samples. The null hypothesis assumes that "
"both groups have the same mean µ, whereas the alternative assumes that they "
"have different means µ\\ :sub:`1` and µ\\ :sub:`2`\\. Notice that it is "
"assumed that the population distributions are normal, and that, although the "
"alternative hypothesis allows the group to have different means, it assumes "
"they have the same standard deviation."
msgstr ""
"Grafisk illustrasjon av nullhypotesen og alternativhypotesen ved Students "
"uavhengig *t*-test. Nullhypotesen antar at begge gruppene har samme "
"gjennomsnitt µ, mens alternativhypotesen antar at de har forskjellige "
"gjennomsnitt µ\\ :sub:`1` og µ\\ :sub:`2`\\. Legg merke til at det "
"forutsettes at data i populasjon er normalfordelt, og at selv om "
"alternativhypotesen tillater at gruppene har ulike gjennomsnitt, forutsettes "
"det at de har samme standardavvik."

#: ../../Ch11/Ch11_tTest_03.rst:126
msgid ""
"To construct a hypothesis test that handles this scenario we start by noting "
"that if the null hypothesis is true, then the difference between the "
"population means is *exactly* zero, µ\\ :sub:`1` - µ\\ :sub:`1` = 0. As a "
"consequence, a diagnostic test statistic will be based on the difference "
"between the two sample means. Because if the null hypothesis is true, then "
"we’d expect *X̄*\\ :sub:`1` – *X̄*\\ :sub:`2` to be *pretty close* to zero. "
"However, just like we saw with our one-sample tests (i.e., the one-sample "
"*z*-test and the one-sample *t*-test) we have to be precise about exactly "
"*how close* to zero this difference should be. And the solution to the "
"problem is more or less the same one. We calculate a standard error estimate "
"(SE), just like last time, and then divide the difference between means by "
"this estimate. So our **t-statistic** will be of the form:"
msgstr ""
"For å gjennomføre en hypotesetest som håndterer dette scenariet, starter vi "
"med å merke oss at hvis nullhypotesen er sann, er forskjellen mellom "
"populasjonsgjennomsnittene *eksakt* null, µ\\ :sub:`1` - µ\\ :sub:`1` = 0. "
"Følgelig vil en diagnostisk teststatistikk være basert på forskjellen mellom "
"de to utvalgsgjennomsnittene. For hvis nullhypotesen er sann, vil vi "
"forvente at *X̄*\\ :sub:`1` - *X̄*\\ :sub:`2` er *ganske nær* null. Men "
"akkurat som vi så med våre tester med ett utvalg (både *z*-test og *t*-test "
"med ett utvalg), må vi være presise med hensyn til nøyaktig *hvor nær* null "
"denne forskjellen skal være. Og løsningen på problemet er mer eller mindre "
"den samme. Vi beregner et standardfeil-estimat (SE), akkurat som sist, og "
"dividerer deretter differansen mellom gjennomsnittene med dette estimatet. "
"Vår **t-statistikk** vil altså være på formen:"

#: ../../Ch11/Ch11_tTest_03.rst:139
msgid "*t* = (*X̄*\\ :sub:`1` – *X̄*\\ :sub:`2`) / SE"
msgstr "*t* = (*X̄*\\ :sub:`1` – *X̄*\\ :sub:`2`) / SE"

#: ../../Ch11/Ch11_tTest_03.rst:141
msgid ""
"We just need to figure out what this standard error estimate actually is. "
"This is a bit trickier than was the case for either of the two tests we’ve "
"looked at so far, so we need to go through it a lot more carefully to "
"understand how it works."
msgstr ""
"Vi må bare finne ut hva dette standardfeilestimatet faktisk er. Dette er "
"litt vanskeligere enn for noen av de to testene vi har sett på så langt, så "
"vi må gå gjennom det mye mer nøye for å forstå hvordan det fungerer."

#: ../../Ch11/Ch11_tTest_03.rst:147
msgid "A “pooled estimate” of the standard deviation"
msgstr "Et «samlet estimat» av standardavviket"

#: ../../Ch11/Ch11_tTest_03.rst:149
msgid ""
"In the original “Student *t*-test”, we make the assumption that the two "
"groups have the same population standard deviation. That is, regardless of "
"whether the population means are the same, we assume that the population "
"standard deviations are identical, σ\\ :sub:`1` = σ\\ :sub:`2`. Since we’re "
"assuming that the two standard deviations are the same, we drop the "
"subscripts and refer to both of them as σ. How should we estimate this? How "
"should we construct a single estimate of a standard deviation when we have "
"two samples? The answer is, basically, we average them. Well, sort of. "
"Actually, what we do is take a *weighed* average of the *variance* "
"estimates, which we use as our **pooled estimate of the variance**. The "
"weight assigned to each sample is equal to the number of observations in "
"that sample, minus 1."
msgstr ""
"I opprinnelig «Students *t*-test» antar vi at de to gruppene har samme "
"standardavvik i populasjonen. Det vil si at uavhengig av om "
"populasjonsgjennomsnittene er de samme, antar vi at standardavvikene i "
"populasjonen er identiske, σ\\ :sub:`1` = σ\\ :sub:`2`. Siden vi antar at de "
"to standardavvikene er de samme, dropper vi abonnementene og refererer til "
"dem begge som σ. Hvordan skal vi estimere dette? Hvordan skal vi lage et "
"enkelt estimat av et standardavvik når vi har to utvalg? Svaret er at vi tar "
"gjennomsnittet av dem. Vel, på en måte. Det vi gjør, er å ta et *veid* "
"gjennomsnitt av *avviksestimatene*, som vi bruker som vårt **samlede estimat "
"av variansen**. Vekten som tilordnes hvert utvalg, er lik antall "
"observasjoner i utvalget minus 1."

#: ../../Ch11/Ch11_tTest_03.rst:161
msgid "Mathematically, we can write this as"
msgstr "Matematisk kan vi skrive dette som"

#: ../../Ch11/Ch11_tTest_03.rst:163
msgid "w\\ :sub:`1` = *N*\\ :sub:`1` - 1"
msgstr "w\\ :sub:`1` = *N*\\ :sub:`1` - 1"

#: ../../Ch11/Ch11_tTest_03.rst:164
msgid "w\\ :sub:`2` = *N*\\ :sub:`2` - 1"
msgstr "w\\ :sub:`2` = *N*\\ :sub:`2` - 1"

#: ../../Ch11/Ch11_tTest_03.rst:166
msgid ""
"Now that we’ve assigned weights to each sample we calculate the pooled "
"estimate of the variance by taking the weighted average of the two variance "
"estimates, :math:`{\\hat\\sigma_1}^2` and :math:`{\\hat\\sigma_2}^2`"
msgstr ""
"Nå som vi har tilordnet vekter til hvert utvalg, beregner vi det samlede "
"estimatet av variansen ved å ta det vektede gjennomsnittet av de to "
"variansestimatene, :math:`{\\hat\\sigma_1}^2` og :math:`{\\hat\\sigma_2}^2`"

#: ../../Ch11/Ch11_tTest_03.rst:171
msgid ""
"\\hat\\sigma^2_p = \\frac{w_1 {\\hat\\sigma_1}^2 + w_2 {\\hat\\sigma_2}^2}"
"{w_1 + w_2}\n"
"\n"
msgstr ""
"\\hat\\sigma^2_p = \\frac{w_1 {\\hat\\sigma_1}^2 + w_2 {\\hat\\sigma_2}^2}"
"{w_1 + w_2}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:173
msgid ""
"Finally, we convert the pooled variance estimate to a pooled standard "
"deviation estimate, by taking the square root."
msgstr ""
"Til slutt konverterer vi det samlede variansestimatet til et samlet "
"standardavviksestimat ved å ta kvadratroten."

#: ../../Ch11/Ch11_tTest_03.rst:176
msgid ""
"\\hat\\sigma_p = \\sqrt{\\frac{w_1 {\\hat\\sigma_1}^2 + w_2 {\\hat\\sigma_2}"
"^2}{w_1 + w_2}}\n"
"\n"
msgstr ""
"\\hat\\sigma_p = \\sqrt{\\frac{w_1 {\\hat\\sigma_1}^2 + w_2 {\\hat\\sigma_2}"
"^2}{w_1 + w_2}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:178
msgid ""
"And if you mentally substitute w\\ :sub:`1` = *N*\\ :sub:`1` - 1 and w\\ :"
"sub:`2` = *N*\\ :sub:`2` - 1 into this equation you get a very ugly looking "
"formula. A very ugly formula that actually seems to be the “standard” way of "
"describing the pooled standard deviation estimate. It’s not my favourite way "
"of thinking about pooled standard deviations, however. I prefer to think "
"about it like this. Our data set actually corresponds to a set of *N* "
"observations which are sorted into two groups. So let’s use the notation "
"*X*\\ :sub:`ik` to refer to the grade received by the i-th student in the k-"
"th tutorial group. That is, *X*\\ :sub:`11` is the grade received by the "
"first student in Anastasia’s class, *X*\\ :sub:`21` is her second student, "
"and so on. And we have two separate group means *X̄*\\ :sub:`1` and *X̄*\\ :"
"sub:`2`, which we could “generically” refer to using the notation *X̄*\\ :sub:"
"`k`, i.e., the mean grade for the k-th tutorial group. So far, so good. Now, "
"since every single student falls into one of the two tutorials, we can "
"describe their deviation from the group mean as the difference"
msgstr ""
"Og hvis du mentalt setter inn w\\ :sub:`1` = *N*\\ :sub:`1` - 1 og w\\ :sub:"
"`2` = *N*\\ :sub:`2` - 1 i denne ligningen, får du en formel som ser veldig "
"stygg ut. En veldig stygg formel som faktisk ser ut til å være den «vanlige» "
"måten å beskrive det sammenslåtte standardavviksestimatet på. Det er "
"imidlertid ikke min favorittmåte å tenke på sammenslåtte standardavvik på. "
"Jeg foretrekker å tenke på det slik. Datasettet vårt tilsvarer faktisk et "
"sett med *N* observasjoner som er sortert i to grupper. La oss derfor bruke "
"notasjonen *X*\\ :sub:`ik` for å referere til karakteren som den i-te "
"studenten i den k-te veiledningsgruppen har fått. Det vil si at *X*\\ :sub:"
"`11` er karakteren til den første studenten i Anastasias klasse, *X*\\ :sub:"
"`21` er karakteren til hennes andre student, og så videre. Og vi har to "
"separate gruppegjennomsnitt *X̄*\\ :sub:`1` og *X̄*\\ :sub:`2`, som vi "
"«generisk» kan referere til ved å bruke notasjonen *X̄*\\ :sub:`k`, dvs. "
"gjennomsnittskarakteren for den k-te veiledningsgruppen. Så langt, så bra. "
"Siden hver enkelt student tilhører én av de to opplæringsgruppene, kan vi "
"beskrive avviket deres fra gruppegjennomsnittet som differansen"

#: ../../Ch11/Ch11_tTest_03.rst:194
msgid "*X*\\ :sub:`ik` - *X̄*\\ :sub:`k`"
msgstr "*X*\\ :sub:`ik` - *X̄*\\ :sub:`k`"

#: ../../Ch11/Ch11_tTest_03.rst:196
msgid ""
"So why not just use these deviations (i.e., the extent to which each "
"student’s grade differs from the mean grade in their tutorial)? Remember, a "
"variance is just the average of a bunch of squared deviations, so let’s do "
"that. Mathematically, we could write it like this:"
msgstr ""
"Så hvorfor ikke bare bruke disse avvikene (dvs. i hvor stor grad hver "
"students karakter avviker fra gjennomsnittskarakteren i "
"undervisningsopplegget)? Husk at en varians bare er gjennomsnittet av en "
"rekke kvadrerte avvik, så la oss gjøre det. Matematisk sett kan vi skrive "
"det slik:"

#: ../../Ch11/Ch11_tTest_03.rst:201
msgid ""
"\\frac{\\sum_{ik} \\left( X_{ik} - \\bar{X}_k \\right)^2}{N}\n"
"\n"
msgstr ""
"\\frac{\\sum_{ik} \\left( X_{ik} - \\bar{X}_k \\right)^2}{N}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:203
msgid ""
"where the notation “Σ\\ :sub:`ik`” is a lazy way of saying “calculate a sum "
"by looking at all students in all tutorials”, since each “ik” corresponds to "
"one student.\\ [#]_ But, as we saw in chapter :doc:`../Ch08/"
"Ch08_Estimation`, calculating the variance by dividing by *N* produces a "
"biased estimate of the population variance. And previously we needed to "
"divide by *N* - 1 to fix this. However, as I mentioned at the time, the "
"reason why this bias exists is because the variance estimate relies on the "
"sample mean, and to the extent that the sample mean isn’t equal to the "
"population mean it can systematically bias our estimate of the variance. But "
"this time we’re relying on *two* sample means! Does this mean that we’ve got "
"more bias? Yes, yes it does. And does this mean we now need to divide by *N* "
"- 2 instead of *N* - 1, in order to calculate our pooled variance estimate? "
"Why, yes"
msgstr ""
"hvor notasjonen «Σ\\ :sub:`ik`» er en lat måte å si «beregn en sum ved å se "
"på alle studenter i alle øvinger», siden hver «ik» tilsvarer én student.\\ "
"[#]_ Men som vi så i kapittel :doc:`../Ch08/Ch08_Estimation`, gir det å "
"beregne variansen ved å dividere med *N* et skjevt estimat av "
"populasjonsvariansen. Tidligere måtte vi dividere med *N* - 1 for å fikse "
"dette. Men som jeg nevnte den gangen, er grunnen til at denne skjevheten "
"eksisterer, at variansestimatet er avhengig av utvalgsgjennomsnittet, og i "
"den grad utvalgsgjennomsnittet ikke er lik populasjonsgjennomsnittet, kan "
"det systematisk gi et skjevt estimat av variansen. Men denne gangen baserer "
"vi oss på *to* utvalgsgjennomsnitt! Betyr dette at vi har mer skjevhet? Ja, "
"ja, det gjør det. Og betyr det at vi nå må dividere med *N* - 2 i stedet for "
"*N* - 1 for å beregne vårt samlede variansestimat? Ja, det gjør det"

#: ../../Ch11/Ch11_tTest_03.rst:216
msgid ""
"\\hat\\sigma^2_p = \\frac{\\sum_{ik} \\left( X_{ik} - \\bar{X}_k \\right)^2}"
"{N -2}\n"
"\n"
msgstr ""
"\\hat\\sigma^2_p = \\frac{\\sum_{ik} \\left( X_{ik} - \\bar{X}_k \\right)^2}"
"{N -2}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:218
msgid ""
"Oh, and if you take the square root of this then you get :math:"
"`\\hat{\\sigma}_p`, the pooled standard deviation estimate. In other words, "
"the pooled standard deviation calculation is nothing special. It’s not "
"terribly different to the regular standard deviation calculation."
msgstr ""
"Og hvis du tar kvadratroten av dette, får du :math:`\\hat{\\sigma}_p`, det "
"sammenslåtte standardavviksestimatet. Med andre ord er ikke beregningen av "
"samlet standardavvik noe spesielt. Den er ikke veldig forskjellig fra den "
"vanlige beregningen av standardavvik."

#: ../../Ch11/Ch11_tTest_03.rst:225
msgid "Completing the test"
msgstr "Gjennomføring av testen"

#: ../../Ch11/Ch11_tTest_03.rst:227
msgid ""
"Regardless of which way you want to think about it, we now have our pooled "
"estimate of the standard deviation. From now on, I’ll drop the silly *p* "
"subscript, and just refer to this estimate as :math:`\\hat\\sigma`. Great. "
"Let’s now go back to thinking about the bloody hypothesis test, shall we? "
"Our whole reason for calculating this pooled estimate was that we knew it "
"would be helpful when calculating our *standard error* estimate. But "
"standard error of *what*? In the one-sample *t*-test it was the standard "
"error of the sample mean, SE(X̄), and since :math:`SE(X̄) = \\sigma / \\sqrt{N}"
"` that’s what the denominator of our *t*-statistic looked like. This time "
"around, however, we have *two* sample means. And what we’re interested in, "
"specifically, is the difference between the two *X̄*\\ :sub:`1` – *X̄*\\ :sub:"
"`2`. As a consequence, the standard error that we need to divide by is in "
"fact the **standard error of the difference** between means."
msgstr ""
"Uansett hvordan du vil se på det, har vi nå vårt samlede estimat av "
"standardavviket. Fra nå av vil jeg droppe den dumme *p*-betegnelsen, og bare "
"referere til dette estimatet som :math:`\\hat\\sigma`. Det er flott. La oss "
"nå gå tilbake til å tenke på den fordømte hypotesetesten, skal vi? Hele "
"grunnen til at vi beregnet dette sammenslåtte estimatet, var at vi visste at "
"det ville være nyttig når vi skulle beregne *standardfeilen*. Men "
"standardfeil for *hva*? I *t*-test med ett utvalg var det standardfeilen til "
"utvalgsgjennomsnittet, SE(X̄), og siden :math:`SE(X̄) = \\sigma / \\sqrt{N}`, "
"var det slik nevneren i *t*-statistikken vår så ut. Denne gangen har vi "
"imidlertid *to* utvalgsgjennomsnitt. Og det vi er interessert i, er "
"forskjellen mellom de to *X̄*\\ :sub:`1` - *X̄*\\ :sub:`2`. Standardfeilen som "
"vi må dividere med, er derfor **standardfeilen til differansen** mellom "
"gjennomsnittene."

#: ../../Ch11/Ch11_tTest_03.rst:241
msgid ""
"As long as the two variables really do have the same standard deviation, "
"then our estimate for the standard error is"
msgstr ""
"Så lenge de to variablene virkelig har samme standardavvik, er vårt estimat "
"for standardfeilen"

#: ../../Ch11/Ch11_tTest_03.rst:244
msgid ""
"SE(\\bar{X}_1 - \\bar{X}_2) = \\hat\\sigma \\sqrt{\\frac{1}{N_1} + \\frac{1}"
"{N_2}}\n"
"\n"
msgstr ""
"SE(\\bar{X}_1 - \\bar{X}_2) = \\hat\\sigma \\sqrt{\\frac{1}{N_1} + \\frac{1}"
"{N_2}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:246
msgid "and our *t*-statistic is therefore"
msgstr "og vår *t*-statistikk er derfor"

#: ../../Ch11/Ch11_tTest_03.rst:248 ../../Ch11/Ch11_tTest_04.rst:42
msgid ""
"t = \\frac{\\bar{X}_1 - \\bar{X}_2}{SE(\\bar{X}_1 - \\bar{X}_2)}\n"
"\n"
msgstr ""
"t = \\frac{\\bar{X}_1 - \\bar{X}_2}{SE(\\bar{X}_1 - \\bar{X}_2)}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:250
msgid ""
"Just as we saw with our one-sample test, the sampling distribution of this "
"*t*-statistic is a *t*-distribution (shocking, isn’t it?) as long as the "
"null hypothesis is true and all of the assumptions of the test are met. The "
"degrees of freedom, however, is slightly different. As usual, we can think "
"of the degrees of freedom to be equal to the number of data points minus the "
"number of constraints. In this case, we have *N* observations (*N*\\ :sub:"
"`1` in sample 1, and *N*\\ :sub:`2` in sample 2), and 2 constraints (the "
"sample means). So the total degrees of freedom for this test are *N* - 2."
msgstr ""
"Akkurat som vi så med ettutvalgstesten vår, er utvalgsfordelingen av denne "
"*t*-statistikken en *t*-fordeling (sjokkerende, ikke sant?) så lenge "
"nullhypotesen er sann og alle forutsetningene for testen er oppfylt. "
"Frihetsgradene er imidlertid litt annerledes. Som vanlig kan vi tenke oss at "
"frihetsgradene er lik antall datapunkter minus antall begrensninger. I dette "
"tilfellet har vi *N* observasjoner (*N*\\ :sub:`1` i utvalg 1, og *N*\\ :sub:"
"`2` i utvalg 2), og 2 begrensninger (utvalgsgjennomsnittene). De totale "
"frihetsgradene for denne testen er altså *N* - 2."

#: ../../Ch11/Ch11_tTest_03.rst:263
msgid ""
"Not surprisingly, you can run an independent samples *t*-test easily in "
"jamovi. The outcome variable for our test is the student ``grade``, and the "
"groups are defined in terms of the ``tutor`` for each class. So you probably "
"won’t be too surprised that all you have to do in jamovi is go to the "
"relevant analysis (``Analyses`` → ``T-Tests`` → ``Independent Samples T-"
"Test``) and move the ``grade`` variable across to the ``Dependent "
"Variables`` box, and the ``tutor`` variable across into the ``Grouping "
"Variable`` box, as shown in :numref:`fig-ttest_ind`."
msgstr ""
"Det er ikke overraskende at du kan enkelt gjennomføre en uavhengig *t*-test "
"i jamovi. Utfallsvariabelen for testen vår er studentens ``grade``, og "
"gruppene er definert i form av ``tutor`` for hver klasse. Så du blir nok "
"ikke så overrasket over at alt du trenger å gjøre i jamovi, er å gå til den "
"relevante analysen (``Analyses`` → ``T-Tests`` → ``Independent Samples T-"
"Test``) og flytte ``grade``-variabelen over til ``Dependent Variables``-"
"boksen, og ``tutor``-variabelen over til ``Grouping Variable``-boksen, slik "
"det vises i :numref:`fig-ttest_ind`."

#: ../../Ch11/Ch11_tTest_03.rst:274
msgid "Conducting an Independent Samples *t*-test in jamovi"
msgstr "Gjennomføring av en Independent Samples *t*-test i jamovi"

#: ../../Ch11/Ch11_tTest_03.rst:278
msgid ""
"Conducting an Independent Samples *t*-test in jamovi, with options for "
"recommended outputs checked."
msgstr ""
"Gjennomføring av en Independent Samples *t*-test i jamovi, med alternativer "
"for de anbefalte utgavene merket av."

#: ../../Ch11/Ch11_tTest_03.rst:283
msgid ""
"The output has a very familiar form. First, it tells you what test was run, "
"and it tells you the name of the dependent variable that you used. It then "
"reports the test results. Just like last time the test results consist of a "
"*t*-statistic, the degrees of freedom, and the *p*-value. The final section "
"reports two things: it gives you a confidence interval and an effect size. "
"I’ll talk about effect sizes later. The confidence interval, however, I "
"should talk about now."
msgstr ""
"Utgaven har en veldig kjent form. Først får du vite hvilken test som ble "
"kjørt, og navnet på den avhengige variabelen du brukte. Deretter rapporteres "
"testresultatene. Akkurat som forrige gang består testresultatene av en *t*-"
"statistikk, frihetsgradene og *p*-verdien. Den siste delen rapporterer to "
"ting: den gir deg et konfidensintervall og en effektstørrelse. Jeg skal "
"snakke om effektstørrelser senere. Konfidensintervallet bør jeg imidlertid "
"snakke om nå."

#: ../../Ch11/Ch11_tTest_03.rst:291
msgid ""
"It’s pretty important to be clear on what this confidence interval actually "
"refers to. It is a confidence interval for the *difference* between the "
"group means. In our example, Anastasia’s students had an average grade of "
"74.53, and Bernadette’s students had an average grade of 69.06, so the "
"difference between the two sample means is 5.48. But of course the "
"difference between population means might be bigger or smaller than this. "
"The confidence interval reported in :numref:`fig-ttest_ind` tells you that "
"there’s a if we replicated this study again and again, then 95\\% of the "
"time the true difference in means would lie between 0.20 and 10.76. Look "
"back at :doc:`../Ch08/Ch08_Estimation_5` for a reminder about what "
"confidence intervals mean."
msgstr ""
"Det er ganske viktig å ha klart for seg hva dette konfidensintervallet "
"faktisk refererer til. Det er et konfidensintervall for *forskjellen* mellom "
"gruppegjennomsnittene. I vårt eksempel hadde Anastasias studenter en "
"gjennomsnittskarakter på 74,53, og Bernadettes studenter hadde en "
"gjennomsnittskarakter på 69,06, så forskjellen mellom de to "
"utvalgsgjennomsnittene er 5,48. Men forskjellen mellom "
"populasjonsgjennomsnittet kan selvsagt være større eller mindre enn dette. "
"Konfidensintervallet som er rapportert i :numref:`fig-ttest_ind`, forteller "
"deg at hvis vi gjentar denne studien igjen og igjen, vil den sanne "
"forskjellen i gjennomsnitt i 95\\% av tilfellene ligge mellom 0,20 og 10,76. "
"Se :doc:`../Ch08/Ch08_Estimation_5` for å få en påminnelse om hva "
"konfidensintervallene betyr."

#: ../../Ch11/Ch11_tTest_03.rst:303
msgid ""
"In any case, the difference between the two groups is significant (just "
"barely), so we might write up the result using text like this:"
msgstr ""
"Uansett er forskjellen mellom de to gruppene signifikant (så vidt), så vi "
"kan skrive opp resultatet med en tekst som dette:"

#: ../../Ch11/Ch11_tTest_03.rst:306
msgid ""
"The mean grade in Anastasia’s class was 74.5\\% (std dev = 9.0), whereas the "
"mean in Bernadette’s class was 69.1\\% (std dev = 5.8). A Student’s "
"independent samples *t*-test showed that this 5.4\\% difference was "
"significant (*t*\\(31) = 2.1, *p* < 0.05, CI\\ :sub:`95` = [0.2, 10.8]`, *d* "
"= 0.74), suggesting that a genuine difference in learning outcomes has "
"occurred."
msgstr ""
"Gjennomsnittskarakteren i Anastasias klasse var 74,5\\% (std.avvik = 9,0), "
"mens gjennomsnittskarakteren i Bernadettes klasse var 69,1\\% (std.avvik = "
"5,8). En Students uavhengig *t*-test viste at denne forskjellen på 5,4\\% "
"var signifikant (*t*\\(31) = 2,1, *p* < 0,05, KI\\ :sub:`95` = [0,2, 10,8]`, "
"*d* = 0,74), noe som tyder på at det har oppstått en reell forskjell i "
"læringsutbytte."

#: ../../Ch11/Ch11_tTest_03.rst:313
msgid ""
"Notice that I’ve included the confidence interval and the effect size in the "
"stat block. People don’t always do this. At a bare minimum, you’d expect to "
"see the *t*-statistic, the degrees of freedom and the *p*-value. So you "
"should include something like this at a minimum: *t*\\(31) = 2.1, *p* < "
"0.05. If statisticians had their way, everyone would also report the "
"confidence interval and probably the effect size measure too, because they "
"are useful things to know. But real life doesn’t always work the way "
"statisticians want it to so you should make a judgment based on whether you "
"think it will help your readers and, if you’re writing a scientific paper, "
"the editorial standard for the journal in question. Some journals expect you "
"to report effect sizes, others don’t. Within some scientific communities it "
"is standard practice to report confidence intervals, in others it is not. "
"You’ll need to figure out what your audience expects. But, just for the sake "
"of clarity, if you’re taking my class, my default position is that it’s "
"usually worth including both the effect size and the confidence interval."
msgstr ""
"Legg merke til at jeg har tatt med konfidensintervallet og effektstørrelsen "
"i statistikkblokken. Det er ikke alltid folk gjør dette. Som et minimum "
"forventer du å se *t*-statistikken, frihetsgradene og *p*-verdien. Så du bør "
"som et minimum inkludere noe som dette: *t*\\(31) = 2,1, *p* < 0,05. Hvis "
"statistikerne fikk bestemme, ville alle også rapportert konfidensintervallet "
"og sannsynligvis også effektstørrelsesmålet, fordi det er nyttig å vite. Men "
"virkeligheten fungerer ikke alltid slik statistikerne ønsker, så du bør "
"gjøre en vurdering basert på om du tror det vil hjelpe leserne dine, og, "
"hvis du skriver en vitenskapelig artikkel, den redaksjonelle standarden for "
"det aktuelle tidsskriftet. Noen tidsskrifter forventer at du rapporterer "
"effektstørrelser, andre gjør det ikke. I noen vitenskapelige miljøer er det "
"vanlig praksis å rapportere konfidensintervaller, i andre ikke. Du må finne "
"ut hva publikum forventer. Men bare for å gjøre det klart: Hvis du tar "
"kurset mitt, er standardinnstillingen min at det vanligvis lønner seg å "
"inkludere både effektstørrelsen og konfidensintervallet."

#: ../../Ch11/Ch11_tTest_03.rst:332
msgid "Positive and negative *t*-values"
msgstr "Positive og negative *t*-verdier"

#: ../../Ch11/Ch11_tTest_03.rst:334
msgid ""
"Before moving on to talk about the assumptions of the *t*-test, there’s one "
"additional point I want to make about the use of *t*-tests in practice. The "
"first one relates to the sign of the *t*-statistic (that is, whether it is a "
"positive number or a negative one). One very common worry that students have "
"when they start running their first *t*-test is that they often end up with "
"negative values for the *t*-statistic and don’t know how to interpret it. In "
"fact, it’s not at all uncommon for two people working independently to end "
"up with results that are almost identical, except that one person has a "
"negative *t*-values and the other one has a positive *t*-value. Assuming "
"that you’re running a two-sided test then the *p*-values will be identical. "
"On closer inspection, the students will notice that the confidence intervals "
"also have the opposite signs. This is perfectly okay. Whenever this happens, "
"what you’ll find is that the two versions of the results arise from slightly "
"different ways of running the *t*-test. What’s happening here is very "
"simple. The *t*-statistic that we calculate here is always of the form"
msgstr ""
"Før jeg går videre til å snakke om forutsetningene for *t*-testen, vil jeg "
"komme med ytterligere ett poeng om bruken av *t*-tester i praksis. Det "
"første gjelder fortegnet til *t*-statistikken (det vil si om det er et "
"positivt eller negativt tall). En veldig vanlig bekymring som studenter har "
"når de begynner å kjøre sin første *t*-test, er at de ofte ender opp med "
"negative verdier for *t*-statistikken og ikke vet hvordan de skal tolke den. "
"Det er faktisk ikke uvanlig at to personer som jobber uavhengig av "
"hverandre, ender opp med resultater som er nesten identiske, bortsett fra at "
"den ene personen har en negativ *t*-verdi og den andre har en positiv *t*-"
"verdi. Hvis du antar at du kjører en tosidig test, vil *p*-verdiene være "
"identiske. Ved nærmere ettersyn vil studentene legge merke til at "
"konfidensintervallene også har motsatt fortegn. Dette er helt i orden. Når "
"dette skjer, vil du oppdage at de to versjonene av resultatene skyldes litt "
"forskjellige måter å kjøre *t*-testene på. Det som skjer her, er veldig "
"enkelt. *t*-statistikken som vi beregner her, er alltid på formen"

#: ../../Ch11/Ch11_tTest_03.rst:353
msgid "*t* = (mean 1 - mean 2) / SE"
msgstr "*t* = (gjennomsnitt 1 - gjennomsnitt 2) / SE"

#: ../../Ch11/Ch11_tTest_03.rst:355
msgid ""
"If “mean 1” is larger than “mean 2” the *t*-statistic will be positive, "
"whereas if “mean 2” is larger then the *t*-statistic will be negative. "
"Similarly, the confidence interval that jamovi reports is the confidence "
"interval for the difference “(mean 1) minus (mean 2)”, which will be the "
"reverse of what you’d get if you were calculating the confidence interval "
"for the difference “(mean 2) minus (mean 1)”."
msgstr ""
"Hvis «gjennomsnitt 1» er større enn «gjennomsnitt 2», vil *t*-statistikken "
"være positiv, mens hvis «gjennomsnitt 2» er større, vil *t*-statistikken "
"være negativ. På samme måte er konfidensintervallet som jamovi rapporterer, "
"konfidensintervallet for differansen «(gjennomsnitt 1 minus gjennomsnitt "
"2)», som vil være det motsatte av det du ville fått hvis du beregnet "
"konfidensintervallet for differansen «(gjennomsnitt 2 minus gjennomsnitt 1)»."

#: ../../Ch11/Ch11_tTest_03.rst:362
msgid ""
"Okay, that’s pretty straightforward when you think about it, but now "
"consider our *t*-test comparing Anastasia’s class to Bernadette’s class. "
"Which one should we call “mean 1” and which one should we call “mean 2”. "
"It’s arbitrary. However, you really do need to designate one of them as "
"“mean 1” and the other one as “mean 2”. Not surprisingly, the way that "
"jamovi handles this is also pretty arbitrary. In earlier versions of the "
"book I used to try to explain it, but after a while I gave up, because it’s "
"not really all that important and to be honest I can never remember myself. "
"Whenever I get a significant *t*-test result, and I want to figure out which "
"mean is the larger one, I don’t try to figure it out by looking at the *t*-"
"statistic. Why would I bother doing that? It’s foolish. It’s easier just to "
"look at the actual group means since the jamovi output actually shows them!"
msgstr ""
"Ok, det er ganske enkelt når du tenker over det, men tenk nå på *t*-testen "
"vår som sammenligner Anastasias klasse med Bernadettes klasse. Hvilken av "
"dem skal vi kalle «gjennomsnitt 1» og hvilken skal vi kalle «gjennomsnitt "
"2»? Det er vilkårlig. Men du trenger virkelig å betegne en av dem som "
"«gjennomsnitt 1» og den andre som «gjennomsnitt 2». Ikke overraskende er "
"måten jamovi håndterer dette på, også ganske vilkårlig. I tidligere "
"versjoner av boken pleide jeg å prøve å forklare det, men etter en stund ga "
"jeg opp, fordi det egentlig ikke er så viktig, og for å være ærlig kan jeg "
"aldri huske det selv. Når jeg får et signifikant *t*-testresultat, og jeg "
"vil finne ut hvilket gjennomsnitt som er det største, prøver jeg ikke å "
"finne ut av det ved å se på *t*-statistikken. Hvorfor skulle jeg gidde å "
"gjøre det? Det er tåpelig. Det er enklere å bare se på de faktiske "
"gruppegjennomsnittene, siden jamovi-utgaven faktisk viser dem!"

#: ../../Ch11/Ch11_tTest_03.rst:376
msgid ""
"Here’s the important thing. Because it really doesn’t matter what jamovi "
"shows you, I usually try to *report* the *t*-statistic in such a way that "
"the numbers match up with the text. Suppose that what I want to write in my "
"report is “Anastasia’s class had higher grades than Bernadette’s class”. The "
"phrasing here implies that Anastasia’s group comes first, so it makes sense "
"to report the *t*-statistic as if Anastasia’s class corresponded to group 1. "
"If so, I would write"
msgstr ""
"Her er det viktige. Fordi det egentlig ikke spiller noen rolle hva jamovi "
"viser deg, prøver jeg vanligvis å *rapportere* *t*-statistikken på en slik "
"måte at tallene stemmer overens med teksten. Anta at det jeg ønsker å skrive "
"i rapporten min er «Anastasias klasse hadde høyere karakterer enn "
"Bernadettes klasse». Formuleringen her antyder at Anastasias gruppe kommer "
"først, så det gir mening å rapportere *t*-statistikken som om Anastasias "
"klasse tilsvarte gruppe 1. I så fall ville jeg skrevet"

#: ../../Ch11/Ch11_tTest_03.rst:384
msgid ""
"Anastasia’s class had higher grades than Bernadette’s class: *t*\\(31) = "
"2.1, *p* = 0.04."
msgstr ""
"Anastasias klasse hadde høyere karakterer enn Bernadettes klasse: *t*\\(31) "
"= 2,1, *p* = 0,04."

#: ../../Ch11/Ch11_tTest_03.rst:387
msgid ""
"(I wouldn’t actually underline the word “higher” in real life, I’m just "
"doing it to emphasise the point that “higher” corresponds to positive *t*-"
"values). On the other hand, suppose the phrasing I wanted to use has "
"Bernadette’s class listed first. If so, it makes more sense to treat her "
"class as group 1, and if so, the write up looks like this:"
msgstr ""
"(Jeg ville ikke ha understreket ordet «høyere» i virkeligheten, jeg gjør det "
"bare for å understreke poenget med at «høyere» tilsvarer positive *t*-"
"verdier). På den annen side kan du tenke deg at Bernadettes klasse står "
"først i den formuleringen jeg ønsket å bruke. I så fall gir det mer mening å "
"behandle hennes klasse som gruppe 1, og i så fall ser det slik ut:"

#: ../../Ch11/Ch11_tTest_03.rst:393
msgid ""
"Bernadette’s class had lower grades than Anastasia’s class: *t*\\(31) = "
"-2.1, *p* = 0.04."
msgstr ""
"Bernadettes klasse hadde lavere karakterer enn Anastasias klasse: *t*\\(31) "
"= -2,1, *p* = 0,04."

#: ../../Ch11/Ch11_tTest_03.rst:396
msgid ""
"Because I’m talking about one group having “lower” scores this time around, "
"it is more sensible to use the negative form of the *t*-statistic. It just "
"makes it read more cleanly."
msgstr ""
"Fordi jeg snakker om at en gruppe har «lavere» skår denne gangen, er det mer "
"fornuftig å bruke den negative formen av *t*-statistikken. Det gjør det bare "
"mer oversiktlig."

#: ../../Ch11/Ch11_tTest_03.rst:400
msgid ""
"One last thing: please note that you *can’t* do this for other types of test "
"statistics. It works for *t*-tests, but it wouldn’t be meaningful for χ²-"
"tests, *F*-tests or indeed for most of the tests I talk about in this book. "
"So don’t over-generalise this advice! I’m really just talking about *t*-"
"tests here and nothing else!"
msgstr ""
"En siste ting: Vær oppmerksom på at du *ikke* kan gjøre dette for andre "
"typer teststatistikk. Det fungerer for *t*-tester, men det vil ikke være "
"meningsfylt for χ²-tester, *F*-tester eller de fleste testene jeg snakker om "
"i denne boken. Så ikke overgeneraliser dette rådet! Jeg snakker egentlig "
"bare om *t*-tester her, og ikke noe annet!"

#: ../../Ch11/Ch11_tTest_03.rst:410
msgid "Assumptions of the Student *t*-test"
msgstr "Forutsetninger for Students *t*-test"

#: ../../Ch11/Ch11_tTest_03.rst:412
msgid ""
"As always, our hypothesis test relies on some assumptions. So what are they? "
"For the Student *t*-test there are three assumptions, some of which we saw "
"previously in the context of the one sample *t*-test (see section :ref:"
"`Assumptions of the one sample *t*-test <assumptions_one_sample_t_test>`):"
msgstr ""
"Som alltid er hypotesetesten vår avhengig av noen forutsetninger. Så hva er "
"disse? For Students *t*-test er det tre forutsetninger, og noen av disse har "
"vi sett tidligere i forbindelse med *t*-test med ett utvalg (se avsnitt :ref:"
"`Forutsetninger for *t*-test med ett utvalg "
"<assumptions_one_sample_t_test>`):"

#: ../../Ch11/Ch11_tTest_03.rst:417
msgid ""
"*Normality*. Like the one-sample *t*-test, it is assumed that the data are "
"normally distributed. Specifically, we assume that both groups are normally "
"distributed. In section :doc:`Ch11_tTest_08`, we’ll discuss how to test for "
"normality, and in section :doc:`Ch11_tTest_09` we’ll discuss possible "
"solutions."
msgstr ""
"*Normalfordeling*. I likhet med *t*-test med ett utvalg forutsettes det at "
"dataene er normalfordelte. Nærmere bestemt antar vi at begge gruppene er "
"normalfordelte. I avsnitt :doc:`Ch11_tTest_08` diskuterer vi hvordan man "
"tester for normalfordeling, og i avsnitt :doc:`Ch11_tTest_09` diskuterer vi "
"mulige løsninger."

#: ../../Ch11/Ch11_tTest_03.rst:423
msgid ""
"*Independence*. Once again, it is assumed that the observations are "
"independently sampled. In the context of the Student test this has two "
"aspects to it. Firstly, we assume that the observations within each sample "
"are independent of one another (exactly the same as for the one-sample "
"test). However, we also assume that there are no cross-sample dependencies. "
"If, for instance, it turns out that you included some participants in both "
"experimental conditions of your study (e.g., by accidentally allowing the "
"same person to sign up to different conditions), then there are some cross "
"sample dependencies that you’d need to take into account."
msgstr ""
"*Uavhengighet*. Igjen forutsettes det at observasjonene er uavhengige av "
"hverandre. I forbindelse med Students *t*-test har dette to aspekter. For "
"det første antar vi at observasjonene i hvert utvalg er uavhengige av "
"hverandre (nøyaktig det samme som for ettutvalgstesten). Vi antar imidlertid "
"også at det ikke finnes noen avhengigheter på tvers av utvalgene. Hvis det "
"for eksempel viser seg at du har inkludert noen deltakere i begge "
"eksperimentelle betingelser i studien din (f.eks. ved at du ved et uhell har "
"latt samme person melde seg på forskjellige betingelser), er det noen "
"kryssutvalgsavhengigheter som du må ta hensyn til."

#: ../../Ch11/Ch11_tTest_03.rst:434
msgid ""
"*Homogeneity of variance* (also called “homoscedasticity”). The third "
"assumption is that the population standard deviation is the same in both "
"groups. You can test this assumption using the Levene test, which I’ll talk "
"about later on in the book (section :ref:`Checking the homogeneity of "
"variance assumption <homogeneity_of_variance_anova>`). However, there’s a "
"very simple remedy for this assumption if you are worried, which I’ll talk "
"about in the next section."
msgstr ""
"*Varianshomogenitet* (også kalt «homoskedastisitet»). Den tredje "
"forutsetningen er at standardavviket i populasjonen er det samme i begge "
"gruppene. Du kan teste denne forutsetningen ved hjelp av Levene-testen, som "
"jeg vil snakke om senere i boken (avsnitt :ref:`Sjekke forutsetningen om "
"varianshomogenitet <homogeneity_of_variance_anova>`). Det finnes imidlertid "
"en veldig enkel løsning på denne forutsetningen hvis du er bekymret, som jeg "
"skal snakke om i neste avsnitt."

#: ../../Ch11/Ch11_tTest_03.rst:445
msgid "Although it is the simplest, which is why I started with it."
msgstr "Selv om det er den enkleste, og det var derfor jeg begynte med den."

#: ../../Ch11/Ch11_tTest_03.rst:448
msgid ""
"A funny question almost always pops up at this point: what the heck *is* the "
"population being referred to in this case? Is it the set of students "
"actually taking Dr Harpo’s class (all 33 of them)? The set of people who "
"might take the class (an unknown number of them)? Or something else? Does it "
"matter which of these we pick? It’s traditional in an introductory "
"behavioural stats class to mumble a lot at this point, but since I get asked "
"this question every year by my students, I’ll give a brief answer. "
"Technically yes, it does matter. If you change your definition of what the "
"“real world” population actually is, then the sampling distribution of your "
"observed mean *X̄* changes too. The *t*-test relies on an assumption that the "
"observations are sampled at random from an infinitely large population and, "
"to the extent that real life isn’t like that, then the *t*-test can be "
"wrong. In practice, however, this isn’t usually a big deal. Even though the "
"assumption is almost always wrong, it doesn’t lead to a lot of pathological "
"behaviour from the test, so we tend to just ignore it."
msgstr ""
"Et morsomt spørsmål dukker nesten alltid opp på dette punktet: Hva pokker "
"*er* populasjonen det refereres til i dette tilfellet? Er det de studentene "
"som faktisk tar dr. Harpos kurs (alle 33)? Gruppen av personer som kan komme "
"til å ta kurset (et ukjent antall)? Eller noe annet? Spiller det noen rolle "
"hvilken av disse vi velger? Det er tradisjon for å mumle mye på dette "
"punktet i en introduksjonskurs i atferdsstatistikk, men siden jeg får dette "
"spørsmålet hvert år av studentene mine, skal jeg gi et kort svar. Teknisk "
"sett, ja, det spiller en rolle. Hvis du endrer definisjonen av hva "
"populasjonen i den «virkelige verden» faktisk er, endres også "
"utvalgsfordelingen av det observerte gjennomsnittet *X̄*. *t*-testen bygger "
"på en antakelse om at observasjonene er tilfeldig utvalgt fra en uendelig "
"stor populasjon, og i den grad virkeligheten ikke er slik, kan *t*-testen ta "
"feil. I praksis er dette imidlertid vanligvis ikke så farlig. Selv om "
"antakelsen nesten alltid er feil, fører det ikke til mye patologisk atferd "
"fra testen, så vi pleier å ignorere den."

#: ../../Ch11/Ch11_tTest_03.rst:465
msgid ""
"A more correct notation will be introduced in chapter :doc:`../Ch13/"
"Ch13_ANOVA`."
msgstr ""
"En mer korrekt notasjon vil bli introdusert i kapittel :doc:`../Ch13/"
"Ch13_ANOVA`."

#: ../../Ch11/Ch11_tTest_04.rst:4
msgid "The independent samples *t*-test (Welch test)"
msgstr "Uavhengig *t*-test (Welch-test)"

#: ../../Ch11/Ch11_tTest_04.rst:6
msgid ""
"The biggest problem with using the Student test in practice is the third "
"assumption listed in the previous section. It assumes that both groups have "
"the same standard deviation. This is rarely true in real life. If two "
"samples don’t have the same means, why should we expect them to have the "
"same standard deviation? There’s really no reason to expect this assumption "
"to be true. We’ll talk a little bit about how you can check this assumption "
"later on because it does crop up in a few different places, not just the *t*-"
"test. But right now I’ll talk about a different form of the *t*-test (:ref:"
"`Welch, 1947 <Welch_1947>`) that does not rely on this assumption. A "
"graphical illustration of what the **Welch t test** assumes about the data "
"is shown in :numref:`fig-ttesthyp2`, to provide a contrast with the Student "
"test version in :numref:`fig-ttesthyp`. I’ll admit it’s a bit odd to talk "
"about the cure before talking about the diagnosis, but as it happens the "
"``Welch's`` test can be specified as one of the ``Independent Samples T-"
"Test`` options in jamovi, so this is probably the best place to discuss it."
msgstr ""
"Det største problemet med å bruke Students *t*-test i praksis er den tredje "
"forutsetningen som ble nevnt i forrige avsnitt. Den forutsetter at begge "
"gruppene har samme standardavvik. Dette stemmer sjelden i virkeligheten. "
"Hvis to utvalg ikke har samme gjennomsnitt, hvorfor skulle vi da forvente at "
"de har samme standardavvik? Det er egentlig ingen grunn til å forvente at "
"denne antakelsen skulle være sann. Vi skal snakke litt om hvordan du kan "
"sjekke denne antakelsen senere, for den dukker opp flere steder, ikke bare i "
"*t*-testen. Men akkurat nå skal jeg snakke om en annen form for *t*-testen (:"
"ref:`Welch, 1947 <Welch_1947>`) som ikke baserer seg på denne antakelsen. En "
"grafisk illustrasjon av hva **Welch-t-test** antar om dataene er vist i :"
"numref:`fig-ttesthyp2`, for å gi en kontrast til Students *t*-test-versjonen "
"i :numref:`fig-ttesthyp`. Jeg innrømmer at det er litt rart å snakke om "
"kuren før vi snakker om diagnosen, men det har seg slik at ``Welch's`` test "
"kan spesifiseres som et av ``Independent Samples T-Test``-alternativene i "
"jamovi, så dette er sannsynligvis det beste stedet å diskutere den."

#: ../../Ch11/Ch11_tTest_04.rst:24
msgid "Illustration: Null and alternative hypotheses for the Welch *t*-test"
msgstr "Illustrasjon: Null- og alternativhypoteser for Welch *t*-test"

#: ../../Ch11/Ch11_tTest_04.rst:28
msgid ""
"Graphical illustration of the null and alternative hypotheses assumed by the "
"Welch *t*-test. Like the Student *t*-test for Independent Samples (:numref:"
"`fig-ttesthyp`) we assume that both samples are drawn from a normally-"
"distributed population; but the alternative hypothesis no longer requires "
"the two populations to have equal variance."
msgstr ""
"Grafisk illustrasjon av nullhypotesen og alternativhypotesen i *t*-test med "
"Welch-korreksjon. I likhet med Students uavhengig *t*-test (:numref:`fig-"
"ttesthyp`) antar vi at begge utvalgene er trukket fra en normalfordelt "
"populasjon, men alternativhypotesen krever ikke lenger at de to "
"populasjonene har lik varians."

#: ../../Ch11/Ch11_tTest_04.rst:36
msgid ""
"The Welch test is very similar to the Student test. For example, the *t*-"
"statistic that we use in the Welch test is calculated in much the same way "
"as it is for the Student test. That is, we take the difference between the "
"sample means and then divide it by some estimate of the standard error of "
"that difference:"
msgstr ""
"Welchs *t*-test er svært lik Students *t*-test. For eksempel beregnes *t*-"
"statistikken som vi bruker i Welchs *t*-test, på omtrent samme måte som i "
"Students *t*-test. Det vil si at vi tar differansen mellom "
"utvalgsgjennomsnittene og dividerer den med et estimat av standardfeilen til "
"denne differansen:"

#: ../../Ch11/Ch11_tTest_04.rst:44
msgid ""
"The main difference is that the standard error calculations are different. "
"If the two populations have different standard deviations, then it’s a "
"complete nonsense to try to calculate a pooled standard deviation estimate, "
"because you’re averaging apples and oranges.\\ [#]_"
msgstr ""
"Hovedforskjellen er at standardfeilberegningene er forskjellige. Hvis de to "
"populasjonene har ulike standardavvik, er det fullstendig meningsløst å "
"prøve å beregne et samlet standardavviksestimat, fordi du da beregner "
"gjennomsnittet av epler og pærer.\\ [#]_"

#: ../../Ch11/Ch11_tTest_04.rst:49
msgid ""
"But you can still estimate the standard error of the difference between "
"sample means, it just ends up looking different"
msgstr ""
"Men du kan fortsatt estimere standardfeilen for forskjellen mellom "
"utvalgsgjennomsnitt, det ser bare annerledes ut"

#: ../../Ch11/Ch11_tTest_04.rst:52
msgid ""
"SE(\\bar{X}_1 - \\bar{X}_2) = \\sqrt{ \\frac{{\\hat{\\sigma}_1}^2}{N_1} + "
"\\frac{{\\hat{\\sigma}_2}^2}{N_2} }\n"
"\n"
msgstr ""
"SE(\\bar{X}_1 - \\bar{X}_2) = \\sqrt{ \\frac{{\\hat{\\sigma}_1}^2}{N_1} + "
"\\frac{{\\hat{\\sigma}_2}^2}{N_2} }\n"
"\n"

#: ../../Ch11/Ch11_tTest_04.rst:54
msgid ""
"The reason why it’s calculated this way is beyond the scope of this book. "
"What matters for our purposes is that the *t*-statistic that comes out of "
"the Welch *t*-test is actually somewhat different to the one that comes from "
"the Student *t*-test."
msgstr ""
"Grunnen til at den beregnes på denne måten, ligger utenfor denne bokens "
"rammer. Det som er viktig for vårt formål, er at *t*-statistikken som kommer "
"ut av Welch-*t*-test, faktisk er noe annerledes enn den som kommer ut av "
"Students *t*-test."

#: ../../Ch11/Ch11_tTest_04.rst:59
msgid ""
"The second difference between Welch and Student is that the degrees of "
"freedom are calculated in a very different way. In the Welch test, the "
"“degrees of freedom” doesn’t have to be a whole number any more, and it "
"doesn’t correspond all that closely to the “number of data points minus the "
"number of constraints” heuristic that I’ve been using up to this point."
msgstr ""
"Den andre forskjellen mellom Welch og Student er at frihetsgradene beregnes "
"på en helt annen måte. I Welchs *t*-test trenger ikke «frihetsgradene» "
"lenger å være et helt tall, og det samsvarer ikke så godt med heuristikken "
"«antall datapunkter minus antall constraints» som jeg har brukt til nå."

#: ../../Ch11/Ch11_tTest_04.rst:66
msgid "The degrees of freedom are, in fact"
msgstr "Frihetsgradene er i realiteten"

#: ../../Ch11/Ch11_tTest_04.rst:68
msgid ""
"\\mbox{df} = \\frac{ ({\\hat{\\sigma}_1}^2 / N_1 + {\\hat{\\sigma}_2}^2 / "
"N_2)^2 }{  ({\\hat{\\sigma}_1}^2 / N_1)^2 / (N_1 -1 )  + ({\\hat{\\sigma}_2}"
"^2 / N_2)^2 / (N_2 -1 ) }\n"
"\n"
msgstr ""
"\\mbox{df} = \\frac{ ({\\hat{\\sigma}_1}^2 / N_1 + {\\hat{\\sigma}_2}^2 / "
"N_2)^2 }{  ({\\hat{\\sigma}_1}^2 / N_1)^2 / (N_1 -1 )  + ({\\hat{\\sigma}_2}"
"^2 / N_2)^2 / (N_2 -1 ) }\n"
"\n"

#: ../../Ch11/Ch11_tTest_04.rst:70
msgid ""
"which is all pretty straightforward and obvious, right? Well, perhaps not. "
"It doesn’t really matter for our purposes. What matters is that you’ll see "
"that the “df” value that pops out of a Welch test tends to be a little bit "
"smaller than the one used for the Student test, and it doesn’t have to be a "
"whole number."
msgstr ""
"som er jo ganske enkelt og opplagt, ikke sant? Vel, kanskje ikke. Det "
"spiller egentlig ingen rolle for vårt formål. Det som betyr noe, er at du "
"vil se at «df»-verdien som kommer ut av en Welch-test, har en tendens til å "
"være litt mindre enn den som brukes for Students *t*-test, og den trenger "
"ikke å være et helt tall."

#: ../../Ch11/Ch11_tTest_04.rst:77
msgid "Doing the Welch test in jamovi"
msgstr "Gjennomfør Welchs *t*-test i jamovi"

#: ../../Ch11/Ch11_tTest_04.rst:79
msgid ""
"If you tick the check box for the ``Welch's`` test in the analysis we did "
"above, then this is what it gives you :numref:`fig-ttest_welch`:"
msgstr ""
"Hvis du krysser av i boksen for ``Welch's`` test i analysen vi gjorde "
"ovenfor, får du dette :numref:`fig-ttest_welch`:"

#: ../../Ch11/Ch11_tTest_04.rst:84
msgid "Results showing the Welch test alongside the default Student’s *t*-test"
msgstr ""
"Resultater som viser Welchs *t*-test sammen med standard Student's *t*-test"

#: ../../Ch11/Ch11_tTest_04.rst:88
msgid ""
"Results showing the Welch test alongside the default Student’s *t*-test in "
"jamovi"
msgstr ""
"Resultater som viser Welchs *t*-test sammen med standard Student's *t*-test "
"i jamovi"

#: ../../Ch11/Ch11_tTest_04.rst:93
msgid ""
"The interpretation of this output should be fairly obvious. You read the "
"output for the Welch’s test in the same way that you would for the Student’s "
"test. You’ve got your descriptive statistics, the test results and some "
"other information. So that’s all pretty easy."
msgstr ""
"Tolkningen av dette resultatet burde være ganske åpenbar. Du leser utgaven "
"for Welchs test på samme måte som du ville gjort for Students test. Du har "
"deskriptivstatistikk, testresultatene og litt annen informasjon. Så det er "
"ganske enkelt."

#: ../../Ch11/Ch11_tTest_04.rst:98
msgid ""
"Except, except… our result isn’t significant anymore. When we ran the "
"Student test we did get a significant effect, but the Welch test on the same "
"data set is not (*t*\\(23.02) = 2.03, *p* = 0.054). What does this mean? "
"Should we panic? Is the sky burning? Probably not. The fact that one test is "
"significant and the other isn’t doesn’t itself mean very much, especially "
"since I kind of rigged the data so that this would happen. As a general "
"rule, it’s not a good idea to go out of your way to try to interpret or "
"explain the difference between a *p*-value of 0.049 and a *p*-value of "
"0.051. If this sort of thing happens in real life, the *difference* in these "
"*p*-values is almost certainly due to chance. What does matter is that you "
"take a little bit of care in thinking about what test you use. The Student "
"test and the Welch test have different strengths and weaknesses. If the two "
"populations really do have equal variances, then the Student test is "
"slightly more powerful (lower Type II error rate) than the Welch test. "
"However, if they *don’t* have the same variances, then the assumptions of "
"the Student test are violated and you may not be able to trust it; you might "
"end up with a higher Type I error rate. So it’s a trade off. However, in "
"real life I tend to prefer the Welch test, because almost no-one *actually* "
"believes that the population variances are identical."
msgstr ""
"Bortsett fra at resultatet vårt ikke lenger er signifikant. Da vi kjørte "
"Students *t*-test, fikk vi en signifikant effekt, men Welchs *t*-test på det "
"samme datasettet er ikke signifikant (*t*\\(23,02) = 2,03, *p* = 0,054). Hva "
"betyr dette? Bør vi få panikk? Brenner himmelen? Sannsynligvis ikke. At den "
"ene testen er signifikant og den andre ikke er det, betyr i seg selv ikke så "
"mye, spesielt siden jeg på en måte har rigget dataene slik at dette skulle "
"skje. Som en generell regel er det ikke lurt å gjøre seg store anstrengelser "
"for å tolke eller forklare forskjellen mellom en *p*-verdi på 0,049 og en "
"*p*-verdi på 0,051. Hvis slike ting skjer i virkeligheten, skyldes "
"*forskjellen* i disse *p*-verdiene nesten helt sikkert tilfeldigheter. Det "
"som betyr noe, er at du tenker litt nøye gjennom hvilken test du bruker. "
"Students *t*-test og Welchs *t*-test har ulike styrker og svakheter. Hvis de "
"to populasjonene virkelig har lik varians, er Students *t*-test litt "
"sterkere (lavere type II-feilrate) enn Welchs *t*-test. Men hvis de *ikke* "
"har samme varians, brytes forutsetningene for Students *t*-test, og det er "
"ikke sikkert at du kan stole på den; du kan ende opp med en høyere type I-"
"feilrate. Så det er en avveining. I det virkelige liv foretrekker jeg "
"imidlertid Welch-testen, fordi nesten ingen *faktisk* tror at variansene i "
"populasjonen er identiske."

#: ../../Ch11/Ch11_tTest_04.rst:120
msgid "Assumptions of the test"
msgstr "Forutsetninger for testen"

#: ../../Ch11/Ch11_tTest_04.rst:122
msgid ""
"The assumptions of the Welch test are very similar to those made by the "
"Student *t*-test (see :ref:`Assumptions of the Student *t*-test "
"<assumptions_student_t_test>`), except that the Welch test does not assume "
"homogeneity of variance. This leaves only the assumption of normality and "
"the assumption of independence. The specifics of these assumptions are the "
"same for the Welch test as for the Student test."
msgstr ""
"Forutsetningene for Welchs *t*-test er svært like forutsetningene for "
"Students *t*-test (se :ref:`Forutsetninger for Students *t*-test "
"<assumptions_student_t_test>`), bortsett fra at Welchs *t*-test ikke "
"forutsetter varianshomogenitet. Dermed gjenstår bare forutsetningen om "
"normalfordeling og forutsetningen om uavhengighet. Disse forutsetningene er "
"de samme for Welchs *t*-test som for Students *t*-test."

#: ../../Ch11/Ch11_tTest_04.rst:132
msgid ""
"Well, I guess you can average apples and oranges, and what you end up with "
"is a delicious fruit smoothie. But no one really thinks that a fruit "
"smoothie is a very good way to describe the original fruits, do they?"
msgstr ""
"Vel, man kan vel ta et gjennomsnitt av epler og appelsiner, og det man ender "
"opp med er en deilig fruktsmoothie. Men ingen synes vel egentlig at en "
"fruktsmoothie er en veldig god måte å beskrive de opprinnelige fruktene på?"

#: ../../Ch11/Ch11_tTest_05.rst:4
msgid "The paired-samples *t*-test"
msgstr "Parvise *t*-tester"

#: ../../Ch11/Ch11_tTest_05.rst:6
msgid ""
"Regardless of whether we’re talking about the Student test or the Welch "
"test, an independent samples *t*-test is intended to be used in a situation "
"where you have two samples that are, well, independent of one another. This "
"situation arises naturally when participants are assigned randomly to one of "
"two experimental conditions, but it provides a very poor approximation to "
"other sorts of research designs. In particular, a repeated measures design, "
"in which each participant is measured (with respect to the same outcome "
"variable) in both experimental conditions, is not suited for analysis using "
"independent samples *t*-tests. For example, we might be interested in "
"whether listening to music reduces people’s working memory capacity. To that "
"end, we could measure each person’s working memory capacity in two "
"conditions: with music, and without music. In an experimental design such as "
"this one,\\ [#]_ each participant appears in *both* groups. This requires us "
"to approach the problem in a different way, by using the **paired samples t-"
"test**."
msgstr ""
"Uavhengig av om vi snakker om Student- eller Welch-versjonen, er en "
"uavhengig *t*-test beregnet på å brukes i en situasjon der du har to utvalg "
"som er uavhengige av hverandre. Denne situasjonen oppstår naturlig når "
"deltakerne fordeles tilfeldig til én av to eksperimentelle betingelser, men "
"den gir en svært dårlig tilnærming til andre typer forskningsdesign. "
"Spesielt er et design med gjentatte målinger, der hver deltaker måles (med "
"hensyn til den samme utfallsvariabelen) i begge eksperimentelle betingelser, "
"ikke egnet for analyse ved hjelp av uavhengig *t*-test. Vi kan for eksempel "
"være interessert i å finne ut om lytting til musikk reduserer folks "
"arbeidshukommelseskapasitet. I så fall kan vi måle hver persons "
"arbeidsminnekapasitet under to betingelser: med musikk og uten musikk. I et "
"eksperimentelt design som dette\\ [#]_ er hver deltaker med i *begge* "
"gruppene. Dette krever at vi tilnærmer oss problemet på en annen måte, ved å "
"bruke **paret t-test**."

#: ../../Ch11/Ch11_tTest_05.rst:26
msgid ""
"The data set that we’ll use this time comes from Dr Chico’s class.\\ [#]_ In "
"her class students take two major tests, one early in the semester and one "
"later in the semester. To hear her tell it, she runs a very hard class, one "
"that most students find very challenging. But she argues that by setting "
"hard assessments students are encouraged to work harder. Her theory is that "
"the first test is a bit of a “wake up call” for students. When they realise "
"how hard her class really is, they’ll work harder for the second test and "
"get a better mark. Is she right? To test this, let’s import the |chico|_ "
"data set into jamovi. This time jamovi does a good job during the import of "
"attributing measurement levels correctly. The |chico|_ data set contains "
"three variables: an ``id`` variable that identifies each student in the "
"class, the ``grade_test1`` variable that records the student grade for the "
"first test, and the ``grade_test2`` variable that has the grades for the "
"second test."
msgstr ""
"Datasettet vi skal bruke denne gangen, kommer fra klassen til Dr. Chico.\\ "
"[#]_ I klassen hennes tar studentene to store prøver, en tidlig i semesteret "
"og en senere i semesteret. Hun sier selv at hun har en svært vanskelig "
"klasse, en klasse som de fleste studentene synes er veldig utfordrende. Men "
"hun mener at ved å sette opp tøffe prøver blir studentene oppmuntret til å "
"jobbe hardere. Hennes teori er at den første prøven er litt av en «vekker» "
"for studentene. Når de innser hvor vanskelig faget hennes egentlig er, vil "
"de jobbe hardere på den andre prøven og få en bedre karakter. Har hun rett? "
"For å teste dette, la oss importere datasettet |chico|_ til jamovi. Denne "
"gangen gjør jamovi en god jobb med å tilordne målenivåene riktig under "
"importen. Datasettet |chico|_ inneholder tre variabler: en ``id``-variabel "
"som identifiserer hver student i klassen, variabelen ``grade_test1`` som "
"registrerer karakteren til studenten for den første prøven, og variabelen "
"``grade_test2`` som inneholder karakteren for den andre prøven."

#: ../../Ch11/Ch11_tTest_05.rst:41
msgid ""
"If we look at the jamovi spreadsheet it does seem like the class is a hard "
"one (most grades are between 50\\% and 60\\%), but it does look like there’s "
"an improvement from the first test to the second one."
msgstr ""
"Hvis vi ser på jamovi-regnearket, ser det ut til at klassen er vanskelig (de "
"fleste karakterene ligger mellom 50\\% og 60\\%), men det ser ut til at det "
"er en forbedring fra den første til den andre prøven."

#: ../../Ch11/Ch11_tTest_05.rst:47 ../../Ch11/Ch11_tTest_05.rst:51
msgid "Descriptives for the two grade test variables in the |chico|_ data set"
msgstr ""
"Deskriptivstatistikk for de to variablene med eksamenskarakterer i "
"datasettet |chico|_"

#: ../../Ch11/Ch11_tTest_05.rst:55
msgid ""
"If we take a quick look at the descriptive statistics, in :numref:`fig-"
"ttest_paired1`, we see that this impression seems to be supported. Across "
"all 20 students the mean grade for the first test is 57\\%, but this rises "
"to 58\\% for the second test. Although, given that the standard deviations "
"are 6.6\\% and 6.4\\% respectively, it’s starting to feel like maybe the "
"improvement is just illusory; maybe just random variation. This impression "
"is reinforced when you see the means and confidence intervals plotted in :"
"numref:`fig-pairedt` (left panel). If we were to rely on this plot alone, "
"looking at how wide those confidence intervals are, we’d be tempted to think "
"that the apparent improvement in student performance is pure chance."
msgstr ""
"Hvis vi tar en rask titt på den deskriptivstatistiske analysen, i :numref:"
"`fig-ttest_paired1`, ser vi at dette inntrykket ser ut til å bli støttet. På "
"tvers av alle de 20 studentene er gjennomsnittskarakteren for den første "
"testen 57\\%, men denne stiger til 58\\% for den andre testen. Men med tanke "
"på at standardavvikene er henholdsvis 6,6\\% og 6,4\\%, begynner det å føles "
"som om forbedringen kanskje bare er illusorisk; kanskje bare tilfeldig "
"variasjon. Dette inntrykket forsterkes når du ser gjennomsnittene og "
"konfidensintervallene plottet i :numref:`fig-pairedt` (venstre panel). Hvis "
"vi skulle stole på dette plottet alene, og se på hvor brede "
"konfidensintervallene er, ville vi bli fristet til å tro at den "
"tilsynelatende forbedringen i studentenes prestasjoner er ren tilfeldighet."

#: ../../Ch11/Ch11_tTest_05.rst:69
msgid "Mean grade for test 1 and test 2 in Dr Chico's class"
msgstr "Gjennomsnittskarakter for prøve 1 og prøve 2 i Dr. Chicos klasse"

#: ../../Ch11/Ch11_tTest_05.rst:73
msgid ""
"Mean grade for test 1 and test 2, with associated 95\\% confidence intervals "
"(left panel). Scatterplot showing the individual grades for test 1 and test "
"2 (middle panel). Histogram showing the improvement made by each student in "
"Dr Chico’s class (right panel). In the right panel, notice that almost the "
"entire distribution is above zero: the vast majority of students did improve "
"their performance from the first test to the second one."
msgstr ""
"Gjennomsnittskarakter for test 1 og test 2, med tilhørende 95\\%-"
"konfidensintervall (venstre panel). Spredningsdiagram som viser de "
"individuelle karakterene for test 1 og test 2 (midtre panel). Histogram som "
"viser forbedringen hver enkelt student i Dr. Chicos klasse har gjort (høyre "
"panel). Legg merke til at nesten hele fordelingen er over null i høyre "
"panel: De aller fleste studentene forbedret prestasjonene sine fra den "
"første til den andre prøven."

#: ../../Ch11/Ch11_tTest_05.rst:82
msgid ""
"Nevertheless, this impression is wrong. To see why, take a look at the "
"scatterplot of the grades for test 1 against the grades for test 2, shown "
"in :numref:`fig-pairedt` (middle panel). In this plot each dot corresponds "
"to the two grades for a given student. If their grade for test 1 (*x* co-"
"ordinate) equals their grade for test 2 (*y* co-ordinate), then the dot "
"falls on the line. Points falling above the line are the students that "
"performed better on the second test. Critically, almost all of the data "
"points fall above the diagonal line: almost all of the students *do* seem to "
"have improved their grade, if only by a small amount. This suggests that we "
"should be looking at the *improvement* made by each student from one test to "
"the next and treating that as our raw data. To do this, we’ll need to create "
"a new variable for the ``improvement`` that each student makes, and add it "
"to the |chico|_ data set. The easiest way to do this is to compute a new "
"variable, with the expression ``grade_test2 - grade_test1``."
msgstr ""
"Likevel er dette inntrykket feil. For å se hvorfor, kan du ta en titt på "
"spredningsdiagrammet over karakterene for prøve 1 mot karakterene for prøve "
"2, vist i :numref:`fig-pairedt` (midtre panel). I dette plottet tilsvarer "
"hver prikk de to karakterene for en gitt student. Hvis karakteren for prøve "
"1 (*x*-koordinat) er lik karakteren for prøve 2 (*y*-koordinat), faller "
"prikken på linjen. Punkter som faller over linjen, er de studentene som "
"presterte bedre på den andre prøven. Det kritiske er at nesten alle "
"datapunktene faller over den diagonale linjen: Nesten alle studentene *ser* "
"ut til å ha forbedret karakteren sin, om enn bare litt. Dette tyder på at vi "
"bør se på *forbedringen* hver enkelt student har gjort fra én prøve til den "
"neste, og behandle dette som rådata. For å gjøre dette må vi opprette en ny "
"variabel for ``improvement``, den forbedringen som hver student gjør, og "
"legge den til i datasettet |chico|_. Den enkleste måten å gjøre dette på er "
"å beregne en ny variabel med uttrykket ``grade_test2 - grade_test1``."

#: ../../Ch11/Ch11_tTest_05.rst:98
msgid ""
"Once we have computed this new ``improvement`` variable we can draw a "
"histogram showing the distribution of these improvement scores, shown in :"
"numref:`fig-pairedt` (right panel). When we look at the histogram, it’s very "
"clear that there *is* a real improvement here. The vast majority of the "
"students scored higher on test 2 than on test 1, reflected in the fact that "
"almost the entire histogram is above zero."
msgstr ""
"Når vi har beregnet denne nye variabelen ``improvement``, kan vi tegne et "
"histogram som viser fordelingen av disse forbedringsscorene, som vist i :"
"numref:`fig-pairedt` (høyre panel). Når vi ser på histogrammet, er det "
"veldig tydelig at det *er* en reell forbedring her. De aller fleste "
"studentene scoret høyere på test 2 enn på test 1, noe som gjenspeiles i at "
"nesten hele histogrammet ligger over null."

#: ../../Ch11/Ch11_tTest_05.rst:106
msgid "What is the paired samples *t*-test?"
msgstr "Hva er en paret *t*-test?"

#: ../../Ch11/Ch11_tTest_05.rst:108
msgid ""
"In light of the previous exploration, let’s think about how to construct an "
"appropriate *t*-test. One possibility would be to try to run an independent "
"samples *t*-test using ``grade_test1`` and ``grade_test2`` as the variables "
"of interest. However, this is clearly the wrong thing to do as the "
"independent samples *t*-test assumes that there is no particular "
"relationship between the two samples. Yet clearly that’s not true in this "
"case because of the repeated measures structure in the data. To use the "
"language that I introduced in the last section, if we were to try to do an "
"independent samples *t*-test, we would be conflating the **within subject** "
"differences (which is what we’re interested in testing) with the **between "
"subject** variability (which we are not)."
msgstr ""
"I lys av den foregående utforskningen, la oss tenke på hvordan vi kan sette "
"opp en passende *t*-test. En mulighet er å prøve å kjøre en uavhengig *t*-"
"test ved å bruke ``grade_test1`` og ``grade_test2`` som de aktuelle "
"variablene. Dette er imidlertid helt klart feil ting å gjøre, ettersom en "
"uavhengig *t*-test forutsetter at det ikke er noen sammenheng mellom de to "
"utvalgene. Men det er åpenbart ikke sant i dette tilfellet på grunn et "
"design med gjentatte målinger. For å bruke språket jeg introduserte i "
"forrige avsnitt: Hvis vi skulle forsøke å gjøre en uavhengig *t*-test, ville "
"vi blande sammen forskjellene **innenfor individet** (som er det vi er "
"interessert i å teste) med variabiliteten **mellom individene** (som vi ikke "
"er interessert i å teste)."

#: ../../Ch11/Ch11_tTest_05.rst:121
msgid ""
"The solution to the problem is obvious, I hope, since we already did all the "
"hard work in the previous section. Instead of running an independent samples "
"*t*-test on ``grade_test1`` and ``grade_test2``, we run a *one-sample* *t*-"
"test on the within-subject difference variable, ``improvement``. To "
"formalise this slightly, if *X*\\ :sub:`i1` is the score that the i-th "
"participant obtained on the first variable, and *X*\\ :sub:`i2` is the score "
"that the same person obtained on the second one, then the difference score "
"is:"
msgstr ""
"Løsningen på problemet er åpenbar, håper jeg, siden vi allerede har gjort "
"alt det harde arbeidet i forrige avsnitt. I stedet for å kjøre en uavhengig "
"*t*-test på ``grade_test1`` og ``grade_test2``, gjennomfører vi en *t*-test "
"for ett utvalg (*one sample*) på variabelen for forskjellen i resultatene "
"mellom testene, ``improvement``. For å formalisere dette litt, hvis *X*\\ :"
"sub:`i1` er poengsummen som den i-te deltakeren oppnådde på den første "
"variabelen, og *X*\\ :sub:`i2` er poengsummen som den samme personen "
"oppnådde på den andre variabelen, så er differansescoren:"

#: ../../Ch11/Ch11_tTest_05.rst:130
msgid "*D*\\ :sub:`i` = *X*\\ :sub:`i1` - *X*\\ :sub:`i2`}"
msgstr "*D*\\ :sub:`i` = *X*\\ :sub:`i1` - *X*\\ :sub:`i2`}"

#: ../../Ch11/Ch11_tTest_05.rst:132
msgid ""
"Notice that the difference scores is *variable 1 minus variable 2* and not "
"the other way around, so if we want improvement to correspond to a positive "
"valued difference, we actually want “test 2” to be our “variable 1”. "
"Equally, we would say that µ\\ :sub:`D` = µ\\ :sub:`1` - µ\\ :sub:`2` is the "
"population mean for this difference variable. So, to convert this to a "
"hypothesis test, our null hypothesis is that this mean difference is zero "
"and the alternative hypothesis is that it is not"
msgstr ""
"Legg merke til at differanseverdiene er *variabel 1 minus variabel 2* og "
"ikke omvendt, så hvis vi vil at forbedringen skal tilsvare en positivt "
"verdsatt differanse, vil vi faktisk at «test 2» skal være vår «variabel 1». "
"På samme måte vil vi si at µ\\ :sub:`D` = µ\\ :sub:`1` - µ\\ :sub:`2` er "
"populasjonsgjennomsnittet for denne differansevariabelen. For å konvertere "
"dette til en hypotesetest, er nullhypotesen vår at denne "
"gjennomsnittsforskjellen er null, og alternativhypotesen er at den ikke er "
"det"

#: ../../Ch11/Ch11_tTest_05.rst:140
msgid "H\\ :sub:`0`: µ\\ :sub:`D` = 0"
msgstr "H\\ :sub:`0`: µ\\ :sub:`D` = 0"

#: ../../Ch11/Ch11_tTest_05.rst:141
msgid "H\\ :sub:`2`: µ\\ :sub:`D` ≠ 0"
msgstr "H\\ :sub:`2`: µ\\ :sub:`D` ≠ 0"

#: ../../Ch11/Ch11_tTest_05.rst:143
msgid ""
"This is assuming we’re talking about a two-sided test here. This is more or "
"less identical to the way we described the hypotheses for the one-sample *t*-"
"test. The only difference is that the specific value that the null "
"hypothesis predicts is 0. And so our *t*-statistic is defined in more or "
"less the same way too. If we let D̄ denote the mean of the difference scores, "
"then"
msgstr ""
"Dette forutsetter at det er snakk om en tosidig test. Dette er mer eller "
"mindre identisk med måten vi beskrev hypotesene for *t*-test med ett utvalg. "
"Den eneste forskjellen er at den spesifikke verdien som nullhypotesen "
"predikerer, er 0. Og dermed er *t*-statistikken vår også definert på mer "
"eller mindre samme måte. Hvis vi lar D̄ betegne gjennomsnittet av "
"differansescorene, så"

#: ../../Ch11/Ch11_tTest_05.rst:149
msgid ""
"t = \\frac{\\bar{D}}{SE(\\bar{D})}\n"
"\n"
msgstr ""
"t = \\frac{\\bar{D}}{SE(\\bar{D})}\n"
"\n"

#: ../../Ch11/Ch11_tTest_05.rst:151
msgid "which is"
msgstr "som er"

#: ../../Ch11/Ch11_tTest_05.rst:153
msgid ""
"t = \\frac{\\bar{D}}{\\hat\\sigma_D / \\sqrt{N}}\n"
"\n"
msgstr ""
"t = \\frac{\\bar{D}}{\\hat\\sigma_D / \\sqrt{N}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_05.rst:155
msgid ""
"where :math:`\\hat\\sigma_D` is the standard deviation of the difference "
"scores. Since this is just an ordinary, one-sample *t*-test, with nothing "
"special about it, the degrees of freedom are still *N* - 1. And that’s it. "
"The paired samples *t*-test really isn’t a new test at all. It’s a one-"
"sample *t*-test, but applied to the difference between two variables. It’s "
"actually very simple. The only reason it merits a discussion as long as the "
"one we’ve just gone through is that you need to be able to recognise *when* "
"a paired samples test is appropriate, and to understand *why* it’s better "
"than an independent samples *t*-test."
msgstr ""
"hvor :math:`\\hat\\sigma_D` er standardavviket til differansescorene. Siden "
"dette bare er en vanlig *t*-test med ett utvalg, uten noe spesielt, er "
"frihetsgradene fortsatt *N* - 1. Og det er alt. Paret *t*-test er egentlig "
"ikke en ny test i det hele tatt. Det er en *t*-test med ett utvalg, men "
"anvendt på forskjellen mellom to variabler. Den er faktisk veldig enkel. Den "
"eneste grunnen til at den fortjener en så lang diskusjon som den vi nettopp "
"har gått gjennom, er at du må kunne gjenkjenne *når* en paret *t*-test er "
"hensiktsmessig, og forstå *hvorfor* den er bedre enn en uavhengig *t*-test."

#: ../../Ch11/Ch11_tTest_05.rst:168
msgid ""
"How do you do a paired samples *t*-test in jamovi? One possibility is to "
"follow the process I outlined above. That is, create a difference variable "
"and then run a one sample *t*-test on that. Since we’ve already created a "
"variable called ``improvement``, let’s do that and see what we get (see :"
"numref:`fig-ttest_paired2`\\)."
msgstr ""
"Hvordan gjør du en paret *t*-test i jamovi? En mulighet er å følge prosessen "
"jeg skisserte ovenfor. Det vil si å opprette en differansevariabel og "
"deretter kjøre en *t*-test med ett utvalg på den. Siden vi allerede har "
"opprettet en slik variabel som heter ``improvement``, la oss gjøre det og se "
"hva vi får (se :numref:`fig-ttest_paired2`\\)."

#: ../../Ch11/Ch11_tTest_05.rst:176 ../../Ch11/Ch11_tTest_05.rst:180
msgid "Results showing a one sample *t*-test on paired difference scores"
msgstr "Resultater fra en *t*-test på parvise forskjeller i poengsum"

#: ../../Ch11/Ch11_tTest_05.rst:184
msgid ""
"The output shown in :numref:`fig-ttest_paired2` is (obviously) formatted "
"exactly the same was as it was the last time we used the ``One Sample T-"
"Test`` analysis (section :doc:`Ch11_tTest_02`), and it confirms our "
"intuition. There’s an average improvement of 1.4\\% from test 1 to test 2, "
"and this is significantly different from 0 (*t*\\(19) = 6.48, *p* < 0.001)."
msgstr ""
"Resultatet som vises i :numref:`fig-ttest_paired2` er (selvsagt) formatert "
"på nøyaktig samme måte som forrige gang vi brukte ``One Sample T-Test``-"
"analysen (avsnitt :doc:`Ch11_tTest_02`), og det bekrefter intuisjonen vår. "
"Det er en gjennomsnittlig forbedring på 1,4\\% fra test 1 til test 2, og "
"dette er signifikant forskjellig fra 0 (*t*\\(19) = 6,48, *p* < 0,001)."

#: ../../Ch11/Ch11_tTest_05.rst:190
msgid ""
"However, suppose you’re lazy and you don’t want to go to all the effort of "
"creating a new variable. Or perhaps you just want to keep the difference "
"between one-sample and paired-samples tests clear in your head. If so, you "
"can use the jamovi ``Paired Samples T-Test`` analysis, getting the results "
"shown in :numref:`fig-ttest_paired3`."
msgstr ""
"Men tenk om du er lat og ikke ønsker å ta deg bryet med å opprette en ny "
"variabel. Eller kanskje du bare ønsker å holde forskjellen mellom *t*-tester "
"med ett utvalg og paret *t*-test klar i hodet. I så fall kan du bruke jamovi "
"``Paired Samples T-Test``-analysen, og få resultatene som vises i :numref:"
"`fig-ttest_paired3`."

#: ../../Ch11/Ch11_tTest_05.rst:198
msgid "Results showing a paired sample *t*-test"
msgstr "Resultater fra en parvis *t*-test"

#: ../../Ch11/Ch11_tTest_05.rst:202
msgid ""
"Results showing a paired sample *t*-test. Compare it with :numref:`fig-"
"ttest_paired2`."
msgstr ""
"Resultater som viser en parvis *t*-test. Sammenlign det med :numref:`fig-"
"ttest_paired2`."

#: ../../Ch11/Ch11_tTest_05.rst:207
msgid ""
"The numbers are identical to those that come from the one sample test, which "
"of course they have to be given that the paired samples *t*-test is just a "
"one sample test under the hood."
msgstr ""
"Tallene er identiske med dem som kommer fra *t*-test med ett utvalg, noe de "
"selvfølgelig må være, siden paret *t*-test i bunn og grunn bare er en *t*-"
"test med ett utvalg."

#: ../../Ch11/Ch11_tTest_05.rst:214
msgid ""
"This design is very similar to the one in section :doc:`../Ch10/"
"Ch10_ChiSquare_7` that motivated the McNemar test. This should be no "
"surprise. Both are standard repeated measures designs involving two "
"measurements. The only difference is that this time our outcome variable is "
"interval scale (working memory capacity, |continuous|) rather than a binary "
"scale variable (a yes-or-no question, |nominal|)."
msgstr ""
"Dette designet er svært likt det som ligger til grunn for McNemar-testen i "
"avsnitt :doc:`../Ch10/Ch10_ChiSquare_7`. Dette burde ikke være noen "
"overraskelse. Begge er standard gjentatte målinger med to målinger. Den "
"eneste forskjellen er at utfallsvariabelen vår denne gangen er en "
"intervallvariabel (arbeidshukommelseskapasitet, |continuous|) i stedet for "
"en binær skalavariabel (et ja-eller-nei-spørsmål, |nominal|)."

#: ../../Ch11/Ch11_tTest_05.rst:222
msgid ""
"At this point we have Drs Harpo, Chico and Zeppo. No prizes for guessing who "
"Dr Groucho is."
msgstr ""
"Nå har vi dr. Harpo, Chico og Zeppo. Ingen premie for å gjette hvem dr. "
"Groucho er."

#: ../../Ch11/Ch11_tTest_06.rst:4
msgid "One-sided tests"
msgstr "Ensidige tester"

#: ../../Ch11/Ch11_tTest_06.rst:6
msgid ""
"When introducing the theory of null hypothesis tests, I mentioned that there "
"are some situations when it’s appropriate to specify a *one-sided* test (see "
"section :ref:`The difference between one-sided and two-sided tests "
"<one_vs_twosided_tests>`). So far all of the *t*-tests have been two-sided "
"tests. For instance, when we specified a one sample *t*-test for the grades "
"in Dr Zeppo’s class the null hypothesis was that the true mean was 67.5\\%. "
"The alternative hypothesis was that the true mean was greater than *or* less "
"than 67.5\\%. Suppose we were only interested in finding out if the true "
"mean is greater than 67.5\\%, and have no interest whatsoever in testing to "
"find out if the true mean is lower than \\67.5\\%. If so, our null "
"hypothesis would be that the true mean is 67.5\\% or less, and the "
"alternative hypothesis would be that the true mean is greater than 67.5\\%. "
"In jamovi, for the ``One Sample T-Test`` analysis, you can specify this by "
"clicking on the ``> Test Value`` option, under ``Hypothesis``. When you have "
"done this, you will get the results as shown in :numref:`fig-"
"ttest_onesided1`."
msgstr ""
"Da jeg introduserte teorien om nullhypotesetester, nevnte jeg at det finnes "
"situasjoner der det er hensiktsmessig å spesifisere en *ensidig* test (se "
"avsnitt :ref:`Forskjellen mellom ensidige og tosidige tester "
"<one_vs_twosided_tests>`). Så langt har alle *t*-testene vært tosidige "
"tester. Da vi for eksempel spesifiserte en *t*-test med ett utvalg for "
"karakterene i Dr. Zeppos klasse, var nullhypotesen at det sanne "
"gjennomsnittet var 67,5\\%. Alternativhypotesen var at det sanne "
"gjennomsnittet var større enn *eller* mindre enn 67,5\\%. Anta at vi bare er "
"interessert i å finne ut om det sanne gjennomsnittet er større enn 67,5\\%, "
"og ikke har noen som helst interesse av å teste om det sanne gjennomsnittet "
"er lavere enn \\67,5\\%. I så fall vil nullhypotesen vår være at det sanne "
"gjennomsnittet er 67,5\\% eller mindre, og alternativhypotesen vil være at "
"det sanne gjennomsnittet er større enn 67,5\\%. I jamovi kan du spesifisere "
"dette for analysen ``One Sample T-Test`` ved å klikke på alternativet ``> "
"Test Value`` under ``Hypothesis``. Når du har gjort dette, vil du få "
"resultatene som vist i :numref:`fig-ttest_onesided1`."

#: ../../Ch11/Ch11_tTest_06.rst:24
msgid "jamovi results showing a ``One Sample T-Test``"
msgstr "jamovi-resultater som viser en ``One Sample T-Test``"

#: ../../Ch11/Ch11_tTest_06.rst:28
msgid ""
"jamovi results showing a ``One Sample T-Test`` where the actual hypothesis "
"is one-sided, i.e. that the true mean is greater than 67.5\\%."
msgstr ""
"jamovi-resultatene viser en ``One Sample T-Test`` der den faktiske hypotesen "
"er ensidig, dvs. at det sanne gjennomsnittet er større enn 67,5\\%."

#: ../../Ch11/Ch11_tTest_06.rst:33
msgid ""
"Notice that there are a few changes from the output that we saw last time. "
"Most important is the fact that the actual hypothesis has changed, to "
"reflect the different test. The second thing to note is that although the "
"*t*-statistic and degrees of freedom have not changed, the *p*-value has. "
"This is because the one-sided test has a different rejection region from the "
"two-sided test. If you’ve forgotten why this is and what it means, you may "
"find it helpful to read back over chapter :doc:`../Ch09/"
"Ch09_HypothesisTesting`, and section :ref:`The difference between one-sided "
"and two-sided tests <one_vs_twosided_tests>` in particular. The third thing "
"to note is that the confidence interval is different too: it now reports a "
"“one-sided” confidence interval rather than a two-sided one. In a two-sided "
"confidence interval we’re trying to find numbers *a* and *b* such that we’re "
"confident that, if we were to repeat the study many times, then 95\\% of the "
"time the mean would lie *between* *a* and *b*. In a one-sided confidence "
"interval, we’re trying to find a single number *a* such that we’re confident "
"that 95\\% of the time the true mean would be *greater than* *a* (or less "
"than *a* if you selected ``Measure 1 < Measure 2`` in the ``Hypothesis`` "
"section)."
msgstr ""
"Legg merke til at det er noen få endringer i forhold til forrige gang. Den "
"viktigste er at den faktiske hypotesen har endret seg for å gjenspeile den "
"nye testen. Den andre tingen å merke seg er at selv om *t*-statistikken og "
"frihetsgradene ikke har endret seg, har *p*-verdien gjort det. Dette skyldes "
"at den ensidige testen har en annen forkastningsregion enn den tosidige "
"testen. Hvis du har glemt hvorfor dette er slik og hva det betyr, kan det "
"være nyttig å lese kapittel :doc:`../Ch09/Ch09_HypothesisTesting`, og "
"spesielt avsnitt :ref:`Forskjellen mellom ensidige og tosidige tester "
"<one_vs_twosided_tests>`. Den tredje tingen å merke seg er at "
"konfidensintervallet også er annerledes: Det rapporterer nå et «ensidig» "
"konfidensintervall i stedet for et tosidig. I et tosidig konfidensintervall "
"prøver vi å finne tallene *a* og *b* slik at vi er sikre på at hvis vi "
"gjentar studien mange ganger, vil gjennomsnittet i 95\\% av tilfellene ligge "
"*mellom* *a* og *b*. I et ensidig konfidensintervall prøver vi å finne ett "
"enkelt tall *a* slik at vi er sikre på at det sanne gjennomsnittet i 95\\% "
"av tilfellene vil være *større enn* *a* (eller mindre enn *a* hvis du valgte "
"``Measure 1 < Measure 2`` i avsnitt ``Hypothesis``)."

#: ../../Ch11/Ch11_tTest_06.rst:51
msgid ""
"So that’s how to do a one-sided one sample *t*-test. However, all versions "
"of the *t*-test can be one-sided. For an independent samples *t*-test, you "
"could have a one-sided test if you’re only interested in testing to see if "
"group A has *higher* scores than group B, but have no interest in finding "
"out if group B has higher scores than group A. Let’s suppose that, for Dr "
"Harpo’s class, you wanted to see if Anastasia’s students had higher grades "
"than Bernadette’s. For this analysis, in the ``Hypothesis`` options, specify "
"that ``Group 1 > Group 2``. You should get the results shown in :numref:`fig-"
"ttest_onesided2`."
msgstr ""
"Slik gjør du en ensidig *t*-test med ett utvalg. Alle versjoner av *t*-"
"testen kan imidlertid være ensidige. For en uavhengig *t*-test kan du ha en "
"ensidig test hvis du bare er interessert i å teste om gruppe A har *høyere* "
"poengsum enn gruppe B, men ikke er interessert i å finne ut om gruppe B har "
"høyere poengsum enn gruppe A. La oss anta at du, for Dr. Harpos klasse, "
"ønsket å se om Anastasias studenter hadde høyere karakterer enn Bernadettes. "
"For denne analysen angir du i ``Hypothesis``-opsjonene at ``Group 1 > Group "
"2``. Du bør få resultatene som vises i :numref:`fig-ttest_onesided2`."

#: ../../Ch11/Ch11_tTest_06.rst:63
msgid "One-sided hypothesis in an ``Independent Samples T-Test``"
msgstr "Ensidig hypotese i en ``Independent Samples T-Test``"

#: ../../Ch11/Ch11_tTest_06.rst:67
msgid ""
"jamovi results showing an ``Independent Samples T-Test`` where the actual "
"hypothesis is one-sided, i.e. that Anastasia’s students had higher grades "
"than Bernadette’s."
msgstr ""
"jamovi viser resultater fra en ``Independent Samples T-Test`` der den "
"egentlige hypotesen er ensidig, dvs. at Anastasias studenter hadde høyere "
"karakterer enn Bernadettes."

#: ../../Ch11/Ch11_tTest_06.rst:73
msgid ""
"Again, the output changes in a predictable way. The definition of the "
"alternative hypothesis has changed, the *p*-value has changed, and it now "
"reports a one-sided confidence interval rather than a two-sided one."
msgstr ""
"Igjen endres resultatet på en forutsigbar måte. Definisjonen av "
"alternativhypotesen er endret, *p*-verdien er endret, og den rapporterer nå "
"et ensidig konfidensintervall i stedet for et tosidig."

#: ../../Ch11/Ch11_tTest_06.rst:78
msgid ""
"What about the paired samples *t*-test? Suppose we wanted to test the "
"hypothesis that grades go *up* from test 1 to test 2 in Dr Zeppo’s class, "
"and are not prepared to consider the idea that the grades go down. In jamovi "
"you would do this by specifying, under the ``Hypotheses`` option, that "
"``grade_test2`` (``Measure 1`` in jamovi, because we copied this first into "
"the paired variables box) > ``grade_test1`` (``Measure 2`` in jamovi). You "
"should get the results shown in :numref:`fig-ttest_onesided3`."
msgstr ""
"Hva med paret *t*-test? Anta at vi ønsker å teste hypotesen om at "
"karakterene går *opp* fra test 1 til test 2 i Dr. Zeppos klasse, og at vi "
"ikke er villige til å vurdere ideen om at karakterene går ned. I jamovi gjør "
"du dette ved å spesifisere, under alternativet ``Hypotheses``, at "
"``grade_test2`` (``Measure 1`` i jamovi, fordi vi kopierte denne først inn i "
"boksen for parede variabler) > ``grade_test1`` (``Measure 2`` i jamovi). Du "
"bør få resultatene som vises i :numref:`fig-ttest_onesided3`."

#: ../../Ch11/Ch11_tTest_06.rst:89
msgid "One-sided hypothesis in an ``Paired Samples T-Test``"
msgstr "Ensidig hypotese i en ``Paired Samples T-Test``"

#: ../../Ch11/Ch11_tTest_06.rst:93
msgid ""
"jamovi results showing a ``Paired Samples T-Test`` where the actual "
"hypothesis is one-sided, i.e. that ``grade_test2`` (``Measure 1``) is larger "
"than ``grade_test1`` (``Measure 2``)."
msgstr ""
"jamovi-resultater som viser en ``Paired Samples T-Test`` der den faktiske "
"hypotesen er ensidig, dvs. at ``grade_test2`` (``Measure 1``) er større enn "
"``grade_test1`` (``Measure 2``)."

#: ../../Ch11/Ch11_tTest_06.rst:99
msgid ""
"Yet again, the output changes in a predictable way. The hypothesis has "
"changed, the *p*-value has changed, and the confidence interval is now one-"
"sided."
msgstr ""
"Nok en gang endres resultatet på en forutsigbar måte. Hypotesen er endret, "
"*p*-verdien er endret, og konfidensintervallet er nå ensidig."

#: ../../Ch11/Ch11_tTest_07.rst:4
msgid "Effect size"
msgstr "Effektstørrelse"

#: ../../Ch11/Ch11_tTest_07.rst:6
msgid ""
"The most commonly used measure of effect size for a *t*-test is **Cohen’s "
"d** (:ref:`Cohen, 1988 <Cohen_1988>`). It’s a very simple measure in "
"principle, with quite a few wrinkles when you start digging into the "
"details. Cohen himself defined it primarily in the context of an independent "
"samples *t*-test, specifically the Student test. In that context, a natural "
"way of defining the effect size is to divide the difference between the "
"means by an estimate of the standard deviation. In other words, we’re "
"looking to calculate *something* along the lines of this:"
msgstr ""
"Det mest brukte effektstørrelsesmålet for en *t*-test er **Cohen's d** (:ref:"
"`Cohen, 1988 <Cohen_1988>`). Det er i prinsippet et veldig enkelt mål, men "
"når man begynner å grave seg ned i detaljene, får man en del problemer. "
"Cohen selv definerte det først og fremst i forbindelse med en uavhengig *t*-"
"test, nærmere bestemt Students *t*-test. I den sammenhengen er en naturlig "
"måte å definere effektstørrelsen på å dividere forskjellen mellom "
"gjennomsnittene med et estimat av standardavviket. Med andre ord er vi ute "
"etter å beregne *noe* i retning av dette:"

#: ../../Ch11/Ch11_tTest_07.rst:15
msgid "d = (mean 1 - mean 2) / std. dev."
msgstr "d = (gjennomsnitt 1 - gjennomsnitt 2) / std. dev."

#: ../../Ch11/Ch11_tTest_07.rst:17
msgid ""
"and he suggested a rough guide for interpreting *d* in :numref:`tab-"
"cohensdinterpretation`. You’d think that this would be pretty unambiguous, "
"but it’s not. This is largely because Cohen wasn’t too specific on what he "
"thought should be used as the measure of the standard deviation (in his "
"defence he was trying to make a broader point in his book, not nitpick about "
"tiny details). As discussed by :ref:`McGrath and Meyer (2006) "
"<McGrath_2006>`, there are several different versions in common usage, and "
"each author tends to adopt slightly different notation. For the sake of "
"simplicity (as opposed to accuracy), I’ll use *d* to refer to any statistic "
"that you calculate from the sample, and use δ to refer to a theoretical "
"population effect. Obviously, that does mean that there are several "
"different things all called *d*."
msgstr ""
"og han foreslo en grov guide for tolkning av *d* i :numref:`tab-"
"cohensdinterpretation`. Man skulle tro at dette ville være ganske entydig, "
"men det er det ikke. Dette skyldes i stor grad at Cohen ikke var så "
"spesifikk med hensyn til hva han mente burde brukes som mål på "
"standardavviket (til hans forsvar må det sies at han prøvde å få frem et "
"bredere poeng i boken sin, ikke å pirke i små detaljer). Som diskutert i :"
"ref:`McGrath and Meyer (2006) <McGrath_2006>`, finnes det flere ulike "
"versjoner som er i vanlig bruk, og hver forfatter har en tendens til å bruke "
"litt ulik notasjon. For enkelhets skyld (i motsetning til nøyaktighet) vil "
"jeg bruke *d* for å referere til enhver statistikk som du beregner fra "
"utvalget, og bruke δ for å referere til en teoretisk populasjonseffekt. Det "
"betyr selvsagt at det finnes flere forskjellige ting som alle kalles *d*."

#: ../../Ch11/Ch11_tTest_07.rst:30
msgid ""
"My suspicion is that the only time that you would want Cohen’s *d* is when "
"you’re running a *t*-test, and jamovi has an option to calculate the effect "
"size for all the different flavours of *t*-test it provides."
msgstr ""
"Jeg mistenker at den eneste gangen du vil ha Cohens *d*, er når du kjører en "
"*t*-test, og jamovi har et alternativ for å beregne effektstørrelsen for "
"alle de ulike variantene av *t*-tester som tilbys."

#: ../../Ch11/Ch11_tTest_07.rst:34
msgid ""
"A (very) rough guide to interpreting Cohen’s *d*. My personal recommendation "
"is to not use these blindly. The *d*-statistic has a natural interpretation "
"in and of itself. It re-describes the difference in means as the number of "
"standard deviations that separates those means. So it’s generally a good "
"idea to think about what that means in practical terms. In some contexts a "
"“small” effect could be of big practical importance. In other situations a "
"“large” effect may not be all that interesting."
msgstr ""
"En (veldig) grov guide til tolkning av Cohens *d*. Min personlige anbefaling "
"er å ikke bruke disse blindt. *d*-statistikken har en naturlig tolkning i "
"seg selv. Den beskriver forskjellen i gjennomsnitt som antall standardavvik "
"som skiller disse gjennomsnittene. Derfor er det som regel lurt å tenke over "
"hva det betyr i praksis. I noen sammenhenger kan en «liten» effekt være av "
"stor praktisk betydning. I andre situasjoner er en «stor» effekt kanskje "
"ikke så interessant."

#: ../../Ch11/Ch11_tTest_07.rst:45
msgid "*d*-value"
msgstr "*d*-verdi"

#: ../../Ch11/Ch11_tTest_07.rst:45
msgid "rough interpretation"
msgstr "grov tolkning"

#: ../../Ch11/Ch11_tTest_07.rst:47
msgid "about 0.2"
msgstr "omtrent 0,2"

#: ../../Ch11/Ch11_tTest_07.rst:47
msgid "“small” effect"
msgstr "«liten» effekt"

#: ../../Ch11/Ch11_tTest_07.rst:49
msgid "about 0.5"
msgstr "omtrent 0,5"

#: ../../Ch11/Ch11_tTest_07.rst:49
msgid "“moderate” effect"
msgstr "«moderat» effekt"

#: ../../Ch11/Ch11_tTest_07.rst:51
msgid "about 0.8"
msgstr "omtrent 0,8"

#: ../../Ch11/Ch11_tTest_07.rst:51
msgid "“large” effect"
msgstr "«stor» effekt"

#: ../../Ch11/Ch11_tTest_07.rst:55
msgid "Cohen’s *d* from one sample"
msgstr "Cohens *d* fra ett utvalg"

#: ../../Ch11/Ch11_tTest_07.rst:57
msgid ""
"The simplest situation to consider is the one corresponding to a one-sample "
"*t*-test. In this case, this is the one sample mean *X̄* and one "
"(hypothesised) population mean µ\\ :sub:`o` to compare it to. Not only that, "
"there’s really only one sensible way to estimate the population standard "
"deviation. We just use our usual estimate :math:`\\hat{\\sigma}`. Therefore, "
"we end up with the following as the only way to calculate d:"
msgstr ""
"Den enkleste situasjonen å vurdere er den som tilsvarer en *t*-test med ett "
"utvalg. I dette tilfellet er det ett utvalgsgjennomsnitt *X̄* og ett (antatt) "
"populasjonsgjennomsnitt µ\\ :sub:`o` å sammenligne det med. Ikke bare det, "
"det finnes egentlig bare én fornuftig måte å estimere standardavviket i "
"populasjonen på. Vi bruker bare vårt vanlige estimat :math:`\\hat{\\sigma}`. "
"Derfor ender vi opp med følgende som den eneste måten å beregne d på:"

#: ../../Ch11/Ch11_tTest_07.rst:64
msgid ""
"d = \\frac{\\bar{X} - \\mu_0}{\\hat{\\sigma}}\n"
"\n"
msgstr ""
"d = \\frac{\\bar{X} - \\mu_0}{\\hat{\\sigma}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_07.rst:66
msgid ""
"When we look back at the results in :numref:`fig-ttest_one`, the effect size "
"value is Cohen’s *d* = 0.50. Overall, then, the psychology students in Dr "
"Zeppo’s class are achieving grades (mean = 72.3\\%) that are about 0.5 "
"standard deviations higher than the level that you’d expect (67.5\\%) if "
"they were performing at the same level as other students. Judged against "
"Cohen’s rough guide, this is a moderate effect size."
msgstr ""
"Når vi ser tilbake på resultatene i :numref:`fig-ttest_one`, er "
"effektstørrelsesverdien Cohens *d* = 0,50. Samlet sett oppnår altså "
"psykologistudentene i Dr. Zeppos klasse karakterer (gjennomsnitt = 72,3\\%) "
"som er omtrent 0,5 standardavvik høyere enn det nivået du ville forvente "
"(67,5\\%) hvis de presterte på samme nivå som andre studenter. Dette er en "
"moderat effektstørrelse, vurdert ut fra Cohens veiledning."

#: ../../Ch11/Ch11_tTest_07.rst:74
msgid "Cohen’s *d* from a Student’s *t*-test"
msgstr "Cohens *d* fra en Student's *t*-test"

#: ../../Ch11/Ch11_tTest_07.rst:76
msgid ""
"The majority of discussions of Cohen’s *d* focus on a situation that is "
"analogous to Student’s independent samples *t*-test, and it’s in this "
"context that the story becomes messier, since there are several different "
"versions of *d* that you might want to use in this situation. To understand "
"why there are multiple versions of *d*, it helps to take the time to write "
"down a formula that corresponds to the true population effect size δ. It’s "
"pretty straightforward, δ = (µ\\ :sub:`1` - µ\\ :sub:`2`) / σ."
msgstr ""
"De fleste diskusjoner om Cohens *d* fokuserer på en situasjon som er analog "
"med Students uavhengig *t*-test, og det er i denne sammenhengen at historien "
"blir mer rotete, siden det finnes flere ulike versjoner av *d* som du kan "
"ønske å bruke i denne situasjonen. For å forstå hvorfor det finnes flere "
"versjoner av *d*, er det nyttig å ta seg tid til å skrive ned en formel som "
"tilsvarer den sanne populasjonseffektstørrelsen δ. Det er ganske enkelt, δ = "
"(µ\\ :sub:`1` - µ\\ :sub:`2`) / σ."

#: ../../Ch11/Ch11_tTest_07.rst:84
msgid ""
"where, as usual, µ\\ :sub:`1` and µ\\ :sub:`2` are the population means "
"corresponding to group 1 and group 2 respectively, and σ is the standard "
"deviation (the same for both populations). The obvious way to estimate δ is "
"to do exactly the same thing that we did in the *t*-test itself, i.e., use "
"the sample means as the top line and a pooled standard deviation estimate "
"for the bottom line"
msgstr ""
"hvor, som vanlig, µ\\ :sub:`1` og µ\\ :sub:`2` er populasjonsgjennomsnittene "
"for henholdsvis gruppe 1 og gruppe 2, og σ er standardavviket (det samme for "
"begge populasjonene). Den åpenbare måten å estimere δ på er å gjøre akkurat "
"det samme som vi gjorde i selve *t*-testen, dvs. bruke "
"utvalgsgjennomsnittene som øverste linje og et sammenslått "
"standardavviksestimat som nederste linje"

#: ../../Ch11/Ch11_tTest_07.rst:92
msgid ""
"d = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\hat{\\sigma}_p}\n"
"\n"
msgstr ""
"d = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\hat{\\sigma}_p}\n"
"\n"

#: ../../Ch11/Ch11_tTest_07.rst:94
msgid ""
"where :math:`\\hat\\sigma_p` is the exact same pooled standard deviation "
"measure that appears in the *t*-test. This is the most commonly used version "
"of Cohen’s *d* when applied to the outcome of a Student *t*-test, and is the "
"one provided in jamovi. It is sometimes referred to as Hedges’ *g* statistic "
"(:ref:`Hedges, 1981 <Hedges_1981>`)."
msgstr ""
"hvor :math:`\\hat\\sigma_p` er nøyaktig det samme standardavviksmålet som "
"vises i *t*-testen. Dette er den mest brukte versjonen av Cohens *d* når den "
"brukes på utfallet av en Student *t*-test, og det er den som leveres i "
"jamovi. Den omtales noen ganger som Hedges' *g*-statistikk (:ref:`Hedges, "
"1981 <Hedges_1981>`)."

#: ../../Ch11/Ch11_tTest_07.rst:100
msgid ""
"However, there are other possibilities which I’ll briefly describe. Firstly, "
"you may have reason to want to use only one of the two groups as the basis "
"for calculating the standard deviation. This approach (often called Glass’ "
"*Δ*, pronounced *delta*) only makes most sense when you have good reason to "
"treat one of the two groups as a purer reflection of “natural variation” "
"than the other. This can happen if, for instance, one of the two groups is a "
"control group. Secondly, recall that in the usual calculation of the pooled "
"standard deviation we divide by *N* - 2 to correct for the bias in the "
"sample variance. In one version of Cohen’s *d* this correction is omitted, "
"and instead we divide by *N*. This version makes sense primarily when you’re "
"trying to calculate the effect size in the sample rather than estimating an "
"effect size in the population. Finally, there is a version based on :ref:"
"`Hedges and Olkin (1985) <Hedges_1985>`, who point out there is a small bias "
"in the usual (pooled) estimation for Cohen’s *d*. Thus they introduce a "
"small correction by multiplying the usual value of *d* by (*N* - 3) / (*N* "
"-2.25)."
msgstr ""
"Det finnes imidlertid andre muligheter som jeg kort vil beskrive. For det "
"første kan det være grunn til å ønske å bruke bare én av de to gruppene som "
"grunnlag for beregning av standardavviket. Denne tilnærmingen (ofte kalt "
"Glass' *Δ*, uttales *delta*) gir mest mening når man har god grunn til å "
"betrakte den ene av de to gruppene som en renere avspeiling av «naturlig "
"variasjon» enn den andre. Dette kan for eksempel skje hvis en av de to "
"gruppene er en kontrollgruppe. For det andre må du huske at i den vanlige "
"beregningen av det sammenslåtte standardavviket dividerer vi med *N* - 2 for "
"å korrigere for skjevheten i utvalgsvariansen. I en versjon av Cohens *d* "
"utelates denne korreksjonen, og i stedet dividerer vi med *N*. Denne "
"versjonen gir først og fremst mening når du prøver å beregne "
"effektstørrelsen i utvalget i stedet for å estimere en effektstørrelse i "
"populasjonen. Endelig finnes det en versjon basert på :ref:`Hedges og Olkin "
"(1985) <Hedges_1985>`, som påpeker at det er en liten skjevhet i den vanlige "
"(sammenslåtte) estimeringen for Cohens *d*. De innfører derfor en liten "
"korreksjon ved å multiplisere den vanlige verdien av *d* med (*N* - 3) / "
"(*N* -2,25)."

#: ../../Ch11/Ch11_tTest_07.rst:117
msgid ""
"In any case, ignoring all those variations that you could make use of if you "
"wanted, let’s have a look at the default version in jamovi. In :numref:`fig-"
"ttest_ind` Cohen’s *d* = 0.74, indicating that the grade scores for students "
"in Anastasia’s class are, on average, 0.74 standard deviations higher than "
"the grade scores for students in Bernadette’s class. For a Welch-test, the "
"estimated effect size is the same (:numref:`fig-ttest_welch`)."
msgstr ""
"Uansett, la oss se på standardversjonen i jamovi, og se bort fra alle disse "
"variasjonene som du kan benytte deg av hvis du vil. I :numref:`fig-"
"ttest_ind` er Cohens *d* = 0,74, noe som indikerer at karakterresultatene "
"for studentene i Anastasias klasse i gjennomsnitt er 0,74 standardavvik "
"høyere enn karakterresultatene for studentene i Bernadettes klasse. For en "
"Welch-test er den estimerte effektstørrelsen den samme (:numref:`fig-"
"ttest_welch`)."

#: ../../Ch11/Ch11_tTest_07.rst:125
msgid "Cohen’s *d* from a paired-samples test"
msgstr "Cohens *d* fra en paret *t*-test"

#: ../../Ch11/Ch11_tTest_07.rst:127
msgid ""
"Finally, what should we do for a paired samples *t*-test? In this case, the "
"answer depends on what it is you’re trying to do. jamovi assumes that you "
"want to measure your effect sizes relative to the distribution of difference "
"scores, and the measure of *d* that you calculate is:"
msgstr ""
"Til slutt, hva bør vi gjøre for en paret *t*-test? I dette tilfellet "
"avhenger svaret av hva du prøver å gjøre. jamovi antar at du ønsker å måle "
"effektstørrelsene dine i forhold til fordelingen av differanseskårer, og "
"målet på *d* som du beregner, er:"

#: ../../Ch11/Ch11_tTest_07.rst:133
msgid ""
"d = \\frac{\\bar{D}}{\\hat{\\sigma}_D}\n"
"\n"
msgstr ""
"d = \\frac{\\bar{D}}{\\hat{\\sigma}_D}\n"
"\n"

#: ../../Ch11/Ch11_tTest_07.rst:135
msgid ""
"where :math:`\\hat{\\sigma}_D` is the estimate of the standard deviation of "
"the differences. In :numref:`fig-ttest_paired3` Cohen’s *d* = 1.45, "
"indicating that the time 2 grade scores are, on average, 1.45 standard "
"deviations higher than the time 1 grade scores."
msgstr ""
"hvor :math:`\\hat{\\sigma}_D` er estimatet av standardavviket til "
"forskjellene. I :numref:`fig-ttest_paired3` er Cohens *d* = 1,45, noe som "
"indikerer at skårene for tid 2 i gjennomsnitt er 1,45 standardavvik høyere "
"enn skårene for tid 1."

#: ../../Ch11/Ch11_tTest_07.rst:140
msgid ""
"This is the version of Cohen’s *d* that gets reported by the jamovi ``Paired "
"Samples T-Test`` analysis. The only wrinkle is figuring out whether this is "
"the measure you want or not. To the extent that you care about the practical "
"consequences of your research, you often want to measure the effect size "
"relative to the *original* variables, not the *difference* scores (e.g., the "
"1\\% improvement in Dr Chico’s class over time is pretty small when measured "
"against the amount of between-student variation in grades), in which case "
"you use the same versions of Cohen’s *d* that you would use for a Student or "
"Welch test. It’s not so straightforward to do this in jamovi; essentially "
"you have to change the structure of the data in the spreadsheet view so I "
"won’t go into that here,\\ [#]_ but the Cohen’s *d* for this perspective is "
"quite different: it is 0.22 which is quite small when assessed on the scale "
"of the original variables."
msgstr ""
"Dette er den versjonen av Cohens *d* som blir rapportert av jamovi ``Paired "
"Samples T-Test``-analysen. Det eneste problemet er å finne ut om dette er "
"det målet du ønsker eller ikke. I den grad du bryr deg om de praktiske "
"konsekvensene av forskningen din, ønsker du ofte å måle effektstørrelsen i "
"forhold til de *originale* variablene, ikke *forskjellen* (f.eks. er "
"forbedringen på 1\\% i Dr. Chicos klasse over tid ganske liten når den måles "
"opp mot variasjonen i karakterer mellom studentene), og i så fall bruker du "
"de samme versjonene av Cohens *d* som du ville brukt for en Students eller "
"Welchs *t*-test. Det er ikke så enkelt å gjøre dette i jamovi; du må i "
"hovedsak endre datastrukturen i regnearkvisningen, så det vil jeg ikke gå "
"inn på her, \\ [#]_ men Cohens *d* for dette perspektivet er ganske "
"annerledes: den er 0,22, noe som er ganske lite sett i forhold til skalaen "
"til de opprinnelige variablene."

#: ../../Ch11/Ch11_tTest_07.rst:158
msgid ""
"If you are interested, you can look at how this was done in the |chico2|_ "
"dataset"
msgstr ""
"Hvis du er interessert, kan du se hvordan dette ble gjort i datasettet |"
"chico2|_"

#: ../../Ch11/Ch11_tTest_08.rst:4
msgid "Checking the normality of a sample"
msgstr "Sjekk forutsetningen om normalfordeling for en stikkprøve"

#: ../../Ch11/Ch11_tTest_08.rst:6
msgid ""
"All of the tests that we have discussed so far in this chapter have assumed "
"that the data are normally distributed. This assumption is often quite "
"reasonable, because :ref:`the central limit theorem <central_limit_theorem>` "
"does tend to ensure that many real world quantities are normally "
"distributed. Any time that you suspect that your variable is *actually* an "
"average of lots of different things, there’s a pretty good chance that it "
"will be normally distributed, or at least close enough to normal that you "
"can get away with using *t*-tests. However, life doesn’t come with "
"guarantees, and besides there are lots of ways in which you can end up with "
"variables that are highly non-normal. For example, any time you think that "
"your variable is actually the minimum of lots of different things, there’s a "
"very good chance it will end up quite skewed. In psychology, response time "
"(RT) data is a good example of this. If you suppose that there are lots of "
"things that could trigger a response from a human participant, then the "
"actual response will occur the first time one of these trigger events occurs."
"\\ [#]_ This means that RT data are systematically non-normal. Okay, so if "
"normality is assumed by all the tests, and is mostly but not always "
"satisfied (at least approximately) by real world data, how can we check the "
"normality of a sample? In this section I discuss two methods: QQ plots and "
"the Shapiro-Wilk test."
msgstr ""
"Alle testene vi har diskutert så langt i dette kapitlet, har forutsatt at "
"dataene er normalfordelte. Denne antakelsen er ofte ganske rimelig, fordi :"
"ref:`det sentrale grenseteoremet <central_limit_theorem>` har en tendens til "
"å sikre at mange størrelser i den virkelige verden er normalfordelte. Hver "
"gang du mistenker at variabelen din *faktisk* er et gjennomsnitt av mange "
"forskjellige ting, er det en ganske god sjanse for at den vil være "
"normalfordelt, eller i det minste nær nok normal til at du kan slippe unna "
"med å bruke *t*-tester. Men livet kommer ikke med garantier, og dessuten er "
"det mange måter du kan ende opp med variabler som er svært avvikende fra en "
"normalfordeling. Hvis du for eksempel tror at variabelen din faktisk er et "
"minimum av mange forskjellige ting, er det stor sjanse for at den ender opp "
"med å bli ganske skjev. I psykologien er data om responstid (RT) et godt "
"eksempel på dette. Hvis du antar at det er mange ting som kan utløse en "
"respons fra en menneskelig deltaker, vil den faktiske responsen inntreffe "
"første gang en av disse utløsende hendelsene inntreffer.\\ [#]_ Dette betyr "
"at RT-dataene er systematisk avvikende fra en normalfordeling. Ok, så hvis "
"det forutsettes en normalfordeling i alle testene, og for det meste, men "
"ikke alltid, oppfylles (i det minste tilnærmet) av data fra den virkelige "
"verden, hvordan kan vi da sjekke forutsetningen om normalfordeling for en "
"stikkprøve? I denne delen diskuterer jeg to metoder: QQ-plott og Shapiro-"
"Wilk-testen."

#: ../../Ch11/Ch11_tTest_08.rst:27
msgid "QQ plots"
msgstr "QQ-plott"

#: ../../Ch11/Ch11_tTest_08.rst:31
msgid "Histogram and QQ plot for normally-distributed data"
msgstr "Histogram og QQ-plott for normalfordelte data"

#: ../../Ch11/Ch11_tTest_08.rst:35
msgid ""
"Histogram (left panel) and QQ plot (right panel) for the column ``Normal`` "
"in the |distributions|_ data set, a normally-distributed sample with 200 "
"observations. The Shapiro-Wilk statistic associated with these data is *W* = "
"0.992, indicating that no significant departures from normality were "
"detected (*p* = 0.361)."
msgstr ""
"Histogram (venstre panel) og QQ-plott (høyre panel) for kolonnen ``Normal`` "
"i datasettet |distributions|_, et normalfordelt utvalg med 200 "
"observasjoner. Shapiro-Wilk-statistikken knyttet til disse dataene er *W* = "
"0,992, noe som indikerer at det ikke ble oppdaget noen signifikante avvik "
"fra normalfordeling (*p* = 0,361)."

#: ../../Ch11/Ch11_tTest_08.rst:43
msgid "Histogram and QQ plot for skewed and tailed data"
msgstr "Histogram og QQ-plott for skjeve og haleformede data"

#: ../../Ch11/Ch11_tTest_08.rst:47
msgid ""
"In the top row, a histogram (top-left panel) and QQ plot (top-right panel) "
"for 200 observations in the column ``Skewed`` of the |distributions|_ data "
"set. The skewness of the data here is 1.543, and is reflected in a QQ plot "
"that curves upwards and is lacking the lower values within the "
"``Standardized Residuals``. As a consequence, the Shapiro-Wilk statistic is "
"*W* = 0.732, reflecting a significant departure from normality (*p* < "
"0.001). The bottom row shows the same plots for the 200 observations in the "
"column ``Heavy Tailed`` of the |distributions|_ data set. In this case, the "
"heavy tails in the data produce a high kurtosis (8.225), and cause the QQ "
"plot to flatten in the middle, and curve away sharply on either side. The "
"resulting Shapiro-Wilk statistic is *W* = 0.765, again reflecting a "
"significant deviation from normality (*p* < 0.001)."
msgstr ""
"Øverste rad viser et histogram (øverst til venstre) og et QQ-plott (øverst "
"til høyre) for 200 observasjoner i kolonnen ``Skewed`` i datasettet |"
"distributions|_. Skjevheten i dataene her er 1,543, noe som gjenspeiles i et "
"QQ-plott som buer oppover og mangler de lavere verdiene i ``Standardized "
"Residuals``. Som en konsekvens av dette er Shapiro-Wilk-statistikken *W* = "
"0,732, noe som gjenspeiler et signifikant avvik fra normalfordelingen (*p* < "
"0,001). Den nederste raden viser de samme plottene for de 200 observasjonene "
"i kolonnen ``Heavy Tailed`` i datasettet |distributions|_. I dette tilfellet "
"gir de tunge halene i dataene en høy kurtosis (8,225), noe som fører til at "
"QQ-plottet flater ut i midten og bøyer kraftig av på hver side. Den "
"resulterende Shapiro-Wilk-statistikken er *W* = 0,765, noe som igjen "
"gjenspeiler et signifikant avvik fra normalfordelingen (*p* < 0,001)."

#: ../../Ch11/Ch11_tTest_08.rst:62
msgid ""
"One way to check whether a sample violates the normality assumption is to "
"draw a **“QQ plot”** (Quantile-Quantile plot). This allows you to visually "
"check whether you’re seeing any systematic violations. In a QQ plot, each "
"observation is plotted as a single dot. The x co-ordinate is the theoretical "
"quantile that the observation should fall in if the data were normally "
"distributed (with mean and variance estimated from the sample), and on the y "
"co-ordinate is the actual quantile of the data within the sample. If the "
"data are normal, the dots should form a straight line. For instance, lets "
"see what happens if we generate data by sampling from a normal distribution, "
"and then drawing a QQ plot. The results are shown in :numref:`fig-qq1`. As "
"you can see, these data form a pretty straight line; which is no surprise "
"given that we sampled them from a normal distribution! In contrast, have a "
"look at the two data sets shown in :numref:`fig-qq2`. The top panels show "
"the histogram and a QQ plot for a data set that is highly skewed: the QQ "
"plot curves upwards. The lower panels show the same plots for a heavy tailed "
"(i.e., high kurtosis) data set: in this case the QQ plot flattens in the "
"middle and curves sharply at either end."
msgstr ""
"En måte å sjekke om en stikkprøve bryter med forutsetningen om "
"normalfordeling, er å tegne et **«QQ-plott»** (*Quantile-Quantile plot*). På "
"denne måten kan du visuelt sjekke om du ser noen systematiske brudd. I et QQ-"
"plott plottes hver observasjon som en enkelt prikk. X-koordinaten er den "
"teoretiske kvantilen observasjonen burde ligge i hvis dataene var "
"normalfordelte (med gjennomsnitt og varians estimert ut fra utvalget), og y-"
"koordinaten er den faktiske kvantilen for dataene i utvalget. Hvis dataene "
"er normalfordelte, skal prikkene danne en rett linje. La oss for eksempel se "
"hva som skjer hvis vi genererer data ved å ta et utvalg fra en "
"normalfordeling og deretter tegne et QQ-plott. Resultatene vises i :numref:"
"`fig-qq1`. Som du kan se, danner disse dataene en ganske rett linje; noe som "
"ikke er noen overraskelse gitt at vi samplet dem fra en normalfordeling! Se "
"derimot på de to datasettene som vises i :numref:`fig-qq2`. De øverste "
"panelene viser histogrammet og et QQ-plott for et datasett som er svært "
"skjevt: QQ-plottet kurver oppover. De nederste panelene viser de samme "
"plottene for et datasett med kraftig hale (dvs. høy kurtose): I dette "
"tilfellet flater QQ-plottet ut i midten og buer skarpt i hver ende."

#: ../../Ch11/Ch11_tTest_08.rst:82
msgid "Shapiro-Wilk tests"
msgstr "Shapiro-Wilk-tester"

#: ../../Ch11/Ch11_tTest_08.rst:84
msgid ""
"QQ plots provide a nice way to informally check the normality of your data, "
"but sometimes you’ll want to do something a bit more formal and the "
"**Shapiro-Wilk test** (:ref:`Shapiro & Wilk, 1965 <Shapiro_1965>`) is "
"probably what you’re looking for.\\ [#]_ As you’d expect, the null "
"hypothesis being tested is that a set of *N* observations is normally "
"distributed."
msgstr ""
"QQ-plott er en fin måte å sjekke om dataene dine tilsvarer en "
"normalfordeling, men noen ganger vil du gjøre noe litt mer formelt, og "
"**Shapiro-Wilk-testen** (:ref:`Shapiro & Wilk, 1965 <Shapiro_1965>`) er "
"sannsynligvis det du er ute etter.\\ [#]_ Som du forventer, er nullhypotesen "
"som testes, at et sett med *N* observasjoner er normalfordelt."

#: ../../Ch11/Ch11_tTest_08.rst:91
msgid ""
"The test statistic that it calculates is conventionally denoted as *W*, and "
"it’s calculated as follows. First, we sort the observations in order of "
"increasing size, and let *X*\\ :sub:`1` be the smallest value in the sample, "
"*X*\\ :sub:`2` be the second smallest and so on. Then the value of *W* is "
"given by"
msgstr ""
"Teststatistikken som beregnes, kalles vanligvis *W*, og den beregnes på "
"følgende måte. Først sorterer vi observasjonene i rekkefølge etter økende "
"størrelse, og lar *X*\\ :sub:`1` være den minste verdien i utvalget, *X*\\ :"
"sub:`2` er den nest minste og så videre. Da er verdien av *W* gitt ved"

#: ../../Ch11/Ch11_tTest_08.rst:97
msgid ""
"W = \\frac{ \\left( \\sum_{i = 1}^N a_i X_i \\right)^2 }{ \\sum_{i = 1}^N "
"(X_i - \\bar{X})^2}\n"
"\n"
msgstr ""
"W = \\frac{ \\left( \\sum_{i = 1}^N a_i X_i \\right)^2 }{ \\sum_{i = 1}^N "
"(X_i - \\bar{X})^2}\n"
"\n"

#: ../../Ch11/Ch11_tTest_08.rst:99
msgid ""
"where *X̄* is the mean of the observations, and the *a*\\ :sub:`i` values are "
"an introductory text."
msgstr ""
"der *X̄* er gjennomsnittet av observasjonene, og *a*\\ :sub:`i`-verdiene er "
"en innledende tekst."

#: ../../Ch11/Ch11_tTest_08.rst:102
msgid ""
"Because it’s a little hard to explain the maths behind the *W* statistic, a "
"better idea is to give a broad brush description of how it behaves. Unlike "
"most … mumble, mumble … something complicated that is a bit beyond the scope "
"of of the test statistics that we’ll encounter in this book, it’s actually "
"*small* values of *W* that indicate departure from normality. The *W* "
"statistic has a maximum value of 1, which occurs when the data look "
"“perfectly normal”. The smaller the value of *W* the less normal the data "
"are. However, the sampling distribution for *W*, which is not one of the "
"standard ones that I discussed in chapter :doc:`../Ch07/Ch07_Probability` "
"and is in fact a complete pain in the arse to work with, does depend on the "
"sample size *N*. To give you a feel for what these sampling distributions "
"look like, I’ve plotted three of them in :numref:`fig-swdist`. Notice that, "
"as the sample size starts to get large, the sampling distribution becomes "
"very tightly clumped up near *W* = 1, and as a consequence, for larger "
"samples *W* doesn’t have to be very much smaller than 1 in order for the "
"test to be significant."
msgstr ""
"Fordi det er litt vanskelig å forklare matematikken bak *W*-statistikken, er "
"det bedre å gi en bred beskrivelse av hvordan den oppfører seg. I motsetning "
"til de fleste … mumle, mumle … noe komplisert som ligger litt utenfor "
"omfanget av teststatistikken som vi kommer til å møte i denne boken, er det "
"faktisk *små* verdier av *W* som indikerer avvik fra normalfordelingen. *W*-"
"statistikken har en maksimumsverdi på 1, som oppstår når dataene ser «helt "
"normalfordelt» ut. Jo mindre verdien av *W* er, desto mindre er dataene "
"normalfordelt. Utvalgsfordelingen for *W*, som ikke er en av "
"standardfordelingene jeg diskuterte i kapittelet :doc:`../Ch07/"
"Ch07_Probability`, og som faktisk er en skikkelig plage å jobbe med, "
"avhenger imidlertid av utvalgsstørrelsen *N*. For å gi deg en følelse av "
"hvordan disse utvalgsfordelingene ser ut, har jeg plottet tre av dem i :"
"numref:`fig-swdist`. Legg merke til at når utvalgsstørrelsen begynner å bli "
"stor, blir utvalgsfordelingen veldig tett sammenklumpet i nærheten av *W* = "
"1, og som en konsekvens av dette trenger ikke *W* for større utvalg å være "
"veldig mye mindre enn 1 for at testen skal være signifikant."

#: ../../Ch11/Ch11_tTest_08.rst:120
msgid "Sampling distribution of the Shapiro-Wilk W statistic"
msgstr "Utvalgsfordeling av Shapiro-Wilk W-statistikken"

#: ../../Ch11/Ch11_tTest_08.rst:124
msgid ""
"Sampling distribution of the Shapiro-Wilk W statistic, under the null "
"hypothesis that the data are normally-distributed, for samples of size 10, "
"20 and 50. Note that small values of W indicate departure from normality."
msgstr ""
"Utvalgsfordeling av Shapiro-Wilk W-statistikken, under nullhypotesen om at "
"dataene er normalfordelte, for utvalg av størrelse 10, 20 og 50. Merk at små "
"verdier av W indikerer avvik fra normalfordelingen."

#: ../../Ch11/Ch11_tTest_08.rst:130
msgid ""
"To get the Shapiro-Wilk statistic in jamovi *t*-tests, check the option for "
"``Normality`` listed under ``Assumptions``. In the randomly sampled data "
"(*N* = 100) we used for the QQ plot, the value for the Shapiro-Wilk "
"normality test statistic was W = 0.99 with a *p*-value of 0.69. So, not "
"surprisingly, we have no evidence that these data depart from normality. "
"When reporting the results for a Shapiro-Wilk test, you should (as usual) "
"make sure to include the test statistic *W* and the *p*-value, though given "
"that the sampling distribution depends so heavily on *N* it would probably "
"be a politeness to include *N* as well."
msgstr ""
"For å få Shapiro-Wilk-statistikken i jamovi *t*-tester, sjekk alternativet "
"for ``Normality`` under ``Assumptions``. I de tilfeldig utvalgte dataene "
"(*N* = 100) vi brukte til QQ-plottet, var verdien for Shapiro-Wilk-"
"teststatistikken W = 0,99 med en *p*-verdi på 0,69. Ikke overraskende har vi "
"altså ingen bevis for at disse dataene avviker fra normalifordelingen. Når "
"du rapporterer resultatene for en Shapiro-Wilk-test, bør du (som vanlig) "
"sørge for å inkludere teststatistikken *W* og *p*-verdien, men siden "
"utvalgsfordelingen avhenger så sterkt av *N*, ville det nok være høflig å "
"inkludere *N* også."

#: ../../Ch11/Ch11_tTest_08.rst:141
msgid "Example"
msgstr "Eksempel"

#: ../../Ch11/Ch11_tTest_08.rst:143
msgid ""
"In the meantime, it’s probably worth showing you an example of what happens "
"to the QQ plot and the Shapiro-Wilk test when the data turn out to be non-"
"normal. For that, let’s look at the distribution of our AFL winning margins "
"variable (``afl.margins`` from the |aflsmall_margins|_ data set), which if "
"you remember back to th chapter on :doc:`../Ch04/Ch04_Descriptives` didn’t "
"look like they came from a normal distribution at all. Here’s what happens "
"to the QQ plot:"
msgstr ""
"I mellomtiden er det nok verdt å vise deg et eksempel på hva som skjer med "
"QQ-plottet og Shapiro-Wilk-testen når dataene viser seg å være ikke-"
"normalfordelt. La oss se på fordelingen av AFL-vinnermarginvariabelen (``afl."
"margins`` fra datasettet |aflsmall_margins|_), som, hvis du husker tilbake "
"til kapittelet om :doc:`../Ch04/Ch04_Descriptives`, ikke så ut som om de kom "
"fra en normalfordeling i det hele tatt. Her er hva som skjer med QQ-plottet:"

#: ../../Ch11/Ch11_tTest_08.rst:152
msgid ""
"QQ plot for the data (skewed) data in the ``afl.margins`` variable\n"
"of the |aflsmall_margins| dataset"
msgstr ""
"QQ-plott for dataene (skjeve) i variabelen ``afl.margins`` i datasettet\n"
"i datasettet |aflsmall_margins|"

#: ../../Ch11/Ch11_tTest_08.rst:157
msgid ""
"QQ plot for the (skewed) data in the ``afl.margins`` variable of the |"
"aflsmall_margins|_ data set"
msgstr ""
"QQ-plott for (skjeve) data i variabelen ``afl.margins`` i datasettet |"
"aflsmall_margins|_"

#: ../../Ch11/Ch11_tTest_08.rst:162
msgid ""
"And when we run the Shapiro-Wilk test with ``afl.margins``, we get a value "
"for the Shapiro-Wilk normality test statistic of W = 0.94, and *p*-value = "
"9.481e-07. Clearly a significant effect!"
msgstr ""
"Og når vi kjører Shapiro-Wilk-testen med ``afl.margins``, får vi en verdi "
"for Shapiro-Wilk-teststatistikken på W = 0,94, og *p*-verdi = 9,481e-07. "
"Helt klart en signifikant effekt som indikerer avvik fra normalfordelingen!"

#: ../../Ch11/Ch11_tTest_08.rst:169
msgid "This is a massive oversimplification."
msgstr "Dette er en kraftig forenkling."

#: ../../Ch11/Ch11_tTest_08.rst:172
msgid ""
"Either that, or the Kolmogorov-Smirnov test, which is probably more "
"traditional than the Shapiro-Wilk. Although most things I’ve read seem to "
"suggest Shapiro-Wilk is the better test of normality, the Kolomogorov-"
"Smirnov is a general purpose test of distributional equivalence that can be "
"adapted to handle other kinds of distribution tests. In jamovi the Shapiro-"
"Wilk test is preferred."
msgstr ""
"Enten det, eller Kolmogorov-Smirnov-testen, som sannsynligvis er mer "
"tradisjonell enn Shapiro-Wilk. Selv om det meste jeg har lest tyder på at "
"Shapiro-Wilk er den beste testen for sjekke om normalfordeling er gitt, er "
"Kolomogorov-Smirnov en generell test av fordelingsekvivalens som kan "
"tilpasses til å håndtere andre typer fordelinger. I jamovi er Shapiro-Wilk-"
"testen å foretrekke."

#: ../../Ch11/Ch11_tTest_09.rst:4
msgid "Testing non-normal data with Wilcoxon tests"
msgstr "Testing av ikke-normalfordelte data med Wilcoxon-tester"

#: ../../Ch11/Ch11_tTest_09.rst:6
msgid ""
"Okay, suppose your data turn out to be pretty substantially non-normal, but "
"you still want to run something like a *t*-test? This situation occurs a lot "
"in real life. For the AFL winning margins data (``afl.margins`` from the |"
"aflsmall_margins|_ data set), for instance, the Shapiro-Wilk test made it "
"very clear that the normality assumption is violated. This is the situation "
"where you want to use Wilcoxon tests."
msgstr ""
"Hva om dataene dine viser seg å være avvikende fra en normalfordeling, men "
"du likevel ønsker å kjøre en *t*-test? Denne situasjonen forekommer ofte i "
"det virkelige liv. For AFL-dataene for vinnermarginer (``afl.margins`` fra "
"datasettet |aflsmall_margins|_), for eksempel, gjorde Shapiro-Wilk-testen "
"det veldig klart at forutsetningen om normalfordeling er brutt. Det er i "
"slike situasjoner du bør bruke Wilcoxon-tester."

#: ../../Ch11/Ch11_tTest_09.rst:13
msgid ""
"Like the *t*-test, the Wilcoxon test comes in two forms, one-sample and two-"
"sample, and they’re used in more or less the exact same situations as the "
"corresponding *t*-tests. Unlike the *t*-test, the Wilcoxon test doesn’t "
"assume normality, which is nice. In fact, they don’t make any assumptions "
"about what kind of distribution is involved. In statistical jargon, this "
"makes them **nonparametric tests**. While avoiding the normality assumption "
"is nice, there’s a drawback: the Wilcoxon test is usually less powerful than "
"the *t*-test (i.e., higher Type II error rate). I won’t discuss the Wilcoxon "
"tests in as much detail as the *t*-tests, but I’ll give you a brief overview."
msgstr ""
"I likhet med *t*-testen finnes Wilcoxon-test i to former, med ett utvalg og "
"paret, og de brukes i mer eller mindre nøyaktig de samme situasjonene som de "
"tilsvarende *t*-testene. I motsetning til *t*-test forutsetter ikke Wilcoxon-"
"test normalfordeling, noe som er bra. Faktisk har den ingen forutsetninger "
"om hva slags fordeling som er involvert. I statistisk sjargong gjør dette "
"dem til **ikke-parametriske tester**. Selv om det er fint å unngå "
"forutsetningen om normalfordeling, er det en ulempe: Wilcoxon-test er "
"vanligvis mindre sterkt enn *t*-test (dvs. høyere type II-feilrate). Jeg "
"skal ikke gå like detaljert inn på Wilcoxon-test som *t*-test, men jeg skal "
"gi deg en kort oversikt."

#: ../../Ch11/Ch11_tTest_09.rst:26
msgid "Two sample Mann-Whitney U test"
msgstr "Mann-Whitney U-test med to utvalg"

#: ../../Ch11/Ch11_tTest_09.rst:28
msgid ""
"I’ll start by describing the **Mann-Whitney U test**, since it’s actually "
"simpler than the one sample version. Suppose we’re looking at the scores of "
"10 people on some test. Since my imagination has now failed me completely, "
"let’s pretend it’s a “test of awesomeness” and there are two groups of "
"people, “A” and “B”. I’m curious to know which group is more awesome. The "
"data are included in the |awesome|_ data set, and there are two variables "
"apart from the usual ``ID`` variable: ``scores`` |continuous| and ``group`` |"
"nominal|."
msgstr ""
"Jeg begynner med å beskrive **Mann-Whitney U-testen**, siden den faktisk er "
"enklere enn versjonen med ett utvalg. Anta at vi ser på resultatene til 10 "
"personer på en eller annen test. Siden fantasien min nå har sviktet meg "
"fullstendig, kan vi late som om det er en «test av fantastiskhet», og at det "
"finnes to grupper av personer, «A» og «B». Jeg er nysgjerrig på hvilken "
"gruppe som er mest fantastisk. Dataene er inkludert i datasettet |awesome|_, "
"og det er to variabler i tillegg til den vanlige variabelen ``ID``: "
"``scores`` |continuous| og ``group`` |nominal|."

#: ../../Ch11/Ch11_tTest_09.rst:37
msgid ""
"As long as there are no ties (i.e., people with the exact same awesomeness "
"score) then the test that we want to do is surprisingly simple. All we have "
"to do is construct a table that compares every observation in group A "
"against every observation in group B. Whenever the group A datum is larger, "
"we place a check mark in the table:"
msgstr ""
"Så lenge det ikke er noen uavgjort (dvs. personer med nøyaktig samme "
"awesomeness-score), er testen vi ønsker å gjøre overraskende enkel. Alt vi "
"trenger å gjøre, er å lage en tabell som sammenligner hver observasjon i "
"gruppe A med hver observasjon i gruppe B. Hver gang gruppe A er større, "
"setter vi en hake i tabellen:"

#: ../../Ch11/Ch11_tTest_09.rst:44
msgid "**Group B**"
msgstr "**Gruppe B**"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "14.5"
msgstr "14.5"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "10.4"
msgstr "10.4"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "12.4"
msgstr "12.4"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "11.7"
msgstr "11.7"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "13.0"
msgstr "13.0"

#: ../../Ch11/Ch11_tTest_09.rst:52
msgid "**Group A**"
msgstr "**Gruppe A**"

#: ../../Ch11/Ch11_tTest_09.rst:48
msgid "6.4"
msgstr "6.4"

#: ../../Ch11/Ch11_tTest_09.rst:50
msgid "10.7"
msgstr "10.7"

#: ../../Ch11/Ch11_tTest_09.rst:50 ../../Ch11/Ch11_tTest_09.rst:52
#: ../../Ch11/Ch11_tTest_09.rst:94 ../../Ch11/Ch11_tTest_09.rst:96
msgid "✓"
msgstr "✓"

#: ../../Ch11/Ch11_tTest_09.rst:52
msgid "11.9"
msgstr "11.9"

#: ../../Ch11/Ch11_tTest_09.rst:54
msgid "7.3"
msgstr "7.3"

#: ../../Ch11/Ch11_tTest_09.rst:56
msgid "10.0"
msgstr "10.0"

#: ../../Ch11/Ch11_tTest_09.rst:59
msgid ""
"We then count up the number of checkmarks. This is our test statistic, *W*."
"\\ [#]_ The actual sampling distribution for *W* is somewhat complicated, "
"and I’ll skip the details. For our purposes, it’s sufficient to note that "
"the interpretation of *W* is qualitatively the same as the interpretation of "
"*t* or *z*. That is, if we want a two-sided test then we reject the null "
"hypothesis when *W* is very large or very small, but if we have a "
"directional (i.e., one-sided) hypothesis then we only use one or the other."
msgstr ""
"Deretter teller vi opp antall avkrysninger. Dette er vår teststatistikk, *W*."
"\\ [#]_ Den faktiske utvalgsfordelingen for *W* er noe komplisert, og jeg "
"hopper over detaljene. For vårt formål er det tilstrekkelig å merke seg at "
"tolkningen av *W* er kvalitativt den samme som tolkningen av *t* eller *z*. "
"Det vil si at hvis vi ønsker en tosidig test, forkaster vi nullhypotesen når "
"*W* er veldig stor eller veldig liten, men hvis vi har en retningsbestemt "
"(dvs. ensidig) hypotese, bruker vi bare den ene eller den andre."

#: ../../Ch11/Ch11_tTest_09.rst:67
msgid ""
"In jamovi, if we run an ``Independent Samples T-Test`` with ``scores`` |"
"continuous| as the dependent variable. and ``group`` as the grouping "
"variable |nominal|, and then under the options for ``Tests`` check the "
"option for ``Mann-Whitney U``, we will get results showing that U = 3 (i.e., "
"the same number of check marks as shown above), and a *p*-value = 0.05556."
msgstr ""
"Hvis vi i jamovi kjører en ``Independent Samples T-Test`` med ``scores`` |"
"continuous| som avhengig variabel og ``group`` som grupperingsvariabel |"
"nominal|, og deretter under alternativene for ``Tests`` krysser av for "
"``Mann-Whitney U``, vil vi få resultater som viser at U = 3 (dvs. samme "
"antall avkrysninger som vist ovenfor), og en *p*-verdi = 0,05556."

#: ../../Ch11/Ch11_tTest_09.rst:74
msgid "One sample Wilcoxon test"
msgstr "Ett utvalg Wilcoxon-test"

#: ../../Ch11/Ch11_tTest_09.rst:76
msgid ""
"What about the **one sample Wilcoxon test** (or equivalently, the paired "
"samples Wilcoxon test)? Suppose I’m interested in finding out whether taking "
"a statistics class has any effect on the happiness of students. The |"
"happiness|_ data set contains the happiness of each student ``before`` "
"taking the class |ordinal| and ``after`` taking the class |ordinal|. The "
"``change`` score is the difference between the two. Just like we saw with "
"the *t*-test, there’s no fundamental difference between doing a paired-"
"samples test using ``before`` and ``after``, versus doing a one-sample test "
"using the ``change`` scores. As before, the simplest way to think about the "
"test is to construct a tabulation. The way to do it this time is to take "
"those change scores that are positive differences, and tabulate them against "
"all the complete sample. What you end up with is a table that looks like "
"this:"
msgstr ""
"Hva med Wilcoxon-testen** (eller tilsvarende Wilcoxon-testen for parvise "
"utvalg)? Anta at jeg er interessert i å finne ut om det å ta et "
"statistikkurs har noen effekt på studentenes lykke. Datasettet |happiness|_ "
"inneholder lykken til hver student ``before`` å ta klassen |ordinal| og "
"``after`` å ta klassen |ordinal|. Variablen ``change`` er forskjellen mellom "
"de to. Akkurat som vi så med *t*-testen, er det ingen prinsipiell forskjell "
"mellom å gjøre en paret *t*-test med ved hjelp av ``before`` og ``after``, "
"og å gjøre en *t*-test med ett utvalg ved hjelp av variablen ``change``. Som "
"tidligere er den enkleste måten å tenke på testen på å lage en tabell. Denne "
"gangen tar man de endringsscorene som er positive forskjeller, og setter dem "
"opp i tabell mot hele utvalget. Det du ender opp med, er en tabell som ser "
"slik ut:"

#: ../../Ch11/Ch11_tTest_09.rst:145
msgid "ordinal"
msgstr "ordinal"

#: ../../Ch11/Ch11_tTest_09.rst:90
msgid "all differences"
msgstr "alle forskjeller"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-24"
msgstr "-24"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-14"
msgstr "-14"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-10"
msgstr "-10"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "7"
msgstr "7"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-6"
msgstr "-6"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-38"
msgstr "-38"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "2"
msgstr "2"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-35"
msgstr "-35"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-30"
msgstr "-30"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "5"
msgstr "5"

#: ../../Ch11/Ch11_tTest_09.rst:95
msgid "positive differences"
msgstr "positive forskjeller"

#: ../../Ch11/Ch11_tTest_09.rst:94
msgid "7 2 5"
msgstr "7 2 5"

#: ../../Ch11/Ch11_tTest_09.rst:94
msgid "✓ ✓ ✓"
msgstr "✓ ✓ ✓"

#: ../../Ch11/Ch11_tTest_09.rst:99
msgid ""
"Counting up the tick marks this time we get a test statistic of *W* = 7. As "
"before, if our test is two-sided, then we reject the null hypothesis when "
"*W* is very large or very small. As far as running it in jamovi goes, it’s "
"pretty much what you’d expect. For the one-sample version, you specify the "
"``Wilcoxon rank`` option under ``Tests`` in the ``One Sample *t*-Test`` "
"options panel.This gives you Wilcoxon *W* = 7, *p*-value = 0.03711. As this "
"shows, we have a significant effect. Evidently, taking a statistics class "
"does have an effect on your happiness. Switching to a paired samples version "
"of the test won’t give us a different answer, of course; see :numref:`fig-"
"ttest_nonparametric`."
msgstr ""
"Ved å telle opp avkrysningene denne gangen får vi en teststatistikk på *W* = "
"7. Som før, hvis testen vår er tosidig, forkaster vi nullhypotesen når *W* "
"er veldig stor eller veldig liten. Når det gjelder kjøringen i jamovi, er "
"det omtrent som forventet. For versjonen med ett utvalg spesifiserer du "
"alternativet ``Wilcoxon rank`` under ``Tests`` i panelet ``One Sample *t*-"
"Test``. Dette gir deg Wilcoxon *W* = 7, *p*-value = 0,03711. Som dette "
"viser, har vi en signifikant effekt. Å ta et statistikkurs har tydeligvis en "
"effekt på lykken din. Hvis vi bytter til en versjon av testen med parvise "
"utvalg, får vi selvfølgelig ikke et annet svar; se :numref:`fig-"
"ttest_nonparametric`."

#: ../../Ch11/Ch11_tTest_09.rst:112
msgid "Results for one sample and paired sample Wilcoxon non-parametric tests"
msgstr ""
"Resultater for ikke-parametriske Wilcoxon-tester med ett utvalg og parvise "
"utvalg"

#: ../../Ch11/Ch11_tTest_09.rst:116
msgid ""
"jamovi screen showing results for one sample and paired sample Wilcoxon non-"
"parametric tests"
msgstr ""
"jamovi-skjermbildet viser resultater for ikke-parametriske Wilcoxon-tester "
"med ett utvalg og parete utvalg"

#: ../../Ch11/Ch11_tTest_09.rst:124
msgid ""
"Actually, there are two different versions of the test statistic that differ "
"from each other by a constant value. The version that I’ve described is the "
"one that jamovi calculates."
msgstr ""
"Det finnes faktisk to ulike versjoner av teststatistikken som skiller seg "
"fra hverandre med en konstant verdi. Den versjonen jeg har beskrevet, er den "
"som jamovi beregner."

#: ../../Ch11/Ch11_tTest_10.rst:4
msgid "Summary"
msgstr "Sammendrag"

#: ../../Ch11/Ch11_tTest_10.rst:6
msgid ""
"A :doc:`one sample *t*-test <Ch11_tTest_02>` is used to compare a single "
"sample mean against a hypothesised value for the population mean."
msgstr ""
"En :doc:`one sample *t*-test <Ch11_tTest_02>` brukes til å sammenligne et "
"enkelt utvalgs gjennomsnitt med en hypotetisk verdi for "
"populasjonsgjennomsnittet."

#: ../../Ch11/Ch11_tTest_10.rst:9
msgid ""
"An :doc:`independent samples *t*-test <Ch11_tTest_03>` is used to compare "
"the means of two groups, and tests the null hypothesis that they have the "
"same mean. It comes in two forms: the :doc:`Student test <Ch11_tTest_03>` "
"assumes that the groups have the same standard deviation, the :doc:`Welch "
"test <Ch11_tTest_04>` does not."
msgstr ""
"En :doc:`uavhengig *t*-test <Ch11_tTest_03>` brukes til å sammenligne "
"gjennomsnittet til to grupper, og tester nullhypotesen om at de har samme "
"gjennomsnitt. Den finnes i to former: :doc:`Students *t*-test "
"<Ch11_tTest_03>` forutsetter at gruppene har samme standardavvik, mens :doc:"
"`Welchs *t*-test <Ch11_tTest_04>` ikke gjør det."

#: ../../Ch11/Ch11_tTest_10.rst:15
msgid ""
"A :doc:`paired samples *t*-test <Ch11_tTest_05>` is used when you have two "
"scores from each person, and you want to test the null hypothesis that the "
"two scores have the same mean. It is equivalent to taking the difference "
"between the two scores for each person, and then running a one sample *t*-"
"test on the difference scores."
msgstr ""
"En :doc:`paret *t*-test <Ch11_tTest_05>` brukes når du har to skårer fra "
"hver person, og du ønsker å teste nullhypotesen om at de to skårene har "
"samme gjennomsnitt. Det tilsvarer å ta differansen mellom de to skårene for "
"hver person, og deretter kjøre en *t*-test med ett utvalg på "
"differanseskårene."

#: ../../Ch11/Ch11_tTest_10.rst:21
msgid ""
":doc:`Ch11_tTest_06` are perfectly legitimate as long as they are pre-"
"planned."
msgstr ""
":doc:`Ch11_tTest_06` er helt legitime så lenge de er planlagt på forhånd."

#: ../../Ch11/Ch11_tTest_10.rst:24
msgid ""
":doc:`Ch11_tTest_07` calculations for the difference between means can be "
"calculated via the Cohen’s *d*-statistic."
msgstr ""
":doc:`Ch11_tTest_07` beregninger for forskjellen mellom gjennomsnitt kan "
"beregnes ved hjelp av Cohens *d*-statistikk."

#: ../../Ch11/Ch11_tTest_10.rst:27
msgid ""
"You can :doc:`check the normality of a sample <Ch11_tTest_08>` using QQ "
"plots and the Shapiro-Wilk test."
msgstr ""
"Du kan :doc:`forutsetningen om normalfordeling for en stikkprøve "
"<Ch11_tTest_08>` ved hjelp av QQ-plott og Shapiro-Wilk-testen."

#: ../../Ch11/Ch11_tTest_10.rst:30
msgid ""
"If your data are non-normal, you can use :doc:`Mann-Whitney or Wilcoxon "
"tests <Ch11_tTest_09>` instead of *t*-tests."
msgstr ""
"Hvis dataene dine ikke er normalfordelt, kan du bruke :doc:`Mann-Whitney- "
"eller Wilcoxon-tester <Ch11_tTest_09>` i stedet for *t*-tester."
