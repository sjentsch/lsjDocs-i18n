#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-04-01 22:32+0200\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../Ch13/Ch13_ANOVA.rst:4
msgid "Comparing several means (one-way ANOVA)"
msgstr "Sammenligning av flere gjennomsnitt (enveis ANOVA)"

#: ../../Ch13/Ch13_ANOVA.rst:22
msgid ""
"This chapter introduces one of the most widely used tools in psychological "
"statistics, known as “the analysis of variance”, but usually referred to as "
"ANOVA. The basic technique was developed by Sir Ronald Fisher in the early "
"20th century and it is to him that we owe the rather unfortunate "
"terminology. The term ANOVA is a little misleading, in two respects. "
"Firstly, although the name of the technique refers to variances, ANOVA is "
"concerned with investigating differences in means. Secondly, there are "
"several different things out there that are all referred to as ANOVAs, some "
"of which have only a very tenuous connection to one another. Later on in the "
"book we’ll encounter a range of different ANOVA methods that apply in quite "
"different situations, but for the purposes of this chapter we’ll only "
"consider the simplest form of ANOVA, in which we have several different "
"groups of observations, and we’re interested in finding out whether those "
"groups differ in terms of some outcome variable of interest. This is the "
"question that is addressed by a **one-way ANOVA**."
msgstr ""
"Dette kapittelet introduserer et av de mest brukte verktøyene i psykologisk "
"statistikk, kjent som «variansanalyse», men vanligvis omtalt som ANOVA. Den "
"grunnleggende teknikken ble utviklet av Sir Ronald Fisher på begynnelsen av "
"1900-tallet, og det er ham vi kan takke for den noe uheldige terminologien. "
"Begrepet ANOVA er litt misvisende på to måter. For det første, selv om "
"navnet på teknikken refererer til varianser, handler ANOVA om å undersøke "
"forskjeller i gjennomsnitt. For det andre finnes det flere forskjellige ting "
"der ute som alle omtales som ANOVA, og noen av dem har bare en svært svak "
"forbindelse med hverandre. Senere i boken vil vi støte på en rekke ulike "
"ANOVA-metoder som kan brukes i ganske forskjellige situasjoner, men i dette "
"kapittelet skal vi bare se på den enkleste formen for ANOVA, der vi har "
"flere ulike grupper av observasjoner, og vi er interessert i å finne ut om "
"disse gruppene er forskjellige når det gjelder en eller annen "
"utfallsvariabel av interesse. Det er dette spørsmålet en **enveis ANOVA** "
"tar for seg."

#: ../../Ch13/Ch13_ANOVA.rst:39
msgid ""
"The structure of this chapter is as follows: in section :doc:`Ch13_ANOVA_01` "
"I’ll introduce a fictitious data set that we’ll use as a running example "
"throughout the chapter. After introducing the data, I’ll describe the "
"mechanics of how a one-way ANOVA actually works (:doc:`Ch13_ANOVA_02`) and "
"then focus on :doc:`how you can run one in jamovi <Ch13_ANOVA_03>`. These "
"two sections are the core of the chapter. The remainder of the chapter "
"discusses a range of important topics that inevitably arise when running an "
"ANOVA, namely how to calculate :doc:`effect sizes <Ch13_ANOVA_04>`, and :doc:"
"`post-hoc tests and corrections for multiple comparisons <Ch13_ANOVA_05>`. "
"Afterwards, we will talk about the :doc:`assumptions the ANOVA relies upon "
"<Ch13_ANOVA_06>`, how to check those assumptions and some of the things you "
"can do if the assumptions are violated. Then we’ll cover :doc:`repeated "
"measures ANOVA <Ch13_ANOVA_07>` and it's non-parametric equivalent, the :doc:"
"`Friedman test <Ch13_ANOVA_08>`."
msgstr ""
"Strukturen i dette kapittelet er som følger: I avsnitt :doc:`Ch13_ANOVA_01` "
"introduserer jeg et fiktivt datasett som vi vil bruke som et løpende "
"eksempel gjennom hele kapittelet. Etter å ha introdusert dataene beskriver "
"jeg hvordan en enveis ANOVA faktisk fungerer (:doc:`Ch13_ANOVA_02`), og "
"deretter fokuserer jeg på :doc:`hvordan du kan kjøre en enveis ANOVA i "
"jamovi <Ch13_ANOVA_03>`. Disse to avsnittene utgjør kjernen i kapitlet. "
"Resten av kapittelet tar for seg en rekke viktige temaer som uunngåelig "
"dukker opp når man kjører en ANOVA, nemlig hvordan man beregner :doc:"
"`effektstørrelser <Ch13_ANOVA_04>`, og :doc:`post-hoc-tester og korreksjoner "
"for multiple sammenligninger <Ch13_ANOVA_05>`. Etterpå snakker vi om :doc:"
"`forutsetningene som ANOVA bygger på <Ch13_ANOVA_06>`, hvordan du kan sjekke "
"disse forutsetningene og noen av de tingene du kan gjøre hvis "
"forutsetningene brytes. Deretter tar vi for oss :doc:`repeated measures "
"ANOVA <Ch13_ANOVA_07>` og dens ikke-parametriske ekvivalent, :doc:`Friedman-"
"testen <Ch13_ANOVA_08>`."

#: ../../Ch13/Ch13_ANOVA.rst:54
msgid ""
"At the end of the chapter we’ll talk a little about the :doc:`relationship "
"between ANOVA and other statistical tools <Ch13_ANOVA_09>`."
msgstr ""
"På slutten av kapittelet skal vi snakke litt om :doc:`forholdet mellom ANOVA "
"og andre statistiske verktøy <Ch13_ANOVA_09>`."

#: ../../Ch13/Ch13_ANOVA_01.rst:4
msgid "An illustrative data set"
msgstr "Et illustrativt datasett"

#: ../../Ch13/Ch13_ANOVA_01.rst:6
msgid ""
"Suppose you’ve become involved in a clinical trial in which you are testing "
"a new antidepressant drug called *Joyzepam*. In order to construct a fair "
"test of the drug’s effectiveness, the study involves three separate drugs to "
"be administered. One is a placebo, and the other is an existing "
"antidepressant / anti-anxiety drug called *Anxifree*. A collection of 18 "
"participants with moderate to severe depression are recruited for your "
"initial testing. Because the drugs are sometimes administered in conjunction "
"with psychological therapy, your study includes 9 people undergoing "
"cognitive behavioural therapy (CBT) and 9 who are not. Participants are "
"randomly assigned (doubly blinded, of course) a treatment, such that there "
"are 3 CBT people and 3 no-therapy people assigned to each of the 3 drugs. A "
"psychologist assesses the mood of each person after a 3 month run with each "
"drug, and the overall *improvement* in each person’s mood is assessed on a "
"scale ranging from -5 to +5. With that as the study design, let’s now load |"
"clinicaltrial|_ data set. It contains the three variables ``drug`` |"
"nominal|, ``therapy`` |nominal| and ``mood.gain`` |continuous|."
msgstr ""
"Anta at du har blitt involvert i en klinisk studie der dere tester et nytt "
"antidepressivt legemiddel kalt *Joyzepam*. For å kunne lage en rettferdig "
"test av legemiddelets effektivitet, innebærer studien at tre separate "
"legemiddel skal administreres. Det ene er placebo, og det andre er et "
"eksisterende antidepressivt / angstdempende legemiddel kalt *Anxifree*. En "
"samling på 18 deltakere med moderat til alvorlig depresjon rekrutteres til "
"den innledende testingen. Fordi legemidlene noen ganger gis sammen med "
"psykologisk terapi, inkluderer studien din 9 personer som gjennomgår "
"kognitiv atferdsterapi (KAT) og 9 som ikke gjør det. Deltakerne blir "
"tilfeldig tildelt (dobbelt blindet, selvfølgelig) en terapi, slik at tre "
"personer som får CBT og tre personer som ikke får terapi, får hvert av de "
"tre legemidlene. En psykolog vurderer stemningsleiet til hver person etter 3 "
"måneders behandling med hvert legemiddel, og den generelle *forbedringen* i "
"stemningsleiet til hver person vurderes på en skala fra -5 til +5. Med dette "
"som studiedesign, la oss nå laste inn datasettet |clinicaltrial|_. Det "
"inneholder de tre variablene ``drug`` |nominal|, ``therapy`` |nominal| og "
"``mood.gain`` |continuous|."

#: ../../Ch13/Ch13_ANOVA_01.rst:55 ../../Ch13/Ch13_ANOVA_08.rst:48
msgid "nominal"
msgstr "nominal"

#: ../../Ch13/Ch13_ANOVA_01.rst:52
msgid "continuous"
msgstr "continuous"

#: ../../Ch13/Ch13_ANOVA_01.rst:24
msgid ""
"For the purposes of this chapter, what we’re really interested in is the "
"effect of ``drug`` on ``mood.gain``. The first thing to do is calculate some "
"descriptive statistics and draw some graphs. In :doc:`../Ch04/"
"Ch04_Descriptives` we showed you how to do this, and some of the descriptive "
"statistics we can calculate in jamovi are shown in :numref:`fig-anova1`."
msgstr ""
"I dette kapittelet er vi egentlig interessert i effekten av ``drug`` på "
"``mood.gain``. Det første vi må gjøre, er å beregne deskriptivstatistikk og "
"lage noen diagrammer. I :doc:`../Ch04/Ch04_Descriptives` viste vi deg "
"hvordan du gjør dette, og noen deskriptivstatistikk vi kan beregne i jamovi, "
"vises i :numref:`fig-anova1`."

#: ../../Ch13/Ch13_ANOVA_01.rst:33 ../../Ch13/Ch13_ANOVA_01.rst:37
msgid "Descriptives for ``mood.gain``, and box plots by ``drug`` administered"
msgstr ""
"Deskriptivstatistikk for ``mood.gain``, og boksplotter gruppert etter "
"hvilket legemiddel (``drug``) ble administrert"

#: ../../Ch13/Ch13_ANOVA_01.rst:41
msgid ""
"As the plot makes clear, there is a larger improvement in mood for "
"participants in the ``joyzepam`` group than for either the ``anxifree`` "
"group or the ``placebo`` group. The ``anxifree`` group shows a larger mood "
"gain than the ``placebo`` group, but the difference isn’t as large. The "
"question that we want to answer is are these difference “real”, or are they "
"just due to chance?"
msgstr ""
"Som det fremgår av diagrammet, er det en større bedring i humøret for "
"deltakerne i ``joyzepam``-gruppen enn for både ``anxifree``-gruppen og "
"``placebo``-gruppen. Gruppen som fikk ``anxifree`` viser en større "
"humørforbedring enn ``placebo``-gruppen, men forskjellen er ikke like stor. "
"Spørsmålet vi ønsker å få svar på er om disse forskjellene er «reelle», "
"eller om de bare skyldes tilfeldigheter?"

#: ../../Ch13/Ch13_ANOVA_02.rst:4
msgid "How ANOVA works"
msgstr "Hvordan ANOVA fungerer"

#: ../../Ch13/Ch13_ANOVA_02.rst:6
msgid ""
"In order to answer the question posed by our |clinicaltrial|_ data we’re "
"going to run a one-way ANOVA. I’m going to start by showing you how to do it "
"the hard way, building the statistical tool from the ground up and showing "
"you how you could do it if you didn’t have access to any of the cool built-"
"in ANOVA functions in jamovi. And I hope you’ll read it carefully, try to do "
"it the long way once or twice to make sure you really understand how ANOVA "
"works, and then once you’ve grasped the concept never *ever* do it this way "
"again."
msgstr ""
"For å svare på spørsmålet som stilles av dataene fra |clinicaltrial|_, skal "
"vi kjøre en enveis ANOVA. Jeg skal begynne med å vise deg hvordan du gjør "
"det på den vanskelige måten, ved å bygge det statistiske verktøyet fra "
"grunnen av og vise deg hvordan du kan gjøre det hvis du ikke har tilgang til "
"noen av de kule innebygde ANOVA-funksjonene i jamovi. Jeg håper du vil lese "
"den nøye, prøve å gjøre det på den lange måten en eller to ganger for å "
"forsikre deg om at du virkelig forstår hvordan ANOVA fungerer, og når du har "
"forstått konseptet, aldri *noen gang* gjøre det på denne måten igjen."

#: ../../Ch13/Ch13_ANOVA_02.rst:15
msgid ""
"The experimental design that I described in the previous section strongly "
"suggests that we’re interested in comparing the average mood change for the "
"three different drugs. In that sense, we’re talking about an analysis "
"similar to the *t*-test (chapter :doc:`../Ch11/Ch11_tTest`) but involving "
"more than two groups. If we let µ\\ :sub:`P` denote the population mean for "
"the mood change induced by the placebo, and let µ\\ :sub:`A` and µ\\ :sub:"
"`J` denote the corresponding means for our two drugs, Anxifree and Joyzepam, "
"then the (somewhat pessimistic) null hypothesis that we want to test is that "
"all three population means are identical. That is, *neither* of the two "
"drugs is any more effective than a placebo. We can write out this null "
"hypothesis as:"
msgstr ""
"Forsøksdesignet som jeg beskrev i forrige avsnitt, tyder sterkt på at vi er "
"interessert i å sammenligne den gjennomsnittlige stemningsendringen for de "
"tre ulike legemidlene. I så måte snakker vi om en analyse som ligner på *t*-"
"testen (kapittel :doc:`../Ch11/Ch11_tTest`), men som involverer flere enn to "
"grupper. Hvis vi lar µ\\ :sub:`P` betegne populasjonsgjennomsnittet for "
"stemningsendringen indusert av placebo, og lar µ\\ :sub:`A` og µ\\ :sub:`J` "
"betegne de tilsvarende gjennomsnittene for våre to legemiddel, Anxifree og "
"Joyzepam, så er den (noe pessimistiske) nullhypotesen vi ønsker å teste, at "
"alle tre populasjonsgjennomsnittene er identiske. Det vil si at *ingen* av "
"de to legemidlene er mer effektive enn placebo. Vi kan skrive ut denne "
"nullhypotesen som:"

#: ../../Ch13/Ch13_ANOVA_02.rst:26
msgid ""
"H\\ :sub:`0`: it is true that µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`"
msgstr ""
"H\\ :sub:`0`: det er sant at µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`"

#: ../../Ch13/Ch13_ANOVA_02.rst:28
msgid ""
"As a consequence, our alternative hypothesis is that at least one of the "
"three different treatments is different from the others. It’s a bit tricky "
"to write this mathematically, because (as we’ll discuss) there are quite a "
"few different ways in which the null hypothesis can be false. So for now "
"we’ll just write the alternative hypothesis like this:"
msgstr ""
"Alternativhypotesen vår er derfor at minst én av de tre ulike behandlingene "
"er forskjellig fra de andre. Det er litt vanskelig å skrive dette "
"matematisk, for (som vi skal komme tilbake til) kan nullhypotesen være falsk "
"på mange forskjellige måter. Så inntil videre skriver vi bare "
"alternativhypotesen slik:"

#: ../../Ch13/Ch13_ANOVA_02.rst:34
msgid ""
"H\\ :sub:`1`: it is NOT true that µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`"
msgstr ""
"H\\ :sub:`1`: det er IKKE sant at µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`"

#: ../../Ch13/Ch13_ANOVA_02.rst:36
msgid ""
"This null hypothesis is a lot trickier to test than any of the ones we’ve "
"seen previously. How shall we do it? A sensible guess would be to “do an "
"ANOVA”, since that’s the title of the chapter, but it’s not particularly "
"clear why an “analysis of *variances*” will help us learn anything useful "
"about the *means*. In fact, this is one of the biggest conceptual "
"difficulties that people have when first encountering ANOVA. To see how this "
"works, I find it most helpful to start by talking about variances. In fact, "
"what I’m going to do is start by playing some mathematical games with the "
"formula that describes the variance. That is, we’ll start out by playing "
"around with variances and it will turn out that this gives us a useful tool "
"for investigating means."
msgstr ""
"Denne nullhypotesen er mye vanskeligere å teste enn noen av de vi har sett "
"tidligere. Hvordan skal vi gjøre det? Et fornuftig forslag ville være å "
"«gjennomføre en ANOVA», siden det er tittelen på kapitlet, men det er ikke "
"spesielt klart hvorfor en «*varians*analyse» vil hjelpe oss å lære noe "
"nyttig om *gjennomsnittene*. Faktisk er dette en av de største konseptuelle "
"vanskelighetene folk har når de først møter ANOVA. For å se hvordan dette "
"fungerer, synes jeg det er mest nyttig å begynne med å snakke om varianser. "
"Jeg skal faktisk begynne med å leke litt matematisk med formelen som "
"beskriver variansen. Det vil si at vi begynner med å leke oss med varianser, "
"og det vil vise seg at dette gir oss et nyttig verktøy for å undersøke "
"gjennomsnitt."

#: ../../Ch13/Ch13_ANOVA_02.rst:49
msgid "Two formulas for the variance of *Y*"
msgstr "To formler for variansen til *Y*"

#: ../../Ch13/Ch13_ANOVA_02.rst:51
msgid ""
"First, let’s start by introducing some notation. We’ll use *G* to refer to "
"the total number of groups. For our data set there are three drugs, so there "
"are *G* = 3 groups. Next, we’ll use *N* to refer to the total sample size; "
"there are a total of *N* = 18 people in our data set. Similarly, let’s use |"
"N_k| to denote the number of people in the *k*-th group. In our |"
"clinicaltrial|_ data, the sample size is |N_k| = 6` for all three groups.\\ "
"[#]_ Finally, we’ll use *Y* to denote the outcome variable. In our case, *Y* "
"refers to mood change. Specifically, we’ll use |Y_ik| to refer to the mood "
"change experienced by the *i*-th member of the *k*-th group. Similarly, "
"we’ll use |Yb| to be the average mood change, taken across all 18 people in "
"the experiment, and |Yb_k| to refer to the average mood change experienced "
"by the 6 people in group *k*."
msgstr ""
"La oss begynne med å introdusere noen notasjoner. Vi bruker *G* for å "
"referere til det totale antallet grupper. I vårt datasett er det tre "
"legemidler, så det er *G* = 3 grupper. Deretter bruker vi *N* for å referere "
"til den totale utvalgsstørrelsen; det er totalt *N* = 18 personer i "
"datasettet vårt. På samme måte bruker vi |N_k| for å betegne antall personer "
"i den *k*-tredje gruppen. I våre data fra |clinicaltrial|_ er "
"utvalgsstørrelsen |N_k| = 6` for alle tre gruppene.\\ [#]_ Til slutt bruker "
"vi *Y* for å betegne utfallsvariabelen. I vårt tilfelle refererer *Y* til "
"humørforbedringer. Nærmere bestemt bruker vi |Y_ik| for å referere til "
"humørforbedringen som oppleves av det *i*-te medlemmet av den *k*-te "
"gruppen. På samme måte bruker vi |Yb| for å betegne den gjennomsnittlige "
"humørforbedringen for alle de 18 personene i eksperimentet, og |Yb_k| for å "
"referere til den gjennomsnittlige humørforbedringen som ble opplevd av de "
"seks personene i gruppe *k*."

#: ../../Ch13/Ch13_ANOVA_02.rst:66
msgid ""
"Now that we’ve got our notation sorted out we can start writing down "
"formulas. To start with, let’s recall the :ref:`formula for the variance "
"<variance_formula>` that we used way back in those kinder days when we were "
"just doing descriptive statistics. The sample variance of *Y* is defined as "
"follows:"
msgstr ""
"Nå som vi har fått orden på notasjonen, kan vi begynne å skrive ned formler. "
"Til å begynne med kan vi minne om :ref:`formelen for variansen "
"<variance_formula>`, som vi brukte den gang vi bare drev med "
"deskriptivstatistikk. Utvalgsvariansen til *Y* er definert på følgende måte:"

#: ../../Ch13/Ch13_ANOVA_02.rst:72
msgid ""
"\\mbox{Var}(Y) = \\frac{1}{N} \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left(Y_{ik} "
"- \\bar{Y} \\right)^2\n"
"\n"
msgstr ""
"\\mbox{Var}(Y) = \\frac{1}{N} \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left(Y_{ik} "
"- \\bar{Y} \\right)^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:74
msgid ""
"This formula looks pretty much identical to the :ref:`formula for the "
"variance <variance_formula>`. The only difference is that this time around "
"I’ve got two summations here: I’m summing over groups (i.e., values for *k*) "
"and over the people within the groups (i.e., values for *:`i*). This is "
"purely a cosmetic detail. If I’d instead used the notation |Y_p| to refer to "
"the value of the outcome variable for person *p* in the sample, then I’d "
"only have a single summation. The only reason that we have a double "
"summation here is that I’ve classified people into groups, and then assigned "
"numbers to people within groups."
msgstr ""
"Denne formelen ser stort sett identisk ut med :ref:`formelen for variansen "
"<variance_formula>`. Den eneste forskjellen er at jeg denne gangen har to "
"summeringer her: Jeg summerer over grupper (dvs. verdiene for *k*) og over "
"personene i gruppene (dvs. verdiene for *:`i*). Dette er en ren kosmetisk "
"detalj. Hvis jeg i stedet hadde brukt notasjonen |Y_p| for å referere til "
"verdien av utfallsvariabelen for person *p* i utvalget, ville jeg bare hatt "
"en enkelt summering. Den eneste grunnen til at vi har en dobbel summering "
"her, er at jeg har klassifisert personer i grupper, og deretter tildelt tall "
"til personer i gruppene."

#: ../../Ch13/Ch13_ANOVA_02.rst:84
msgid ""
"A concrete example might be useful here. Let’s consider this table, in which "
"we have a total of *N* = 5 people sorted into *G* = 2 groups. Arbitrarily, "
"let’s say that the “cool” people are group 1 and the “uncool” people are "
"group 2. It turns out that we have three cool people (*N*\\ :sub:`1` = 3) "
"and two uncool people (*N*\\ :sub:`2` = 2)."
msgstr ""
"Et konkret eksempel kan være nyttig her. La oss se på denne tabellen, der vi "
"har totalt *N* = 5 personer sortert i *G* = 2 grupper. La oss si at de "
"«kule» personene er gruppe 1 og de «ukule» personene er gruppe 2. Det viser "
"seg at vi har tre kule personer (*N*\\ :sub:`1` = 3) og to ukule personer "
"(*N*\\ :sub:`2` = 2)."

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "name"
msgstr "navn"

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "person"
msgstr "person"

#: ../../Ch13/Ch13_ANOVA_02.rst:91 ../../Ch13/Ch13_ANOVA_02.rst:397
#: ../../Ch13/Ch13_ANOVA_02.rst:423 ../../Ch13/Ch13_ANOVA_02.rst:444
#: ../../Ch13/Ch13_ANOVA_02.rst:490 ../../Ch13/Ch13_ANOVA_02.rst:520
msgid "group"
msgstr "gruppe"

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "group num."
msgstr "gruppenummer."

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "index in group"
msgstr "indeks i gruppe"

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "grumpiness"
msgstr "grettenhet"

#: ../../Ch13/Ch13_ANOVA_02.rst:93
msgid "*p*"
msgstr "*p*"

#: ../../Ch13/Ch13_ANOVA_02.rst:93 ../../Ch13/Ch13_ANOVA_02.rst:399
#: ../../Ch13/Ch13_ANOVA_02.rst:425 ../../Ch13/Ch13_ANOVA_02.rst:446
#: ../../Ch13/Ch13_ANOVA_02.rst:492 ../../Ch13/Ch13_ANOVA_02.rst:522
msgid "*k*"
msgstr "*k*"

#: ../../Ch13/Ch13_ANOVA_02.rst:93
msgid "*i*"
msgstr "*i*"

#: ../../Ch13/Ch13_ANOVA_02.rst:93
msgid "|Y_ik| or |Y_p|"
msgstr "|Y_ik| eller |Y_p|"

#: ../../Ch13/Ch13_ANOVA_02.rst:95
msgid "Ann"
msgstr "Ann"

#: ../../Ch13/Ch13_ANOVA_02.rst:95 ../../Ch13/Ch13_ANOVA_02.rst:97
#: ../../Ch13/Ch13_ANOVA_02.rst:99 ../../Ch13/Ch13_ANOVA_02.rst:101
#: ../../Ch13/Ch13_ANOVA_05.rst:43 ../../Ch13/Ch13_ANOVA_05.rst:206
#: ../../Ch13/Ch13_ANOVA_06.rst:333 ../../Ch13/Ch13_ANOVA_07.rst:66
msgid "1"
msgstr "1"

#: ../../Ch13/Ch13_ANOVA_02.rst:95 ../../Ch13/Ch13_ANOVA_02.rst:97
#: ../../Ch13/Ch13_ANOVA_02.rst:99
msgid "cool"
msgstr "kult"

#: ../../Ch13/Ch13_ANOVA_02.rst:95
msgid "20"
msgstr "20"

#: ../../Ch13/Ch13_ANOVA_02.rst:97
msgid "Ben"
msgstr "Ben"

#: ../../Ch13/Ch13_ANOVA_02.rst:97 ../../Ch13/Ch13_ANOVA_02.rst:101
#: ../../Ch13/Ch13_ANOVA_02.rst:103 ../../Ch13/Ch13_ANOVA_02.rst:596
#: ../../Ch13/Ch13_ANOVA_05.rst:45 ../../Ch13/Ch13_ANOVA_05.rst:204
#: ../../Ch13/Ch13_ANOVA_06.rst:333 ../../Ch13/Ch13_ANOVA_07.rst:68
#: ../../Ch13/Ch13_ANOVA_07.rst:74
msgid "2"
msgstr "2"

#: ../../Ch13/Ch13_ANOVA_02.rst:97
msgid "55"
msgstr "55"

#: ../../Ch13/Ch13_ANOVA_02.rst:99
msgid "Cat"
msgstr "Katt"

#: ../../Ch13/Ch13_ANOVA_02.rst:99 ../../Ch13/Ch13_ANOVA_05.rst:47
#: ../../Ch13/Ch13_ANOVA_05.rst:202 ../../Ch13/Ch13_ANOVA_07.rst:70
msgid "3"
msgstr "3"

#: ../../Ch13/Ch13_ANOVA_02.rst:99
msgid "21"
msgstr "21"

#: ../../Ch13/Ch13_ANOVA_02.rst:101
msgid "Tim"
msgstr "Tim"

#: ../../Ch13/Ch13_ANOVA_02.rst:101 ../../Ch13/Ch13_ANOVA_05.rst:49
#: ../../Ch13/Ch13_ANOVA_05.rst:200 ../../Ch13/Ch13_ANOVA_07.rst:72
#: ../../Ch13/Ch13_ANOVA_07.rst:76
msgid "4"
msgstr "4"

#: ../../Ch13/Ch13_ANOVA_02.rst:101 ../../Ch13/Ch13_ANOVA_02.rst:103
msgid "uncool"
msgstr "ukul"

#: ../../Ch13/Ch13_ANOVA_02.rst:101
msgid "91"
msgstr "91"

#: ../../Ch13/Ch13_ANOVA_02.rst:103
msgid "Egg"
msgstr "Egg"

#: ../../Ch13/Ch13_ANOVA_02.rst:103 ../../Ch13/Ch13_ANOVA_05.rst:51
#: ../../Ch13/Ch13_ANOVA_05.rst:198 ../../Ch13/Ch13_ANOVA_07.rst:70
#: ../../Ch13/Ch13_ANOVA_07.rst:72 ../../Ch13/Ch13_ANOVA_07.rst:74
msgid "5"
msgstr "5"

#: ../../Ch13/Ch13_ANOVA_02.rst:103
msgid "22"
msgstr "22"

#: ../../Ch13/Ch13_ANOVA_02.rst:106
msgid ""
"Notice that I’ve constructed two different labelling schemes here. We have a "
"“person” variable *p* so it would be perfectly sensible to refer to |Y_p| as "
"the grumpiness of the *p*-th person in the sample. For instance, the table "
"shows that Tim is the fourth so we’d say *p* = 4. So, when talking about the "
"grumpiness *Y* of this “Tim” person, whoever he might be, we could refer to "
"his grumpiness by saying that |Y_p| = 91, for person *p* = 4 that is. "
"However, that’s not the only way we could refer to Tim. As an alternative we "
"could note that Tim belongs to the “uncool” group (*k* = 2), and is in fact "
"the first person listed in the “uncool” group (*i* = 1). So it’s equally "
"valid to refer to Tim’s grumpiness by saying that |Y_ik| = 91, where *k* = 2 "
"and *i* = 1."
msgstr ""
"Legg merke til at jeg har laget to forskjellige systemer av betegnelser her."
"Vi har en «person»-variabel *p*, så det ville være helt fornuftig å referere "
"til |Y_p| som grettenheten til den *p*-tredje personen i utvalget. Tabellen "
"viser for eksempel at Tim er den fjerde, så vi sier *p* = 4. Så når vi "
"snakker om grettenheten *Y* til denne «Tim»-personen, uansett hvem han er, "
"kan vi referere til grettenheten hans ved å si at |Y_p| = 91, for person *p* "
"= 4, altså. Det er imidlertid ikke den eneste måten vi kan referere til Tim "
"på. Alternativt kan vi si at Tim tilhører den «ukule» gruppen (*k* = 2), og "
"at han faktisk er den første personen i den «ukule» gruppen (*i* = 1). Det "
"er altså like gyldig å referere til Tims grettenhet ved å si at |Y_ik| = 91, "
"der *k* = 2 og *i* = 1."

#: ../../Ch13/Ch13_ANOVA_02.rst:119
msgid ""
"In other words, each person *p* corresponds to a unique *ik* combination, "
"and so the formula that I gave above is actually identical to our original "
"formula for the variance, which would be"
msgstr ""
"Med andre ord, hver person *p* tilsvarer en unik *ik*-kombinasjon, og dermed "
"er formelen jeg ga ovenfor faktisk identisk med vår opprinnelige formel for "
"variansen, som ville vært"

#: ../../Ch13/Ch13_ANOVA_02.rst:123
msgid ""
"\\mbox{Var}(Y) = \\frac{1}{N} \\sum_{p=1}^N  \\left(Y_{p} - \\bar{Y} "
"\\right)^2\n"
"\n"
msgstr ""
"\\mbox{Var}(Y) = \\frac{1}{N} \\sum_{p=1}^N  \\left(Y_{p} - \\bar{Y} "
"\\right)^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:125
msgid ""
"In both formulas, all we’re doing is summing over all of the observations in "
"the sample. Most of the time we would just use the simpler |Y_p| notation; "
"the equation using |Y_p| is clearly the simpler of the two. However, when "
"doing an ANOVA it’s important to keep track of which participants belong in "
"which groups, and we need to use the |Y_ik| notation to do this."
msgstr ""
"I begge formlene summerer vi bare over alle observasjonene i utvalget. Som "
"oftest vil vi bare bruke den enklere |Y_p|-notasjonen; ligningen som bruker |"
"Y_p| er helt klart den enkleste av de to. Når vi utfører en ANOVA, er det "
"imidlertid viktig å holde rede på hvilke deltakere som tilhører hvilke "
"grupper, og vi må bruke |Y_ik|-notasjonen for å gjøre dette."

#: ../../Ch13/Ch13_ANOVA_02.rst:133
msgid "From variances to sums of squares"
msgstr "Fra varianser til kvadratsummer"

#: ../../Ch13/Ch13_ANOVA_02.rst:135
msgid ""
"Okay, now that we’ve got a good grasp on how the variance is calculated, "
"let’s define something called the **total sum of squares**, which is denoted "
"|SS_t|\\. This is very simple. Instead of averaging the squared deviations, "
"which is what we do when calculating the variance, we just add them up."
msgstr ""
"Nå som vi har fått en god forståelse av hvordan variansen beregnes, kan vi "
"definere noe som kalles **total sum av kvadrater**, som betegnes |SS_t|\\. "
"Dette er veldig enkelt. I stedet for å ta gjennomsnittet av de kvadrerte "
"avvikene, som vi gjør når vi beregner variansen, legger vi dem bare sammen."

#: ../../Ch13/Ch13_ANOVA_02.rst:141
msgid ""
"So the formula for the total sum of squares is almost identical to the "
"formula for the variance"
msgstr ""
"Formelen for den totale kvadratsummen er altså nesten identisk med formelen "
"for variansen"

#: ../../Ch13/Ch13_ANOVA_02.rst:144
msgid ""
"\\mbox{SS}_{tot} = \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left(Y_{ik} - \\bar{Y} "
"\\right)^2\n"
"\n"
msgstr ""
"\\mbox{SS}_{tot} = \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left(Y_{ik} - \\bar{Y} "
"\\right)^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:146
msgid ""
"When we talk about analysing variances in the context of ANOVA, what we’re "
"really doing is working with the total sums of squares rather than the "
"actual variance. One very nice thing about the total sum of squares is that "
"we can break it up into two different kinds of variation."
msgstr ""
"Når vi snakker om å analysere varianser i forbindelse med ANOVA, jobber vi "
"egentlig med den totale kvadratsummen i stedet for den faktiske variansen. "
"En veldig fin ting med den totale kvadratsummen er at vi kan dele den opp i "
"to forskjellige typer variasjon."

#: ../../Ch13/Ch13_ANOVA_02.rst:151
msgid ""
"First, we can talk about the **within-group sum of squares**, in which we "
"look to see how different each individual person is from their own group mean"
msgstr ""
"For det første kan vi snakke om **kvadratsummen innenfor gruppen**, der vi "
"ser på hvor forskjellig hver enkelt person er fra gjennomsnittet i sin egen "
"gruppe"

#: ../../Ch13/Ch13_ANOVA_02.rst:155
msgid ""
"\\mbox{SS}_w = \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left( Y_{ik} - \\bar{Y}_k "
"\\right)^2\n"
"\n"
msgstr ""
"\\mbox{SS}_w = \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left( Y_{ik} - \\bar{Y}_k "
"\\right)^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:157
msgid ""
"where |Yb_k| is a group mean. In our example, |Yb_k| would be the average "
"mood change experienced by those people given the *k*-th drug. So, instead "
"of comparing individuals to the average of all people in the experiment, "
"we’re only comparing them to those people in the the same group. As a "
"consequence, you’d expect the value of |SS_w| to be smaller than the total "
"sum of squares, because it’s completely ignoring any group differences, i."
"e., whether the drugs will have different effects on people’s moods."
msgstr ""
"hvor |Yb_k| er et gruppegjennomsnitt. I vårt eksempel vil |Yb_k| være den "
"gjennomsnittlige humørforbedringen som oppleves av de personene som får det "
"*k*-te legemiddelet. Så i stedet for å sammenligne enkeltpersoner med "
"gjennomsnittet av alle personene i eksperimentet, sammenligner vi dem bare "
"med personene i samme gruppe. Som en konsekvens av dette kan du forvente at "
"verdien av |SS_w| er mindre enn den totale kvadratsummen, fordi den "
"fullstendig ignorerer eventuelle gruppeforskjeller, dvs. om legemidlene vil "
"ha ulik effekt på humøret til folk."

#: ../../Ch13/Ch13_ANOVA_02.rst:165
msgid ""
"Next, we can define a third notion of variation which captures *only* the "
"differences between groups. We do this by looking at the differences between "
"the group means |Yb_k| and grand mean |Yb|."
msgstr ""
"Deretter kan vi definere et tredje variasjonsbegrep som *kun* fanger opp "
"forskjellene mellom grupper. Dette gjør vi ved å se på forskjellene mellom "
"gruppegjennomsnittet |Yb_k| og det totale gjennomsnittet |Yb|."

#: ../../Ch13/Ch13_ANOVA_02.rst:169
msgid ""
"In order to quantify the extent of this variation, what we do is calculate "
"the **between-group sum of squares**"
msgstr ""
"For å kvantifisere omfanget av denne variasjonen beregner vi **kvadratsummen "
"mellom gruppene**"

#: ../../Ch13/Ch13_ANOVA_02.rst:172
msgid ""
"\\begin{aligned}\n"
"\\mbox{SS}_{b} &=& \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left( \\bar{Y}_k - "
"\\bar{Y} \\right)^2 \\\\\n"
"              &=& \\sum_{k=1}^G N_k \\left( \\bar{Y}_k - \\bar{Y} "
"\\right)^2\\end{aligned}"
msgstr ""
"\\begin{aligned}\n"
"\\mbox{SS}_{b} &=& \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left( \\bar{Y}_k - "
"\\bar{Y} \\right)^2 \\\\\n"
"              &=& \\sum_{k=1}^G N_k \\left( \\bar{Y}_k - \\bar{Y} "
"\\right)^2\\end{aligned}"

#: ../../Ch13/Ch13_ANOVA_02.rst:178
msgid ""
"It’s not too difficult to show that the total variation among people in the "
"experiment |SS_t| is actually the sum of the differences between the groups |"
"SS_b| and the variation inside the groups |SS_w|. That is,"
msgstr ""
"Det er ikke så vanskelig å vise at den totale variasjonen blant personene i "
"eksperimentet |SS_t| faktisk er summen av forskjellene mellom gruppene |"
"SS_b| og variasjonen innenfor hver av gruppene |SS_w|. Det vil si at,"

#: ../../Ch13/Ch13_ANOVA_02.rst:182
msgid "|SS_w| + |SS_b| = |SS_t|"
msgstr "|SS_w| + |SS_b| = |SS_t|"

#: ../../Ch13/Ch13_ANOVA_02.rst:184
msgid "Yay."
msgstr "Jippi!"

#: ../../Ch13/Ch13_ANOVA_02.rst:188
msgid "Illustration of between and within groups variation"
msgstr "Illustrasjon av variasjon mellom og innenfor gruppene"

#: ../../Ch13/Ch13_ANOVA_02.rst:192
msgid ""
"Graphical illustration of “between groups” variation (left panel) and "
"“within groups” variation (right panel). In the left panel, the arrows show "
"the differences in the group means. In the right panel, the arrows highlight "
"the variability within each group."
msgstr ""
"Grafisk illustrasjon av variasjon «mellom grupper» (venstre panel) og "
"variasjon «innenfor gruppene» (høyre panel). I det venstre panelet viser "
"pilene forskjellene i gruppegjennomsnitt. I det høyre panelet fremhever "
"pilene variasjonen innenfor hver gruppe."

#: ../../Ch13/Ch13_ANOVA_02.rst:199
msgid ""
"Okay, so what have we found out? We’ve discovered that the total variability "
"associated with the outcome variable (|SS_t|\\) can be mathematically carved "
"up into the sum of “the variation due to the differences in the sample means "
"for the different groups” (|SS_b|\\) plus “all the rest of the variation” (|"
"SS_w|\\).\\ [#]_"
msgstr ""
"Hva har vi funnet ut? Vi har oppdaget at den totale variasjonen knyttet til "
"utfallsvariabelen (|SS_t|\\) matematisk sett kan deles opp i summen av "
"«variasjonen som skyldes forskjellene i utvalgsgjennomsnitt for de ulike "
"gruppene» (|SS_b|\\) pluss «all den øvrige variasjonen» (|SS_w|\\).\\ [#]_"

#: ../../Ch13/Ch13_ANOVA_02.rst:206
msgid ""
"How does that help me find out whether the groups have different population "
"means? Um. Wait. Hold on a second. Now that I think about it, this is "
"*exactly* what we were looking for. If the null hypothesis is true then "
"you’d expect all the sample means to be pretty similar to each other, right? "
"And that would imply that you’d expect |SS_b| to be really small, or at "
"least you’d expect it to be a lot smaller than “the variation associated "
"with everything else”, |SS_w|\\. Hmm. I detect a hypothesis test coming on."
msgstr ""
"Hvordan hjelper det meg å finne ut om gruppene har ulike "
"populasjonsgjennomsnitt? Vent litt. Nå som jeg tenker meg om, er det "
"*nøyaktig* det vi var ute etter. Hvis nullhypotesen er sann, forventer du "
"vel at alle utvalgsgjennomsnittene er ganske like hverandre? Og det ville "
"innebære at du forventer at |SS_b| er veldig liten, eller i det minste "
"forventer du at den er mye mindre enn «variasjonen knyttet til alt annet», |"
"SS_w|\\. Hmm. Jeg aner en hypotesetest på vei."

#: ../../Ch13/Ch13_ANOVA_02.rst:215
msgid "From sums of squares to the *F*-test"
msgstr "Fra kvadratsummer til *F*-test"

#: ../../Ch13/Ch13_ANOVA_02.rst:217
msgid ""
"As we saw in the last section, the *qualitative* idea behind ANOVA is to "
"compare the two sums of squares values |SS_b| and |SS_w| to each other. If "
"the between-group variation |SS_b| is large relative to the within-group "
"variation |SS_w| then we have reason to suspect that the population means "
"for the different groups aren’t identical to each other. In order to convert "
"this into a workable hypothesis test, there’s a little bit of “fiddling "
"around” needed. What I’ll do is first show you *what* we do to calculate our "
"test statistic, the **F-ratio**, and then try to give you a feel for *why* "
"we do it this way."
msgstr ""
"Som vi så i forrige avsnitt, er den *kvalitative* ideen bak ANOVA å "
"sammenligne de to kvadratsummene |SS_b| og |SS_w| med hverandre. Hvis "
"variasjonen mellom gruppene |SS_b| er stor i forhold til variasjonen "
"innenfor gruppene |SS_w|, har vi grunn til å mistenke at "
"populasjonsgjennomsnittene for de ulike gruppene ikke er identiske med "
"hverandre. For å konvertere dette til en brukbar hypotesetest, er det "
"nødvendig med litt «fikling». Jeg skal først vise deg *hvad* vi gjør for å "
"beregne teststatistikken vår, **F-ratio**, og deretter prøve å gi deg en "
"følelse av *hvorfor* vi gjør det på denne måten."

#: ../../Ch13/Ch13_ANOVA_02.rst:228
msgid ""
"In order to convert our SS values into an *F*-ratio the first thing we need "
"to calculate is the **degrees of freedom** associated with the |SS_b| and |"
"SS_w| values. As usual, the degrees of freedom corresponds to the number of "
"unique “data points” that contribute to a particular calculation, minus the "
"number of “constraints” that they need to satisfy. For the within-groups "
"variability what we’re calculating is the variation of the individual "
"observations (*N* data points) around the group means (*G* constraints). In "
"contrast, for the between groups variability we’re interested in the "
"variation of the group means (*G* data points) around the grand mean (1 "
"constraint). Therefore, the degrees of freedom here are:"
msgstr ""
"For å konvertere SS-verdiene våre til et *F*-forhold må vi først beregne "
"**frihetsgradene** som er knyttet til |SS_b|- og |SS_w|-verdiene. Som vanlig "
"tilsvarer frihetsgradene antallet unike «datapunkter» som bidrar til en "
"bestemt beregning, minus antallet «begrensninger» (*constraints*) som de må "
"tilfredsstille. For variabiliteten innenfor gruppene beregner vi variasjonen "
"i de individuelle observasjonene (*N* datapunkter) rundt "
"gruppegjennomsnittet (*G* begrensninger, *constraints*). For variabiliteten "
"mellom grupper er vi derimot interessert i variasjonen i "
"gruppegjennomsnittet (*G* datapunkter) rundt det totale gjennomsnittet (1 "
"begrensning, *constraint*). Derfor er frihetsgradene her:"

#: ../../Ch13/Ch13_ANOVA_02.rst:241 ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "|df_b| = *G* - 1"
msgstr "|df_b| = *G* - 1"

#: ../../Ch13/Ch13_ANOVA_02.rst:242 ../../Ch13/Ch13_ANOVA_02.rst:290
msgid "|df_w| = *N* - *G*"
msgstr "|df_w| = *N* - *G*"

#: ../../Ch13/Ch13_ANOVA_02.rst:244
msgid ""
"Okay, that seems simple enough. What we do next is convert our summed "
"squares value into a “mean squares” value, which we do by dividing by the "
"degrees of freedom:"
msgstr ""
"Ok, det virker enkelt nok. Det neste vi gjør, er å konvertere kvadratsummen "
"(*sum of squares*) til en «gjennomsnittlig kvadratsumme», (*mean square*; "
"MS) noe vi gjør ved å dividere med frihetsgradene:"

#: ../../Ch13/Ch13_ANOVA_02.rst:248 ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "|MS_b| = |SS_b| / |df_b|"
msgstr "|MS_b| = |SS_b| / |df_b|"

#: ../../Ch13/Ch13_ANOVA_02.rst:249 ../../Ch13/Ch13_ANOVA_02.rst:290
msgid "|MS_w| = |SS_w| / |df_w|"
msgstr "|MS_w| = |SS_w| / |df_w|"

#: ../../Ch13/Ch13_ANOVA_02.rst:251
msgid ""
"Finally, we calculate the *F*-ratio by dividing the between-groups MS by the "
"within-groups MS:"
msgstr ""
"Til slutt beregner vi *F*-ratioen ved å dividere MS mellom grupper med MS "
"innenfor gruppene:"

#: ../../Ch13/Ch13_ANOVA_02.rst:254 ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "F = |MS_b| / |MS_w|"
msgstr "F = |MS_b| / |MS_w|"

#: ../../Ch13/Ch13_ANOVA_02.rst:256
msgid ""
"At a very general level, the intuition behind the *F*-statistic is "
"straightforward. Bigger values of *F* means that the between-groups "
"variation is large relative to the within-groups variation. As a "
"consequence, the larger the value of *F* the more evidence we have against "
"the null hypothesis. But how large does *F* have to be in order to actually "
"*reject* H\\ :sub:`0`? In order to understand this, you need a slightly "
"deeper understanding of what ANOVA is and what the mean squares values "
"actually are."
msgstr ""
"På et veldig generelt nivå er intuisjonen bak *F*-statistikken enkel. Større "
"verdier av *F* betyr at variasjonen mellom gruppene er stor i forhold til "
"variasjonen innenfor gruppene. Jo større verdien av *F* er, desto mer bevis "
"har vi mot nullhypotesen. Men hvor stor må *F* være for at vi faktisk skal "
"kunne *forkaste* H\\ :sub:`0`? For å forstå dette trenger du en litt dypere "
"forståelse av hva ANOVA er, og hva de gjennomsnittlige kvadratsummene "
"faktisk er."

#: ../../Ch13/Ch13_ANOVA_02.rst:265
msgid ""
"The next section discusses that in a bit of detail, but for readers that "
"aren’t interested in the details of what the test is actually measuring I’ll "
"cut to the chase. In order to complete our hypothesis test we need to know "
"the sampling distribution for *F* if the null hypothesis is true. Not "
"surprisingly, the sampling distribution for the *F*-statistic under the null "
"hypothesis is an *F*-distribution. If you recall our discussion of the *F*-"
"distribution in chapter :doc:`../Ch07/Ch07_Probability`, the *F*-"
"distribution has two parameters, corresponding to the two degrees of freedom "
"involved. The first one *df*\\ :sub:`1` is the between groups degrees of "
"freedom |df_b|, and the second one *df*\\ :sub:`2` is the within groups "
"degrees of freedom |df_w|\\."
msgstr ""
"I neste avsnitt diskuterer vi dette i detalj, men for lesere som ikke er "
"interessert i detaljene om hva testen faktisk måler, skal jeg gå rett på "
"sak. For å kunne fullføre hypotesetesten må vi kjenne utvalgsfordelingen for "
"*F* hvis nullhypotesen er sann. Ikke overraskende er utvalgsfordelingen for "
"*F*-statistikken under nullhypotesen en *F*-fordeling. Hvis du husker "
"diskusjonen om *F*-fordelingen i kapittel :doc:`../Ch07/Ch07_Probability`, "
"har *F*-fordelingen to parametere, som tilsvarer de to frihetsgradene som er "
"involvert. Den første *df*\\ :sub:`1` er frihetsgradene mellom grupper |"
"df_b|, og den andre *df*\\ :sub:`2` er frihetsgradene innenfor grupper |df_w|"
"\\."

#: ../../Ch13/Ch13_ANOVA_02.rst:276
msgid ""
"A summary of all the key quantities involved in a one-way ANOVA, including "
"the formulas showing how they are calculated, is shown in :numref:`tab-"
"anovatable`."
msgstr ""
"En oppsummering av alle de viktigste størrelsene som inngår i en enveis "
"ANOVA, inkludert formlene som viser hvordan de beregnes, er vist i :numref:"
"`tab-anovatable`."

#: ../../Ch13/Ch13_ANOVA_02.rst:279
msgid ""
"All of the key quantities involved in an ANOVA organised into a “standard” "
"ANOVA table. The formulas for all quantities (except the *p*-value which has "
"a very ugly formula and would be nightmarishly hard to calculate without a "
"computer) are shown."
msgstr ""
"Alle de viktigste størrelsene som inngår i en ANOVA, er organisert i en "
"«standard» ANOVA-tabell. Formlene for alle størrelsene (bortsett fra *p*-"
"verdien, som har en veldig stygg formel og ville vært marerittaktig "
"vanskelig å beregne uten datamaskin) er vist."

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "*df*"
msgstr "*df*"

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "sum of squares"
msgstr "Kvadratsummer"

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "mean squares"
msgstr "Gjennomsnittlige kvadratsummer"

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "*F*-statistic"
msgstr "*F*-statistikk"

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "*p*-value"
msgstr "*p*-verdi"

#: ../../Ch13/Ch13_ANOVA_02.rst:288 ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "**between groups**"
msgstr "**mellom grupper**"

#: ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "|SS_b| = |f_SS_b|"
msgstr "|SS_b| = |f_SS_b|"

#: ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "[complicated]"
msgstr "[komplisert]"

#: ../../Ch13/Ch13_ANOVA_02.rst:290 ../../Ch13/Ch13_ANOVA_02.rst:598
msgid "**within groups**"
msgstr "**innenfor grupper**"

#: ../../Ch13/Ch13_ANOVA_02.rst:290
msgid "|SS_w| = |f_SS_w|"
msgstr "|SS_w| = |f_SS_w|"

#: ../../Ch13/Ch13_ANOVA_02.rst:296
msgid "The model for the data and the meaning of *F*"
msgstr "Modellen for dataene og betydningen av *F*"

#: ../../Ch13/Ch13_ANOVA_02.rst:298
msgid ""
"At a fundamental level ANOVA is a competition between two different "
"statistical models, H\\ :sub:`0` and H\\ :sub:`1`. When I described the null "
"and alternative hypotheses at the start of the section, I was a little "
"imprecise about what these models actually are. I’ll remedy that now, though "
"you probably won’t like me for doing so. If you recall, our null hypothesis "
"was that all of the group means are identical to one another. If so, then a "
"natural way to think about the outcome variable |Y_ik| is to describe "
"individual scores in terms of a single population mean µ, plus the deviation "
"from that population mean. This deviation is usually denoted ϵ\\ :sub:`ik` "
"and is traditionally called the *error* or **residual** associated with that "
"observation. Be careful though. Just like we saw with the word "
"“significant”, the word “error” has a technical meaning in statistics that "
"isn’t quite the same as its everyday English definition. In everyday "
"language, “error” implies a mistake of some kind, but in statistics it "
"doesn’t (or at least, not necessarily). With that in mind, the word "
"“residual” is a better term than the word “error”. In statistics both words "
"mean “leftover variability”, that is “stuff” that the model can’t explain."
msgstr ""
"På et grunnleggende nivå er ANOVA en konkurranse mellom to ulike statistiske "
"modeller, H\\ :sub:`0` og H\\ :sub:`1`. Da jeg beskrev nullhypotesen og "
"alternativhypotesen i begynnelsen av avsnittet, var jeg litt upresis med "
"hensyn til hva disse modellene egentlig er. Det skal jeg rette på nå, selv "
"om du sikkert ikke vil like at jeg gjør det. Hvis du husker det, var "
"nullhypotesen vår at alle gruppegjennomsnittene er identiske med hverandre. "
"I så fall er en naturlig måte å tenke på utfallsvariabelen |Y_ik| å beskrive "
"individuelle resultater i form av et enkelt populasjonsgjennomsnitt µ, pluss "
"avviket fra dette populasjonsgjennomsnittet. Dette avviket betegnes "
"vanligvis ϵ\\ :sub:`ik` og kalles tradisjonelt *feilen* eller **residuum** "
"som er knyttet til observasjonen. Men vær forsiktig. Akkurat som vi så med "
"ordet «signifikant», har ordet «feil» en teknisk betydning i statistikk som "
"ikke er helt den samme som den engelske hverdagsdefinisjonen. I "
"dagligspråket innebærer «feil» et feilgrep av et eller annet slag, men i "
"statistikken gjør det ikke det (eller i hvert fall ikke nødvendigvis). Med "
"det i bakhodet er ordet «residuum» et bedre begrep enn ordet «feil». I "
"statistikk betyr begge ordene «resterende variabilitet», det vil si «ting» "
"som modellen ikke kan forklare."

#: ../../Ch13/Ch13_ANOVA_02.rst:318
msgid ""
"In any case, here’s what the null hypothesis looks like when we write it as "
"a statistical model"
msgstr ""
"Slik ser nullhypotesen uansett ut når vi skriver den som en statistisk modell"

#: ../../Ch13/Ch13_ANOVA_02.rst:321
msgid "|Y_ik| = µ + ϵ\\ :sub:`ik`"
msgstr "|Y_ik| = µ + ϵ\\ :sub:`ik`"

#: ../../Ch13/Ch13_ANOVA_02.rst:323
msgid ""
"where we make the *assumption* (discussed later) that the residual values "
"ϵ\\ :sub:`ik` are normally distributed, with mean 0 and a standard deviation "
"σ that is the same for all groups. To use the notation that we introduced in "
"chapter :doc:`../Ch07/Ch07_Probability` we would write this assumption like "
"this:"
msgstr ""
"hvor vi gjør den *antakelsen* (diskutert senere) at residuene ϵ\\ :sub:`ik` "
"er normalfordelte, med et gjennomsnitt på 0 og et standardavvik σ som er "
"likt for alle gruppene. For å bruke notasjonen som vi introduserte i "
"kapittel :doc:`../Ch07/Ch07_Probability`, ville vi skrevet denne "
"forutsetningen slik:"

#: ../../Ch13/Ch13_ANOVA_02.rst:329 ../../Ch13/Ch13_ANOVA_06.rst:29
msgid "ϵ\\ :sub:`ik` ~ Normal(0, σ²)"
msgstr "ϵ\\ :sub:`ik` ~ Normal(0, σ²)"

#: ../../Ch13/Ch13_ANOVA_02.rst:331
msgid ""
"What about the alternative hypothesis, H\\ :sub:`1`? The only difference "
"between the null hypothesis and the alternative hypothesis is that we allow "
"each group to have a different population mean. So, if we let µ\\ :sub:`k` "
"denote the population mean for the *k*-th group in our experiment, then the "
"statistical model corresponding to H\\ :sub:`1` is"
msgstr ""
"Hva med alternativhypotesen, H\\ :sub:`1`? Den eneste forskjellen mellom "
"nullhypotesen og alternativhypotesen er at vi tillater at hver gruppe har et "
"forskjellig populasjonsgjennomsnitt. Så hvis vi lar µ\\ :sub:`k` betegne "
"populasjonsgjennomsnittet for den *k*-tredje gruppen i eksperimentet vårt, "
"er den statistiske modellen som svarer til H\\ :sub:`1`"

#: ../../Ch13/Ch13_ANOVA_02.rst:338
msgid "|Y_ik| = µ\\ :sub:`k` + ϵ\\ :sub:`ik`"
msgstr "|Y_ik| = µ\\ :sub:`k` + ϵ\\ :sub:`ik`"

#: ../../Ch13/Ch13_ANOVA_02.rst:340
msgid ""
"where, once again, we assume that the error terms are normally distributed "
"with mean 0 and standard deviation σ. That is, the alternative hypothesis "
"also assumes that ϵ ~ Normal(0, σ²)"
msgstr ""
"hvor vi igjen antar at residuene er normalfordelte med gjennomsnitt 0 og "
"standardavvik σ. Det vil si at alternativhypotesen også forutsetter at ϵ ~ "
"Normal(0, σ²)"

#: ../../Ch13/Ch13_ANOVA_02.rst:345
msgid ""
"Okay, now that we’ve described the statistical models underpinning H\\ :sub:"
"`0` and H\\ :sub:`1` in more detail, it’s now pretty straightforward to say "
"what the mean square values are measuring, and what this means for the "
"interpretation of *F*. I won’t bore you with the proof of this but it turns "
"out that the within-groups mean square, |MS_w|, can be viewed as an "
"estimator (in the technical sense, chapter :doc:`../Ch08/Ch08_Estimation`) "
"of the error variance σ². The between-groups mean square |MS_b| is also an "
"estimator, but what it estimates is the error variance *plus* a quantity "
"that depends on the true differences among the group means. If we call this "
"quantity *Q*, then we can see that the *F*-statistic is basically:\\ [#]_"
msgstr ""
"Nå som vi har beskrevet de statistiske modellene som ligger til grunn for "
"H\\ :sub:`0` og H\\ :sub:`1` i mer detalj, er det nå ganske enkelt å si hva "
"de gjennomsnittlige kvadratsummene (*mean squares*; MS) måler, og hva dette "
"betyr for tolkningen av *F*. Jeg skal ikke kjede deg med beviset for dette, "
"men det viser seg at gjennomsnittskvadratet innenfor grupper, |MS_w|, kan "
"betraktes som en estimator (i teknisk forstand, se kapittel :doc:`../Ch08/"
"Ch08_Estimation`) av feilvariansen σ². Mellomgruppe-gjennomsnittskvadratet |"
"MS_b| er også en estimator, men det den estimerer, er feilvariansen *pluss* "
"en størrelse som avhenger av de sanne forskjellene mellom "
"gruppegjennomsnittene. Hvis vi kaller denne størrelsen *Q*, kan vi se at *F*-"
"statistikken i bunn og grunn er:\\ [#]_"

#: ../../Ch13/Ch13_ANOVA_02.rst:356
msgid ""
"F = \\frac{\\hat{Q} + \\hat\\sigma^2}{\\hat\\sigma^2}\n"
"\n"
msgstr ""
"F = \\frac{\\hat{Q} + \\hat\\sigma^2}{\\hat\\sigma^2}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:358
msgid ""
"where the true value *Q* = 0 if the null hypothesis is true, and *Q* > 0 if "
"the alternative hypothesis is true (:ref:`Hays, 1994 <Hays_1994>`, Ch. 10). "
"Therefore, at a bare minimum *the F-value must be larger than 1* to have any "
"chance of rejecting the null hypothesis. Note that this *doesn’t* mean that "
"it’s impossible to get an *F*-value less than 1. What it means is that if "
"the null hypothesis is true the sampling distribution of the *F*-ratio has a "
"mean of 1,\\ [#]_ and so we need to see *F*-values larger than 1 in order to "
"safely reject the null."
msgstr ""
"der den sanne verdien *Q* = 0 hvis nullhypotesen er sann, og *Q* > 0 hvis "
"alternativhypotesen er sann (:ref:`Hays, 1994 <Hays_1994>`, kap. 10). F-"
"verdien må derfor som et minimum *være større enn 1* for å ha en sjanse til "
"å forkaste nullhypotesen. Merk at dette *ikke* betyr at det er umulig å få "
"en *F*-verdi mindre enn 1. Det betyr at hvis nullhypotesen er sann, har "
"utvalgsfordelingen av *F*-forholdet et gjennomsnitt på 1,\\ [#]_, og derfor "
"må vi se *F*-verdier som er større enn 1 for å kunne forkaste nullhypotesen "
"med sikkerhet."

#: ../../Ch13/Ch13_ANOVA_02.rst:367
msgid ""
"To be a bit more precise about the sampling distribution, notice that if the "
"null hypothesis is true, both |MS_b| and |MS_w| are estimators of the "
"variance of the residuals ϵ\\ :sub:`ik`. If those residuals are normally "
"distributed, then you might suspect that the estimate of the variance of "
"ϵ\\ :sub:`ik` is χ²-distributed, because (as discussed in :doc:`../Ch07/"
"Ch07_Probability_6`) that’s what a χ²-distribution *is*: it’s what you get "
"when you square a bunch of normally-distributed things and add them up. And "
"since the *F*-distribution is (again, by definition) what you get when you "
"take the ratio between two things that are χ² distributed, we have our "
"sampling distribution. Obviously, I’m glossing over a whole lot of stuff "
"when I say this, but in broad terms, this really is where our sampling "
"distribution comes from."
msgstr ""
"For å være litt mer presis om utvalgsfordelingen, legg merke til at hvis "
"nullhypotesen er sann, er både |MS_b| og |MS_w| estimatorer av variansen til "
"residuene ϵ\\ :sub:`ik`. Hvis disse residuene er normalfordelte, kan du "
"mistenke at estimatet av variansen til ϵ\\ :sub:`ik` er χ²-fordelt, fordi "
"(som diskutert i :doc:`../Ch07/Ch07_Probability_6`) det er det en χ²-"
"fordeling *er*: det er det du får når du kvadrerer en haug med "
"normalfordelte ting og legger dem sammen. Og siden *F*-fordelingen (igjen, "
"per definisjon) er det du får når du tar forholdet mellom to ting som er χ²-"
"fordelt, har vi utvalgsfordelingen vår. Jeg hopper selvsagt over en hel "
"masse ting når jeg sier dette, men i grove trekk er det dette som er "
"utgangspunktet for utvalgsfordelingen vår."

#: ../../Ch13/Ch13_ANOVA_02.rst:382
msgid "A worked example"
msgstr "Et gjennomarbeidet eksempel"

#: ../../Ch13/Ch13_ANOVA_02.rst:384
msgid ""
"The previous discussion was fairly abstract and a little on the technical "
"side, so I think that at this point it might be useful to see a worked "
"example. For that, let’s go back to the |clinicaltrial|_ data set that was "
"introduced earlier in the chapter. The descriptive statistics that we "
"calculated at the beginning tell us our group means: An average mood gain of "
"0.45 for the placebo, 0.72 for Anxifree, and 1.48 for Joyzepam. With that in "
"mind, let’s party like it’s 1899\\ [#]_ and start doing some pencil and "
"paper calculations. I’ll only do this for the first 5 observations because "
"it’s not bloody 1899 and I’m very lazy. Let’s start by calculating |SS_w|, "
"the within-group sums of squares. First, let’s draw up a nice table to help "
"us with our calculations:"
msgstr ""
"Den forrige diskusjonen var ganske abstrakt og litt teknisk, så jeg tror det "
"kan være nyttig å se et fungerende eksempel nå. La oss derfor gå tilbake til "
"datasettet |clinicaltrial|_ som ble introdusert tidligere i kapittelet. Den "
"deskriptive statistikken som vi beregnet i begynnelsen, forteller oss "
"gruppegjennomsnittet: En gjennomsnittlig humørforbedring på 0,45 for "
"placebo, 0,72 for Anxifree og 1,48 for Joyzepam. Med det i bakhodet, la oss "
"feste som om det er 1899\\ [#]_ og begynne å gjøre noen beregninger med "
"blyant og papir. Jeg gjør dette bare for de første fem observasjonene, fordi "
"det ikke er 1899, og jeg er veldig lat. La oss begynne med å beregne |SS_w|, "
"kvadratsummene innenfor gruppene. La oss først lage en fin tabell for å "
"hjelpe oss med beregningene:"

#: ../../Ch13/Ch13_ANOVA_02.rst:397 ../../Ch13/Ch13_ANOVA_02.rst:423
#: ../../Ch13/Ch13_ANOVA_02.rst:444
msgid "outcome"
msgstr "resultat"

#: ../../Ch13/Ch13_ANOVA_02.rst:399 ../../Ch13/Ch13_ANOVA_02.rst:425
#: ../../Ch13/Ch13_ANOVA_02.rst:446
msgid "|Y_ik|"
msgstr "|Y_ik|"

#: ../../Ch13/Ch13_ANOVA_02.rst:401 ../../Ch13/Ch13_ANOVA_02.rst:403
#: ../../Ch13/Ch13_ANOVA_02.rst:405 ../../Ch13/Ch13_ANOVA_02.rst:427
#: ../../Ch13/Ch13_ANOVA_02.rst:429 ../../Ch13/Ch13_ANOVA_02.rst:431
#: ../../Ch13/Ch13_ANOVA_02.rst:448 ../../Ch13/Ch13_ANOVA_02.rst:450
#: ../../Ch13/Ch13_ANOVA_02.rst:452 ../../Ch13/Ch13_ANOVA_02.rst:494
#: ../../Ch13/Ch13_ANOVA_02.rst:524
msgid "placebo"
msgstr "placebo"

#: ../../Ch13/Ch13_ANOVA_02.rst:401 ../../Ch13/Ch13_ANOVA_02.rst:427
#: ../../Ch13/Ch13_ANOVA_02.rst:448 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.5"
msgstr "0.5"

#: ../../Ch13/Ch13_ANOVA_02.rst:403 ../../Ch13/Ch13_ANOVA_02.rst:429
#: ../../Ch13/Ch13_ANOVA_02.rst:450 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.3"
msgstr "0.3"

#: ../../Ch13/Ch13_ANOVA_02.rst:405 ../../Ch13/Ch13_ANOVA_02.rst:431
#: ../../Ch13/Ch13_ANOVA_02.rst:452 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.1"
msgstr "0.1"

#: ../../Ch13/Ch13_ANOVA_02.rst:407 ../../Ch13/Ch13_ANOVA_02.rst:409
#: ../../Ch13/Ch13_ANOVA_02.rst:433 ../../Ch13/Ch13_ANOVA_02.rst:435
#: ../../Ch13/Ch13_ANOVA_02.rst:454 ../../Ch13/Ch13_ANOVA_02.rst:456
#: ../../Ch13/Ch13_ANOVA_02.rst:496 ../../Ch13/Ch13_ANOVA_02.rst:526
msgid "anxifree"
msgstr "anxifree"

#: ../../Ch13/Ch13_ANOVA_02.rst:407 ../../Ch13/Ch13_ANOVA_02.rst:433
#: ../../Ch13/Ch13_ANOVA_02.rst:454 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.6"
msgstr "0.6"

#: ../../Ch13/Ch13_ANOVA_02.rst:409 ../../Ch13/Ch13_ANOVA_02.rst:435
#: ../../Ch13/Ch13_ANOVA_02.rst:456 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.4"
msgstr "0.4"

#: ../../Ch13/Ch13_ANOVA_02.rst:412
msgid ""
"At this stage, the only thing I’ve included in the table is the raw data "
"itself. That is, the grouping variable (i.e., ``drug``) and outcome variable "
"(i.e. ``mood.gain``) for each person. Note that the outcome variable here "
"corresponds to the |Y_ik| value in our equation previously. The next step in "
"the calculation is to write down, for each person in the study, the "
"corresponding group mean, |Yb_k|. This is slightly repetitive but not "
"particularly difficult since we already calculated those group means when "
"doing our descriptive statistics:"
msgstr ""
"På dette stadiet er det eneste jeg har inkludert i tabellen, selve "
"rådataene. Det vil si grupperingsvariabelen (dvs. ``drug``) og "
"utfallsvariabelen (dvs. ``mood.gain``) for hver person. Merk at "
"utfallsvariabelen her tilsvarer |Y_ik|-verdien i ligningen vår tidligere. "
"Det neste trinnet i beregningen er å skrive ned det tilsvarende "
"gruppegjennomsnittet, |Yb_k|, for hver person i studien. Dette er litt "
"repeterende, men ikke spesielt vanskelig, siden vi allerede har beregnet "
"disse gruppegjennomsnittene i forbindelse med den deskriptive statistikken:"

#: ../../Ch13/Ch13_ANOVA_02.rst:423 ../../Ch13/Ch13_ANOVA_02.rst:444
#: ../../Ch13/Ch13_ANOVA_02.rst:490
msgid "group mean"
msgstr "gruppegjennomsnitt"

#: ../../Ch13/Ch13_ANOVA_02.rst:425 ../../Ch13/Ch13_ANOVA_02.rst:446
#: ../../Ch13/Ch13_ANOVA_02.rst:492
msgid "|Yb_k|"
msgstr "|Yb_k|"

#: ../../Ch13/Ch13_ANOVA_02.rst:427 ../../Ch13/Ch13_ANOVA_02.rst:429
#: ../../Ch13/Ch13_ANOVA_02.rst:431
msgid "**0.45**"
msgstr "**0.45**"

#: ../../Ch13/Ch13_ANOVA_02.rst:433 ../../Ch13/Ch13_ANOVA_02.rst:435
msgid "**0.72**"
msgstr "**0.72**"

#: ../../Ch13/Ch13_ANOVA_02.rst:438
msgid ""
"Now that we’ve written those down, we need to calculate, again for every "
"person, the deviation from the corresponding group mean. That is, we want to "
"subtract |Y_ik| - |Yb_k|. After we’ve done that, we need to square "
"everything. When we do that, here’s what we get:"
msgstr ""
"Nå som vi har skrevet dem ned, må vi igjen beregne avviket fra det "
"tilsvarende gruppegjennomsnittet for hver person. Det vil si at vi ønsker å "
"trekke fra |Y_ik| - |Yb_k|. Etter at vi har gjort det, må vi kvadrere alt. "
"Når vi gjør det, får vi følgende resultat:"

#: ../../Ch13/Ch13_ANOVA_02.rst:444
msgid "dev. from group mean"
msgstr "avvik fra gruppegjennomsnittet"

#: ../../Ch13/Ch13_ANOVA_02.rst:444
msgid "squared deviation"
msgstr "kvadrert avvik"

#: ../../Ch13/Ch13_ANOVA_02.rst:446
msgid "(|Y_ik| - |Yb_k|)"
msgstr "(|Y_ik| - |Yb_k|)"

#: ../../Ch13/Ch13_ANOVA_02.rst:446
msgid "(|Y_ik| - |Yb_k|\\)²"
msgstr "(|Y_ik| - |Yb_k|\\)²"

#: ../../Ch13/Ch13_ANOVA_02.rst:448 ../../Ch13/Ch13_ANOVA_02.rst:450
#: ../../Ch13/Ch13_ANOVA_02.rst:452 ../../Ch13/Ch13_ANOVA_02.rst:494
msgid "0.45"
msgstr "0.45"

#: ../../Ch13/Ch13_ANOVA_02.rst:448
msgid "**0.05**"
msgstr "**0.05**"

#: ../../Ch13/Ch13_ANOVA_02.rst:448
msgid "**0.0025**"
msgstr "**0.0025**"

#: ../../Ch13/Ch13_ANOVA_02.rst:450
msgid "**-0.15**"
msgstr "**-0.15**"

#: ../../Ch13/Ch13_ANOVA_02.rst:450
msgid "**0.0225**"
msgstr "**0.0225**"

#: ../../Ch13/Ch13_ANOVA_02.rst:452
msgid "**-0.35**"
msgstr "**-0.35**"

#: ../../Ch13/Ch13_ANOVA_02.rst:452
msgid "**0.1225**"
msgstr "**0.1225**"

#: ../../Ch13/Ch13_ANOVA_02.rst:454 ../../Ch13/Ch13_ANOVA_02.rst:456
#: ../../Ch13/Ch13_ANOVA_02.rst:496
msgid "0.72"
msgstr "0.72"

#: ../../Ch13/Ch13_ANOVA_02.rst:454
msgid "**-0.12**"
msgstr "**-0.12**"

#: ../../Ch13/Ch13_ANOVA_02.rst:454
msgid "**0.0136**"
msgstr "**0.0136**"

#: ../../Ch13/Ch13_ANOVA_02.rst:456
msgid "**-0.32**"
msgstr "**-0.32**"

#: ../../Ch13/Ch13_ANOVA_02.rst:456
msgid "**0.1003**"
msgstr "**0.1003**"

#: ../../Ch13/Ch13_ANOVA_02.rst:459
msgid ""
"The last step is equally straightforward. In order to calculate the within-"
"group sum of squares we just add up the squared deviations across all "
"observations:"
msgstr ""
"Det siste trinnet er like enkelt. For å beregne kvadratsummen innenfor "
"gruppene summerer vi bare de kvadrerte avvikene på tvers av alle "
"observasjonene:"

#: ../../Ch13/Ch13_ANOVA_02.rst:463
msgid "|SS_w| = 0.0025 + 0.0225 + 0.1225 + 0.0136 + 0.1003 = 0.2614"
msgstr "|SS_w| = 0.0025 + 0.0225 + 0.1225 + 0.0136 + 0.1003 = 0.2614"

#: ../../Ch13/Ch13_ANOVA_02.rst:465
msgid ""
"Of course, if we actually wanted to get the *right* answer we’d need to do "
"this for all 18 observations in the data set, not just the first five. We "
"could continue with the pencil and paper calculations if we wanted to, but "
"it’s pretty tedious. Alternatively, it’s not too hard to do this in jamovi."
msgstr ""
"Hvis vi faktisk ønsker å finne det *riktige* svaret, må vi selvfølgelig "
"gjøre dette for alle de 18 observasjonene i datasettet, ikke bare de fem "
"første. Vi kan fortsette med blyant- og papirberegningene hvis vi vil, men "
"det er ganske kjedelig. Alternativt er det ikke så vanskelig å gjøre dette i "
"jamovi."

#: ../../Ch13/Ch13_ANOVA_02.rst:471
msgid ""
"Go to an empty column (at the end of the data set) and double click on the "
"column header, choose ``New computed variable`` and enter ``sq_res_wth`` in "
"the first line and the formula ``(mood.gain - VMEAN(mood.gain, group_by = "
"drug)) ^ 2`` in the line starting with ``=`` (next to the *f*\\ :sub:`x`). "
"``mood.gain`` represents |Y_ik|, ``VMEAN(mood.gain, group_by = drug)`` the "
"group mean |Yb_k|. This difference (third column in the table above) is then "
"squared and it is therefore not much surprise to see that the values are "
"(apart from rounding errors) identical to those in the last column of the "
"table above."
msgstr ""
"Gå til en tom kolonne (på slutten av datasettet) og dobbeltklikk på "
"kolonneoverskriften, velg ``New computed variable`` og skriv inn "
"``sq_res_wth`` i første linje og formelen ``(mood.gain - VMEAN(mood.gain, "
"group_by = drug)) ^ 2`` i linjen som begynner med ``=`` (ved siden av *f*\\ :"
"sub:`x`). ``mood.gain`` representerer |Y_ik|, ``VMEAN(mood.gain, group_by = "
"drug)`` gruppegjennomsnittet |Yb_k|. Denne differansen (tredje kolonne i "
"tabellen ovenfor) er deretter kvadrert, og det er derfor ikke så "
"overraskende at verdiene (bortsett fra avrundingsfeil) er identiske med "
"verdiene i den siste kolonnen i tabellen ovenfor."

#: ../../Ch13/Ch13_ANOVA_02.rst:481
msgid ""
"Okay. Now that we’ve calculated the within groups variation, |SS_w|, it’s "
"time to turn our attention to the between-group sum of squares, |SS_b|. The "
"calculations for this case are very similar. The main difference is that "
"instead of calculating the differences between an observation |Y_ik| and a "
"group mean |Yb_k| for all of the observations, we calculate the differences "
"between the group means |Yb_k| and the grand mean |Yb| (in this case 0.88) "
"for all of the groups."
msgstr ""
"Nå som vi har beregnet variasjonen innenfor gruppene, |SS_w|, er det på tide "
"å rette oppmerksomheten mot kvadratsummen mellom gruppene, |SS_b|. "
"Beregningene for dette tilfellet er veldig like. Hovedforskjellen er at i "
"stedet for å beregne forskjellene mellom en observasjon |Y_ik| og et "
"gruppegjennomsnitt |Yb_k| for alle observasjonene, beregner vi forskjellene "
"mellom gruppegjennomsnittet |Yb_k| og det totale gjennomsnittet |Yb| (i "
"dette tilfellet 0,88) for alle gruppene."

#: ../../Ch13/Ch13_ANOVA_02.rst:490
msgid "grand mean"
msgstr "totalt gjennomsnitt"

#: ../../Ch13/Ch13_ANOVA_02.rst:490
msgid "deviation"
msgstr "avvik"

#: ../../Ch13/Ch13_ANOVA_02.rst:490 ../../Ch13/Ch13_ANOVA_02.rst:520
msgid "squared deviations"
msgstr "kvadrerte avvik"

#: ../../Ch13/Ch13_ANOVA_02.rst:492
msgid "|Yb|"
msgstr "|Yb|"

#: ../../Ch13/Ch13_ANOVA_02.rst:492
msgid "|Yb_k| - |YB|"
msgstr "|Yb_k| - |YB|"

#: ../../Ch13/Ch13_ANOVA_02.rst:492 ../../Ch13/Ch13_ANOVA_02.rst:522
msgid "(|Yb_k| - |Yb|)²"
msgstr "(|Yb_k| - |Yb|)²"

#: ../../Ch13/Ch13_ANOVA_02.rst:494 ../../Ch13/Ch13_ANOVA_02.rst:496
#: ../../Ch13/Ch13_ANOVA_02.rst:498
msgid "0.88"
msgstr "0.88"

#: ../../Ch13/Ch13_ANOVA_02.rst:494
msgid "-0.43"
msgstr "-0.43"

#: ../../Ch13/Ch13_ANOVA_02.rst:494 ../../Ch13/Ch13_ANOVA_02.rst:524
msgid "0.19"
msgstr "0.19"

#: ../../Ch13/Ch13_ANOVA_02.rst:496
msgid "-0.16"
msgstr "-0.16"

#: ../../Ch13/Ch13_ANOVA_02.rst:496 ../../Ch13/Ch13_ANOVA_02.rst:526
msgid "0.03"
msgstr "0.03"

#: ../../Ch13/Ch13_ANOVA_02.rst:498 ../../Ch13/Ch13_ANOVA_02.rst:528
msgid "joyzepam"
msgstr "joyzepam"

#: ../../Ch13/Ch13_ANOVA_02.rst:498
msgid "1.48"
msgstr "1.48"

#: ../../Ch13/Ch13_ANOVA_02.rst:498
msgid "0.60"
msgstr "0.60"

#: ../../Ch13/Ch13_ANOVA_02.rst:498 ../../Ch13/Ch13_ANOVA_02.rst:528
msgid "0.36"
msgstr "0.36"

#: ../../Ch13/Ch13_ANOVA_02.rst:501
msgid ""
"We create another computed variable with the name ``sq_res_btw`` and "
"``(VMEAN(mood.gain, group_by = drug) - VMEAN(mood.gain) - ) ^ 2`` as "
"formula. The term ``VMEAN(mood.gain, group_by = drug)`` represents the group "
"mean |Yb_k|, and ``VMEAN(mood.gain)`` the grand mean |Yb|. Again, we find "
"that the values for that variable are the same as in the last column of the "
"table above: the first three rows represent ``placebo``, followed by three "
"lines with ``anxifree`` and three lines with ``joyzepam``; the next nine "
"lines are a repetition of the first nine ones."
msgstr ""
"Vi oppretter en annen beregnet variabel med navnet ``sq_res_btw`` og "
"``(VMEAN(mood.gain, group_by = drug) - VMEAN(mood.gain) - ) ^ 2`` som "
"formel. Uttrykket ``VMEAN(mood.gain, group_by = drug)`` representerer "
"gruppegjennomsnittet |Yb_k|, og ``VMEAN(mood.gain)`` det totale "
"gjennomsnittet |Yb|. Igjen ser vi at verdiene for denne variabelen er de "
"samme som i den siste kolonnen i tabellen ovenfor: De tre første radene "
"representerer ``placebo``, etterfulgt av tre rader med ``anxifree`` og tre "
"rader med ``joyzepam``; de neste ni radene er en repetisjon av de ni første."

#: ../../Ch13/Ch13_ANOVA_02.rst:510
msgid ""
"However, for the between group calculations we need to multiply each of "
"these squared deviations by |N_k|, the number of observations in the group. "
"We do this because every *observation* in the group (all |N_k| of them) is "
"associated with a between group difference. So if there are six people in "
"the placebo group and the placebo group mean differs from the grand mean by "
"0.19, then the *total* between group variation associated with these six "
"people is 6 · 0.19 = 1.14. So we have to extend our little table of "
"calculations:"
msgstr ""
"For beregningene mellom grupper må vi imidlertid multiplisere hvert av disse "
"kvadrerte avvikene med |N_k|, antall observasjoner i gruppen. Vi gjør dette "
"fordi hver *observasjon* i gruppen (alle |N_k| av dem) er forbundet med en "
"mellomgruppeforskjell. Så hvis det er seks personer i placebogruppen, og "
"placebogruppens gjennomsnitt avviker fra det totale gjennomsnittet med 0,19, "
"er den *totale* variasjonen mellom gruppene knyttet til disse seks personene "
"6 - 0,19 = 1,14. Så vi må utvide den lille utregningstabellen vår:"

#: ../../Ch13/Ch13_ANOVA_02.rst:520 ../../Ch13/Ch13_ANOVA_02.rst:522
#: ../../Ch13/Ch13_ANOVA_02.rst:524 ../../Ch13/Ch13_ANOVA_02.rst:526
#: ../../Ch13/Ch13_ANOVA_02.rst:528
msgid "…"
msgstr "…"

#: ../../Ch13/Ch13_ANOVA_02.rst:520
msgid "sample size"
msgstr "utvalgsstørrelse"

#: ../../Ch13/Ch13_ANOVA_02.rst:520
msgid "weighted squared deviat."
msgstr "vektet kvadrert avvik."

#: ../../Ch13/Ch13_ANOVA_02.rst:522
msgid "|N_k|"
msgstr "|N_k|"

#: ../../Ch13/Ch13_ANOVA_02.rst:522
msgid "|N_k| · (|Yb_k| - |Yb|)²"
msgstr "|N_k| · (|Yb_k| - |Yb|)²"

#: ../../Ch13/Ch13_ANOVA_02.rst:524 ../../Ch13/Ch13_ANOVA_02.rst:526
#: ../../Ch13/Ch13_ANOVA_02.rst:528 ../../Ch13/Ch13_ANOVA_05.rst:53
#: ../../Ch13/Ch13_ANOVA_07.rst:66 ../../Ch13/Ch13_ANOVA_07.rst:68
#: ../../Ch13/Ch13_ANOVA_07.rst:74 ../../Ch13/Ch13_ANOVA_07.rst:76
msgid "6"
msgstr "6"

#: ../../Ch13/Ch13_ANOVA_02.rst:524
msgid "1.14"
msgstr "1.14"

#: ../../Ch13/Ch13_ANOVA_02.rst:526
msgid "0.18"
msgstr "0.18"

#: ../../Ch13/Ch13_ANOVA_02.rst:528
msgid "2.16"
msgstr "2.16"

#: ../../Ch13/Ch13_ANOVA_02.rst:531
msgid ""
"And so now our between group sum of squares is obtained by summing these "
"“weighted squared deviations” over all three groups in the study:"
msgstr ""
"Nå får vi kvadratsummen mellom gruppene ved å summere disse «vektede "
"kvadrerte avvikene» (*weighted squared deviations*) over alle de tre "
"gruppene i studien:"

#: ../../Ch13/Ch13_ANOVA_02.rst:534
msgid "|SS_b| = 1.14 + 0.18 + 2.16 = 3.48"
msgstr "|SS_b| = 1.14 + 0.18 + 2.16 = 3.48"

#: ../../Ch13/Ch13_ANOVA_02.rst:536
msgid ""
"As you can see, the between group calculations are a lot shorter (when "
"calculated b hand)."
msgstr ""
"Som du kan se, er beregningene mellom gruppene mye kortere (når de beregnes "
"for hånd)."

#: ../../Ch13/Ch13_ANOVA_02.rst:539
msgid ""
"In jamovi, we can calculate these sums, i.e., the values for |SS_b| and |"
"SS_w|, by clicking ``Descriptives`` →  ``Descriptive Statistics``, then "
"moving ``sq_res_wth`` and ``sq_res_btw`` to the ``Variables`` box, and "
"finally selecting ``Sum`` from the ``Statistics`` drop-down menu. The sum of "
"``sq_res_wth`` (|SS_w|) has a value of **1.392**, ``sq_res_wth`` (|SS_b|) a "
"value of **3.453** (just rounding errors away from the 3.48 we calculated "
"above)."
msgstr ""
"I jamovi kan vi beregne disse summene, dvs. verdiene for |SS_b| og |SS_w|, "
"ved å klikke på ``Descriptives`` → ``Descriptive Statistics``, deretter "
"flytte ``sq_res_wth`` og ``sq_res_btw`` til ``Variables``-boksen, og til "
"slutt velge ``Sum`` fra rullegardinmenyen ``Statistics``. Summen av "
"``sq_res_wth`` (|SS_w|) har en verdi på **1,392**, ``sq_res_wth`` (|SS_b|) "
"en verdi på **3,453** (bare avrundingsfeil fra de 3,48 vi beregnet ovenfor)."

#: ../../Ch13/Ch13_ANOVA_02.rst:547
msgid ""
"Now that we’ve calculated our sums of squares values, |SS_b| and |SS_w|, the "
"rest of the ANOVA is pretty painless. The next step is to calculate the "
"degrees of freedom. Since we have *G* = 3 groups and *N* = 18 observations "
"in total our degrees of freedom can be calculated by simple subtraction:"
msgstr ""
"Nå som vi har beregnet kvadratsummene våre, |SS_b| og |SS_w|, er resten av "
"ANOVA ganske smertefritt. Neste trinn er å beregne frihetsgradene. Siden vi "
"har *G* = 3 grupper og *N* = 18 observasjoner totalt, kan frihetsgradene "
"våre beregnes ved enkel subtraksjon:"

#: ../../Ch13/Ch13_ANOVA_02.rst:552
msgid "|df_b| = *G* - 1 = 2 |df_w| = *N* - *G* = 15"
msgstr "|df_b| = *G* - 1 = 2 |df_w| = *N* - *G* = 15"

#: ../../Ch13/Ch13_ANOVA_02.rst:555
msgid ""
"Next, since we’ve now calculated the values for the sums of squares and the "
"degrees of freedom, for both the within-groups variability and the between-"
"groups variability, we can obtain the mean square values by dividing one by "
"the other:"
msgstr ""
"Siden vi nå har beregnet verdiene for kvadratsummene og frihetsgradene, både "
"for variabiliteten innenfor gruppene og variabiliteten mellom gruppene, kan "
"vi finne de gjennomsnittlige kvadratsummene (*mean squares*; MS) ved å "
"dividere den ene med den andre:"

#: ../../Ch13/Ch13_ANOVA_02.rst:560
msgid ""
"\\begin{array}{lclclcl}\n"
"\\mbox{MS}_b &=& \\displaystyle\\frac{\\mbox{SS}_b }{  \\mbox{df}_b } &=& "
"\\displaystyle\\frac{3.453}{ 2} &=& 1.727 \\\\\n"
"\\mbox{MS}_w &=& \\displaystyle\\frac{\\mbox{SS}_w }{  \\mbox{df}_w } &=& "
"\\displaystyle\\frac{1.392}{15} &=& 0.093\n"
"\\end{array}"
msgstr ""
"\\begin{array}{lclclcl}\n"
"\\mbox{MS}_b &=& \\displaystyle\\frac{\\mbox{SS}_b }{  \\mbox{df}_b } &=& "
"\\displaystyle\\frac{3.453}{ 2} &=& 1.727 \\\\\n"
"\\mbox{MS}_w &=& \\displaystyle\\frac{\\mbox{SS}_w }{  \\mbox{df}_w } &=& "
"\\displaystyle\\frac{1.392}{15} &=& 0.093\n"
"\\end{array}"

#: ../../Ch13/Ch13_ANOVA_02.rst:567
msgid ""
"We’re almost done. The mean square values can be used to calculate the *F*-"
"value, which is the test statistic that we’re interested in. We do this by "
"dividing the between-groups MS value by the within-groups MS value.\\ [#]_"
msgstr ""
"Vi er nesten ferdige. De gjennomsnittlige kvadratsummene kan brukes til å "
"beregne *F*-verdien, som er den teststatistikken vi er interessert i. Dette "
"gjør vi ved å dividere MS-verdien mellom gruppene med MS-verdien innenfor "
"gruppene.\\ [#]_"

#: ../../Ch13/Ch13_ANOVA_02.rst:572
msgid ""
"F = \\frac{\\mbox{MS}_b }{\\mbox{MS}_w} = \\frac{1.727}{0.093} = 18.611\n"
"\n"
msgstr ""
"F = \\frac{\\mbox{MS}_b }{\\mbox{MS}_w} = \\frac{1.727}{0.093} = 18.611\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:574
msgid ""
"Woohooo! This is terribly exciting, yes? Now that we have our test "
"statistic, the last step is to find out whether the test itself gives us a "
"significant result. As discussed in chapter :doc:`../Ch09/"
"Ch09_HypothesisTesting` back in the “old days” what we’d do is open up a "
"statistics textbook or flick to the back section which would actually have a "
"huge lookup table and we would find the threshold *F*-value corresponding to "
"a particular value of α (the null hypothesis rejection region), e.g. 0.05, "
"0.01 or 0.001, for 2 and 15 degrees of freedom. Doing it this way would give "
"us a threshold *F*-value for an α of 0.001 of 11.34. As this is less than "
"our calculated *F*-value we say that *p* < 0.001. But those were the old "
"days, and nowadays fancy stats software calculates the exact *p*-value for "
"you. In fact, the exact *p*-value is 0.000086. So, unless we’re being "
"*extremely* conservative about our Type I error rate, we’re pretty much "
"guaranteed to reject the null hypothesis."
msgstr ""
"Woohooo! Dette er fryktelig spennende, ikke sant? Nå som vi har "
"teststatistikken vår, er det siste steget å finne ut om selve testen gir oss "
"et signifikant resultat. Som diskutert i kapittel :doc:`../Ch09/"
"Ch09_HypothesisTesting` i «gamle dager» åpnet vi en lærebok i statistikk "
"eller bladde til bakerste del, som faktisk hadde en enorm oppslagstabell, og "
"fant terskelverdien *F* som tilsvarte en bestemt verdi av α (nullhypotesens "
"forkastelsesområde), f.eks. 0,05, 0,01 eller 0,001, for 2 og 15 "
"frihetsgrader. Hvis vi gjør det på denne måten, får vi en terskel *F*-verdi "
"for en α på 0,001 på 11,34. Siden dette er mindre enn vår beregnede *F*-"
"verdi, sier vi at *p* < 0,001. Men det var i gamle dager, og i dag beregner "
"fancy statistikkprogramvare den nøyaktige *p*-verdien for deg. Faktisk er "
"den eksakte *p*-verdien 0,000086. Så med mindre vi er *ekstremt* "
"konservative når det gjelder type I-feilprosent, er vi så godt som garantert "
"å forkaste nullhypotesen."

#: ../../Ch13/Ch13_ANOVA_02.rst:588
msgid ""
"At this point, we’re basically done. Having completed our calculations, it’s "
"traditional to organise all these numbers into an ANOVA table like the one "
"in :numref:`tab-anovatable`. For our |clinicaltrial|_ data, the ANOVA table "
"would look like this:\\ [#]_"
msgstr ""
"På dette tidspunktet er vi i utgangspunktet ferdige. Etter å ha fullført "
"beregningene våre er det tradisjonelt å organisere alle disse tallene i en "
"ANOVA-tabell som den i :numref:`tab-anovatable`. For våre |clinicaltrial|_-"
"data vil ANOVA-tabellen se slik ut:\\ [#]_"

#: ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "3.453"
msgstr "3.453"

#: ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "1.727"
msgstr "1.727"

#: ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "18.611"
msgstr "18.611"

#: ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "0.000086"
msgstr "0.000086"

#: ../../Ch13/Ch13_ANOVA_02.rst:598
msgid "15"
msgstr "15"

#: ../../Ch13/Ch13_ANOVA_02.rst:598
msgid "1.392"
msgstr "1.392"

#: ../../Ch13/Ch13_ANOVA_02.rst:598
msgid "0.093"
msgstr "0.093"

#: ../../Ch13/Ch13_ANOVA_02.rst:601
msgid ""
"These days, you’ll probably never have much reason to want to construct one "
"of these tables yourself, but you will find that almost all statistical "
"software (jamovi included) tends to organise the output of an ANOVA into a "
"table like this, so it’s a good idea to get used to reading them. However, "
"although the software will output a full ANOVA table, there’s almost never a "
"good reason to include the whole table in your write up. A pretty standard "
"way of reporting this result would be to write something like this:"
msgstr ""
"I dag vil du sannsynligvis aldri ha noen grunn til å lage en slik tabell "
"selv, men du vil oppdage at nesten all statistisk programvare (jamovi "
"inkludert) har en tendens til å organisere resultatet av en ANOVA i en slik "
"tabell, så det er lurt å bli vant til å lese dem. Selv om programvaren vil "
"vise en fullstendig ANOVA-tabell, er det imidlertid nesten aldri noen god "
"grunn til å ta med hele tabellen i rapporten. En ganske vanlig måte å "
"rapportere dette resultatet på ville være å skrive noe sånt som dette:"

#: ../../Ch13/Ch13_ANOVA_02.rst:610
msgid ""
"One-way ANOVA showed a significant effect of drug on mood gain: *F*\\(2,15) "
"= 18.61, *p* < 0.001."
msgstr ""
"Enveis ANOVA viste en signifikant effekt av legemiddelet på "
"humørforbedringen: *F*\\(2,15) = 18,61, *p* < 0,001."

#: ../../Ch13/Ch13_ANOVA_02.rst:613
msgid "Sigh. So much work for one short sentence."
msgstr "Sukk. Så mye arbeid for en kort setning."

#: ../../Ch13/Ch13_ANOVA_02.rst:618
msgid ""
"When all groups have the same number of observations, the experimental "
"design is said to be “balanced”. Balance isn’t such a big deal for one-way "
"ANOVA, which is the topic of this chapter. It becomes more important when "
"you start doing more complicated ANOVAs."
msgstr ""
"Når alle gruppene har like mange observasjoner, sier man at forsøksdesignet "
"er «balansert». Balanse er ikke så viktig for enveis ANOVA, som er temaet "
"for dette kapittelet. Det blir viktigere når du begynner å gjøre mer "
"kompliserte ANOVAer."

#: ../../Ch13/Ch13_ANOVA_02.rst:624
msgid ""
"|SS_w| is also referred to in an independent ANOVA as the error variance, or "
"SS\\ :sub:`error`"
msgstr ""
"|SS_w| refereres også til i en uavhengig ANOVA som feilvariansen, eller "
"SS\\ :sub:`error`"

#: ../../Ch13/Ch13_ANOVA_02.rst:628
msgid ""
"If you read ahead to chapter :doc:`../Ch14/Ch14_ANOVA2` and look at how the "
"“treatment effect” at level *k* of a factor is defined in terms of the α\\ :"
"sub:`k` values (see section :doc:`../Ch14/Ch14_ANOVA2_02`), it turns out "
"that *Q* refers to a weighted mean of the squared treatment effects, :math:"
"`Q = (\\sum_{k=1}^G N_k \\alpha_k^2)/(G-1)`."
msgstr ""
"Hvis du leser videre til kapittel :doc:`../Ch14/Ch14_ANOVA2` og ser på "
"hvordan «behandlingseffekten» (*treatment effect*) på nivå *k* av en faktor "
"er definert med hensyn til α\\ :sub:`k`-verdiene (se avsnitt :doc:`../Ch14/"
"Ch14_ANOVA2_02`), viser det seg at *Q* refererer til et vektet gjennomsnitt "
"av de kvadrerte behandlingseffektene, :math:`Q = (\\sum_{k=1}^G N_k "
"\\alpha_k^2)/(G-1)`."

#: ../../Ch13/Ch13_ANOVA_02.rst:635
msgid ""
"Or, if we want to be sticklers for accuracy, :math:`1 + \\frac{2}{df_2 - 2}`."
msgstr ""
"Eller, hvis vi skal være helt nøyaktige, :math:`1 + \\frac{2}{df_2 - 2}`."

#: ../../Ch13/Ch13_ANOVA_02.rst:639
msgid ""
"Or, to be precise, party like “it’s 1899 and we’ve got no friends and "
"nothing better to do with our time than do some calculations that wouldn’t "
"have made any sense in 1899 because ANOVA didn’t exist until about the "
"1920s”."
msgstr ""
"Eller, for å være mer presis, en fest som «det er 1899, og vi har ingen "
"venner og ikke noe bedre å gjøre enn å gjøre noen beregninger som ikke ville "
"ha gitt noen mening i 1899, fordi ANOVA ikke eksisterte før på 1920-tallet»."

#: ../../Ch13/Ch13_ANOVA_02.rst:645
msgid ""
"We could as well do this with creating yet another computed variable, named "
"``F`` using the formula ``(VSUM(sq_res_btw) / 2) / (VSUM(sq_res_wth) / 15)`` "
"which gives us 18.611 as value. If you could not reprodcuce the calculation "
"steps above, you can download and open the |clinicaltrial_anova|_ data set."
msgstr ""
"Vi kan like godt gjøre dette ved å opprette enda en beregnet variabel, kalt "
"``F`` ved hjelp av formelen ``(VSUM(sq_res_btw) / 2) / (VSUM(sq_res_wth) / "
"15)`` som gir oss 18,611 som verdi. Hvis du ikke kunne reprodusere "
"beregningstrinnene ovenfor, kan du laste ned og åpne datasettet |"
"clinicaltrial_anova|_."

#: ../../Ch13/Ch13_ANOVA_02.rst:652
msgid ""
"In order to see the *p*-value with a high number of decimal places, click on "
"the settings menu (``⋮``, top-right corner) and set the ``p-value format`` "
"to ``16 dp``."
msgstr ""
"For å se *p*-verdien med et høyt antall desimaler, klikker du på "
"innstillingsmenyen (``⋮``, øverst i høyre hjørne) og setter ``p-value "
"format`` til ``16 dp``."

#: ../../Ch13/Ch13_ANOVA_03.rst:4
msgid "Running an ANOVA in jamovi"
msgstr "Kjører en ANOVA i jamovi"

#: ../../Ch13/Ch13_ANOVA_03.rst:6
msgid ""
"I’m pretty sure I know what you’re thinking after reading the last section, "
"*especially* if you followed my advice and did all of that by pencil and "
"paper (i.e., in a spreadsheet) yourself. Doing the ANOVA calculations "
"yourself *sucks*. There’s quite a lot of calculations that we needed to do "
"along the way, and it would be tedious to have to do this over and over "
"again every time you wanted to do an ANOVA."
msgstr ""
"Jeg er ganske sikker på at jeg vet hva du tenker etter å ha lest den siste "
"delen, *spesielt* hvis du fulgte rådet mitt og gjorde alt dette med blyant "
"og papir (dvs. i et regneark) selv. Å gjøre ANOVA-beregningene selv *suger*. "
"Det er ganske mange beregninger vi måtte gjøre underveis, og det ville vært "
"kjedelig å måtte gjøre dette om og om igjen hver gang du ønsket å gjøre en "
"ANOVA."

#: ../../Ch13/Ch13_ANOVA_03.rst:14
msgid "Using jamovi to specify your ANOVA"
msgstr "Bruke jamovi til å spesifisere ANOVA"

#: ../../Ch13/Ch13_ANOVA_03.rst:16
msgid ""
"To make life easier for you, jamovi can do ANOVA… hurrah! Go to the "
"``ANOVA`` - ``ANOVA`` analysis, and move the ``mood.gain`` variable across "
"so it is in the ``Dependent Variable`` box, and then move the ``drug`` "
"variable across so it is in the ``Fixed Factors`` box. This should give the "
"results as shown in :numref:`fig-anova2`.\\ [#]_ Note I have also checked "
"the η² checkbox, pronounced “eta” squared, under the ``Effect Size`` option "
"and this is also shown on the results table. We will come back to effect "
"sizes a bit later."
msgstr ""
"For å gjøre livet enklere for deg, jamovi kan gjøre ANOVA… hurra! Opprett "
"analysen med ``ANOVA`` - ``ANOVA``, og flytt ``mood.gain``-variabelen over "
"slik at den er i ``Dependent Variable``-boksen, og flytt deretter ``drug``-"
"variabelen over slik at den er i ``Fixed Factors``-boksen. Dette skal gi "
"resultatene som vist i :numref:`fig-anova2`.\\ [#]_ Merk at jeg også har "
"krysset av for η², som uttales «eta kvadrat», under alternativet ``Effect "
"Size``, og dette vises også i resultattabellen. Vi kommer tilbake til "
"effektstørrelser litt senere."

#: ../../Ch13/Ch13_ANOVA_03.rst:27
msgid "``ANOVA`` results table for ``mood.gain`` by ``drug`` administered"
msgstr "``ANOVA`` resultattabell for ``mood.gain`` etter ``drug`` administrert"

#: ../../Ch13/Ch13_ANOVA_03.rst:31
msgid ""
"jamovi ``ANOVA`` results table for ``mood.gain`` by ``drug`` administered"
msgstr ""
"jamovi ``ANOVA`` resultattabell for ``mood.gain`` etter ``drug`` administrert"

#: ../../Ch13/Ch13_ANOVA_03.rst:35
msgid ""
"The jamovi results table shows you the sums of squares values, the degrees "
"of freedom, and a couple of other quantities that we’re not really "
"interested in right now. Notice, however, that jamovi doesn’t use the names "
"“between-group” and “within-group”. Instead, it tries to assign more "
"meaningful names. In our particular example, the *between groups* variance "
"corresponds to the effect that the ``drug`` has on the outcome variable, and "
"the *within groups* variance corresponds to the “leftover” variability so it "
"calls that the *residuals*. If we compare these numbers to the numbers that "
"I calculated by hand in section :ref:`A worked example <worked_example>`, "
"you can see that they’re more or less the same, apart from rounding errors. "
"The between groups sums of squares is SS\\ :sub:`b` = 3.45, the within "
"groups sums of squares is SS\\ :sub:`w` = 1.39, and the degrees of freedom "
"are 2 and 15 respectively. We also get the *F*-value and the *p*-value and, "
"again, these are more or less the same, give or take rounding errors, to the "
"numbers that we calculated ourselves when doing it the long and tedious way."
msgstr ""
"Resultattabellen i jamovi viser kvadratsummene, frihetsgradene og et par "
"andre størrelser som vi egentlig ikke er interessert i akkurat nå. Legg "
"imidlertid merke til at jamovi ikke bruker navnene «mellom "
"gruppene» (*between groups*) og «innenfor gruppene» (*within group*). I "
"stedet prøver den å tildele mer meningsfulle navn. I vårt eksempel tilsvarer "
"variansen *mellom gruppene* effekten som legemiddelet (``drug``) har på "
"utfallsvariabelen, og variansen *innenfor gruppene* tilsvarer den "
"«resterende» variabiliteten, så den kaller det for *residuene*. Hvis vi "
"sammenligner disse tallene med tallene som jeg beregnet for hånd i avsnitt :"
"ref:`Et bearbeidet eksempel <worked_example>`, kan du se at de er mer eller "
"mindre de samme, bortsett fra avrundingsfeil. Kvadratsummene mellom gruppene "
"er SS\\ :sub:`b` = 3,45, kvadratsummene innenfor gruppene er SS\\ :sub:`w` = "
"1,39, og frihetsgradene er henholdsvis 2 og 15. Vi får også *F*-verdien og "
"*p*-verdien, og igjen er disse mer eller mindre de samme, med eller uten "
"avrundingsfeil, som de tallene vi beregnet selv da vi gjorde det på den "
"lange og kjedelige måten."

#: ../../Ch13/Ch13_ANOVA_03.rst:54
msgid ""
"The jamovi results are more accurate than the ones in the text above, due to "
"rounding errors."
msgstr ""
"Resultatene fra jamovi er mer nøyaktige enn resultatene i teksten ovenfor, "
"på grunn av avrundingsfeil."

#: ../../Ch13/Ch13_ANOVA_04.rst:4
msgid "Effect size"
msgstr "Effektstørrelse"

#: ../../Ch13/Ch13_ANOVA_04.rst:6
msgid ""
"There’s a few different ways you could measure the effect size in an ANOVA, "
"but the most commonly used measures are η² (**eta squared**) and partial η². "
"For a one-way analysis of variance they’re identical to each other, so for "
"the moment I’ll just explain η². The definition of η² is actually really "
"simple"
msgstr ""
"Det finnes flere ulike måter å måle effektstørrelsen på i en ANOVA, men de "
"mest brukte målene er η² (**eta-kvadrat**) og partiell η². For en enveis "
"variansanalyse er de identiske, så for øyeblikket vil jeg bare forklare η². "
"Definisjonen av η² er faktisk veldig enkel"

#: ../../Ch13/Ch13_ANOVA_04.rst:13
msgid "η² = SS\\ :sub:`b` / SS\\ :sub:`tot`"
msgstr "η² = SS\\ :sub:`b` / SS\\ :sub:`tot`"

#: ../../Ch13/Ch13_ANOVA_04.rst:15
msgid ""
"That’s all it is. So when I look at the ANOVA table in :numref:`fig-anova2`, "
"I see that SS\\ :sub:`b`   = 3.45 and SS\\ :sub:`tot` = 3.45 + 1.39 = 4.84. "
"Thus we get an η² value of"
msgstr ""
"Det er alt det er. Så når jeg ser på ANOVA-tabellen i :numref:`fig-anova2`, "
"ser jeg at SS\\ :sub:`b` = 3,45 og SS\\ :sub:`tot` = 3,45 + 1,39 = 4,84. "
"Dermed får vi en η²-verdi på"

#: ../../Ch13/Ch13_ANOVA_04.rst:20
msgid "η² = 3.45 / 4.84 = 0.71"
msgstr "η² = 3.45 / 4.84 = 0.71"

#: ../../Ch13/Ch13_ANOVA_04.rst:22
msgid ""
"The interpretation of η² is equally straightforward. It refers to the "
"proportion of the variability in the outcome variable (``mood.gain``) that "
"can be explained in terms of the predictor (``drug``). A value of η² = 0 "
"means that there is no relationship at all between the two, whereas a value "
"of η = 1 means that the relationship is perfect. Better yet, the η² value is "
"very closely related to *R*\\², as discussed previously in subsection :doc:"
"`The *R*\\² (R-squared) value <../Ch12/Ch12_Regression_06>`, and has an "
"equivalent interpretation."
msgstr ""
"Tolkningen av η² er like enkel. Den viser til hvor stor andel av "
"variabiliteten i utfallsvariabelen (``mood.gain``) som kan forklares ved "
"hjelp av prediktoren (``drug``). En verdi på η² = 0 betyr at det ikke er "
"noen sammenheng mellom de to, mens en verdi på η = 1 betyr at sammenhengen "
"er perfekt. Enda bedre er det at η²-verdien er svært nært beslektet med "
"*R*\\², som diskutert tidligere i underavsnittet :doc:`*R*\\² (R-kvadrat)-"
"verdien <../Ch12/Ch12_Regression_06>`, og har en tilsvarende tolkning."

#: ../../Ch13/Ch13_ANOVA_04.rst:31
msgid ""
"Although many statistics text books suggest η² as the default effect size "
"measure in ANOVA, there’s an interesting `blog post <https://daniellakens."
"blogspot.com.au/2015/06/why-you-should-use-omega-squared.html>`__ by Daniel "
"Lakens suggesting that eta-squared is perhaps not the best measure of effect "
"size in real world data analysis, because it can be a biased estimator. "
"Usefully, there is also an option in jamovi to specify omega-squared (ω²), "
"which is less biased, alongside eta-squared."
msgstr ""
"Selv om mange lærebøker i statistikk foreslår η² som standard "
"effektstørrelsesmål i ANOVA, finnes det et interessant `blogginnlegg "
"<https://daniellakens.blogspot.com.au/2015/06/why-you-should-use-omega-"
"squared.html>`__ av Daniel Lakens som antyder at eta-kvadrat kanskje ikke er "
"det beste effektstørrelsesmålet i dataanalyse i den virkelige verden, fordi "
"det kan være en skjev estimator. Det er nyttig å merke seg at det også "
"finnes en opsjon i jamovi for å spesifisere omega-kvadrat (ω²), som er "
"mindre skjevt, i tillegg til eta-kvadrat."

#: ../../Ch13/Ch13_ANOVA_05.rst:4
msgid "Multiple comparisons and post-hoc tests"
msgstr "Multiple sammenligninger og post-hoc-tester"

#: ../../Ch13/Ch13_ANOVA_05.rst:6
msgid ""
"Any time you run an ANOVA with more than two groups and you end up with a "
"significant effect, the first thing you’ll probably want to ask is which "
"groups are actually different from one another. In our drugs example, our "
"null hypothesis was that all three drugs (placebo, Anxifree and Joyzepam) "
"have the exact same effect on mood. But if you think about it, the null "
"hypothesis is actually claiming *three* different things all at once here. "
"Specifically, it claims that:"
msgstr ""
"Hver gang du kjører en ANOVA med mer enn to grupper og ender opp med en "
"signifikant effekt, er det første du sannsynligvis vil spørre deg selv om "
"hvilke grupper som faktisk er forskjellige fra hverandre. I eksemplet med "
"legemiddel var nullhypotesen vår at alle tre legemidlene (placebo, Anxifree "
"og Joyzepam) har nøyaktig samme effekt på humøret. Men hvis du tenker over "
"det, hevder nullhypotesen faktisk *tre* forskjellige ting på en gang. "
"Nærmere bestemt hevder den at:"

#: ../../Ch13/Ch13_ANOVA_05.rst:14
msgid ""
"Your competitor’s drug (Anxifree) is no better than a placebo (i.e., µ\\ :"
"sub:`A` = µ\\ :sub:`P`)"
msgstr ""
"Konkurrentens legemiddel (Anxifree) er ikke bedre enn placebo (dvs. µ\\ :sub:"
"`A` = µ\\ :sub:`P`)"

#: ../../Ch13/Ch13_ANOVA_05.rst:17
msgid ""
"Your drug (Joyzepam) is no better than a placebo (i.e., µ\\ :sub:`J` = µ\\ :"
"sub:`P`)"
msgstr ""
"Legemidlet ditt (Joyzepam) er ikke bedre enn placebo (dvs. µ\\ :sub:`J` = "
"µ\\ :sub:`P`)"

#: ../../Ch13/Ch13_ANOVA_05.rst:20
msgid ""
"Anxifree and Joyzepam are equally effective (i.e., µ\\ :sub:`J` = µ\\ :sub:"
"`A`)"
msgstr ""
"Anxifree og Joyzepam er like effektive (dvs. µ\\ :sub:`J` = µ\\ :sub:`A`)"

#: ../../Ch13/Ch13_ANOVA_05.rst:23
msgid ""
"If any one of those three claims is false, then the null hypothesis is also "
"false. So, now that we’ve rejected our null hypothesis, we’re thinking that "
"*at least* one of those things isn’t true. But which ones? All three of "
"these propositions are of interest. Since you certainly want to know if your "
"new drug Joyzepam is better than a placebo, it would be nice to know how "
"well it stacks up against an existing commercial alternative (i.e., "
"Anxifree). It would even be useful to check the performance of Anxifree "
"against the placebo. Even if Anxifree has already been extensively tested "
"against placebos by other researchers, it can still be very useful to check "
"that your study is producing similar results to earlier work."
msgstr ""
"Hvis en av disse tre påstandene er usanne, er også nullhypotesen usann. Så "
"nå som vi har forkastet nullhypotesen, tenker vi at *mindst* én av disse "
"tingene ikke er sanne. Men hvilken av dem? Alle disse tre påstandene er av "
"interesse. Siden du absolutt ønsker å vite om ditt nye legemiddel Joyzepam "
"er bedre enn placebo, ville det vært fint å vite hvor godt det står seg i "
"forhold til et eksisterende kommersielt alternativ (f.eks. Anxifree). Det "
"ville til og med vært nyttig å sjekke resultatene til Anxifree opp mot "
"placebo. Selv om Anxifree allerede har blitt grundig testet mot placebo av "
"andre forskere, kan det likevel være svært nyttig å sjekke at studien din "
"gir lignende resultater som tidligere arbeid."

#: ../../Ch13/Ch13_ANOVA_05.rst:35
msgid ""
"When we characterise the null hypothesis in terms of these three distinct "
"propositions, it becomes clear that there are eight possible “states of the "
"world” that we need to distinguish between:"
msgstr ""
"Når vi karakteriserer nullhypotesen i form av disse tre ulike påstandene, "
"blir det klart at det finnes åtte mulige «verdenstilstander» som vi må "
"skille mellom:"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "possibility:"
msgstr "mulighet:"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "is µ\\ :sub:`P` = µ\\ :sub:`A`"
msgstr "er µ\\ :sub:`P` = µ\\ :sub:`A`"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "is µ\\ :sub:`P` = µ\\ :sub:`J`"
msgstr "er µ\\ :sub:`P` = µ\\ :sub:`J`"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "is µ\\ :sub:`A` = µ\\ :sub:`J`"
msgstr "er µ\\ :sub:`A` = µ\\ :sub:`J`"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "which hypothesis?"
msgstr "Hvilken hypotese?"

#: ../../Ch13/Ch13_ANOVA_05.rst:43 ../../Ch13/Ch13_ANOVA_05.rst:45
#: ../../Ch13/Ch13_ANOVA_05.rst:47 ../../Ch13/Ch13_ANOVA_05.rst:49
#: ../../Ch13/Ch13_ANOVA_05.rst:51 ../../Ch13/Ch13_ANOVA_05.rst:53
#: ../../Ch13/Ch13_ANOVA_05.rst:55
msgid "✓"
msgstr "✓"

#: ../../Ch13/Ch13_ANOVA_05.rst:43
msgid "null"
msgstr "null"

#: ../../Ch13/Ch13_ANOVA_05.rst:45 ../../Ch13/Ch13_ANOVA_05.rst:47
#: ../../Ch13/Ch13_ANOVA_05.rst:49 ../../Ch13/Ch13_ANOVA_05.rst:51
#: ../../Ch13/Ch13_ANOVA_05.rst:53 ../../Ch13/Ch13_ANOVA_05.rst:55
#: ../../Ch13/Ch13_ANOVA_05.rst:57
msgid "alternative"
msgstr "alternativ"

#: ../../Ch13/Ch13_ANOVA_05.rst:55 ../../Ch13/Ch13_ANOVA_07.rst:66
#: ../../Ch13/Ch13_ANOVA_07.rst:68 ../../Ch13/Ch13_ANOVA_07.rst:76
msgid "7"
msgstr "7"

#: ../../Ch13/Ch13_ANOVA_05.rst:57 ../../Ch13/Ch13_ANOVA_07.rst:66
#: ../../Ch13/Ch13_ANOVA_07.rst:68 ../../Ch13/Ch13_ANOVA_07.rst:76
msgid "8"
msgstr "8"

#: ../../Ch13/Ch13_ANOVA_05.rst:60
msgid ""
"By rejecting the null hypothesis, we’ve decided that we *don’t* believe that "
"#1 is the true state of the world. The next question to ask is, which of the "
"other seven possibilities *do* we think is right? When faced with this "
"situation, its usually helps to look at the data. For instance, if we look "
"at the plots in :numref:`fig-anova1`, it’s tempting to conclude that "
"Joyzepam is better than the placebo and better than Anxifree, but there’s no "
"real difference between Anxifree and the placebo. However, if we want to get "
"a clearer answer about this, it might help to run some tests."
msgstr ""
"Ved å forkaste nullhypotesen har vi bestemt oss for at vi *ikke* tror at #1 "
"er den sanne tilstanden i verden. Det neste spørsmålet vi må stille oss, er "
"hvilken av de andre sju mulighetene *tror* vi er riktig? Når vi står overfor "
"en slik situasjon, hjelper det vanligvis å se på dataene. Hvis vi for "
"eksempel ser på plottene i :numref:`fig-anova1`, er det fristende å "
"konkludere med at Joyzepam er bedre enn placebo og bedre enn Anxifree, men "
"at det ikke er noen reell forskjell mellom Anxifree og placebo. Hvis vi "
"ønsker å få et klarere svar på dette, kan det imidlertid hjelpe å kjøre noen "
"tester."

#: ../../Ch13/Ch13_ANOVA_05.rst:71
msgid "Running “pairwise” *t*-tests"
msgstr "Gjennomføre «parvise» *t*-tester"

#: ../../Ch13/Ch13_ANOVA_05.rst:73
msgid ""
"How might we go about solving our problem? Given that we’ve got three "
"separate pairs of means (placebo versus Anxifree, placebo versus Joyzepam, "
"and Anxifree versus Joyzepam) to compare, what we could do is run three "
"separate *t*-tests and see what happens. This is easy to do in jamovi. Go to "
"the ``ANOVA`` → ``Post Hoc Tests`` options, move the ``drug`` variable "
"across into the active box on the right, and then click on the ``No "
"correction`` checkbox. This will produce a neat table showing all the "
"pairwise *t*-test comparisons amongst the three levels of the ``drug`` "
"variable, as in :numref:`fig-anova3`."
msgstr ""
"Hvordan kan vi gå frem for å løse problemet vårt? Gitt at vi har tre "
"separate gjennomsnittspar (placebo versus anxifree, placebo versus joyzepam, "
"og anxifree versus joyzepam) å sammenligne, kan vi kjøre tre separate *t*-"
"tester og se hva som skjer. Dette er enkelt å gjøre i jamovi. Gå til "
"``ANOVA`` → ``Post Hoc Tests``, flytt ``drug``-variabelen over i den aktive "
"boksen til høyre, og klikk deretter på avkrysningsboksen ``No correction``. "
"Dette vil produsere en fin tabell som viser alle de parvise *t*-"
"testsammenligningene mellom de tre nivåene av variabelen ``drug``, som i :"
"numref:`fig-anova3`."

#: ../../Ch13/Ch13_ANOVA_05.rst:85 ../../Ch13/Ch13_ANOVA_05.rst:89
msgid "Uncorrected pairwise *t*-tests as post-hoc comparisons in jamovi"
msgstr "Ukorrigerte parvise *t*-tester som post-hoc-sammenligninger i jamovi"

#: ../../Ch13/Ch13_ANOVA_05.rst:94
msgid "Corrections for multiple testing"
msgstr "Korrigeringer for flere tester"

#: ../../Ch13/Ch13_ANOVA_05.rst:96
msgid ""
"In the previous section I hinted that there’s a problem with just running "
"lots and lots of *t*-tests. The concern is that, when running these "
"analyses, what we’re doing is going on a “fishing expedition”. We’re running "
"lots and lots of tests without much theoretical guidance in the hope that "
"some of them come up significant. This kind of theory-free search for group "
"differences is referred to as **post-hoc analysis** (“post-hoc” being Latin "
"for “after this”).\\ [#]_"
msgstr ""
"I forrige avsnitt antydet jeg at det er et problem med å bare kjøre massevis "
"av *t*-tester. Problemet er at når vi kjører disse analysene, er det vi gjør "
"å dra på en «fiskeekspedisjon». Vi kjører mange, mange tester uten særlig "
"teoretisk veiledning i håp om at noen av dem skal vise seg å være "
"signifikante. Denne typen leting etter gruppeforskjeller uten at det baserer "
"seg på en teori omtales som **post-hoc-analyse** («post-hoc» er latin for "
"«etter dette»).\\ [#]_"

#: ../../Ch13/Ch13_ANOVA_05.rst:104
msgid ""
"It’s okay to run post-hoc analyses, but a lot of care is required. For "
"instance, the analysis that I ran in the previous section should be avoided, "
"as each *individual* *t*-test is designed to have a 5\\% Type I error rate "
"(i.e., α = 0.05) and I ran three of these tests. Imagine what would have "
"happened if my ANOVA involved 10 different groups, and I had decided to run "
"45 “post-hoc” *t*-tests to try to find out which ones were significantly "
"different from each other, you’d expect 2 or 3 of them to come up "
"significant *by chance alone*. As we saw in chapter :doc:`../Ch09/"
"Ch09_HypothesisTesting`, the central organising principle behind null "
"hypothesis testing is that we seek to control our Type I error rate, but now "
"that I’m running lots of *t*-tests at once in order to determine the source "
"of my ANOVA results, my actual Type I error rate across this whole *family* "
"of tests has gotten completely out of control."
msgstr ""
"Det er greit å kjøre post-hoc-analyser, men det krever stor forsiktighet. "
"For eksempel bør analysen jeg kjørte i forrige avsnitt unngås, ettersom hver "
"*individuelle* *t*-test er designet for å ha en type-I-feilrate på 5\\% "
"(dvs. α = 0,05), og jeg kjørte tre av disse testene. Tenk deg hva som ville "
"ha skjedd hvis ANOVAen min omfattet 10 forskjellige grupper, og jeg hadde "
"bestemt meg for å kjøre 45 «post-hoc»-*t*-tester for å prøve å finne ut "
"hvilke som var signifikant forskjellige fra hverandre, da ville du forvente "
"at 2 eller 3 av dem ville være signifikante *ved en tilfeldighet alene*. Som "
"vi så i kapittel :doc:`../Ch09/Ch09_HypothesisTesting`, er det sentrale "
"organisatoriske prinsippet bak nullhypotesetesting at vi søker å kontrollere "
"Type I-feilraten vår, men nå som jeg kjører mange *t*-tester samtidig for å "
"finne kilden til ANOVA-resultatene mine, har den faktiske Type I-feilraten "
"min på tvers av hele denne *familien* av tester kommet helt ut av kontroll."

#: ../../Ch13/Ch13_ANOVA_05.rst:117
msgid ""
"The usual solution to this problem is to introduce an adjustment to the *p*-"
"value, which aims to control the total error rate across the family of tests "
"(:ref:`Shaffer, 1995 <Shaffer_1995>`). An adjustment of this form, which is "
"usually (but not always) applied because one is doing post-hoc analysis, is "
"often referred to as a **correction for multiple comparisons**, though it is "
"sometimes referred to as “simultaneous inference”. In any case, there are "
"quite a few different ways of doing this adjustment. I’ll discuss a few of "
"them in this section and in section :doc:`../Ch14/Ch14_ANOVA2_09`, but you "
"should be aware that there are many other methods out there (:ref:`Hsu, 1996 "
"<Hsu_1996>`)."
msgstr ""
"Den vanlige løsningen på dette problemet er å innføre en justering av *p*-"
"verdien, som tar sikte på å kontrollere den totale feilraten i hele "
"testfamilien (:ref:`Shaffer, 1995 <Shaffer_1995>`). En slik justering, som "
"vanligvis (men ikke alltid) brukes fordi man gjør en post-hoc-analyse, "
"kalles ofte en **korreksjon for multiple sammenligninger**, selv om den noen "
"ganger omtales som «samtidig slutning» (*simultaneous inference*). Uansett "
"finnes det ganske mange forskjellige måter å gjøre denne justeringen på. Jeg "
"vil diskutere noen av dem i dette avsnittet og i avsnitt :doc:`../Ch14/"
"Ch14_ANOVA2_09`, men du bør være klar over at det finnes mange andre metoder "
"der ute (:ref:`Hsu, 1996 <Hsu_1996>`)."

#: ../../Ch13/Ch13_ANOVA_05.rst:129
msgid "Bonferroni corrections"
msgstr "Bonferroni-korreksjon"

#: ../../Ch13/Ch13_ANOVA_05.rst:131
msgid ""
"The simplest of these adjustments is called the **Bonferroni correction** (:"
"ref:`Dunn, 1961 <Dunn_1961>`), and it’s very very simple indeed. Suppose "
"that my post-hoc analysis consists of *m* separate tests, and I want to "
"ensure that the total probability of making *any* Type I errors at all is at "
"most α.\\ [#]_ If so, then the Bonferroni correction just says “multiply all "
"your raw *p*-values by *m*”. If we let *p* denote the original *p*-value, "
"and let *p*'\\ :sub:`j` be the corrected value, then the Bonferroni "
"correction tells that:"
msgstr ""
"Den enkleste av disse justeringene kalles **Bonferroni-korreksjonen** (:ref:"
"`Dunn, 1961 <Dunn_1961>`), og den er veldig, veldig enkel. Anta at post-hoc-"
"analysen min består av *m* separate tester, og at jeg ønsker å sikre at den "
"totale sannsynligheten for å gjøre *noen* type I-feil i det hele tatt er "
"høyst α.\\ [#]_ I så fall sier Bonferroni-korreksjonen bare «multipliser "
"alle de rå *p*-verdiene dine med *m*». Hvis vi lar *p* betegne den "
"opprinnelige *p*-verdien, og lar *p*'\\ :sub:`j` være den korrigerte "
"verdien, så forteller Bonferroni-korreksjonen at:"

#: ../../Ch13/Ch13_ANOVA_05.rst:140
msgid "*p*'\\ :sub:`j` = *m* × *p*"
msgstr "*p*'\\ :sub:`j` = *m* × *p*"

#: ../../Ch13/Ch13_ANOVA_05.rst:142
msgid ""
"And therefore, if you’re using the Bonferroni correction, you would reject "
"the null hypothesis if *p*'\\ :sub:`j` < α. The logic behind this correction "
"is very straightforward. We’re doing *m* different tests, so if we arrange "
"it so that each test has a Type I error rate of at most α / *m*, then the "
"*total* Type I error rate across these tests cannot be larger than α. That’s "
"pretty simple, so much so that in the original paper, the author writes,"
msgstr ""
"Hvis du bruker Bonferroni-korreksjonen, vil du derfor forkaste nullhypotesen "
"hvis *p*'\\ :sub:`j` < α. Logikken bak denne korreksjonen er veldig enkel. "
"Vi gjør *m* forskjellige tester, så hvis vi ordner det slik at hver test har "
"en type I-feilrate på maksimalt α / *m*, kan ikke den *totale* type I-"
"feilraten på tvers av disse testene være større enn α. Det er ganske enkelt, "
"så mye at forfatteren skriver i den opprinnelige artikkelen,"

#: ../../Ch13/Ch13_ANOVA_05.rst:150
msgid ""
"The method given here is so simple and so general that I am sure it must "
"have been used before this. I do not find it, however, so can only conclude "
"that perhaps its very simplicity has kept statisticians from realizing that "
"it is a very good method in some situations (:ref:`Dunn, 1961 <Dunn_1961>`, "
"pp. 52-53)."
msgstr ""
"Metoden som er gitt her, er så enkel og så generell at jeg er sikker på at "
"den må ha vært brukt før dette. Jeg finner den imidlertid ikke, så jeg kan "
"bare konkludere med at det kanskje er nettopp enkelheten som har hindret "
"statistikere i å innse at det er en svært god metode i noen situasjoner (:"
"ref:`Dunn, 1961 <Dunn_1961>`, s. 52-53)."

#: ../../Ch13/Ch13_ANOVA_05.rst:156
msgid ""
"To use the Bonferroni correction in jamovi, just click on the ``Bonferroni`` "
"checkbox in the ``Correction`` options, and you will see another column "
"added to the ``ANOVA`` results table showing the adjusted *p*-values for the "
"Bonferroni correction (:numref:`fig-anova3`). If we compare these three *p*-"
"values to those for the uncorrected, pairwise *t*-tests, it is clear that "
"the only thing that jamovi has done is multiply them by 3."
msgstr ""
"Hvis du vil bruke Bonferroni-korreksjonen i jamovi, klikker du bare på "
"avmerkingsboksen ``Bonferroni`` i ``Correction``-opsjonene, og du vil se en "
"ny kolonne lagt til i ``ANOVA``-resultattabellen som viser de justerte *p*-"
"verdiene for Bonferroni-korreksjonen (:numref:`fig-anova3`). Hvis vi "
"sammenligner disse tre *p*-verdiene med de ukorrigerte, parvise *t*-testene, "
"er det tydelig at det eneste jamovi har gjort, er å multiplisere dem med 3."

#: ../../Ch13/Ch13_ANOVA_05.rst:165
msgid "Holm corrections"
msgstr "Holm-korreksjoner"

#: ../../Ch13/Ch13_ANOVA_05.rst:167
msgid ""
"Although the Bonferroni correction is the simplest adjustment out there, "
"it’s not usually the best one to use. One method that is often used instead "
"is the **Holm correction** (:ref:`Holm, 1979 <Holm_1979>`). The idea behind "
"the Holm correction is to pretend that you’re doing the tests sequentially, "
"starting with the smallest (raw) *p*-value and moving onto the largest one. "
"For the *j*-th largest of the *p*-values, the adjustment is *either*"
msgstr ""
"Selv om Bonferroni-korreksjonen er den enkleste justeringen som finnes, er "
"den vanligvis ikke den beste å bruke. En metode som ofte brukes i stedet, er "
"**Holm-korreksjonen** (:ref:`Holm, 1979 <Holm_1979>`). Ideen bak Holm-"
"korreksjonen er å late som om du gjør testene sekvensielt, ved å starte med "
"den minste (rå) *p*-verdien og gå videre til den største. For den *j*-tredje "
"største av *p*-verdiene er justeringen *enten*"

#: ../../Ch13/Ch13_ANOVA_05.rst:174
msgid "*p*'\\ :sub:`j` = j × *p*\\ :sub:`j`"
msgstr "*p*'\\ :sub:`j` = j × *p*\\ :sub:`j`"

#: ../../Ch13/Ch13_ANOVA_05.rst:176
msgid ""
"(i.e., the biggest *p*-value remains unchanged, the second biggest *p*-value "
"is doubled, the third biggest *p*-value is tripled, and so on), *or*"
msgstr ""
"(dvs. den største *p*-verdien forblir uendret, den nest største *p*-verdien "
"dobles, den tredje største *p*-verdien tredobles, og så videre), *eller*"

#: ../../Ch13/Ch13_ANOVA_05.rst:180
msgid "*p*'\\ :sub:`j` = *p*'\\ :sub:`j + 1`"
msgstr "*p*'\\ :sub:`j` = *p*'\\ :sub:`j + 1`"

#: ../../Ch13/Ch13_ANOVA_05.rst:182
msgid ""
"whichever one is larger. This might sound a little confusing, so let’s go "
"through it a little more slowly. Here’s what the Holm correction does. "
"First, you sort all of your *p*-values in order, from smallest to largest. "
"For the smallest *p*-value all you do is multiply it by *m*, and you’re "
"done. However, for all the other ones it’s a two-stage process. For "
"instance, when you move to the second smallest *p*-value, you first multiply "
"it by *m* - 1. If this produces a number that is bigger than the adjusted "
"*p*-value that you got last time, then you keep it. But if it’s smaller than "
"the last one, then you copy the last *p*-value. To illustrate how this "
"works, consider the table below, which shows the calculations of a Holm "
"correction for a collection of five *p*-values:"
msgstr ""
"avhengig av hvilken som er størst. Dette høres kanskje litt forvirrende ut, "
"så la oss gå gjennom det litt saktere. Dette er hva Holm-korreksjonen gjør. "
"Først sorterer du alle *p*-verdiene dine i rekkefølge, fra den minste til "
"den største. For den minste *p*-verdien multipliserer du den bare med *m*, "
"og så er du ferdig. For alle de andre er det imidlertid en totrinnsprosess. "
"Når du for eksempel går til den nest minste *p*-verdien, multipliserer du "
"den først med *m* - 1. Hvis dette gir et tall som er større enn den justerte "
"*p*-verdien du fikk forrige gang, beholder du det. Men hvis den er mindre "
"enn den forrige, kopierer du den forrige *p*-verdien. For å illustrere "
"hvordan dette fungerer, kan du se på tabellen nedenfor, som viser "
"beregningene av en Holm-korreksjon for en samling av fem *p*-verdier:"

#: ../../Ch13/Ch13_ANOVA_05.rst:196
msgid "raw *p* rank"
msgstr "rå *p* rang"

#: ../../Ch13/Ch13_ANOVA_05.rst:196
msgid "*j*"
msgstr "*j*"

#: ../../Ch13/Ch13_ANOVA_05.rst:196
msgid "*p* × *j*"
msgstr "*p* × *j*"

#: ../../Ch13/Ch13_ANOVA_05.rst:196
msgid "Holm *p*"
msgstr "Holm *p*"

#: ../../Ch13/Ch13_ANOVA_05.rst:198
msgid ".001"
msgstr ".001"

#: ../../Ch13/Ch13_ANOVA_05.rst:198
msgid "0.005"
msgstr "0.005"

#: ../../Ch13/Ch13_ANOVA_05.rst:200
msgid ".005"
msgstr ".005"

#: ../../Ch13/Ch13_ANOVA_05.rst:200
msgid "0.020"
msgstr "0.020"

#: ../../Ch13/Ch13_ANOVA_05.rst:202
msgid ".019"
msgstr ".019"

#: ../../Ch13/Ch13_ANOVA_05.rst:202 ../../Ch13/Ch13_ANOVA_05.rst:204
msgid "0.057"
msgstr "0.057"

#: ../../Ch13/Ch13_ANOVA_05.rst:204
msgid ".022"
msgstr ".022"

#: ../../Ch13/Ch13_ANOVA_05.rst:204
msgid "0.044"
msgstr "0.044"

#: ../../Ch13/Ch13_ANOVA_05.rst:206
msgid ".103"
msgstr ".103"

#: ../../Ch13/Ch13_ANOVA_05.rst:206
msgid "0.103"
msgstr "0.103"

#: ../../Ch13/Ch13_ANOVA_05.rst:209
msgid "Hopefully that makes things clear."
msgstr "Forhåpentligvis gjør det ting klart."

#: ../../Ch13/Ch13_ANOVA_05.rst:211
msgid ""
"Although it’s a little harder to calculate, the Holm correction has some "
"very nice properties. It’s more powerful than Bonferroni (i.e., it has a "
"lower Type II error rate) but, counter-intuitive as it might seem, it has "
"the *same* Type I error rate. As a consequence, in practice there’s never "
"any reason to use the simpler Bonferroni correction since it is always "
"outperformed by the slightly more elaborate Holm correction. Because of "
"this, the Holm correction should be your *go to* multiple comparison "
"correction. :numref:`fig-anova3` also shows the Holm corrected *p*-values "
"and, as you can see, the biggest *p*-value (corresponding to the comparison "
"between Anxifree and the placebo) is unaltered. At a value of 0.15, it is "
"exactly the same as the value we got originally when we applied no "
"correction at all. In contrast, the smallest *p*-value (Joyzepam versus "
"placebo) has been multiplied by three."
msgstr ""
"Selv om den er litt vanskeligere å beregne, har Holm-korreksjonen noen "
"veldig fine egenskaper. Den er kraftigere enn Bonferroni (dvs. at den har en "
"lavere type II-feilrate), men, selv om det kan virke kontraintuitivt, har "
"den *samme* type I-feilrate. I praksis er det derfor aldri noen grunn til å "
"bruke den enklere Bonferroni-korreksjonen, siden den alltid blir "
"utkonkurrert av den litt mer forseggjorte Holm-korreksjonen. På grunn av "
"dette bør Holm-korreksjonen være din *go to* korreksjon for multiple "
"sammenligninger. :numref:`fig-anova3` viser også de Holm-korrigerte *p*-"
"verdiene, og som du kan se, er den største *p*-verdien (som tilsvarer "
"sammenligningen mellom Anxifree og placebo) uendret. Med en verdi på 0,15 er "
"den nøyaktig den samme som den opprinnelige verdien vi fikk da vi ikke "
"korrigerte i det hele tatt. Derimot har den minste *p*-verdien (Joyzepam "
"versus placebo) blitt multiplisert med tre."

#: ../../Ch13/Ch13_ANOVA_05.rst:226
msgid "Writing up the post-hoc test"
msgstr "Skriving av post-hoc-testen"

#: ../../Ch13/Ch13_ANOVA_05.rst:228
msgid ""
"Finally, having run the post-hoc analysis to determine which groups are "
"significantly different to one another, you might write up the result like "
"this:"
msgstr ""
"Når du til slutt har kjørt post-hoc-analysen for å finne ut hvilke grupper "
"som er signifikant forskjellige fra hverandre, kan du skrive opp resultatet "
"slik:"

#: ../../Ch13/Ch13_ANOVA_05.rst:232
msgid ""
"Post-hoc tests (using the Holm correction to adjust *p*) indicated that "
"Joyzepam produced a significantly larger mood change than both Anxifree (*p* "
"= 0.001) and the placebo (*p* = 9.0 · 10\\ :sup:`-5`). We found no evidence "
"that Anxifree performed better than the placebo (*p* = 0.15)."
msgstr ""
"Post-hoc-tester (med Holm-korreksjon for å justere *p*) indikerte at "
"Joyzepam ga en signifikant større stemningsendring enn både Anxifree (*p* = "
"0,001) og placebo (*p* = 9,0 - 10\\ :sup:`-5`). Vi fant ingen bevis for at "
"Anxifree ga bedre resultater enn placebo (*p* = 0,15)."

#: ../../Ch13/Ch13_ANOVA_05.rst:238
msgid ""
"Or, if you don’t like the idea of reporting exact *p*-values, then you’d "
"change those numbers to *p* < 0.001`, *p* < 0.01 and *p* > 0.05 "
"respectively. Either way, the key thing is that you indicate that you used "
"Holm’s correction to adjust the *p*-values. And of course, I’m assuming that "
"elsewhere in the write up you’ve included the relevant descriptive "
"statistics (i.e., the group means and standard deviations), since these *p*-"
"values on their own aren’t terribly informative."
msgstr ""
"Eller, hvis du ikke liker tanken på å rapportere eksakte *p*-verdier, kan du "
"endre disse tallene til henholdsvis *p* < 0,001`, *p* < 0,01 og *p* > 0,05. "
"Uansett, det viktigste er at du angir at du brukte Holms korreksjon for å "
"justere *p*-verdiene. Og jeg går selvfølgelig ut fra at du et annet sted i "
"rapporten har tatt med relevant deskriptivstatistikk (dvs. "
"gruppegjennomsnitt og standardavvik), siden disse *p*-verdiene i seg selv "
"ikke er veldig informative."

#: ../../Ch13/Ch13_ANOVA_05.rst:250
msgid ""
"If you *do* have some theoretical basis for wanting to investigate some "
"comparisons but not others, it’s a different story. In those circumstances "
"you’re not really running “post-hoc” analyses at all, you’re making “planned "
"comparisons”. I do talk about this situation later in the book in section :"
"doc:`../Ch14/Ch14_ANOVA2_10`), but for now I want to keep things simple."
msgstr ""
"Hvis du *har* et teoretisk grunnlag for å ville undersøke noen "
"sammenligninger, men ikke andre, er det en annen sak. I slike tilfeller "
"gjennomfører du egentlig ikke «post-hoc»-analyser i det hele tatt, du gjør "
"«planlagte sammenligninger» (*planned comparisons*). Jeg kommer tilbake til "
"denne situasjonen senere i boken i avsnittet :doc:`../Ch14/Ch14_ANOVA2_10`), "
"men nå vil jeg holde det enkelt."

#: ../../Ch13/Ch13_ANOVA_05.rst:257
msgid ""
"It’s worth noting in passing that not all adjustment methods try to do this. "
"What I’ve described here is an approach for controlling “family wise Type I "
"error rate”. However, there are other post-hoc tests that seek to control "
"the “false discovery rate”, which is a somewhat different thing."
msgstr ""
"Det er verdt å merke seg at ikke alle justeringsmetoder forsøker å gjøre "
"dette. Det jeg har beskrevet her, er en tilnærming for å kontrollere den "
"«familievise type-I-feilraten». Det finnes imidlertid andre post-hoc-tester "
"som søker å kontrollere «falsk oppdagelsesrate» (*false discovery rate*), "
"noe som er en annen ting."

#: ../../Ch13/Ch13_ANOVA_06.rst:4
msgid "Assumptions of the one-way ANOVA"
msgstr "Forutsetninger for enveis ANOVA"

#: ../../Ch13/Ch13_ANOVA_06.rst:6
msgid ""
"Like any statistical test, analysis of variance relies on some assumptions "
"about the data, specifically the residuals. There are three key assumptions "
"that you need to be aware of: *normality*, *homogeneity of variance* and "
"*independence*."
msgstr ""
"Som alle andre statistiske tester er variansanalyse avhengig av noen "
"antakelser om dataene, spesielt residuene. Det er tre viktige forutsetninger "
"du må være klar over: *normalfordeling*, *varianshomogenitet* og "
"*uavhengighet*."

#: ../../Ch13/Ch13_ANOVA_06.rst:11
msgid ""
"If you remember back to subsection :ref:`The model for the data and the "
"meaning of *F* <meaning_of_F>` which I hope you at least skimmed even if you "
"didn’t read the whole thing, I described the statistical models underpinning "
"ANOVA in this way:"
msgstr ""
"Hvis du husker tilbake til underavsnittet :ref:`Modellen for dataene og "
"betydningen av *F* <meaning_of_F>`, som jeg håper du i det minste skummet "
"over selv om du ikke leste hele, beskrev jeg de statistiske modellene som "
"ligger til grunn for ANOVA på denne måten:"

#: ../../Ch13/Ch13_ANOVA_06.rst:16
msgid "H\\ :sub:`0`: Y\\ :sub:`ik` = µ           + ϵ\\ :sub:`ik`"
msgstr "H\\ :sub:`0`: Y\\ :sub:`ik` = µ           + ϵ\\ :sub:`ik`"

#: ../../Ch13/Ch13_ANOVA_06.rst:17
msgid "H\\ :sub:`1`: Y\\ :sub:`ik` = µ\\ :sub:`k` + ϵ\\ :sub:`ik`"
msgstr "H\\ :sub:`1`: Y\\ :sub:`ik` = µ\\ :sub:`k` + ϵ\\ :sub:`ik`"

#: ../../Ch13/Ch13_ANOVA_06.rst:19
msgid ""
"In these equations µ refers to a single grand population mean which is the "
"same for all groups, and µ\\ :sub:`k` is the population mean for the *k*-th "
"group. Up to this point we’ve been mostly interested in whether our data are "
"best described in terms of a single grand mean (the null hypothesis) or in "
"terms of different group-specific means (the alternative hypothesis). This "
"makes sense, of course, as that’s actually the important research question! "
"However, all of our testing procedures have, implicitly, relied on a "
"specific assumption about the residuals, ϵ\\ :sub:`ik`, namely that"
msgstr ""
"I disse ligningene refererer µ til et enkelt overordnet "
"populasjonsgjennomsnitt som er det samme for alle grupper, og µ\\ :sub:`k` "
"er populasjonsgjennomsnittet for den *k*-tredje gruppen. Frem til nå har vi "
"vært mest interessert i om dataene våre best kan beskrives ved hjelp av ett "
"enkelt totalt gjennomsnitt (nullhypotesen) eller ved hjelp av ulike "
"gruppespesifikke gjennomsnitt (alternativhypotesen). Dette gir selvfølgelig "
"mening, siden det faktisk er det viktige forskningsspørsmålet! Alle "
"testprosedyrene våre har imidlertid implisitt basert seg på en spesifikk "
"antakelse om residuene, ϵ\\ :sub:`ik`, nemlig at"

#: ../../Ch13/Ch13_ANOVA_06.rst:31
msgid ""
"None of the maths works properly without this bit. Or, to be precise, you "
"can still do all the calculations and you’ll end up with an *F*-statistic, "
"but you have no guarantee that this *F*-statistic actually measures what you "
"think it’s measuring, and so any conclusions that you might draw on the "
"basis of the *F* test might be wrong."
msgstr ""
"Ingen av regnestykkene fungerer skikkelig uten denne biten. Eller, for å "
"være presis, du kan fortsatt gjøre alle beregningene og ende opp med en *F*-"
"statistikk, men du har ingen garanti for at denne *F*-statistikken faktisk "
"måler det du tror den måler, og dermed kan eventuelle konklusjoner du "
"trekker på grunnlag av *F*-testen, være feil."

#: ../../Ch13/Ch13_ANOVA_06.rst:38
msgid ""
"So, how do we check whether the assumption about the residuals is accurate? "
"Well, as I indicated above, there are three distinct claims buried in this "
"one statement, and we’ll consider them separately."
msgstr ""
"Så hvordan sjekker vi om forutsetningen om residuene er korrekt? Som jeg "
"antydet ovenfor, ligger det tre forskjellige påstander begravd i denne ene "
"påstanden, og vi skal se på dem hver for seg."

#: ../../Ch13/Ch13_ANOVA_06.rst:42
msgid ""
"**Homogeneity of variance**. Notice that we’ve only got the one value for "
"the population standard deviation (i.e., σ), rather than allowing each group "
"to have it’s own value (i.e., σ\\ :sub:`k`). This is referred to as the "
"homogeneity of variance (sometimes called homoscedasticity) assumption. "
"ANOVA assumes that the population standard deviation is the same for all "
"groups. We’ll talk about this extensively in subsection :ref:`Checking the "
"homogeneity of variance assumption <homogeneity_of_variance_anova>`."
msgstr ""
"**Varianshomogenitet**. Legg merke til at vi bare har én verdi for "
"populasjonens standardavvik (dvs. σ), i stedet for å la hver gruppe ha sin "
"egen verdi (dvs. σ\\ :sub:`k`). Dette kalles forutsetningen om "
"varianshomogenitet (noen ganger kalt homoskedastisitet). ANOVA forutsetter "
"at standardavviket i populasjonen er det samme for alle grupper. Vi skal "
"snakke mye om dette i underavsnittet :ref:`Sjekk forutsetningen om "
"varianshomogenitet <homogeneity_of_variance_anova>`."

#: ../../Ch13/Ch13_ANOVA_06.rst:50
msgid ""
"**Normality**. The residuals are assumed to be normally distributed. As we "
"saw in subsection :doc:`../Ch11/Ch11_tTest_08`, we can assess this by "
"looking at QQ-plots (or running a Shapiro-Wilk test). I’ll talk about this "
"more in an ANOVA context in subsection :ref:`Checking the normality "
"assumption <normality_anova>`."
msgstr ""
"**Normalfordeling**. Residuene antas å være normalfordelte. Som vi så i "
"underavsnitt :doc:`../Ch11/Ch11_tTest_08`, kan vi vurdere dette ved å se på "
"QQ-plott (eller kjøre en Shapiro-Wilk-test). Jeg skal snakke mer om dette i "
"en ANOVA-sammenheng i underavsnitt :ref:`Sjekk forutsetningen om "
"normalfordeling <normality_anova>`."

#: ../../Ch13/Ch13_ANOVA_06.rst:56
msgid ""
"**Independence**. The independence assumption is a little trickier. What it "
"basically means is that, knowing one residual tells you nothing about any "
"other residual. All of the ϵ\\ :sub:`ik` values are assumed to have been "
"generated without any “regard for” or “relationship to” any of the other "
"ones. There’s not an obvious or simple way to test for this, but there are "
"some situations that are clear violations of this. For instance, if you have "
"a repeated-measures design, where each participant in your study appears in "
"more than one condition, then independence doesn’t hold. There’s a special "
"relationship between some observations, namely those that correspond to the "
"same person! When that happens, you need to use something like repeated "
"measures ANOVA (see section :doc:`Ch13_ANOVA_07`)."
msgstr ""
"**Uavhengighet**. Antakelsen om uavhengighet er litt vanskeligere. Det betyr "
"i bunn og grunn at det å kjenne til et residuum ikke forteller deg noe om "
"noen annet residuum. Alle ϵ\\ :sub:`ik`-verdiene antas å ha blitt generert "
"uten «hensyn til» eller «forhold til» noen av de andre. Det finnes ingen "
"åpenbar eller enkel måte å teste dette på, men det finnes noen situasjoner "
"som er klare brudd på dette. Hvis du for eksempel har et design med "
"gjentatte målinger, der hver deltaker i studien deltar i mer enn én "
"betingelse, gjelder ikke uavhengighet. Det er et spesielt forhold mellom "
"noen observasjoner, nemlig de som tilsvarer samme person! Når det skjer, må "
"du bruke noe som ANOVA for gjentatte målinger (se avsnitt :doc:"
"`Ch13_ANOVA_07`)."

#: ../../Ch13/Ch13_ANOVA_06.rst:72
msgid "Checking the homogeneity of variance assumption"
msgstr "Sjekk av forutsetningen om varianshomogenitet"

#: ../../Ch13/Ch13_ANOVA_06.rst:82
msgid ""
"There’s more than one way to skin a cat, as the saying goes, and more than "
"one way to test the homogeneity of variance assumption, too (though for some "
"reason no-one made a saying out of that). The most commonly used test for "
"this that I’ve seen in the literature is the **Levene test** (:ref:`Levene, "
"1960 <Levene_1960>`), and the closely related **Brown-Forsythe test** (:ref:"
"`Brown & Forsythe, 1974 <Brown_1974>`)."
msgstr ""
"Det er mer enn én måte å flå en katt på, som det heter, og det er mer enn én "
"måte å teste forutsetningen om varianshomogenitet på også (selv om ingen av "
"en eller annen grunn har gjort et ordtak ut av det). Den mest brukte testen "
"for dette som jeg har sett i litteraturen, er **Levene-testen** (:ref:"
"`Levene, 1960 <Levene_1960>`), og den nært beslektede **Brown-Forsythe-"
"testen** (:ref:`Brown & Forsythe, 1974 <Brown_1974>`)."

#: ../../Ch13/Ch13_ANOVA_06.rst:89
msgid ""
"Regardless of whether you’re doing the standard Levene test or the Brown-"
"Forsythe test, the test statistic, which is sometimes denoted *F* but also "
"sometimes written as *W*, is calculated in exactly the same way that the *F*-"
"statistic for the regular ANOVA is calculated, just using a Z\\ :sub:`ik` "
"rather than Y\\ :sub:`ik`. With that in mind, we can go on to look at how to "
"run the test in jamovi."
msgstr ""
"Uansett om du bruker standard Levene-test eller Brown-Forsythe-test, "
"beregnes teststatistikken, som noen ganger betegnes *F*, men som også noen "
"ganger skrives *W*, på nøyaktig samme måte som *F*-statistikken for den "
"vanlige ANOVA, bare at du bruker Z\\ :sub:`ik` i stedet for Y\\ :sub:`ik`. "
"Med dette i bakhodet kan vi gå videre til å se på hvordan vi kjører testen i "
"jamovi."

#: ../../Ch13/Ch13_ANOVA_06.rst:97
msgid ""
"The Levene test is shockingly simple. Suppose we have our outcome variable "
"Y\\ :sub:`ik`. All we do is define a new variable, which I’ll call Z\\ :sub:"
"`ik`, corresponding to the absolute deviation from the group mean"
msgstr ""
"Levene-testen er sjokkerende enkel. Anta at vi har utfallsvariabelen Y\\ :"
"sub:`ik`. Alt vi trenger å gjøre er å definere en ny variabel, som jeg "
"kaller Z\\ :sub:`ik`, som tilsvarer det absolutte avviket fra "
"gruppegjennomsnittet"

#: ../../Ch13/Ch13_ANOVA_06.rst:102
msgid "Z\\ :sub:`ik` = Y\\ :sub:`ik` - Ȳ\\ :sub:`k`"
msgstr "Z\\ :sub:`ik` = Y\\ :sub:`ik` - Ȳ\\ :sub:`k`"

#: ../../Ch13/Ch13_ANOVA_06.rst:104
msgid ""
"Okay, what good does this do us? Well, let’s take a moment to think about "
"what Z\\ :sub:`ik` actually is and what we’re trying to test. The value of "
"Z\\ :sub:`ik` is a measure of how the *i*-th observation in the *k*-th group "
"deviates from its group mean. And our null hypothesis is that all groups "
"have the same variance, i.e., the same overall deviations from the group "
"means! So the null hypothesis in a Levene test is that the population means "
"of Z are identical for all groups. Hmm. So what we need now is a statistical "
"test of the null hypothesis that all group means are identical. Where have "
"we seen that before? Oh right, that’s what ANOVA is, and so all that the "
"Levene test does is run an ANOVA on the new variable Z\\ :sub:`ik`."
msgstr ""
"Ok, hva kan vi bruke dette til? La oss bruke et øyeblikk på å tenke over hva "
"Z\\ :sub:`ik` egentlig er og hva vi prøver å teste. Verdien av Z\\ :sub:`ik` "
"er et mål på hvordan den *i*-te observasjonen i den *k*-te gruppen avviker "
"fra gruppegjennomsnittet. Og nullhypotesen vår er at alle gruppene har samme "
"varians, dvs. samme totale avvik fra gruppegjennomsnittet! Nullhypotesen i "
"en Levene-test er altså at populasjonsgjennomsnittet av Z er identisk for "
"alle grupper. Ja. Så det vi trenger nå, er en statistisk test av "
"nullhypotesen om at alle gruppegjennomsnitt er identiske. Hvor har vi sett "
"det før? Akkurat, det er det en ANOVA er, så alt Levene-testen gjør er å "
"kjøre en ANOVA på den nye variabelen Z\\ :sub:`ik`."

#: ../../Ch13/Ch13_ANOVA_06.rst:116
msgid ""
"What about the Brown-Forsythe test? Does that do anything particularly "
"different? Nope. The only change from the Levene test is that it constructs "
"the transformed variable *Z* in a slightly different way, using deviations "
"from the group *medians* rather than deviations from the group *means*. That "
"is, for the Brown-Forsythe test"
msgstr ""
"Hva med Brown-Forsythe-testen? Gjør den noe særlig annerledes? Nei, det gjør "
"den ikke. Den eneste endringen fra Levene-testen er at den beregner den "
"transformerte variabelen *Z* på en litt annen måte, ved å bruke avvik fra "
"gruppens *medianer* i stedet for avvik fra gruppens *gjennomsnitt*. Det vil "
"si at for Brown-Forsythe-testen"

#: ../../Ch13/Ch13_ANOVA_06.rst:122
msgid "Z\\ :sub:`ik` = Y\\ :sub:`ik` - median\\ :sub:`k(Y)`"
msgstr "Z\\ :sub:`ik` = Y\\ :sub:`ik` - median\\ :sub:`k(Y)`"

#: ../../Ch13/Ch13_ANOVA_06.rst:124
msgid "where median\\ :sub:`k(Y)` is the median for group *k*."
msgstr "der median\\ :sub:`k(Y)` er medianen for gruppe *k*."

#: ../../Ch13/Ch13_ANOVA_06.rst:127
msgid "Running the Levene-test in jamovi"
msgstr "Kjører Levene-testen i jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:129
msgid ""
"Okay, so how do we run the Levene test? Simple really - under the ``ANOVA`` "
"→ ``Assumption Checks`` option, just click on the ``Homogeneity tests`` "
"checkbox. If we look at the output, shown in :numref:`fig-anova4`, we see "
"that the test is non-significant (*F*\\{2,15} = 1.45, *p* = 0.266), so it "
"looks like the homogeneity of variance assumption is fine. However, looks "
"can be deceptive! If your sample size is pretty big, then the Levene test "
"could show up a significant effect (i.e., *p* < 0.05) even when the "
"homogeneity of variance assumption is not violated to an extent which "
"troubles the robustness of ANOVA. This was the point George Box was making "
"in the quote above. Similarly, if your sample size is quite small, then the "
"homogeneity of variance assumption might not be satisfied and yet a Levene "
"test could be non-significant (i.e. *p* > 0.05). What this means is that, "
"alongside any statistical test of the assumption being met, you should "
"always plot the standard deviation around the means for each group / "
"category in the analysis… just to see if they look fairly similar (i.e. "
"homogeneity of variance) or not."
msgstr ""
"Hvordan kjører vi Levene-testen? Det er egentlig enkelt - under ``ANOVA`` → "
"``Assumption Checks`` klikker du bare på avmerkingsboksen ``Homogeneity "
"tests``. Hvis vi ser på resultatet, som vises i :numref:`fig-anova4`, ser vi "
"at testen ikke er signifikant (*F*\\{2,15} = 1,45, *p* = 0,266), så det ser "
"ut til at forutsetningen om varianshomogenitet er gitt. Utseendet kan "
"imidlertid bedra! Hvis utvalgsstørrelsen er ganske stor, kan Levene-testen "
"vise en signifikant effekt (dvs. *p* < 0,05) selv om forutsetningen om "
"varianshomogenitet ikke er brutt i en grad som svekker robustheten til "
"ANOVA. Dette var poenget George Box kom med i sitatet ovenfor. På samme måte "
"kan det hende at forutsetningen om varianshomogenitet ikke er oppfylt hvis "
"utvalgsstørrelsen er ganske liten, og at en Levene-test likevel kan være "
"ikke-signifikant (dvs. *p* > 0,05). Dette betyr at du, ved siden av enhver "
"statistisk test av om forutsetningen er oppfylt, alltid bør plotte "
"standardavviket rundt gjennomsnittene for hver gruppe / kategori i analysen… "
"bare for å se om de ser ganske like ut (dvs. varianshomogenitet) eller ikke."

#: ../../Ch13/Ch13_ANOVA_06.rst:148 ../../Ch13/Ch13_ANOVA_06.rst:152
msgid "``Levene test`` output for ``One-Way ANOVA`` in jamovi"
msgstr "Utgave fra ``Levene test`` for ``One-Way ANOVA`` i jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:157
msgid "Removing the homogeneity of variance assumption"
msgstr "Analyser som ikke forutsetter varianshomogenitet"

#: ../../Ch13/Ch13_ANOVA_06.rst:159
msgid ""
"In our example, the homogeneity of variance assumption turned out to be a "
"pretty safe one: the Levene test came back non-significant (notwithstanding "
"that we should also look at the plot of standard deviations), so we probably "
"don’t need to worry. However, in real life we aren’t always that lucky. How "
"do we save our ANOVA when the homogeneity of variance assumption is "
"violated? If you recall from our discussion of *t*-tests, we’ve seen this "
"problem before. The Student *t*-test assumes equal variances, so the "
"solution was to use the Welch *t*-test, which does not. In fact, :ref:`Welch "
"(1951) <Welch_1951>` also showed how we can solve this problem for ANOVA too "
"(the **Welch One-way test**). It’s implemented in jamovi using the ``One-Way "
"ANOVA`` analysis. This is a specific analysis approach just for one-way "
"ANOVA, and to run the Welch one-way ANOVA for our example, we would re-run "
"the analysis as previously, but this time use the jamovi ``ANOVA`` → ``One "
"Way ANOVA`` analysis command, and check the option ``Don't assume equal "
"(Welch’s)`` (see :numref:`fig-anova4a`)."
msgstr ""
"I vårt eksempel viste det seg at forutsetningen om varianshomogenitet var "
"ganske trygg: Levene-testen viste seg å være ikke-signifikant (selv om vi "
"også bør se på plottet av standardavvik), så vi trenger sannsynligvis ikke å "
"bekymre oss. Men i virkeligheten er vi ikke alltid like heldige. Hvordan "
"redder vi ANOVA-en vår når forutsetningen om varianshomogenitet er brutt? "
"Hvis du husker fra diskusjonen vår om *t*-tester, har vi sett dette "
"problemet før. Student *t*-testen forutsetter lik varians, så løsningen var "
"å bruke Welch *t*-testen, som ikke gjør det. Faktisk viste :ref:`Welch "
"(1951) <Welch_1951>` også hvordan vi kan løse dette problemet for ANOVA også "
"(**Welch One-way test**). Den er implementert i jamovi ved hjelp av ``One-"
"Way ANOVA``-analysen. Dette er en spesifikk analysetilnærming bare for "
"enveis ANOVA, og for å kjøre Welch enveis ANOVA for vårt eksempel, kjører vi "
"analysen på nytt som tidligere, men denne gangen bruker vi jamovi ``ANOVA`` "
"→ ``One Way ANOVA``-analysen, og merker av for alternativet ``Don't assume "
"equal (Welch's)`` (se :numref:`fig-anova4a`)."

#: ../../Ch13/Ch13_ANOVA_06.rst:176 ../../Ch13/Ch13_ANOVA_06.rst:180
msgid "Welch’s test as part of the One-Way ANOVA analysis in jamovi"
msgstr "Welchs test som en del av enveis ANOVA i jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:184
msgid ""
"To understand what’s happening here, let’s compare these numbers with those "
"obtained earlier in section :doc:`Ch13_ANOVA_03`, namely: *F*\\(2,15) = "
"18.611, *p* = 0.00009. As shown in :numref:`fig-anova4a`, these values are "
"also displayed in the ``One-Way ANOVA`` table (in the row starting with "
"``Fisher's``) if the option ``Assume equal (Fisher's)`` was chosen."
msgstr ""
"For å forstå hva som skjer her, kan vi sammenligne disse tallene med dem vi "
"fikk tidligere i avsnitt :doc:`Ch13_ANOVA_03`, nemlig *F*\\(2,15) = 18,611, "
"*p* = 0,00009. Som vist i :numref:`fig-anova4a`, vises disse verdiene også i "
"tabellen ``One-Way ANOVA`` (i raden som begynner med ``Fisher's``) hvis "
"alternativet ``Assume equal (Fisher's)`` ble valgt."

#: ../../Ch13/Ch13_ANOVA_06.rst:190
msgid ""
"Okay, so originally our ANOVA gave us the result *F*\\(2,15) = 18.6, whereas "
"the Welch one-way test gave us *F*\\(2,9.49) = 26.32. In other words, the "
"Welch test has reduced the within-groups degrees of freedom from 15 to 9.49, "
"and the *F*-value has increased from 18.6 to 26.32."
msgstr ""
"Ok, så opprinnelig ga vår ANOVA oss resultatet *F*\\(2,15) = 18,6, mens "
"Welchs enveistest ga oss *F*\\(2,9,49) = 26,32. Welch-testen har med andre "
"ord redusert frihetsgradene innenfor gruppene fra 15 til 9,49, og *F*-"
"verdien har økt fra 18,6 til 26,32."

#: ../../Ch13/Ch13_ANOVA_06.rst:199
msgid "Checking the normality assumption"
msgstr "Sjekk forutsetningen om normalfordeling"

#: ../../Ch13/Ch13_ANOVA_06.rst:201
msgid ""
"Testing the normality assumption is relatively straightforward. We covered "
"most of what you need to know in section :doc:`../Ch11/Ch11_tTest_08`. The "
"only thing we really need to do is draw a QQ plot and, in addition if it is "
"available, run the Shapiro-Wilk test. The QQ plot is shown in :numref:`fig-"
"anova5` and it looks pretty normal to me. If the Shapiro-Wilk test is not "
"significant (i.e. *p* > 0.05) then this indicates that the assumption of "
"normality is not violated. However, as with Levene’s test, if the sample "
"size is large then a significant Shapiro-Wilk test may in fact be a false "
"positive, where the assumption of normality is not violated in any "
"substantive problematic sense for the analysis. And, similarly, a very small "
"sample can produce false negatives. That’s why a visual inspection of the QQ "
"plot is important."
msgstr ""
"Det er relativt enkelt å sjekke forutsetningen om normalfordeling. Vi har "
"dekket det meste av det du trenger å vite i avsnitt :doc:`../Ch11/"
"Ch11_tTest_08`. Det eneste vi egentlig trenger å gjøre, er å tegne et QQ-"
"plott og i tillegg kjøre Shapiro-Wilk-testen, hvis den er tilgjengelig. QQ-"
"plottet vises i :numref:`fig-anova5`, og jeg synes det ser ganske normalt "
"ut. Hvis Shapiro-Wilk-testen ikke er signifikant (dvs. *p* > 0,05), "
"indikerer dette at forutsetningen om normalfordeling ikke er brutt. Men som "
"med Levenes test, kan en signifikant Shapiro-Wilk-test, hvis utvalget er "
"stort, faktisk være en falsk positiv, der forutsetningen om normalfordeling "
"ikke er brutt i noen vesentlig problematisk forstand for analysen. Og på "
"samme måte kan et svært lite utvalg gi falske negative resultater. Derfor er "
"det viktig med en visuell inspeksjon av QQ-plottet."

#: ../../Ch13/Ch13_ANOVA_06.rst:214
msgid ""
"Alongside inspecting the QQ plot for any deviations from normality, the "
"Shapiro-Wilk test for our data does show a non-significant effect, with *p* "
"= 0.6053 (see :numref:`fig-anova4a`). This therefore supports the QQ plot "
"assessment; both checks find no indication that normality is violated."
msgstr ""
"I tillegg til å inspisere QQ-plottet for eventuelle avvik fra "
"normalfordelingen, viser Shapiro-Wilk-testen for dataene våre en ikke-"
"signifikant effekt, med *p* = 0,6053 (se :numref:`fig-anova4a`). Dette "
"støtter derfor QQ-plottvurderingen; begge kontrollene finner ingen "
"indikasjon på at forutsetning om normalfordelingen er brutt."

#: ../../Ch13/Ch13_ANOVA_06.rst:222 ../../Ch13/Ch13_ANOVA_06.rst:226
msgid "QQ-plot produced from jamovi One-Way ANOVA options"
msgstr "QQ-plott produsert fra jamovi One-Way ANOVA-alternativer"

#: ../../Ch13/Ch13_ANOVA_06.rst:231
msgid "Removing the normality assumption"
msgstr "Brudd på forutsetningen om normalfordeling"

#: ../../Ch13/Ch13_ANOVA_06.rst:233
msgid ""
"Now that we’ve seen how to check for normality, we are led naturally to ask "
"what we can do to address violations of normality. In the context of a One-"
"way ANOVA, the easiest solution is probably to switch to a non-parametric "
"test (i.e., one that doesn’t rely on any particular assumption about the "
"kind of distribution involved). We’ve seen non-parametric tests before, in "
"section :doc:`../Ch11/Ch11_tTest_09`. When you only have two groups, the "
"Mann-Whitney or the Wilcoxon test provides the non-parametric alternative "
"that you need. When you’ve got three or more groups, you can use the "
"**Kruskal-Wallis rank sum test** (:ref:`Kruskal & Wallis, 1952 "
"<Kruskal_1952>`). So that’s the test we’ll talk about next."
msgstr ""
"Nå som vi har sett hvordan vi kan sjekke for normalfordeling, er det "
"naturlig å spørre hva vi kan gjøre for å håndtere brudd på forutsetningen om "
"normalfordeling. I forbindelse med en enveis ANOVA er den enkleste løsningen "
"sannsynligvis å gå over til en ikke-parametrisk test (dvs. en test som ikke "
"er avhengig av noen spesiell antakelse om hva slags fordeling som er "
"involvert). Vi har sett ikke-parametriske tester før, i avsnitt :doc:`../"
"Ch11/Ch11_tTest_09`. Når du bare har to grupper, er Mann-Whitney- eller "
"Wilcoxon-testen det ikke-parametriske alternativet du trenger. Når du har "
"tre eller flere grupper, kan du bruke **Kruskal-Wallis rangsumtest** (:ref:"
"`Kruskal & Wallis, 1952 <Kruskal_1952>`). Det er den neste testen vi skal "
"snakke om."

#: ../../Ch13/Ch13_ANOVA_06.rst:244
msgid ""
"The Kruskal-Wallis test is surprisingly similar to ANOVA, in some ways. In "
"ANOVA we started with Y\\ :sub:`ik`, the value of the outcome variable for "
"the *i*-th person in the *k*-th group. For the Kruskal-Wallis test what "
"we’ll do is rank order all of these Y\\ :sub:`ik` values and conduct our "
"analysis on the ranked data."
msgstr ""
"Kruskal-Wallis-testen er overraskende lik ANOVA, på noen måter. I ANOVA "
"startet vi med Y\\ :sub:`ik`, verdien av utfallsvariabelen for den *i*-te "
"personen i den *k*-te gruppen. I Kruskal-Wallis-testen skal vi rangere alle "
"disse Y\\ :sub:`ik`-verdiene og utføre analysen på de rangerte dataene."

#: ../../Ch13/Ch13_ANOVA_06.rst:250
msgid ""
"So let’s let R\\ :sub:`ik` refer to the ranking given to the *i*-th member "
"of the *k*-th group. Now, let’s calculate R̄\\ :sub:`k`, the average rank "
"given to observations in the *k*-th group:"
msgstr ""
"La oss la R\\ :sub:`ik` referere til rangeringen som er gitt til det *i*-te "
"medlemmet av den *k*-te gruppen. La oss nå beregne R̄\\ :sub:`k`, den "
"gjennomsnittlige rangeringen som er gitt til observasjonene i den *k*-te "
"gruppen:"

#: ../../Ch13/Ch13_ANOVA_06.rst:254
msgid ""
"\\bar{R}_k = \\frac{1}{N_K} \\sum_{i} R_{ik}\n"
"\n"
msgstr ""
"\\bar{R}_k = \\frac{1}{N_K} \\sum_{i} R_{ik}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:256
msgid "and let’s also calculate R̄, the grand mean rank"
msgstr "og la oss også beregne R̄, den totale gjennomsnittlige rangen"

#: ../../Ch13/Ch13_ANOVA_06.rst:258
msgid ""
"\\bar{R} = \\frac{1}{N} \\sum_{i} \\sum_{k} R_{ik}\n"
"\n"
msgstr ""
"\\bar{R} = \\frac{1}{N} \\sum_{i} \\sum_{k} R_{ik}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:260
msgid ""
"Now that we’ve done this, we can calculate the squared deviations from the "
"grand mean rank R̄. When we do this for the individual scores, i.e., if we "
"calculate (R\\ :sub:`ik` – R̄)², what we have is a “nonparametric” measure of "
"how far the *ik*-th observation deviates from the grand mean rank. When we "
"calculate the squared deviation of the group means from the grand means, i."
"e., if we calculate (R̄\\ :sub:`k` – R̄)², then what we have is a "
"nonparametric measure of how much the *group* deviates from the grand mean "
"rank. With this in mind, we’ll follow the same logic that we did with ANOVA "
"and define our *ranked* sums of squares measures, much like we did earlier. "
"First, we have our “total ranked sums of squares”"
msgstr ""
"Nå som vi har gjort dette, kan vi beregne de kvadrerte avvikene fra den "
"totale gjennomsnittsverdien R̄. Når vi gjør dette for de individuelle "
"skårene, dvs. hvis vi beregner (R\\ :sub:`ik` - R̄)², har vi et «ikke-"
"parametrisk» mål på hvor langt den *ik*-te observasjonen avviker fra den "
"totale gjennomsnittsrangeringen. Når vi beregner det kvadrerte avviket til "
"gruppegjennomsnittet fra det totale gjennomsnittet, dvs. hvis vi beregner "
"(R̄\\ :sub:`k` - R̄)², har vi et ikke-parametrisk mål på hvor mye *gruppen* "
"avviker fra den totale gjennomsnittsrangeringen. Med dette i bakhodet følger "
"vi samme logikk som vi gjorde med ANOVA og definerer våre *rangerte* "
"kvadratsummer (*ranked sums of squares*), omtrent som vi gjorde tidligere. "
"Først har vi våre «totale rangerte kvadratsummen»"

#: ../../Ch13/Ch13_ANOVA_06.rst:271
msgid ""
"\\mbox{RSS}_{tot} = \\sum_k \\sum_i ( R_{ik} - \\bar{R} )^2\n"
"\n"
msgstr ""
"\\mbox{RSS}_{tot} = \\sum_k \\sum_i ( R_{ik} - \\bar{R} )^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:273
msgid ""
"and we can define the “between groups ranked sums of squares” like this:"
msgstr "og vi kan definere de «rangerte kvadratsummene mellom gruppene» slik:"

#: ../../Ch13/Ch13_ANOVA_06.rst:275
msgid ""
"\\begin{array}{rcl}\n"
"\\mbox{RSS}_{b} &=& \\sum_k \\sum_i ( \\bar{R}_k  - \\bar{R} )^2 \\\\\n"
"               &=& \\sum_k N_k ( \\bar{R}_k  - \\bar{R} )^2\n"
"\\end{array}"
msgstr ""
"\\begin{array}{rcl}\n"
"\\mbox{RSS}_{b} &=& \\sum_k \\sum_i ( \\bar{R}_k  - \\bar{R} )^2 \\\\\n"
"               &=& \\sum_k N_k ( \\bar{R}_k  - \\bar{R} )^2\n"
"\\end{array}"

#: ../../Ch13/Ch13_ANOVA_06.rst:282
msgid ""
"So, if the null hypothesis is true and there are no true group differences "
"at all, you’d expect the between group rank sums RSS\\ :sub:`b` to be very "
"small, much smaller than the total rank sums RSS\\ :sub:`tot`. Qualitatively "
"this is very much the same as what we found when we went about constructing "
"the ANOVA *F*-statistic, but for technical reasons the Kruskal-Wallis test "
"statistic, usually denoted *K*, is constructed in a slightly different way,"
msgstr ""
"Så hvis nullhypotesen er sann og det ikke er noen sanne gruppeforskjeller i "
"det hele tatt, vil du forvente at rangsummene mellom gruppene RSS\\ :sub:`b` "
"er svært små, mye mindre enn de totale rangsummene RSS\\ :sub:`tot`. "
"Kvalitativt sett er dette omtrent det samme som vi fant da vi beregnet ANOVA "
"*F*-statistikken, men av tekniske årsaker er Kruskal-Wallis-"
"teststatistikken, vanligvis betegnet *K*, beregnet på en litt annen måte,"

#: ../../Ch13/Ch13_ANOVA_06.rst:291
msgid ""
"K = (N - 1) \\times \\frac{\\mbox{RSS}_b}{\\mbox{RSS}_{tot}}\n"
"\n"
msgstr ""
"K = (N - 1) \\times \\frac{\\mbox{RSS}_b}{\\mbox{RSS}_{tot}}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:293
msgid ""
"and if the null hypothesis is true, then the sampling distribution of *K* is "
"*approximately* χ² with *G* - 1 degrees of freedom (where *G* is the number "
"of groups). The larger the value of *K*, the less consistent the data are "
"with the null hypothesis, so this is a one-sided test. We reject H\\ :sub:"
"`0` when *K* is sufficiently large."
msgstr ""
"og hvis nullhypotesen er sann, er utvalgsfordelingen av *K* *tilnærmet* χ² "
"med *G* - 1 frihetsgrader (hvor *G* er antall grupper). Jo større verdien av "
"*K* er, desto mindre konsistente er dataene med nullhypotesen, så dette er "
"en ensidig test. Vi forkaster H\\ :sub:`0` når *K* er tilstrekkelig stor."

#: ../../Ch13/Ch13_ANOVA_06.rst:299
msgid ""
"The description in the previous section illustrates the logic behind the "
"Kruskal-Wallis test. At a conceptual level, this is the right way to think "
"about how the test works. However, from a purely mathematical perspective "
"it’s needlessly complicated. I won’t show you the derivation, but you can "
"use a bit of algebraic jiggery-pokery [#]_ to show that the equation for *K* "
"can be rewritten as"
msgstr ""
"Beskrivelsen i forrige avsnitt illustrerer logikken bak Kruskal-Wallis-"
"testen. På et konseptuelt nivå er dette den riktige måten å tenke på hvordan "
"testen fungerer. Fra et rent matematisk perspektiv er det imidlertid "
"unødvendig komplisert. Jeg skal ikke vise deg utledningen, men du kan bruke "
"litt algebraisk jiggery-pokery [#]_ for å vise at ligningen for *K* kan "
"skrives om til"

#: ../../Ch13/Ch13_ANOVA_06.rst:306
msgid ""
"K = \\frac{12}{N(N-1)} \\sum_k N_k {\\bar{R}_k}^2 - 3(N+1)\n"
"\n"
msgstr ""
"K = \\frac{12}{N(N-1)} \\sum_k N_k {\\bar{R}_k}^2 - 3(N+1)\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:308
msgid ""
"It’s this last equation that you sometimes see given for *K*. This is way "
"easier to calculate than the version I described in the previous section, "
"but it’s just that it’s totally meaningless to actual humans. It’s probably "
"best to think of *K* the way I described it earlier, as an analogue of ANOVA "
"based on ranks. But keep in mind that the test statistic that gets "
"calculated ends up with a rather different look to it than the one we used "
"for our original ANOVA."
msgstr ""
"Det er denne siste ligningen som du noen ganger ser oppgitt for *K*. Den er "
"mye enklere å beregne enn den versjonen jeg beskrev i forrige avsnitt, men "
"det er bare det at den er helt meningsløs for mennesker. Det er nok best å "
"tenke på *K* slik jeg beskrev det tidligere, som en analog til ANOVA basert "
"på rangeringer. Men husk at teststatistikken som blir beregnet, ender opp "
"med å se ganske annerledes ut enn den vi brukte for den opprinnelige ANOVAen."

#: ../../Ch13/Ch13_ANOVA_06.rst:316
msgid ""
"But wait, there’s more! Dear lord, why is there always *more*? The story "
"I’ve told so far is only actually true when there are no ties in the raw "
"data. That is, if there are no two observations that have exactly the same "
"value. If there *are* ties, then we have to introduce a correction factor to "
"these calculations. At this point I’m assuming that even the most diligent "
"reader has stopped caring (or at least formed the opinion that the tie-"
"correction factor is something that doesn’t require their immediate "
"attention). So I’ll very quickly tell you how it’s calculated, and omit the "
"tedious details about *why* it’s done this way. Suppose we construct a "
"frequency table for the raw data, and let f\\ :sub:`j` be the number of "
"observations that have the *j*-th unique value. This might sound a bit "
"abstract, so here’s a concrete example from the frequency table of ``mood."
"gain`` from the |clinicaltrial|_ data set:"
msgstr ""
"Men vent, det er mer! Herregud, hvorfor er det alltid *mer*? Historien jeg "
"har fortalt så langt, er faktisk bare sann når det ikke er noen bindinger i "
"rådataene. Det vil si hvis det ikke finnes to observasjoner som har nøyaktig "
"samme verdi. Hvis det *er* bindinger, må vi innføre en korreksjonsfaktor i "
"disse beregningene. På dette tidspunktet antar jeg at selv den mest flittige "
"leser har sluttet å bry seg (eller i det minste har dannet seg en oppfatning "
"om at korreksjonsfaktoren ikke er noe som krever umiddelbar oppmerksomhet). "
"Så jeg skal raskt fortelle deg hvordan den beregnes, og utelate de kjedelige "
"detaljene om *hvorfor* den gjøres på denne måten. Anta at vi lager en "
"frekvenstabell for rådataene, og la f\\ :sub:`j` være antallet observasjoner "
"som har den *j*-te unike verdien. Dette høres kanskje litt abstrakt ut, så "
"her er et konkret eksempel fra frekvenstabellen for ``mood.gain`` fra "
"datasettet |clinicaltrial|_:"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.2"
msgstr "0.2"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.8"
msgstr "0.8"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.9"
msgstr "0.9"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.1"
msgstr "1.1"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.2"
msgstr "1.2"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.3"
msgstr "1.3"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.4"
msgstr "1.4"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.7"
msgstr "1.7"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.8"
msgstr "1.8"

#: ../../Ch13/Ch13_ANOVA_06.rst:336
msgid ""
"Looking at this table, notice that the third entry in the frequency table "
"has a value of 2. Since this corresponds to a ``mood.gain`` of 0.3, this "
"table is telling us that two people’s mood increased by 0.3. More to the "
"point, in the mathematical notation I introduced above, this is telling us "
"that f\\ :sub:`3` = 2. Yay. So, now that we know this, the tie correction "
"factor (TCF) is:"
msgstr ""
"Når vi ser på denne tabellen, legger vi merke til at den tredje oppføringen "
"i frekvenstabellen har verdien 2. Siden dette tilsvarer en ``mood.gain`` på "
"0,3, forteller denne tabellen oss at humøret til to personer økte med 0,3. I "
"den matematiske notasjonen jeg introduserte ovenfor, forteller dette oss at "
"f\\ :sub:`3` = 2. Jippi. Nå som vi vet dette, er korreksjonsfaktoren for "
"forbundne rangeringer (*tie correction factor*; TCF):"

#: ../../Ch13/Ch13_ANOVA_06.rst:343
msgid ""
"\\mbox{TCF} = 1 - \\frac{\\sum_j {f_j}^3 - f_j}{N^3 - N}\n"
"\n"
msgstr ""
"\\mbox{TCF} = 1 - \\frac{\\sum_j {f_j}^3 - f_j}{N^3 - N}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:345
msgid ""
"The tie-corrected value of the Kruskal-Wallis statistic is obtained by "
"dividing the value of *K* by this quantity. It is this tie-corrected version "
"that jamovi calculates. And at long last, we’re actually finished with the "
"theory of the Kruskal-Wallis test. I’m sure you’re all terribly relieved "
"that I’ve cured you of the existential anxiety that naturally arises when "
"you realise that you *don’t* know how to calculate the tie-correction factor "
"for the Kruskal-Wallis test. Right?"
msgstr ""
"Den uavhengighetskorrigerte verdien av Kruskal-Wallis-statistikken får du "
"ved å dividere verdien av *K* med denne størrelsen. Det er denne tie-"
"korrigerte versjonen jamovi beregner. Og endelig er vi faktisk ferdige med "
"teorien om Kruskal-Wallis-testen. Dere er sikkert veldig lettet over at jeg "
"har kurert dere for den eksistensielle angsten som naturlig nok oppstår når "
"man innser at man *ikke* vet hvordan man beregner tie-korreksjonsfaktoren "
"for Kruskal-Wallis-testen. Eller hva?"

#: ../../Ch13/Ch13_ANOVA_06.rst:355
msgid "How to run the Kruskal-Wallis test in jamovi"
msgstr "Slik kjører du Kruskal-Wallis-testen i jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:357
msgid ""
"Despite the horror that we’ve gone through in trying to understand what the "
"Kruskal-Wallis test actually does, it turns out that running the test is "
"pretty painless, since jamovi has an analysis as part of the ``ANOVA`` "
"analysis set called ``Non-Parametric`` - ``One-Way ANOVA (Kruskall-"
"Wallis)``. Most of the time you’ll have data like the |clinicaltrial|_ data "
"set, in which you have your outcome variable ``mood.gain`` and a grouping "
"variable ``drug``. If so, you can just go ahead and run the analysis in "
"jamovi. What this gives us is a Kruskal-Wallis χ² = 12.076, *df* = 2, *p*-"
"value = 0.00239, as in :numref:`fig-anova6`."
msgstr ""
"Til tross for at vi har gått gjennom en hel del for å prøve å forstå hva "
"Kruskal-Wallis-testen egentlig gjør, viser det seg at det er ganske "
"smertefritt å kjøre testen, siden jamovi har en analyse som en del av "
"analysesettet ``ANOVA`` som heter ``Non-Parametric`` - ``One-Way ANOVA "
"(Kruskall-Wallis)``. Som oftest vil du ha data som i datasettet |"
"clinicaltrial|_, der du har utfallsvariabelen ``mood.gain`` og en "
"grupperingsvariabel ``drug``. I så fall kan du bare gå videre og kjøre "
"analysen i jamovi. Dette gir oss en Kruskal-Wallis χ² = 12,076, *df* = 2, "
"*p*-verdi = 0,00239, som i :numref:`fig-anova6`."

#: ../../Ch13/Ch13_ANOVA_06.rst:369
msgid "non-parametric ``One-Way ANOVA (Kruskal-Wallis)`` in jamovi"
msgstr "ikke-parametrisk ``One-Way ANOVA (Kruskal-Wallis)`` i jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:373
msgid "Non-parametric ``One-Way ANOVA (Kruskal-Wallis)`` in jamovi"
msgstr "Ikke-parametrisk ``One-Way ANOVA (Kruskal-Wallis)`` i jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:380
msgid "A technical term."
msgstr "En teknisk term."

#: ../../Ch13/Ch13_ANOVA_07.rst:4
msgid "Repeated measures one-way ANOVA"
msgstr "Enveis ANOVA for gjentatte målinger"

#: ../../Ch13/Ch13_ANOVA_07.rst:6
msgid ""
"The one-way repeated measures ANOVA test is a statistical method of testing "
"for significant differences between three or more groups where the same "
"participants are used in each group (or each participant is closely matched "
"with participants in other experimental groups). For this reason, there "
"should always be an equal number of scores (data points) in each "
"experimental group. This type of design and analysis can also be called a "
"“related ANOVA” or a “within-subjects ANOVA”."
msgstr ""
"Enveis ANOVA for gjentatte målinger er en statistisk metode for å teste for "
"signifikante forskjeller mellom tre eller flere grupper der de samme "
"deltakerne brukes i hver gruppe (eller der hver deltaker er tett matchet med "
"deltakere i andre eksperimentgrupper). Av denne grunn bør det alltid være "
"like mange poengsummer (datapunkter) i hver forsøksgruppe. Denne typen "
"design og analyse kan også kalles en «relatert ANOVA» eller en «*within-"
"subjects* ANOVA»."

#: ../../Ch13/Ch13_ANOVA_07.rst:14
msgid ""
"The logic behind a repeated measures ANOVA is very similar to that of an "
"independent ANOVA (sometimes called a “between-subjects” ANOVA). You’ll "
"remember that earlier we showed that in a between-subjects ANOVA total "
"variability is partitioned into between-groups variability (SS\\ :sub:`b`) "
"and within-groups variability (SS\\ :sub:`w`), and after each is divided by "
"the respective degrees of freedom to give MS\\ :sub:`b` and MS\\ :sub:`w` "
"(see :numref:`tab-anovatable`) the *F*-ratio is calculated as:"
msgstr ""
"Logikken bak en ANOVA for gjentatte målinger er svært lik logikken bak en "
"uavhengig ANOVA (noen ganger kalt en «between-subjects»-ANOVA). Du husker "
"sikkert at vi tidligere viste at i en between-subjects-ANOVA deles den "
"totale variabiliteten inn i variabilitet mellom grupper (SS\\ :sub:`b`) og "
"variabilitet innenfor gruppene (SS\\ :sub:`w`), og etter at hver av dem er "
"delt på de respektive frihetsgradene for å gi MS\\ :sub:`b` og MS\\ :sub:`w` "
"(se :numref:`tab-anovatable`), beregnes *F*-forholdet som følger:"

#: ../../Ch13/Ch13_ANOVA_07.rst:23
msgid "*F* = MS\\ :sub:`b` / MS\\ :sub:`w`"
msgstr "*F* = MS\\ :sub:`b` / MS\\ :sub:`w`"

#: ../../Ch13/Ch13_ANOVA_07.rst:25
msgid ""
"In a repeated measures ANOVA, the *F*-ratio is calculated in a similar way, "
"but whereas in an independent ANOVA the within-group variability (SS\\ :sub:"
"`w`) is used as the basis for the MS\\ :sub:`w` denominator, in a repeated "
"measures ANOVA the SS\\ :sub:`w` is partioned into two parts. As we are "
"using the same subjects in each group, we can remove the variability due to "
"the individual differences between subjects (referred to as SS\\ :sub:"
"`subjects`) from the within-groups variability. We won’t go into too much "
"technical detail about how this is done, but essentially each subject "
"becomes a level of a factor called subjects. The variability in this within-"
"subjects factor is then calculated in the same way as any between-subjects "
"factor. And then we can subtract SS\\ :sub:`subjects` from SS\\ :sub:`w` to "
"provide a smaller SS\\ :sub:`error` term:"
msgstr ""
"I en ANOVA for gjentatte målinger beregnes *F*-ratioen på samme måte, men "
"mens man i en uavhengig ANOVA bruker variabiliteten innenfor gruppen (SS\\ :"
"sub:`w`) som grunnlag for nevneren i MS\\ :sub:`w`, deles SS\\ :sub:`w` i en "
"ANOVA for gjentatte målinger opp i to deler. Ettersom vi bruker de samme "
"forsøkspersonene i hver gruppe, kan vi fjerne variabiliteten som skyldes "
"individuelle forskjeller mellom forsøkspersonene (referert til som SS\\ :sub:"
"`subjects`) fra variabiliteten innenfor gruppene. Vi skal ikke gå for mye "
"inn på tekniske detaljer om hvordan dette gjøres, men i bunn og grunn blir "
"hver forsøksperson et nivå av en faktor som kalles forsøkspersoner. "
"Variabiliteten i denne innenfor-gruppen-faktoren beregnes deretter på samme "
"måte som en hvilken som helst faktor mellom grupper. Og så kan vi trekke "
"SS\\ :sub:`subjects` fra SS\\ :sub:`w` for å få et mindre SS\\ :sub:`error`-"
"term:"

#: ../../Ch13/Ch13_ANOVA_07.rst:40
msgid "Independent ANOVA:       SS\\ :sub:`error` = SS\\ :sub:`w`"
msgstr "Uavhengig ANOVA: SS\\ :sub:`error` = SS\\ :sub:`w`"

#: ../../Ch13/Ch13_ANOVA_07.rst:41
msgid ""
"Repeated Measures ANOVA: SS\\ :sub:`error` = SS\\ :sub:`w - SS\\ :sub:"
"`subjects`"
msgstr ""
"ANOVA for gjentatte målinger: SS\\ :sub:`error` = SS\\ :sub:`w - SS\\ :sub:"
"`subjekter`"

#: ../../Ch13/Ch13_ANOVA_07.rst:43
msgid ""
"This change in SS\\ :sub:`error` term often leads to a more powerful "
"statistical test, but this does depend on whether the reduction in the SS\\ :"
"sub:`error` more than compensates for the reduction in degrees of freedom "
"for the error term: the degrees of freedom go from (*n* - *k*)\\ [#]_ to "
"(*n* - 1)(*k* - 1) remembering that there are more subjects in the "
"independent ANOVA design."
msgstr ""
"Denne endringen i SS\\ :sub:`error`-termen fører ofte til en sterkere "
"statistisk test, men dette avhenger av om reduksjonen i SS\\ :sub:`error` "
"mer enn oppveier for reduksjonen i frihetsgrader for feiltermen: "
"Frihetsgradene går fra (*n* - *k*)\\ [#]_ til (*n* - 1)(*k* - 1), med tanke "
"på at det er flere forsøkspersoner i den uavhengige ANOVA-designen."

#: ../../Ch13/Ch13_ANOVA_07.rst:51
msgid "Repeated measures ANOVA in jamovi"
msgstr "ANOVA for gjentatte målinger i jamovi"

#: ../../Ch13/Ch13_ANOVA_07.rst:53
msgid ""
"First, we need some data. :ref:`Geschwind (1972) <Geschwind_1972>` has "
"suggested that the exact nature of a patient’s language deficit following a "
"stroke can be used to diagnose the specific region of the brain that has "
"been damaged. A researcher is concerned with identifying the specific "
"communication difficulties experienced by six patients suffering from "
"Broca’s Aphasia (a language deficit commonly experienced following a stroke)."
msgstr ""
"Først trenger vi noen data. :ref:`Geschwind (1972) <Geschwind_1972>` har "
"foreslått at den nøyaktige karakteren av en pasients språkvansker etter et "
"hjerneslag kan brukes til å diagnostisere den spesifikke regionen i hjernen "
"som har blitt skadet. En forsker er opptatt av å identifisere de spesifikke "
"kommunikasjonsvanskene hos seks pasienter som lider av Brocas afasi (en "
"språkvanske som ofte oppstår etter et hjerneslag)."

#: ../../Ch13/Ch13_ANOVA_07.rst:60
msgid "Number of attempts successfully completed on three experimental tasks."
msgstr "Antall forsøk som ble fullført på tre eksperimentelle oppgaver."

#: ../../Ch13/Ch13_ANOVA_07.rst:64
msgid "Participant"
msgstr "Deltaker"

#: ../../Ch13/Ch13_ANOVA_07.rst:64
msgid "Speech"
msgstr "Tale"

#: ../../Ch13/Ch13_ANOVA_07.rst:64
msgid "Conceptual"
msgstr "Konseptuell"

#: ../../Ch13/Ch13_ANOVA_07.rst:64
msgid "Syntax"
msgstr "Syntaks"

#: ../../Ch13/Ch13_ANOVA_07.rst:70
msgid "9"
msgstr "9"

#: ../../Ch13/Ch13_ANOVA_07.rst:79
msgid ""
"The patients were required to complete three word recognition tasks. On the "
"first (speech production) task, patients were required to repeat single "
"words read out aloud by the researcher. On the second (conceptual) task, "
"designed to test word comprehension, patients were required to match a "
"series of pictures with their correct name. On the third (syntax) task, "
"designed to test knowledge of correct word order, patients were asked to "
"reorder syntactically incorrect sentences. Each patient completed all three "
"tasks. The order in which patients attempted the tasks was counterbalanced "
"between participants. Each task consisted of a series of 10 attempts. The "
"number of attempts successfully completed by each patient are shown in :"
"numref:`tab-RManova`. Enter these data into jamovi ready for analysis (or "
"take a short-cut and load the |broca|_ data set)."
msgstr ""
"Pasientene måtte gjennomføre tre ordgjenkjenningsoppgaver. I den første "
"oppgaven (taleproduksjon) skulle pasientene gjenta enkeltord som ble lest "
"høyt av forskeren. I den andre oppgaven (begrepsforståelse), som skulle "
"teste ordforståelsen, skulle pasientene matche en rekke bilder med riktig "
"navn. I den tredje oppgaven (syntaks), som skulle teste kunnskap om korrekt "
"ordstilling, ble pasientene bedt om å omorganisere syntaktisk ukorrekte "
"setninger. Hver pasient fullførte alle tre oppgavene. Rekkefølgen pasientene "
"løste oppgavene i, ble utjevnet mellom deltakerne. Hver oppgave besto av en "
"serie på 10 forsøk. Antall forsøk som ble fullført av hver pasient, vises i :"
"numref:`tab-RManova`. Legg inn disse dataene i jamovi klar for analyse "
"(eller ta en snarvei og last inn datasettet |broca|_)."

#: ../../Ch13/Ch13_ANOVA_07.rst:93
msgid ""
"To perform a one-way related ANOVA in jamovi, open the one-way repeated "
"measures ANOVA dialogue box, as in :numref:`fig-RManova1`, via ``ANOVA - "
"Repeated Measures ANOVA``. Then:"
msgstr ""
"For å utføre en enveis ANOVA i jamovi, åpner du dialogboksen for enveis "
"ANOVA for gjentatte målinger, som i :numref:`fig-RManova1`, via ``ANOVA - "
"Repeated Measures ANOVA``. Åpne deretter:"

#: ../../Ch13/Ch13_ANOVA_07.rst:97
msgid ""
"Enter a name for the ``Repeated Measures Factors`` (orginally: ``RM Factor …"
"``). This should be a label that you choose to describe the conditions "
"repeated by all participants. For example, to describe the speech, "
"conceptual and syntax tasks completed by all participants a suitable label "
"would be ``Task``. Note that this new factor name represents the independent "
"variable in the analysis."
msgstr ""
"Skriv inn et navn for ``Repeated Measures Factors`` (opprinnelig: ``RM "
"Factor…``). Dette bør være en etikett som du velger for å beskrive "
"forholdene som gjentas av alle deltakerne. For eksempel, for å beskrive "
"tale-, begreps- og syntaksoppgavene som ble fullført av alle deltakerne, vil "
"en passende etikett være ``Task``. Merk at dette nye faktornavnet "
"representerer den uavhengige variabelen i analysen."

#: ../../Ch13/Ch13_ANOVA_07.rst:104
msgid ""
"Add a third level in the ``Repeated Measures Factors`` variable box, as "
"there are three levels representing the three tasks: ``Speech``, "
"``Conceptual`` and ``Syntax``. Change the labels of the levels accordingly."
msgstr ""
"Legg til et tredje nivå i variabelboksen ``Repeated Measures Factors``, "
"siden det er tre nivåer som representerer de tre oppgavene: ``Speech``, "
"``Conceptual`` og ``Syntax``. Endre etikettene på nivåene tilsvarende."

#: ../../Ch13/Ch13_ANOVA_07.rst:108
msgid ""
"Then move each of the levels variables across to the ``Repeated Measures "
"Cells`` text box."
msgstr ""
"Flytt deretter hver av nivåvariablene over til tekstboksen ``Repeated "
"Measures Cells``."

#: ../../Ch13/Ch13_ANOVA_07.rst:111
msgid ""
"Finally, under the ``Assumption Checks`` option, tick the ``Sphericity "
"checks`` check box."
msgstr ""
"Til slutt krysser du av for ``Sphericity checks`` under alternativet "
"``Assumption Checks``."

#: ../../Ch13/Ch13_ANOVA_07.rst:116 ../../Ch13/Ch13_ANOVA_07.rst:120
msgid "Repeated measures ANOVA dialogue box in jamovi"
msgstr "Dialogboks for ANOVA for gjentatte målinger i jamovi"

#: ../../Ch13/Ch13_ANOVA_07.rst:124
msgid ""
"jamovi output for a one-way ``Repeated Measures ANOVA`` is produced as shown "
"in the :numref:`fig-RManova2` to :numref:`fig-RManova5`. The first output we "
"should look at is ``Mauchly’s Test of Sphericity``, which tests the "
"hypothesis that the variances of the differences between the conditions are "
"equal (meaning that the spread of difference scores between the study "
"conditions is approximately the same). In :numref:`fig-RManova2`, Mauchly’s "
"test significance level is *p* = 0.720. If Mauchly’s test is non-significant "
"(i.e. *p* > 0.05, as is the case in this analysis) then it is reasonable to "
"conclude that the variances of the differences are not significantly "
"different (i.e. they are roughly equal and sphericity can be assumed.)."
msgstr ""
"Utgave fra en enveis ``Repeated Measures ANOVA`` i jamovi produseres som "
"vist i :numref:`fig-RManova2` til :numref:`fig-RManova5`. Det første "
"resultatet vi bør se på, er ``Mauchly's Test of Sphericity``, som tester "
"hypotesen om at variansene i forskjellene mellom betingelsene er like (noe "
"som betyr at spredningen i differansescore mellom studiebetingelsene er "
"omtrent den samme). I :numref:`fig-RManova2` er Mauchlys testsignifikansnivå "
"*p* = 0,720. Hvis Mauchlys test ikke er signifikant (dvs. *p* > 0,05, som er "
"tilfellet i denne analysen), er det rimelig å konkludere med at variansene i "
"forskjellene ikke er signifikant forskjellige (dvs. at de er omtrent like "
"store og sfæricitet kan antas)."

#: ../../Ch13/Ch13_ANOVA_07.rst:138 ../../Ch13/Ch13_ANOVA_07.rst:142
msgid "One-way repeated measures ANOVA output: Mauchly’s Test of Sphericity"
msgstr "Enveis ANOVA for gjentatte målinger: Mauchlys test av sfæricitet"

#: ../../Ch13/Ch13_ANOVA_07.rst:146
msgid ""
"If, on the other hand, Mauchly’s test had been significant (*p* < 0.05) then "
"we would conclude that there are significant differences between the "
"variance of the differences, and the requirement of sphericity has not been "
"met. In this case, we should apply a correction to the *F*-value obtained in "
"the one-way related ANOVA analysis:"
msgstr ""
"Hvis Mauchlys test derimot hadde vært signifikant (*p* < 0,05), ville vi "
"konkludert med at det er signifikante forskjeller mellom variansen i "
"forskjellene, og at kravet om sfæricitet ikke er oppfylt. I dette tilfellet "
"bør vi korrigere *F*-verdien som ble oppnådd i den enveisrelaterte ANOVA-"
"analysen:"

#: ../../Ch13/Ch13_ANOVA_07.rst:153
msgid ""
"If the ``Greenhouse-Geisser`` value in the ``Tests of Sphericity`` table is "
"> 0.75 then you should use the Huynh-Feldt correction."
msgstr ""
"Hvis verdien ``Greenhouse-Geisser`` i tabellen ``Tests of Sphericity`` er > "
"0,75, bør du bruke Huynh-Feldt-korreksjonen."

#: ../../Ch13/Ch13_ANOVA_07.rst:156
msgid ""
"But if the ``Greenhouse-Geisser`` value is < 0.75, then you should use the "
"Greenhouse-Geisser correction."
msgstr ""
"Men hvis ``Greenhouse-Geisser``-verdien er < 0,75, bør du bruke Greenhouse-"
"Geisser-korreksjonen."

#: ../../Ch13/Ch13_ANOVA_07.rst:159
msgid ""
"Both these corrected *F*-values can be specified in the ``Sphericity "
"Corrections`` check boxes under the ``Assumption Checks`` options, and the "
"corrected *F*-values are then shown in the results table, as in :numref:`fig-"
"RManova3`."
msgstr ""
"Begge disse korrigerte *F*-verdiene kan spesifiseres i avmerkingsboksene "
"``Sphericity Corrections`` under ``Assumption Checks``, og de korrigerte *F*-"
"verdiene vises deretter i resultattabellen, som i :numref:`fig-RManova3`."

#: ../../Ch13/Ch13_ANOVA_07.rst:166
msgid "Repeated measures ANOVA output: Tests of Within-Subjects Effects"
msgstr ""
"Utgave fra ANOVA for gjentatte målinger: Test av effekter innenfor deltakere "
"(*within subjects*)"

#: ../../Ch13/Ch13_ANOVA_07.rst:170
msgid ""
"One-way repeated measures ANOVA output: Tests of Within-Subjects Effects"
msgstr ""
"Enveis ANOVA for gjentatte målinger: Test av effekter innenfor deltakere "
"(*within subjects*)"

#: ../../Ch13/Ch13_ANOVA_07.rst:175
msgid ""
"In our analysis, we saw that the significance of Mauchly’s Test of "
"Sphericity was *p* = 0.720 (i.e. *p* > 0.05). So, this means we can assume "
"that the requirement of sphericity has been met so no correction to the *F*-"
"value is needed. Therefore, we can use the ``None`` Sphericity Correction "
"output values for the repeated measure ``Task``: *F* = 6.93, *df1* = 2, "
"*df2* = 10, *p* = 0.013, and we can conclude that the number of tests "
"successfully completed on each language task did vary significantly "
"depending on whether the task was speech, comprehension or syntax based "
"(*F*\\(2,10) = 6.93, *p* = 0.013)."
msgstr ""
"I analysen vår så vi at signifikansen til Mauchlys sfæricitetstest var *p* = "
"0,720 (dvs. *p* > 0,05). Dette betyr at vi kan anta at kravet til sfæricitet "
"er oppfylt, og at det ikke er nødvendig å korrigere *F*-verdien. Derfor kan "
"vi bruke utgangsverdiene for sfæricitetskorreksjon ``None`` for den "
"gjentatte målingen ``Task``: *F* = 6,93, *df1* = 2, *df2* = 10, *p* = 0,013, "
"og vi kan konkludere med at antallet tester som ble fullført på hver "
"språkoppgave, varierte signifikant avhengig av om oppgaven var tale-, "
"forståelses- eller syntaksbasert (*F*\\(2,10) = 6,93, *p* = 0,013)."

#: ../../Ch13/Ch13_ANOVA_07.rst:187 ../../Ch13/Ch13_ANOVA_07.rst:191
msgid "Post-hoc tests in repeated measures ANOVA in jamovi"
msgstr "Post-hoc-tester i ANOVA for gjentatte målinger i jamovi"

#: ../../Ch13/Ch13_ANOVA_07.rst:195
msgid ""
"Post-hoc tests can also be specified in jamovi for repeated measures ANOVA "
"in the same way as for independent ANOVA. The results are shown in :numref:"
"`fig-RManova4`. These indicate that there is a significant difference "
"between ``Speech`` and ``Syntax``, but not between other levels."
msgstr ""
"Post-hoc-tester kan også spesifiseres i jamovi for ANOVA for gjentatte "
"målinger på samme måte som for uavhengig ANOVA. Resultatene vises i :numref:"
"`fig-RManova4`. Disse indikerer at det er en signifikant forskjell mellom "
"``Speech`` og ``Syntax``, men ikke mellom de andre nivåene."

#: ../../Ch13/Ch13_ANOVA_07.rst:201
msgid ""
"Descriptive statistics (marginal means) can be reviewed to help interpret "
"the results, produced in the jamovi output as in :numref:`fig-RManova5`. "
"Comparison of the mean number of trials successfully completed by "
"participants shows that Broca’s Aphasics perform reasonably well on speech "
"production (mean = 7.17) and language comprehension (mean = 6.17) tasks. "
"However, their performance was considerably worse on the syntax task (mean = "
"4.33), with a significant difference in post-hoc tests between ``Speech`` "
"and ``Syntax`` task performance."
msgstr ""
"Deskriptivstatistikk (esimterte randgjennomsnitt) kan gjennomgås for å tolke "
"resultatene, som produseres i jamovi-utgaven som i :numref:`fig-RManova5`. "
"Sammenligning av gjennomsnittlig antall forsøk som deltakerne fullførte, "
"viser at Brocas afasirammede presterer rimelig bra på oppgavene "
"taleproduksjon (gjennomsnitt = 7,17) og språkforståelse (gjennomsnitt = "
"6,17). De presterte imidlertid betydelig dårligere på syntaksoppgaven "
"(gjennomsnitt = 4,33), med en signifikant forskjell i post-hoc-tester mellom "
"``Speech`` og ``Syntax``."

#: ../../Ch13/Ch13_ANOVA_07.rst:212 ../../Ch13/Ch13_ANOVA_07.rst:216
msgid "One-way repeated measures ANOVA output: Descriptive Statistics"
msgstr "Enveis ANOVA for gjentatte målinger: Deskriptivstatistikk"

#: ../../Ch13/Ch13_ANOVA_07.rst:223
msgid "(n - k): (number of subjects - number of groups)"
msgstr "(n - k): (antall forsøkspersoner - antall grupper)"

#: ../../Ch13/Ch13_ANOVA_08.rst:4
msgid "The Friedman non-parametric repeated measures ANOVA test"
msgstr "Friedmans ikke-parametriske ANOVA for gjentatte målinger"

#: ../../Ch13/Ch13_ANOVA_08.rst:6
msgid ""
"The Friedman test is a non-parametric version of a repeated measures ANOVA "
"and can be used instead of the Kruskall-Wallis test when testing for "
"differences between three or more groups |nominal| where the same "
"participants are in each group, or each participant is closely matched with "
"participants in other conditions. If the dependent variable is ordinal |"
"ordinal|, or if the assumption of normality is not met, then the Friedman "
"test can be used."
msgstr ""
"Friedman-testen er en ikke-parametrisk versjon av en ANOVA for gjentatte "
"målinger og kan brukes i stedet for Kruskall-Wallis-testen når man tester "
"for forskjeller mellom tre eller flere grupper |nominal| der de samme "
"deltakerne er i hver gruppe, eller der hver deltaker er tett matchet med "
"deltakere i andre betingelser. Hvis den avhengige variabelen er ordinal |"
"ordinal|, eller hvis forutsetningen om normalfordeling ikke er oppfylt, kan "
"Friedman-testen brukes."

#: ../../Ch13/Ch13_ANOVA_08.rst:51
msgid "ordinal"
msgstr "ordinal"

#: ../../Ch13/Ch13_ANOVA_08.rst:15 ../../Ch13/Ch13_ANOVA_08.rst:19
msgid "``Repeated Measures ANOVA (Non-parametric)`` dialogue box in jamovi"
msgstr "Dialogboksen ``Repeated Measures ANOVA (Non-parametric)`` i jamovi"

#: ../../Ch13/Ch13_ANOVA_08.rst:23
msgid ""
"As with the Kruskall-Wallis test, the underlying mathematics is complicated, "
"and won’t be presented here. For the purpose of this book, it is sufficient "
"to note that jamovi calculates the tie-corrected version of the Friedman "
"test, and in :numref:`fig-RManova6` there is an example using the Broca’s "
"Aphasia data we have already looked at."
msgstr ""
"Som med Kruskall-Wallis-testen er den underliggende matematikken komplisert, "
"og vil ikke bli presentert her. For denne bokens formål er det tilstrekkelig "
"å merke seg at jamovi beregner den uavhengighetskorrigerte versjonen av "
"Friedman-testen, og i :numref:`fig-RManova6` finnes det et eksempel med "
"Brocas afasidata som vi allerede har sett på."

#: ../../Ch13/Ch13_ANOVA_08.rst:29
msgid ""
"It’s pretty straightforward to run a Friedman test in jamovi. Just select "
"``Analyses`` → ``ANOVA`` → ``Repeated Measures ANOVA (Non-parametric)``, as "
"in :numref:`fig-RManova6`. Then highlight and transfer the names of the "
"repeated measures variables you wish to compare (``Speech``, ``Conceptual``, "
"``Syntax``) into the ``Measures:`` text box. To produce descriptive "
"statistics (means and medians) for the three repeated measures variables, "
"click on the ``Descriptives`` button."
msgstr ""
"Det er ganske enkelt å kjøre en Friedman-test i jamovi. Bare velg "
"``Analyses`` → ``ANOVA`` → ``Repeated Measures ANOVA (Non-parametric)``, som "
"i :numref:`fig-RManova6`. Deretter markerer du og overfører navnene på de "
"gjentatte målevariablene du ønsker å sammenligne (``Speech``, "
"``Conceptual``, ``Syntax``) til tekstboksen ``Measures:``. Klikk på "
"``Descriptives``-knappen for å produsere deskriptivstatistikk (gjennomsnitt "
"og median) for de tre variablene med gjentatte målinger."

#: ../../Ch13/Ch13_ANOVA_08.rst:37
msgid ""
"The jamovi results show descriptive statistics, χ²-value, degrees of "
"freedom, and the *p*-value (:numref:`fig-RManova6`). Since the *p*-value is "
"less than the level conventionally used to determine significance (*p* < "
"0.05), we can conclude that Broca’s Aphasics perform reasonably well on "
"speech production (median = 7.5) and language comprehension (median = 6.5) "
"tasks. However, their performance was considerably worse on the syntax task "
"(median = 4.5), with a significant difference in post-hoc tests between "
"Speech and Syntax task performance."
msgstr ""
"Resultatene fra jamovi viser deskriptivstatistikk, χ²-verdi, frihetsgrader "
"og *p*-verdi (:numref:`fig-RManova6`). Siden *p*-verdien er lavere enn det "
"nivået som vanligvis brukes for å fastslå signifikans (*p* < 0,05), kan vi "
"konkludere med at Brocas afasirammede presterer rimelig godt på "
"taleproduksjon (median = 7,5) og språkforståelse (median = 6,5). De "
"presterte imidlertid betydelig dårligere på syntaksoppgaven (median = 4,5), "
"med en signifikant forskjell i post-hoc-tester mellom tale- og "
"syntaksoppgavene."

#: ../../Ch13/Ch13_ANOVA_09.rst:4
msgid "On the relationship between ANOVA and the Student *t*-test"
msgstr "Om forholdet mellom ANOVA og Student *t*-testen"

#: ../../Ch13/Ch13_ANOVA_09.rst:6
msgid ""
"There’s one last thing I want to point out before finishing. It’s something "
"that a lot of people find kind of surprising, but it’s worth knowing about. "
"An ANOVA with two groups is identical to the Student *t*-test. No, really. "
"It’s not just that they are similar, but they are actually equivalent in "
"every meaningful way. I won’t try to prove that this is always true, but I "
"will show you a single concrete demonstration. Suppose that, instead of "
"running an ANOVA on our ``mood.gain ~ drug`` model, let’s instead do it "
"using ``therapy`` as the predictor. If we run this ANOVA we get an *F*-"
"statistic of F(1,16) = 1.71, and a *p*-value = 0.210. Since we only have two "
"groups, I didn’t actually need to resort to an ANOVA, I could have just "
"decided to run a Student *t*-test. So let’s see what happens when I do that: "
"I get a *t*-statistic of t(16) = -1.3068 and a *p*-value = 0.21. Curiously, "
"the *p*-values are identical. Once again we obtain a value of *p* = 0.210. "
"But what about the test statistic? Having run a *t*-test instead of an "
"ANOVA, we get a somewhat different answer, namely t(16) = -1.3068. However, "
"there is a fairly straightforward relationship here. If we square the *t*-"
"statistic then we get the *F*-statistic from before: -1.3068² = 1.7077."
msgstr ""
"Det er en siste ting jeg vil påpeke før jeg avslutter. Det er noe som mange "
"synes er litt overraskende, men det er verdt å vite om. En ANOVA med to "
"grupper er identisk med Student *t*-testen. Nei, jeg mener det. Det er ikke "
"bare det at de er like, men de er faktisk ekvivalente på alle meningsfulle "
"måter. Jeg skal ikke prøve å bevise at dette alltid er sant, men jeg vil "
"vise deg en enkelt konkret demonstrasjon. Anta at vi i stedet for å kjøre en "
"ANOVA på vår ``mood.gain ~ drug``-modell, la oss i stedet gjøre det med "
"``therapy`` som prediktor. Hvis vi kjører denne ANOVA-en, får vi en *F*-"
"statistikk på F(1,16) = 1,71, og en *p*-verdi = 0,210. Siden vi bare har to "
"grupper, trengte jeg faktisk ikke å ty til en ANOVA, jeg kunne bare ha "
"bestemt meg for å kjøre en Student *t*-test. Så la oss se hva som skjer når "
"jeg gjør det: Jeg får en *t*-statistikk på t(16) = -1,3068 og en *p*-verdi = "
"0,21. Merkelig nok er *p*-verdiene identiske. Igjen får vi en verdi på *p* = "
"0,210. Men hva med teststatistikken? Etter å ha kjørt en *t*-test i stedet "
"for en ANOVA får vi et noe annet svar, nemlig t(16) = -1,3068. Det er "
"imidlertid en ganske enkel sammenheng her. Hvis vi kvadrerer *t*-"
"statistikken, får vi *F*-statistikken fra før: -1,3068² = 1,7077."

#: ../../Ch13/Ch13_ANOVA_10.rst:4
msgid "Summary"
msgstr "Sammendrag"

#: ../../Ch13/Ch13_ANOVA_10.rst:6
msgid ""
"There’s a fair bit covered in this chapter, but there’s still a lot missing. "
"Most obviously, I haven’t discussed how to run an ANOVA when you are "
"interested in more than one grouping variable, but that will be discussed in "
"a lot of detail in chapter :doc:`../Ch14/Ch14_ANOVA2`. In terms of what we "
"have discussed, the key topics were:"
msgstr ""
"Det er en god del som er dekket i dette kapittelet, men det er fortsatt mye "
"som mangler. Det mest åpenbare er at jeg ikke har diskutert hvordan man "
"kjører en ANOVA når man er interessert i mer enn én grupperingsvariabel, men "
"det vil bli diskutert i detalj i kapittel :doc:`../Ch14/Ch14_ANOVA2`. De "
"viktigste temaene vi har diskutert, var:"

#: ../../Ch13/Ch13_ANOVA_10.rst:12
msgid ""
"The basic logic behind :doc:`how ANOVA works <Ch13_ANOVA_02>` and :doc:`how "
"to run one in jamovi <Ch13_ANOVA_03>`."
msgstr ""
"Den grunnleggende logikken bak :doc:`hvordan ANOVA fungerer <Ch13_ANOVA_02>` "
"og :doc:`hvordan du kjører en ANOVA i jamovi <Ch13_ANOVA_03>`."

#: ../../Ch13/Ch13_ANOVA_10.rst:15
msgid "How to compute an :doc:`effect size <Ch13_ANOVA_04>` for an ANOVA."
msgstr ""
"Slik beregner du en :doc:`effektstørrelse <Ch13_ANOVA_04>` for en ANOVA."

#: ../../Ch13/Ch13_ANOVA_10.rst:17
msgid ""
":doc:`Post-hoc analysis and corrections for multiple testing "
"<Ch13_ANOVA_05>`."
msgstr ""
":doc:`Post-hoc-analyse og korreksjoner for multippel testing "
"<Ch13_ANOVA_05>`."

#: ../../Ch13/Ch13_ANOVA_10.rst:19
msgid ""
"The :doc:`assumptions made by the ANOVA <Ch13_ANOVA_06>`: How to check the "
"homogeneity of variance assumption and what to do if it is violated; as well "
"as how to check the normality assumption and what to do if it is violated."
msgstr ""
"The :doc:`forutsetningene for ANOVA <Ch13_ANOVA_06>`: Hvordan du undersøker "
"forutsetningen om varianshomogenitet og hva du skal gjøre hvis den brytes, "
"samt hvordan du undersøker forutsetningen om normalfordeling og hva du skal "
"gjøre hvis den brytes."

#: ../../Ch13/Ch13_ANOVA_10.rst:23
msgid ""
":doc:`Repeated measures ANOVA <Ch13_ANOVA_07>` and its non-parametric "
"equivalent, the :doc:`Friedman test <Ch13_ANOVA_08>`."
msgstr ""
":doc:`Repeated measures ANOVA <Ch13_ANOVA_07>` og dens ikke-parametriske "
"ekvivalent, :doc:`Friedman-test <Ch13_ANOVA_08>`."

#: ../../Ch13/Ch13_ANOVA_10.rst:26
msgid ""
"As with all of the chapters in this book, there are quite a few different "
"sources that I’ve relied upon, but the one stand-out text that I’ve been "
"most heavily influenced by is :ref:`Sahai and Ageel (2000) <Sahai_2000>`. "
"It’s not a good book for beginners, but it’s an excellent book for more "
"advanced readers who are interested in understanding the mathematics behind "
"ANOVA."
msgstr ""
"Som med alle kapitlene i denne boken er det ganske mange ulike kilder jeg "
"har støttet meg til, men den teksten jeg har vært mest påvirket av, er :ref:"
"`Sahai og Ageel (2000) <Sahai_2000>`. Det er ikke en god bok for "
"nybegynnere, men det er en utmerket bok for mer avanserte lesere som er "
"interessert i å forstå matematikken bak ANOVA."
