msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-03-17 17:35+0100\n"
"PO-Revision-Date: 2025-03-17 16:58+0000\n"
"Last-Translator: Sebastian Jentschke <sebastian.jentschke@uib.no>\n"
"Language-Team: Norwegian Bokmål <https://hosted.weblate.org/projects/lsjdocs/"
"ch14/nb_NO/>\n"
"Language: nb\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"X-Generator: Weblate 5.11-dev\n"
"Generated-By: Babel 2.17.0\n"

#: ../../Ch14/Ch14_ANOVA2.rst:4
msgid "Factorial ANOVA"
msgstr "Faktoriell ANOVA"

#: ../../Ch14/Ch14_ANOVA2.rst:23
msgid ""
"Over the course of the last few chapters we have done quite a lot. We have "
"looked at statistical tests you can use when you have one nominal predictor "
"variable |nominal| with two groups (e.g. the *t*-test, chapter :doc:`../Ch11/"
"Ch11_tTest`) or with three or more groups (e.g. in chapter :doc:`../Ch13/"
"Ch13_ANOVA`). The chapter on :doc:`../Ch12/Ch12_Regression` introduced a "
"powerful new idea, that is building statistical models with *multiple* "
"continuous predictor variables |continuous| used to explain a single outcome "
"variable |continuous|. For instance, a regression model could be used to "
"predict the number of errors a student makes in a reading comprehension test "
"based on the number of hours they studied for the test and their score on a "
"standardised IQ test."
msgstr ""
"I løpet av de siste kapitlene har vi gjort ganske mye. Vi har sett på "
"statistiske tester du kan bruke når du har én nominell prediktorvariabel |"
"nominal| med to grupper (f.eks. *t*-testen, kapittel :doc:`../Ch11/"
"Ch11_tTest`) eller med tre eller flere grupper (f.eks. i kapittel :doc:`../"
"Ch13/Ch13_ANOVA`). Kapittelet om :doc:`../Ch12/Ch12_Regression` introduserte "
"en ny, kraftfull idé, nemlig å bygge statistiske modeller med *flere* "
"kontinuerlige prediktorvariabler |continuous| som brukes til å forklare en "
"enkelt utfallsvariabel |continuous|. En regresjonsmodell kan for eksempel "
"brukes til å forutsi hvor mange feil en elev gjør i en leseforståelsestest "
"basert på antall timer de har studert til testen og poengsummen deres på en "
"standardisert IQ-test."

#: ../../Ch14/Ch14_ANOVA2.rst:53 ../../Ch14/Ch14_ANOVA2_01.rst:668
#: ../../Ch14/Ch14_ANOVA2_06.rst:150 ../../Ch14/Ch14_ANOVA2_07.rst:549
#: ../../Ch14/Ch14_ANOVA2_11.rst:656
msgid "nominal"
msgstr "nominal"

#: ../../Ch14/Ch14_ANOVA2.rst:50 ../../Ch14/Ch14_ANOVA2_01.rst:665
#: ../../Ch14/Ch14_ANOVA2_06.rst:147 ../../Ch14/Ch14_ANOVA2_11.rst:653
msgid "continuous"
msgstr "continuous"

#: ../../Ch14/Ch14_ANOVA2.rst:35
msgid ""
"The goal in this chapter is to extend the idea of using multiple predictors "
"into the ANOVA framework. For instance, suppose we were interested in using "
"the reading comprehension test to measure student achievements in three "
"different schools, and we suspect that girls and boys are developing at "
"different rates (and so would be expected to have different performance on "
"average). Each student is classified in two different ways: on the basis of "
"their gender and on the basis of their school. What we’d like to do is "
"analyse the reading comprehension scores in terms of *both* of these "
"grouping variables |nominal|. The tool for doing so is generically referred "
"to as **factorial ANOVA**. However, since we have two grouping variables |"
"nominal|, we sometimes refer to the analysis as a two-way ANOVA, in contrast "
"to the one-way ANOVAs that we ran in chapter :doc:`../Ch13/Ch13_ANOVA`."
msgstr ""
"Målet med dette kapittelet er å utvide ideen om bruk av flere prediktorer "
"til ANOVA-rammeverket. Anta for eksempel at vi er interessert i å bruke "
"leseforståelsestesten til å måle elevenes prestasjoner på tre forskjellige "
"skoler, og at vi mistenker at jenter og gutter utvikler seg i ulik takt (og "
"dermed forventes å ha ulike prestasjoner i gjennomsnitt). Hver elev er "
"klassifisert på to forskjellige måter: på grunnlag av kjønn og på grunnlag "
"av skole. Det vi ønsker å gjøre, er å analysere leseforståelsesresultatene "
"med hensyn til *begge* disse grupperingsvariablene |nominal|. Verktøyet for "
"å gjøre dette kalles vanligvis **faktoriell ANOVA**. Men siden vi har to "
"grupperingsvariabler |nominal|, refererer vi noen ganger til analysen som en "
"toveis ANOVA, i motsetning til enveis ANOVA som vi kjørte i kapittel :doc:"
"`../Ch13/Ch13_ANOVA`."

#: ../../Ch14/Ch14_ANOVA2_01.rst:4
msgid "Factorial ANOVA 1: balanced designs, no interactions"
msgstr "Faktoriell ANOVA 1: balansert design, ingen interaksjoner"

#: ../../Ch14/Ch14_ANOVA2_01.rst:6
msgid ""
"When we discussed analysis of variance in chapter :doc:`../Ch13/Ch13_ANOVA`, "
"we assumed a fairly simple experimental design. Each person is in one of "
"several groups and we want to know whether these groups have different mean "
"scores on some outcome variable. In this section, I’ll discuss a broader "
"class of experimental designs known as **factorial designs**, in which we "
"have more than one grouping variable |nominal|. I gave one example of how "
"this kind of design might arise above. Another example appears in chapter :"
"doc:`../Ch13/Ch13_ANOVA` in which we were looking at the effect of different "
"drugs on the ``mood.gain`` experienced by each person |continuous|. In that "
"chapter we did find a significant effect of drug, but at the end of the "
"chapter we also ran an analysis to see if there was an effect of therapy. We "
"didn’t find one, but there’s something a bit worrying about trying to run "
"two *separate* analyses trying to predict the same outcome. Maybe there "
"actually *is* an effect of therapy on mood gain, but we couldn’t find it "
"because it was being “hidden” by the effect of drug? In other words, we’re "
"going to want to run a *single* analysis that includes *both* ``drug`` and "
"``therapy`` as predictors. For this analysis each person is cross-classified "
"by the drug they were given (a factor with 3 levels) and what therapy they "
"received (a factor with 2 levels). We refer to this as a 3 × 2 factorial "
"design."
msgstr ""
"Da vi diskuterte variansanalyse i kapittel :doc:`../Ch13/Ch13_ANOVA`, tok vi "
"utgangspunkt i et ganske enkelt eksperimentelt design. Hver person er i én "
"av flere grupper, og vi ønsker å finne ut om disse gruppene har forskjellige "
"gjennomsnittsskårer på en eller annen utfallsvariabel. I denne delen skal "
"jeg ta for meg en bredere klasse av eksperimentelle design som kalles "
"**faktorielle design**, der vi har mer enn én grupperingsvariabel |nominal|. "
"Jeg ga ett eksempel på hvordan denne typen design kan oppstå ovenfor. Et "
"annet eksempel finner du i kapittel :doc:`../Ch13/Ch13_ANOVA`, der vi så på "
"effekten av ulike legemidler på den ``mood.gain`` som hver person opplevde |"
"continuous|. I det kapittelet fant vi en signifikant effekt av legemiddel, "
"men på slutten av kapittelet kjørte vi også en analyse for å se om det var "
"en effekt av terapi. Vi fant ingen effekt, men det er litt bekymringsfullt å "
"prøve å kjøre to *separate* analyser for å forutsi det samme utfallet. "
"Kanskje det faktisk *er* en effekt av terapi (``therapy``) på "
"humørforbedringer (``mood.gain``), men at vi ikke kunne finne den fordi den "
"ble «skjult» av effekten av legemiddelet? Med andre ord ønsker vi å kjøre en "
"*enkel* analyse som inkluderer *både* ``drug`` og ``therapy`` som "
"prediktorer. I denne analysen kryssklassifiseres hver person etter hvilket "
"legemiddel de fikk (``drug``; en faktor med tre nivåer) og hvilken terapi de "
"fikk (``therapy``; en faktor med to nivåer). Vi kaller dette en 3 × 2-"
"faktoriell design."

#: ../../Ch14/Ch14_ANOVA2_01.rst:26
msgid ""
"If we cross-tabulate ``drug`` by ``therapy``, using the ``Frequencies`` → "
"``Contingency Tables`` analysis in jamovi (see :doc:`../Ch06/"
"Ch06_DataHandling_1`), we get the table shown in :numref:`fig-"
"factorialanova1`."
msgstr ""
"Hvis vi krysstabulerer ``drug`` med ``therapy``, ved hjelp av "
"``Frequencies`` → ``Contingency Tables`` i jamovi (se :doc:`../Ch06/"
"Ch06_DataHandling_1`), får vi tabellen som vises i :numref:`fig-"
"factorialanova1`."

#: ../../Ch14/Ch14_ANOVA2_01.rst:33 ../../Ch14/Ch14_ANOVA2_01.rst:37
msgid "jamovi contingency table for ``drug`` by ``therapy``"
msgstr "jamovi krysstabell for ``drug`` etter ``therapy``"

#: ../../Ch14/Ch14_ANOVA2_01.rst:41
msgid ""
"As you can see, not only do we have participants corresponding to all "
"possible combinations of the two factors, indicating that our design is "
"**completely crossed**, it turns out that there are an equal number of "
"people in each group. In other words, we have a **balanced** design. In this "
"section I’ll talk about how to analyse data from balanced designs, since "
"this is the simplest case. The story for unbalanced designs is quite "
"tedious, so we’ll put it to one side for the moment."
msgstr ""
"Som du kan se, har vi ikke bare deltakere som tilsvarer alle mulige "
"kombinasjoner av de to faktorene, noe som indikerer at designet vårt er "
"**fullstendig krysset**, det viser seg også at det er like mange personer i "
"hver gruppe. Vi har med andre ord et **balansert** design. I denne delen "
"skal jeg snakke om hvordan man analyserer data fra balanserte design, siden "
"dette er det enkleste tilfellet. Historien om ubalanserte design er ganske "
"kjedelig, så vi legger den til side for øyeblikket."

#: ../../Ch14/Ch14_ANOVA2_01.rst:52
msgid "What hypotheses are we testing?"
msgstr "Hvilke hypoteser tester vi?"

#: ../../Ch14/Ch14_ANOVA2_01.rst:54
msgid ""
"Like one-way ANOVA, factorial ANOVA is a tool for testing certain types of "
"hypotheses about population means. So a sensible place to start would be to "
"be explicit about what our hypotheses actually are. However, before we can "
"even get to that point, it’s really useful to have some clean and simple "
"notation to describe the population means. Because of the fact that "
"observations are cross-classified in terms of two different factors, there "
"are quite a lot of different means that one might be interested in. To see "
"this, let’s start by thinking about all the different sample means that we "
"can calculate for this kind of design. Firstly, there’s the obvious idea "
"that we might be interested in this list of group means:"
msgstr ""
"I likhet med enveis ANOVA er faktoriell ANOVA et verktøy for å teste visse "
"typer hypoteser om populasjonsgjennomsnitt. Et fornuftig sted å starte ville "
"derfor være å være eksplisitt om hva hypotesene våre faktisk er. Men før vi "
"i det hele tatt kommer så langt, er det nyttig å ha en ren og enkel notasjon "
"for å beskrive populasjonsgjennomsnittet. Siden observasjonene er "
"kryssklassifisert med hensyn til to ulike faktorer, finnes det ganske mange "
"ulike gjennomsnitt som man kan være interessert i. For å se dette, la oss "
"begynne med å tenke på alle de ulike utvalgsgjennomsnittene som vi kan "
"beregne for denne typen design. For det første er det åpenbart at vi kan "
"være interessert i denne listen over gruppegjennomsnitt:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:76
msgid ""
"Now, this output shows a list of the group means for all possible "
"combinations of the two factors (e.g., people who received the placebo and "
"no therapy, people who received the placebo while getting CBT, etc.). It is "
"helpful to organise all these numbers, plus the marginal and grand means, "
"into a single table which looks like this:"
msgstr ""
"Dette resultatet viser en liste over gruppegjennomsnitt for alle mulige "
"kombinasjoner av de to faktorene (f.eks. personer som fikk placebo og ingen "
"terapi, personer som fikk placebo samtidig som de fikk CBT, osv.) Det er "
"nyttig å organisere alle disse tallene, pluss marginal- og "
"totalgjennomsnittet, i en enkelt tabell som ser slik ut:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:83 ../../Ch14/Ch14_ANOVA2_01.rst:118
#: ../../Ch14/Ch14_ANOVA2_01.rst:146 ../../Ch14/Ch14_ANOVA2_01.rst:383
msgid "no therapy"
msgstr "ingen terapi"

#: ../../Ch14/Ch14_ANOVA2_01.rst:83 ../../Ch14/Ch14_ANOVA2_01.rst:118
#: ../../Ch14/Ch14_ANOVA2_01.rst:146 ../../Ch14/Ch14_ANOVA2_01.rst:383
msgid "CBT"
msgstr "CBT"

#: ../../Ch14/Ch14_ANOVA2_01.rst:83 ../../Ch14/Ch14_ANOVA2_01.rst:118
#: ../../Ch14/Ch14_ANOVA2_01.rst:146 ../../Ch14/Ch14_ANOVA2_01.rst:383
msgid "total"
msgstr "totalt"

#: ../../Ch14/Ch14_ANOVA2_01.rst:85 ../../Ch14/Ch14_ANOVA2_01.rst:120
#: ../../Ch14/Ch14_ANOVA2_01.rst:148 ../../Ch14/Ch14_ANOVA2_01.rst:385
msgid "**placebo**"
msgstr "**placebo**"

#: ../../Ch14/Ch14_ANOVA2_01.rst:85
msgid "0.30"
msgstr "0.30"

#: ../../Ch14/Ch14_ANOVA2_01.rst:85
msgid "0.60"
msgstr "0.60"

#: ../../Ch14/Ch14_ANOVA2_01.rst:85
msgid "0.45"
msgstr "0.45"

#: ../../Ch14/Ch14_ANOVA2_01.rst:87 ../../Ch14/Ch14_ANOVA2_01.rst:122
#: ../../Ch14/Ch14_ANOVA2_01.rst:150 ../../Ch14/Ch14_ANOVA2_01.rst:387
msgid "**anxifree**"
msgstr "**anxifree**"

#: ../../Ch14/Ch14_ANOVA2_01.rst:87
msgid "0.40"
msgstr "0.40"

#: ../../Ch14/Ch14_ANOVA2_01.rst:87
msgid "1.03"
msgstr "1.03"

#: ../../Ch14/Ch14_ANOVA2_01.rst:87 ../../Ch14/Ch14_ANOVA2_01.rst:91
msgid "0.72"
msgstr "0.72"

#: ../../Ch14/Ch14_ANOVA2_01.rst:89 ../../Ch14/Ch14_ANOVA2_01.rst:124
#: ../../Ch14/Ch14_ANOVA2_01.rst:152 ../../Ch14/Ch14_ANOVA2_01.rst:389
msgid "**joyzepam**"
msgstr "**joyzepam**"

#: ../../Ch14/Ch14_ANOVA2_01.rst:89
msgid "1.47"
msgstr "1.47"

#: ../../Ch14/Ch14_ANOVA2_01.rst:89
msgid "1.50"
msgstr "1.50"

#: ../../Ch14/Ch14_ANOVA2_01.rst:89
msgid "1.48"
msgstr "1.48"

#: ../../Ch14/Ch14_ANOVA2_01.rst:91 ../../Ch14/Ch14_ANOVA2_01.rst:126
#: ../../Ch14/Ch14_ANOVA2_01.rst:154 ../../Ch14/Ch14_ANOVA2_01.rst:391
msgid "**total**"
msgstr "**totalt**"

#: ../../Ch14/Ch14_ANOVA2_01.rst:91
msgid "1.04"
msgstr "1.04"

#: ../../Ch14/Ch14_ANOVA2_01.rst:91
msgid "0.88"
msgstr "0.88"

#: ../../Ch14/Ch14_ANOVA2_01.rst:94
msgid ""
"Now, each of these different means is of course a sample statistic. It’s a "
"quantity that pertains to the specific observations that we’ve made during "
"our study. What we want to make inferences about are the corresponding "
"population parameters. That is, the true means as they exist within some "
"broader population. Those population means can also be organised into a "
"similar table, but we’ll need a little mathematical notation to do so. As "
"usual, I’ll use the symbol µ to denote a population mean. However, because "
"there are lots of different means, I’ll need to use subscripts to "
"distinguish between them."
msgstr ""
"Hvert av disse ulike gjennomsnittene er selvfølgelig en utvalgsstatistikk. "
"Det er en størrelse som gjelder de spesifikke observasjonene vi har gjort i "
"løpet av studien vår. Det vi ønsker å trekke slutninger om, er de "
"tilsvarende populasjonsparametrene. Det vil si de sanne gjennomsnittene slik "
"de eksisterer i en bredere populasjon. Disse populasjonsgjennomsnittene kan "
"også organiseres i en lignende tabell, men vi trenger litt matematisk "
"notasjon for å gjøre det. Som vanlig bruker jeg symbolet µ for å betegne et "
"populasjonsgjennomsnitt. Men fordi det finnes mange forskjellige "
"gjennomsnitt, må jeg bruke abonnementer for å skille mellom dem."

#: ../../Ch14/Ch14_ANOVA2_01.rst:104
msgid ""
"Here’s how the notation works. Our table is defined in terms of two factors. "
"Each row corresponds to a different level of Factor A (in this case "
"``drug``), and each column corresponds to a different level of Factor B (in "
"this case ``therapy``). If we let *R* denote the number of rows in the "
"table, and *C* denote the number of columns, we can refer to this as an R × "
"C factorial ANOVA. In this case R = 3 and C = 2. We’ll use lowercase letters "
"to refer to specific rows and columns, so µ\\ :sub:`rc` refers to the "
"population mean associated with the *r*\\ th level of Factor A (i.e. row "
"number *r*) and the *c*-th level of Factor B (column number *c*).\\ [#]_ So "
"the population means are now written like this:"
msgstr ""
"Slik fungerer notasjonen. Tabellen vår er definert i form av to faktorer. "
"Hver rad tilsvarer et nivå av faktor A (i dette tilfellet ``drug``), og hver "
"kolonne tilsvarer et nivå av faktor B (i dette tilfellet ``therapy``). Hvis "
"vi lar *R* betegne antall rader i tabellen, og *C* betegne antall kolonner, "
"kan vi kalle dette en R × C-faktoriell ANOVA. I dette tilfellet er R = 3 og "
"C = 2. Vi bruker små bokstaver for å referere til spesifikke rader og "
"kolonner, slik at µ\\ :sub:`rc` refererer til populasjonsgjennomsnittet "
"knyttet til det *r*\\. nivået av faktor A (dvs. radnummer *r*) og det *c*. "
"nivået av faktor B (kolonnenummer *c*).\\ [#]_ Så populasjonsgjennomsnittene "
"skrives nå slik:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:120 ../../Ch14/Ch14_ANOVA2_01.rst:122
#: ../../Ch14/Ch14_ANOVA2_01.rst:124 ../../Ch14/Ch14_ANOVA2_01.rst:148
msgid "µ\\ :sub:`11`"
msgstr "µ\\ :sub:`11`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:122 ../../Ch14/Ch14_ANOVA2_01.rst:150
msgid "µ\\ :sub:`21`"
msgstr "µ\\ :sub:`21`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:124 ../../Ch14/Ch14_ANOVA2_01.rst:152
msgid "µ\\ :sub:`31`"
msgstr "µ\\ :sub:`31`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:129
msgid ""
"Okay, what about the remaining entries? For instance, how should we describe "
"the average mood gain across the entire (hypothetical) population of people "
"who might be given Joyzepam in an experiment like this, regardless of "
"whether they were in CBT? We use the “dot” notation to express this. In the "
"case of Joyzepam, notice that we’re talking about the mean associated with "
"the third row in the table. That is, we’re averaging across two cell means "
"(i.e., µ\\ :sub:`31` and µ\\ :sub:`32`). The result of this averaging is "
"referred to as a **marginal mean**, and would be denoted µ\\ :sub:`3.` in "
"this case. The marginal mean for CBT corresponds to the population mean "
"associated with the second column in the table, so we use the notation µ\\ :"
"sub:`.2` to describe it. The grand mean is denoted µ\\ :sub:`..` because it "
"is the mean obtained by averaging (marginalising\\ [#]_) over both. So our "
"full table of population means can be written down like this:"
msgstr ""
"Ok, hva med de resterende oppføringene? Hvordan skal vi for eksempel "
"beskrive den gjennomsnittlige humørforbedringen (``mood.gain``) i hele den "
"(hypotetiske) populasjonen av personer som kan få Joyzepam i et eksperiment "
"som dette, uavhengig av om de får ``CBT`` eller ikke? Vi bruker «dot»-"
"notasjonen for å uttrykke dette. Når det gjelder Joyzepam, legger du merke "
"til at vi snakker om gjennomsnittet knyttet til den tredje raden i tabellen. "
"Det vil si at vi tar gjennomsnittet av to cellegjennomsnitt (dvs. µ\\ :sub:"
"`31` og µ\\ :sub:`32`). Resultatet av denne gjennomsnittsberegningen kalles "
"et **marginalgjennomsnitt**, og betegnes i dette tilfellet µ\\ :sub:`3.`. "
"Det marginale gjennomsnittet for CBT tilsvarer populasjonsgjennomsnittet som "
"er knyttet til den andre kolonnen i tabellen, så vi bruker notasjonen µ\\ :"
"sub:`.2` for å beskrive det. Det totale gjennomsnittet betegnes µ\\ :sub:`.."
"` fordi det er gjennomsnittet som oppnås ved å beregne gjennomsnittet "
"(marginalising\\ [#]_) over begge. Den fullstendige tabellen over "
"populasjonsgjennomsnitt kan altså skrives slik:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:148
msgid "µ\\ :sub:`12`"
msgstr "µ\\ :sub:`12`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:148
msgid "µ\\ :sub:`1.`"
msgstr "µ\\ :sub:`1.`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:150
msgid "µ\\ :sub:`22`"
msgstr "µ\\ :sub:`22`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:150
msgid "µ\\ :sub:`2.`"
msgstr "µ\\ :sub:`2.`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:152
msgid "µ\\ :sub:`32`"
msgstr "µ\\ :sub:`32`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:152
msgid "µ\\ :sub:`3.`"
msgstr "µ\\ :sub:`3.`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:154
msgid "µ\\ :sub:`.1`"
msgstr "µ\\ :sub:`.1`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:154
msgid "µ\\ :sub:`.2`"
msgstr "µ\\ :sub:`.2`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:154
msgid "µ\\ :sub:`..`"
msgstr "µ\\ :sub:`..`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:157
msgid ""
"Now that we have this notation, it is straightforward to formulate and "
"express some hypotheses. Let’s suppose that the goal is to find out two "
"things. First, does the choice of drug have any effect on mood? And second, "
"does CBT have any effect on mood? These aren’t the only hypotheses that we "
"could formulate of course, and we’ll see a really important example of a "
"different kind of hypothesis in section :doc:`Ch14_ANOVA2_02`, but these are "
"the two simplest hypotheses to test, and so we’ll start there. Consider the "
"first test. If the drug has no effect then we would expect all of the row "
"means to be identical, right? So that’s our null hypothesis. On the other "
"hand, if the drug does matter then we should expect these row means to be "
"different. Formally, we write down our null and alternative hypotheses in "
"terms of the *equality of marginal means*:"
msgstr ""
"Nå som vi har denne notasjonen, er det enkelt å formulere og uttrykke noen "
"hypoteser. La oss anta at målet er å finne ut to ting. For det første: Har "
"valg av legemiddel noen effekt på humøret? Og for det andre: Har CBT noen "
"effekt på humøret? Dette er selvsagt ikke de eneste hypotesene vi kan "
"formulere, og vi skal se et veldig viktig eksempel på en annen type hypotese "
"i avsnitt :doc:`Ch14_ANOVA2_02`, men dette er de to enkleste hypotesene å "
"teste, så vi begynner der. Se på den første testen. Hvis legemiddelet ikke "
"har noen effekt, forventer vi at alle radgjennomsnittene er identiske, ikke "
"sant? Så det er nullhypotesen vår. Hvis legemiddelet (``drug``) derimot har "
"en effekt, forventer vi at disse radgjennomsnittene er forskjellige. Formelt "
"sett skriver vi ned nullhypotesen og alternativhypotesen i form av *likheten "
"mellom marginale gjennomsnitt*:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:171 ../../Ch14/Ch14_ANOVA2_01.rst:199
msgid "Null hypothesis, H\\ :sub:`0`:"
msgstr "Nullhypotese, H\\ :sub:`0`:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:171
msgid ""
"row means are the same, i.e., µ\\ :sub:`1.` = µ\\ :sub:`2.` = µ\\ :sub:`3.`"
msgstr ""
"radmidlene er de samme, dvs. µ\\ :sub:`1.` = µ\\ :sub:`2.` = µ\\ :sub:`3.`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:174 ../../Ch14/Ch14_ANOVA2_01.rst:202
msgid "Alternative hypothesis, H\\ :sub:`1`:"
msgstr "Alternativ hypotese, H\\ :sub:`1`:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:174
msgid "at least one row mean is different."
msgstr "minst ett radgjennomsnitt er forskjellig."

#: ../../Ch14/Ch14_ANOVA2_01.rst:178
msgid ""
"It’s worth noting that these are *exactly* the same statistical hypotheses "
"that we formed when we ran a one-way ANOVA on these data back in :doc:`the "
"previous chapter <../Ch13/Ch13_ANOVA>`. Back then, I used the notation µ\\ :"
"sub:`P` to refer to the mean mood gain for the placebo group, with µ\\ :sub:"
"`A` and µ\\ :sub:`J` corresponding to the group means for the two drugs, and "
"the null hypothesis was µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`. So we’re "
"actually talking about the same hypothesis, it’s just that the more "
"complicated ANOVA requires more careful notation due to the presence of "
"multiple grouping variables, so we’re now referring to this hypothesis as "
"µ\\ :sub:`1.` = µ\\ :sub:`2.` = µ\\ :sub:`3.`. However, as we’ll see "
"shortly, although the hypothesis is identical the test of that hypothesis is "
"subtly different due to the fact that we’re now acknowledging the existence "
"of the second grouping variable."
msgstr ""
"Det er verdt å merke seg at dette er *nøyaktig* de samme statistiske "
"hypotesene som vi dannet da vi kjørte en enveis ANOVA på disse dataene i :"
"doc:`det forrige kapitlet <../Ch13/Ch13_ANOVA>`. Den gang brukte jeg "
"notasjonen µ\\ :sub:`P` for å referere til den gjennomsnittlige "
"humørforbedringen for placebogruppen, mens µ\\ :sub:`A` og µ\\ :sub:`J` "
"tilsvarte gruppegjennomsnittene for de to legemidlene, og nullhypotesen var "
"µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`. Så vi snakker faktisk om den "
"samme hypotesen, det er bare det at den mer kompliserte ANOVA-en krever en "
"mer forsiktig notasjon på grunn av tilstedeværelsen av flere "
"grupperingsvariabler, så vi refererer nå til denne hypotesen som µ\\ :sub:`1."
"` = µ\\ :sub:`2.` = µ\\ :sub:`3.`. Men som vi snart skal se, er testen av "
"hypotesen litt annerledes, selv om hypotesen er identisk, fordi vi nå "
"erkjenner eksistensen av den andre grupperingsvariabelen."

#: ../../Ch14/Ch14_ANOVA2_01.rst:192
msgid ""
"Speaking of the other grouping variable, you won’t be surprised to discover "
"that our second hypothesis test is formulated the same way. However, since "
"we’re talking about the psychological therapy rather than drugs our null "
"hypothesis now corresponds to the equality of the column means:"
msgstr ""
"Når vi snakker om den andre grupperingsvariabelen, vil du ikke bli "
"overrasket over å oppdage at vår andre hypotesetest er formulert på samme "
"måte. Men siden vi snakker om psykologisk terapi i stedet for legemiddel, "
"tilsvarer nullhypotesen vår nå likhet mellom kolonnegjennomsnittene:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:199
msgid "column means are the same, i.e., µ\\ :sub:`.1` = µ\\ :sub:`.2`"
msgstr "kolonnemidlene er de samme, dvs. µ\\ :sub:`.1` = µ\\ :sub:`.2`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:202
msgid "column means are different, i.e., µ\\ :sub:`.1` ≠ µ\\ :sub:`.2`"
msgstr "kolonnemidlene er forskjellige, dvs. µ\\ :sub:`.1` ≠ µ\\ :sub:`.2`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:207
msgid "Running the analysis in jamovi"
msgstr "Kjører analysen i jamovi"

#: ../../Ch14/Ch14_ANOVA2_01.rst:209
msgid ""
"The null and alternative hypotheses that I described in the last section "
"should seem awfully familiar. They’re basically the same as the hypotheses "
"that we were testing in our simpler :doc:`one-way ANOVAs <../Ch13/"
"Ch13_ANOVA>`. So you’re probably expecting that the hypothesis *tests* that "
"are used in factorial ANOVA will be essentially the same as the *F*-test "
"from :doc:`the previous chapter <../Ch13/Ch13_ANOVA>`. You’re expecting to "
"see references to sums of squares (SS), mean squares (MS), degrees of "
"freedom (df), and finally an *F*-statistic that we can convert into a *p*-"
"value, right? Well, you’re absolutely and completely right. So much so that "
"I’m going to depart from my usual approach. Throughout this book, I’ve "
"generally taken the approach of describing the logic (and to an extent the "
"mathematics) that underpins a particular analysis first and only then "
"introducing the analysis in jamovi. This time I’m going to do it the other "
"way around and show you how to do it in jamovi first. The reason for doing "
"this is that I want to highlight the similarities between the simpler one-"
"Way ANOVA that we discussed in :doc:`the previous chapter <../Ch13/"
"Ch13_ANOVA>`, and the more complicated approach that we’re going to use in "
"this chapter."
msgstr ""
"Null- og alternativhypotesene som jeg beskrev i forrige avsnitt, bør virke "
"veldig kjent. De er i bunn og grunn de samme som hypotesene vi testet i vår "
"enklere :doc:`enveis ANOVA <../Ch13/Ch13_ANOVA>`. Så du forventer "
"sannsynligvis at *hypotesetestene* som brukes i faktoriell ANOVA, i hovedsak "
"er de samme som *F*-testen fra :doc:`det forrige kapittelet <../Ch13/"
"Ch13_ANOVA>`. Du forventer å se referanser til kvadratsummer (SS), "
"gjennomsnittskvadrat (MS), frihetsgrader (df) og til slutt en *F*-"
"statistikksom vi kan konvertere til en *p*-verdi, ikke sant? Det har du helt "
"og holdent rett i. Så mye at jeg kommer til å avvike fra min vanlige "
"tilnærming. I denne boken har jeg som regel valgt å beskrive logikken (og "
"til en viss grad matematikken) som ligger til grunn for en bestemt analyse "
"først, og først deretter introdusere analysen i jamovi. Denne gangen skal "
"jeg gjøre det omvendt og vise deg hvordan du gjør det i jamovi først. "
"Grunnen til at jeg gjør dette, er at jeg ønsker å fremheve likhetene mellom "
"den enklere enveis ANOVA-analysen som vi diskuterte i :doc:`det forrige "
"kapittelet <../Ch13/Ch13_ANOVA>`, og den mer kompliserte tilnærmingen som vi "
"skal bruke i dette kapittelet."

#: ../../Ch14/Ch14_ANOVA2_01.rst:227
msgid ""
"If the data you’re trying to analyse correspond to a balanced factorial "
"design then running your analysis of variance is easy. To see how easy it "
"is, let’s start by reproducing the original analysis from chapter :doc:`../"
"Ch13/Ch13_ANOVA`. In case you’ve forgotten, for that analysis we were using "
"only a single factor (i.e., ``drug``) to predict our outcome variable (i.e., "
"``mood.gain``), and we got the results shown in :numref:`fig-"
"factorialanova2`."
msgstr ""
"Hvis dataene du prøver å analysere, tilsvarer et balansert faktorialt "
"design, er det enkelt å kjøre variansanalysen. For å se hvor enkelt det er, "
"la oss begynne med å reprodusere den opprinnelige analysen fra kapittel :doc:"
"`../Ch13/Ch13_ANOVA`. I tilfelle du har glemt det, brukte vi i den analysen "
"bare én enkelt faktor (dvs. ``drug``) til å predikere utfallsvariabelen vår "
"(dvs. ``mood.gain``), og vi fikk resultatene som vises i :numref:`fig-"
"factorialanova2`."

#: ../../Ch14/Ch14_ANOVA2_01.rst:237 ../../Ch14/Ch14_ANOVA2_01.rst:241
msgid "jamovi One-way ANOVA of ``mood.gain`` by ``drug``"
msgstr "jamovi Enveis ANOVA av ``mood.gain`` etter ``drug``"

#: ../../Ch14/Ch14_ANOVA2_01.rst:245
msgid ""
"Now, suppose I’m also curious to find out if ``therapy`` has a relationship "
"to ``mood.gain``. In light of what we’ve seen from our discussion of "
"multiple regression in chapter :doc:`../Ch12/Ch12_Regression`, you probably "
"won’t be surprised that all we have to do is add ``therapy`` as a second "
"``Fixed Factor`` in the analysis, see :numref:`fig-factorialanova3`."
msgstr ""
"Sett nå at jeg også er nysgjerrig på om ``therapy`` har en sammenheng med "
"``mood.gain``. I lys av det vi har sett fra diskusjonen om multippel "
"regresjon i kapittel :doc:`../Ch12/Ch12_Regression`, vil du sannsynligvis "
"ikke bli overrasket over at alt vi trenger å gjøre er å legge til "
"``therapy`` som en annen ``Fixed Factor`` i analysen, se :numref:`fig-"
"factorialanova3`."

#: ../../Ch14/Ch14_ANOVA2_01.rst:253
msgid ""
"jamovi factorial ANOVA for ``mood.gain`` with the factors ``drug`` and "
"``therapy``"
msgstr ""
"jamovi faktoriell ANOVA for ``mood.gain`` med faktorene ``drug`` og "
"``therapy``"

#: ../../Ch14/Ch14_ANOVA2_01.rst:257
msgid ""
"jamovi factorial ANOVA for ``mood.gain`` with the two factors ``drug`` and "
"``therapy``"
msgstr ""
"jamovi faktoriell ANOVA for ``mood.gain`` med de to faktorene ``drug`` og "
"``therapy``"

#: ../../Ch14/Ch14_ANOVA2_01.rst:262
msgid ""
"This output is pretty simple to read too. The first row of the table reports "
"a between-group sum of squares (SS) value associated with the ``drug`` "
"factor, along with a corresponding between-group *df*-value. It also "
"calculates a mean square value (MS), an *F*-statistic and a *p*-value. There "
"is also a row corresponding to the ``therapy`` factor and a row "
"corresponding to the residuals (i.e., the within groups variation)."
msgstr ""
"Dette resultatet er også ganske enkelt å lese. Den første raden i tabellen "
"rapporterer en kvadratsumverdi (SS) mellom gruppene knyttet til faktoren "
"``drug``, sammen med en tilsvarende *df*-verdi mellom gruppene. Den beregner "
"også en gjennomsnittlig kvadratverdi (MS), en *F*-statistikk og en *p*-"
"verdi. Det finnes også en rad som tilsvarer faktoren ``therapy`` og en rad "
"som tilsvarer residuene (dvs. variasjonen innenfor gruppene)."

#: ../../Ch14/Ch14_ANOVA2_01.rst:269
msgid ""
"Not only are all of the individual quantities pretty familiar, the "
"relationships between these different quantities has remained unchanged, "
"just like we saw with the original one-way ANOVA. Note that the mean square "
"value is calculated by dividing SS by the corresponding *df*. That is, it’s "
"still true that:"
msgstr ""
"Ikke bare er alle de individuelle størrelsene ganske velkjente, men "
"forholdet mellom de ulike størrelsene er også uendret, akkurat som vi så med "
"den opprinnelige enveis-ANOVAen. Legg merke til at den gjennomsnittlige "
"kvadratverdien beregnes ved å dividere SS med den tilsvarende *df*. Det vil "
"si at det fortsatt er sant at:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:275
msgid "MS = SS / df"
msgstr "MS = SS / df"

#: ../../Ch14/Ch14_ANOVA2_01.rst:277
msgid ""
"regardless of whether we’re talking about ``drug``, ``therapy`` or the "
"residuals. To see this, let’s not worry about how the sums of squares values "
"are calculated. Instead, let’s take it on faith that jamovi has calculated "
"the SS values correctly, and try to verify that all the rest of the numbers "
"make sense. First, note that for the ``drug`` factor, we divide 3.45 by 2 "
"and end up with a mean square value of 1.73. For the ``therapy`` factor, "
"there’s only 1 degree of freedom, so our calculations are even simpler: "
"dividing 0.47 (the SS value) by 1 gives us an answer of 0.47 (the MS value)."
msgstr ""
"uavhengig av om vi snakker om ``drug``, ``therapy`` eller residuene. For å "
"se dette, la oss ikke bekymre oss for hvordan kvadratsummene (SS) er "
"beregnet. La oss i stedet stole på at jamovi har beregnet kvadratsummene "
"riktig, og prøve å verifisere at resten av tallene gir mening. Først må vi "
"legge merke til at for faktoren ``drug`` dividerer vi 3,45 med 2 og ender "
"opp med en gjennomsnittlig kvadratverdi (MS) på 1,73. For faktoren "
"``therapy`` er det bare én frihetsgrad, så beregningene våre er enda "
"enklere: Ved å dividere 0,47 (SS) med 1 får vi et svar på 0,47 (MS)."

#: ../../Ch14/Ch14_ANOVA2_01.rst:286
msgid ""
"Turning to the *F*-statistics and the *p*-values, notice that we have two of "
"each; one corresponding to the ``drug`` factor and the other corresponding "
"to the ``therapy`` factor. Regardless of which one we’re talking about, the "
"*F*-statistic is calculated by dividing the mean square value associated "
"with the factor by the mean square value associated with the residuals. If "
"we use “A” as shorthand notation to refer to the first factor (factor A; in "
"this case ``drug``) and “R” as shorthand notation to refer to the residuals, "
"then the *F*-statistic associated with factor A is denoted *F*\\ :sub:`A`, "
"and is calculated as follows:"
msgstr ""
"Når det gjelder *F*-statistikken og *p*-verdiene, legger vi merke til at vi "
"har to av hver; én som svarer til faktoren ``drug`` og én som svarer til "
"faktoren ``therapy``. Uansett hvilken av dem vi snakker om, beregnes *F*-"
"statistikken ved å dividere den gjennomsnittlige kvadratverdien knyttet til "
"faktoren med den gjennomsnittlige kvadratverdien knyttet til residuene. Hvis "
"vi bruker «A» som forkortelse for den første faktoren (faktor A; i dette "
"tilfellet ``drug``) og «R» som forkortelse for residuene, blir *F*-"
"statistikken knyttet til faktor A betegnet *F*\\ :sub:`A`, og beregnes på "
"følgende måte:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:297
msgid "*F*\\ :sub:`A` = MS\\ :sub:`A` / MS\\ :sub:`R`"
msgstr "*F*\\ :sub:`A` = MS\\ :sub:`A` / MS\\ :sub:`R`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:299
msgid ""
"and an equivalent formula exists for factor B (i.e., ``therapy``). Note that "
"this use of “R” to refer to residuals is a bit awkward, since we also used "
"the letter R to refer to the number of rows in the table, but I’m only going "
"to use “R” to mean residuals in the context of SS\\ :sub:`R` and MS\\ :sub:"
"`R`, so hopefully this shouldn’t be confusing. Anyway, to apply this formula "
"to the ``drug`` factor we take the mean square of 1.73 and divide it by the "
"residual mean square value of 0.07, which gives us an *F*-statistic of "
"26.15. The corresponding calculation for the ``therapy`` variable would be "
"to divide 0.47 by 0.07 which gives 7.08 as the *F*-statistic. Not "
"surprisingly, of course, these are the same values that jamovi has reported "
"in the ANOVA table above."
msgstr ""
"og en tilsvarende formel finnes for faktor B (dvs. ``therapy``). Merk at "
"denne bruken av «R» for å referere til residuer er litt vanskelig, siden vi "
"også brukte bokstaven R for å referere til antall rader i tabellen, men jeg "
"kommer bare til å bruke «R» for å referere til residuer i forbindelse med "
"SS\\ :sub:`R` og MS\\ :sub:`R`, så forhåpentligvis bør ikke dette være "
"forvirrende. Uansett, for å bruke denne formelen på faktoren ``drug`` tar vi "
"den gjennomsnittlige kvadratverdien på 1,73 og deler det på den "
"gjennomsnittlige kvadratverdien av residuene på 0,07, noe som gir oss en *F*-"
"statistikk på 26,15. Den tilsvarende beregningen for variabelen ``therapy`` "
"ville være å dividere 0,47 med 0,07, noe som gir 7,08 som *F*-statistikk. "
"Ikke overraskende er dette de samme verdiene som jamovi har rapportert i "
"ANOVA-tabellen ovenfor."

#: ../../Ch14/Ch14_ANOVA2_01.rst:312
msgid ""
"Also in the ANOVA table is the calculation of the *p*-values. Once again, "
"there is nothing new here. For each of our two factors what we’re trying to "
"do is test the null hypothesis that there is no relationship between the "
"factor and the outcome variable (I’ll be a bit more precise about this later "
"on). To that end, we’ve (apparently) followed a similar strategy to what we "
"did in the One-Way ANOVA and have calculated an *F*-statistic for each of "
"these hypotheses. To convert these to *p*-values, all we need to do is note "
"that the sampling distribution for the *F*-*statistic* under the null "
"hypothesis (that the factor in question is irrelevant) is an *F*- "
"*distribution*. Also note that the two degrees of freedom values are those "
"corresponding to the factor and those corresponding to the residuals. For "
"the ``drug`` factor we’re talking about an *F*- distribution with 2 and 14 "
"degrees of freedom (I’ll discuss degrees of freedom in more detail later). "
"In contrast, for the ``therapy`` factor the sampling distribution is *F* "
"with 1 and 14 degrees of freedom."
msgstr ""
"I ANOVA-tabellen finner du også beregningen av *p*-verdiene. Heller ikke her "
"er det noe nytt. For hver av de to faktorene våre prøver vi å teste "
"nullhypotesen om at det ikke er noen sammenheng mellom faktoren og "
"utfallsvariabelen (jeg skal være litt mer presis om dette senere). For å "
"oppnå dette har vi (tilsynelatende) fulgt en lignende strategi som vi gjorde "
"i en enveis ANOVA, og vi har beregnet en *F*-statistikk for hver av disse "
"hypotesene. For å konvertere disse til *p*-verdier trenger vi bare å merke "
"oss at utvalgsfordelingen for *F*-*statistikken* under nullhypotesen (at den "
"aktuelle faktoren er irrelevant) er en *F*-*fordeling*. Legg også merke til "
"at det er to verdier for frihetsgradene: en som svarer til faktoren og en "
"som svarer til residuene. For faktoren ``drug`` snakker vi om en *F*-"
"fordeling med 2 og 14 frihetsgrader (jeg kommer nærmere inn på frihetsgrader "
"senere). For faktoren ``therapy`` er det derimot en *F*-fordeling med 1 og "
"14 frihetsgrader."

#: ../../Ch14/Ch14_ANOVA2_01.rst:329
msgid ""
"At this point, I hope you can see that the ANOVA table for this more "
"complicated factorial analysis should be read in much the same way as the "
"ANOVA table for the simpler one-way analysis. In short, it’s telling us that "
"the factorial ANOVA for our 3 × 2 design found a significant effect of drug: "
"*F*\\(2,14) = 26.15, *p* < 0.001, as well as a significant effect of "
"therapy: *F*\\(1,14) = 7.08, *p* = 0.02. Or, to use the more technically "
"correct terminology, we would say that there are two **main effects** of "
"drug and therapy. At the moment, it probably seems a bit redundant to refer "
"to these as “main” effects, but it actually does make sense. Later on, we’re "
"going to want to talk about the possibility of “interactions” between the "
"two factors, and so we generally make a distinction between main effects and "
"interaction effects."
msgstr ""
"Nå håper jeg at du forstår at ANOVA-tabellen for denne mer kompliserte "
"faktoranalysen bør leses på omtrent samme måte som ANOVA-tabellen for den "
"enklere enveisanalysen. Kort sagt forteller den oss at den faktorielle ANOVA-"
"analysen for vårt 3 × 2-design fant en signifikant effekt av legemiddelet "
"(``drug``): *F*\\(2,14) = 26,15, *p* < 0,001, samt en signifikant effekt av "
"terapi (``therapy``): *F*\\(1,14) = 7,08, *p* = 0,02. Eller, for å bruke en "
"mer teknisk korrekt terminologi, vi kan si at det er to **hovedeffekter** av "
"legemiddel og terapi. Akkurat nå virker det kanskje litt overflødig å "
"referere til disse som «hovedeffekter», men det gir faktisk mening. Senere "
"kommer vi til å snakke om muligheten for «interaksjoner» mellom de to "
"faktorene, og derfor skiller vi generelt mellom hovedeffekter og "
"interaksjonseffekter."

#: ../../Ch14/Ch14_ANOVA2_01.rst:344
msgid "How are the sum of squares calculated?"
msgstr "Hvordan beregnes kvadratsummen?"

#: ../../Ch14/Ch14_ANOVA2_01.rst:346
msgid ""
"In the previous section I had two goals. Firstly, to show you that the "
"jamovi method needed to do factorial ANOVA is pretty much the same as what "
"we used for a One-Way ANOVA. The only difference is the addition of a second "
"factor. Secondly, I wanted to show you what the ANOVA table looks like in "
"this case, so that you can see from the outset that the basic logic and "
"structure behind factorial ANOVA is the same as that which underpins One-Way "
"ANOVA. Try to hold onto that feeling. It’s genuinely true, insofar as "
"factorial ANOVA is built in more or less the same way as the simpler one-way "
"ANOVA model. It’s just that this feeling of familiarity starts to evaporate "
"once you start digging into the details. Traditionally, this comforting "
"sensation is replaced by an urge to hurl abuse at the authors of statistics "
"textbooks."
msgstr ""
"I forrige avsnitt hadde jeg to mål. For det første å vise at jamovi-metoden "
"som trengs for å gjøre en faktoriell ANOVA, er stort sett den samme som den "
"vi brukte for en enveis ANOVA. Den eneste forskjellen er at vi legger til en "
"ekstra faktor. For det andre vil jeg vise deg hvordan ANOVA-tabellen ser ut "
"i dette tilfellet, slik at du fra starten av kan se at den grunnleggende "
"logikken og strukturen bak faktoriell ANOVA er den samme som den som ligger "
"til grunn for enveis ANOVA. Prøv å holde fast ved den følelsen. Det er "
"faktisk sant, i den forstand at faktoriell ANOVA er bygget opp på mer eller "
"mindre samme måte som den enklere enveis ANOVA-modellen. Det er bare det at "
"denne følelsen av fortrolighet begynner å fordampe når du begynner å grave "
"deg ned i detaljene. Tradisjonelt sett blir denne trygghetsfølelsen "
"erstattet av en trang til å skjelle ut forfatterne av lærebøker i statistikk."

#: ../../Ch14/Ch14_ANOVA2_01.rst:359
msgid ""
"Okay, let’s start by looking at some of those details. The explanation that "
"I gave in the last section illustrates the fact that the hypothesis tests "
"for the main effects (of ``drug`` and ``therapy`` in this case) are *F*-"
"tests, but what it doesn’t do is show you how the sum of squares (SS) values "
"are calculated. Nor does it tell you explicitly how to calculate degrees of "
"freedom (*df*-values) though that’s a simple thing by comparison. Let’s "
"assume for now that we have only two predictor variables, Factor A and "
"Factor B. If we use *Y* to refer to the outcome variable, then we would use "
"*Y*\\ :sub:`rci` to refer to the outcome associated with the i-th member of "
"group rc (i.e., level/row *r* for Factor A and level/column *c* for Factor "
"B). Thus, if we use Ȳ to refer to a sample mean, we can use the same "
"notation as before to refer to group means, marginal means and grand means. "
"That is, Ȳ\\ :sub:`rc` is the sample mean associated with the *r*\\ th level "
"of Factor A and the *c*\\ th level of Factor B, Ȳ\\ :sub:`r.` would be the "
"marginal mean for the *r*\\ th level of Factor A, Ȳ\\ :sub:`.c` would be the "
"marginal mean for the *c*\\ th level of Factor B, and Ȳ\\ :sub:`..` is the "
"grand mean. In other words, our sample means can be organised into the same "
"table as the population means. For our |clinicaltrial|_ data, that table "
"looks like this:"
msgstr ""
"La oss begynne med å se på noen av disse detaljene. Forklaringen jeg ga i "
"forrige avsnitt, illustrerer det faktum at hypotesetestene for "
"hovedeffektene (av ``drug`` og ``therapy`` i dette tilfellet) er *F*-tester, "
"men den viser ikke hvordan kvadratsummenene (SS) beregnes. Den forteller deg "
"heller ikke eksplisitt hvordan du beregner frihetsgrader (*df*-verdier), "
"selv om det er en enkel ting til sammenligning. La oss foreløpig anta at vi "
"bare har to prediktorvariabler, Faktor A og Faktor B. Hvis vi bruker *Y* for "
"å referere til utfallsvariabelen, vil vi bruke *Y*\\ :sub:`rci` for å "
"referere til utfallet som er knyttet til det i-te medlemmet av gruppe rc "
"(dvs. nivå/rad *r* for Faktor A og nivå/kolonne *c* for Faktor B). Hvis vi "
"bruker Ȳ for å referere til et utvalgsgjennomsnitt, kan vi bruke samme "
"notasjon som tidligere for å referere til gruppegjennomsnitt, "
"marginalgjennomsnitt og totalgjennomsnitt. Det vil si at Ȳ\\ :sub:`rc` er "
"utvalgsgjennomsnittet som er knyttet til *r*\\th-nivået for faktor A og "
"*c*\\th-nivået for faktor B, Ȳ\\ :sub:`r.` vil være det marginale "
"gjennomsnittet for *r*\\th-nivået for faktor A, Ȳ\\ :sub:`.c` vil være det "
"marginale gjennomsnittet for *c*\\th-nivået for faktor B, og Ȳ\\ :sub:`..` "
"er det totale gjennomsnittet. Med andre ord kan gjennomsnittene fra "
"stikkprøvene organiseres i samme tabell som populasjonsgjennomsnittene. For "
"dataene våre fra |clinicaltrial|_ ser tabellen slik ut:"

#: ../../Ch14/Ch14_ANOVA2_01.rst:385
msgid "Ȳ\\ :sub:`11`"
msgstr "Ȳ\\ :sub:`11`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:385
msgid "Ȳ\\ :sub:`12`"
msgstr "Ȳ\\ :sub:`12`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:385
msgid "Ȳ\\ :sub:`1.`"
msgstr "Ȳ\\ :sub:`1.`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:387
msgid "Ȳ\\ :sub:`21`"
msgstr "Ȳ\\ :sub:`21`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:387
msgid "Ȳ\\ :sub:`22`"
msgstr "Ȳ\\ :sub:`22`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:387
msgid "Ȳ\\ :sub:`2.`"
msgstr "Ȳ\\ :sub:`2.`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:389
msgid "Ȳ\\ :sub:`31`"
msgstr "Ȳ\\ :sub:`31`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:389
msgid "Ȳ\\ :sub:`32`"
msgstr "Ȳ\\ :sub:`32`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:389
msgid "Ȳ\\ :sub:`3.`"
msgstr "Ȳ\\ :sub:`3.`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:391
msgid "Ȳ\\ :sub:`.1`"
msgstr "Ȳ\\ :sub:`.1`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:391
msgid "Ȳ\\ :sub:`.2`"
msgstr "Ȳ\\ :sub:`.2`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:391
msgid "Ȳ\\ :sub:`..`"
msgstr "Ȳ\\ :sub:`..`"

#: ../../Ch14/Ch14_ANOVA2_01.rst:394
msgid ""
"And if we look at the sample means that I showed earlier, we have Ȳ\\ :sub:"
"`11` = 0.30, Ȳ\\ :sub:`12` = 0.60 etc. In our |clinicaltrial|_ data, the "
"``drug`` factor has 3 levels and the ``therapy`` factor has 2 levels, and so "
"what we’re trying to run is a 3 × 2 factorial ANOVA. However, we’ll be a "
"little more general and say that Factor A (the row factor) has *R* levels "
"and Factor B (the column factor) has *C* levels, and so what we’re runnning "
"here is an R × C factorial ANOVA."
msgstr ""
"Og hvis vi ser på utvalgsgjennomsnittet som jeg viste tidligere, har vi Ȳ\\ :"
"sub:`11` = 0,30, Ȳ\\ :sub:`12` = 0,60 osv. I våre |clinicaltrial|_-data har "
"faktoren ``drug`` 3 nivåer og faktoren ``therapy`` har 2 nivåer, og det vi "
"prøver å kjøre er derfor en 3 × 2 faktoriell ANOVA. Vi kan imidlertid være "
"litt mer generelle og si at faktor A (radfaktoren) har *R* nivåer og faktor "
"B (kolonnefaktoren) har *C* nivåer, så det vi kjører her, er en R × C-"
"faktoriell ANOVA."

#: ../../Ch14/Ch14_ANOVA2_01.rst:402
msgid ""
"Now that we’ve got our notation straight, we can compute the sum of squares "
"values for each of the two factors in a relatively familiar way. For Factor "
"A, our between group sum of squares is calculated by assessing the extent to "
"which the (row) marginal means Ȳ\\ :sub:`1.`, Ȳ\\ :sub:`2.` etc, are "
"different from the grand mean Ȳ\\ :sub:`..`\\. We do this in the same way "
"that we did for one-way ANOVA: calculate the sum of squared difference "
"between the Ȳ\\ :sub:`i.` values and the Ȳ\\ :sub:`..` values. Specifically, "
"if there are *N* people in each group, then we calculate this"
msgstr ""
"Nå som vi har fått orden på notasjonen, kan vi beregne kvadratsummen for "
"hver av de to faktorene på en relativt velkjent måte. For faktor A beregnes "
"kvadratsummen mellom gruppene ved å vurdere i hvilken grad de (rad)marginale "
"gjennomsnittene Ȳ\\ :sub:`1.`, Ȳ\\ :sub:`2.` osv. er forskjellige fra det "
"totale gjennomsnittet Ȳ\\ :sub:`..`\\. Vi gjør dette på samme måte som vi "
"gjorde for enveis ANOVA: beregner summen av den kvadrerte forskjellen mellom "
"Ȳ\\ :sub:`i.`-verdiene og Ȳ\\ :sub:`..`-verdiene. Hvis det er *N* personer i "
"hver gruppe, beregner vi dette"

#: ../../Ch14/Ch14_ANOVA2_01.rst:412
msgid ""
"\\mbox{SS}_{A} = (N \\times C)  \\sum_{r=1}^R  \\left( \\bar{Y}_{r.} - "
"\\bar{Y}_{..} \\right)^2\n"
"\n"
msgstr ""
"\\mbox{SS}_{A} = (N \\times C)  \\sum_{r=1}^R  \\left( \\bar{Y}_{r.} - "
"\\bar{Y}_{..} \\right)^2\n"
"\n"

#: ../../Ch14/Ch14_ANOVA2_01.rst:414
msgid ""
"As with one-way ANOVA, the most interesting\\ [#]_ part of this formula is "
"the (Ȳ\\ :sub:`r.` – Ȳ\\ :sub:`..`)² bit, which corresponds to the squared "
"deviation associated with level *r*. All that this formula does is calculate "
"this squared deviation for all *R* levels of the factor, add them up, and "
"then multiply the result by *N* × *C*. The reason for this last part is that "
"there are multiple cells in our design that have level *r* on Factor A. In "
"fact, there are *C* of them, one corresponding to each possible level of "
"Factor B! For instance, in our example there are *two* different cells in "
"the design corresponding to the ``anxifree`` drug: one for people with ``no."
"therapy`` and one for the ``CBT`` group. Not only that, within each of these "
"cells there are *N* observations. So, if we want to convert our SS value "
"into a quantity that calculates the between-groups sum of squares on a “per "
"observation” basis, we have to multiply by *N* × *C*. The formula for factor "
"B is of course the same thing, just with some subscripts shuffled around"
msgstr ""
"Som ved enveis ANOVA er den mest interessante\\ [#]_ delen av denne formelen "
"(Ȳ\\ :sub:`r.` - Ȳ\\ :sub:`..`)²-biten, som tilsvarer det kvadrerte avviket "
"som er knyttet til nivå *r*. Alt denne formelen gjør, er å beregne dette "
"kvadrerte avviket for alle *R* nivåer av faktoren, legge dem sammen og "
"deretter multiplisere resultatet med *N* × *C*. Grunnen til det siste er at "
"det er flere celler i designet vårt som har nivå *r* på faktor A. Faktisk er "
"det *C* av dem, én som tilsvarer hvert mulige nivå på faktor B! I vårt "
"eksempel er det for eksempel *to* forskjellige celler i designet som "
"tilsvarer det legemiddelet ``anxifree``: én for personer som ikke fikk "
"terapi (``no.therapy``) og én for gruppen som fikk ``CBT``. Ikke bare det, "
"innenfor hver av disse cellene finnes det *N* observasjoner. Så hvis vi "
"ønsker å konvertere våre kvadratsummene (SS) til en størrelse som beregner "
"kvadratsummen mellom gruppene på «per observasjon»-basis, må vi multiplisere "
"med *N* × *C*. Formelen for faktor B er selvfølgelig den samme, bare med "
"noen endringer i indeksene"

#: ../../Ch14/Ch14_ANOVA2_01.rst:429
msgid ""
"\\mbox{SS}_{B} = (N \\times R) \\sum_{c=1}^C \\left( \\bar{Y}_{.c} - \\bar{Y}"
"_{..} \\right)^2\n"
"\n"
msgstr ""
"\\mbox{SS}_{B} = (N \\times R) \\sum_{c=1}^C \\left( \\bar{Y}_{.c} - \\bar{Y}"
"_{..} \\right)^2\n"
"\n"

#: ../../Ch14/Ch14_ANOVA2_01.rst:431
msgid ""
"Now that we have these formulas we can check them against the jamovi output "
"from the earlier section."
msgstr ""
"Nå som vi har disse formlene, kan vi sjekke dem mot jamovi-utgaven fra "
"forrige avsnitt."

#: ../../Ch14/Ch14_ANOVA2_01.rst:434
msgid ""
"First, let’s calculate the sum of squares associated with the main effect of "
"``drug``. There are a total of *N* = 3 people in each group and *C* = 2 "
"different types of therapy. Or, to put it another way, there are 3 · 2 = 6 "
"people who received any particular drug. When we do these calculations in a "
"spreadsheet programme, we get a value of 3.45 for the sum of squares "
"associated with the main effect of ``drug``. Not surprisingly, this is the "
"same number that you get when you look up the SS value for the ``drug`` "
"factor in the ANOVA table that I presented earlier, in :numref:`fig-"
"factorialanova3`."
msgstr ""
"La oss først beregne summen av kvadrater knyttet til hovedeffekten av "
"``drug``. Det er totalt *N* = 3 personer i hver gruppe og *C* = 2 ulike "
"typer terapi (``therapy``). Eller sagt på en annen måte: Det er 3 - 2 = 6 "
"personer som har fått et bestemt legemiddel (``drug``). Når vi gjør disse "
"beregningene i et regnearkprogram, får vi en verdi på 3,45 for kvadratsummen "
"knyttet til hovedeffekten av ``drug``. Ikke overraskende er dette det samme "
"tallet som du får når du slår opp kvadratsummen (SS) for faktoren ``drug`` i "
"ANOVA-tabellen som jeg presenterte tidligere, i :numref:`fig-"
"factorialanova3`."

#: ../../Ch14/Ch14_ANOVA2_01.rst:443
msgid ""
"We can repeat the same kind of calculation for the effect of ``therapy``. "
"Again, there are *N* = 3 people in each group, but since there are R = 3 "
"different values in ``drug``, this time around we note that there are 3 · 3 "
"= 9 people who received ``CBT`` and an additional 9 people who received ``no."
"therapy``. So our calculation in this case gives us a value of 0.47 for the "
"sum of squares associated with the main effect of ``therapy``. Once again, "
"we are not surprised to see that our calculations are identical to the ANOVA "
"output in :numref:`fig-factorialanova3`."
msgstr ""
"Vi kan gjenta samme type beregning for effekten av ``therapy``. Igjen er det "
"*N* = 3 personer i hver gruppe, men siden det er R = 3 forskjellige verdier "
"i ``drug``, ser vi denne gangen at det er 3 · 3 = 9 personer som fikk "
"``CBT`` og ytterligere 9 personer som fikk ``no.therapy``. I dette tilfellet "
"gir beregningen en verdi på 0,47 for kvadratsummen knyttet til hovedeffekten "
"av ``therapy``. Igjen er vi ikke overrasket over å se at beregningene våre "
"er identiske med utgaven fra ANOVA i :numref:`fig-factorialanova3`."

#: ../../Ch14/Ch14_ANOVA2_01.rst:451
msgid ""
"So that’s how you calculate the SS values for the two main effects. These SS "
"values are analogous to the between-group sum of squares values that we "
"calculated when doing the one-way ANOVA in :doc:`the previous chapter <../"
"Ch13/Ch13_ANOVA>`. However, it’s not a good idea to think of them as between-"
"groups SS values anymore, just because we have two different grouping "
"variables and it’s easy to get confused. In order to construct an *F*-test, "
"however, we also need to calculate the within-groups sum of squares. In "
"keeping with the terminology that we used in chapter :doc:`../Ch12/"
"Ch12_Regression` and the terminology that jamovi uses when printing out the "
"ANOVA table, I’ll start referring to the within-groups SS value as the "
"*residual* sum of squares SS\\ :sub:`R`."
msgstr ""
"Slik beregner du kvadratsummene (SS) for de to hovedeffektene. Verdiene for "
"SS er analoge med summen av kvadratsummene mellom gruppene som vi beregnet "
"da vi utførte enveis ANOVA i :doc:`det forrige kapittelet <../Ch13/"
"Ch13_ANOVA>`. Det er imidlertid ikke så lurt å tenke på dem som kvdratsummer "
"(SS) mellom grupper lenger, bare fordi vi har to forskjellige "
"grupperingsvariabler, og det er lett å bli forvirret. For å kunne konstruere "
"en *F*-test må vi imidlertid også beregne kvadratsummen innenfor gruppene. I "
"tråd med terminologien som vi brukte i kapittel :doc:`../Ch12/"
"Ch12_Regression` og terminologien som jamovi bruker når vi skriver ut ANOVA-"
"tabellen, vil jeg begynne å referere til kvadratsummen (SS) innenfor "
"gruppene som kvadratersummen av *residuene* SS\\ :sub:`R`."

#: ../../Ch14/Ch14_ANOVA2_01.rst:463
msgid ""
"The easiest way to think about the residual SS values in this context, I "
"think, is to think of it as the leftover variation in the outcome variable "
"after you take into account the differences in the marginal means (i.e., "
"after you remove SS\\ :sub:`A` and SS\\ :sub:`B`). What I mean by that is we "
"can start by calculating the total sum of squares, which I’ll label SS\\ :"
"sub:`T`. The formula for this is pretty much the same as it was for one-way "
"ANOVA. We take the difference between each observation *Y*\\ :sub:`rci` and "
"the grand mean Ȳ\\ :sub:`..`, square the differences, and add them all up"
msgstr ""
"Den enkleste måten å tenke på kvadratsummen av residuene i denne "
"sammenhengen er å se på dem som resterende variasjonen i utfallsvariabelen "
"etter at du har tatt hensyn til forskjellene i de randgjennomsnittene (dvs. "
"etter at du har subtrahert SS\\ :sub:`A` og SS\\ :sub:`B`). Det jeg mener "
"med det, er at vi kan begynne med å beregne den totale kvadratsummen, som "
"jeg kaller SS\\ :sub:`T`. Formelen for dette er stort sett den samme som for "
"enveis ANOVA. Vi tar differansen mellom hver observasjon *Y*\\ :sub:`rci` og "
"det totale gjennomsnittet Ȳ\\ :sub:`..`, kvadrerer differansene og legger "
"dem sammen"

#: ../../Ch14/Ch14_ANOVA2_01.rst:472
msgid ""
"\\mbox{SS}_T = \\sum_{r=1}^R \\sum_{c=1}^C \\sum_{i=1}^N \\left( Y_{rci} - "
"\\bar{Y}_{..}\\right)^2\n"
"\n"
msgstr ""
"\\mbox{SS}_T = \\sum_{r=1}^R \\sum_{c=1}^C \\sum_{i=1}^N \\left( Y_{rci} - "
"\\bar{Y}_{..}\\right)^2\n"
"\n"

#: ../../Ch14/Ch14_ANOVA2_01.rst:474
msgid ""
"The “triple summation” here looks more complicated than it is. In the first "
"two summations, we’re summing across all levels of Factor A (i.e., over all "
"possible rows *r* in our table) and across all levels of Factor B (i.e., all "
"possible columns *c*). Each rc-combination corresponds to a single group and "
"each group contains *N* people, so we have to sum across all those people (i."
"e., all i values) too. In other words, all we’re doing here is summing "
"across all observations in the data set (i.e., all possible rci-"
"combinations)."
msgstr ""
"«Trippelsummeringen» her ser mer komplisert ut enn den er. I de to første "
"summeringene summerer vi over alle nivåer av faktor A (dvs. over alle mulige "
"rader *r* i tabellen vår) og over alle nivåer av faktor B (dvs. alle mulige "
"kolonner *c*). Hver rc-kombinasjon tilsvarer én enkelt gruppe, og hver "
"gruppe inneholder *N* personer, så vi må også summere over alle disse "
"personene (dvs. alle i-verdiene). Med andre ord, alt vi gjør her, er å "
"summere over alle observasjonene i datasettet (dvs. alle mulige rci-"
"kombinasjoner)."

#: ../../Ch14/Ch14_ANOVA2_01.rst:482
msgid ""
"At this point, we know the total variability of the outcome variable SS\\ :"
"sub:`T`, and we know how much of that variability can be attributed to "
"Factor A (SS\\ :sub:`A`) and how much of it can be attributed to Factor B "
"(SS\\ :sub:`B`). The residual sum of squares is thus defined to be the "
"variability in *Y* that *can’t* be attributed to either of our two factors. "
"In other words"
msgstr ""
"På dette tidspunktet kjenner vi den totale variabiliteten i "
"utfallsvariabelen SS\\ :sub:`T`, og vi vet hvor mye av denne variabiliteten "
"som kan tilskrives faktor A (SS\\ :sub:`A`) og hvor mye som kan tilskrives "
"faktor B (SS\\ :sub:`B`). Kvadratsummen for residuene er dermed definert som "
"den variasjonen i *Y* som *ikke* kan tilskrives en av de to faktorene våre. "
"Med andre ord"

#: ../../Ch14/Ch14_ANOVA2_01.rst:489
msgid "SS\\ :sub:`R` = SS\\ :sub:`T` - (SS\\ :sub:`A` + SS\\ :sub:`B`)"
msgstr "SS\\ :sub:`R` = SS\\ :sub:`T` - (SS\\ :sub:`A` + SS\\ :sub:`B`)"

#: ../../Ch14/Ch14_ANOVA2_01.rst:491
msgid ""
"Of course, there is a formula that you can use to calculate the residual SS "
"(SS\\ :sub:`R`) directly, but I think that it makes more conceptual sense to "
"think of it like this. The whole point of calling it a residual is that it’s "
"the leftover variation, and the formula above makes that clear. I should "
"also note that, in keeping with the terminology used in the regression "
"chapter, it is commonplace to refer to SS\\ :sub:`A` + SS\\ :sub:`B` as the "
"variance attributable to the “ANOVA model”, denoted SS\\ :sub:`M`, and so we "
"often say that the total sum of squares is equal to the model sum of squares "
"plus the residual sum of squares. Later on in this chapter we’ll see that "
"this isn’t just a surface similarity: ANOVA and regression are actually the "
"same thing under the hood."
msgstr ""
"Det finnes selvfølgelig en formel som du kan bruke til å beregne "
"kvadratsummen for residuene (SS\\ :sub:`R`) direkte, men jeg tror det gir "
"mer konseptuell mening å tenke på det slik. Hele poenget med å kalle det en "
"residuum er at det er den resterende variasjonen, og formelen ovenfor gjør "
"det klart. Jeg bør også merke meg at det, i tråd med terminologien som "
"brukes i regresjonskapitlet, er vanlig å referere til SS\\ :sub:`A` + SS\\ :"
"sub:`B` som variansen som kan tilskrives «ANOVA-modellen», betegnet SS\\ :"
"sub:`M`, og derfor sier vi ofte at den totale kvadratsummen er lik "
"kvadratsummen for modellen pluss kvadratsummen for residuene. Senere i dette "
"kapittelet skal vi se at dette ikke bare er en overfladisk likhet: ANOVA og "
"regresjon er faktisk det samme under panseret."

#: ../../Ch14/Ch14_ANOVA2_01.rst:504
msgid ""
"In any case, it’s probably worth taking a moment to check that we can "
"calculate SS\\ :sub:`R` using this formula and verify that we do obtain the "
"same answer that jamovi produces in its ANOVA table. The calculations are "
"pretty straightforward when done using computed variables in jamovi. We "
"download and open the |clinicaltrial|_ data set and define three computed "
"variables: (1) ``sq_res_T`` with ``(mood.gain - VMEAN(mood.gain)) ^ 2`` as "
"formula, (2) ``sq_res_A`` with ``(VMEAN(mood.gain) - VMEAN(mood.gain, "
"group_by = drug)) ^ 2`` as formula, and (3) ``sq_res_B`` with ``(VMEAN(mood."
"gain) - VMEAN(mood.gain, group_by = therapy)) ^ 2`` as formula. Once we "
"created those three variables, we calculate the sum of squares using "
"``Descriptives`` → ``Descriptive Statistics``, then moving ``sq_res_T``, "
"``sq_res_A`` and ``sq_res_B`` to the ``Variables`` box, and finally "
"selecting ``Sum`` from the ``Statistics`` drop-down menu. SS\\ :sub:`T` "
"(``sq_res_T``) has a value of **4.845**, SS\\ :sub:`A` (``sq_res_A``) a "
"value of **3.453**, and SS\\ :sub:`B` (``sq_res_B``) a value of **0.467**. "
"Using these three values, we can calculate SS\\ :sub:`R` using the formula "
"above."
msgstr ""
"Uansett er det nok verdt å sjekke at vi kan beregne SS\\ :sub:`R` ved hjelp "
"av denne formelen, og verifisere at vi får det samme svaret som jamovi "
"produserer i ANOVA-tabellen sin. Beregningene er ganske enkle når de gjøres "
"ved hjelp av beregnede variabler i jamovi. Vi laster ned og åpner datasettet "
"|clinicaltrial|_ og definerer tre beregnede variabler: (1) ``sq_res_T`` med "
"``(mood.gain - VMEAN(mood.gain)) ^ 2`` som formel, (2) ``sq_res_A`` med "
"``(VMEAN(mood.gain) - VMEAN(mood.gain, group_by = drug)) ^ 2`` som formel, "
"og (3) ``sq_res_B`` med ``(VMEAN(mood.gain) - VMEAN(mood.gain, group_by = "
"therapy)) ^ 2`` som formel. Når vi har opprettet disse tre variablene, "
"beregner vi kvadratsummen ved å bruke ``Descriptives`` → ``Descriptive "
"Statistics``, deretter flytter vi ``sq_res_T``, ``sq_res_A`` og ``sq_res_B`` "
"til ``Variables``-boksen, og til slutt velger vi ``Sum`` fra ``Statistics``-"
"rullegardinmenyen. SS\\ :sub:`T` (``sq_res_T``) har en verdi på **4,845**, "
"SS\\ :sub:`A` (``sq_res_A``) en verdi på **3,453** og SS\\ :sub:`B` "
"(``sq_res_B``) en verdi på **0,467**. Ved hjelp av disse tre verdiene kan vi "
"beregne SS\\ :sub:`R` ved hjelp av formelen ovenfor."

#: ../../Ch14/Ch14_ANOVA2_01.rst:521
msgid "SS\\ :sub:`R` = 4.845 - (3.453 + 0.467)"
msgstr "SS\\ :sub:`R` = 4.845 - (3.453 + 0.467)"

#: ../../Ch14/Ch14_ANOVA2_01.rst:522
msgid "SS\\ :sub:`R` = 0.924"
msgstr "SS\\ :sub:`R` = 0.924"

#: ../../Ch14/Ch14_ANOVA2_01.rst:524
msgid ""
"Alternatively, we can create another computed variable with the name "
"``SS_R`` and the formula ``VSUM(sq_res_T) - (VSUM(sq_res_A) + "
"VSUM(sq_res_B))``."
msgstr ""
"Alternativt kan vi opprette en annen beregnet variabel med navnet ``SS_R`` "
"og formelen ``VSUM(sq_res_T) - (VSUM(sq_res_A) + VSUM(sq_res_B))``."

#: ../../Ch14/Ch14_ANOVA2_01.rst:528
msgid "What are our degrees of freedom?"
msgstr "Hva er våre frihetsgrader?"

#: ../../Ch14/Ch14_ANOVA2_01.rst:530
msgid ""
"The degrees of freedom are calculated in much the same way as for one-way "
"ANOVA. For any given factor, the degrees of freedom is equal to the number "
"of levels minus 1 (i.e., R - 1 for the row variable Factor A, and C - 1 for "
"the column variable Factor B). So, for the ``drug`` factor we obtain *df* = "
"2, and for the ``therapy`` factor we obtain *df* = 1. Later on, when we "
"discuss the interpretation of ANOVA as a regression model (see section :doc:"
"`ANOVA as a linear model <Ch14_ANOVA2_07>`), I’ll give a clearer statement "
"of how we arrive at this number. But for the moment we can use the simple "
"definition of degrees of freedom, namely that the degrees of freedom equals "
"the number of quantities that are observed, minus the number of constraints. "
"So, for the ``drug`` factor, we observe 3 separate group means, but these "
"are constrained by 1 grand mean, and therefore the degrees of freedom is 2. "
"For the residuals, the logic is similar, but not quite the same. The total "
"number of observations in our experiment is 18. The constraints correspond "
"to 1 grand mean, the 2 additional group means that the ``drug`` factor "
"introduces, and the 1 additional group mean that the the ``therapy`` factor "
"introduces, and so our degrees of freedom is 14. As a formula, this is *N* - "
"1 - (*R* - 1) - (*C* - 1), which simplifies to *N* - *R* - *C* + 1."
msgstr ""
"Frihetsgradene beregnes på omtrent samme måte som for enveis ANOVA. For en "
"gitt faktor er frihetsgradene lik antall nivåer minus 1 (dvs. R - 1 for "
"radvariabelen Faktor A, og C - 1 for kolonnevariabelen Faktor B). For "
"faktoren ``drug`` får vi altså *df* = 2, og for faktoren ``therapy`` får vi "
"*df* = 1. Senere, når vi diskuterer tolkningen av ANOVA som en "
"regresjonsmodell (se avsnitt :doc:`ANOVA som en lineær modell "
"<Ch14_ANOVA2_07>`), skal jeg gi en klarere redegjørelse for hvordan vi "
"kommer frem til dette tallet. Men for øyeblikket kan vi bruke den enkle "
"definisjonen av frihetsgrader, nemlig at frihetsgradene er lik antall "
"observerte størrelser minus antall begrensninger. For faktoren ``drug`` "
"observerer vi altså tre separate gruppegjennomsnitt, men disse er begrenset "
"av ett hovedgjennomsnitt, og frihetsgradene er derfor 2. For residuene er "
"logikken lik, men ikke helt den samme. Det totale antallet observasjoner i "
"eksperimentet vårt er 18. Begrensningene tilsvarer 1 total gjennomsnitt, de "
"2 gruppegjennomsnittene som faktoren ``drug`` introduserer, og det 1 "
"gruppegjennomsnittet som faktoren ``therapy`` introduserer, og dermed er "
"frihetsgradene våre 14. Som en formel er dette *N* - 1 - (*R* - 1) - (*C* - "
"1), som forenkles til *N* - *R* - *C* + 1."

#: ../../Ch14/Ch14_ANOVA2_01.rst:549
msgid ""
"Using the degrees of freedom and the square sums we calculated above, we can "
"calculate the following *F*-values for the factors A and B."
msgstr ""
"Ved hjelp av frihetsgradene og kvadratsummene vi beregnet ovenfor, kan vi "
"beregne følgende *F*-verdier for faktorene A og B."

#: ../../Ch14/Ch14_ANOVA2_01.rst:552
msgid ""
"F\\ :sub:`A` = (SS\\ :sub:`A` / SS\\ :sub:`A`) / (SS\\ :sub:`R` / SS\\ :sub:"
"`R`)"
msgstr ""
"F\\ :sub:`A` = (SS\\ :sub:`A` / SS\\ :sub:`A`) / (SS\\ :sub:`R` / SS\\ :sub:"
"`R`)"

#: ../../Ch14/Ch14_ANOVA2_01.rst:553
msgid "F\\ :sub:`A` = (3.453 / 2) / (0.924 / 14)"
msgstr "F\\ :sub:`A` = (3.453 / 2) / (0.924 / 14)"

#: ../../Ch14/Ch14_ANOVA2_01.rst:554
msgid "F\\ :sub:`A` = 1.727 / 0.066"
msgstr "F\\ :sub:`A` = 1.727 / 0.066"

#: ../../Ch14/Ch14_ANOVA2_01.rst:555
msgid "F\\ :sub:`A` = 26.149"
msgstr "F\\ :sub:`A` = 26.149"

#: ../../Ch14/Ch14_ANOVA2_01.rst:557
msgid ""
"F\\ :sub:`B` = (SS\\ :sub:`B` / SS\\ :sub:`B`) / (SS\\ :sub:`R` / SS\\ :sub:"
"`R`)"
msgstr ""
"F\\ :sub:`B` = (SS\\ :sub:`B` / SS\\ :sub:`B`) / (SS\\ :sub:`R` / SS\\ :sub:"
"`R`)"

#: ../../Ch14/Ch14_ANOVA2_01.rst:558
msgid "F\\ :sub:`B` = (0.467 / 1) / (0.924 / 14)"
msgstr "F\\ :sub:`B` = (0.467 / 1) / (0.924 / 14)"

#: ../../Ch14/Ch14_ANOVA2_01.rst:559
msgid "F\\ :sub:`B` = 0.467 / 0.066"
msgstr "F\\ :sub:`B` = 0.467 / 0.066"

#: ../../Ch14/Ch14_ANOVA2_01.rst:560
msgid "F\\ :sub:`B` = 7.076"
msgstr "F\\ :sub:`B` = 7.076"

#: ../../Ch14/Ch14_ANOVA2_01.rst:562
msgid ""
"Again, we can also create two new computed variables, the first with the "
"name ``F_A`` and the formula ``(VSUM(sq_res_A) / 2) / (SS_R / 14)``, and the "
"second with the name ``F_B`` and the formula ``(VSUM(sq_res_B) / 1) / "
"(SS_R / 14)``."
msgstr ""
"Igjen kan vi også opprette to nye beregnede variabler, den første med navnet "
"``F_A`` og formelen ``(VSUM(sq_res_A) / 2) / (SS_R / 14)``, og den andre med "
"navnet ``F_B`` og formelen ``(VSUM(sq_res_B) / 1) / (SS_R / 14)``."

#: ../../Ch14/Ch14_ANOVA2_01.rst:566
msgid ""
"Those, who don't want to have a go themselves or can't reproduce the "
"calculations described in the previous paragraphs can download and open the |"
"clinicaltrial_factorialanova|_ data set and look at the calculations there."
msgstr ""
"De som ikke ønsker å prøve selv eller ikke kan gjengi beregningene som er "
"beskrevet i de foregående avsnittene, kan laste ned og åpne datasettet |"
"clinicaltrial_factorialanova|_ og se på beregningene der."

#: ../../Ch14/Ch14_ANOVA2_01.rst:571
msgid "Factorial ANOVA versus one-way ANOVAs"
msgstr "Faktoriell ANOVA versus enveis ANOVA"

#: ../../Ch14/Ch14_ANOVA2_01.rst:573
msgid ""
"Now that we’ve seen *how* a factorial ANOVA works, it’s worth taking a "
"moment to compare it to the results of the one-way analyses, because this "
"will give us a really good sense of *why* it’s a good idea to run the "
"factorial ANOVA. In chapter :doc:`../Ch13/Ch13_ANOVA`, I ran a one-way ANOVA "
"that looked to see if there are any differences between the three levels of "
"``drug``, and a second one-way ANOVA to see if there were any differences "
"between the two levels of ``therapy``. As we saw in section :ref:`What "
"hypotheses are we testing? <what_hypotheses>`, the null and alternative "
"hypotheses tested by the one-way ANOVAs are in fact identical to the "
"hypotheses tested by the factorial ANOVA. Looking even more carefully at the "
"ANOVA tables, we can see that the sum of squares associated with the factors "
"are identical in the two different analyses (3.453 for ``drug`` and 0.467 "
"for ``therapy``), as are the degrees of freedom (2 for ``drug``, 1 for "
"``therapy``). But they don’t give the same answers! Most notably, when we "
"ran the one-way ANOVA for ``therapy`` in section :doc:`../Ch13/"
"Ch13_ANOVA_09` we didn’t find a significant effect (the *p*-value was "
"0.210). However, when we look at the main effect of ``therapy`` within the "
"context of the two-way ANOVA, we do get a significant effect (p = 0.019). "
"The two analyses are clearly not the same."
msgstr ""
"Nå som vi har sett *hvordan* en faktoriell ANOVA fungerer, er det verdt å "
"bruke et øyeblikk på å sammenligne den med resultatene fra enveisanalysene, "
"fordi dette vil gi oss en veldig god følelse av *hvorfor* det er en god idé "
"å kjøre den faktorielle ANOVAen. I kapittel :doc:`../Ch13/Ch13_ANOVA` kjørte "
"jeg en enveis ANOVA for å se om det var noen forskjeller mellom de tre "
"nivåene av ``drug``, og en annen enveis ANOVA for å se om det var noen "
"forskjeller mellom de to nivåene av ``therapy``. Som vi så i avsnitt :ref:"
"`Hvilke hypoteser tester vi? <what_hypotheses>`, er null- og "
"alternativhypotesene som testes av enveis-ANOVAene, faktisk identiske med "
"hypotesene som testes av den faktorielle ANOVAen. Ser vi enda nøyere på "
"ANOVA-tabellene, ser vi at kvadratsummene knyttet til faktorene er identiske "
"i de to ulike analysene (3,453 for ``drug`` og 0,467 for ``therapy``), og "
"det samme er frihetsgradene (2 for ``drug``, 1 for ``therapy``). Men de gir "
"ikke de samme svarene! Spesielt når vi kjørte enveis ANOVA for ``therapy`` i "
"seksjon :doc:`../Ch13/Ch13_ANOVA_09`, fant vi ingen signifikant effekt (*p*-"
"verdien var 0,210). Når vi ser på hovedeffekten av ``therapy`` i forbindelse "
"med toveis ANOVA, får vi imidlertid en signifikant effekt (p = 0,019). De to "
"analysene er tydeligvis ikke de samme."

#: ../../Ch14/Ch14_ANOVA2_01.rst:592
msgid ""
"Why does that happen? The answer lies in understanding how the *residuals* "
"are calculated. Recall that the whole idea behind an *F*-test is to compare "
"the variability that can be attributed to a particular factor with the "
"variability that cannot be accounted for (the residuals). If you run a one-"
"way ANOVA for ``therapy``, and therefore ignore the effect of ``drug``, the "
"ANOVA will end up dumping all of the drug-induced variability into the "
"residuals! This has the effect of making the data look more noisy than they "
"really are, and the effect of ``therapy`` which is correctly found to be "
"significant in the two-way ANOVA now becomes non-significant. If we ignore "
"something that actually matters (e.g., ``drug``) when trying to assess the "
"contribution of something else (e.g., ``therapy``) then our analysis will be "
"distorted. Of course, it’s perfectly okay to ignore variables that are "
"genuinely irrelevant to the phenomenon of interest. If we had recorded the "
"colour of the walls, and that turned out to be a non-significant factor in a "
"three-way ANOVA, it would be perfectly okay to disregard it and just report "
"the simpler two-way ANOVA that doesn’t include this irrelevant factor. What "
"you shouldn’t do is drop variables that actually make a difference!"
msgstr ""
"Hvorfor skjer det? Svaret ligger i å forstå hvordan *residuene* beregnes. "
"Husk at hele ideen bak en *F*-test er å sammenligne variabiliteten som kan "
"tilskrives en bestemt faktor, med variabiliteten som ikke kan tilskrives "
"denne faktoren (residuene). Hvis du kjører en enveis ANOVA for ``therapy``, "
"og derfor ignorerer effekten av ``drug``, vil ANOVAen ende opp med å "
"forkaste den hele legemiddel-induserte variabiliteten i residuene! Dette får "
"dataene til å se mer støyende ut enn de egentlig er, og effekten av "
"``therapy``, som korrekt er funnet å være signifikant i toveis ANOVA, blir "
"nå ikke-signifikant. Hvis vi ignorerer noe som faktisk betyr noe (f.eks. "
"``drug``) når vi prøver å vurdere bidraget fra noe annet (f.eks. "
"``therapy``), vil analysen vår bli forvrengt. Det er selvfølgelig helt i "
"orden å ignorere variabler som er genuint irrelevante for fenomenet vi er "
"interessert i. Hvis vi hadde registrert fargen på veggene, og det viste seg "
"å være en ikke-signifikant faktor i en treveis ANOVA, ville det være helt i "
"orden å se bort fra den og bare rapportere den enklere toveis ANOVA-en som "
"ikke inkluderer denne irrelevante faktoren. Det du ikke bør gjøre, er å "
"droppe variabler som faktisk utgjør en forskjell!"

#: ../../Ch14/Ch14_ANOVA2_01.rst:612
msgid "Four different outcomes for a 2 × 2 ANOVA"
msgstr "Fire ulike utfall for en 2 × 2 ANOVA"

#: ../../Ch14/Ch14_ANOVA2_01.rst:616
msgid ""
"The four different outcomes for a 2 × 2 ANOVA when no interactions are "
"present. In the top-left panel, we see a main effect of Factor A and no "
"effect of Factor B. The top-right panel shows a main effect of Factor B but "
"no effect of Factor A. The bottom-left panel shows main effects of both "
"Factor A and Factor B. Finally, the bottom-right panel shows if neither "
"factor has an effect."
msgstr ""
"De fire ulike utfallene for en 2 × 2 ANOVA når ingen interaksjoner er til "
"stede. I panelet øverst til venstre ser vi en hovedeffekt av faktor A og "
"ingen effekt av faktor B. Panelet øverst til høyre viser en hovedeffekt av "
"faktor B, men ingen effekt av faktor A. Panelet nederst til venstre viser "
"hovedeffekter av både faktor A og faktor B. Til slutt viser panelet nederst "
"til høyre om ingen av faktorene har en effekt."

#: ../../Ch14/Ch14_ANOVA2_01.rst:626
msgid "What kinds of outcomes does this analysis capture?"
msgstr "Hva slags resultater fanger denne analysen opp?"

#: ../../Ch14/Ch14_ANOVA2_01.rst:628
msgid ""
"The ANOVA model that we’ve been talking about so far covers a range of "
"different patterns that we might observe in our data. For instance, in a two-"
"way ANOVA design there are four possibilities. An example of each of these "
"four possibilities is plotted in :numref:`fig-maineffects`: (1) only Factor "
"A matters (top-left), (2) only Factor B matters (top-right), (3) both A and "
"B matter (bottom-left), and (4) neither A nor B matters (bottom-right)."
msgstr ""
"ANOVA-modellen som vi har snakket om så langt, dekker en rekke ulike mønstre "
"som vi kan observere i dataene våre. I et toveis ANOVA-design finnes det for "
"eksempel fire muligheter. Et eksempel på hver av disse fire mulighetene er "
"plottet i :numref:`fig-maineffects`: (1) bare faktor A betyr noe (øverst til "
"venstre), (2) bare faktor B betyr noe (øverst til høyre), (3) både A og B "
"betyr noe (nederst til venstre), og (4) verken A eller B betyr noe (nederst "
"til høyre)."

#: ../../Ch14/Ch14_ANOVA2_01.rst:638
msgid ""
"The nice thing about the subscript notation is that it generalises nicely. "
"If our experiment had involved a third factor, then we could just add a "
"third subscript. In principle, the notation extends to as many factors as "
"you might care to include, but in this book we’ll rarely consider analyses "
"involving more than two factors, and never more than three."
msgstr ""
"Det fine med subscript-notasjonen er at den generaliserer på en fin måte. "
"Hvis eksperimentet vårt hadde involvert en tredje faktor, kunne vi bare "
"legge til et tredje subscript. I prinsippet kan notasjonen utvides til å "
"omfatte så mange faktorer som du måtte ønske, men i denne boken vil vi "
"sjelden ta for oss analyser som involverer mer enn to faktorer, og aldri mer "
"enn tre."

#: ../../Ch14/Ch14_ANOVA2_01.rst:646
msgid ""
"Technically, marginalising isn’t quite identical to a regular mean. It’s a "
"weighted average where you take into account the frequency of the different "
"events that you’re averaging over. However, in a balanced design, all of our "
"cell frequencies are equal by definition so the two are equivalent. We’ll "
"discuss unbalanced designs later, and when we do so you’ll see that all of "
"our calculations become a real headache. But let’s ignore this for now."
msgstr ""
"Teknisk sett er marginalisering ikke helt identisk med et vanlig "
"gjennomsnitt. Det er et vektet gjennomsnitt der du tar hensyn til frekvensen "
"av de ulike hendelsene du beregner gjennomsnittet over. I et balansert "
"design er imidlertid alle cellefrekvensene våre like per definisjon, så de "
"to er ekvivalente. Vi skal diskutere ubalanserte design senere, og når vi "
"gjør det, vil du se at alle beregningene våre blir en skikkelig hodepine. "
"Men la oss se bort fra dette nå."

#: ../../Ch14/Ch14_ANOVA2_01.rst:655
msgid "To put it bluntly: “least tedious”."
msgstr "Satt på spissen: «minst kjedelig»."

#: ../../Ch14/Ch14_ANOVA2_02.rst:4
msgid "Factorial ANOVA 2: balanced designs, interactions allowed"
msgstr "Faktoriell ANOVA 2: balansert design, interaksjoner tillatt"

#: ../../Ch14/Ch14_ANOVA2_02.rst:8 ../../Ch14/Ch14_ANOVA2_02.rst:12
msgid "Qualitatively different interactions for a 2 × 2 ANOVA"
msgstr "Kvalitativt forskjellige interaksjoner for en 2 × 2 ANOVA"

#: ../../Ch14/Ch14_ANOVA2_02.rst:16
msgid ""
"The four patterns of data shown in :numref:`fig-maineffects` are all quite "
"realistic. There are a great many data sets that produce exactly those "
"patterns. However, they are not the whole story and the ANOVA model that we "
"have been talking about up to this point is not sufficient to fully account "
"for a table of group means. Why not? Well, so far we have the ability to "
"talk about the idea that drugs can influence mood, and therapy can influence "
"mood, but no way of talking about the possibility of an **interaction** "
"between the two. An interaction between A and B is said to occur whenever "
"the effect of Factor A is *different*, depending on which level of Factor B "
"we’re talking about. Several examples of an interaction effect with the "
"context of a 2 × 2 ANOVA are shown in :numref:`fig-interactions`. To give a "
"more concrete example, suppose that the operation of Anxifree and Joyzepam "
"is governed by quite different physiological mechanisms. One consequence of "
"this is that while Joyzepam has more or less the same effect on mood "
"regardless of whether one is in therapy, Anxifree is actually much more "
"effective when administered in conjunction with CBT. The ANOVA that we "
"developed in the previous section does not capture this idea. To get some "
"idea of whether an interaction is actually happening here, it helps to plot "
"the various group means. In jamovi this is done via the ANOVA ``Estimated "
"Marginal Means`` option - just move ``drug`` and ``therapy`` across into the "
"``Marginal Means`` box under ``Term 1``. This should look something like :"
"numref:`fig-interaction`. Our main concern relates to the fact that the two "
"lines aren’t parallel. The effect of ``CBT`` (difference between solid line "
"and dotted line) when the ``drug`` is ``joyzepam`` (right side) appears to "
"be near zero, even smaller than the effect of ``CBT`` when a ``placebo`` is "
"used (left side). However, when ``anxifree`` is administered, the effect of "
"``CBT`` is larger than that of ``no.therapy`` (middle). Is this effect real, "
"or is this just random variation due to chance? Our original ANOVA cannot "
"answer this question, because we make no allowances for the idea that "
"interactions even exist! In this section, we’ll fix this problem."
msgstr ""
"De fire datamønstrene som vises i :numref:`fig-maineffects` er alle ganske "
"realistiske. Det finnes svært mange datasett som gir akkurat disse "
"mønstrene. De er imidlertid ikke hele historien, og ANOVA-modellen som vi "
"har snakket om til nå, er ikke tilstrekkelig til å gjøre fullstendig rede "
"for en tabell med gruppegjennomsnitt. Hvorfor ikke? Vel, så langt har vi "
"muligheten til å snakke om at legemidler kan påvirke humøret, og at terapi "
"kan påvirke humøret, men ingen måte å snakke om muligheten for en "
"**interaksjon** mellom de to. En interaksjon mellom A og B sies å oppstå når "
"effekten av faktor A er *forskjellig*, avhengig av hvilket nivå av faktor B "
"vi snakker om. Flere eksempler på en interaksjonseffekt i forbindelse med en "
"2 × 2 ANOVA er vist i :numref:`fig-interactions`. For å gi et mer konkret "
"eksempel kan vi anta at virkningen av Anxifree og Joyzepam styres av ganske "
"forskjellige fysiologiske mekanismer. En konsekvens av dette er at mens "
"Joyzepam har mer eller mindre samme effekt på humøret uavhengig av om man er "
"i terapi eller ikke, er Anxifree faktisk mye mer effektivt når det gis i "
"forbindelse med KAT. ANOVA-analysen som vi utviklet i forrige avsnitt, "
"fanger ikke opp denne ideen. For å få en idé om hvorvidt det faktisk skjer "
"en interaksjon her, er det nyttig å plotte de ulike gruppegjennomsnittene. I "
"jamovi gjøres dette via ANOVA-alternativet ``Estimated Marginal Means`` - "
"bare flytt ``drug`` og ``therapy`` over i ``Marginal Means``-boksen under "
"``Term 1``. Dette bør se ut omtrent som :numref:`fig-interaction`. Vår "
"største bekymring er knyttet til det faktum at de to linjene ikke er "
"parallelle. Effekten av ``CBT`` (forskjellen mellom heltrukken linje og "
"stiplet linje) når legemiddelet (``drug``) er ``joyzepam`` (høyre side) ser "
"ut til å være nær null, til og med mindre enn effekten av ``CBT`` når "
"``placebo`` brukes (venstre side). Når ``anxifree`` administreres, er "
"imidlertid effekten av ``CBT`` større enn effekten av ``no.therapy`` "
"(midten). Er denne effekten reell, eller er dette bare tilfeldig variasjon "
"som skyldes tilfeldigheter? Vår opprinnelige ANOVA kan ikke svare på dette "
"spørsmålet, fordi vi ikke tar høyde for at det i det hele tatt eksisterer "
"interaksjoner! I dette avsnittet skal vi løse dette problemet."

#: ../../Ch14/Ch14_ANOVA2_02.rst:48
msgid "Descriptive interaction plot in jamovi"
msgstr "(Deskriptivstatistisk) Interaksjonsplott i jamovi"

#: ../../Ch14/Ch14_ANOVA2_02.rst:52
msgid ""
"jamovi screen shot showing how to generate a descriptive interaction plot "
"within the ANOVA (using ``Estimated Marginal Means``) for the |clinicaltrial|"
"_ data set"
msgstr ""
"jamovi-skjermbilde som viser hvordan du genererer et interaksjonsplott i "
"ANOVA (ved hjelp av ``Estimated Marginal Means``) for datasettet |"
"clinicaltrial|_"

#: ../../Ch14/Ch14_ANOVA2_02.rst:59
msgid "What exactly is an interaction effect?"
msgstr "Hva er egentlig en interaksjonseffekt?"

#: ../../Ch14/Ch14_ANOVA2_02.rst:61
msgid ""
"The key idea that we’re going to introduce in this section is that of an "
"interaction effect. In the ANOVA model we have looked at so far there are "
"only two *factors* involved in our model (i.e., ``drug`` and ``therapy``). "
"But when we add an interaction we add a new component to the model: the "
"combination of ``drug`` and ``therapy``. Intuitively, the idea behind an "
"interaction effect is fairly simple. It just means that the effect of Factor "
"A is different, depending on which level of Factor B we’re talking about. "
"But what does that actually mean in terms of our data? The plot in :numref:"
"`fig-interactions` depicts several different patterns that, although quite "
"different to each other, would all count as an interaction effect. So it’s "
"not entirely straightforward to translate this qualitative idea into "
"something mathematical that a statistician can work with."
msgstr ""
"Nøkkelbegrepet som vi skal introdusere i dette avsnittet, er "
"interaksjonseffekten. I ANOVA-modellen vi har sett på så langt, er det bare "
"to *faktorer* involvert i modellen vår (dvs. ``drug`` og ``therapy``). Men "
"når vi legger til en interaksjon, legger vi til en ny komponent i modellen: "
"kombinasjonen av ``drug`` og ``therapy``. Intuitivt er ideen bak en "
"interaksjonseffekt ganske enkel. Det betyr bare at effekten av faktor A er "
"forskjellig, avhengig av hvilket nivå av faktor B vi snakker om. Men hva "
"betyr det egentlig for dataene våre? Plottet i :numref:`fig-interactions` "
"viser flere forskjellige mønstre som, selv om de er ganske forskjellige fra "
"hverandre, alle vil telle som en interaksjonseffekt. Så det er ikke helt "
"enkelt å oversette denne kvalitative ideen til noe matematisk som en "
"statistiker kan jobbe med."

#: ../../Ch14/Ch14_ANOVA2_02.rst:74
msgid ""
"As a consequence, the way that the idea of an interaction effect is "
"formalised in terms of null and alternative hypotheses is slightly "
"difficult, and I’m guessing that a lot of readers of this book probably "
"won’t be all that interested. Even so, I’ll try to give the basic idea here."
msgstr ""
"Derfor er det litt vanskelig å formalisere ideen om en interaksjonseffekt i "
"form av nullhypoteser og alternative hypoteser, og jeg antar at mange av "
"leserne av denne boken sannsynligvis ikke vil være så interessert i dette. "
"Jeg skal likevel forsøke å gi en grunnleggende innføring her."

#: ../../Ch14/Ch14_ANOVA2_02.rst:80
msgid ""
"To start with, we need to be a little more explicit about our main effects. "
"Consider the main effect of Factor A (``drug`` in our running example). We "
"originally formulated this in terms of the null hypothesis that the two "
"marginal means µ\\ :sub:`r.` are all equal to each other. Obviously, if all "
"of these are equal to each other, then they must also be equal to the grand "
"mean µ\\ :sub:`..` as well, right? So what we can do is define the *effect* "
"of Factor A at level *r* to be equal to the difference between the marginal "
"mean µ\\ :sub:`r.` and the grand mean µ\\ :sub:`..`. Let’s denote this "
"effect by α\\ :sub:`r`, and note that"
msgstr ""
"Til å begynne med må vi være litt mer eksplisitte når det gjelder "
"hovedeffektene våre. La oss se på hovedeffekten av faktor A (``drug`` i vårt "
"løpende eksempel). Opprinnelig formulerte vi dette i form av nullhypotesen "
"om at de to marginale gjennomsnittene µ\\ :sub:`r.` alle er lik hverandre. "
"Det er klart at hvis alle disse er like hverandre, så må de også være like "
"det totale gjennomsnittet µ\\ :sub:`..`, ikke sant? Vi kan altså definere "
"*effekten* av faktor A på nivå *r* som lik differansen mellom det marginale "
"gjennomsnittet µ\\ :sub:`r.` og det totale gjennomsnittet µ\\ :sub:`..`. La "
"oss betegne denne effekten med α\\ :sub:`r`, og merke oss at"

#: ../../Ch14/Ch14_ANOVA2_02.rst:91
msgid "α\\ :sub:`r`  = µ\\ :sub:`r.` - µ\\ :sub:`..`"
msgstr "α\\ :sub:`r`  = µ\\ :sub:`r.` - µ\\ :sub:`..`"

#: ../../Ch14/Ch14_ANOVA2_02.rst:93
msgid ""
"Now, by definition all of the α\\ :sub:`r` values must sum to zero, for the "
"same reason that the average of the marginal means µ\\ :sub:`r.` must be the "
"grand mean µ\\ :sub:`..`. We can similarly define the effect of Factor B at "
"level i to be the difference between the column marginal mean µ\\ :sub:`.c` "
"and the grand mean µ\\ :sub:`..`"
msgstr ""
"Nå må per definisjon alle α\\ :sub:`r`-verdiene summere seg til null, av "
"samme grunn som at gjennomsnittet av de marginale gjennomsnittene µ\\ :sub:"
"`r.` må være det totale gjennomsnittet µ\\ :sub:`..`. På samme måte kan vi "
"definere effekten av faktor B på nivå i som differansen mellom kolonnens "
"marginalgjennomsnitt µ\\ :sub:`.c` og totalgjennomsnittet µ\\ :sub:`..`"

#: ../../Ch14/Ch14_ANOVA2_02.rst:100
msgid "β\\ :sub:`c` = µ\\ :sub:`..` - µ\\ :sub:`..`"
msgstr "β\\ :sub:`c` = µ\\ :sub:`..` - µ\\ :sub:`..`"

#: ../../Ch14/Ch14_ANOVA2_02.rst:102
msgid ""
"and once again, these β\\ :sub:`c` values must sum to zero. The reason that "
"statisticians sometimes like to talk about the main effects in terms of "
"these α\\ :sub:`r` and β\\ :sub:`c` values is that it allows them to be "
"precise about what it means to say that there is no interaction effect. If "
"there is no interaction at all, then these α\\ :sub:`r` and β\\ :sub:`c` "
"values will perfectly describe the group means µ\\ :sub:`rc`. Specifically, "
"it means that"
msgstr ""
"og igjen må disse β\\ :sub:`c`-verdiene summere seg til null. Grunnen til at "
"statistikere noen ganger liker å snakke om hovedeffektene i form av disse "
"α\\ :sub:`r`- og β\\ :sub:`c`-verdiene, er at det gjør det mulig for dem å "
"være presise når det gjelder hva det betyr å si at det ikke finnes noen "
"interaksjonseffekt. Hvis det ikke er noen interaksjon i det hele tatt, vil "
"disse α\\ :sub:`r`- og β\\ :sub:`c`-verdiene beskrive gruppemidlene µ\\ :sub:"
"`rc` perfekt. Konkret betyr det at"

#: ../../Ch14/Ch14_ANOVA2_02.rst:110
msgid "µ\\ :sub:`rc` = µ\\ :sub:`..` + α\\ :sub:`r` + β\\ :sub:`c`"
msgstr "µ\\ :sub:`rc` = µ\\ :sub:`..` + α\\ :sub:`r` + β\\ :sub:`c`"

#: ../../Ch14/Ch14_ANOVA2_02.rst:112
msgid ""
"That is, there’s nothing *special* about the group means that you couldn’t "
"predict perfectly by knowing all the marginal means. And that’s our null "
"hypothesis, right there. The alternative hypothesis is that"
msgstr ""
"Det vil si at det ikke er noe *spesielt* ved gruppegjennomsnittet som du "
"ikke kan forutsi perfekt ved å kjenne til alle marginalgjennomsnittene. Og "
"det er nullhypotesen vår. Den alternative hypotesen er at"

#: ../../Ch14/Ch14_ANOVA2_02.rst:116
msgid "µ\\ :sub:`rc` ≠ µ\\ :sub:`..` + α\\ :sub:`r` + β\\ :sub:`c`"
msgstr "µ\\ :sub:`rc` ≠ µ\\ :sub:`..` + α\\ :sub:`r` + β\\ :sub:`c`"

#: ../../Ch14/Ch14_ANOVA2_02.rst:118
msgid ""
"for at least one group rc in our table. However, statisticians often like to "
"write this slightly differently. They’ll usually define the specific "
"interaction associated with group rc to be some number, awkwardly referred "
"to as αβ\\ :sub:`rc`, and then they will say that the alternative hypothesis "
"is that"
msgstr ""
"for minst én gruppe rc i tabellen vår. Statistikere liker imidlertid ofte å "
"skrive dette på en litt annen måte. De definerer vanligvis den spesifikke "
"interaksjonen knyttet til gruppe rc til å være et tall, gjerne kalt αβ\\ :"
"sub:`rc`, og så sier de at den alternative hypotesen er at"

#: ../../Ch14/Ch14_ANOVA2_02.rst:124
msgid ""
"µ\\ :sub:`rc` = µ\\ :sub:`..` + α\\ :sub:`r` + β\\ :sub:`c` + αβ\\ :sub:`rc`"
msgstr ""
"µ\\ :sub:`rc` = µ\\ :sub:`..` + α\\ :sub:`r` + β\\ :sub:`c` + αβ\\ :sub:`rc`"

#: ../../Ch14/Ch14_ANOVA2_02.rst:126
msgid ""
"where αβ\\ :sub:`rc` is non-zero for at least one group. This notation is "
"kind of ugly to look at, but it is handy as we’ll see in the next section "
"when discussing how to calculate the sum of squares."
msgstr ""
"hvor αβ\\ :sub:`rc` er forskjellig fra null for minst én gruppe. Denne "
"notasjonen er litt stygg å se på, men den er nyttig, som vi skal se i neste "
"avsnitt når vi diskuterer hvordan man beregner kvadratsummen."

#: ../../Ch14/Ch14_ANOVA2_02.rst:131
msgid "Calculating sums of squares for the interaction"
msgstr "Beregning av kvadratsummer for interaksjonen"

#: ../../Ch14/Ch14_ANOVA2_02.rst:133
msgid ""
"How should we calculate the sum of squares for the interaction terms, SS\\ :"
"sub:`A:B`? Well, first off, it helps to notice how the previous section "
"defined the interaction effect in terms of the extent to which the actual "
"group means differ from what you’d expect by just looking at the marginal "
"means. Of course, all of those formulas refer to population parameters "
"rather than sample statistics, so we don’t actually know what they are. "
"However, we can estimate them by using sample means in place of population "
"means. So for Factor A, a good way to estimate the main effect at level *r* "
"is as the difference between the *sample* marginal mean Ȳ\\ :sub:`rc` and "
"the sample grand mean Ȳ\\ :sub:`..`\\. That is, we would use this as our "
"estimate of the effect"
msgstr ""
"Hvordan skal vi beregne kvadratsummen for interaksjonstermene, SS\\ :sub:`A:"
"B`? For det første er det nyttig å legge merke til hvordan forrige avsnitt "
"definerte interaksjonseffekten i form av i hvilken grad de faktiske "
"gruppegjennomsnittene avviker fra det du ville forvente ved bare å se på de "
"marginale gjennomsnittene. Alle disse formlene refererer selvfølgelig til "
"populasjonsparametere i stedet for utvalgsstatistikk, så vi vet faktisk ikke "
"hva de er. Vi kan imidlertid estimere dem ved å bruke utvalgsgjennomsnitt i "
"stedet for populasjonsgjennomsnitt. For faktor A er en god måte å estimere "
"hovedeffekten på nivå *r* på, forskjellen mellom *utvalgets* marginale "
"gjennomsnitt Ȳ\\ :sub:`rc` og utvalgets totale gjennomsnitt Ȳ\\ :sub:`..`\\. "
"Det vil si at vi bruker dette som vårt estimat av effekten"

#: ../../Ch14/Ch14_ANOVA2_02.rst:144
msgid ""
"\\hat{\\alpha}_r = \\bar{Y}_{r.} - \\bar{Y}_{..}\n"
"\n"
msgstr ""
"\\hat{\\alpha}_r = \\bar{Y}_{r.} - \\bar{Y}_{..}\n"
"\n"

#: ../../Ch14/Ch14_ANOVA2_02.rst:146
msgid ""
"Similarly, our estimate of the main effect of Factor B at level *c* can be "
"defined as follows"
msgstr ""
"På samme måte kan vårt estimat av hovedeffekten av faktor B på nivå *c* "
"defineres som følger"

#: ../../Ch14/Ch14_ANOVA2_02.rst:149
msgid ""
"\\hat{\\beta}_c = \\bar{Y}_{.c} - \\bar{Y}_{..}\n"
"\n"
msgstr ""
"\\hat{\\beta}_c = \\bar{Y}_{.c} - \\bar{Y}_{..}\n"
"\n"

#: ../../Ch14/Ch14_ANOVA2_02.rst:151
msgid ""
"Now, if you go back to the formulas that I used to describe the SS values "
"for the two main effects, you’ll notice that these effect terms are exactly "
"the quantities that we were squaring and summing! So, what’s the analog of "
"this for interaction terms? The answer to this can be found by first "
"rearranging the formula for the group means µ\\ :sub:`rc` under the "
"alternative hypothesis, so that we get this"
msgstr ""
"Hvis du nå går tilbake til formlene jeg brukte for å beskrive kvadratsummen "
"(SS) for de to hovedeffektene, vil du legge merke til at disse effekttermene "
"er nøyaktig de størrelsene som vi kvadrerte og summerte! Hva er så det "
"analoge til dette for interaksjonstermene? Svaret på dette finner vi ved "
"først å omorganisere formelen for gruppegjennomsnittene µ\\ :sub:`rc` under "
"alternativhypotesen, slik at vi får dette"

#: ../../Ch14/Ch14_ANOVA2_02.rst:158
msgid ""
"αβ\\ :sub:`rc` = µ\\ :sub:`rc` - µ\\ :sub:`..` - α\\ :sub:`r` - β\\ :sub:`c` "
"\\\\"
msgstr ""
"αβ\\ :sub:`rc` = µ\\ :sub:`rc` - µ\\ :sub:`..` - α\\ :sub:`r` - β\\ :sub:`c` "
"\\\\"

#: ../../Ch14/Ch14_ANOVA2_02.rst:159
msgid ""
"αβ\\ :sub:`rc` = µ\\ :sub:`rc` - µ\\ :sub:`..` - (µ\\ :sub:`r.` - µ\\ :sub:"
"`..`) - (µ\\ :sub:`.c` - µ\\ :sub:`..`) \\\\"
msgstr ""
"αβ\\ :sub:`rc` = µ\\ :sub:`rc` - µ\\ :sub:`..` - (µ\\ :sub:`r.` - µ\\ :sub:"
"`..`) - (µ\\ :sub:`.c` - µ\\ :sub:`..`) \\\\"

#: ../../Ch14/Ch14_ANOVA2_02.rst:160
msgid ""
"αβ\\ :sub:`rc` = µ\\ :sub:`rc` - µ\\ :sub:`r.` - µ\\ :sub:`.c` + µ\\ :sub:`.."
"`"
msgstr ""
"αβ\\ :sub:`rc` = µ\\ :sub:`rc` - µ\\ :sub:`r.` - µ\\ :sub:`.c` + µ\\ :sub:`.."
"`"

#: ../../Ch14/Ch14_ANOVA2_02.rst:162
msgid ""
"So, once again if we substitute our sample statistics in place of the "
"population means, we get the following as our estimate of the interaction "
"effect for group rc, which is"
msgstr ""
"Hvis vi igjen erstatter populasjonsgjennomsnittet med utvalgsstatistikken "
"vår, får vi følgende estimat av interaksjonseffekten for gruppe rc, som er"

#: ../../Ch14/Ch14_ANOVA2_02.rst:166
msgid ""
"\\hat{(\\alpha\\beta)}_{rc} = \\bar{Y}_{rc} - \\bar{Y}_{r.} - \\bar{Y}_{.c} "
"+ \\bar{Y}_{..}\n"
"\n"
msgstr ""
"\\hat{(\\alpha\\beta)}_{rc} = \\bar{Y}_{rc} - \\bar{Y}_{r.} - \\bar{Y}_{.c} "
"+ \\bar{Y}_{..}\n"
"\n"

#: ../../Ch14/Ch14_ANOVA2_02.rst:168
msgid ""
"Now all we have to do is sum all of these estimates across all *R* levels of "
"Factor A and all *C* levels of Factor B, and we obtain the following formula "
"for the sum of squares associated with the interaction as a whole"
msgstr ""
"Nå trenger vi bare å summere alle disse estimatene på tvers av alle *R*-"
"nivåer av faktor A og alle *C*-nivåer av faktor B, og vi får følgende formel "
"for summen av kvadrater knyttet til interaksjonen som helhet"

#: ../../Ch14/Ch14_ANOVA2_02.rst:173
msgid ""
"\\mbox{SS}_{A:B} = N \\sum_{r=1}^R \\sum_{c=1}^C \\left( \\bar{Y}_{rc} - "
"\\bar{Y}_{r.} - \\bar{Y}_{.c} + \\bar{Y}_{..} \\right)^2\n"
"\n"
msgstr ""
"\\mbox{SS}_{A:B} = N \\sum_{r=1}^R \\sum_{c=1}^C \\left( \\bar{Y}_{rc} - "
"\\bar{Y}_{r.} - \\bar{Y}_{.c} + \\bar{Y}_{..} \\right)^2\n"
"\n"

#: ../../Ch14/Ch14_ANOVA2_02.rst:175
msgid ""
"where we multiply by *N* because there are *N* observations in each of the "
"groups, and we want our SS values to reflect the variation among "
"*observations* accounted for by the interaction, not the variation among "
"groups."
msgstr ""
"der vi multipliserer med *N* fordi det er *N* observasjoner i hver av "
"gruppene, og vi ønsker at kvadratummene (SS) våre skal gjenspeile "
"variasjonen blant *observasjonene* som interaksjonen står for, ikke "
"variasjonen mellom gruppene."

#: ../../Ch14/Ch14_ANOVA2_02.rst:179
msgid ""
"Now that we have a formula for calculating SS\\ :sub:`A:B`, it’s important "
"to recognise that the interaction term is part of the model (of course), so "
"the total sum of squares associated with the model, SS\\ :sub:`M`, is now "
"equal to the sum of the three relevant SS values, SS\\ :sub:`A` + SS\\ :sub:"
"`B` + SS\\ :sub:`A:B`. The residual sum of squares SS\\ :sub:`R` is still "
"defined as the leftover variation, namely SS\\ :sub:`T` - SS\\ :sub:`M`, but "
"now that we have the interaction term this becomes"
msgstr ""
"Nå som vi har en formel for å beregne SS\\ :sub:`A:B`, er det viktig å være "
"klar over at interaksjonstermen (selvfølgelig) er en del av modellen, slik "
"at den totale kvadratsummen knyttet til modellen, SS\\ :sub:`M`, nå er lik "
"summen av de tre relevante kvadratummene, SS\\ :sub:`A` + SS\\ :sub:`B` + "
"SS\\ :sub:`A:B`. Den kvadratsummen for residuene SS\\ :sub:`R` er fortsatt "
"definert som den resterende variasjonen, nemlig SS\\ :sub:`T` - SS\\ :sub:"
"`M`, men nå som vi har interaksjonstermen, blir dette"

#: ../../Ch14/Ch14_ANOVA2_02.rst:187
msgid ""
"SS\\ :sub:`R` = SS\\ :sub:`T` - (SS\\ :sub:`A` + SS\\ :sub:`B` + SS\\ :sub:"
"`A:B`\\)"
msgstr ""
"SS\\ :sub:`R` = SS\\ :sub:`T` - (SS\\ :sub:`A` + SS\\ :sub:`B` + SS\\ :sub:"
"`A:B`\\)"

#: ../../Ch14/Ch14_ANOVA2_02.rst:189
msgid ""
"As a consequence, the residual sum of squares SS\\ :sub:`R` will be smaller "
"than in our original ANOVA that didn’t include interactions."
msgstr ""
"Som en konsekvens vil kvadratsummen til residuene SS\\ :sub:`R` være mindre "
"enn i vår opprinnelige ANOVA som ikke inkluderte interaksjoner."

#: ../../Ch14/Ch14_ANOVA2_02.rst:193
msgid "Degrees of freedom for the interaction"
msgstr "Frihetsgrader for interaksjonen"

#: ../../Ch14/Ch14_ANOVA2_02.rst:195
msgid ""
"Calculating the degrees of freedom for the interaction is, once again, "
"slightly trickier than the corresponding calculation for the main effects. "
"To start with, let’s think about the ANOVA model as a whole. Once we include "
"interaction effects in the model we’re allowing every single group to have a "
"unique mean, µ\\ :sub:`rc`. For an R × C factorial ANOVA, this means that "
"there are R × C quantities of interest in the model and only the one "
"constraint: all of the group means need to average out to the grand mean. So "
"the model as a whole needs to have (R × C) - 1 degrees of freedom. But the "
"main effect of Factor A has R - 1 degrees of freedom, and the main effect of "
"Factor B has C - 1 degrees of freedom. This means that the degrees of "
"freedom associated with the interaction is"
msgstr ""
"Beregningen av frihetsgradene for interaksjonen er, nok en gang, litt "
"vanskeligere enn den tilsvarende beregningen for hovedeffektene. La oss "
"begynne med å tenke på ANOVA-modellen som helhet. Når vi inkluderer "
"interaksjonseffekter i modellen, tillater vi at hver enkelt gruppe har et "
"unikt gjennomsnitt, µ\\ :sub:`rc`. For en R × C-faktoriell ANOVA betyr dette "
"at det er R × C størrelser av interesse i modellen, og at det bare er én "
"begrensning: alle gruppegjennomsnittene må ha et gjennomsnitt som tilsvarer "
"det totale gjennomsnittet. Modellen som helhet må altså ha (R × C) - 1 "
"frihetsgrader. Men hovedeffekten av faktor A har R - 1 frihetsgrader, og "
"hovedeffekten av faktor B har C - 1 frihetsgrader. Dette betyr at "
"frihetsgradene knyttet til interaksjonen er"

#: ../../Ch14/Ch14_ANOVA2_02.rst:209
msgid "*df*\\ :sub:`A:B` = (R × C - 1) - (R - 1) - (C -1)"
msgstr "*df*\\ :sub:`A:B` = (R × C - 1) - (R - 1) - (C -1)"

#: ../../Ch14/Ch14_ANOVA2_02.rst:210
msgid "*df*\\ :sub:`A:B` = RC - R - C + 1"
msgstr "*df*\\ :sub:`A:B` = RC - R - C + 1"

#: ../../Ch14/Ch14_ANOVA2_02.rst:211
msgid "*df*\\ :sub:`A:B` = (R-1)(C-1)"
msgstr "*df*\\ :sub:`A:B` = (R-1)(C-1)"

#: ../../Ch14/Ch14_ANOVA2_02.rst:213
msgid ""
"which is just the product of the degrees of freedom associated with the row "
"factor and the column factor."
msgstr ""
"som bare er produktet av frihetsgradene knyttet til radfaktoren og "
"kolonnefaktoren."

#: ../../Ch14/Ch14_ANOVA2_02.rst:216
msgid ""
"What about the residual degrees of freedom? Because we’ve added interaction "
"terms which absorb some degrees of freedom, there are fewer residual degrees "
"of freedom left over. Specifically, note that if the model with interaction "
"has a total of (R × C) - 1, and there are *N* observations in your data set "
"that are constrained to satisfy 1 grand mean, your residual degrees of "
"freedom now become *N* -(R × C) - 1 + 1, or just *N* - (R × C)."
msgstr ""
"Hva med de resterende frihetsgradene? Fordi vi har lagt til interaksjonsterm "
"som absorberer noen frihetsgrader, blir det færre gjenværende frihetsgrader "
"igjen. Merk at hvis modellen med interaksjon har totalt (R × C) - 1, og det "
"er *N* observasjoner i datasettet ditt som er begrenset til å tilfredsstille "
"1 grand mean, blir de gjenværende frihetsgradene nå *N* -(R × C) - 1 + 1, "
"eller bare *N* - (R × C)."

#: ../../Ch14/Ch14_ANOVA2_02.rst:225
msgid "Running the ANOVA in jamovi"
msgstr "Kjører ANOVA i jamovi"

#: ../../Ch14/Ch14_ANOVA2_02.rst:227
msgid ""
"Adding interaction terms to the ANOVA model in jamovi is straightforward. In "
"fact it is more than straightforward because it is the default option for "
"ANOVA. This means that when you specify an ANOVA with two factors, e.g. "
"``drug`` and ``therapy`` then the interaction component - ``drug`` × "
"``therapy`` (shown as ``drug * therapy``) - is added automatically to the "
"model.\\ [#]_ When we run the ANOVA with the interaction term included, then "
"we get the results shown in :numref:`fig-factorialanova4`."
msgstr ""
"Det er enkelt å legge til interaksjonsterm i ANOVA-modellen i jamovi. "
"Faktisk er det mer enn enkelt, fordi det er standardalternativet for ANOVA. "
"Det betyr at når du spesifiserer en ANOVA med to faktorer, f.eks. ``drug`` "
"og ``therapy``, blir interaksjonskomponenten - ``drug`` × ``therapy`` (vist "
"som ``drug * therapy``) - automatisk lagt til i modellen.\\ [#]_ Når vi "
"kjører ANOVA-en med interaksjonstermen inkludert, får vi resultatene vist i :"
"numref:`fig-factorialanova4`."

#: ../../Ch14/Ch14_ANOVA2_02.rst:238
msgid "Results for the full factorial model"
msgstr "Resultater for den fullstendige faktorielle modellen"

#: ../../Ch14/Ch14_ANOVA2_02.rst:242
msgid ""
"Results for the full factorial model, including the interaction component "
"``drug`` × ``therapy``"
msgstr ""
"Resultater for den fullstendige faktorielle modellen, inkludert "
"interaksjonskomponenten ``drug`` × ``therapy``"

#: ../../Ch14/Ch14_ANOVA2_02.rst:247
msgid ""
"As it turns out, while we do have a significant main effect of ``drug``: "
"*F*\\(2,12) = 31.7, *p* < 0.001, and ``therapy``: *F*\\(1,12) = 8.6, *p* = "
"\\0.013), there is no significant interaction between the two: *F*\\(2,12) = "
"2.5, *p* = 0.125)."
msgstr ""
"Det viser seg at selv om vi har en signifikant hovedeffekt av ``drug``: "
"*F*\\(2,12) = 31,7, *p* < 0,001, og ``therapy``: *F*\\(1,12) = 8,6, *p* = "
"\\0,013), men det er ingen signifikant interaksjon mellom de to: *F*\\(2,12) "
"= 2,5, *p* = 0,125)."

#: ../../Ch14/Ch14_ANOVA2_02.rst:253
msgid "Interpreting the results"
msgstr "Tolkning av resultatene"

#: ../../Ch14/Ch14_ANOVA2_02.rst:255
msgid ""
"There’s a couple of very important things to consider when interpreting the "
"results of factorial ANOVA. First, there’s the same issue that we had with "
"one-way ANOVA, which is that if you obtain a significant main effect of "
"(say) ``drug``, it doesn’t tell you anything about how the levels of "
"``drug`` are different to one another. To find that out, you need to run "
"additional analyses. We’ll talk about some analyses that you can run in "
"sections :doc:`Ch14_ANOVA2_08` and :doc:`Ch14_ANOVA2_09`. The same is true "
"for interaction effects. Knowing that there’s a significant interaction "
"doesn’t tell you anything about what kind of interaction exists. Again, "
"you’ll need to run additional analyses."
msgstr ""
"Det er et par svært viktige ting å ta hensyn til når du tolker resultatene "
"av en faktoriell ANOVA. For det første har vi det samme problemet som vi "
"hadde med enveis ANOVA, nemlig at hvis du får en signifikant hovedeffekt av "
"(la oss si) ``drug``, forteller det deg ingenting om hvordan nivåene av "
"``drug`` er forskjellige fra hverandre. For å finne ut av det, må du kjøre "
"flere analyser. Vi skal snakke om noen analyser du kan kjøre i avsnittene :"
"doc:`Ch14_ANOVA2_08` og :doc:`Ch14_ANOVA2_09`. Det samme gjelder for "
"interaksjonseffekter. Å vite at det finnes en signifikant interaksjon, "
"forteller deg ikke noe om hva slags interaksjon som eksisterer. Igjen må du "
"kjøre flere analyser."

#: ../../Ch14/Ch14_ANOVA2_02.rst:266
msgid ""
"Secondly, there’s a very peculiar interpretation issue that arises when you "
"obtain a significant interaction effect but no corresponding main effect. "
"This happens sometimes. For instance, in the crossover interaction shown in :"
"numref:`fig-interactions` (top-left panel), this is exactly what you’d find. "
"In this case, neither of the main effects would be significant, but the "
"interaction effect would be. This is a difficult situation to interpret, and "
"people often get a bit confused about it. The general advice that "
"statisticians like to give in this situation is that you shouldn’t pay much "
"attention to the main effects when an interaction is present. The reason "
"they say this is that, although the tests of the main effects are perfectly "
"valid from a mathematical point of view, when there is a significant "
"interaction effect the main effects rarely test interesting hypotheses. "
"Recall from section :ref:`What hypotheses are we testing? <what_hypotheses>` "
"that the null hypothesis for a main effect is that the *marginal means* are "
"equal to each other, and that a marginal mean is formed by averaging across "
"several different groups. But if you have a significant interaction effect "
"then you *know* that the groups that comprise the marginal mean aren’t "
"homogeneous, so it’s not really obvious why you would even care about those "
"marginal means."
msgstr ""
"For det andre er det et veldig spesielt tolkningsproblem som oppstår når du "
"får en signifikant interaksjonseffekt, men ingen tilsvarende hovedeffekt. "
"Dette skjer noen ganger. For eksempel, i crossover-interaksjonen som vises "
"i :numref:`fig-interactions` (panelet øverst til venstre), er det akkurat "
"dette du vil finne. I dette tilfellet ville ingen av hovedeffektene være "
"signifikante, men interaksjonseffekten ville være det. Dette er en vanskelig "
"situasjon å tolke, og folk blir ofte litt forvirret. Det generelle rådet som "
"statistikere liker å gi i denne situasjonen, er at du ikke bør legge så mye "
"vekt på hovedeffektene når det er en interaksjon til stede. Grunnen til at "
"de sier dette, er at selv om testene av hovedeffektene er helt gyldige fra "
"et matematisk synspunkt, er det sjelden at hovedeffektene tester "
"interessante hypoteser når det er en signifikant interaksjonseffekt. Husk "
"fra avsnitt :ref:`Hvilke hypoteser tester vi? <what_hypotheses>` at "
"nullhypotesen for en hovedeffekt er at *marginalgjennomsnittene* er like "
"hverandre, og at et marginalgjennomsnitt dannes ved å ta gjennomsnittet over "
"flere ulike grupper. Men hvis du har en signifikant interaksjonseffekt, "
"*vet* du at gruppene som utgjør det marginale gjennomsnittet ikke er "
"homogene, så det er egentlig ikke åpenbart hvorfor du i det hele tatt skulle "
"bry deg om de marginale gjennomsnittene."

#: ../../Ch14/Ch14_ANOVA2_02.rst:285
msgid ""
"Here’s what I mean. Again, let’s stick with a clinical example. Suppose that "
"we had a 2 × 2 design comparing two different treatments for phobias (e.g., "
"systematic desensitisation vs. flooding), and two different anxiety reducing "
"drugs (e.g., Anxifree vs Joyzepam). Now, suppose what we found was that "
"Anxifree had no effect when desensitisation was the treatment, and Joyzepam "
"had no effect when flooding was the treatment. But both were pretty "
"effective for the other treatment. This is a classic crossover interaction, "
"and what we’d find when running the ANOVA is that there is no main effect of "
"``drug``, but a significant interaction. Now, what does it actually *mean* "
"to say that there’s no main effect? Well, it means that if we average over "
"the two different psychological treatments, then the *average* effect of "
"Anxifree and Joyzepam is the same. But why would anyone care about that? "
"When treating someone for phobias it is never the case that a person can be "
"treated using an “average” of flooding and desensitisation. That doesn’t "
"make a lot of sense. You either get one or the other. For one treatment one "
"drug is effective, and for the other treatment the other drug is effective. "
"The interaction is the important thing and the main effect is kind of "
"irrelevant."
msgstr ""
"Her er hva jeg mener. La oss igjen holde oss til et klinisk eksempel. Anta "
"at vi hadde et 2 × 2-design som sammenlignet to ulike terapier for fobier (f."
"eks. systematisk desensitivisering vs. flooding), og to ulike angstdempende "
"legemidler (f.eks. Anxifree vs. Joyzepam). Anta nå at vi fant at Anxifree "
"ikke hadde noen effekt når desensitivisering var terapien, og at Joyzepam "
"ikke hadde noen effekt når flooding var terapien. Men begge var ganske "
"effektive for den andre terapien. Dette er en klassisk crossover-"
"interaksjon, og det vi vil finne når vi kjører ANOVA, er at det ikke er noen "
"hovedeffekt av ``drug``, men en signifikant interaksjon. Hva *betyr* det "
"egentlig å si at det ikke er noen hovedeffekt? Vel, det betyr at hvis vi tar "
"gjennomsnittet av de to ulike psykologiske terapiene, så er den "
"*gjennomsnittlige* effekten av Anxifree og Joyzepam den samme. Men hvorfor "
"skulle noen bry seg om det? Når man behandler noen for fobier, er det aldri "
"slik at en person kan behandles ved hjelp av et «gjennomsnitt» av flooding "
"og desensitivisering. Det gir ikke mye mening. Man får enten det ene eller "
"det andre. For den ene terapien er det ene legemiddelet effektivt, og for "
"den andre terapien er det andre legemiddelet effektivt. Interaksjonen er det "
"viktige, og hovedeffekten er på en måte irrelevant."

#: ../../Ch14/Ch14_ANOVA2_02.rst:303
msgid ""
"This sort of thing happens a lot. The main effect are tests of marginal "
"means, and when an interaction is present we often find ourselves not being "
"terribly interested in marginal means because they imply averaging over "
"things that the interaction tells us shouldn’t be averaged! Of course, it’s "
"not always the case that a main effect is meaningless when an interaction is "
"present. Often you can get a big main effect and a very small interaction, "
"in which case you can still say things like “drug A is generally more "
"effective than drug B” (because there was a big effect of drug), but you’d "
"need to modify it a bit by adding that “the difference in effectiveness was "
"different for different psychological treatments”. In any case, the main "
"point here is that whenever you get a significant interaction you should "
"stop and *think* about what the main effect actually means in this context. "
"Don’t automatically assume that the main effect is interesting."
msgstr ""
"Denne typen ting skjer ofte. Hovedeffekten er tester av marginale "
"gjennomsnitt, og når det er en interaksjon til stede, er vi ofte ikke så "
"veldig interessert i marginale gjennomsnitt fordi de innebærer "
"gjennomsnittsberegning over ting som interaksjonen forteller oss at det ikke "
"skal beregnes gjennomsnitt for! Det er selvfølgelig ikke alltid slik at en "
"hovedeffekt er meningsløs når det er en interaksjon til stede. Ofte kan du "
"få en stor hovedeffekt og en veldig liten interaksjon, og i så fall kan du "
"fortsatt si ting som «legemiddel A er generelt mer effektivt enn legemiddel "
"B» (fordi det var en stor effekt av legemiddelet), men du må modifisere det "
"litt ved å legge til at «forskjellen i effektivitet varierte mellom ulike "
"psykologiske terapier». Uansett er hovedpoenget her at hver gang du får en "
"signifikant interaksjon, bør du stoppe opp og *tenke* over hva hovedeffekten "
"faktisk betyr i denne sammenhengen. Ikke anta automatisk at hovedeffekten er "
"interessant."

#: ../../Ch14/Ch14_ANOVA2_02.rst:320
msgid ""
"You may have spotted this already when looking at the main effects analysis "
"in jamovi that we described earlier. For the purpose of the explanation in "
"this book I removed the interaction component from the earlier model to keep "
"things clean and simple"
msgstr ""
"Du har kanskje allerede oppdaget dette når du ser på hovedeffektanalysen i "
"jamovi som vi beskrev tidligere. I denne boken har jeg fjernet "
"interaksjonskomponenten fra den tidligere modellen for å holde det enkelt og "
"oversiktlig"

#: ../../Ch14/Ch14_ANOVA2_03.rst:4
msgid "Effect size"
msgstr "Effektstørrelse"

#: ../../Ch14/Ch14_ANOVA2_03.rst:6
msgid ""
"The effect size calculation for a factorial ANOVA is pretty similar to those "
"used in One-Way ANOVA (see section :doc:`../Ch13/Ch13_ANOVA_04`). "
"Specifically, we can use η² (eta-squared) as a simple way to measure how big "
"the overall effect is for any particular term. As before, η² is defined by "
"dividing the sum of squares associated with that term by the total sum of "
"squares. For instance, to determine the size of the main effect of Factor A, "
"we would use the following formula:"
msgstr ""
"Beregningen av effektstørrelsen for en faktoriell ANOVA er ganske lik de som "
"brukes i en enveis ANOVA (se avsnitt :doc:`../Ch13/Ch13_ANOVA_04`). Vi kan "
"bruke η² (eta-kvadrat) som en enkel måte å måle hvor stor den samlede "
"effekten er for en bestemt term. Som tidligere defineres η² ved å dividere "
"kvadratsummen knyttet til denne effekten med den totale kvadratsummen. For å "
"finne ut hvor stor hovedeffekten av faktor A er, kan vi for eksempel bruke "
"følgende formel:"

#: ../../Ch14/Ch14_ANOVA2_03.rst:14
msgid "η² = SS\\ :sub:`A` / SS\\ :sub:`T`"
msgstr "η² = SS\\ :sub:`A` / SS\\ :sub:`T`"

#: ../../Ch14/Ch14_ANOVA2_03.rst:16
msgid ""
"As before, this can be interpreted in much the same way as *R*\\² in "
"regression.\\ [#]_ It tells you the proportion of variance in the outcome "
"variable that can be accounted for by the main effect of Factor A. It is "
"therefore a number that ranges from 0 (no effect at all) to 1 (accounts for "
"*all* of the variability in the outcome). Moreover, the sum of all the η² "
"values, taken across all the terms in the model, will sum to the the total "
"*R*\\² for the ANOVA model. If, for instance, the ANOVA model fits perfectly "
"(i.e., there is no within-groups variability at all!), the η² values will "
"sum to 1. Of course, that rarely if ever happens in real life."
msgstr ""
"Som tidligere kan denne tolkes på samme måte som *R*\\² i regresjon:\\ [#]_ "
"Den forteller hvor stor andel av variansen i utfallsvariabelen som kan "
"forklares av hovedeffekten av faktor A. Det er altså et tall som går fra 0 "
"(ingen effekt i det hele tatt) til 1 (forklarer *all* variasjonen i "
"utfallet). Videre vil summen av alle η²-verdiene, tatt på tvers av alle "
"termene i modellen, utgjøre den totale *R*\\² for ANOVA-modellen. Hvis ANOVA-"
"modellen for eksempel passer perfekt (det vil si at det ikke er noen "
"variabilitet i gruppene i det hele tatt!), vil η²-verdiene summere seg til "
"1. Det skjer selvfølgelig sjelden eller aldri i virkeligheten."

#: ../../Ch14/Ch14_ANOVA2_03.rst:27
msgid ""
"However, when doing a factorial ANOVA, there is a second measure of effect "
"size that people like to report, known as partial η². The idea behind "
"partial η² (which is sometimes denoted :sub:`p`\\ η² or \\η²\\ :sub:`p`) is "
"that, when measuring the effect size for a particular term (say, the main "
"effect of Factor A), you want to deliberately ignore the other effects in "
"the model (e.g., the main effect of Factor B). That is, you would pretend "
"that the effect of all these other terms is zero, and then calculate what "
"the η²-value would have been. This is actually pretty easy to calculate. All "
"you have to do is remove the sum of squares associated with the other terms "
"from the denominator. In other words, if you want the partial η² for the "
"main effect of Factor A, the denominator is just the sum of the SS values "
"for Factor A and the residuals"
msgstr ""
"Når man utfører en faktoriell ANOVA, er det imidlertid et annet mål på "
"effektstørrelse som folk liker å rapportere, kjent som partiell η². Tanken "
"bak partiell η² (som noen ganger betegnes :sub:`p`\\ η² eller \\η²\\ :sub:"
"`p`) er at når man måler effektstørrelsen for en bestemt term (f.eks. "
"hovedeffekten av faktor A), ønsker man bevisst å ignorere de andre effektene "
"i modellen (f.eks. hovedeffekten av faktor B). Det vil si at du later som om "
"effekten av alle disse andre termene er null, og deretter beregner hva η²-"
"verdien ville ha vært. Dette er faktisk ganske enkelt å beregne. Alt du "
"trenger å gjøre, er å fjerne kvadratsummen forbundet med de andre termene "
"fra nevneren. Med andre ord, hvis du vil ha den partielle η²-verdien for "
"hovedeffekten av faktor A, er nevneren bare de oppsummerte kvadratsummenene "
"(SS) for faktor A og residuene"

#: ../../Ch14/Ch14_ANOVA2_03.rst:39
msgid "partial η²\\ :sub:`A` = SS\\ :sub:`A` / (SS\\ :sub:`A` + SS\\ :sub:`R`)"
msgstr ""
"partial η²\\ :sub:`A` = SS\\ :sub:`A` / (SS\\ :sub:`A` + SS\\ :sub:`R`)"

#: ../../Ch14/Ch14_ANOVA2_03.rst:41
msgid ""
"This will always give you a larger number than η², which the cynic in me "
"suspects accounts for the popularity of partial η². And once again you get a "
"number between 0 and 1, where 0 represents no effect. However, it’s slightly "
"trickier to interpret what a large partial η² value means. In particular, "
"you can’t actually compare the partial η² values across terms! Suppose, for "
"instance, there is no within-groups variability at all: if so, SS\\ :sub:`R` "
"= 0. What that means is that *every* term has a partial η² value of 1. But "
"that doesn’t mean that all terms in your model are equally important, or "
"indeed that they are equally large. All it mean is that all terms in your "
"model have effect sizes that are large *relative to the residual variation*. "
"It is not comparable across terms."
msgstr ""
"Dette vil alltid gi deg et større tall enn η², noe kynikeren i meg mistenker "
"er årsaken til populariteten til partiell η². Og nok en gang får du et tall "
"mellom 0 og 1, der 0 representerer ingen effekt. Det er imidlertid litt "
"vanskeligere å tolke hva en stor partiell η²-verdi betyr. Du kan nemlig ikke "
"sammenligne de partielle η²-verdiene på tvers av termene! Anta for eksempel "
"at det ikke er noen variabilitet innad i gruppene i det hele tatt: I så fall "
"er SS\\ :sub:`R` = 0. Det betyr at *alle* termene har en partiell η²-verdi "
"på 1. Men det betyr ikke at alle termene i modellen din er like viktige, "
"eller at de er like store. Det betyr bare at alle termene i modellen din har "
"effektstørrelser som er store *relativt til den resterende variasjonen* "
"(dvs. kvadratsummen til residuene). Det er ikke sammenlignbart på tvers av "
"termene."

#: ../../Ch14/Ch14_ANOVA2_03.rst:55
msgid ""
"To see what I mean by this, it’s useful to see a concrete example. First, "
"let’s have a look at the effect sizes for the original ANOVA without the "
"interaction term, from :numref:`fig-factorialanova3`:"
msgstr ""
"For å se hva jeg mener med dette, er det nyttig å se et konkret eksempel. La "
"oss først ta en titt på effektstørrelsene for den opprinnelige ANOVA-en uten "
"interaksjonstermen, fra :numref:`fig-factorialanova3`:"

#: ../../Ch14/Ch14_ANOVA2_03.rst:65
msgid ""
"Looking at the η² values first, we see that ``drug`` accounts for 71\\% of "
"the variance (i.e. η² = 0.71) in ``mood.gain``, whereas ``therapy`` only "
"accounts for 10\\%. This leaves a total of 19\\% of the variation "
"unaccounted for (i.e., the residuals constitute 19\\% of the variation in "
"the outcome). Overall, this implies that we have a very large effect\\ [#]_ "
"of ``drug`` and a modest effect of ``therapy``."
msgstr ""
"Ser vi først på η²-verdiene, ser vi at ``drug`` står for 71\\% av variansen "
"(dvs. η² = 0,71) i ``mood.gain``, mens ``therapy`` bare står for 10\\%. "
"Dette etterlater totalt 19\\% av variasjonen uforklart (dvs. at residuene "
"utgjør 19\\% av variasjonen i utfallsvariablen). Samlet sett innebærer dette "
"at vi har en svært stor effekt\\ [#]_ av ``drug`` og en beskjeden effekt av "
"``therapy``."

#: ../../Ch14/Ch14_ANOVA2_03.rst:72
msgid ""
"Now let’s look at the partial η² values, shown in :numref:`fig-"
"factorialanova3`. Because the effect of ``therapy`` isn’t all that large, "
"controlling for it doesn’t make much of a difference, so the partial η² for "
"``drug`` doesn’t increase very much, and we obtain a value of :sub:`p`\\ η² "
"= 0.79). In contrast, because the effect of ``drug`` was very large, "
"controlling for it makes a big difference, and so when we calculate the "
"partial η² for ``therapy`` you can see that it rises to :sub:`p`\\ η² = "
"0.34. The question that we have to ask ourselves is, what do these partial "
"η² values actually *mean*? The way I generally interpret the partial η² for "
"the main effect of Factor A is to interpret it as a statement about a "
"hypothetical experiment in which *only* Factor A was being varied. So, even "
"though in *this* experiment we varied both A and B, we can easily imagine an "
"experiment in which only Factor A was varied, and the partial η² statistic "
"tells you how much of the variance in the outcome variable you would expect "
"to see accounted for in that experiment. However, it should be noted that "
"this interpretation, like many things associated with main effects, doesn’t "
"make a lot of sense when there is a large and significant interaction effect."
msgstr ""
"La oss nå se på de partielle η²-verdiene, som vises i :numref:`fig-"
"factorialanova3`. Fordi effekten av ``therapy`` ikke er så stor, gjør det "
"ikke så stor forskjell å kontrollere for den, så den partielle η² for "
"``drug`` øker ikke særlig mye, og vi får en verdi på :sub:`p`\\ η² = 0,79). "
"Fordi effekten av ``drug`` var svært stor, gjør det derimot en stor "
"forskjell å kontrollere for den, og når vi beregner den partielle η² for "
"``therapy``, ser vi at den stiger til :sub:`p`\\ η² = 0,34. Spørsmålet vi må "
"stille oss, er hva disse partielle η²-verdiene egentlig *betyr*. Jeg pleier "
"å tolke den partielle η²-verdien for hovedeffekten av faktor A som et utsagn "
"om et hypotetisk eksperiment der *bare* faktor A ble variert. Så selv om vi "
"i *dette* eksperimentet har variert både A og B, kan vi lett forestille oss "
"et eksperiment der bare faktor A ble variert, og den partielle η²-"
"statistikken forteller deg hvor mye av variansen i utfallsvariabelen du "
"ville forvente å finne i dette eksperimentet. Det er imidlertid verdt å "
"merke seg at denne tolkningen, i likhet med mange andre ting som er "
"forbundet med hovedeffekter, ikke gir særlig mening når det er en stor og "
"signifikant interaksjonseffekt."

#: ../../Ch14/Ch14_ANOVA2_03.rst:90
msgid ""
"Speaking of interaction effects, here’s what we get when we calculate the "
"effect sizes for the model that includes the interaction term, as in :numref:"
"`fig-factorialanova4`. As you can see, the η² values for the main effects "
"don’t change, but the partial η² values do:"
msgstr ""
"Apropos interaksjonseffekter, her er hva vi får når vi beregner "
"effektstørrelsene for modellen som inkluderer interaksjonstermen, som i :"
"numref:`fig-factorialanova4`. Som du kan se, endres ikke η²-verdiene for "
"hovedeffektene, men det gjør de partielle η²-verdiene:"

#: ../../Ch14/Ch14_ANOVA2_03.rst:103
msgid "Estimated group means"
msgstr "Estimert gruppegjennomsnitt"

#: ../../Ch14/Ch14_ANOVA2_03.rst:105
msgid ""
"In many situations you will find yourself wanting to report estimates of all "
"the group means based on the results of your ANOVA, as well as confidence "
"intervals associated with them. You can use the ``Estimated Marginal Means`` "
"option in the jamovi ANOVA analysis to do this, as in :numref:`fig-"
"margmean1`. If the ANOVA that you have run is a **saturated model** (i.e., "
"contains all possible main effects and all possible interaction effects) "
"then the estimates of the group means are actually identical to the sample "
"means, though the confidence intervals will use a pooled estimate of the "
"standard errors rather than use a separate one for each group."
msgstr ""
"I mange situasjoner vil du ønske å rapportere estimater av alle "
"gruppegjennomsnittene basert på resultatene av ANOVA-analysen, samt "
"konfidensintervallene som er knyttet til dem. Du kan bruke alternativet "
"``Estimated Marginal Means`` i jamovi ANOVA-analysen for å gjøre dette, som "
"i :numref:`fig-margmean1`. Hvis ANOVA-analysen du har kjørt er en "
"**fullstendig modell** (*saturated model*; dvs. inneholder alle mulige "
"hovedeffekter og alle mulige interaksjonseffekter), er estimatene av "
"gruppegjennomsnittene faktisk identiske med utvalgsgjennomsnittet, selv om "
"konfidensintervallene vil bruke et samlet estimat av standardfeilene i "
"stedet for å bruke et separat estimat for hver gruppe."

#: ../../Ch14/Ch14_ANOVA2_03.rst:117
msgid "Estimated marginal means for the saturated model"
msgstr "Estimerte marginale gjennomsnitt for den mettede modellen"

#: ../../Ch14/Ch14_ANOVA2_03.rst:121
msgid ""
"jamovi screenshot showing the estimated marginal means for the saturated "
"model, i.e. including the interaction component, with the |clinicaltrial|_ "
"dataset"
msgstr ""
"jamovi-skjermbilde som viser de estimerte marginale gjennomsnittene for den "
"mettede modellen, dvs. inkludert interaksjonskomponenten, med datasettet |"
"clinicaltrial|_"

#: ../../Ch14/Ch14_ANOVA2_03.rst:127
msgid ""
"In the output we see that the estimated mean mood gain for the placebo group "
"with no therapy was 0.300, with a 95\\% confidence interval from 0.006 to "
"0.594. Note that these are not the same confidence intervals that you would "
"get if you calculated them separately for each group, because of the fact "
"that the ANOVA model assumes homogeneity of variance and therefore uses a "
"pooled estimate of the standard deviation."
msgstr ""
"I resultatet ser vi at den estimerte gjennomsnittlige humørforbedringen "
"(``mood.gain``) for placebogruppen uten terapi (``no.therapy``) var 0,300, "
"med et 95\\%-konfidensintervall fra 0,006 til 0,594. Merk at dette ikke er "
"de samme konfidensintervallene som du ville fått hvis du beregnet dem "
"separat for hver gruppe, fordi ANOVA-modellen forutsetter varianshomogenitet "
"og derfor bruker et samlet estimat av standardavviket."

#: ../../Ch14/Ch14_ANOVA2_03.rst:134
msgid ""
"When the model doesn’t contain the interaction term, then the estimated "
"group means will be different from the sample means. Instead of reporting "
"the sample mean, jamovi will calculate the value of the group means that "
"would be expected on the basis of the marginal means (i.e., assuming no "
"interaction). Using the notation we developed earlier, the estimate reported "
"for µ\\ :sub:`rc`, the mean for level *r* on the (row) Factor A and level "
"*c* on the (column) Factor B would be µ\\ :sub:`..` + α\\ :sub:`r` + β\\ :"
"sub:`c`\\. If there are genuinely no interactions between the two factors, "
"this is actually a better estimate of the population mean than the raw "
"sample mean would be. Removing the interaction term from the model, via the "
"``Model`` options in the jamovi ANOVA analysis, provides the marginal means "
"for the analysis shown in :numref:`fig-margmean2`."
msgstr ""
"Når modellen ikke inneholder interaksjonstermen, vil de estimerte "
"gruppegjennomsnittene være forskjellige fra utvalgsgjennomsnittene. I stedet "
"for å rapportere utvalgsgjennomsnittet, vil jamovi beregne verdien av "
"gruppegjennomsnittet som ville vært forventet på grunnlag av de marginale "
"gjennomsnittene (dvs. forutsatt at det ikke er noen interaksjon). Ved å "
"bruke notasjonen vi utviklet tidligere, vil estimatet som rapporteres for "
"µ\\ :sub:`rc`, gjennomsnittet for nivå *r* på (rad) Faktor A og nivå *c* på "
"(kolonne) Faktor B, være µ\\ :sub:`..` + α\\ :sub:`r` + β\\ :sub:`c`\\. Hvis "
"det virkelig ikke er noen interaksjon mellom de to faktorene, er dette "
"faktisk et bedre estimat av populasjonsgjennomsnittet enn det rå "
"utvalgsgjennomsnittet ville ha vært. Ved å fjerne interaksjonstermen fra "
"modellen, via ``Model``-alternativene i jamovi ANOVA-analysen, får man de "
"marginale gjennomsnittene for analysen som vises i :numref:`fig-margmean2`."

#: ../../Ch14/Ch14_ANOVA2_03.rst:148
msgid "Estimated marginal means for the unsaturated model"
msgstr "Estimerte marginale gjennomsnitt for den umettede modellen"

#: ../../Ch14/Ch14_ANOVA2_03.rst:152
msgid ""
"jamovi screenshot showing the estimated marginal means for the unsaturated "
"model, i.e. without the interaction component, with the |clinicaltrial|_ "
"dataset"
msgstr ""
"jamovi-skjermbilde som viser de estimerte marginale gjennomsnittene for den "
"umettede modellen, dvs. uten interaksjonskomponenten, med datasettet |"
"clinicaltrial|_"

#: ../../Ch14/Ch14_ANOVA2_03.rst:161
msgid ""
"This chapter seems to be setting a new record for the number of different "
"things that the letter R can stand for. So far we have R referring to the "
"software package, the number of rows in our table of means, the residuals in "
"the model, and now the correlation coefficient in a regression. Sorry. We "
"clearly don’t have enough letters in the alphabet. However, I’ve tried "
"pretty hard to be clear on which thing R is referring to in each case."
msgstr ""
"Dette kapittelet ser ut til å sette ny rekord i antall forskjellige ting "
"bokstaven R kan stå for. Så langt har vi hatt R som betegnelse på "
"programvarepakken, antall rader i gjennomsnittstabellen, residuene i "
"modellen og nå altså korrelasjonskoeffisienten i en regresjon. Det var leit "
"å høre. Vi har tydeligvis ikke nok bokstaver i alfabetet. Men jeg har "
"forsøkt å være tydelig på hva R refererer til i hvert enkelt tilfelle."

#: ../../Ch14/Ch14_ANOVA2_03.rst:170
msgid ""
"Implausibly large, I would think. The artificiality of this data set is "
"really starting to show!"
msgstr ""
"Usannsynlig stort, vil jeg tro. Det kunstige ved dette datasettet begynner "
"virkelig å vise seg!"

#: ../../Ch14/Ch14_ANOVA2_04.rst:4
msgid "Assumption checking"
msgstr "Sjekk av forutsetninger"

#: ../../Ch14/Ch14_ANOVA2_04.rst:6
msgid ""
"As with one-way ANOVA, the key assumptions of factorial ANOVA are "
"homogeneity of variance (all groups have the same standard deviation), "
"normality of the residuals, and independence of the observations. The first "
"two are things we can check for. The third is something that you need to "
"assess yourself by asking if there are any special relationships between "
"different observations, for example repeated measures where the independent "
"variable is time so there is a relationship between the observations at time "
"one and time two: observations at different time points are from the *same* "
"people. Additionally, if you aren’t using a saturated model (e.g., if you’ve "
"omitted the interaction terms) then you’re also assuming that the omitted "
"terms aren’t important. Of course, you can check this last one by running an "
"ANOVA with the omitted terms included and see if they’re significant, so "
"that’s pretty easy. What about homogeneity of variance and normality of the "
"residuals? As it turns out, these are pretty easy to check. It’s no "
"different to the checks we did for a one-way ANOVA."
msgstr ""
"Som for enveis ANOVA er de viktigste forutsetningene for faktoriell ANOVA "
"varianshomogenitet (alle gruppene har samme standardavvik), normalfordeling "
"av residuene og uavhengighet mellom observasjonene. De to første er ting vi "
"kan sjekke for. Det tredje er noe du må vurdere selv ved å spørre om det er "
"noen spesielle sammenhenger mellom ulike observasjoner, for eksempel "
"gjentatte målinger der den uavhengige variabelen er tid, slik at det er en "
"sammenheng mellom observasjonene på tidspunkt én og tidspunkt to: "
"observasjoner på ulike tidspunkter er fra *samme* personer. Hvis du i "
"tillegg ikke bruker en fullstendig modell (f.eks. hvis du har utelatt "
"interaksjonstermene), antar du også at de utelatte termene ikke er viktige. "
"Du kan selvfølgelig sjekke dette siste ved å kjøre en ANOVA med de utelatte "
"termene inkludert og se om de er signifikante, så det er ganske enkelt. Hva "
"med varianshomogenitet og normalfordeling av residuene? Det viser seg at "
"disse er ganske enkle å sjekke. Det er ikke annerledes enn kontrollene vi "
"gjorde for en enveis ANOVA."

#: ../../Ch14/Ch14_ANOVA2_04.rst:24
msgid "Homogeneity of variance"
msgstr "Varianshomogenitet"

#: ../../Ch14/Ch14_ANOVA2_04.rst:26
msgid ""
"As mentioned in subsection :ref:`Checking the homogeneity of variance "
"assumption <homogeneity_of_variance_anova>`, it’s a good idea to visually "
"inspect a plot of the standard deviations compared across different groups / "
"categories, and also see if the Levene test is consistent with the visual "
"inspection. The theory behind the Levene test was discussed in that section, "
"so I won’t discuss it again. This test expects that you have a saturated "
"model (i.e., including all of the relevant terms), because the test is "
"primarily concerned with the within-group variance, and it doesn’t really "
"make a lot of sense to calculate this any way other than with respect to the "
"full model. The Levene test can be specified under the ANOVA ``Assumption "
"Checks`` → ``Homogeneity Tests`` option in jamovi, with the result shown as "
"in :numref:`fig-factorialanova5`. The fact that the Levene test is non-"
"significant means that, providing it is consistent with a visual inspection "
"of the plot of standard deviations, we can safely assume that the "
"homogeneity of variance assumption is not violated."
msgstr ""
"Som nevnt i underkapittelet :ref:`Sjekk av forutsetningen om "
"varianshomogenitet <homogeneity_of_variance_anova>`, er det en god idé å "
"inspisere visuelt et plott av standardavvikene sammenlignet på tvers av "
"ulike grupper/kategorier, og også se om Levene-testen stemmer overens med "
"den visuelle inspeksjonen. Teorien bak Levene-testen ble diskutert i det "
"avsnittet, så jeg skal ikke gå inn på den igjen. Denne testen forutsetter at "
"du har en fullstendig modell (dvs. at alle relevante termer er inkludert), "
"fordi testen først og fremst er opptatt av variansen innad i gruppene, og "
"det gir egentlig ikke så mye mening å beregne denne på noen annen måte enn "
"med hensyn til den fullstendige modellen. Levene-testen kan spesifiseres "
"under alternativet ANOVA ``Assumption Checks`` → ``Homogeneity Tests`` i "
"jamovi, med resultatet vist som i :numref:`fig-factorialanova5`. Det faktum "
"at Levene-testen ikke er signifikant, betyr at vi trygt kan anta at "
"forutsetningen om varianshomogenitet ikke er brutt, forutsatt at den stemmer "
"overens med en visuell inspeksjon av plottet av standardavvikene."

#: ../../Ch14/Ch14_ANOVA2_04.rst:44 ../../Ch14/Ch14_ANOVA2_04.rst:48
msgid "Checking assumptions in an ANOVA model"
msgstr "Sjekk av forutsetninger for en ANOVA-modell"

#: ../../Ch14/Ch14_ANOVA2_04.rst:53
msgid "Normality of residuals"
msgstr "Normalfordeling av residuer"

#: ../../Ch14/Ch14_ANOVA2_04.rst:55
msgid ""
"As with one-way ANOVA we can test for the normality of residuals in a "
"straightforward fashion (see :ref:`Checking the normality assumption "
"<normality_anova>`). Primarily though, it’s generally a good idea to examine "
"the residuals graphically using a QQ-plot. See :numref:`fig-factorialanova5`."
msgstr ""
"Som med enveis ANOVA kan vi teste for normalfordeling av residuene på en "
"enkel måte (se :ref:`Sjekk forutsetningen om normalfordeling "
"<normality_anova>`). Først og fremst er det imidlertid en god idé å "
"undersøke residuene grafisk ved hjelp av et QQ-plott. Se :numref:`fig-"
"factorialanova5`."

#: ../../Ch14/Ch14_ANOVA2_06.rst:4
msgid "Analysis of Covariance (ANCOVA)"
msgstr "Kovariansanalyse (ANCOVA)"

#: ../../Ch14/Ch14_ANOVA2_06.rst:6
msgid ""
"A variation in ANOVA is when you have an additional continuous variable |"
"continuous| that you think might be related to the dependent variable. This "
"additional variable can be added to the analysis as a covariate, in the "
"aptly named analysis of covariance (ANCOVA)."
msgstr ""
"En variant av ANOVA er når du har en ekstra kontinuerlig variabel |"
"continuous| som du tror kan være relatert til den avhengige variabelen. "
"Denne tilleggsvariabelen kan legges til i analysen som en kovariat, i en "
"kovariansanalyse (ANCOVA)."

#: ../../Ch14/Ch14_ANOVA2_06.rst:11
msgid ""
"In ANCOVA the values of the dependent variable are “adjusted” for the "
"influence of the covariate, and then the “adjusted” score means are tested "
"between groups |nominal| in the usual way. This technique can increase the "
"precision of an experiment, and therefore provide a more “powerful” test of "
"the equality of group means in the dependent variable. How does ANCOVA do "
"this? Well, although the covariate itself is typically not of any "
"experimental interest, adjustment for the covariate can decrease the "
"estimate of experimental error and thus, by reducing error variance, "
"precision is increased. This means that an inappropriate failure to reject "
"the null hypothesis (false negative or type II error) is less likely."
msgstr ""
"I ANCOVA «justeres» verdiene for den avhengige variabelen for påvirkningen "
"fra kovariaten, og deretter testes de «justerte» gjennomsnittene mellom "
"gruppene |nominal| på vanlig måte. Denne teknikken kan øke presisjonen i et "
"eksperiment, og dermed gi en mer «kraftfull» test av likheten mellom "
"gruppegjennomsnitt i den avhengige variabelen. Hvordan gjør ANCOVA dette? "
"Jo, selv om kovariaten i seg selv vanligvis ikke er av eksperimentell "
"interesse, kan justering for kovariaten redusere estimatet av "
"eksperimentelle feil, og ved å redusere feilvariansen øker dermed "
"presisjonen. Dette betyr at det er mindre sannsynlig at nullhypotesen ikke "
"kan forkastes (falsk negativ eller type-II-feil)."

#: ../../Ch14/Ch14_ANOVA2_06.rst:22
msgid ""
"Despite this advantage, ANCOVA runs the risk of undoing real differences "
"between groups |nominal|, and this should be avoided. Look at :numref:`fig-"
"ancova_groups`, for example, which shows a plot of Statistics anxiety "
"against age and shows two distinct groups – students who have either an Arts "
"or Science background or preference. ANCOVA with age as a covariate might "
"lead to the conclusion that statistics anxiety does not differ in the two "
"groups. Would this conclusion be reasonable – probably not because the ages "
"of the two groups do not overlap and analysis of variance has essentially "
"“extrapolated into a region with no data” (:ref:`Everitt, 1996 "
"<Everitt_1996>`)."
msgstr ""
"Til tross for denne fordelen risikerer ANCOVA å utviske reelle forskjeller "
"mellom grupper |nominal|, og dette bør unngås. Se for eksempel :numref:`fig-"
"ancova_groups`, som viser et plott av statistikkangst mot alder og viser to "
"distinkte grupper - studenter som enten har en kunst- eller "
"naturvitenskapelig bakgrunn eller preferanser. ANCOVA med alder som kovariat "
"kan føre til den konklusjonen at statistikkangst ikke er forskjellig i de to "
"gruppene. Ville denne konklusjonen være rimelig - sannsynligvis ikke fordi "
"alderen til de to gruppene ikke overlapper hverandre, og variansanalysen har "
"i hovedsak «ekstrapolert inn i et område uten data» (:ref:`Everitt, 1996 "
"<Everitt_1996>`)."

#: ../../Ch14/Ch14_ANOVA2_06.rst:34 ../../Ch14/Ch14_ANOVA2_06.rst:38
msgid "Plot of Statistics anxiety against age for two distinct groups"
msgstr "Plott av statistikk for angst mot alder for to forskjellige grupper"

#: ../../Ch14/Ch14_ANOVA2_06.rst:42
msgid ""
"Clearly, careful thought needs to be given to an analysis of covariance with "
"distinct groups. This applies to both one-way and factorial designs, as "
"ANCOVA can be used with both."
msgstr ""
"Det er klart at man må tenke nøye gjennom en kovariansanalyse med distinkte "
"grupper. Dette gjelder både enveis- og faktorielle design, ettersom ANCOVA "
"kan brukes med begge."

#: ../../Ch14/Ch14_ANOVA2_06.rst:47
msgid "Running ANCOVA in jamovi"
msgstr "Kjører ANCOVA i jamovi"

#: ../../Ch14/Ch14_ANOVA2_06.rst:49
msgid ""
"A health psychologist was interested in the effect of routine cycling and "
"stress on happiness levels, with age as a covariate. Open the |ancova|_ data "
"set in jamovi and then, to undertake an ANCOVA, select ``Analyses`` → "
"``ANOVA`` → ``ANCOVA`` to open the ANCOVA analysis window (:numref:`fig-"
"ancova1`). Highlight the dependent variable ``happiness`` |continuous| and "
"transfer it into the ``Dependent Variable`` text box. Highlight the "
"independent variables ``stress`` |nominal| and ``commute`` |nominal| and "
"transfer them into the ``Fixed Factors`` text box. Highlight the covariate "
"``age`` |continuous| and transfer it into the ``Covariates`` text box. Then, "
"click on ``Estimated Marginal Means`` to bring up the plots and tables "
"options."
msgstr ""
"En helsepsykolog var interessert i effekten av å sykle til jobben og stress "
"på lykkenivået, med alder som kovariat. Åpne datasettet |ancova|_ i jamovi, "
"og velg deretter ``Analyses`` → ``ANOVA`` → ``ANCOVA`` for å åpne ANCOVA-"
"analysevinduet (:numref:`fig-ancova1`) for å foreta en ANCOVA. Marker den "
"avhengige variabelen ``happiness`` |continuous| og overfør den til "
"tekstboksen ``Dependent Variable``. Marker de uavhengige variablene "
"``stress`` |nominal| og ``commute`` |nominal|, og overfør dem til "
"tekstboksen ``Fixed Factors``. Marker kovariaten ``age`` |continuous| og "
"overfør den til tekstboksen ``Covariates``. Klikk deretter på ``Estimated "
"Marginal Means`` for å få opp alternativene for plott og tabeller."

#: ../../Ch14/Ch14_ANOVA2_06.rst:62
msgid "The jamovi ANCOVA options panel"
msgstr "Analysepanel for ANCOVA i jamovi"

#: ../../Ch14/Ch14_ANOVA2_06.rst:66
msgid ""
"Options panel showing the variable boxes to assign the ``Dependent "
"Variable``, ``Fixed Factors`` and the ``Covariates`` for the ANCOVA in jamovi"
msgstr ""
"Analysepanel for ANCOVA i jamovi som viser variabelboksene for å tilordne "
"``Dependent Variable``, ``Fixed Factors`` og ``Covariates``"

#: ../../Ch14/Ch14_ANOVA2_06.rst:72
msgid ""
"An ANCOVA table showing Tests of Between-Subjects Effects is produced in the "
"jamovi results panel (:numref:`fig-ancova2`). The *F*-value for the "
"covariate ``age`` is significant at *p* = 0.023, suggesting that age is an "
"important predictor of the dependent variable, happiness. When we look at "
"the estimated marginal mean scores (:numref:`fig-ancova3`), adjustments have "
"been made (compared to an analysis without the covariate) because of the "
"inclusion of the covariate ``age`` in this ANCOVA. A plot (:numref:`fig-"
"ancova4`) is a good way of visualising and interpreting the significant "
"effects."
msgstr ""
"En ANCOVA-tabell som viser tester av effekter mellom subjekter, er produsert "
"i jamovi-resultatpanelet (:numref:`fig-ancova2`). *F*-verdien for kovariaten "
"``age`` er signifikant med *p* = 0,023, noe som tyder på at alder er en "
"viktig prediktor for den avhengige variabelen, lykke. Når vi ser på de "
"estimerte marginale gjennomsnittsverdiene (:numref:`fig-ancova3`), har det "
"blitt gjort justeringer (sammenlignet med en analyse uten kovariaten) på "
"grunn av inkluderingen av kovariaten ``age`` i denne ANCOVA-en. Et plott (:"
"numref:`fig-ancova4`) er en god måte å visualisere og tolke de signifikante "
"effektene på."

#: ../../Ch14/Ch14_ANOVA2_06.rst:83
msgid "jamovi ANCOVA output"
msgstr "Utgave fra ANCOVA i jamovi"

#: ../../Ch14/Ch14_ANOVA2_06.rst:87
msgid ""
"jamovi ANCOVA output for happiness as a function of stress and commuting "
"method, with age as a covariate"
msgstr ""
"Utgave fra ANCOVA for lykke som en funksjon av stress og pendlingsmetode, "
"med alder som kovariat i jamovi"

#: ../../Ch14/Ch14_ANOVA2_06.rst:92
msgid "Estimated Marginal means within the ANCOVA"
msgstr "Estimerte marginale gjennomsnitt innenfor ANCOVA"

#: ../../Ch14/Ch14_ANOVA2_06.rst:96
msgid ""
"Table with the Estimated Marginal means within the ANCOVA: Shown are the "
"mean happiness level as a function of stress and commuting method (adjusted "
"for the covariate age) with 95\\% confidence intervals"
msgstr ""
"Tabell med de estimerte marginale gjennomsnittene i ANCOVA: Her vises "
"gjennomsnittlig lykkenivå som en funksjon av stress og pendlingsmetode "
"(justert for kovariaten alder) med 95\\%-konfidensintervall"

#: ../../Ch14/Ch14_ANOVA2_06.rst:102
msgid ""
"The *F*-value for the main effect ``stress`` (52.61) has an associated "
"probability of *p* < 0.001. The *F*-value for the main effect ``commute`` "
"(42.33) has an associated probability of *p* < 0.001. Since both of these "
"are less than the probability that is typically used to decide if a "
"statistical result is significant (*p* < 0.05) we can conclude that there "
"was a significant main effect of stress (*F*\\(1,15) = 52.61, *p* < 0.001) "
"and a significant main effect of commuting method (*F*\\(1,15) = 42.33, *p* "
"< 0.001). A significant interaction between stress and commuting method was "
"also found (*F*\\(1,15) = \\14.15, *p* = 0.002)."
msgstr ""
"*F*-verdien for hovedeffekten ``stress`` (52,61) har en tilhørende "
"sannsynlighet på *p* < 0,001. *F*-verdien for hovedeffekten ``commute`` "
"(42,33) har en tilhørende sannsynlighet på *p* < 0,001. Siden begge disse er "
"mindre enn den sannsynligheten som vanligvis brukes for å avgjøre om et "
"statistisk resultat er signifikant (*p* < 0,05), kan vi konkludere med at "
"det var en signifikant hovedeffekt av stress (*F*\\(1,15) = 52,61, *p* < "
"0,001) og en signifikant hovedeffekt av pendlingsmetode (*F*\\(1,15) = "
"42,33, *p* < 0,001). Det ble også funnet en signifikant interaksjon mellom "
"stress og pendlingsmetode (*F*\\(1,15) = \\14,15, *p* = 0,002)."

#: ../../Ch14/Ch14_ANOVA2_06.rst:112
msgid ""
"In :numref:`fig-ancova4` we can see the adjusted, marginal, mean happiness "
"scores when age is a covariate in an ANCOVA. In this analysis there is a "
"significant interaction effect, whereby people with low stress who cycle to "
"work are happier than people with low stress who drive and people with high "
"stress whether they cycle or drive to work. There is also a significant main "
"effect of stress – people with low stress are happier than those with high "
"stress. And there is also a significant main effect of commuting behaviour – "
"people who cycle are happier, on average, than those who drive to work."
msgstr ""
"I :numref:`fig-ancova4` kan vi se de justerte, marginale, gjennomsnittlige "
"lykkeskårene når alder er en kovariat i en ANCOVA. I denne analysen er det "
"en signifikant interaksjonseffekt, der personer med lavt stressnivå som "
"sykler til jobben, er lykkeligere enn personer med lavt stressnivå som "
"kjører bil, og personer med høyt stressnivå, uansett om de sykler eller "
"kjører bil til jobben. Det er også en signifikant hovedeffekt av stress - "
"personer med lavt stressnivå er lykkeligere enn personer med høyt "
"stressnivå. Og det er også en signifikant hovedeffekt av pendleratferd - "
"personer som sykler, er i gjennomsnitt lykkeligere enn de som kjører bil til "
"jobben."

#: ../../Ch14/Ch14_ANOVA2_06.rst:123
msgid "Plot with the Estimated Marginal means within the ANCOVA"
msgstr "Plot med de estimerte marginale gjennomsnittene innenfor ANCOVA"

#: ../../Ch14/Ch14_ANOVA2_06.rst:127
msgid ""
"Plot with the Estimated Marginal means within the ANCOVA: Shown are the mean "
"happiness level as a function of stress and commuting method"
msgstr ""
"Plott med de estimerte marginale gjennomsnittene i ANCOVA: Her vises "
"gjennomsnittlig lykkenivå som en funksjon av stress og pendlingsmetode"

#: ../../Ch14/Ch14_ANOVA2_06.rst:132
msgid ""
"One thing to be aware of is that, if you are thinking of including a "
"covariate in your ANOVA, there is an additional assumption: the relationship "
"between the covariate and the dependent variable should be similar for all "
"levels of the independent variable. This can be checked by adding an "
"interaction term between the covariate and each independent variable in the "
"jamovi ``Model`` → ``Model terms`` option. If the interaction effect is not "
"significant it can be removed. If it is significant then a different and "
"more advanced statistical technique might be appropriate (which is beyond "
"the scope of this book so you might want to consult a friendly statistician)."
msgstr ""
"En ting du må være oppmerksom på, er at hvis du vurderer å inkludere en "
"kovariat i ANOVA-en din, er det en ekstra forutsetning: Forholdet mellom "
"kovariaten og den avhengige variabelen skal være likt for alle nivåer av den "
"uavhengige variabelen. Dette kan kontrolleres ved å legge til en "
"interaksjonsterm mellom kovariaten og hver av de uavhengige variablene i "
"jamovi ``Model`` → ``Model terms``. Hvis interaksjonseffekten ikke er "
"signifikant, kan den fjernes. Hvis den er signifikant, kan en annen og mer "
"avansert statistisk teknikk være hensiktsmessig (noe som ligger utenfor "
"denne bokens omfang, så det kan være lurt å rådføre seg med en vennligsinnet "
"statistiker)."

#: ../../Ch14/Ch14_ANOVA2_07.rst:4
msgid "ANOVA as a linear model"
msgstr "ANOVA som en lineær modell"

#: ../../Ch14/Ch14_ANOVA2_07.rst:6
msgid ""
"One of the most important things to understand about ANOVA and regression is "
"that they’re basically the same thing. On the surface of it, you maybe "
"wouldn’t think this is true. After all, the way that I’ve described them so "
"far suggests that ANOVA is primarily concerned with testing for group "
"differences, and regression is primarily concerned with understanding the "
"correlations between variables. And, as far as it goes that’s perfectly "
"true. But when you look under the hood, so to speak, the underlying "
"mechanics of ANOVA and regression are awfully similar. In fact, if you think "
"about it, you’ve already seen evidence of this. ANOVA and regression both "
"rely heavily on sums of squares (SS), both make use of *F*-tests, and so on. "
"Looking back, it’s hard to escape the feeling that chapters :doc:`../Ch12/"
"Ch12_Regression` and :doc:`../Ch13/Ch13_ANOVA` were a bit repetitive."
msgstr ""
"Noe av det viktigste å forstå når det gjelder ANOVA og regresjon, er at de i "
"bunn og grunn er det samme. På overflaten skulle man kanskje ikke tro at "
"dette er sant. Måten jeg har beskrevet dem på så langt, tyder tross alt på "
"at ANOVA først og fremst handler om å teste for gruppeforskjeller, mens "
"regresjon først og fremst handler om å forstå korrelasjonene mellom "
"variabler. Og det er for så vidt helt sant. Men når du ser under panseret, "
"for å si det sånn, er den underliggende mekanikken i ANOVA og regresjon "
"veldig lik. Hvis du tenker deg om, har du faktisk allerede sett bevis på "
"dette. Både ANOVA og regresjon baserer seg i stor grad på kvadratsummer "
"(SS), begge bruker *F*-tester, og så videre. Når jeg ser tilbake, er det "
"vanskelig å unngå følelsen av at kapitlene :doc:`../Ch12/Ch12_Regression` "
"og :doc:`../Ch13/Ch13_ANOVA` var litt repetitive."

#: ../../Ch14/Ch14_ANOVA2_07.rst:19
msgid ""
"The reason for this is that ANOVA and regression are both kinds of **linear "
"models**. In the case of regression, this is kind of obvious. The regression "
"equation that we use to define the relationship between predictors and "
"outcomes *is* the equation for a straight line, so it’s quite obviously a "
"linear model, with the equation"
msgstr ""
"Grunnen til dette er at ANOVA og regresjon begge er **lineære modeller**. "
"Når det gjelder regresjon, er dette ganske åpenbart. Regresjonsligningen som "
"vi bruker til å definere forholdet mellom prediktorer og utfall *er* "
"ligningen for en rett linje, så det er helt åpenbart en lineær modell, med "
"ligningen"

#: ../../Ch14/Ch14_ANOVA2_07.rst:25 ../../Ch14/Ch14_ANOVA2_07.rst:132
msgid ""
"*Y*\\ :sub:`p` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1p` + *b*\\ :"
"sub:`2` *X*\\ :sub:`2p` + ϵ\\ :sub:`p`"
msgstr ""
"*Y*\\ :sub:`p` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1p` + *b*\\ :"
"sub:`2` *X*\\ :sub:`2p` + ϵ\\ :sub:`p`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:27
msgid ""
"where *Y*\\ :sub:`p` is the outcome value for the *p*-th observation (e.g., "
"*p*-th person), *X*\\ :sub:`1p` is the value of the first predictor for the "
"*p*-th observation, *X*\\ :sub:`2p` is the value of the second predictor for "
"the *p*-th observation, the *b*\\ :sub:`0`, *b*\\ :sub:`1`, and *b*\\ :sub:"
"`2` terms are our regression coefficients, and *ϵ*\\ :sub:`p` is the *p*-th "
"residual. If we ignore the residuals *ϵ*\\ :sub:`p` and just focus on the "
"regression line itself, we get the following formula:"
msgstr ""
"der *Y*\\ :sub:`p` er utfallsverdien for den *p*-te observasjonen (f.eks, "
"*p*-den tredje personen), *X*\\ :sub:`1p` er verdien av den første "
"prediktoren for *p*-den tredje observasjonen, *X*\\ :sub:`2p` er verdien av "
"den andre prediktoren for *p*-den tredje observasjonen, *b*\\ :sub:`0`, "
"*b*\\ :sub:`1` og *b*\\ :sub:`2` er regresjonskoeffisientene våre, og *ϵ*\\ :"
"sub:`p` er *p*-te residuen. Hvis vi ignorerer residuene *ϵ*\\ :sub:`p` og "
"bare fokuserer på selve regresjonslinjen, får vi følgende formel:"

#: ../../Ch14/Ch14_ANOVA2_07.rst:36
msgid ""
"*Ŷ*\\ :sub:`p` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1p` + *b*\\ :"
"sub:`2` *X*\\ :sub:`2p`"
msgstr ""
"*Ŷ*\\ :sub:`p` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1p` + *b*\\ :"
"sub:`2` *X*\\ :sub:`2p`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:38
msgid ""
"where *Ŷ*\\ :sub:`p` is the value of *Y* that the regression line predicts "
"for person *p*, as opposed to the actually-observed value *Y*\\ :sub:`p`. "
"The thing that isn’t immediately obvious is that we can write ANOVA as a "
"linear model as well. However, it’s actually pretty straightforward to do "
"this. Let’s start with a really simple example, rewriting a 2 × 2 factorial "
"ANOVA as a linear model."
msgstr ""
"der *Ŷ*\\ :sub:`p` er den verdien av *Y* som regresjonslinjen predikerer for "
"person *p*, i motsetning til den faktisk observerte verdien *Y*\\ :sub:`p`. "
"Det som ikke umiddelbart er åpenbart, er at vi også kan skrive ANOVA som en "
"lineær modell. Men det er faktisk ganske enkelt å gjøre dette. La oss starte "
"med et veldig enkelt eksempel, der vi omskriver en 2 × 2 faktoriell ANOVA "
"som en lineær modell."

#: ../../Ch14/Ch14_ANOVA2_07.rst:46
msgid "Some data"
msgstr "Noen data"

#: ../../Ch14/Ch14_ANOVA2_07.rst:48
msgid ""
"To make things concrete, let’s suppose that our outcome variable is the "
"``grade`` that a student receives in my class, a ratio-scale variable "
"corresponding to a mark from 0\\% to 100\\%. There are two predictor "
"variables of interest: whether or not the student turned up to lectures (the "
"``attend`` variable) and whether or not the student actually read the "
"textbook (the ``reading`` variable). We’ll say that ``attend = 1`` if the "
"student attended class, and ``attend = 0`` if they did not. Similarly, we’ll "
"say that ``reading = 1`` if the student read the textbook, and ``reading = "
"0`` if they did not."
msgstr ""
"For å gjøre ting konkret, la oss anta at utfallsvariabelen vår er karakteren "
"(``grade``) som en student får i klassen min, en forholdstallsvariabel som "
"tilsvarer en karakter fra 0\\% til 100\\%. Det er to prediktorvariabler som "
"er av interesse: hvorvidt studenten møtte opp til forelesningene eller ikke "
"(variabelen ``attend``) og hvorvidt studenten faktisk leste læreboken eller "
"ikke (variabelen ``reading``). Vi sier at ``attend = 1`` hvis studenten "
"møtte opp til forelesningene, og ``attend = 0`` hvis den ikke gjorde det. På "
"samme måte sier vi at ``reading = 1`` hvis studenten leste læreboken, og "
"``reading = 0`` hvis den ikke gjorde det."

#: ../../Ch14/Ch14_ANOVA2_07.rst:58
msgid ""
"Okay, so far that’s simple enough. The next thing we need to do is to wrap "
"some maths around this (sorry!). For the purposes of this example, let "
"*Y*\\ :sub:`p` denote the ``grade`` of the *p*-th student in the class. This "
"is not quite the same notation that we used earlier in this chapter. "
"Previously, we’ve used the notation *Y*\\ :sub:`rci` to refer to the i-th "
"person in the *r*-th group for predictor 1 (the row factor) and the *c*-th "
"group for predictor 2 (the column factor). This extended notation was really "
"handy for describing how the SS values are calculated, but it’s a pain in "
"the current context, so I’ll switch notation here. Now, the *Y*\\ :sub:`p` "
"notation is visually simpler than *Y*\\ :sub:`rci`, but it has the "
"shortcoming that it doesn’t actually keep track of the group memberships! "
"That is, if I told you that *Y*\\ :sub:`0,0,3` = 35, you’d immediately know "
"that we’re talking about a student (the 3rd such student, in fact) who "
"didn’t attend the lectures (i.e., ``attend = 0``) and didn’t read the "
"textbook (i.e. ``reading = 0``), and who ended up failing the class (``grade "
"= 35``). But if I tell you that *Y*\\ :sub:`p` = 35, all you know is that "
"the *p*-th student didn’t get a good grade. We’ve lost some key information "
"here. Of course, it doesn’t take a lot of thought to figure out how to fix "
"this. What we’ll do instead is introduce two new variables *X*\\ :sub:`1p` "
"and *X*\\ :sub:`2p` that keep track of this information. In the case of our "
"hypothetical student, we know that *X*\\ :sub:`1p` = 0 (i.e., ``attend = "
"0``) and *X*\\ :sub:`2p` = 0 (i.e., ``reading = 0``). So the data might look "
"like this:"
msgstr ""
"Ok, så langt er det enkelt nok. Det neste vi må gjøre er å regne litt "
"matematikk rundt dette (beklager!). I dette eksemplet skal vi la *Y*\\ :sub:"
"`p` betegne karakteren (``grade``) til den *p*-tredje eleven i klassen. "
"Dette er ikke helt den samme notasjonen som vi brukte tidligere i dette "
"kapitlet. Tidligere har vi brukt notasjonen *Y*\\ :sub:`rci` for å referere "
"til den i-te personen i den *r*-te gruppen for prediktor 1 (radfaktoren) og "
"den *c*-te gruppen for prediktor 2 (kolonnefaktoren). Denne utvidede "
"notasjonen var veldig nyttig for å beskrive hvordan kvadratummene (SS) "
"beregnes, men den er litt tungvint i denne sammenhengen, så jeg bytter "
"notasjon her. Notasjonen *Y*\\ :sub:`p` er visuelt enklere enn *Y*\\ :sub:"
"`rci`, men den har den svakheten at den faktisk ikke holder styr på "
"gruppemedlemskapene! Det vil si at hvis jeg fortalte deg at *Y*\\ :sub:"
"`0,0,3` = 35, ville du umiddelbart vite at vi snakker om en student (faktisk "
"den tredje studenten) som ikke deltok på forelesningene (dvs. ``attend = "
"0``) og ikke leste læreboken (dvs. ``reading = 0``), og som endte opp med å "
"stryke i faget (``grade = 35``). Men hvis jeg forteller deg at *Y*\\ :sub:"
"`p` = 35, vet du bare at den *p*-ende studenten ikke fikk en god karakter. "
"Her har vi mistet viktig informasjon. Det krever selvfølgelig ikke mye "
"tankevirksomhet å finne ut hvordan vi kan fikse dette. I stedet introduserer "
"vi to nye variabler, *X*\\ :sub:`1p` og *X*\\ :sub:`2p`, som holder styr på "
"denne informasjonen. I tilfellet med vår hypotetiske student vet vi at "
"*X*\\ :sub:`1p` = 0 (dvs. ``attend = 0``) og *X*\\ :sub:`2p` = 0 (dvs. "
"``reading = 0``). Så dataene kan se slik ut:"

#: ../../Ch14/Ch14_ANOVA2_07.rst:84
msgid "person, p"
msgstr "person, p"

#: ../../Ch14/Ch14_ANOVA2_07.rst:84
msgid "``grade``, *Y*\\ :sub:`p`"
msgstr "``grade``, *Y*\\ :sub:`p`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:84
msgid "``attend``, *X*\\ :sub:`1p`"
msgstr "``attend``, *X*\\ :sub:`1p`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:84
msgid "``reading``, *X*\\ :sub:`2p`"
msgstr "``reading``, *X*\\ :sub:`2p`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:87 ../../Ch14/Ch14_ANOVA2_07.rst:89
#: ../../Ch14/Ch14_ANOVA2_07.rst:91 ../../Ch14/Ch14_ANOVA2_07.rst:93
#: ../../Ch14/Ch14_ANOVA2_07.rst:99 ../../Ch14/Ch14_ANOVA2_07.rst:101
#: ../../Ch14/Ch14_ANOVA2_07.rst:343 ../../Ch14/Ch14_ANOVA2_07.rst:345
#: ../../Ch14/Ch14_ANOVA2_08.rst:15 ../../Ch14/Ch14_ANOVA2_08.rst:17
msgid "1"
msgstr "1"

#: ../../Ch14/Ch14_ANOVA2_07.rst:87
msgid "90"
msgstr "90"

#: ../../Ch14/Ch14_ANOVA2_07.rst:89
msgid "2"
msgstr "2"

#: ../../Ch14/Ch14_ANOVA2_07.rst:89
msgid "87"
msgstr "87"

#: ../../Ch14/Ch14_ANOVA2_07.rst:91
msgid "3"
msgstr "3"

#: ../../Ch14/Ch14_ANOVA2_07.rst:91
msgid "75"
msgstr "75"

#: ../../Ch14/Ch14_ANOVA2_07.rst:91 ../../Ch14/Ch14_ANOVA2_07.rst:93
#: ../../Ch14/Ch14_ANOVA2_07.rst:95 ../../Ch14/Ch14_ANOVA2_07.rst:97
#: ../../Ch14/Ch14_ANOVA2_07.rst:99 ../../Ch14/Ch14_ANOVA2_07.rst:101
#: ../../Ch14/Ch14_ANOVA2_07.rst:341 ../../Ch14/Ch14_ANOVA2_07.rst:343
#: ../../Ch14/Ch14_ANOVA2_07.rst:345 ../../Ch14/Ch14_ANOVA2_08.rst:13
#: ../../Ch14/Ch14_ANOVA2_08.rst:15 ../../Ch14/Ch14_ANOVA2_08.rst:17
#: ../../Ch14/Ch14_ANOVA2_11.rst:543 ../../Ch14/Ch14_ANOVA2_11.rst:545
msgid "0"
msgstr "0"

#: ../../Ch14/Ch14_ANOVA2_07.rst:93
msgid "4"
msgstr "4"

#: ../../Ch14/Ch14_ANOVA2_07.rst:93
msgid "60"
msgstr "60"

#: ../../Ch14/Ch14_ANOVA2_07.rst:95 ../../Ch14/Ch14_ANOVA2_11.rst:562
#: ../../Ch14/Ch14_ANOVA2_11.rst:564
msgid "5"
msgstr "5"

#: ../../Ch14/Ch14_ANOVA2_07.rst:95
msgid "35"
msgstr "35"

#: ../../Ch14/Ch14_ANOVA2_07.rst:97
msgid "6"
msgstr "6"

#: ../../Ch14/Ch14_ANOVA2_07.rst:97
msgid "50"
msgstr "50"

#: ../../Ch14/Ch14_ANOVA2_07.rst:99
msgid "7"
msgstr "7"

#: ../../Ch14/Ch14_ANOVA2_07.rst:99
msgid "65"
msgstr "65"

#: ../../Ch14/Ch14_ANOVA2_07.rst:101
msgid "8"
msgstr "8"

#: ../../Ch14/Ch14_ANOVA2_07.rst:101
msgid "70"
msgstr "70"

#: ../../Ch14/Ch14_ANOVA2_07.rst:104
msgid ""
"This isn’t anything particularly special, of course. It’s exactly the format "
"in which we expect to see our data! See the |rtfm|_ data set. We can use the "
"jamovi analysis ``Descriptives`` to confirm that this data set corresponds "
"to a balanced design, with 2 observations for each combination of ``attend`` "
"and ``reading``. In the same way we can also calculate the mean grade for "
"each combination. This is shown in :numref:`fig-rtfmdescriptives`. Looking "
"at the mean scores, one gets the strong impression that reading the text and "
"attending the class both matter a lot."
msgstr ""
"Dette er selvfølgelig ikke noe spesielt. Det er akkurat det formatet vi "
"forventer å se dataene våre i! Se datasettet |rtfm|_. Vi kan bruke jamovi-"
"analysen ``Descriptives`` for å bekrefte at dette datasettet tilsvarer et "
"balansert design, med 2 observasjoner for hver kombinasjon av ``attend`` og "
"``reading``. På samme måte kan vi også beregne gjennomsnittskarakteren for "
"hver kombinasjon. Dette er vist i :numref:`fig-rtfmdescriptives`. Når man "
"ser på gjennomsnittskarakterene, får man et sterkt inntrykk av at både det å "
"lese teksten og det å delta i undervisningen betyr mye."

#: ../../Ch14/Ch14_ANOVA2_07.rst:115
msgid "jamovi descriptives for the |rtfm|_ data set"
msgstr "jamovi-deskriptivstatistikk for datasettet |rtfm|_"

#: ../../Ch14/Ch14_ANOVA2_07.rst:119
msgid "jamovi descriptives for the |rtfm|_ dataset"
msgstr "jamovi-beskrivelser for datasettet |rtfm|_"

#: ../../Ch14/Ch14_ANOVA2_07.rst:124
msgid "ANOVA with binary factors as a regression model"
msgstr "ANOVA med binære faktorer som regresjonsmodell"

#: ../../Ch14/Ch14_ANOVA2_07.rst:126
msgid ""
"Okay, let’s get back to talking about the mathematics. We now have our data "
"expressed in terms of three numeric variables: the continuous variable *Y* "
"and the two binary variables *X*\\ :sub:`1` and *X*\\ :sub:`2`. What I want "
"you to recognise is that our 2 × 2 factorial ANOVA is *exactly* equivalent "
"to the regression model:"
msgstr ""
"La oss gå tilbake til matematikken. Vi har nå dataene våre uttrykt i form av "
"tre numeriske variabler: den kontinuerlige variabelen *Y* og de to binære "
"variablene *X*\\ :sub:`1` og *X*\\ :sub:`2`. Det jeg vil at du skal forstå, "
"er at vår 2 × 2-faktorielle ANOVA er *nøyaktig* ekvivalent med "
"regresjonsmodellen:"

#: ../../Ch14/Ch14_ANOVA2_07.rst:134
msgid ""
"This is, of course, the exact same equation that I used earlier to describe "
"a two-predictor regression model! The only difference is that *X*\\ :sub:`1` "
"and *X*\\ :sub:`2` are now *binary* variables (i.e., values can only be 0 or "
"1), whereas in a regression analysis we expect that *X*\\ :sub:`1` and "
"*X*\\ :sub:`2` will be continuous. There’s a couple of ways I could try to "
"convince you of this. One possibility would be to do a lengthy mathematical "
"exercise proving that the two are identical. However, I’m going to go out on "
"a limb and guess that most of the readership of this book will find that "
"annoying rather than helpful. Instead, I’ll explain the basic ideas and then "
"rely on jamovi to show that ANOVA analyses and regression analyses aren’t "
"just similar, they’re identical for all intents and purposes. Let’s start by "
"running this as an ANOVA. To do this, we’ll use the |rtfm|_ data set, and :"
"numref:`fig-factorialanova6` shows what we get when we run the analysis in "
"jamovi."
msgstr ""
"Dette er selvfølgelig nøyaktig den samme ligningen som jeg brukte tidligere "
"for å beskrive en regresjonsmodell med to prediktorer! Den eneste "
"forskjellen er at *X*\\ :sub:`1` og *X*\\ :sub:`2` nå er *binære* variabler "
"(dvs. at verdiene bare kan være 0 eller 1), mens vi i en regresjonsanalyse "
"forventer at *X*\\ :sub:`1` og *X*\\ :sub:`2` vil være kontinuerlige. Det er "
"flere måter jeg kan prøve å overbevise deg om dette på. En mulighet ville "
"være å gjøre en lang matematisk øvelse for å bevise at de to er identiske. "
"Jeg tar imidlertid sjansen på å gjette at de fleste som leser denne boken, "
"vil synes at det er mer irriterende enn nyttig. I stedet vil jeg forklare de "
"grunnleggende ideene og deretter bruke jamovi til å vise at ANOVA-analyser "
"og regresjonsanalyser ikke bare ligner på hverandre, men at de i praksis er "
"identiske. La oss starte med å kjøre dette som en ANOVA. For å gjøre dette "
"bruker vi datasettet |rtfm|_, og :numref:`fig-factorialanova6` viser hva vi "
"får når vi kjører analysen i jamovi."

#: ../../Ch14/Ch14_ANOVA2_07.rst:151
msgid "ANOVA with two factors (only main effects, without their interaction)"
msgstr "ANOVA med to faktorer (kun hovedeffekter, uten interaksjon)"

#: ../../Ch14/Ch14_ANOVA2_07.rst:155
msgid ""
"ANOVA of the |rtfm|_ data set in jamovi: Model with two factors ``attend`` "
"and ``reading`` but without the interaction term for these two factors"
msgstr ""
"ANOVA av datasettet |rtfm|_ i jamovi: Modell med to faktorer, ``attend`` og "
"``reading``, men uten interaksjonstermen for disse to faktorene"

#: ../../Ch14/Ch14_ANOVA2_07.rst:160
msgid ""
"So, by reading the key numbers off the ANOVA table and the mean scores that "
"we presented earlier, we can see that the students obtained a higher grade "
"if they attended class (*F*\\(1,5) = 21.6, *p* = 0.0056) and if they read "
"the textbook: *F*\\(1,5) = 52.3,*p* = 0.0008. Let’s make a note of those *p*-"
"values and those *F*-statistics."
msgstr ""
"Ved å lese nøkkeltallene fra ANOVA-tabellen og gjennomsnittsskårene som vi "
"presenterte tidligere, kan vi se at elevene fikk en bedre karakter hvis de "
"deltok i undervisningen (*F*\\(1,5) = 21,6, *p* = 0,0056) og hvis de leste "
"læreboken: *F*\\(1,5) = 52,3, *p* = 0,0008. La oss notere oss disse *p*-"
"verdiene og *F*-statistikkene."

#: ../../Ch14/Ch14_ANOVA2_07.rst:166
msgid ""
"Now let’s think about the same analysis from a linear regression "
"perspective. In the |rtfm|_ data set, we have encoded ``attend`` and "
"``reading`` as if they were numeric predictors. In this case, this is "
"perfectly acceptable. There really is a sense in which a student who turns "
"up to class (i.e. ``attend = 1``) has in fact done “more attendance” than a "
"student who does not (i.e. ``attend = 0``). So it’s not at all unreasonable "
"to include it as a predictor in a regression model. It’s a little unusual, "
"because the predictor only takes on two possible values, but it doesn’t "
"violate any of the assumptions of linear regression. And it’s easy to "
"interpret. If the regression coefficient for ``attend`` is greater than 0 it "
"means that students that attend lectures get higher grades. If it’s less "
"than zero then students attending lectures get lower grades. The same is "
"true for our ``reading`` variable."
msgstr ""
"La oss nå se på den samme analysen fra et lineært regresjonsperspektiv. I "
"datasettet |rtfm|_ har vi kodet ``attend`` og ``reading`` som om de var "
"numeriske prediktorer. I dette tilfellet er dette helt akseptabelt. Det er "
"faktisk slik at en student som møter opp til timene (dvs. ``attend = 1``), "
"faktisk har vært «mer til stede» enn en student som ikke møter opp (dvs. "
"``attend = 0``). Så det er slett ikke urimelig å inkludere det som en "
"prediktor i en regresjonsmodell. Det er litt uvanlig, fordi prediktoren bare "
"har to mulige verdier, men det bryter ikke med noen av forutsetningene for "
"lineær regresjon. Og det er enkelt å tolke. Hvis regresjonskoeffisienten for "
"``attend`` er større enn 0, betyr det at studenter som deltar på "
"forelesninger, får høyere karakterer. Hvis den er mindre enn null, får "
"studenter som deltar på forelesninger, lavere karakterer. Det samme gjelder "
"for variabelen ``reading``."

#: ../../Ch14/Ch14_ANOVA2_07.rst:179
msgid ""
"Wait a second though. *Why* is this true? It’s something that is intuitively "
"obvious to everyone who has taken a few stats classes and is comfortable "
"with the maths, but it *isn’t* clear to everyone else at first pass. To see "
"why this is true, it helps to look closely at a few specific students. Let’s "
"start by considering the 6th and 7th students in our data set (i.e. p = 6 "
"and p = 7). Neither one has read the textbook, so in both cases we can set "
"``reading = 0``. Or, to say the same thing in our mathematical notation, we "
"observe *X*\\ :sub:`2,6` = 0 and *X*\\ :sub:`2,7` = 0. However, student "
"number 7 did turn up to lectures (i.e., ``attend = 1``, *X*\\ :sub:`1,7` = "
"1) whereas student number 6 did not (i.e., ``attend = 0``, *X*\\ :sub:`1,6` "
"= 0). Now let’s look at what happens when we insert these numbers into the "
"general formula for our regression line. For student number 6, the "
"regression predicts that:"
msgstr ""
"Men vent litt. *Hvorfor* er dette sant? Det er noe som er intuitivt åpenbart "
"for alle som har tatt noen statistikkurs og er komfortable med matematikken, "
"men det *er* ikke klart for alle andre ved første gjennomkjøring. For å se "
"hvorfor det er slik, er det nyttig å se nærmere på noen spesifikke "
"studenter. La oss begynne med å se på 6. og 7. elev i datasettet vårt (dvs. "
"p = 6 og p = 7). Ingen av dem har lest læreboken, så i begge tilfeller kan "
"vi sette ``reading = 0``. Eller, for å si det samme i vår matematiske "
"notasjon, vi observerer *X*\\ :sub:`2,6` = 0 og *X*\\ :sub:`2,7` = 0. "
"Student nummer 7 møtte imidlertid opp til forelesningene (dvs. ``attend = "
"1``, *X*\\ :sub:`1,7` = 1), mens student nummer 6 ikke gjorde det (dvs. "
"``attend = 0``, *X*\\ :sub:`1,6` = 0). La oss nå se på hva som skjer når vi "
"setter disse tallene inn i den generelle formelen for regresjonslinjen vår. "
"For elev nummer 6 predikerer regresjonen at:"

#: ../../Ch14/Ch14_ANOVA2_07.rst:192
msgid ""
"*Ŷ*\\ :sub:`6` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1,6` +  *b*\\ :"
"sub:`2` *X*\\ :sub:`2,6`"
msgstr ""
"*Ŷ*\\ :sub:`6` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1,6` +  *b*\\ :"
"sub:`2` *X*\\ :sub:`2,6`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:193
msgid ""
"*Ŷ*\\ :sub:`6` = *b*\\ :sub:`0` + *b*\\ :sub:`1` · 0 + *b*\\ :sub:`2` · 0"
msgstr ""
"*Ŷ*\\ :sub:`6` = *b*\\ :sub:`0` + *b*\\ :sub:`1` · 0 + *b*\\ :sub:`2` · 0"

#: ../../Ch14/Ch14_ANOVA2_07.rst:194
msgid "*Ŷ*\\ :sub:`6` = *b*\\ :sub:`0`"
msgstr "*Ŷ*\\ :sub:`6` = *b*\\ :sub:`0`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:196
msgid ""
"So we’re expecting that this student will obtain a grade corresponding to "
"the value of the intercept term *b*\\ :sub:`0`. What about student 7? This "
"time when we insert the numbers into the formula for the regression line, we "
"obtain the following:"
msgstr ""
"Vi forventer altså at denne eleven vil få en karakter som tilsvarer verdien "
"av termen for intercept *b*\\ :sub:`0`. Hva med student 7? Når vi denne "
"gangen setter inn tallene i formelen for regresjonslinjen, får vi følgende:"

#: ../../Ch14/Ch14_ANOVA2_07.rst:201
msgid ""
"*Ŷ*\\ :sub:`7` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1,7` +  *b*\\ :"
"sub:`2` *X*\\ :sub:`2,7`"
msgstr ""
"*Ŷ*\\ :sub:`7` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1,7` +  *b*\\ :"
"sub:`2` *X*\\ :sub:`2,7`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:202
msgid ""
"*Ŷ*\\ :sub:`7` = *b*\\ :sub:`0` + *b*\\ :sub:`1` · 1 + *b*\\ :sub:`2` · 0"
msgstr ""
"*Ŷ*\\ :sub:`7` = *b*\\ :sub:`0` + *b*\\ :sub:`1` · 1 + *b*\\ :sub:`2` · 0"

#: ../../Ch14/Ch14_ANOVA2_07.rst:203
msgid "*Ŷ*\\ :sub:`7` = *b*\\ :sub:`0` + *b*\\ :sub:`1`"
msgstr "*Ŷ*\\ :sub:`7` = *b*\\ :sub:`0` + *b*\\ :sub:`1`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:205
msgid ""
"Because this student attended class, the predicted grade is equal to the "
"intercept term *b*\\ :sub:`0` *plus* the coefficient associated with the "
"``attend`` variable, *b*\\ :sub:`1`. So, if *b*\\ :sub:`1` is greater than "
"zero, we’re expecting that the students who turn up to lectures will get "
"higher grades than those students who don’t. If this coefficient is negative "
"we’re expecting the opposite: students who turn up at class end up "
"performing much worse. In fact, we can push this a little bit further. What "
"about student number 1, who turned up to class (*X*\\ :sub:`1,1` = 1) *and* "
"read the textbook (*X*\\ :sub:`2,1` = 1)? If we plug these numbers into the "
"regression we get:"
msgstr ""
"Fordi denne studenten møtte til forelesningene, er den predikerte karakteren "
"lik termen for intercept *b*\\ :sub:`0` *pluss* koeffisienten knyttet til "
"variabelen ``attend``, *b*\\ :sub:`1`. Hvis *b*\\ :sub:`1` er større enn "
"null, forventer vi altså at de studentene som møter opp til forelesningene, "
"får bedre karakterer enn de som ikke møter opp. Hvis koeffisienten er "
"negativ, forventer vi det motsatte: Studenter som møter opp til "
"forelesningene, ender opp med å prestere mye dårligere. Vi kan faktisk dra "
"dette litt lenger. Hva med elev nummer 1, som møtte opp til timen (*X*\\ :"
"sub:`1,1` = 1) *og* leste læreboka (*X*\\ :sub:`2,1` = 1)? Hvis vi setter "
"disse tallene inn i regresjonen, får vi:"

#: ../../Ch14/Ch14_ANOVA2_07.rst:215
msgid ""
"*Ŷ*\\ :sub:`1` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1,1` +  *b*\\ :"
"sub:`2` *X*\\ :sub:`2,1`"
msgstr ""
"*Ŷ*\\ :sub:`1` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`1,1` +  *b*\\ :"
"sub:`2` *X*\\ :sub:`2,1`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:216
msgid ""
"*Ŷ*\\ :sub:`1` = *b*\\ :sub:`0` + *b*\\ :sub:`1` · 1 + *b*\\ :sub:`2` · 1"
msgstr ""
"*Ŷ*\\ :sub:`1` = *b*\\ :sub:`0` + *b*\\ :sub:`1` · 1 + *b*\\ :sub:`2` · 1"

#: ../../Ch14/Ch14_ANOVA2_07.rst:217
msgid "*Ŷ*\\ :sub:`1` = *b*\\ :sub:`0` + *b*\\ :sub:`1` + *b*\\ :sub:`2`"
msgstr "*Ŷ*\\ :sub:`1` = *b*\\ :sub:`0` + *b*\\ :sub:`1` + *b*\\ :sub:`2`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:219
msgid ""
"So if we assume that attending class helps you get a good grade (i.e., "
"*b*\\ :sub:`1` > 0) and if we assume that reading the textbook also helps "
"you get a good grade (i.e., *b*\\ :sub:`2` > 0), then our expectation is "
"that student 1 will get a grade that that is higher than student 6 and "
"student 7."
msgstr ""
"Så hvis vi antar at det å delta i undervisningen hjelper deg å få en god "
"karakter (dvs. *b*\\ :sub:`1` > 0), og hvis vi antar at det å lese læreboken "
"også hjelper deg å få en god karakter (dvs. *b*\\ :sub:`2` > 0), forventer "
"vi at student 1 vil få en karakter som er høyere enn student 6 og student 7."

#: ../../Ch14/Ch14_ANOVA2_07.rst:224
msgid ""
"And at this point you won’t be at all suprised to learn that the regression "
"model predicts that student 3, who read the book but didn’t attend lectures, "
"will obtain a grade of *b*\\ :sub:`2` + *b*\\ :sub:`0`. I won’t bore you "
"with yet another regression formula. Instead, what I’ll do is show you the "
"following table of *expected grades*:"
msgstr ""
"Og nå blir du ikke overrasket over å høre at regresjonsmodellen predikerer "
"at student 3, som har lest boken, men ikke deltatt på forelesningene, vil få "
"en karakter på *b*\\ :sub:`2` + *b*\\ :sub:`0`. Jeg skal ikke kjede deg med "
"enda en regresjonsformel. I stedet vil jeg vise deg følgende tabell over "
"*forventede karakterer*:"

#: ../../Ch14/Ch14_ANOVA2_07.rst:231
msgid "read the textbook?"
msgstr "lest læreboken?"

#: ../../Ch14/Ch14_ANOVA2_07.rst:233
msgid "no"
msgstr "nei"

#: ../../Ch14/Ch14_ANOVA2_07.rst:233
msgid "yes"
msgstr "ja"

#: ../../Ch14/Ch14_ANOVA2_07.rst:235
msgid "**attended?**"
msgstr "**oppmøte?**"

#: ../../Ch14/Ch14_ANOVA2_07.rst:235
msgid "**no**"
msgstr "**nei**"

#: ../../Ch14/Ch14_ANOVA2_07.rst:235
msgid "*b*\\ :sub:`0`"
msgstr "*b*\\ :sub:`0`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:235
msgid "*b*\\ :sub:`0` + *b*\\ :sub:`2`"
msgstr "*b*\\ :sub:`0` + *b*\\ :sub:`2`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:237
msgid "**yes**"
msgstr "**ja**"

#: ../../Ch14/Ch14_ANOVA2_07.rst:237
msgid "*b*\\ :sub:`0` + *b*\\ :sub:`1`"
msgstr "*b*\\ :sub:`0` + *b*\\ :sub:`1`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:237
msgid "*b*\\ :sub:`0` + *b*\\ :sub:`1` + *b*\\ :sub:`2`"
msgstr "*b*\\ :sub:`0` + *b*\\ :sub:`1` + *b*\\ :sub:`2`"

#: ../../Ch14/Ch14_ANOVA2_07.rst:240
msgid ""
"As you can see, the intercept term *b*\\ :sub:`0` acts like a kind of "
"“baseline” grade that you would expect from those students who don’t take "
"the time to attend class or read the textbook. Similarly, *b*\\ :sub:`1` "
"represents the boost that you’re expected to get if you come to class, and "
"*b*\\ :sub:`2` represents the boost that comes from reading the textbook. In "
"fact, if this were an ANOVA you might very well want to characterise *b*\\ :"
"sub:`1` as the main effect of attendance, and *b*\\ :sub:`2` as the main "
"effect of reading! In fact, for a simple 2 × 2 ANOVA that’s *exactly* how it "
"plays out."
msgstr ""
"Som du kan se, fungerer skjæringspunktet (*intercept term*) *b*\\ :sub:`0` "
"som en slags «grunn»-karakter (``grade``) som du kan forvente av de "
"studentene som ikke tar seg tid til å delta i undervisningen eller lese "
"læreboken. På samme måte representerer *b*\\ :sub:`1` det løftet du "
"forventes å få hvis du kommer til timen, og *b*\\ :sub:`2` representerer det "
"løftet du får ved å lese læreboken. Hvis dette var en ANOVA, ville du "
"kanskje ha karakterisert *b*\\ :sub:`1` som hovedeffekten av ``attend``, og "
"*b*\\ :sub:`2` som hovedeffekten av ``reading``! For en enkel 2 × 2 ANOVA er "
"det faktisk *nøyaktig* slik det ser ut."

#: ../../Ch14/Ch14_ANOVA2_07.rst:249
msgid ""
"Okay, now that we’re really starting to see why ANOVA and regression are "
"basically the same thing, let’s actually run our regression using the |rtfm|"
"_ data set and the jamovi regression analysis to convince ourselves that "
"this is really true. Running the regression in the usual way gives the "
"results shown in :numref:`fig-factorialanova7`."
msgstr ""
"Ok, nå som vi virkelig begynner å forstå hvorfor ANOVA og regresjon i bunn "
"og grunn er det samme, la oss faktisk kjøre regresjonen vår ved hjelp av "
"datasettet |rtfm|_ og jamovi-regresjonsanalysen for å overbevise oss selv om "
"at dette virkelig er sant. Å kjøre regresjonen på vanlig måte gir "
"resultatene som vises i :numref:`fig-factorialanova7`."

#: ../../Ch14/Ch14_ANOVA2_07.rst:257
msgid "Regression analysis for the rtfm dataset, unsaturated"
msgstr "Regresjonsanalyse for rtfm-datasett, umettet (*unsaturated*)"

#: ../../Ch14/Ch14_ANOVA2_07.rst:261
msgid ""
"Regression analysis for the |rtfm|_ data set in jamovi: Model with two "
"factors ``attend`` and ``reading`` but without the interaction term for "
"these two factors"
msgstr ""
"Regresjonsanalyse for datasettet |rtfm|_ i jamovi: Modell med to faktorer, "
"``attend`` og ``reading``, men uten interaksjonstermen for disse to faktorene"

#: ../../Ch14/Ch14_ANOVA2_07.rst:267
msgid ""
"There’s a few interesting things to note here. First, notice that the "
"intercept term is 43.5 which is close to the “group” mean of 42.5 observed "
"for those two students who didn’t read the text or attend class. Second, "
"notice that we have the regression coefficient of *b*\\ :sub:`1` = 18.0 for "
"the variable ``attend``, suggesting that those students that attended class "
"scored 18\\% higher than those who didn’t. So our expectation would be that "
"those students who turned up to class but didn’t read the textbook would "
"obtain a grade of *b*\\ :sub:`0` + *b*\\ :sub:`1`, which is equal to 43.5 + "
"18.0 = 61.5. You can verify for yourself that the same thing happens when we "
"look at the students that read the textbook."
msgstr ""
"Det er et par interessante ting å legge merke til her. For det første legger "
"vi merke til at skjæringspunktet (*intercept*) er 43,5, noe som ligger nær "
"«gruppegjennomsnittet» på 42,5 som ble observert for de to studentene som "
"ikke leste teksten eller deltok i undervisningen. For det andre legger vi "
"merke til at regresjonskoeffisienten *b*\\ :sub:`1` = 18,0 for variabelen "
"``attend``, noe som tyder på at de studentene som var til stede i timene, "
"fikk 18\\% høyere poengsum enn de som ikke var til stede. Vi forventer altså "
"at de studentene som møtte opp til timen, men ikke leste læreboken, ville "
"fått en karakter på *b*\\ :sub:`0` + *b*\\ :sub:`1`, noe som tilsvarer 43,5 "
"+ 18,0 = 61,5. Du kan selv kontrollere at det samme skjer når vi ser på "
"elevene som har lest læreboken."

#: ../../Ch14/Ch14_ANOVA2_07.rst:278
msgid ""
"Actually, we can push a little further in establishing the equivalence of "
"our ANOVA and our regression. Look at the *p*-values associated with the "
"``attend`` variable and the ``reading`` variable in the regression output. "
"They’re identical to the ones we encountered earlier when running the ANOVA. "
"This might seem a little surprising, since the test used when running our "
"regression model calculates a *t*-statistic and the ANOVA calculates an *F*-"
"statistic. However, if you can remember all the way back to chapter :doc:`../"
"Ch07/Ch07_Probability`, I mentioned that there’s a relationship between the "
"*t*-distribution and the *F*-distribution. If you have some quantity that is "
"distributed according to a *t*-distribution with *k* degrees of freedom and "
"you square it, then this new squared quantity follows an *F*-distribution "
"whose degrees of freedom are 1 and *k*. We can check this with respect to "
"the *t*-statistics in our regression model. For the ``attend`` variable we "
"get a *t*-value of 4.65. If we square this number we end up with 21.6, which "
"matches the corresponding *F*-statistic in our ANOVA."
msgstr ""
"Vi kan faktisk gå litt lenger når det gjelder å fastslå ekvivalensen mellom "
"ANOVA og regresjon. Se på *p*-verdiene som er knyttet til variablene "
"``attend`` og ``reading`` i regresjonsresultatet. De er identiske med dem vi "
"fant tidligere da vi kjørte ANOVA. Dette kan virke litt overraskende, siden "
"testen som ble brukt ved kjøring av regresjonsmodellen vår, beregner en *t*-"
"statistikk, mens ANOVA-en beregner en *F*-statistikk. Men hvis du husker "
"helt tilbake til kapittel :doc:`../Ch07/Ch07_Probability`, nevnte jeg at det "
"er en sammenheng mellom *t*-fordelingen og *F*-fordelingen. Hvis du har en "
"størrelse som er fordelt i henhold til en *t*-fordeling med *k* "
"frihetsgrader og du kvadrerer den, så følger den nye kvadrerte størrelsen en "
"*F*-fordeling med frihetsgradene 1 og *k*. Vi kan sjekke dette med hensyn "
"til *t*-statistikken i regresjonsmodellen vår. For variabelen ``attend`` får "
"vi en *t*-verdi på 4,65. Hvis vi kvadrerer dette tallet, får vi 21,6, noe "
"som samsvarer med den tilsvarende *F*-statistikken i vår ANOVA."

#: ../../Ch14/Ch14_ANOVA2_07.rst:294
msgid ""
"Finally, one last thing you should know. Because jamovi understands the fact "
"that ANOVA and regression are both examples of linear models, it lets you "
"extract the classic ANOVA table from your regression model using the "
"``Linear Regression`` - ``Model Coefficients`` - ``Omnibus Test`` - ``ANOVA "
"test``, and this will give you the table shown in :numref:`fig-"
"factorialanova8`."
msgstr ""
"Til slutt er det en siste ting du bør vite. Fordi jamovi forstår at ANOVA og "
"regresjon begge er eksempler på lineære modeller, lar den deg trekke ut den "
"klassiske ANOVA-tabellen fra regresjonsmodellen din ved hjelp av ``Linear "
"Regression`` - ``Model Coefficients`` - ``Omnibus Test`` - ``ANOVA test``, "
"og dette vil gi deg tabellen som vises i :numref:`fig-factorialanova8`."

#: ../../Ch14/Ch14_ANOVA2_07.rst:302
msgid "Omnibus ANOVA Test"
msgstr "Omnibus-ANOVA-test"

#: ../../Ch14/Ch14_ANOVA2_07.rst:306
msgid ""
"Results table showing the Omnibus ANOVA Test from the jamovi regression "
"analysis using the |rtfm|_ dataset"
msgstr ""
"Resultattabell som viser Omnibus-ANOVA-testen fra jamovi-regresjonsanalysen "
"ved bruk av datasettet |rtfm|_"

#: ../../Ch14/Ch14_ANOVA2_07.rst:312
msgid "How to encode non binary factors as contrasts"
msgstr "Hvordan kode ikke-binære faktorer som kontraster"

#: ../../Ch14/Ch14_ANOVA2_07.rst:314
msgid ""
"At this point, I’ve shown you how we can view a 2 × 2 ANOVA into a linear "
"model. And it’s pretty easy to see how this generalises to a 2 × 2 × 2 ANOVA "
"or a 2 × 2 × 2 × 2 ANOVA. It’s the same thing, really. You just add a new "
"binary variable for each of your factors. Where it begins to get trickier is "
"when we consider factors that have more than two levels. Consider, for "
"instance, the 3 × 2 ANOVA that we ran earlier in this chapter using the |"
"clinicaltrial|_ data set. How can we convert the three-level ``drug`` factor "
"|nominal| into a numerical form that is appropriate for a regression?"
msgstr ""
"Nå har jeg vist deg hvordan vi kan se en 2 × 2 ANOVA som en lineær modell. "
"Og det er ganske enkelt å se hvordan dette kan generaliseres til en 2 × 2 × "
"2 ANOVA eller en 2 × 2 × 2 × 2 × 2 ANOVA. Det er egentlig det samme. Du "
"legger bare til en ny binær variabel for hver av faktorene dine. Det "
"begynner å bli vanskeligere når vi vurderer faktorer som har mer enn to "
"nivåer. Tenk for eksempel på 3 × 2 ANOVA som vi kjørte tidligere i dette "
"kapittelet ved hjelp av datasettet |clinicaltrial|_. Hvordan kan vi "
"konvertere faktoren ``drug`` |nominal| med tre nivåer til en numerisk form "
"som passer for en regresjon?"

#: ../../Ch14/Ch14_ANOVA2_07.rst:323
msgid ""
"The answer to this question is pretty simple, actually. All we have to do is "
"realise that a three-level factor can be redescribed as *two* binary "
"variables. Suppose, for instance, I were to create a new binary variable "
"called ``druganxifree``. Whenever the ``drug`` variable is equal to "
"``anxifree`` we set ``druganxifree = 1``. Otherwise, we set ``druganxifree = "
"0``. This variable sets up a **contrast**, in this case between ``anxifree`` "
"and the other two drugs. By itself, of course, the ``druganxifree`` contrast "
"isn’t enough to fully capture all of the information in our ``drug`` "
"variable. We need a second contrast, one that allows us to distinguish "
"between ``joyzepam`` and the ``placebo``. To do this, we can create a second "
"binary contrast, called ``drugjoyzepam``, which equals 1 if the ``drug`` is "
"``joyzepam`` and 0 if it is not. Taken together, these two contrasts allows "
"us to perfectly discriminate between all three possible levels of ``drug``. "
"The table below illustrates this:"
msgstr ""
"Svaret på dette spørsmålet er egentlig ganske enkelt. Alt vi trenger å gjøre "
"er å innse at en faktor på tre nivåer kan beskrives som *to* binære "
"variabler. Anta for eksempel at jeg oppretter en ny binær variabel som heter "
"``druganxifree``. Når variabelen ``drug`` er lik ``anxifree``, setter vi "
"``druganxifree = 1``. Ellers setter vi ``druganxifree = 0``. Denne "
"variabelen setter opp en **kontrast**, i dette tilfellet mellom ``anxifree`` "
"og de to andre legemiddelene. Kontrasten ``druganxifree`` er selvsagt ikke i "
"seg selv nok til å fange opp all informasjonen i variabelen ``drug``. Vi "
"trenger en kontrast til, en som lar oss skille mellom ``joyzepam`` og "
"``placebo``. For å gjøre dette kan vi lage en annen binær kontrast, kalt "
"``drugjoyzepam``, som er lik 1 hvis ``drug`` er ``joyzepam``, og 0 hvis det "
"ikke er det. Til sammen gjør disse to kontrastene det mulig for oss å "
"diskriminere perfekt mellom alle de tre mulige nivåene av ``drug``. Tabellen "
"nedenfor illustrerer dette:"

#: ../../Ch14/Ch14_ANOVA2_07.rst:339 ../../Ch14/Ch14_ANOVA2_08.rst:11
msgid "``drug``"
msgstr "``drug``"

#: ../../Ch14/Ch14_ANOVA2_07.rst:339 ../../Ch14/Ch14_ANOVA2_08.rst:11
msgid "``druganxifree``"
msgstr "``druganxifree``"

#: ../../Ch14/Ch14_ANOVA2_07.rst:339 ../../Ch14/Ch14_ANOVA2_08.rst:11
msgid "``drugjoyzepam``"
msgstr "``drugjoyzepam``"

#: ../../Ch14/Ch14_ANOVA2_07.rst:341 ../../Ch14/Ch14_ANOVA2_08.rst:13
msgid "``placebo``"
msgstr "``placebo``"

#: ../../Ch14/Ch14_ANOVA2_07.rst:343 ../../Ch14/Ch14_ANOVA2_08.rst:15
msgid "``anxifree``"
msgstr "``anxifree``"

#: ../../Ch14/Ch14_ANOVA2_07.rst:345 ../../Ch14/Ch14_ANOVA2_08.rst:17
msgid "``joyzepam``"
msgstr "``joyzepam``"

#: ../../Ch14/Ch14_ANOVA2_07.rst:348
msgid ""
"If the ``drug`` administered to a patient is a ``placebo`` then both of the "
"two contrast variables will equal 0. If the ``drug`` is ``anxifree`` then "
"the ``druganxifree`` variable will equal 1, and ``drugjoyzepam`` will be 0. "
"The reverse is true for ``joyzepam``: ``drugjoyzepam`` is 1 and "
"``druganxifree`` is 0."
msgstr ""
"Hvis legemiddelet som gis (``drug``) til en pasient er ``placebo``, vil "
"begge de to kontrastvariablene være lik 0. Hvis ``drug`` er ``anxifree``, "
"vil variabelen ``druganxifree`` være lik 1, og ``drugjoyzepam`` vil være lik "
"0. Det omvendte gjelder for ``joyzepam``: ``drugjoyzepam`` er lik 1, og "
"``druganxifree`` er lik 0."

#: ../../Ch14/Ch14_ANOVA2_07.rst:354
msgid ""
"Creating contrast variables is not too difficult to do using the jamovi "
"``Compute`` command to create a new variable. For example, to create the "
"``druganxifree`` variable, write this logical expression in the formula box: "
"``IF(drug == 'anxifree', 1, 0)``. Similarly, to create the new variable "
"``drugjoyzepam`` use this logical expression: ``IF(drug == 'joyzepam', 1, "
"0)``. Likewise for ``therapyCBT``: ``IF(therapy == 'CBT', 1, 0)``. You can "
"see these new variables, and the corresponding logical expressions, in the |"
"clinicaltrial2|_ data set."
msgstr ""
"Det er ikke så vanskelig å opprette kontrastvariabler ved å bruke jamovi "
"``Compute``-kommandoen for å opprette en ny variabel. For å opprette "
"variabelen ``druganxifree`` skriver du for eksempel dette logiske uttrykket "
"i formelboksen: ``IF(drug == 'anxifree', 1, 0)``. På samme måte bruker du "
"dette logiske uttrykket for å opprette den nye variabelen ``drugjoyzepam``: "
"``IF(drug == 'joyzepam', 1, 0)``. På samme måte for ``therapyCBT``: "
"``IF(therapy == 'CBT', 1, 0)``. Du kan se disse nye variablene og de "
"tilhørende logiske uttrykkene i datasettet |clinicaltrial2|_."

#: ../../Ch14/Ch14_ANOVA2_07.rst:363
msgid ""
"We have now recoded our three-level factor in terms of two binary variables, "
"and we’ve already seen that ANOVA and regression behave the same way for "
"binary variables. However, there are some additional complexities that arise "
"in this case, which we’ll discuss in the next section."
msgstr ""
"Vi har nå omkodet faktoren vår på tre nivåer til to binære variabler, og vi "
"har allerede sett at ANOVA og regresjon oppfører seg på samme måte for "
"binære variabler. Det er imidlertid noen ekstra kompleksiteter som oppstår i "
"dette tilfellet, som vi skal diskutere i neste avsnitt."

#: ../../Ch14/Ch14_ANOVA2_07.rst:369
msgid "The equivalence between ANOVA and regression for non-binary factors"
msgstr "Ekvivalensen mellom ANOVA og regresjon for ikke-binære faktorer"

#: ../../Ch14/Ch14_ANOVA2_07.rst:371
msgid ""
"Now we have two different versions of the same data set. Our original data "
"in which the ``drug`` variable from the |clinicaltrial|_ data set is "
"expressed as a single three-level factor, and the |clinicaltrial2|_ data set "
"in which it is expanded into two binary contrasts. Once again, the thing "
"that we want to demonstrate is that our original 3 × 2 factorial ANOVA is "
"equivalent to a regression model applied to the contrast variables. Let’s "
"start by re-running the ANOVA, with results shown in :numref:`fig-"
"factorialanova9`."
msgstr ""
"Nå har vi to ulike versjoner av det samme datasettet. Våre opprinnelige data "
"der variabelen ``drug`` fra datasettet |clinicaltrial|_ er uttrykt som en "
"enkelt faktor på tre nivåer, og datasettet |clinicaltrial2|_ der den er "
"utvidet til to binære kontraster. Nok en gang ønsker vi å demonstrere at vår "
"opprinnelige 3 × 2-faktorielle ANOVA tilsvarer en regresjonsmodell som "
"brukes på kontrastvariablene. La oss starte med å kjøre ANOVAen på nytt, med "
"resultatene vist i :numref:`fig-factorialanova9`."

#: ../../Ch14/Ch14_ANOVA2_07.rst:381
msgid "ANOVA results for the |clinicaltrial| dataset: Unsaturated model"
msgstr ""
"ANOVA-resultater for datasettet |clinicaltrial|: Umettet (*unsaturated*) "
"modell"

#: ../../Ch14/Ch14_ANOVA2_07.rst:385
msgid ""
"jamovi ANOVA results for the |clinicaltrial|_ dataset: Unsaturated model "
"with the two main effects for ``drug`` and ``therapy`` but without an "
"interaction component for these two factors"
msgstr ""
"jamovi ANOVA-resultater for datasettet |clinicaltrial|_: Umettet "
"(*unsaturated*) modell med de to hovedeffektene for ``drug`` og ``therapy``, "
"men uten en interaksjonskomponent for disse to faktorene"

#: ../../Ch14/Ch14_ANOVA2_07.rst:391
msgid ""
"Obviously, there are no surprises here. That’s the exact same ANOVA that we "
"ran earlier. Next, let’s run a regression using ``druganxifree``, "
"``drugjoyzepam`` and ``therapyCBT`` as the predictors. The results are shown "
"in :numref:`fig-factorialanova10`."
msgstr ""
"Det er åpenbart ingen overraskelser her. Det er nøyaktig samme ANOVA som vi "
"kjørte tidligere. La oss deretter kjøre en regresjon med ``druganxifree``, "
"``drugjoyzepam`` og ``therapyCBT`` som prediktorer. Resultatene vises i :"
"numref:`fig-factorialanova10`."

#: ../../Ch14/Ch14_ANOVA2_07.rst:398
msgid "Regression: clinicaltrial dataset, generated contrast-variables"
msgstr "Regresjon: datasett fra kliniske studier, genererte kontrastvariabler"

#: ../../Ch14/Ch14_ANOVA2_07.rst:402
msgid ""
"jamovi regression results for the |clinicaltrial|_ data set: Model with the "
"generated contrast variables ``druganxifree`` and ``drugjoyzepam``"
msgstr ""
"Resultater fra regresjon i jamovi for datasettet |clinicaltrial|_: Modell "
"med de genererte kontrastvariablene ``druganxifree`` og ``drugjoyzepam``"

#: ../../Ch14/Ch14_ANOVA2_07.rst:407
msgid ""
"Hmm. This isn’t the same output that we got last time. Not surprisingly, the "
"regression output prints out the results for each of the three predictors "
"separately, just like it did every other time we conducted a regression "
"analysis. On the one hand we can see that the *p*-value for the "
"``therapyCBT`` variable is exactly the same as the one for the ``therapy`` "
"factor |nominal| in our original ANOVA, so we can be reassured that the "
"regression model is doing the same thing as the ANOVA did. On the other "
"hand, this regression model is testing the ``druganxifree`` contrast and the "
"``drugjoyzepam`` contrast *separately*, as if they were two completely "
"unrelated variables. It’s not surprising of course, because the poor "
"regression analysis has no way of knowing that ``drugjoyzepam`` and "
"``druganxifree`` are actually the two different contrasts that we used to "
"encode our three-level ``drug`` factor. As far as it knows, ``drugjoyzepam`` "
"and ``druganxifree`` are no more related to one another than "
"``drugjoyzepam`` and ``therapyCBT``. However, you and I know better. At this "
"stage we’re not at all interested in determining whether these two contrasts "
"are individually significant. We just want to know if there’s an “overall” "
"effect of ``drug``. That is, what *we* want jamovi to do is to run some kind "
"of “model comparison” test, one in which the two “drug-related” contrasts "
"are lumped together for the purpose of the test. Sound familiar? All we need "
"to do is specify our null model, which in this case would include the "
"``therapyCBT`` predictor, and omit both of the drug-related variables, as "
"in :numref:`fig-factorialanova11`\\."
msgstr ""
"Dette er ikke det samme resultatet som sist. Dette er ikke det samme "
"resultatet som vi fikk forrige gang. Ikke overraskende viser "
"regresjonsutskriften resultatene for hver av de tre prediktorene hver for "
"seg, akkurat som den gjorde hver gang vi gjennomførte en regresjonsanalyse. "
"På den ene siden kan vi se at *p*-verdien for variabelen ``therapyCBT`` er "
"nøyaktig den samme som for faktoren ``therapy`` |nominal| i vår opprinnelige "
"ANOVA, så vi kan være trygge på at regresjonsmodellen gjør det samme som "
"ANOVAen gjorde. På den annen side tester denne regresjonsmodellen kontrasten "
"``druganxifree`` og kontrasten ``drugjoyzepam`` *separat*, som om de var to "
"helt urelaterte variabler. Det er selvfølgelig ikke overraskende, for den "
"stakkars regresjonsanalysen har ingen mulighet til å vite at "
"``drugjoyzepam`` og ``druganxifree`` faktisk er de to forskjellige "
"kontrastene som vi brukte til å kode vår ``drug``-faktor på tre nivåer. Så "
"vidt den vet, er ``drugjoyzepam`` og ``druganxifree`` ikke mer relatert til "
"hverandre enn ``drugjoyzepam`` og ``therapyCBT``. Men du og jeg vet bedre. "
"På dette stadiet er vi overhodet ikke interessert i å avgjøre om disse to "
"kontrastene er individuelt signifikante. Vi vil bare vite om det er en "
"«samlet» effekt av ``drug``. Det vil si at det *vi* vil at jamovi skal "
"gjøre, er å kjøre en slags «modellsammenligningstest», der de to ``drug``-"
"relaterte kontrastene er slått sammen for testens formål. Høres dette kjent "
"ut? Alt vi trenger å gjøre er å spesifisere nullmodellen vår, som i dette "
"tilfellet vil inkludere prediktoren ``therapyCBT``, og utelate begge de "
"legemiddel-relaterte variablene, som i :numref:`fig-factorialanova11`\\."

#: ../../Ch14/Ch14_ANOVA2_07.rst:432
msgid "Model comparison: Null model 1 vs. contrasts model 2"
msgstr "Sammenligning av modeller: Nullmodell 1 vs. kontrastmodell 2"

#: ../../Ch14/Ch14_ANOVA2_07.rst:436
msgid ""
"Model comparison in jamovi regression: Null model (Model 1) vs. model using "
"the generated contrast variables (Model 2)"
msgstr ""
"Sammenligning av modeller i jamovi-regresjon: Nullmodell (modell 1) vs. "
"modell med de genererte kontrastvariablene (modell 2)"

#: ../../Ch14/Ch14_ANOVA2_07.rst:441
msgid ""
"Ah, that’s better. Our *F*-statistic is 26.15, the degrees of freedom are 2 "
"and 14, and the *p*-value is 0.00002. The numbers are identical to the ones "
"we obtained for the main effect of ``drug`` in our original ANOVA. Once "
"again we see that ANOVA and regression are essentially the same. They are "
"both linear models, and the underlying statistical machinery for ANOVA is "
"identical to the machinery used in regression. The importance of this fact "
"should not be understated. Throughout the rest of this chapter we’re going "
"to rely heavily on this idea."
msgstr ""
"Ah, det var bedre. Vår *F*-statistikk er 26,15, frihetsgradene er 2 og 14, "
"og *p*-verdien er 0,00002. Tallene er identiske med dem vi fikk for "
"hovedeffekten av ``drug`` i vår opprinnelige ANOVA. Igjen ser vi at ANOVA og "
"regresjon i bunn og grunn er det samme. De er begge lineære modeller, og det "
"underliggende statistiske maskineriet for ANOVA er identisk med maskineriet "
"som brukes i regresjon. Viktigheten av dette faktum bør ikke undervurderes. "
"I resten av dette kapittelet kommer vi til å basere oss mye på denne ideen."

#: ../../Ch14/Ch14_ANOVA2_07.rst:450
msgid ""
"Although we went through all the faff of computing new variables in jamovi "
"for the contrasts ``druganxifree`` and ``drugjoyzepam``, just to show that "
"ANOVA and regression are essentially the same, in the jamovi linear "
"regression analysis there is actually a nifty shortcut to get these "
"contrasts, see :numref:`fig-regfactors`. What jamovi is doing here is "
"allowing you to enter the predictor variables that are factors as, wait for "
"it… factors! Smart, eh. You can also specify which group to use as the "
"reference level, via the ``Reference Levels`` option. We’ve changed this to "
"``placebo`` and ``no.therapy``, respectively, because this makes most sense."
msgstr ""
"Selv om vi gikk gjennom alt bryet med å beregne nye variabler i jamovi for "
"kontrastene ``druganxifree`` og ``drugjoyzepam``, bare for å vise at ANOVA "
"og regresjon i bunn og grunn er det samme, finnes det i jamovis lineære "
"regresjonsanalyse faktisk en fiks snarvei for å få disse kontrastene, se :"
"numref:`fig-regfactors`. Det jamovi gjør her, er å la deg legge inn "
"prediktorvariablene som er faktorer som, vent på det… faktorer! Smart, eller "
"hva? Du kan også spesifisere hvilken gruppe som skal brukes som "
"referansenivå, via alternativet ``Reference Levels``. Vi har endret dette "
"til henholdsvis ``placebo`` og ``no.therapy``, fordi dette gir mest mening."

#: ../../Ch14/Ch14_ANOVA2_07.rst:462
msgid "Regression analysis with factors and contrasts"
msgstr "Regresjonsanalyse med faktorer og kontraster"

#: ../../Ch14/Ch14_ANOVA2_07.rst:466
msgid ""
"Regression analysis with factors and contrasts in jamovi, including omnibus "
"ANOVA test results"
msgstr ""
"Regresjonsanalyse med faktorer og kontraster i jamovi, inkludert omnibus "
"ANOVA-testresultater"

#: ../../Ch14/Ch14_ANOVA2_07.rst:471
msgid ""
"If you also click on the ``ANOVA test`` checkbox under the ``Model "
"Coefficients`` → ``Omnibus Test`` option, we see that the *F*-statistic is "
"26.15, the degrees of freedom are 2 and 14, and the *p*-value is 0.00002 "
"(see :numref:`fig-regfactors`). The numbers are identical to the ones we "
"obtained for the main effect of ``drug`` in our original ANOVA. Once again, "
"we see that ANOVA and regression are essentially the same. They are both "
"linear models, and the underlying statistical machinery for ANOVA is "
"identical to the machinery used in regression."
msgstr ""
"Hvis du også klikker på avmerkingsboksen ``ANOVA test`` under alternativet "
"``Model Coefficients`` → ``Omnibus Test``, ser vi at *F*-statistikken er "
"26,15, frihetsgradene er 2 og 14, og *p*-verdien er 0,00002 (se :numref:`fig-"
"regfactors`). Tallene er identiske med dem vi fikk for hovedeffekten av "
"``drug`` i vår opprinnelige ANOVA. Igjen ser vi at ANOVA og regresjon i bunn "
"og grunn er det samme. De er begge lineære modeller, og det underliggende "
"statistiske maskineriet for ANOVA er identisk med maskineriet som brukes i "
"regresjon."

#: ../../Ch14/Ch14_ANOVA2_07.rst:481
msgid "Degrees of freedom as parameter counting!"
msgstr "Frihetsgrader som parametertelling!"

#: ../../Ch14/Ch14_ANOVA2_07.rst:483
msgid ""
"At long last, I can finally give a definition of degrees of freedom that I "
"am happy with. Degrees of freedom are defined in terms of the number of "
"parameters that have to be estimated in a model. For a regression model or "
"an ANOVA, the number of parameters corresponds to the number of regression "
"coefficients (i.e. *b*-values), including the intercept. Keeping in mind "
"that any *F*-test is always a comparison between two models and the first "
"*df* is the difference in the number of parameters. For example, in the "
"model comparison above, the null model (``mood.gain ~ therapyCBT``) has two "
"parameters: there’s one regression coefficient for the ``therapyCBT`` "
"variable, and a second one for the intercept. The alternative model (``mood."
"gain ~ druganxifree + drugjoyzepam + therapyCBT``) has four parameters: one "
"regression coefficient for each of the three contrasts, and one more for the "
"intercept. So the degrees of freedom associated with the *difference* "
"between these two models is *df*\\ :sub:`1` = 4 - 2 = 2."
msgstr ""
"Endelig kan jeg gi en definisjon av frihetsgrader som jeg er fornøyd med. "
"Frihetsgrader er definert som antall parametere som må estimeres i en "
"modell. For en regresjonsmodell eller en ANOVA tilsvarer antall parametere "
"antall regresjonskoeffisienter (dvs. *b*-verdier), inkludert "
"skjæringspunktet (*intercept*). Husk at enhver *F*-test alltid er en "
"sammenligning mellom to modeller, og at den første *df* er forskjellen i "
"antall parametere. I modellsammenligningen ovenfor har for eksempel "
"nullmodellen (``mood.gain ~ therapyCBT``) to parametere: det er én "
"regresjonskoeffisient for variabelen ``therapyCBT``, og en annen for "
"skjæringspunktet. Den alternative modellen (``mood.gain ~ druganxifree + "
"drugjoyzepam + therapyCBT``) har fire parametere: en regresjonskoeffisient "
"for hver av de tre kontrastene, og en til for skjæringspunktet. "
"Frihetsgradene knyttet til *forskjellen* mellom disse to modellene er altså "
"*df*\\ :sub:`1` = 4 - 2 = 2."

#: ../../Ch14/Ch14_ANOVA2_07.rst:499
msgid ""
"What about the case when there doesn’t seem to *be* a null model? For "
"instance, you might be thinking of the *F*-test that shows up when you "
"select ``F Test`` under the ``Linear Regression`` - ``Model Fit`` options. I "
"originally described that as a test of the regression model as a whole. "
"However, that is still a comparison between two models. The null model is "
"the trivial model that only includes 1 regression coefficient, for the "
"intercept term. The alternative model contains *K* + 1 regression "
"coefficients, one for each of the *K* predictor variables and one more for "
"the intercept. So the *df*-value that you see in this *F*-test is equal to "
"*df*\\ :sub:`1` = *K* + 1 - 1 = *K*."
msgstr ""
"Hva med tilfellet der det ikke ser ut til å *være* en nullmodell? Du tenker "
"kanskje på *F*-testen som dukker opp når du velger ``F Test`` under ``Linear "
"Regression`` - ``Model Fit``. Jeg beskrev den opprinnelig som en test av "
"regresjonsmodellen som helhet. Det er imidlertid fortsatt en sammenligning "
"mellom to modeller. Nullmodellen er den trivielle modellen som bare "
"inneholder én regresjonskoeffisient, for skjæringspunktet. Den alternative "
"modellen inneholder *K* + 1 regresjonskoeffisienter, én for hver av de *K* "
"prediktorvariablene og én til for skjæringspunktet. Så *df*-verdien som du "
"ser i denne *F*-testen, er lik *df*\\ :sub:`1` = *K* + 1 - 1 = *K*."

#: ../../Ch14/Ch14_ANOVA2_07.rst:511
msgid ""
"What about the second *df*-value that appears in the *F*-test? This always "
"refers to the degrees of freedom associated with the residuals. It is "
"possible to think of this in terms of parameters too, but in a slightly "
"counter-intuitive way. Think of it like this. Suppose that the total number "
"of observations across the study as a whole is *N*. If you wanted to "
"*perfectly* describe each of these *N* values, you need to do so using, "
"well… *N* numbers. When you build a regression model, what you’re really "
"doing is specifying that some of the numbers need to perfectly describe the "
"data. If your model has *K* predictors and an intercept, then you’ve "
"specified *K* + 1 numbers. So, without bothering to figure out exactly *how* "
"this would be done, how many *more* numbers do you think are going to be "
"needed to transform a *K* + 1 parameter regression model into a perfect re-"
"description of the raw data? If you found yourself thinking that (*K* + 1) + "
"(*N* - *K* - 1) = *N*, and so the answer would have to be *N* - *K* - 1, "
"well done! That’s exactly right. In principle you can imagine an absurdly "
"complicated regression model that includes a parameter for every single data "
"point, and it would of course provide a perfect description of the data. "
"This model would contain *N* parameters in total, but we’re interested in "
"the difference between the number of parameters required to describe this "
"full model (i.e. *N*) and the number of parameters used by the simpler "
"regression model that you’re actually interested in (i.e., *K* + 1), and so "
"the second degrees of freedom in the *F*-test is *df*\\ :sub:`2` = *N* - *K* "
"- 1, where *K* is the number of predictors (in a regression model) or the "
"number of contrasts (in an ANOVA). In the example I gave above, there are "
"*N* = 18 observations in the data set and *K* + 1 = 4 regression "
"coefficients associated with the ANOVA model, so the degrees of freedom for "
"the residuals is *df*\\ :sub:`2` = 18 - 4 = 14."
msgstr ""
"Hva med den andre *df*-verdien som vises i *F*-testen? Denne refererer "
"alltid til frihetsgradene som er knyttet til residuene. Det er mulig å tenke "
"på dette som parametere også, men på en litt kontraintuitiv måte. Tenk på "
"det på denne måten. Anta at det totale antallet observasjoner i hele studien "
"er *N*. Hvis du ønsker å beskrive hver av disse *N* verdiene *perfekt*, må "
"du gjøre det ved hjelp av, vel… *N* tall. Når du bygger en regresjonsmodell, "
"spesifiserer du egentlig bare at noen av tallene må beskrive dataene "
"perfekt. Hvis modellen din har *K* prediktorer og et skjæringspunkt, har du "
"spesifisert *K* + 1 tall. Så, uten å bry deg med å finne ut nøyaktig "
"*hvordan* dette skal gjøres, hvor mange *flere* tall tror du må til for å "
"gjøre en regresjonsmodell med *K* + 1 parametere om til en perfekt "
"beskrivelse av rådataene? Hvis du tenkte at (*K* + 1) + (*N* - *K* - 1) = "
"*N*, og at svaret derfor må være *N* - *K* - 1, så er det godt gjort! Det er "
"helt riktig. I prinsippet kan man tenke seg en absurd komplisert "
"regresjonsmodell som inneholder en parameter for hvert eneste datapunkt, og "
"den ville selvsagt gi en perfekt beskrivelse av dataene. Denne modellen "
"ville inneholde *N* parametere totalt, men vi er interessert i forskjellen "
"mellom antall parametere som kreves for å beskrive denne fullstendige "
"modellen (dvs. *N*) og antall parametere som brukes av den enklere "
"regresjonsmodellen som du faktisk er interessert i (dvs, *K* + 1), og dermed "
"er den andre frihetsgraden i *F*-testen *df*\\ :sub:`2` = *N* - *K* - 1, der "
"*K* er antall prediktorer (i en regresjonsmodell) eller antall kontraster (i "
"en ANOVA). I eksempelet jeg ga ovenfor, er det *N* = 18 observasjoner i "
"datasettet og *K* + 1 = 4 regresjonskoeffisienter knyttet til ANOVA-"
"modellen, slik at frihetsgradene for residuene er *df*\\ :sub:`2` = 18 - 4 = "
"14."

#: ../../Ch14/Ch14_ANOVA2_08.rst:4
msgid "Different ways to specify contrasts"
msgstr "Ulike måter å spesifisere kontraster på"

#: ../../Ch14/Ch14_ANOVA2_08.rst:6
msgid ""
"In the previous section, I showed you a method for converting a factor into "
"a collection of contrasts. In the method I showed you we specify a set of "
"binary variables in which we defined a table like this one:"
msgstr ""
"I forrige avsnitt viste jeg deg en metode for å konvertere en faktor til en "
"samling kontraster. I metoden jeg viste deg, spesifiserte vi et sett med "
"binære variabler der vi definerte en tabell som denne:"

#: ../../Ch14/Ch14_ANOVA2_08.rst:20
msgid ""
"Each row in the table corresponds to one of the factor levels, and each "
"column corresponds to one of the contrasts. This table, which always has one "
"more row than columns, has a special name. It is called a **contrast "
"matrix**. However, there are lots of different ways to specify a contrast "
"matrix. In this section I discuss a few of the standard contrast matrices "
"that statisticians use and how you can use them in jamovi. If you’re "
"planning to read the section on unbalanced ANOVA later on (section :doc:"
"`Ch14_ANOVA2_11`), it’s worth reading this section carefully. If not, you "
"can get away with skimming it, because the choice of contrasts doesn’t "
"matter much for balanced designs."
msgstr ""
"Hver rad i tabellen tilsvarer ett av faktornivåene, og hver kolonne "
"tilsvarer én av kontrastene. Denne tabellen, som alltid har én rad mer enn "
"kolonner, har et spesielt navn. Den kalles en **kontrastmatrise**. Det "
"finnes imidlertid mange forskjellige måter å spesifisere en kontrastmatrise "
"på. I dette avsnittet tar jeg for meg noen av de vanligste kontrastmatrisene "
"som statistikere bruker, og hvordan du kan bruke dem i jamovi. Hvis du "
"planlegger å lese avsnittet om ubalansert ANOVA senere (avsnitt :doc:"
"`Ch14_ANOVA2_11`), er det verdt å lese dette avsnittet nøye. Hvis ikke, kan "
"du slippe unna med å skumlese det, fordi valget av kontraster ikke har så "
"mye å si for balanserte design."

#: ../../Ch14/Ch14_ANOVA2_08.rst:31
msgid "Treatment contrasts"
msgstr "Behandlingskontraster"

#: ../../Ch14/Ch14_ANOVA2_08.rst:33
msgid ""
"In the particular kind of contrasts that I’ve described above, one level of "
"the factor is special, and acts as a kind of “baseline” category (i.e., "
"``placebo`` in our example), against which the other two are defined. The "
"name for these kinds of contrasts is **treatment contrasts**, also known as "
"“dummy coding”. In this contrast each level of the factor is compared to a "
"base reference level, and the base reference level is the value of the "
"intercept."
msgstr ""
"I den spesielle typen kontraster som jeg har beskrevet ovenfor, er ett nivå "
"av faktoren spesielt, og fungerer som en slags «baseline»-kategori (dvs. "
"``placebo`` i vårt eksempel), som de to andre nivåene defineres i forhold "
"til. Navnet på denne typen kontraster er **behandlingskontraster** "
"(*treatment contrasts*), også kjent som «dummykoding». I denne kontrasten "
"sammenlignes hvert nivå av faktoren med et basisreferansenivå, og "
"basisreferansenivået er verdien av skjæringspunktet."

#: ../../Ch14/Ch14_ANOVA2_08.rst:41
msgid ""
"The name reflects the fact that these contrasts are quite natural and "
"sensible when one of the categories in your factor really is special because "
"it actually does represent a baseline. That makes sense in our |"
"clinicaltrial|_ data. The ``placebo`` condition corresponds to the situation "
"where you don’t give people any real drugs, and so it’s special. The other "
"two conditions are defined in relation to the placebo. In one case you "
"replace the placebo with Anxifree, and in the other case your replace it "
"with Joyzepam."
msgstr ""
"Navnet gjenspeiler det faktum at disse kontrastene er ganske naturlige og "
"fornuftige når en av kategoriene i faktoren din virkelig er spesiell, fordi "
"den faktisk representerer en baseline. Det gir mening i våre data fra |"
"clinicaltrial|_. ``placebo``-betingelsen tilsvarer situasjonen der du ikke "
"gir folk noen ekte legemidler, og den er derfor spesiell. De to andre "
"betingelsene er definert i forhold til placebo. I det ene tilfellet "
"erstatter du placeboen med Anxifree, og i det andre tilfellet erstatter du "
"den med Joyzepam."

#: ../../Ch14/Ch14_ANOVA2_08.rst:50
msgid ""
"The table shown above is a matrix of treatment contrasts for a factor that "
"has 3 levels. But suppose I want a matrix of treatment contrasts for a "
"factor with 5 levels? You would set this out like this:"
msgstr ""
"Tabellen ovenfor er en matrise med behandlingskontraster for en faktor som "
"har 3 nivåer. Men hva om jeg ønsker en matrise med behandlingskontraster for "
"en faktor med 5 nivåer? Da ville du satt den opp slik:"

#: ../../Ch14/Ch14_ANOVA2_08.rst:63
msgid ""
"In this example, the first contrast is level 2 compared with level 1, the "
"second contrast is level 3 compared with level 1, and so on. Notice that, by "
"default, the *first* level of the factor is always treated as the baseline "
"category (i.e., it’s the one that has all zeros and doesn’t have an explicit "
"contrast associated with it). In jamovi you can change which category is the "
"first level of the factor by manipulating the order of the levels of the "
"variable shown in the ``Data Variable`` window (double click on the name of "
"the variable in the spreadsheet column to bring up the ``Data Variable`` "
"view)."
msgstr ""
"I dette eksempelet er den første kontrasten nivå 2 sammenlignet med nivå 1, "
"den andre kontrasten er nivå 3 sammenlignet med nivå 1, og så videre. Legg "
"merke til at det *første* nivået i faktoren som standard alltid behandles "
"som basiskategorien (det vil si at det er den som har alle nuller og ikke "
"har en eksplisitt kontrast knyttet til seg). I jamovi kan du endre hvilken "
"kategori som er det første nivået i faktoren ved å manipulere rekkefølgen på "
"nivåene i variabelen som vises i vinduet ``Data Variable`` (dobbeltklikk på "
"navnet på variabelen i regnearkkolonnen for å få opp ``Data Variable``-"
"vinduet)."

#: ../../Ch14/Ch14_ANOVA2_08.rst:74
msgid "Helmert contrasts"
msgstr "Helmert kontrasterer"

#: ../../Ch14/Ch14_ANOVA2_08.rst:76
msgid ""
"Treatment contrasts are useful for a lot of situations. However, they make "
"most sense in the situation when there really is a baseline category, and "
"you want to assess all the other groups in relation to that one. In other "
"situations, however, no such baseline category exists, and it may make more "
"sense to compare each group to the mean of the other groups. This is where "
"we meet **Helmert contrasts**, generated by the ``Helmert`` option in the "
"jamovi ``ANOVA`` - ``Contrasts`` selection box. The idea behind Helmert "
"contrasts is to compare each group to the mean of the “previous” ones. That "
"is, the first contrast represents the difference between group 2 and group "
"1, the second contrast represents the difference between group 3 and the "
"mean of groups 1 and 2, and so on. This translates to a contrast matrix that "
"looks like this for a factor with five levels:"
msgstr ""
"Behandlingskontraster er nyttige i mange situasjoner. De gir imidlertid mest "
"mening i situasjoner der det virkelig finnes en baseline-kategori, og du "
"ønsker å vurdere alle de andre gruppene i forhold til denne. I andre "
"situasjoner finnes det imidlertid ingen slik basiskategori, og da kan det gi "
"mer mening å sammenligne hver gruppe med gjennomsnittet av de andre "
"gruppene. Det er her vi møter **Helmert-kontraster**, som genereres av "
"alternativet ``Helmert`` i jamovi ``ANOVA`` - ``Contrasts``-valgboksen. "
"Ideen bak Helmert-kontraster er å sammenligne hver gruppe med gjennomsnittet "
"av de «foregående» gruppene. Det vil si at den første kontrasten "
"representerer forskjellen mellom gruppe 2 og gruppe 1, den andre kontrasten "
"representerer forskjellen mellom gruppe 3 og gjennomsnittet av gruppe 1 og "
"2, og så videre. Dette gir en kontrastmatrise som ser slik ut for en faktor "
"med fem nivåer:"

#: ../../Ch14/Ch14_ANOVA2_08.rst:98
msgid ""
"One useful thing about Helmert contrasts is that every contrast sums to zero "
"(i.e., all the columns sum to zero). This has the consequence that, when we "
"interpret the ANOVA as a regression, the intercept term corresponds to the "
"grand mean µ\\ :sub:`..` if we are using Helmert contrasts. Compare this to "
"treatment contrasts, in which the intercept term corresponds to the group "
"mean for the baseline category. This property can be very useful in some "
"situations. It doesn’t matter very much if you have a balanced design, which "
"we’ve been assuming so far, but it will turn out to be important later when "
"we consider unbalanced designs in section :doc:`Ch14_ANOVA2_11`. In fact, "
"the main reason why I’ve even bothered to include this section is that "
"contrasts become important if you want to understand unbalanced ANOVA."
msgstr ""
"En nyttig ting med Helmert-kontraster er at hver kontrast summerer til null "
"(dvs. at alle kolonnene summerer til null). Dette har den konsekvensen at "
"når vi tolker ANOVA-en som en regresjon, tilsvarer skjæringspunktet "
"(*intercept term*) det totale gjennomsnittet µ\\ :sub:`..` hvis vi bruker "
"Helmert-kontraster. Dette kan sammenlignes med behandlingskontraster, der "
"skjæringspunktet tilsvarer gruppegjennomsnittet for baselinekategorien. "
"Denne egenskapen kan være svært nyttig i noen situasjoner. Den betyr ikke så "
"mye hvis du har et balansert design, som vi har antatt så langt, men den vil "
"vise seg å være viktig senere når vi ser på ubalanserte design i avsnitt :"
"doc:`Ch14_ANOVA2_11`. Hovedgrunnen til at jeg i det hele tatt har tatt med "
"dette avsnittet, er faktisk at kontraster blir viktige hvis du vil forstå "
"ubalansert ANOVA."

#: ../../Ch14/Ch14_ANOVA2_08.rst:111
msgid "Sum to zero contrasts"
msgstr "Sum til null kontraster"

#: ../../Ch14/Ch14_ANOVA2_08.rst:113
msgid ""
"The third option that I should briefly mention are “sum to zero” contrasts, "
"called ``Simple`` contrasts in jamovi, which are used to construct pairwise "
"comparisons between groups. Specifically, each contrast encodes the "
"difference between one of the groups and a baseline category, which in this "
"case corresponds to the first group:"
msgstr ""
"Det tredje alternativet som jeg kort vil nevne, er «sum til null»-"
"kontraster, kalt ``Simple``-kontraster i jamovi, som brukes til å konstruere "
"parvise sammenligninger mellom grupper. Hver kontrast koder for forskjellen "
"mellom en av gruppene og en basiskategori, som i dette tilfellet tilsvarer "
"den første gruppen:"

#: ../../Ch14/Ch14_ANOVA2_08.rst:127
msgid ""
"Much like Helmert contrasts, we see that each column sums to zero, which "
"means that the intercept term corresponds to the grand mean when ANOVA is "
"treated as a regression model. When interpreting these contrasts, the thing "
"to recognise is that each of these contrasts is a pairwise comparison "
"between group 1 and one of the other four groups. Specifically, contrast 1 "
"corresponds to a “group 2 minus group 1” comparison, contrast 2 corresponds "
"to a “group 3 minus group 1” comparison, and so on.\\ [#]_"
msgstr ""
"I likhet med Helmert-kontraster ser vi at hver kolonne summerer til null, "
"noe som betyr at termen for intercept tilsvarer det totale gjennomsnittet "
"når ANOVA behandles som en regresjonsmodell. Når man tolker disse "
"kontrastene, er det viktig å være klar over at hver av disse kontrastene er "
"en parvis sammenligning mellom gruppe 1 og en av de fire andre gruppene. "
"Kontrast 1 tilsvarer en «gruppe 2 minus gruppe 1»-sammenligning, kontrast 2 "
"tilsvarer en «gruppe 3 minus gruppe 1»-sammenligning, og så videre.\\ [#]_"

#: ../../Ch14/Ch14_ANOVA2_08.rst:137
msgid "Optional contrasts in jamovi"
msgstr "Valgfrie kontraster i jamovi"

#: ../../Ch14/Ch14_ANOVA2_08.rst:139
msgid ""
"jamovi also comes with a variety of options that can generate different "
"kinds of contrasts in ANOVA. These can be found in the ``Contrasts`` option "
"in the main ANOVA analysis window, where the following contrast types are "
"listed:"
msgstr ""
"jamovi kommer også med en rekke alternativer som kan generere ulike typer "
"kontraster i ANOVA. Disse finner du i ``Contrasts``-opsjonen i hovedvinduet "
"for ANOVA-analyse, der følgende kontrasttyper er listet opp:"

#: ../../Ch14/Ch14_ANOVA2_08.rst:145
msgid "Contrast type"
msgstr "Kontrasttype"

#: ../../Ch14/Ch14_ANOVA2_08.rst:145
msgid "What does the contrast compare?"
msgstr "Hva sammenligner kontrasten?"

#: ../../Ch14/Ch14_ANOVA2_08.rst:147
msgid "**Deviation**"
msgstr "**Avvik**"

#: ../../Ch14/Ch14_ANOVA2_08.rst:147
msgid ""
"Compares the mean of each level (except a reference category) to the mean of "
"all of the levels (grand mean)."
msgstr ""
"Sammenligner gjennomsnittet for hvert nivå (unntatt en referansekategori) "
"med gjennomsnittet for alle nivåene (grand mean)."

#: ../../Ch14/Ch14_ANOVA2_08.rst:151
msgid "**Simple**"
msgstr "**Enkelt**"

#: ../../Ch14/Ch14_ANOVA2_08.rst:151
msgid ""
"Like the treatment contrasts, the simple contrast compares the mean of each "
"level to the mean of a specified level. This type of contrast is useful when "
"there is a control group. By default the first category is the reference. "
"However, with a simple contrast the intercept is the grand mean of all the "
"levels of the factors."
msgstr ""
"I likhet med behandlingskontraster sammenligner den enkle kontrasten "
"gjennomsnittet av hvert nivå med gjennomsnittet av et spesifisert nivå. "
"Denne typen kontrast er nyttig når det finnes en kontrollgruppe. Som "
"standard er den første kategorien referansen. Med en enkel kontrast er "
"imidlertid skjæringspunktet (*intercept*) det totale gjennomsnittet av alle "
"nivåene av faktorene."

#: ../../Ch14/Ch14_ANOVA2_08.rst:159
msgid "**Difference**"
msgstr "**Forskjell**"

#: ../../Ch14/Ch14_ANOVA2_08.rst:159
msgid ""
"Compares the mean of each level (except the first) to the mean of previous "
"levels. (Sometimes called reverse Helmert contrasts)."
msgstr ""
"Sammenligner gjennomsnittet av hvert nivå (unntatt det første) med "
"gjennomsnittet av de foregående nivåene. (Noen ganger kalt omvendt Helmert-"
"kontrast)."

#: ../../Ch14/Ch14_ANOVA2_08.rst:163
msgid "**Helmert**"
msgstr "**Helmert**"

#: ../../Ch14/Ch14_ANOVA2_08.rst:163
msgid ""
"Compares the mean of each level of the factor (except the last) to the mean "
"of subsequent levels."
msgstr ""
"Sammenligner gjennomsnittet for hvert nivå av faktoren (unntatt det siste) "
"med gjennomsnittet for de påfølgende nivåene."

#: ../../Ch14/Ch14_ANOVA2_08.rst:166
msgid "**Repeated**"
msgstr "**Gjentatt**"

#: ../../Ch14/Ch14_ANOVA2_08.rst:166
msgid ""
"Compares the mean of each level (except the last) to the mean of the "
"subsequent level."
msgstr ""
"Sammenligner gjennomsnittet for hvert nivå (bortsett fra det siste) med "
"gjennomsnittet for det påfølgende nivået."

#: ../../Ch14/Ch14_ANOVA2_08.rst:169
msgid "**Polynomial**"
msgstr "**Polynomisk**"

#: ../../Ch14/Ch14_ANOVA2_08.rst:169
msgid ""
"Compares the linear effect and quadratic effect. The first degree of freedom "
"contains the linear effect across all categories; the second degree of "
"freedom, the quadratic effect. These contrasts are often used to estimate "
"polynomial trends."
msgstr ""
"Sammenligner den lineære effekten og den kvadratiske effekten. Den første "
"frihetsgraden inneholder den lineære effekten på tvers av alle kategorier, "
"mens den andre frihetsgraden inneholder den kvadratiske effekten. Disse "
"kontrastene brukes ofte til å estimere polynomiske trender."

#: ../../Ch14/Ch14_ANOVA2_08.rst:179
msgid ""
"What’s the difference between treatment and simple contrasts, I hear you "
"ask? Well, as a basic example consider a gender main effect, with m = 0 and "
"f = 1. The coefficient corresponding to the treatment contrast will measure "
"the difference in mean between females and males, and the intercept would be "
"the mean of the males. However, with a simple contrast, i.e., m = -1 and f = "
"1, the intercept is the average of the means and the main effect is the "
"difference of each group mean from the intercept."
msgstr ""
"Hva er forskjellen mellom behandlings- og enkle kontraster, spør du? Vel, "
"som et grunnleggende eksempel kan vi tenke oss en hovedeffekt for kjønn, med "
"m = 0 og f = 1. Koeffisienten som tilsvarer behandlingskontrasten, vil måle "
"forskjellen i gjennomsnitt mellom kvinner og menn, og skjæringspunktet "
"(*intercept*) vil være gjennomsnittet for mennene. Med en enkel kontrast, "
"det vil si m = -1 og f = 1, er skjæringspunktet gjennomsnittet av "
"gjennomsnittene, og hovedeffekten er forskjellen i hver gruppes gjennomsnitt "
"fra skjæringspunktet."

#: ../../Ch14/Ch14_ANOVA2_09.rst:4
msgid "Post-hoc tests"
msgstr "Post-hoc-tester"

#: ../../Ch14/Ch14_ANOVA2_09.rst:6
msgid ""
"Time to switch to a different topic. Rather than pre-planned comparisons "
"that you have tested using contrasts, let’s suppose you’ve done your ANOVA "
"and it turns out that you obtained some significant effects. Because of the "
"fact that the *F*-tests are “omnibus” tests that only really test the null "
"hypothesis that there are no differences among groups, obtaining a "
"significant effect doesn’t tell you which groups are different to which "
"other ones. We discussed this issue back in chapter :doc:`../Ch13/"
"Ch13_ANOVA`, and in that chapter our solution was to run *t*-tests for all "
"possible pairs of groups, making corrections for multiple comparisons (e.g., "
"Bonferroni, Holm) to control the Type I error rate across all comparisons. "
"The methods that we used back there have the advantage of being relatively "
"simple and being the kind of tools that you can use in a lot of different "
"situations where you’re testing multiple hypotheses, but they’re not "
"necessarily the best choices if you’re interested in doing efficient post-"
"hoc testing in an ANOVA context. There are actually quite a lot of different "
"methods for performing multiple comparisons in the statistics literature (:"
"ref:`Hsu, 1996 <Hsu_1996>`), and it would be beyond the scope of an "
"introductory text like this one to discuss all of them in any detail."
msgstr ""
"På tide å bytte til et annet tema. I stedet for forhåndsplanlagte "
"sammenligninger som du har testet ved hjelp av kontraster, la oss anta at du "
"har gjort ANOVAen din og det viser seg at du har fått noen signifikante "
"effekter. Siden *F*-testene er «omnibus»-tester som egentlig bare tester "
"nullhypotesen om at det ikke er noen forskjeller mellom gruppene, forteller "
"ikke en signifikant effekt deg hvilke grupper som er forskjellige fra de "
"andre. Vi diskuterte dette problemet i kapittel :doc:`../Ch13/Ch13_ANOVA`, "
"og i det kapittelet var løsningen vår å kjøre *t*-tester for alle mulige par "
"av grupper, med korreksjoner for multiple sammenligninger (f.eks. "
"Bonferroni, Holm) for å kontrollere type-I-feilraten på tvers av alle "
"sammenligninger. Metodene vi brukte der har den fordelen at de er relativt "
"enkle og kan brukes i mange ulike situasjoner der du tester flere hypoteser, "
"men de er ikke nødvendigvis de beste valgene hvis du er interessert i å "
"gjøre effektive post-hoc-tester i en ANOVA-sammenheng. Det finnes faktisk "
"ganske mange forskjellige metoder for å utføre multiple sammenligninger i "
"statistiklitteraturen (:ref:`Hsu, 1996 <Hsu_1996>`), og det ville sprenge "
"rammene for en introduksjonstekst som denne å diskutere dem alle i detalj."

#: ../../Ch14/Ch14_ANOVA2_09.rst:25
msgid ""
"That being said, there’s one tool that I do want to draw your attention to, "
"namely Tukey’s “Honestly Significant Difference”, or **Tukey’s HSD** for "
"short. For once, I’ll spare you the formulas and just stick to the "
"qualitative ideas. The basic idea in Tukey’s HSD is to examine all relevant "
"pairwise comparisons between groups, and it’s only really appropriate to use "
"Tukey’s HSD if it is *pairwise* differences that you’re interested in.\\ "
"[#]_ For instance, earlier we conducted a factorial ANOVA using the |"
"clinicaltrial|_ data set, and where we specified a main effect for ``drug`` "
"and a main effect of ``therapy`` we would be interested in the following "
"four comparisons:"
msgstr ""
"Når det er sagt, er det ett verktøy jeg vil gjøre deg oppmerksom på, nemlig "
"Tukey's «*Honestly Significant Difference*», eller **Tukey's HSD** som det "
"forkortes. For en gangs skyld skal jeg spare deg for formlene og bare holde "
"meg til de kvalitative ideene. Den grunnleggende ideen i Tukeys HSD er å "
"undersøke alle relevante parvise sammenligninger mellom grupper, og det er "
"egentlig bare hensiktsmessig å bruke Tukeys HSD hvis det er *parvise* "
"forskjeller du er interessert i.\\ [#]_ For eksempel gjennomførte vi "
"tidligere en faktoriell ANOVA ved hjelp av datasettet |clinicaltrial|_, og "
"der vi spesifiserte en hovedeffekt for ``drug`` og en hovedeffekt for "
"``therapy``, ville vi være interessert i følgende fire sammenligninger:"

#: ../../Ch14/Ch14_ANOVA2_09.rst:36
msgid ""
"The difference in ``mood.gain`` for people given ``anxifree`` versus people "
"given the ``placebo``."
msgstr ""
"Humørforbedring (``mood.gain``) for personer som fikk ``anxifree`` versus "
"personer som fikk ``placebo``."

#: ../../Ch14/Ch14_ANOVA2_09.rst:39
msgid ""
"The difference in ``mood.gain`` for people given ``joyzepam`` versus people "
"given the ``placebo``."
msgstr ""
"Humørforbedring (``mood.gain``) for personer som fikk ``joyzepam`` versus "
"personer som fikk ``placebo``."

#: ../../Ch14/Ch14_ANOVA2_09.rst:42
msgid ""
"The difference in ``mood.gain`` for people given ``anxifree`` versus people "
"given ``joyzepam``."
msgstr ""
"Humørforbedring (``mood.gain``) for personer som fikk ``anxifree`` versus "
"personer som fikk ``joyzepam``."

#: ../../Ch14/Ch14_ANOVA2_09.rst:45
msgid ""
"The difference in ``mood.gain`` for people treated with ``CBT`` and people "
"given ``no.therapy``."
msgstr ""
"Humørforbedring (``mood.gain``) for personer som ble behandlet med ``CBT`` "
"og personer som ikke fikk ingen terapi (``no.therapy``)."

#: ../../Ch14/Ch14_ANOVA2_09.rst:48
msgid ""
"For any one of these comparisons, we’re interested in the true difference "
"between (population) group means. Tukey’s HSD constructs **simultaneous "
"confidence intervals** for all four of these comparisons. What we mean by "
"95\\% “simultaneous” confidence interval is that, if we were to repeat this "
"study many times, then in 95\\% of the study results the confidence "
"intervals would contain the relevant true value. Moreover, we can use these "
"confidence intervals to calculate an adjusted *p*-value for any specific "
"comparison."
msgstr ""
"For hver av disse sammenligningene er vi interessert i den sanne forskjellen "
"mellom (populasjons-)gruppegjennomsnitt. Tukey's HSD konstruerer **simultane "
"konfidensintervaller** for alle disse fire sammenligningene. Det vi mener "
"med «samtidige» (*simultaneous*) 95\\%-konfidensintervaller, er at hvis vi "
"skulle gjenta denne studien mange ganger, ville konfidensintervallene "
"inneholde den relevante sanne verdien i 95\\% av studieresultatene. Videre "
"kan vi bruke disse konfidensintervallene til å beregne en justert *p*-verdi "
"for en spesifikk sammenligning."

#: ../../Ch14/Ch14_ANOVA2_09.rst:57
msgid ""
"The ``TukeyHSD`` function in jamovi is pretty easy to use. You simply "
"specify the ANOVA model term that you want to run the post-hoc tests for. "
"For example, if we were looking to run post-hoc tests for the main effects "
"but not the interaction, we would open up the ``Post Hoc Tests`` option in "
"the ANOVA analysis screen, move the ``drug`` and ``therapy`` variables "
"across to the box on the right, and then select the ``Tukey`` checkbox in "
"the list of possible post-hoc corrections that could be applied. This, along "
"with the corresponding results table, is shown in :numref:`fig-"
"factorialanova13`."
msgstr ""
"``TukeyHSD``-funksjonen i jamovi er ganske enkel å bruke. Du spesifiserer "
"ganske enkelt ANOVA-modelltermen du ønsker å kjøre post-hoc-tester for. Hvis "
"vi for eksempel ønsker å kjøre post-hoc-tester for hovedeffektene, men ikke "
"interaksjonen, kan vi åpne alternativet ``Post Hoc Tests`` i ANOVA-"
"analyseskjermbildet, flytte variablene ``drug`` og ``therapy`` over til "
"boksen til høyre, og deretter krysse av for ``Tukey`` i listen over mulige "
"post-hoc-korreksjoner som kan brukes. Dette, sammen med den tilhørende "
"resultattabellen, vises i :numref:`fig-factorialanova13`."

#: ../../Ch14/Ch14_ANOVA2_09.rst:69
msgid "Options panel to set up post hoc tests"
msgstr "Analysepanel for å sette opp post-hoc-tester"

#: ../../Ch14/Ch14_ANOVA2_09.rst:73
msgid ""
"Options panel for setting up post-hoc test within jamovi's factorial ANOVA "
"procedure (the current settings request a Tukey HSD statistic): Unsaturated "
"model with the factors ``drug`` and ``therapy`` but without an interaction "
"term (using the |clinicaltrial|_ data set)"
msgstr ""
"Analysepanel for oppsett av post-hoc-tester for faktoriell ANOVA i jamovi(de "
"nåværende innstillingene ber om en Tukey HSD-statistikk): Umettet "
"(*unsaturated*) modell med faktorene ``drug`` og ``therapy``, men uten en "
"interaksjonsterm (ved bruk av datasettet |clinicaltrial|_)"

#: ../../Ch14/Ch14_ANOVA2_09.rst:80
msgid ""
"The output shown in the ``Post Hoc Tests`` results table is (I hope) pretty "
"straightforward. The first comparison, for example, is the Anxifree versus "
"placebo difference, and the first part of the output indicates that the "
"observed difference in group means is 0.27. The next number is the standard "
"error for the difference. Then there is a column with the degrees of "
"freedom, a column with the *t*-value, and finally a column with the *p*-"
"value. For the first comparison the adjusted *p*-value is 0.21. In contrast, "
"if you look at the next line, we see that the observed difference between "
"joyzepam and the placebo is 1.03, and this result is significant (*p* < "
"0.001)."
msgstr ""
"Resultatene som vises i resultattabellen ``Post Hoc Tests`` er (håper jeg) "
"ganske enkle. Den første sammenligningen er for eksempel forskjellen mellom "
"Anxifree og placebo, og den første delen av utgaven viser at den observerte "
"forskjellen i gruppegjennomsnitt er 0,27. Det neste tallet er standardfeilen "
"for forskjellen. Deretter følger en kolonne med frihetsgrader, en kolonne "
"med *t*-verdien og til slutt en kolonne med *p*-verdien. For den første "
"sammenligningen er den justerte *p*-verdien 0,21. Hvis du derimot ser på "
"neste linje, ser vi at den observerte forskjellen mellom joyzepam og placebo "
"er 1,03, og dette resultatet er signifikant (*p* < 0,001)."

#: ../../Ch14/Ch14_ANOVA2_09.rst:90
msgid ""
"So far, so good. What about the situation where your model includes "
"interaction terms? For instance, the default option in jamovi is to allow "
"for the possibility that there is an interaction between ``drug`` and "
"``therapy``. If that’s the case, the number of pairwise comparisons that we "
"need to consider starts to increase. As before, we need to consider the "
"three comparisons that are relevant to the main effect of ``drug`` and the "
"one comparison that is relevant to the main effect of ``therapy``. But, if "
"we want to consider the possibility of a significant interaction (and try to "
"find the group differences that underpin that significant interaction), we "
"need to include comparisons such as the following:"
msgstr ""
"Så langt, så bra. Hva med situasjonen der modellen din inkluderer "
"interaksjonstermer? For eksempel er standardalternativet i jamovi å ta "
"hensyn til muligheten for at det er en interaksjon mellom ``drug`` og "
"``therapy``. Hvis det er tilfelle, begynner antallet parvise sammenligninger "
"vi må vurdere å øke. Som før må vi ta hensyn til de tre sammenligningene som "
"er relevante for hovedeffekten av ``drug``, og den ene sammenligningen som "
"er relevant for hovedeffekten av ``therapy``. Men hvis vi ønsker å vurdere "
"muligheten for en signifikant interaksjon (og prøve å finne "
"gruppeforskjellene som ligger til grunn for den signifikante interaksjonen), "
"må vi inkludere sammenligninger som den følgende:"

#: ../../Ch14/Ch14_ANOVA2_09.rst:101
msgid ""
"The difference in ``mood.gain`` for people given ``anxifree`` and treated "
"with ``CBT``, versus people given the ``placebo`` and treated with ``CBT``"
msgstr ""
"Forskjellen i ``mood.gain`` for personer som fikk ``anxifree`` og ble "
"behandlet med ``CBT``, sammenlignet med personer som fikk ``placebo`` og ble "
"behandlet med ``CBT``"

#: ../../Ch14/Ch14_ANOVA2_09.rst:104
msgid ""
"The difference in ``mood.gain`` for people given ``anxifree`` and given ``no."
"therapy``, versus people given the ``placebo`` and given ``no.therapy``."
msgstr ""
"Forskjellen i ``mood.gain`` for personer som fikk ``anxifree`` og ``no."
"therapy``, sammenlignet med personer som fikk ``placebo`` og ``no.therapy``."

#: ../../Ch14/Ch14_ANOVA2_09.rst:108
msgid "etc."
msgstr "osv."

#: ../../Ch14/Ch14_ANOVA2_09.rst:110
msgid ""
"There are quite a lot of these comparisons that you need to consider. So, "
"when we run the Tukey post-hoc analysis for this ANOVA model, we see that it "
"has made a *lot* of pairwise comparisons (19 in total), as shown in :numref:"
"`fig-factorialanova14`. You can see that it looks pretty similar to before, "
"but with a lot more comparisons made."
msgstr ""
"Det er ganske mange av disse sammenligningene du må ta hensyn til. Så når vi "
"kjører Tukey post-hoc-analysen for denne ANOVA-modellen, ser vi at den har "
"gjort *mange* parvise sammenligninger (19 totalt), som vist i :numref:`fig-"
"factorialanova14`. Du kan se at det ser ganske likt ut som før, men med "
"mange flere sammenligninger."

#: ../../Ch14/Ch14_ANOVA2_09.rst:118
msgid "Results table for a Tukey HSD post-hoc test"
msgstr "Resultattabell for en Tukey HSD post-hoc-test"

#: ../../Ch14/Ch14_ANOVA2_09.rst:122
msgid ""
"Results table for a Tukey HSD post-hoc test within jamovi's factorial ANOVA "
"procedure: Unsaturated model with the factors ``drug`` and ``therapy`` but "
"without an interaction term (using the |clinicaltrial|_ data set)"
msgstr ""
"Resultattabell for en Tukey HSD post-hoc-test innenfor jamovis faktorielle "
"ANOVA-prosedyre: Umettet (*unsaturated*) modell med faktorene ``drug`` og "
"``therapy``, men uten interaksjonsterm (ved bruk av datasettet |"
"clinicaltrial|_)"

#: ../../Ch14/Ch14_ANOVA2_09.rst:131
msgid ""
"If, for instance, you actually find yourself interested to know if Group A "
"is significantly different from the mean of Group B and Group C, then you "
"need to use a different tool (e.g., Scheffe’s method, which is more "
"conservative, and beyond the scope of this book). However, in most cases you "
"probably are interested in pairwise group differences, so Tukey’s HSD is a "
"pretty useful thing to know about."
msgstr ""
"Hvis du for eksempel er interessert i å finne ut om gruppe A er signifikant "
"forskjellig fra gjennomsnittet av gruppe B og gruppe C, må du bruke et annet "
"verktøy (for eksempel Scheffes metode, som er mer konservativ og faller "
"utenfor denne bokens rammer). I de fleste tilfeller er du imidlertid "
"sannsynligvis interessert i parvise gruppeforskjeller, så Tukeys HSD er "
"ganske nyttig å kjenne til."

#: ../../Ch14/Ch14_ANOVA2_10.rst:4
msgid "The method of planned comparisons"
msgstr "Metoden med planlagte sammenligninger"

#: ../../Ch14/Ch14_ANOVA2_10.rst:6
msgid ""
"Following on from the previous sections on contrasts and post-hoc tests in "
"ANOVA, I think the method of planned comparisons is important enough to "
"deserve a quick discussion. In our discussions of multiple comparisons, in "
"the previous section and back in chapter :doc:`../Ch13/Ch13_ANOVA`, I’ve "
"been assuming that the tests you want to run are genuinely post-hoc. For "
"instance, in our |clinicaltrial|_ data above, maybe you thought that the "
"levels of ``drug`` would all have different effects on mood (i.e., you "
"hypothesised a main effect of ``drug``), but you didn’t have any specific "
"hypothesis about how they would be different, nor did you have any real idea "
"about *which* pairwise comparisons would be worth looking at. If that is the "
"case, then you really have to resort to something like Tukey’s HSD to do "
"your pairwise comparisons."
msgstr ""
"I forlengelsen av de foregående avsnittene om kontraster og post-hoc-tester "
"i ANOVA, synes jeg metoden med planlagte sammenligninger er viktig nok til å "
"fortjene en kort diskusjon. I diskusjonene våre om multiple sammenligninger, "
"i forrige avsnitt og tilbake i kapittel :doc:`../Ch13/Ch13_ANOVA`, har jeg "
"antatt at testene du ønsker å kjøre, virkelig er post-hoc. For eksempel, i "
"dataene våre fra |clinicaltrial|_ ovenfor, trodde du kanskje at nivåene av "
"``drug`` alle ville ha forskjellige effekter på humøret (dvs. du antok en "
"hovedeffekt av ``drug``), men du hadde ingen spesifikk hypotese om hvordan "
"de ville være forskjellige, og du hadde heller ingen reell idé om *hvilke* "
"parvise sammenligninger som ville være verdt å se på. Hvis det er tilfelle, "
"må du virkelig ty til noe som Tukey's HSD for å gjøre parvise "
"sammenligninger."

#: ../../Ch14/Ch14_ANOVA2_10.rst:18
msgid ""
"The situation is rather different, however, if you genuinely did have real, "
"specific hypotheses about which comparisons are of interest, and you *never "
"ever* have any intention to look at any other comparisons besides the ones "
"that you specified ahead of time. When this is true, and if you honestly and "
"rigorously stick to your noble intentions to not run any other comparisons "
"(even when the data look like they’re showing you deliciously significant "
"effects for stuff you didn’t have a hypothesis test for), then it doesn’t "
"really make a lot of sense to run something like Tukey’s HSD, because it "
"makes corrections for a whole bunch of comparisons that you never cared "
"about and never had any intention of looking at. Under those circumstances, "
"you can safely run a (limited) number of hypothesis tests without making an "
"adjustment for multiple testing. This situation is known as the **method of "
"planned comparisons**, and it is sometimes used in clinical trials. However, "
"further consideration is out of scope for this introductory book, but at "
"least you know that this method exists!"
msgstr ""
"Situasjonen er imidlertid ganske annerledes hvis du virkelig har reelle, "
"spesifikke hypoteser om hvilke sammenligninger som er av interesse, og du "
"*aldri* har noen intensjon om å se på andre sammenligninger enn dem du har "
"spesifisert på forhånd. Når dette er sant, og hvis du ærlig og strengt "
"holder deg til dine edle intensjoner om ikke å kjøre noen andre "
"sammenligninger (selv når dataene ser ut som om de viser deg herlige "
"signifikante effekter for ting du ikke hadde en hypotesetest for), gir det "
"egentlig ikke mye mening å kjøre noe som Tukeys HSD, fordi det korrigerer "
"for en hel haug med sammenligninger som du aldri brydde deg om og aldri "
"hadde noen intensjon om å se på. Under slike omstendigheter kan du trygt "
"kjøre et (begrenset) antall hypotesetester uten å foreta en justering for "
"multippel testing. Denne situasjonen er kjent som **metoden med planlagte "
"sammenligninger**, og den brukes av og til i kliniske studier. Det er "
"imidlertid utenfor rammen for denne introduksjonsboken å gå nærmere inn på "
"dette, men du vet i det minste at denne metoden finnes!"

#: ../../Ch14/Ch14_ANOVA2_11.rst:4
msgid "Factorial ANOVA 3: unbalanced designs"
msgstr "Faktoriell ANOVA 3: ubalanserte design"

#: ../../Ch14/Ch14_ANOVA2_11.rst:6
msgid ""
"Factorial ANOVA is a very handy thing to know about. It’s been one of the "
"standard tools used to analyse experimental data for many decades, and "
"you’ll find that you can’t read more than two or three papers in psychology "
"without running into an ANOVA in there somewhere. However, there’s one huge "
"difference between the ANOVAs that you’ll see in a lot of real scientific "
"articles and the ANOVAs that I’ve described so far. In in real life we’re "
"rarely lucky enough to have perfectly balanced designs. For one reason or "
"another, it’s typical to end up with more observations in some cells than in "
"others. Or, to put it another way, we have an **unbalanced design**."
msgstr ""
"Faktoriell ANOVA er en veldig nyttig metode å kjenne til. Det har vært et av "
"standardverktøyene som har blitt brukt til å analysere eksperimentelle data "
"i mange tiår, og du kan ikke lese mer enn to eller tre artikler i psykologi "
"uten å støte på en ANOVA et eller annet sted. Det er imidlertid en stor "
"forskjell mellom ANOVA-analysene du finner i mange virkelige vitenskapelige "
"artikler, og ANOVA-analysene jeg har beskrevet så langt. I det virkelige liv "
"er vi sjelden heldige nok til å ha perfekt balanserte design. Av en eller "
"annen grunn er det vanlig å ende opp med flere observasjoner i noen celler "
"enn i andre. Eller, for å si det på en annen måte, vi har en **ubalansert "
"design**."

#: ../../Ch14/Ch14_ANOVA2_11.rst:17
msgid ""
"Unbalanced designs need to be treated with a lot more care than balanced "
"designs, and the statistical theory that underpins them is a lot messier. It "
"might be a consequence of this messiness, or it might be a shortage of time, "
"but my experience has been that undergraduate research methods classes in "
"psychology have a nasty tendency to ignore this issue completely. A lot of "
"stats textbooks tend to gloss over it too. The net result of this, I think, "
"is that a lot of active researchers in the field don’t actually know that "
"there’s several different “types” of unbalanced ANOVAs, and they produce "
"quite different answers. In fact, reading the psychological literature, I’m "
"kind of amazed at the fact that most people who report the results of an "
"unbalanced factorial ANOVA don’t actually give you enough details to "
"reproduce the analysis. I secretly suspect that most people don’t even "
"realise that their statistical software package is making a whole lot of "
"substantive data analysis decisions on their behalf. It’s actually a little "
"terrifying when you think about it. So, if you want to avoid handing control "
"of your data analysis to stupid software, read on."
msgstr ""
"Ubalanserte design må behandles med mye større forsiktighet enn balanserte "
"design, og den statistiske teorien som ligger til grunn for dem, er mye mer "
"rotete. Det kan være en konsekvens av denne uoversiktligheten, eller det kan "
"være mangel på tid, men min erfaring er at forskningsmetodeundervisningen i "
"psykologi har en lei tendens til å ignorere dette problemet fullstendig. "
"Mange lærebøker i statistikk har også en tendens til å glatte over det. "
"Nettoresultatet av dette, tror jeg, er at mange aktive forskere på feltet "
"faktisk ikke vet at det finnes flere forskjellige «typer» ubalanserte ANOVA-"
"er, og at de gir ganske forskjellige svar. Når jeg leser psykologisk "
"litteratur, blir jeg faktisk overrasket over at de fleste som rapporterer "
"resultatene av en ubalansert faktoriell ANOVA, faktisk ikke gir deg nok "
"detaljer til at du kan reprodusere analysen. Jeg mistenker i all hemmelighet "
"at de fleste ikke engang er klar over at den statistiske programvarepakken "
"deres tar en hel del substansielle dataanalysebeslutninger på deres vegne. "
"Det er faktisk litt skremmende når man tenker på det. Så hvis du vil unngå å "
"overlate kontrollen over dataanalysen din til dum programvare, bør du lese "
"videre."

#: ../../Ch14/Ch14_ANOVA2_11.rst:36
msgid "The coffee data"
msgstr "Kaffe og «babling»"

#: ../../Ch14/Ch14_ANOVA2_11.rst:38
msgid ""
"As usual, it will help us to work with some data. The |coffee|_ data set "
"contains a hypothetical data set that produces an unbalanced 3 × 2 ANOVA. "
"Suppose we were interested in finding out whether or not the tendency of "
"people to ``babble`` when they have too much coffee is purely an effect of "
"the coffee itself, or whether there’s some effect of the ``milk`` and "
"``sugar`` that people add to the coffee. Suppose we took 18 people and gave "
"them some coffee to drink. The amount of coffee, i.e., the caffeine, was "
"held constant, and we varied whether or not milk was added, so ``milk`` is a "
"binary factor |nominal| with two levels, ``yes`` and ``no``. We also varied "
"the kind of sugar involved. The coffee might contain ``real`` sugar or it "
"might contain ``fake`` sugar (i.e., artificial sweetener) or it might "
"contain ``none`` at all, so the ``sugar`` variable |nominal| is a three "
"level factor. Our outcome variable ``babble`` is a continuous variable |"
"continuous| that presumably refers to some psychologically sensible measure "
"of the extent to which someone is “babbling”. The details don’t really "
"matter for our purpose. Take a look at the data in the jamovi spreadsheet "
"view, as in :numref:`fig-factorialanova15`\\."
msgstr ""
"Som vanlig vil det hjelpe oss å jobbe med noen data. Datasettet |coffee|_ "
"inneholder et hypotetisk datasett som produserer en ubalansert 3 × 2 ANOVA. "
"Anta at vi er interessert i å finne ut om tendensen til at folk "
"«babler» (``babble``) når de drikker for mye kaffe, kun er en effekt av "
"kaffen i seg selv, eller om det også er en effekt av ``milk`` og ``sugar`` "
"som folk tilsetter i kaffen. Anta at vi tar 18 personer og gir dem litt "
"kaffe å drikke. Mengden kaffe, det vil si koffeinet, holdes konstant, og vi "
"varierer om det er tilsatt melk eller ikke, slik at ``milk`` er en binær "
"faktor |nominal| med to nivåer, ``yes`` og ``no``. Vi har også variert hva "
"slags sukker som er involvert. Kaffen kan inneholde ekte sukker (``real``), "
"den kan inneholde falskt sukker (dvs. kunstig søtningsmiddel; ``fake``), "
"eller den kan inneholde ingen sukker i det hele tatt (``none``), dvs. "
"variabelen ``sugar`` er en faktor |nominal| med tre nivåer. "
"Utfallsvariabelen ``babble`` er en kontinuerlig variabel |continuous| som "
"antagelig refererer til et psykologisk fornuftig mål på i hvilken grad noen "
"«babler». Detaljene spiller egentlig ingen rolle for vårt formål. Ta en titt "
"på dataene i jamovi-regnearkvisningen, som i :numref:`fig-"
"factorialanova15`\\."

#: ../../Ch14/Ch14_ANOVA2_11.rst:57
msgid "Descriptive statistics for the different levels of sugar and milk"
msgstr "Deskriptivstatistikk for de ulike nivåene av ``sugar`` og ``milk``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:61
msgid ""
"The |coffee|_ data set in jamovi, showing descriptive statistics aggregated "
"by the different levels of the factors ``sugar`` and ``milk``"
msgstr ""
"Datasettet |coffee|_ i jamovi, som viser deskriptivstatistikk aggregert "
"etter de ulike nivåene av de faktorene ``sugar`` og ``milk``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:66
msgid ""
"Looking at the table of means in :numref:`fig-factorialanova15` we get a "
"strong impression that there are differences between the groups. This is "
"especially true when we compare these means to the standard deviations for "
"the ``babble`` variable. Across groups, this standard deviation varies from "
"0.14 to 0.71, which is fairly small relative to the differences in group "
"means.\\ [#]_ Whilst this at first may seem like a straightforward factorial "
"ANOVA, a problem arises when we look at how many observations we have in "
"each group. See the different *N*\\s for different groups shown in :numref:"
"`fig-factorialanova15`. This violates one of our original assumptions, "
"namely that the number of people in each group is the same. We haven’t "
"really discussed how to handle this situation."
msgstr ""
"Når vi ser på tabellen over gjennomsnitt i :numref:`fig-factorialanova15`, "
"får vi et sterkt inntrykk av at det er forskjeller mellom gruppene. Dette "
"gjelder spesielt når vi sammenligner disse gjennomsnittene med "
"standardavvikene for variabelen ``babble``. På tvers av gruppene varierer "
"dette standardavviket fra 0,14 til 0,71, noe som er ganske lite i forhold "
"til forskjellene i gruppegjennomsnitt.\\ [#]_ Selv om dette i utgangspunktet "
"kan virke som en grei faktoriell ANOVA, oppstår det et problem når vi ser på "
"hvor mange observasjoner vi har i hver gruppe. Se de forskjellige *N*-"
"verdiene for de ulike gruppene som vises i :numref:`fig-factorialanova15`. "
"Dette bryter med en av de opprinnelige forutsetningene våre, nemlig at "
"antallet personer i hver gruppe er det samme. Vi har ikke diskutert hvordan "
"vi skal håndtere denne situasjonen."

#: ../../Ch14/Ch14_ANOVA2_11.rst:79
msgid "“Standard ANOVA” does not exist for unbalanced designs"
msgstr "«Standard-ANOVA» finnes ikke for ubalanserte design"

#: ../../Ch14/Ch14_ANOVA2_11.rst:81
msgid ""
"Unbalanced designs lead us to the somewhat unsettling discovery that there "
"isn’t really any one thing that we might refer to as a standard ANOVA. In "
"fact, it turns out that there are *three* fundamentally different ways\\ "
"[#]_ in which you might want to run an ANOVA in an unbalanced design. If you "
"have a balanced design all three versions produce identical results, with "
"the sums of squares, *F*-values, etc., all conforming to the formulas that I "
"gave at the start of the chapter. However, when your design is unbalanced "
"they don’t give the same answers. Furthermore, they are not all equally "
"appropriate to every situation. Some methods will be more appropriate to "
"your situation than others. Given all this, it’s important to understand "
"what the different types of ANOVA are and how they differ from one another."
msgstr ""
"Ubalanserte design fører oss til den noe urovekkende oppdagelsen at det "
"egentlig ikke finnes én ting som vi kan kalle en standard ANOVA. Faktisk "
"viser det seg at det finnes *tre* fundamentalt forskjellige måter\\ [#]_ å "
"kjøre en ANOVA på i en ubalansert design. Hvis du har en balansert design, "
"gir alle tre versjonene identiske resultater, med kvadratsummer, *F*-verdier "
"osv. i samsvar med formlene som jeg beskrev i begynnelsen av kapittelet. Men "
"når designet ditt er ubalansert, gir de ikke de samme svarene. Dessuten er "
"ikke alle metodene like hensiktsmessige i alle situasjoner. Noen metoder vil "
"være mer hensiktsmessige i din situasjon enn andre. Med tanke på alt dette "
"er det viktig å forstå hva de ulike typene ANOVA er, og hvordan de skiller "
"seg fra hverandre."

#: ../../Ch14/Ch14_ANOVA2_11.rst:94
msgid ""
"The first kind of ANOVA is conventionally referred to as **Type 1 sum of "
"squares**. I’m sure you can guess what the other two are called. The “sum of "
"squares” part of the name was introduced by the SAS statistical software "
"package and has become standard nomenclature, but it’s a bit misleading in "
"some ways. I think the logic for referring to them as different types of sum "
"of squares is that, when you look at the ANOVA tables that they produce, the "
"key difference in the numbers is the SS values. The degrees of freedom don’t "
"change, the MS values are still defined as SS divided by *df*, etc. However, "
"what the terminology gets wrong is that it hides the reason *why* the SS "
"values are different from one another. To that end, it’s a lot more helpful "
"to think of the three different kinds of ANOVA as three different "
"*hypothesis testing strategies*. These different strategies lead to "
"different SS values, to be sure, but it’s the strategy that is the important "
"thing here, not the SS values themselves. Recall from section :doc:"
"`Ch14_ANOVA2_07`, that any particular *F*-test is best thought of as a "
"comparison between two linear models. So, when you’re looking at an ANOVA "
"table, it helps to remember that each of those *F*-tests corresponds to a "
"*pair* of models that are being compared. Of course, this leads naturally to "
"the question of *which* pair of models is being compared. This is the "
"fundamental difference between ANOVA Types 1, 2 and 3: each one corresponds "
"to a different way of choosing the model pairs for the tests."
msgstr ""
"Den første typen ANOVA kalles vanligvis **Type-1-kvadratsum**. Du kan "
"sikkert gjette hva de to andre kalles. «Kvadratsum»-delen av navnet ble "
"introdusert av SAS' statistiske programvarepakke og har blitt standard "
"nomenklatur, men det er litt misvisende på noen måter. Jeg tror logikken bak "
"å kalle dem ulike typer kvadratsummer er at når du ser på ANOVA-tabellene "
"som de produserer, er det kvadratummene (SS) som er den viktigste "
"forskjellen i tallene. Frihetsgradene endres ikke, MS-verdiene er fortsatt "
"definert som SS delt på *df* osv. Det terminologien imidlertid gjør feil, er "
"at den skjuler årsaken til *hvorfor* kvadratummene er forskjellige fra "
"hverandre. Derfor er det mye mer nyttig å tenke på de tre ulike typene ANOVA "
"som tre ulike *hypotesetestingsstrategier*. Disse ulike strategiene fører "
"riktignok til ulike kvadratummer, men det er strategien som er det viktige "
"her, ikke kvadratummene i seg selv. Husk fra avsnitt :doc:`Ch14_ANOVA2_07`, "
"at en hvilken som helst *F*-test best kan betraktes som en sammenligning "
"mellom to lineære modeller. Så når du ser på en ANOVA-tabell, er det nyttig "
"å huske at hver av disse *F*-testene tilsvarer et *par* av modeller som "
"sammenlignes. Dette fører naturlig nok til spørsmålet om *hvilket* par av "
"modeller som sammenlignes. Dette er den grunnleggende forskjellen mellom "
"ANOVA-type 1, 2 og 3: hver av dem tilsvarer en annen måte å velge "
"modellparene for testene på."

#: ../../Ch14/Ch14_ANOVA2_11.rst:117
msgid "Type 1 sum of squares"
msgstr "Kvadratsummen av type 1"

#: ../../Ch14/Ch14_ANOVA2_11.rst:119
msgid ""
"The Type 1 method is sometimes referred to as the “sequential” sum of "
"squares, because it involves a process of adding terms to the model one at a "
"time. Consider, for instance, the |coffee|_ data. Suppose we want to run the "
"full 3 × 2 factorial ANOVA, including interaction terms. The full model "
"contains the outcome variable ``babble``, the predictor variables ``sugar`` "
"and ``milk``, and the interaction term ``sugar * milk``. This can be written "
"as ``babble ~ sugar + milk + sugar * milk``. The Type 1 strategy builds this "
"model up sequentially, starting from the simplest possible model and "
"gradually adding terms."
msgstr ""
"Type-1-metoden kalles noen ganger den «sekvensielle» kvadratsummen, fordi "
"den innebærer en prosess der man legger til en term om gangen i modellen. Ta "
"for eksempel dataene for |coffee|_. Anta at vi ønsker å kjøre en fullstendig "
"3 × 2-faktoriell ANOVA, inkludert interaksjonsbetingelser. Den fullstendige "
"modellen inneholder utfallsvariabelen ``babble``, prediktorvariablene "
"``sugar`` og ``milk``, og interaksjonstermen ``sugar * milk``. Dette kan "
"skrives som ``babble ~ sugar + milk + sugar * milk``. Type-1-strategien "
"bygger opp denne modellen sekvensielt, med utgangspunkt i den enklest mulige "
"modellen, og legger gradvis til flere termer."

#: ../../Ch14/Ch14_ANOVA2_11.rst:130
msgid ""
"The simplest possible model for the data would be one in which neither milk "
"nor sugar is assumed to have any effect on babbling. The only term that "
"would be included in such a model is the intercept, written as ``babble ~ "
"1``. This is our initial null hypothesis. The next simplest model for the "
"data would be one in which only one of the two main effects is included. In "
"the |coffee|_ data, there are two different possible choices here, because "
"we could choose to add milk first or to add sugar first. The order actually "
"turns out to matter, as we’ll see later, but for now let’s just make a "
"choice arbitrarily and pick sugar. So, the second model in our sequence of "
"models is ``babble ~ sugar``, and it forms the alternative hypothesis for "
"our first test. We now have our first hypothesis test:"
msgstr ""
"Den enkleste mulige modellen for dataene ville være en modell der verken "
"melk eller sukker antas å ha noen effekt på babling. Den eneste termen som "
"vil inngå i en slik modell, er skjæringspunktet (*intercept*), skrevet som "
"``babble ~ 1``. Dette er vår opprinnelige nullhypotese. Den nest enkleste "
"modellen for dataene ville være en modell der bare én av de to "
"hovedeffektene er inkludert. I dataene for |coffee|_ er det to forskjellige "
"mulige valg her, fordi vi kan velge å tilsette melk først eller sukker "
"først. Rekkefølgen viser seg faktisk å ha noe å si, som vi skal se senere, "
"men la oss foreløpig bare ta et vilkårlig valg og velge sukker. Den andre "
"modellen i vår sekvens av modeller er altså ``babble ~ sugar``, og den "
"utgjør alternativhypotesen for vår første test. Vi har nå vår første "
"hypotesetest:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:144 ../../Ch14/Ch14_ANOVA2_11.rst:156
#: ../../Ch14/Ch14_ANOVA2_11.rst:175 ../../Ch14/Ch14_ANOVA2_11.rst:258
#: ../../Ch14/Ch14_ANOVA2_11.rst:267 ../../Ch14/Ch14_ANOVA2_11.rst:277
#: ../../Ch14/Ch14_ANOVA2_11.rst:410 ../../Ch14/Ch14_ANOVA2_11.rst:428
#: ../../Ch14/Ch14_ANOVA2_11.rst:465 ../../Ch14/Ch14_ANOVA2_11.rst:473
#: ../../Ch14/Ch14_ANOVA2_11.rst:481
msgid "Null model:"
msgstr "Nullmodell:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:144
msgid "``babble ~ 1``"
msgstr "``babble ~ 1``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:146 ../../Ch14/Ch14_ANOVA2_11.rst:158
#: ../../Ch14/Ch14_ANOVA2_11.rst:177 ../../Ch14/Ch14_ANOVA2_11.rst:260
#: ../../Ch14/Ch14_ANOVA2_11.rst:269 ../../Ch14/Ch14_ANOVA2_11.rst:279
#: ../../Ch14/Ch14_ANOVA2_11.rst:412 ../../Ch14/Ch14_ANOVA2_11.rst:430
#: ../../Ch14/Ch14_ANOVA2_11.rst:467 ../../Ch14/Ch14_ANOVA2_11.rst:475
#: ../../Ch14/Ch14_ANOVA2_11.rst:483
msgid "Alternative model:"
msgstr "Alternativmodell:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:146 ../../Ch14/Ch14_ANOVA2_11.rst:156
#: ../../Ch14/Ch14_ANOVA2_11.rst:473
msgid "``babble ~ sugar``"
msgstr "``babble ~ sugar``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:149
msgid ""
"This comparison forms our hypothesis test of the main effect of ``sugar``. "
"The next step in our model building exercise is to add the other main effect "
"term, so the next model in our sequence is ``babble ~ sugar + milk``. The "
"second hypothesis test is then formed by comparing the following pair of "
"models:"
msgstr ""
"Denne sammenligningen utgjør vår hypotesetest av hovedeffekten av ``sugar``. "
"Neste trinn i modellbyggingen er å legge til den andre hovedeffekttermen, "
"slik at den neste modellen i vår sekvens er ``babble ~ sugar + milk``. Den "
"andre hypotesetesten blir da dannet ved å sammenligne følgende modellpar:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:158 ../../Ch14/Ch14_ANOVA2_11.rst:175
#: ../../Ch14/Ch14_ANOVA2_11.rst:277 ../../Ch14/Ch14_ANOVA2_11.rst:467
#: ../../Ch14/Ch14_ANOVA2_11.rst:475 ../../Ch14/Ch14_ANOVA2_11.rst:481
msgid "``babble ~ sugar + milk``"
msgstr "``babble ~ sugar + milk``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:161
msgid ""
"This comparison forms our hypothesis test of the main effect of ``milk``. In "
"one sense, this approach is very elegant: the alternative hypothesis from "
"the first test forms the null hypothesis for the second one. It is in this "
"sense that the Type 1 method is strictly sequential. Every test builds "
"directly on the results of the last one. However, in another sense it’s very "
"inelegant, because there’s a strong asymmetry between the two tests. The "
"test of the main effect of ``sugar`` (the first test) completely ignores "
"``milk``, whereas the test of the main effect of ``milk`` (the second test) "
"does take ``sugar`` into account. In any case, the fourth model in our "
"sequence is now the full model, ``babble ~ sugar + milk + sugar * milk``, "
"and the corresponding hypothesis test is:"
msgstr ""
"For denne sammenligningen dannes vår hypotesetest av hovedeffekten av "
"``milk``. På én måte er denne tilnærmingen svært elegant: "
"Alternativhypotesen fra den første testen danner nullhypotesen for den "
"andre. Det er i denne forstand at type-1-metoden er strengt sekvensiell. "
"Hver test bygger direkte på resultatene fra den forrige. I en annen forstand "
"er den imidlertid svært uelegant, fordi det er en sterk asymmetri mellom de "
"to testene. Testen av hovedeffekten av ``sugar`` (den første testen) "
"ignorerer ``milk`` fullstendig, mens testen av hovedeffekten av ``milk`` "
"(den andre testen) tar ``sugar`` i betraktning. Uansett, den fjerde modellen "
"i vår sekvens er nå den fullstendige modellen, ``babble ~ sugar + milk + "
"sugar * milk``, og den tilsvarende hypotesetesten er:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:177 ../../Ch14/Ch14_ANOVA2_11.rst:260
#: ../../Ch14/Ch14_ANOVA2_11.rst:269 ../../Ch14/Ch14_ANOVA2_11.rst:279
#: ../../Ch14/Ch14_ANOVA2_11.rst:483
msgid "``babble ~ sugar + milk + sugar * milk``"
msgstr "``babble ~ sugar + milk + sugar * milk``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:180
msgid ""
"Type 3 sum of squares is the default hypothesis testing method used by "
"jamovi ANOVA, so to run a Type 1 sum of squares analysis we have to select "
"``Type 1`` in the ``Sum of squares`` selection box in the jamovi ``ANOVA`` → "
"``Model`` options. This gives us the ANOVA table shown in :numref:`fig-"
"factorialanova16`."
msgstr ""
"Kvadratsummen av type 3 er standardmetoden for hypotesetesting som brukes av "
"ANOVA i jamovi, så for å kjøre en analyse med kvadratsummen av type 1 må vi "
"velge ``Type 1`` i valgboksen ``Sum of squares`` i jamovi ``ANOVA`` → "
"``Model``-opsjonene. Dette gir oss ANOVA-tabellen som vises i :numref:`fig-"
"factorialanova16`."

#: ../../Ch14/Ch14_ANOVA2_11.rst:187
msgid ""
"Results table using Type 1 sum of squares, factor ``sugar`` entered first"
msgstr ""
"Resultattabell med kvadratsummen av type 1, faktor ``sugar`` lagt inn først"

#: ../../Ch14/Ch14_ANOVA2_11.rst:191
msgid ""
"ANOVA results table using Type 1 sum of squares in jamovi (with the |coffee|"
"_ data set and a saturated model with the factors ``sugar``, ``milk``, and "
"their interaction; factor ``sugar`` is entered first)."
msgstr ""
"ANOVA-resultattabell med kvadratsummen av type 1 i jamovi (med datasettet |"
"coffee|_ og en fullstendig modell med faktorene ``sugar``, ``milk`` og deres "
"interaksjon; faktoren ``sugar`` er lagt inn først)."

#: ../../Ch14/Ch14_ANOVA2_11.rst:197
msgid ""
"The big problem with using Type 1 sum of squares is the fact that it really "
"does depend on the order in which you enter the variables. Yet, in many "
"situations the researcher has no reason to prefer one ordering over another. "
"This is presumably the case for our milk and sugar problem. Should we add "
"milk first or sugar first? It feels exactly as arbitrary as a data analysis "
"question as it does as a coffee-making question. There may in fact be some "
"people with firm opinions about ordering, but it’s hard to imagine a "
"principled answer to the question. Yet, look what happens when we change the "
"ordering, as in :numref:`fig-factorialanova17`."
msgstr ""
"Det store problemet med å bruke kvadratsummen av type 1 er at den avhenger "
"av rekkefølgen du legger inn variablene i. I mange situasjoner er det "
"imidlertid ingen grunn til å foretrekke en annen rekkefølge. I mange "
"situasjoner har forskeren imidlertid ingen grunn til å foretrekke én "
"rekkefølge fremfor en annen. Dette er antakelig tilfelle for vårt problem "
"med melk og sukker. Skal vi tilsette melk først eller sukker først? Det "
"føles akkurat like vilkårlig som et spørsmål om dataanalyse som det gjør som "
"et spørsmål om kaffekoking. Det kan faktisk være noen som har bestemte "
"meninger om rekkefølgen, men det er vanskelig å forestille seg et "
"prinsipielt svar på spørsmålet. Likevel, se hva som skjer når vi endrer "
"rekkefølgen, som i :numref:`fig-factorialanova17`."

#: ../../Ch14/Ch14_ANOVA2_11.rst:209
msgid "Results table using Type 1 sum of squares, factor milk entered first"
msgstr ""
"Resultattabell med kvadratsummen av type 1, faktor ``milk`` lagt inn først"

#: ../../Ch14/Ch14_ANOVA2_11.rst:213
msgid ""
"ANOVA results table using Type 1 sum of squares in jamovi (with the |coffee|"
"_ data set and a saturated model with the factors ``milk``, ``sugar``, and "
"their interaction; factor ``milk`` is entered first)."
msgstr ""
"ANOVA-resultattabell med kvadratsummen av type 1 i jamovi (med datasettet |"
"coffee|_ og en fullstendig modell med faktorene ``milk``, ``sugar`` og deres "
"interaksjon ``sugar * milk``; faktoren ``milk`` er lagt inn først)."

#: ../../Ch14/Ch14_ANOVA2_11.rst:219
msgid ""
"The *p*-values for both main effect terms have changed, and fairly "
"dramatically. Among other things, the effect of ``milk`` has become "
"significant (though one should avoid drawing any strong conclusions about "
"this, as I’ve mentioned previously). Which of these two ANOVAs should one "
"report? It’s not immediately obvious."
msgstr ""
"*p*-verdiene for begge hovedeffekttermene har endret seg, og det ganske "
"dramatisk. Blant annet er effekten av ``milk`` blitt signifikant (selv om "
"man bør unngå å trekke noen sterke konklusjoner om dette, som jeg har nevnt "
"tidligere). Hvilken av disse to ANOVAene bør man rapportere? Det er ikke "
"umiddelbart opplagt."

#: ../../Ch14/Ch14_ANOVA2_11.rst:225
msgid ""
"When you look at the hypothesis tests that are used to define the “first” "
"main effect and the “second” one, it’s clear that they’re qualitatively "
"different from one another. In our initial example, we saw that the test for "
"the main effect of ``sugar`` completely ignores ``milk``, whereas the test "
"of the main effect of ``milk`` does take ``sugar`` into account. As such, "
"the Type 1 testing strategy really does treat the first main effect as if it "
"had a kind of theoretical primacy over the second one. In my experience "
"there is very rarely if ever any theoretically primacy of this kind that "
"would justify treating any two main effects asymmetrically."
msgstr ""
"Når du ser på hypotesetestene som brukes til å definere den «første» og den "
"«andre» hovedeffekten, er det tydelig at de er kvalitativt forskjellige fra "
"hverandre. I vårt første eksempel så vi at testen for hovedeffekten av "
"``sugar`` fullstendig ignorerer ``milk``, mens testen for hovedeffekten av "
"``milk`` tar hensyn til ``sugar``. Type-1-teststrategien behandler altså den "
"første hovedeffekten som om den hadde en slags teoretisk forrang over den "
"andre. Etter min erfaring er det svært sjelden eller aldri noen teoretisk "
"forrang av denne typen som rettferdiggjør en asymmetrisk behandling av to "
"hovedeffekter."

#: ../../Ch14/Ch14_ANOVA2_11.rst:236
msgid ""
"The consequence of all this is that Type 1 tests are very rarely of much "
"interest, and so we should move on to discuss Type 2 tests and Type 3 tests."
msgstr ""
"Konsekvensen av alt dette er at type-1-tester sjelden er særlig "
"interessante, og vi bør derfor gå videre til å diskutere type-2-tester og "
"type-3-tester."

#: ../../Ch14/Ch14_ANOVA2_11.rst:241
msgid "Type 3 sum of squares"
msgstr "Kvadratsummen av type 3"

#: ../../Ch14/Ch14_ANOVA2_11.rst:243
msgid ""
"Having just finished talking about Type 1 tests, you might think that the "
"natural thing to do next would be to talk about Type 2 tests. However, I "
"think it’s actually a bit more natural to discuss Type 3 tests (which are "
"simple and the default in jamovi ANOVA) before talking about Type 2 tests "
"(which are trickier). The basic idea behind Type 3 tests is extremely "
"simple. Regardless of which term you’re trying to evaluate, run the *F*-test "
"in which the alternative hypothesis corresponds to the full ANOVA model as "
"specified by the user, and the null model just deletes that one term that "
"you’re testing. For instance, in the example from the |coffee|_ data set, in "
"which our full model was ``babble ~ sugar + milk + sugar * milk``, the test "
"for a main effect of ``sugar`` would correspond to a comparison between the "
"following two models:"
msgstr ""
"Etter å ha snakket om type-1-tester, skulle man kanskje tro at det neste "
"naturlige ville være å snakke om type-2-tester. Men jeg synes faktisk det er "
"litt mer naturlig å snakke om type-3-tester (som er enkle og standard i "
"jamovi ANOVA) før vi snakker om type-2-tester (som er vanskeligere). Den "
"grunnleggende ideen bak type-3-tester er ekstremt enkel. Uansett hvilken "
"term du prøver å evaluere, kjører du *F*-testen der alternativhypotesen "
"tilsvarer den fullstendige ANOVA-modellen som spesifisert av brukeren, og "
"nullmodellen bare sletter den ene termen du tester. For eksempel, i "
"eksemplet fra datasettet |coffee|_, der den fullstendige modellen vår var "
"``babble ~ sugar + milk + sugar * milk``, vil testen for en hovedeffekt av "
"``sugar`` tilsvare en sammenligning mellom følgende to modeller:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:258
msgid "``babble ~ milk + sugar * milk``"
msgstr "``babble ~ milk + sugar * milk``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:263
msgid ""
"Similarly the main effect of ``milk`` is evaluated by testing the full model "
"against a null model that removes the ``milk`` term, like so:"
msgstr ""
"På samme måte evalueres hovedeffekten av ``milk`` ved å teste hele modellen "
"mot en nullmodell som fjerner ``milk``-termen, på denne måten:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:267
msgid "``babble ~ sugar + sugar * milk``"
msgstr "``babble ~ sugar + sugar * milk``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:272
msgid ""
"Finally, the interaction term ``sugar * milk`` is evaluated in exactly the "
"same way. Once again, we test the full model against a null model that "
"removes the ``sugar * milk`` interaction term, like so:"
msgstr ""
"Til slutt evalueres interaksjonstermen ``sugar * milk`` på nøyaktig samme "
"måte. Igjen tester vi den fullstendige modellen mot en nullmodell som "
"fjerner interaksjonstermen ``sugar * milk``, slik:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:282
msgid ""
"The basic idea generalises to higher order ANOVAs. For instance, suppose "
"that we were trying to run an ANOVA with three factors, ``A``, ``B`` and "
"``C``, and we wanted to consider all possible main effects and all possible "
"interactions, including the three way interaction ``A*B*C``. The table below "
"shows you what the Type 3 tests look like for this situation:"
msgstr ""
"Den grunnleggende ideen kan generaliseres til ANOVAer av høyere orden. Anta "
"for eksempel at vi prøver å kjøre en ANOVA med tre faktorer, ``A``, ``B`` og "
"``C``, og at vi ønsker å ta hensyn til alle mulige hovedeffekter og alle "
"mulige interaksjoner, inkludert treveisinteraksjonen ``A*B*C``. Tabellen "
"nedenfor viser hvordan type-3-testene ser ut i denne situasjonen:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:290 ../../Ch14/Ch14_ANOVA2_11.rst:438
msgid "Term being tested is"
msgstr "Termen som testes er"

#: ../../Ch14/Ch14_ANOVA2_11.rst:290 ../../Ch14/Ch14_ANOVA2_11.rst:438
msgid "Null model is ``outcome ~ …``"
msgstr "Nullmodellen er ``outcome ~ …``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:290 ../../Ch14/Ch14_ANOVA2_11.rst:438
msgid "Alternative model is ``outcome ~ …``"
msgstr "Alternativ modell er ``outcome ~ …``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:293 ../../Ch14/Ch14_ANOVA2_11.rst:441
msgid "``A``"
msgstr "``A``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:293
msgid "``B + C + A * B + A * C + B * C + A * B * C``"
msgstr "``B + C + A * B + A * C + B * C + A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:293 ../../Ch14/Ch14_ANOVA2_11.rst:296
#: ../../Ch14/Ch14_ANOVA2_11.rst:299 ../../Ch14/Ch14_ANOVA2_11.rst:302
#: ../../Ch14/Ch14_ANOVA2_11.rst:305 ../../Ch14/Ch14_ANOVA2_11.rst:308
#: ../../Ch14/Ch14_ANOVA2_11.rst:311 ../../Ch14/Ch14_ANOVA2_11.rst:456
msgid "``A + B + C + A * B + A * C + B * C + A * B * C``"
msgstr "``A + B + C + A * B + A * C + B * C + A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:296 ../../Ch14/Ch14_ANOVA2_11.rst:443
msgid "``B``"
msgstr "``B``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:296
msgid "``A + C + A * B + A * C + B * C + A * B * C``"
msgstr "``A + C + A * B + A * C + B * C + A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:299 ../../Ch14/Ch14_ANOVA2_11.rst:445
msgid "``C``"
msgstr "``C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:299
msgid "``A + B + A * B + A * C + B * C + A * B * C``"
msgstr "``A + B + A * B + A * C + B * C + A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:302 ../../Ch14/Ch14_ANOVA2_11.rst:447
msgid "``A * B``"
msgstr "``A * B``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:302
msgid "``A + B + C + A * C + B * C + A * B * C``"
msgstr "``A + B + C + A * C + B * C + A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:305 ../../Ch14/Ch14_ANOVA2_11.rst:450
msgid "``A * C``"
msgstr "``A * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:305
msgid "``A + B + C + A * B + B * C + A * B * C``"
msgstr "``A + B + C + A * B + B * C + A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:308 ../../Ch14/Ch14_ANOVA2_11.rst:453
msgid "``B * C``"
msgstr "``B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:308
msgid "``A + B + C + A * B + A * C + A * B * C``"
msgstr "``A + B + C + A * B + A * C + A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:311 ../../Ch14/Ch14_ANOVA2_11.rst:456
msgid "``A * B * C``"
msgstr "``A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:311 ../../Ch14/Ch14_ANOVA2_11.rst:447
#: ../../Ch14/Ch14_ANOVA2_11.rst:450 ../../Ch14/Ch14_ANOVA2_11.rst:453
#: ../../Ch14/Ch14_ANOVA2_11.rst:456
msgid "``A + B + C + A * B + A * C + B * C``"
msgstr "``A + B + C + A * B + A * C + B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:315
msgid ""
"As ugly as that table looks, it’s pretty simple. In all cases, the "
"alternative hypothesis corresponds to the full model which contains three "
"main effect terms (e.g. ``A``), three two-way interactions (e.g. ``A * B``) "
"and one three-way interaction (i.e., ``A * B * C``). The null model always "
"contains 6 of these 7 terms, and the missing one is the one whose "
"significance we’re trying to test."
msgstr ""
"Selv om tabellen ser stygg ut, er den ganske enkel. I alle tilfeller "
"tilsvarer alternativhypotesen den fullstendige modellen som inneholder tre "
"hovedeffekttermer (f.eks. ``A``), tre toveis interaksjoner (f.eks. ``A * "
"B``) og en treveis interaksjon (dvs. ``A * B * C``). Nullmodellen inneholder "
"alltid 6 av disse 7 termene, og den manglende termen er det vi prøver å "
"teste signifikansen av."

#: ../../Ch14/Ch14_ANOVA2_11.rst:322
msgid ""
"At first pass, Type 3 tests seem like a nice idea. Firstly, we’ve removed "
"the asymmetry that caused us to have problems when running Type 1 tests. And "
"because we’re now treating all terms the same way, the results of the "
"hypothesis tests do not depend on the order in which we specify them. This "
"is definitely a good thing. However, there is a big problem when "
"interpreting the results of the tests, especially for main effect terms. "
"Consider the |coffee|_ data. Suppose it turns out that the main effect of "
"``milk`` is not significant according to the Type 3 tests. What this is "
"telling us is that ``babble ~ sugar + sugar * milk`` is a better model for "
"the data than the full model. But what does that even *mean*? If the "
"interaction term ``sugar * milk`` was also non-significant, we’d be tempted "
"to conclude that the data are telling us that the only thing that matters is "
"``sugar``. But suppose we have a significant interaction term, but a non-"
"significant main effect of ``milk``. In this case, are we to assume that "
"there really is an “effect of sugar”, an “interaction between milk and "
"sugar”, but no “effect of milk”? That seems crazy. The right answer simply "
"*must* be that it’s meaningless\\ [#]_ to talk about the main effect if the "
"interaction is significant. In general, this seems to be what most "
"statisticians advise us to do, and I think that’s the right advice. But if "
"it really is meaningless to talk about non-significant main effects in the "
"presence of a significant interaction, then it’s not at all obvious why Type "
"3 tests should allow the null hypothesis to rely on a model that includes "
"the interaction but omits one of the main effects that make it up. When "
"characterised in this fashion, the null hypotheses really don’t make much "
"sense at all."
msgstr ""
"Ved første øyekast virker type-3-tester som en god idé. For det første har "
"vi fjernet asymmetrien som skapte problemer da vi kjørte type-1-tester. Og "
"fordi vi nå behandler alle termene på samme måte, avhenger ikke resultatene "
"av hypotesetestene av rekkefølgen vi spesifiserer dem i. Dette er definitivt "
"en god ting. Det er imidlertid et stort problem når man skal tolke "
"resultatene av testene, spesielt for hovedeffekttermene. Ta for eksempel "
"dataene for |coffee|_. Anta at det viser seg at hovedeffekten av ``milk`` "
"ikke er signifikant i henhold til type-3-testene. Dette forteller oss at "
"``babble ~ sugar + sugar * milk`` er en bedre modell for dataene enn den "
"fullstendige modellen. Men hva *betyr* det egentlig? Hvis interaksjonstermen "
"``sugar * milk`` også var ikke-signifikant, ville vi være fristet til å "
"konkludere med at dataene forteller oss at det eneste som betyr noe, er "
"``sugar``. Men la oss anta at vi har en signifikant interaksjonsterm, men en "
"ikke-signifikant hovedeffekt av ``milk``. Skal vi i så fall anta at det "
"virkelig er en «effekt av ``sugar``», en «interaksjon mellom ``milk`` og "
"``sugar``», men ingen «effekt av ``milk``»? Det virker jo helt sprøtt. Det "
"riktige svaret *må* rett og slett være at det er meningsløst\\ [#]_ å snakke "
"om hovedeffekten hvis interaksjonen er signifikant. Generelt ser det ut til "
"å være det de fleste statistikere råder oss til å gjøre, og jeg tror det er "
"et riktig råd. Men hvis det virkelig er meningsløst å snakke om ikke-"
"signifikante hovedeffekter i nærvær av en signifikant interaksjon, er det "
"slett ikke opplagt hvorfor type-3-tester skal tillate at nullhypotesen "
"baserer seg på en modell som inkluderer interaksjonen, men utelater en av "
"hovedeffektene som utgjør den. Når nullhypotesene karakteriseres på denne "
"måten, gir de egentlig ikke mye mening i det hele tatt."

#: ../../Ch14/Ch14_ANOVA2_11.rst:349
msgid ""
"Later on, we’ll see that Type 3 tests can be redeemed in some contexts, but "
"first let’s take a look at the ANOVA results table using Type 3 sum of "
"squares, see :numref:`fig-factorialanova18`."
msgstr ""
"Senere skal vi se at type-3-tester kan være nyttige i noen sammenhenger, men "
"la oss først ta en titt på ANOVA-resultattabellen med type-3-kvadratsum, se :"
"numref:`fig-factorialanova18`."

#: ../../Ch14/Ch14_ANOVA2_11.rst:355
msgid "Results table using Type 3 sum of squares"
msgstr "Resultattabell med kvadratsummen av type 3"

#: ../../Ch14/Ch14_ANOVA2_11.rst:359
msgid ""
"ANOVA results table using Type 3 sum of squares in jamovi (with the |coffee|"
"_ data set and a saturated model with the factors ``sugar``, ``milk``, and "
"their interaction)."
msgstr ""
"ANOVA-resultattabell med type-3-kvadratsummen i jamovi (med datasettet |"
"coffee|_ og en fullstendig modell med faktorene ``sugar``, ``milk`` og deres "
"interaksjon)."

#: ../../Ch14/Ch14_ANOVA2_11.rst:365
msgid ""
"But be aware, one of the perverse features of the Type 3 testing strategy is "
"that typically the results turn out to depend on the *contrasts* that you "
"use to encode your factors (see section :doc:`Ch14_ANOVA2_08` if you’ve "
"forgotten what the different types of contrasts are).\\ [#]_"
msgstr ""
"Men vær oppmerksom på at et av de perverse trekkene ved type-3-"
"teststrategien er at resultatene vanligvis viser seg å avhenge av "
"*kontrastene* som du bruker til å kode faktorene dine (se avsnitt :doc:"
"`Ch14_ANOVA2_08` hvis du har glemt hva de forskjellige typene kontraster er)."
"\\ [#]_"

#: ../../Ch14/Ch14_ANOVA2_11.rst:370
msgid ""
"Okay, so if the *p*-values that typically come out of Type 3 analyses (but "
"not in jamovi) are so sensitive to the choice of contrasts, does that mean "
"that Type 3 tests are essentially arbitrary and not to be trusted? To some "
"extent that’s true, and when we turn to a discussion of Type 2 tests we’ll "
"see that Type 2 analyses avoid this arbitrariness entirely, but I think "
"that’s too strong a conclusion. Firstly, it’s important to recognise that "
"some choices of contrasts will always produce the same answers (ah, so this "
"is what is happening in jamovi). Of particular importance is the fact that "
"if the columns of our contrast matrix are all constrained to sum to zero, "
"then the Type 3 analysis will always give the same answers."
msgstr ""
"Ok, så hvis *p*-verdiene som vanligvis kommer ut av type-3-analyser (men "
"ikke i jamovi) er så følsomme for valg av kontraster, betyr det at type-3-"
"tester i bunn og grunn er vilkårlige og ikke til å stole på? Til en viss "
"grad er det sant, og når vi går over til å diskutere type-2-tester, vil vi "
"se at type-2-analyser unngår denne vilkårligheten helt og holdent, men jeg "
"tror det er en for sterk konklusjon. For det første er det viktig å erkjenne "
"at noen valg av kontraster alltid vil gi de samme svarene (ah, så det er "
"dette som skjer i jamovi). Spesielt viktig er det faktum at hvis alle "
"kolonnene i kontrastmatrisen vår er begrenset til å summere til null, så vil "
"type-3-analysen alltid gi de samme svarene."

#: ../../Ch14/Ch14_ANOVA2_11.rst:382
msgid "Type 2 sum of squares"
msgstr "Kvadratsummen av type 2"

#: ../../Ch14/Ch14_ANOVA2_11.rst:384
msgid ""
"Okay, so we’ve seen Type 1 and 3 tests now, and both are pretty "
"straightforward. Type 1 tests are performed by gradually adding terms one at "
"a time, whereas Type 3 tests are performed by taking the full model and "
"looking to see what happens when you remove each term. However, both can "
"have some limitations. Type 1 tests are dependent on the order in which you "
"enter the terms, and Type 3 tests are dependent on how you code up your "
"contrasts. Type 2 tests are a little harder to describe, but they avoid both "
"of these problems, and as a result they are a little easier to interpret."
msgstr ""
"Nå har vi sett type-1- og type-3-tester, og begge er ganske enkle. Type-1-"
"tester utføres ved at man gradvis legger til en term om gangen, mens type-3-"
"tester utføres ved at man tar hele modellen og ser hva som skjer når man "
"fjerner hver term. Begge kan imidlertid ha noen begrensninger. Type-1-tester "
"er avhengig av rekkefølgen du legger inn termene i, og type-3-tester er "
"avhengig av hvordan du koder opp kontrastene dine. Type-2-tester er litt "
"vanskeligere å beskrive, men de unngår begge disse problemene, og er derfor "
"litt enklere å tolke."

#: ../../Ch14/Ch14_ANOVA2_11.rst:394
msgid ""
"Type 2 tests are broadly similar to Type 3 tests. Start with a “full” model, "
"and test a particular term by deleting it from that model. However, Type 2 "
"tests are based on the **marginality principle** which states that you "
"should not omit a lower order term from your model if there are any higher "
"order ones that depend on it. So, for instance, if your model contains the "
"two-way interaction ``A * B`` (a 2nd order term), then it really ought to "
"contain the main effects ``A`` and ``B`` (1st order terms). Similarly, if it "
"contains a three-way interaction term ``A * B * C``, then the model must "
"also include the main effects ``A``, ``B`` and ``C`` as well as the simpler "
"interactions ``A * B``, ``A * C`` and ``B * C``. Type 3 tests routinely "
"violate the marginality principle. For instance, consider the test of the "
"main effect of ``A`` in the context of a three-way ANOVA that includes all "
"possible interaction terms. According to Type 3 tests, our null and "
"alternative models are:"
msgstr ""
"Type-2-tester ligner i stor grad på type-3-tester. Du starter med en "
"«fullstendig» modell, og tester en bestemt term ved å utelate den fra "
"modellen. Type-2-tester er imidlertid basert på **marginalitetsprinsippet**, "
"som sier at du ikke bør utelate en term av lavere orden fra modellen din "
"hvis det finnes termer av høyere orden som avhenger av det. Hvis modellen "
"din for eksempel inneholder toveisinteraksjonen ``A * B`` (et 2. "
"ordensterm), bør den egentlig inneholde hovedeffektene ``A`` og ``B`` (1. "
"ordensterm). Tilsvarende, hvis den inneholder en treveis interaksjonsterm "
"``A * B * C``, må modellen også inneholde hovedeffektene ``A``, ``B`` og "
"``C`` i tillegg til de enklere interaksjonene ``A * B``, ``A * C`` og ``B * "
"C``. Type-3-tester bryter rutinemessig med marginalitetsprinsippet. Tenk for "
"eksempel på testen av hovedeffekten av ``A`` i forbindelse med en treveis "
"ANOVA som inkluderer alle mulige interaksjonsterm. I henhold til type-3-"
"tester er null- og alternativmodellene våre:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:410
msgid "``outcome ~ B + C + A * B + A * C + B * C + A * B * C``"
msgstr "``outcome ~ B + C + A * B + A * C + B * C + A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:412
msgid "``outcome ~ A + B + C + A * B + A * C + B*C + A * B * C``"
msgstr "``outcome ~ A + B + C + A * B + A * C + B*C + A * B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:415
msgid ""
"Notice that the null hypothesis omits ``A``, but includes ``A * B``, ``A * "
"C`` and ``A * B * C`` as part of the model. This, according to the Type 2 "
"tests, is not a good choice of null hypothesis. What we should do instead, "
"if we want to test the null hypothesis that ``A`` is not relevant to our "
"``outcome``, is to specify the null hypothesis that is the most complicated "
"model that does not rely on ``A`` in any form, even as an interaction. The "
"alternative hypothesis corresponds to this null model plus a main effect "
"term of ``A``. This is a lot closer to what most people would intuitively "
"think of as a “main effect of ``A``”, and it yields the following as our "
"Type 2 test of the main effect of ``A``:\\ [#]_"
msgstr ""
"Legg merke til at nullhypotesen utelater ``A``, men inkluderer ``A * B``, "
"``A * C`` og ``A * B * C`` som en del av modellen. Dette er i henhold til "
"type-2-testene ikke et godt valg av nullhypotese. Det vi i stedet bør gjøre, "
"hvis vi ønsker å teste nullhypotesen om at ``A`` ikke er relevant for vårt "
"``outcome``, er å spesifisere nullhypotesen som er den mest kompliserte "
"modellen som ikke er avhengig av ``A`` i noen form, heller ikke som en "
"interaksjon. Alternativhypotesen tilsvarer denne nullmodellen pluss en "
"hovedeffektterm av ``A``. Dette er mye nærmere det folk flest intuitivt vil "
"tenke på som en «hovedeffekt av ``A``», og det gir følgende som vår type-2-"
"test av hovedeffekten av ``A``:\\ [#]_"

#: ../../Ch14/Ch14_ANOVA2_11.rst:428
msgid "``outcome ~ B + C + B * C``"
msgstr "``outcome ~ B + C + B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:430
msgid "``outcome ~ A + B + C + B * C``"
msgstr "``outcome ~ A + B + C + B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:433
msgid ""
"Anyway, just to give you a sense of how the Type 2 tests play out, here’s "
"the full table of tests that would be applied in a three-way factorial ANOVA:"
msgstr ""
"Uansett, bare for å gi deg en følelse av hvordan type-2-testene fungerer, "
"her er den fullstendige tabellen med tester som ville blitt brukt i en "
"treveis faktoriell ANOVA:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:441
msgid "``B + C + B * C``"
msgstr "``B + C + B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:441
msgid "``A + B + C + B * C``"
msgstr "``A + B + C + B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:443
msgid "``A + C + A * C``"
msgstr "``A + C + A * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:443
msgid "``A + B + C + A * C``"
msgstr "``A + B + C + A * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:445
msgid "``A + B + A * B``"
msgstr "``A + B + A * B``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:445
msgid "``A + B + C + A * B``"
msgstr "``A + B + C + A * B``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:447
msgid "``A + A * C + B * C``"
msgstr "``A + A * C + B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:450
msgid "``A + B + C + A * B + B * C``"
msgstr "``A + B + C + A * B + B * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:453
msgid "``A + B + C + A * B + A * C``"
msgstr "``A + B + C + A * B + A * C``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:460
msgid ""
"In the context of the two way ANOVA that we’ve been using in the |coffee|_ "
"data, the hypothesis tests are even simpler. The main effect of ``sugar`` "
"corresponds to an *F*-test comparing these two models:"
msgstr ""
"I forbindelse med toveis ANOVA som vi har brukt i |coffee|_-dataene, er "
"hypotesetestene enda enklere. Hovedeffekten av ``sugar`` tilsvarer en *F*-"
"test som sammenligner disse to modellene:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:465
msgid "``babble ~ milk``"
msgstr "``babble ~ milk``"

#: ../../Ch14/Ch14_ANOVA2_11.rst:470
msgid "The test for the main effect of ``milk`` is"
msgstr "Testen for hovedeffekten av ``milk`` er"

#: ../../Ch14/Ch14_ANOVA2_11.rst:478
msgid "Finally, the test for the interaction ``sugar * milk`` is:"
msgstr "Til slutt er testen for interaksjonen ``sugar * milk``:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:486
msgid ""
"Running the tests are again straightforward. Just select ``Type 2`` in the "
"``Sum of squares`` selection box in the jamovi ``ANOVA`` → ``Model`` "
"options, This gives us the ANOVA table shown in :numref:`fig-"
"factorialanova19`."
msgstr ""
"Det er igjen enkelt å kjøre testene. Bare velg ``Type 2`` i valgboksen ``Sum "
"of squares`` i jamovi ``ANOVA`` → ``Model``-alternativene. Dette gir oss "
"ANOVA-tabellen som vises i :numref:`fig-factorialanova19`."

#: ../../Ch14/Ch14_ANOVA2_11.rst:492
msgid "Results table using Type 2 sum of squares"
msgstr "Resultattabell med kvadratsummen av type 2"

#: ../../Ch14/Ch14_ANOVA2_11.rst:496
msgid ""
"ANOVA results table using Type 2 sum of squares in jamovi (with the |coffee|"
"_ data set and a saturated model with the factors ``sugar``, ``milk``, and "
"their interaction)."
msgstr ""
"ANOVA-resultattabell med type-2-kvadratsummen i jamovi (med datasettet |"
"coffee|_ og en fullstendig modell med faktorene ``sugar``, ``milk`` og deres "
"interaksjon)."

#: ../../Ch14/Ch14_ANOVA2_11.rst:502
msgid ""
"Type 2 tests have some clear advantages over Type 1 and Type 3 tests. They "
"don’t depend on the order in which you specify factors (unlike Type 1), and "
"they don’t depend on the contrasts that you use to specify your factors "
"(unlike Type 3). And although opinions may differ on this last point, and it "
"will definitely depend on what you’re trying to do with your data, I do "
"think that the hypothesis tests that they specify are more likely to "
"correspond to something that you actually care about. As a consequence, I "
"find that it’s usually easier to interpret the results of a Type 2 test than "
"the results of a Type 1 or Type 3 test. For this reason my tentative advice "
"is that, if you can’t think of any obvious model comparisons that directly "
"map onto your research questions but you still want to run an ANOVA in an "
"unbalanced design, Type 2 tests are probably a better choice than Type 1 or "
"Type 3.\\ [#]_"
msgstr ""
"Type-2-tester har noen klare fordeler i forhold til type-1- og type-3-"
"tester. De avhenger ikke av rekkefølgen du spesifiserer faktorene i (i "
"motsetning til type 1), og de avhenger ikke av kontrastene du bruker til å "
"spesifisere faktorene dine (i motsetning til type 3). Og selv om det kan "
"være ulike meninger om dette siste punktet, og det definitivt vil avhenge av "
"hva du prøver å gjøre med dataene dine, tror jeg at det er mer sannsynlig at "
"hypotesetestene som de spesifiserer, samsvarer med noe du faktisk bryr deg "
"om. Derfor synes jeg at det vanligvis er lettere å tolke resultatene av en "
"type-2-test enn resultatene av en type-1- eller type-3-test. Derfor er mitt "
"foreløpige råd at hvis du ikke kan komme på noen åpenbare "
"modellsammenligninger som er direkte knyttet til forskningsspørsmålene dine, "
"men du likevel ønsker å kjøre en ANOVA i et ubalansert design, er type-2-"
"tester sannsynligvis et bedre valg enn type 1 eller type 3.\\ [#]_"

#: ../../Ch14/Ch14_ANOVA2_11.rst:517
msgid "Effect sizes (and non-additive sums of squares)"
msgstr "Effektstørrelser (og ikke-additive kvadratsummer)"

#: ../../Ch14/Ch14_ANOVA2_11.rst:519
msgid ""
"jamovi also provides the effect sizes η² and partial η² when you select "
"these options, as in :numref:`fig-factorialanova19`. However, when you’ve "
"got an unbalanced design there’s a bit of extra complexity involved."
msgstr ""
"jamovi gir også effektstørrelsene η² og partiell η² når du velger disse "
"alternativene, som i :numref:`fig-factorialanova19`. Når du har et "
"ubalansert design, er det imidlertid litt ekstra kompleksitet involvert."

#: ../../Ch14/Ch14_ANOVA2_11.rst:523
msgid ""
"If you remember back to our very early discussions of ANOVA, one of the key "
"ideas behind the sums of squares calculations is that if we add up all the "
"SS terms associated with the effects in the model, and add that to the "
"residual SS, they’re supposed to add up to the total sum of squares. And, on "
"top of that, the whole idea behind η² is that, because you’re dividing one "
"of the SS terms by the total SS value, an η² value can be interpreted as the "
"proportion of variance accounted for by a particular term. But this is not "
"so straightforward in unbalanced designs because some of the variance goes "
"“missing”."
msgstr ""
"Hvis du husker tilbake til de tidlige diskusjonene våre om ANOVA, er en av "
"de viktigste ideene bak kvadratsummene (SS) at hvis vi legger sammen alle SS-"
"termene som er knyttet til effektene i modellen, og legger det til "
"kvadratsummenfor residueene, skal de summere seg til den totale "
"kvadratsummen. Og i tillegg er hele ideen bak η² at fordi du dividerer hver "
"av SS-termene med den totale kvadratummen, kan en η²-verdi tolkes som "
"andelen av variansen som forklares av en bestemt term. Men dette er ikke "
"like enkelt i ubalanserte design, fordi noe av variansen «mangler»."

#: ../../Ch14/Ch14_ANOVA2_11.rst:533
msgid ""
"This seems a bit odd at first, but here’s why. When you have unbalanced "
"designs your factors become correlated with one another, and it becomes "
"difficult to tell the difference between the effect of Factor A and the "
"effect of Factor B. In the extreme case, suppose that we’d run a 2 × 2 "
"design in which the number of participants in each group had been as follows:"
msgstr ""
"Dette virker litt merkelig i første omgang, men her er hvorfor. Når du har "
"ubalanserte design, blir faktorene korrelert med hverandre, og det blir "
"vanskelig å se forskjell på effekten av faktor A og effekten av faktor B. I "
"det ekstreme tilfellet kan vi tenke oss at vi hadde kjørt et 2 × 2-design "
"der antall deltakere i hver gruppe hadde vært som følger:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:541 ../../Ch14/Ch14_ANOVA2_11.rst:560
msgid "sugar"
msgstr "sukker"

#: ../../Ch14/Ch14_ANOVA2_11.rst:541 ../../Ch14/Ch14_ANOVA2_11.rst:560
msgid "no sugar"
msgstr "ingen sukker"

#: ../../Ch14/Ch14_ANOVA2_11.rst:543 ../../Ch14/Ch14_ANOVA2_11.rst:562
msgid "**milk**"
msgstr "**melk**"

#: ../../Ch14/Ch14_ANOVA2_11.rst:543 ../../Ch14/Ch14_ANOVA2_11.rst:545
#: ../../Ch14/Ch14_ANOVA2_11.rst:562 ../../Ch14/Ch14_ANOVA2_11.rst:564
msgid "100"
msgstr "100"

#: ../../Ch14/Ch14_ANOVA2_11.rst:545 ../../Ch14/Ch14_ANOVA2_11.rst:564
msgid "**no milk**"
msgstr "**ingen melk**"

#: ../../Ch14/Ch14_ANOVA2_11.rst:548
msgid ""
"Here we have a spectacularly unbalanced design: 100 people have milk and "
"sugar, 100 people have no milk and no sugar, and that’s all. There are 0 "
"people with milk and no sugar, and 0 people with sugar but no milk. Now "
"suppose that, when we collected the data, it turned out there is a large "
"(and statistically significant) difference between the “milk and sugar” "
"group and the “no-milk and no-sugar” group. Is this a main effect of sugar? "
"A main effect of milk? Or an interaction? It’s impossible to tell, because "
"the presence of sugar has a perfect association with the presence of milk. "
"Now suppose the design had been a little more balanced:"
msgstr ""
"Her har vi en spektakulær ubalansert design: 100 personer har melk og "
"sukker, 100 personer har ikke melk og ikke sukker, og det er alt. Det er 0 "
"personer med melk og uten sukker, og 0 personer med sukker, men uten melk. "
"Anta nå at det viser seg at det er en stor (og statistisk signifikant) "
"forskjell mellom gruppen «melk og sukker» og gruppen «ingen melk og ingen "
"sukker» når vi samler inn dataene. Er dette en hovedeffekt av sukker? En "
"hovedeffekt av melk? Eller en interaksjon? Det er umulig å si, fordi "
"tilstedeværelsen av sukker har en perfekt sammenheng med tilstedeværelsen av "
"melk. Sett nå at designet hadde vært litt mer balansert:"

#: ../../Ch14/Ch14_ANOVA2_11.rst:567
msgid ""
"This time around, it’s technically possible to distinguish between the "
"effect of milk and the effect of sugar, because we have a few people that "
"have one but not the other. However, it will still be pretty difficult to do "
"so, because the association between sugar and milk is still extremely "
"strong, and there are so few observations in two of the groups. Again, we’re "
"very likely to be in the situation where we *know* that the predictor "
"variables (milk and sugar) are related to the outcome (babbling), but we "
"don’t know if the *nature* of that relationship is a main effect of one or "
"the other predictor, or the interaction."
msgstr ""
"Denne gangen er det teknisk mulig å skille mellom effekten av ``milk`` og "
"effekten av ``sugar``, fordi vi har noen få personer som har det ene, men "
"ikke det andre. Det vil imidlertid fortsatt være ganske vanskelig å gjøre "
"det, fordi sammenhengen mellom ``sugar`` og ``milk`` fortsatt er ekstremt "
"sterk, og det er så få observasjoner i to av gruppene. Igjen er det svært "
"sannsynlig at vi er i en situasjon der vi *vet* at prediktorvariablene "
"(``milk`` og ``sugar``) er relatert til utfallet (``babble``), men vi vet "
"ikke om *karakteren* av denne relasjonen er en hovedeffekt av den ene eller "
"den andre prediktoren, eller interaksjonen."

#: ../../Ch14/Ch14_ANOVA2_11.rst:577
msgid ""
"This uncertainty is the reason for the missing variance. The “missing” "
"variance corresponds to variation in the outcome variable that is clearly "
"attributable to the predictors, but we don’t know which of the effects in "
"the model is responsible. When you calculate Type 1 sum of squares, no "
"variance ever goes missing. The sequential nature of Type 1 sum of squares "
"means that the ANOVA automatically attributes this variance to whichever "
"effects are entered first. However, the Type 2 and Type 3 tests are more "
"conservative. Variance that cannot be clearly attributed to a specific "
"effect doesn’t get attributed to any of them, and it goes missing."
msgstr ""
"Denne usikkerheten er årsaken til den manglende variansen. Den «manglende» "
"variansen tilsvarer variasjon i utfallsvariabelen som helt klart kan "
"tilskrives prediktorene, men vi vet ikke hvilken av effektene i modellen som "
"er ansvarlig. Når du beregner kvadratsummen av type 1, er det aldri noen "
"varians som mangler. Den sekvensielle karakteren til kvadratsummen av type 1 "
"betyr at ANOVA automatisk tilskriver denne variansen til de effektene som er "
"lagt inn først. Type-2- og type-3-testene er imidlertid mer konservative. "
"Varians som ikke klart kan tilskrives en spesifikk effekt, blir ikke "
"tilskrevet noen av dem, og den forsvinner."

#: ../../Ch14/Ch14_ANOVA2_11.rst:591
msgid ""
"This discrepancy in standard deviations might (and should) make you wonder "
"if we have a violation of the homogeneity of variance assumption. I’ll leave "
"it as an exercise for the reader to double check this using the Levene test "
"option."
msgstr ""
"Dette avviket i standardavvik kan (og bør) få deg til å lure på om vi har et "
"brudd på forutsetningen om varianshomogenitet. Jeg lar det være opp til "
"leseren å dobbeltsjekke dette ved hjelp av Levene-testen."

#: ../../Ch14/Ch14_ANOVA2_11.rst:597
msgid ""
"Actually, this is a bit of a lie. ANOVAs can vary in other ways besides the "
"ones I’ve discussed in this book. For instance, I’ve completely ignored the "
"difference between fixed-effect models in which the levels of a factor are "
"“fixed” by the experimenter or the world, and random-effect models in which "
"the levels are random samples from a larger population of possible levels "
"(this book only covers fixed-effect models). Don’t make the mistake of "
"thinking that this book, or any other one, will tell you “everything you "
"need to know” about statistics, any more than a single book could possibly "
"tell you everything you need to know about psychology, physics or "
"philosophy. Life is too complicated for that to *ever* be true. This isn’t a "
"cause for despair, though. Most researchers get by with a basic working "
"knowledge of ANOVA that doesn’t go any further than this book does. I just "
"want you to keep in mind that this book is only the beginning of a very long "
"story, not the whole story."
msgstr ""
"Dette er faktisk litt av en løgn. ANOVA-er kan variere på andre måter enn de "
"jeg har diskutert i denne boken. For eksempel har jeg fullstendig ignorert "
"forskjellen mellom modeller med fast effekt, der nivåene til en faktor er "
"«fiksert» av eksperimentator eller verden, og modeller med tilfeldig effekt, "
"der nivåene er tilfeldige utvalg fra en større populasjon av mulige nivåer "
"(denne boken dekker bare modeller med fast effekt). Ikke gjør den feilen å "
"tro at denne boken, eller noen annen, vil fortelle deg «alt du trenger å "
"vite» om statistikk, like lite som en enkelt bok kan fortelle deg alt du "
"trenger å vite om psykologi, fysikk eller filosofi. Livet er for komplisert "
"til at det *aldri* kan være sant. Dette er imidlertid ingen grunn til "
"fortvilelse. De fleste forskere klarer seg med en grunnleggende kunnskap om "
"ANOVA som ikke går lenger enn denne boken gjør. Jeg vil bare at du skal "
"huske på at denne boken bare er begynnelsen på en veldig lang historie, ikke "
"hele historien."

#: ../../Ch14/Ch14_ANOVA2_11.rst:614
msgid "Or, at the very least, rarely of interest."
msgstr "Eller i det minste sjelden av interesse."

#: ../../Ch14/Ch14_ANOVA2_11.rst:617
msgid ""
"However, in jamovi the results for Type 3 sum of squares ANOVA are the same "
"regardless of the contrast selected, so jamovi is obviously doing something "
"different!"
msgstr ""
"I jamovi er imidlertid resultatene for ANOVA med type-3-kvadratsummen de "
"samme, uavhengig av hvilken kontrast som er valgt, så jamovi gjør åpenbart "
"noe annet!"

#: ../../Ch14/Ch14_ANOVA2_11.rst:622
msgid ""
"Note, of course, that this does depend on the model that the user specified. "
"If the original ANOVA model doesn’t contain an interaction term for ``B * "
"C``, then obviously it won’t appear in either the null or the alternative. "
"But that’s true for Types 1, 2 and 3. They never include any terms that you "
"*didn’t* include, but they make different choices about how to construct "
"tests for the ones that you did include."
msgstr ""
"Merk at dette selvfølgelig avhenger av modellen som brukeren har "
"spesifisert. Hvis den opprinnelige ANOVA-modellen ikke inneholder en "
"interaksjonsterm for ``B * C``, vil det selvsagt ikke vises i verken null- "
"eller alternativmodellen. Men det gjelder for type 1, 2 og 3. De inkluderer "
"aldri noen termer som du *ikke* inkluderte, men de gjør forskjellige valg om "
"hvordan du skal konstruere tester for de du inkluderte."

#: ../../Ch14/Ch14_ANOVA2_11.rst:631
msgid ""
"I find it amusing to note that the default in R is Type 1 and the default in "
"SPSS and jamovi is Type 3. Neither of these appeals to me all that much. "
"Relatedly, I find it depressing that almost nobody in the psychological "
"literature ever bothers to report which Type of tests they ran, much less "
"the order of variables (for Type 1) or the contrasts used (for Type 3). "
"Often they don’t report what software they used either. The only way I can "
"ever make any sense of what people typically report is to try to guess from "
"auxiliary cues which software they were using, and to assume that they never "
"changed the default settings. Please don’t do this! Now that you know about "
"these issues make sure you indicate what software you used, and if you’re "
"reporting ANOVA results for unbalanced data, then specify what Type of tests "
"you ran, specify order information if you’ve done Type 1 tests and specify "
"contrasts if you’ve done Type 3 tests. Or, even better, do hypotheses tests "
"that correspond to things you really care about and then report those!"
msgstr ""
"Jeg synes det er morsomt å merke seg at standardinnstillingen i R er type 1, "
"mens standardinnstillingen i SPSS og jamovi er type 3. Ingen av disse "
"tiltaler meg noe særlig. I tillegg synes jeg det er deprimerende at nesten "
"ingen i den psykologiske litteraturen bryr seg om å rapportere hvilken type "
"tester de kjørte, langt mindre rekkefølgen på variablene (for type 1) eller "
"kontrastene som ble brukt (for type 3). Ofte oppgir de heller ikke hvilken "
"programvare de har brukt. Den eneste måten jeg kan forstå hva folk vanligvis "
"rapporterer, er å prøve å gjette hvilken programvare de brukte, og å anta at "
"de aldri endret standardinnstillingene. Vær så snill, ikke gjør dette! Nå "
"som du kjenner til disse problemene, må du sørge for å oppgi hvilken "
"programvare du har brukt, og hvis du rapporterer ANOVA-resultater for "
"ubalanserte data, må du oppgi hvilken type tester du har kjørt, spesifisere "
"rekkefølgeinformasjon hvis du har utført type-1-tester, og spesifisere "
"kontraster hvis du har utført type-3-tester. Eller, enda bedre, gjør "
"hypotesetester som tilsvarer ting du virkelig bryr deg om, og rapporter dem!"

#: ../../Ch14/Ch14_ANOVA2_12.rst:4
msgid "Summary"
msgstr "Sammendrag"

#: ../../Ch14/Ch14_ANOVA2_12.rst:6
msgid ""
"Factorial ANOVA with balanced designs, :doc:`without interactions "
"<Ch14_ANOVA2_01>` and :doc:`with interactions included <Ch14_ANOVA2_02>`"
msgstr ""
"Faktoriell ANOVA med balansert design, :doc:`uten interaksjoner "
"<Ch14_ANOVA2_01>` og :doc:`med interaksjoner inkludert <Ch14_ANOVA2_02>`"

#: ../../Ch14/Ch14_ANOVA2_12.rst:9
msgid ""
":doc:`Effect size, estimated means, and confidence intervals in a factorial "
"ANOVA <Ch14_ANOVA2_03>`"
msgstr ""
":doc:`Effektstørrelse, estimerte gjennomsnitt og konfidensintervaller i en "
"faktoriell ANOVA <Ch14_ANOVA2_03>`"

#: ../../Ch14/Ch14_ANOVA2_12.rst:12
msgid ":doc:`Checking assumptions in the ANOVA <Ch14_ANOVA2_04>`"
msgstr ":doc:`Sjekk av forutsetningene for ANOVA <Ch14_ANOVA2_04>`"

#: ../../Ch14/Ch14_ANOVA2_12.rst:14
msgid ":doc:`Ch14_ANOVA2_06`"
msgstr ":doc:`Ch14_ANOVA2_06`"

#: ../../Ch14/Ch14_ANOVA2_12.rst:16
msgid ""
":doc:`Understanding the linear model underlying ANOVA <Ch14_ANOVA2_07>`, "
"including :doc:`different contrasts <Ch14_ANOVA2_08>`"
msgstr ""
":doc:`Forståelse av den lineære modellen som ligger til grunn for ANOVA "
"<Ch14_ANOVA2_07>`, inkludert :doc:`forskjellige kontraster <Ch14_ANOVA2_08>`"

#: ../../Ch14/Ch14_ANOVA2_12.rst:19
msgid ""
":doc:`Post-hoc testing <Ch14_ANOVA2_09>` (using Tukey’s HSD) and a brief "
"commentary on :doc:`planned comparisons <Ch14_ANOVA2_10>`"
msgstr ""
":doc:`Post-hoc-testing <Ch14_ANOVA2_09>` (ved hjelp av Tukey's HSD) og en "
"kort kommentar til :doc:`planlagte sammenligninger <Ch14_ANOVA2_10>`"

#: ../../Ch14/Ch14_ANOVA2_12.rst:22
msgid ":doc:`Factorial ANOVA with unbalanced designs <Ch14_ANOVA2_11>`"
msgstr ":doc:`Faktoriell ANOVA med ubalanserte design <Ch14_ANOVA2_11>`"
