msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-03-17 18:06+0100\n"
"PO-Revision-Date: 2025-03-31 16:06+0000\n"
"Last-Translator: Anonymous <noreply@weblate.org>\n"
"Language-Team: Tamil <https://hosted.weblate.org/projects/lsjdocs/ch12/ta/>\n"
"Language: ta\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"X-Generator: Weblate 5.11-dev\n"
"Generated-By: Babel 2.17.0\n"

#: ../../Ch12/Ch12_Regression.rst:4
msgid "Correlation and linear regression"
msgstr "தொடர்பு மற்றும் நேரியல் பின்னடைவு"

#: ../../Ch12/Ch12_Regression.rst:24
msgid ""
"The goal in this chapter is to introduce **correlation** and **linear "
"regression**. These are the standard tools that statisticians rely on when "
"analysing the relationship between continuous predictors |continuous| and "
"continuous outcomes |continuous|."
msgstr ""
"இந்த அத்தியாயத்தில் உள்ள குறிக்கோள் ** தொடர்பு ** மற்றும் ** நேரியல் பின்னடைவு ** ஐ "
"அறிமுகப்படுத்துவதாகும். தொடர்ச்சியான முன்கணிப்பாளர்களுக்கிடையேயான உறவை பகுப்பாய்வு "
"செய்யும் போது புள்ளிவிவர வல்லுநர்கள் நம்பியிருக்கும் நிலையான கருவிகள் இவை | தொடர்ச்சியான "
"| மற்றும் தொடர்ச்சியான விளைவுகள் | தொடர்ச்சியான |."

#: ../../Ch12/Ch12_Regression.rst:31 ../../Ch12/Ch12_Regression_01.rst:423
msgid "continuous"
msgstr "continuous"

#: ../../Ch12/Ch12_Regression_01.rst:4
msgid "Correlations"
msgstr "தொடர்புகள்"

#: ../../Ch12/Ch12_Regression_01.rst:6
msgid ""
"In this section we’ll talk about how to describe the relationships *between* "
"variables in the data. To do that, we want to talk mostly about the "
"**correlation** between variables. But first, we need some data."
msgstr ""
"இந்த பிரிவில் தரவுகளில் உள்ள மாறிகள் இடையே உள்ள உறவுகளை எவ்வாறு விவரிப்பது என்பது பற்றி"
" பேசுவோம். அதைச் செய்ய, மாறிகள் இடையே ** தொடர்பு ** பற்றி பெரும்பாலும் பேச "
"விரும்புகிறோம். ஆனால் முதலில், எங்களுக்கு சில தரவு தேவை."

#: ../../Ch12/Ch12_Regression_01.rst:12
msgid "The data"
msgstr ""

#: ../../Ch12/Ch12_Regression_01.rst:14
msgid "Descriptive statistics for the |parenthood|_ data set."
msgstr "| பெற்றோர்ஊட் | _ தரவு தொகுப்புக்கான விளக்க புள்ளிவிவரங்கள்."

#: ../../Ch12/Ch12_Regression_01.rst:18
msgid "Variable"
msgstr "மாறக்கூடிய"

#: ../../Ch12/Ch12_Regression_01.rst:18
msgid "min"
msgstr "மணித்துளி"

#: ../../Ch12/Ch12_Regression_01.rst:18
msgid "max"
msgstr "அதிகபட்சம்"

#: ../../Ch12/Ch12_Regression_01.rst:18
msgid "mean"
msgstr ""

#: ../../Ch12/Ch12_Regression_01.rst:18
msgid "median"
msgstr "இடைநடு"

#: ../../Ch12/Ch12_Regression_01.rst:18
msgid "std. dev"
msgstr "std. தேவ்"

#: ../../Ch12/Ch12_Regression_01.rst:18
msgid "IQR"
msgstr "Iqr"

#: ../../Ch12/Ch12_Regression_01.rst:20
msgid "**Dani’s grumpiness**"
msgstr "** டானியின் எரிச்சல் **"

#: ../../Ch12/Ch12_Regression_01.rst:20
msgid "41"
msgstr "41"

#: ../../Ch12/Ch12_Regression_01.rst:20
msgid "91"
msgstr "91"

#: ../../Ch12/Ch12_Regression_01.rst:20
msgid "63.71"
msgstr "63.71"

#: ../../Ch12/Ch12_Regression_01.rst:20
msgid "62"
msgstr "62"

#: ../../Ch12/Ch12_Regression_01.rst:20
msgid "10.05"
msgstr "10.05"

#: ../../Ch12/Ch12_Regression_01.rst:20
msgid "14"
msgstr "14"

#: ../../Ch12/Ch12_Regression_01.rst:22
msgid "**Dani’s hours slept**"
msgstr "** டானியின் மணிநேரம் தூங்குகிறது **"

#: ../../Ch12/Ch12_Regression_01.rst:22
msgid "4.84"
msgstr "4.84"

#: ../../Ch12/Ch12_Regression_01.rst:22
msgid "9.00"
msgstr "9.00"

#: ../../Ch12/Ch12_Regression_01.rst:22
msgid "6.97"
msgstr "6.97"

#: ../../Ch12/Ch12_Regression_01.rst:22
msgid "7.03"
msgstr "7.03"

#: ../../Ch12/Ch12_Regression_01.rst:22
msgid "1.02"
msgstr "1.02"

#: ../../Ch12/Ch12_Regression_01.rst:22
msgid "1.45"
msgstr "1.45"

#: ../../Ch12/Ch12_Regression_01.rst:24
msgid "**Dani’s son’s hours slept**"
msgstr "** டானியின் மகனின் நேரம் தூங்குகிறது **"

#: ../../Ch12/Ch12_Regression_01.rst:24
msgid "3.25"
msgstr "3.25"

#: ../../Ch12/Ch12_Regression_01.rst:24
msgid "12.07"
msgstr "12.07"

#: ../../Ch12/Ch12_Regression_01.rst:24
msgid "8.05"
msgstr "8.05"

#: ../../Ch12/Ch12_Regression_01.rst:24
msgid "7.95"
msgstr "7.95"

#: ../../Ch12/Ch12_Regression_01.rst:24
msgid "2.07"
msgstr "2.07"

#: ../../Ch12/Ch12_Regression_01.rst:24
msgid "3.21"
msgstr "3.21"

#: ../../Ch12/Ch12_Regression_01.rst:27
msgid ""
"Let’s turn to a topic close to every parent’s heart: sleep. The data set "
"we’ll use is fictitious, but based on real events. Suppose I’m curious to "
"find out how much my infant son’s sleeping habits affect my mood. Let’s say "
"that I can rate my grumpiness very precisely, on a scale from 0 (not at all "
"grumpy) to 100 (grumpy as a very, very grumpy old man or woman). And lets "
"also assume that I’ve been measuring my grumpiness, my sleeping patterns and "
"my son’s sleeping patterns for 100 days. The data are stored in the |"
"parenthood|_ data set, that contains four variables ``dani.sleep``, ``baby."
"sleep``, ``dani.grump`` and ``day``."
msgstr ""
"ஒவ்வொரு பெற்றோரின் இதயத்திற்கும் நெருக்கமான தலைப்புக்கு திரும்புவோம்: தூக்கம். நாங்கள் "
"பயன்படுத்தும் தரவு தொகுப்பு கற்பனையானது, ஆனால் உண்மையான நிகழ்வுகளின் அடிப்படையில். எனது "
"குழந்தை மகனின் தூக்க பழக்கம் எனது மனநிலையை எவ்வளவு பாதிக்கிறது என்பதை அறிய ஆர்வமாக "
"உள்ளேன் என்று வைத்துக்கொள்வோம். எனது எரிச்சலை 0 (எரிச்சல் அல்ல) முதல் 100 வரை "
"(எரிச்சலூட்டுவது மிகவும் எரிச்சலூட்டும் வயதான ஆண் அல்லது பெண்ணாக) என் எரிச்சலை மிகத் "
"துல்லியமாக மதிப்பிட முடியும் என்று சொல்லலாம். மேலும் நான் என் எரிச்சலையும், தூக்க முறைகள் "
"மற்றும் எனது மகனின் தூக்க முறைகளையும் 100 நாட்களுக்கு அளவிடுகிறேன் என்பதையும் "
"கருதுகிறேன். தரவு |"

#: ../../Ch12/Ch12_Regression_01.rst:37
msgid ""
"Next, I’ll take a look at some basic descriptive statistics and, to give a "
"graphical depiction of what each of the three interesting variables looks "
"like, :numref:`fig-grumpHist` plots histograms. One thing to note: just "
"because jamovi can calculate dozens of different statistics doesn’t mean you "
"should report all of them. If I were writing this up for a report, I’d "
"probably pick out those statistics that are of most interest to me (and to "
"my readership), and then put them into a nice, simple table like the one in :"
"numref:`tab-parenthood`.\\ [#]_ Notice that when I put it into a table, I "
"gave everything “human readable” names. This is always good practice. Notice "
"also that I’m not getting enough sleep. This isn’t good practice, but other "
"parents tell me that it’s pretty standard."
msgstr ""
"அடுத்து, நான் சில அடிப்படை விளக்க புள்ளிவிவரங்களைப் பார்ப்பேன், மேலும் மூன்று சுவையான "
"மாறிகள் ஒவ்வொன்றும் எப்படி இருக்கும் என்பதற்கான வரைகலை சித்தரிப்பைக் கொடுக்க,: எண்: "
"`அத்தி-கிரம்பிச்ட்` இச்டோகிராம்கள். கவனிக்க வேண்டிய ஒன்று: சாமோவி டசன் கணக்கான வெவ்வேறு "
"புள்ளிவிவரங்களைக் கணக்கிட முடியும் என்பதால், நீங்கள் அனைத்தையும் புகாரளிக்க வேண்டும் என்று "
"அர்த்தமல்ல. ஒரு அறிக்கைக்காக நான் இதை எழுதுகிறேன் என்றால், எனக்கு மிகவும் ஆர்வமுள்ள (மற்றும்"
" எனது வாசகர்களுக்கு) அந்த புள்ளிவிவரங்களை நான் தேர்ந்தெடுத்தேன், பின்னர் அவற்றைப் போன்ற ஒரு "
"நல்ல, எளிய அட்டவணையில் வைக்கவும்: numref: ` தாவல்-பெற்றோர் `. \\ [#] _ நான் அதை ஒரு "
"அட்டவணையில் வைக்கும்போது, எல்லாவற்றையும்“ மனிதப் படிக்கக்கூடிய ”பெயர்களைக் கொடுத்தேன் "
"என்பதைக் கவனியுங்கள். இது எப்போதும் நல்ல நடைமுறை. எனக்கு போதுமான தூக்கம் வரவில்லை "
"என்பதையும் கவனியுங்கள். இது நல்ல நடைமுறை அல்ல, ஆனால் மற்ற பெற்றோர்கள் இது மிகவும் தரமானதா"
"க என்னிடம் கூறுகிறார்கள்."

#: ../../Ch12/Ch12_Regression_01.rst:51
msgid "Histograms for three variables from the |parenthood|_ data set"
msgstr ""
"| பெற்றோர்உட் | _ தரவு தொகுப்பிலிருந்து மூன்று மாறிகளுக்கான இச்டோகிராம்கள்"

#: ../../Ch12/Ch12_Regression_01.rst:55
msgid ""
"Histograms for the three interesting variables in the |parenthood|_ data set"
msgstr ""
"| பெற்றோர் | _ தரவு தொகுப்பில் உள்ள மூன்று சுவையான மாறிகளுக்கான இச்டோகிராம்கள்"

#: ../../Ch12/Ch12_Regression_01.rst:61
msgid "The strength and direction of a relationship"
msgstr "ஒரு உறவின் வலிமை மற்றும் திசை"

#: ../../Ch12/Ch12_Regression_01.rst:63
msgid ""
"We can draw scatterplots to give us a general sense of how closely related "
"two variables are. Ideally though, we might want to say a bit more about it "
"than that. For instance, let’s compare the relationship between ``dani."
"sleep`` and ``dani.grump`` (:numref:`fig-grumpCor1`, left) with that between "
"``baby.sleep`` and ``dani.grump`` (:numref:`fig-grumpCor1`, right). When "
"looking at these two plots side by side, it’s clear that the relationship is "
"*qualitatively* the same in both cases: more sleep equals less grump! "
"However, it’s also pretty obvious that the relationship between ``dani."
"sleep`` and ``dani.grump`` is *stronger* than the relationship between "
"``baby.sleep`` and ``dani.grump``. The plot on the left is “neater” than the "
"one on the right. What it feels like is that if you want to predict what my "
"mood is, it’d help you a little bit to know how many hours my son slept, but "
"it’d be more helpful to know how many hours I slept."
msgstr ""
"இரண்டு மாறிகள் எவ்வளவு நெருக்கமாக தொடர்புடையவை என்பதற்கான பொதுவான உணர்வை நமக்குத் "
"தெரிவிக்க சிதறல்களை நாம் வரையலாம். வெறுமனே, அதை விட இதைப் பற்றி இன்னும் கொஞ்சம் சொல்ல "
"விரும்பலாம். உதாரணமாக, `` டானி.லீப்` மற்றும் `` டானி. க்ரம்ப்`` (: numref: `Fig-"
"grumpcor1`, சரி). இந்த இரண்டு அடுக்குகளையும் அருகருகே பார்க்கும்போது, இரண்டு "
"நிகழ்வுகளிலும் உறவு * தரமான முறையில் * ஒரே மாதிரியானது என்பது தெளிவாகிறது: அதிக "
"தூக்கம் குறைவான எரிச்சலுக்கு சமம்! எவ்வாறாயினும், `` `டானி. இடதுபுறத்தில் உள்ள சூழ்ச்சி "
"வலதுபுறத்தில் இருந்ததை விட “நேர்த்தி” ஆகும். என் மனநிலை என்ன என்பதை நீங்கள் கணிக்க "
"விரும்பினால், என் மகன் எத்தனை மணிநேரம் தூங்கினான் என்பதை அறிய இது உங்களுக்கு கொஞ்சம் "
"உதவுகிறது, ஆனால் நான் எத்தனை மணிநேரம் தூங்கினேன் என்பதை அறிய இது மிகவும் உதவியாக "
"இருக்கும்."

#: ../../Ch12/Ch12_Regression_01.rst:80
msgid ""
"Scatterplots between ``dani.sleep`` and ``baby.sleep`` to ``dani.grump``"
msgstr ""
"`` Dani.sleep`` மற்றும் `` baby.sleep` க்கு இடையில் `` dani.grump`` க்கு இடையில் "
"சிதறல்கள்"

#: ../../Ch12/Ch12_Regression_01.rst:84
msgid ""
"Scatterplots showing the relationship between ``dani.sleep`` and ``dani."
"grump`` (left panel) and the relationship between ``baby.sleep`` and ``dani."
"grump`` (right panel)."
msgstr "`` டானி.லீப்`` மற்றும் `` டானி."

#: ../../Ch12/Ch12_Regression_01.rst:90
msgid ""
"In contrast, let’s consider the two scatterplots shown in :numref:`fig-"
"grumpCor2`. If we compare the scatterplot of ``baby.sleep`` vs. ``dani."
"grump`` (left) to the scatterplot of ``baby.sleep`` vs. ``dani.sleep`` "
"(right), the overall strength of the relationship is the same, but the "
"direction is different. That is, if my son sleeps more, I get *more* sleep "
"(positive relationship, right hand side), but if he sleeps more then I get "
"*less* grumpy (negative relationship, left hand side)."
msgstr ""
"இதற்கு நேர்மாறாக, காட்டப்பட்டுள்ள இரண்டு சிதறல்களைக் கருத்தில் கொள்வோம்: NUMREF: `Fig-"
"grumpcor2`. `` `Baby.sleep`` `` dani.grump```` (இடது) ஆகியவற்றின் சிதறலை `` "
"`baby.sleep`` `` `dani.sleep`` (சரி) ஆகியவற்றின் சிதறலுடன் ஒப்பிட்டுப் பார்த்தால் "
"உறவின் ஒட்டுமொத்த வலிமை ஒன்றுதான், ஆனால் திசை வேறுபட்டது. அதாவது, என் மகன் அதிகமாக "
"தூங்கினால், எனக்கு * அதிக * தூக்கம் (நேர்மறையான உறவு, வலது கை பக்கம்) கிடைக்கிறது, "
"ஆனால் அவர் அதிகமாக தூங்கினால், நான் * குறைவான * எரிச்சலான (எதிர்மறை உறவு, இடது கை "
"பக்கமாக) பெறுகிறேன்."

#: ../../Ch12/Ch12_Regression_01.rst:101
msgid "Scatterplots between baby.sleep to dani.grump and dani.sleep"
msgstr "பேபி"

#: ../../Ch12/Ch12_Regression_01.rst:105
msgid ""
"Scatterplots showing the relationship between ``baby.sleep`` and ``dani."
"grump`` (left panel) and the relationship between ``baby.sleep`` and ``dani."
"sleep`` (right panel)."
msgstr ""
"`` குழந்தை.லீப்`` மற்றும் `` டானி. கிரம்ப்`` (இடது குழு) மற்றும் `` பேபி."

#: ../../Ch12/Ch12_Regression_01.rst:112
msgid "The correlation coefficient"
msgstr "தொடர்பு குணகம்"

#: ../../Ch12/Ch12_Regression_01.rst:114
msgid ""
"We can make these ideas a bit more explicit by introducing the idea of a "
"**correlation coefficient** (or, more specifically, Pearson’s correlation "
"coefficient), which is traditionally denoted as *r*. The correlation "
"coefficient between two variables *X* and *Y* (sometimes denoted r\\ :sub:"
"`XY`), which we’ll define more precisely in the next section, is a measure "
"that varies from -1 to 1. When *r* = -1 it means that we have a perfect "
"negative relationship, and when *r* = 1 it means we have a perfect positive "
"relationship. When *r* = 0, there’s no relationship at all. If you look at :"
"numref:`fig-corr`, you can see several plots showing what different "
"correlations look like."
msgstr ""
"** தொடர்பு குணகம் ** (அல்லது, இன்னும் குறிப்பாக, பியர்சனின் தொடர்பு குணகம்) என்ற கருத்தை "
"அறிமுகப்படுத்துவதன் மூலம் இந்த யோசனைகளை நாம் இன்னும் கொஞ்சம் வெளிப்படையாக மாற்ற முடியும், "
"இது பாரம்பரியமாக*r*என குறிக்கப்படுகிறது. இரண்டு மாறிகள் * ஃச் * மற்றும் * ஒய் * (சில "
"நேரங்களில் R \\: sub: `xy`) க்கு இடையிலான தொடர்பு குணகம், அடுத்த பகுதியில் நாம் இன்னும்"
" துல்லியமாக வரையறுப்போம், இது -1 முதல் 1 வரை மாறுபடும் ஒரு நடவடிக்கையாகும் * r* = -"
"1 இதன் பொருள் நமக்கு ஒரு சரியான எதிர்மறை உறவு இருக்கிறது,* r* = 1 போது நமக்கு சரியா"
"ன நேர்மறையான உறவு இருக்கிறது என்று பொருள். * R * = 0 போது, எந்த உறவும் இல்லை. நீங்கள் "
"பார்த்தால்: NumRef: `Fig-corr`, வெவ்வேறு தொடர்புகள் எப்படி இருக்கும் என்பதைக் காட்டும் பல "
"அடுக்குகளை நீங்கள் காணலாம்."

#: ../../Ch12/Ch12_Regression_01.rst:126
msgid "Effect of varying the strength and direction of a correlation"
msgstr "ஒரு தொடர்பின் வலிமை மற்றும் திசையை மாற்றுவதன் விளைவு"

#: ../../Ch12/Ch12_Regression_01.rst:130
msgid ""
"Illustration of the effect of varying the strength and direction of a "
"correlation. In the left hand column, the correlations are 0.00, 0.33, 0.67 "
"and 1.00 In the right hand column, the correlations are 0.00, -0.33, -0.67 "
"and -1.00."
msgstr ""
"ஒரு தொடர்பின் வலிமை மற்றும் திசையை மாற்றுவதன் விளைவின் விளக்கம். இடது கை நெடுவரிசையில்"
", வலது கை நெடுவரிசையில் தொடர்புகள் 0.00, 0.33, 0.67 மற்றும் 1.00 ஆகும், தொடர்புகள் "
"0.00, -0.33, -0.67 மற்றும் -1.00 ஆகும்."

#: ../../Ch12/Ch12_Regression_01.rst:137
msgid ""
"The formula for the Pearson’s correlation coefficient can be written in "
"several different ways. I think the simplest way to write down the formula "
"is to break it into two steps. Firstly, let’s introduce the idea of a "
"**covariance**. The covariance between two variables *X* and *Y* is a "
"generalisation of the notion of the variance amd is a mathematically simple "
"way of describing the relationship between two variables that isn’t terribly "
"informative to humans"
msgstr ""
"பியர்சனின் தொடர்பு குணகத்திற்கான சூத்திரத்தை பல்வேறு வழிகளில் எழுதலாம். சூத்திரத்தை "
"எழுதுவதற்கான எளிய வழி அதை இரண்டு படிகளாக உடைப்பதாகும் என்று நான் நினைக்கிறேன். "
"முதலாவதாக, ஒரு ** கோவாரன்ச் ** இன் யோசனையை அறிமுகப்படுத்துவோம். * ஃச் * மற்றும் * ஒய் *"
" ஆகிய இரண்டு மாறிகள் இடையேயான கோவாரன்ச் என்பது AMD என்ற மாறுபாட்டின் கருத்தை "
"பொதுமைப்படுத்துவதாகும்"

#: ../../Ch12/Ch12_Regression_01.rst:145
msgid ""
"\\mbox{Cov}(X,Y) = \\frac{1}{N-1} \\sum_{i=1}^N \\left(X_i - \\bar{X} "
"\\right) \\left(Y_i - \\bar{Y} \\right)\n"
"\n"
msgstr ""
"\\mbox{Cov}(X,Y) = \\frac{1}{N-1} \\sum_{i=1}^N \\left(X_i - \\bar{X} \\right"
") \\left(Y_i - \\bar{Y} \\right)\n"
"\n"

#: ../../Ch12/Ch12_Regression_01.rst:147
msgid ""
"Because we’re multiplying (i.e., taking the “product” of) a quantity that "
"depends on *X* by a quantity that depends on *Y* and then averaging,\\ [#]_ "
"you can think of the formula for the covariance as an “average cross "
"product” between *X* and *Y*."
msgstr ""
"ஏனென்றால், * ஒய் * ஐப் பொறுத்து, பின்னர் சராசரியாக, \\ [#] _ கோவரியன்ச் சூத்திரத்தைப் "
"பற்றி நீங்கள் சிந்திக்கலாம் *x *மற்றும் *y *க்கு இடையில் “சராசரி குறுக்கு தயாரிப்பு” ஆக."

#: ../../Ch12/Ch12_Regression_01.rst:152
msgid ""
"The covariance has the nice property that, if *X* and *Y* are entirely "
"unrelated, then the covariance is exactly zero. If the relationship between "
"them is positive (in the sense shown in :numref:`fig-corr`) then the "
"covariance is also positive, and if the relationship is negative then the "
"covariance is also negative. In other words, the covariance captures the "
"basic qualitative idea of correlation. Unfortunately, the raw magnitude of "
"the covariance isn’t easy to interpret as it depends on the units in which "
"*X* and *Y* are expressed and, worse yet, the actual units that the "
"covariance itself is expressed in are really weird. For instance, if *X* "
"refers to the ``dani.sleep`` variable (units: hours) and *Y* refers to the "
"``dani.grump`` variable (units: grumps), then the units for their covariance "
"are “hours × grumps”. And I have no freaking idea what that would even mean."
msgstr ""
"கோவாரன்ச் நல்ல சொத்து உள்ளது, * ஃச் * மற்றும் * ஒய் * ஆகியவை முற்றிலும் தொடர்பில்லாதவை "
"என்றால், கோவாரன்ச் சரியாக பூச்சியமாக இருக்கும். அவற்றுக்கிடையேயான உறவு நேர்மறையானது "
"என்றால் (காட்டப்பட்டுள்ள பொருளில்: numref: `Fig-corr`) பின்னர் கோவாரன்ச் நேர்மறையானது, "
"மேலும் உறவு எதிர்மறையாக இருந்தால், கோவாரென்சும் எதிர்மறையாக இருக்கும். வேறு வார்த்தைகளில்"
" கூறுவதானால், கோவாரன்ச் தொடர்புகளின் அடிப்படை தரமான யோசனையைப் பிடிக்கிறது. "
"துரதிர்ச்டவசமாக. உதாரணமாக, * ஃச் * என்பது `` டானி.லீப்` `மாறுபாடு (அலகுகள்: மணிநேரம்)"
" மற்றும் * ஒய் * ஆகியவற்றைக் குறிக்கிறது என்றால்` `dani.grump``` `` `` `` மாறுபாடு "
"(அலகுகள்: கிரம்புகள்) “மணிநேரம் × கிரம்புகள்”. அது என்ன பொருள் என்று எனக்கு எந்தவிதமான "
"யோசனையும் இல்லை."

#: ../../Ch12/Ch12_Regression_01.rst:165
msgid ""
"The Pearson correlation coefficient *r* fixes this interpretation problem by "
"standardising the covariance, in pretty much the exact same way that the *z*-"
"score standardises a raw score, by dividing by the standard deviation. "
"However, because we have two variables that contribute to the covariance, "
"the standardisation only works if we divide by both standard deviations.\\ "
"[#]_ In other words, the correlation between *X* and *Y* can be written as "
"follows:"
msgstr ""
"பியர்சன் தொடர்பு குணகம் *ஆர் *இந்த விளக்க சிக்கலை கோவாரன்ச் தரப்படுத்துவதன் மூலம் "
"சரிசெய்கிறது, *z *-ச்கோர் ஒரு மூல மதிப்பெண்ணை தரப்படுத்தும் அதே வழியில், நிலையான "
"விலகலால் பிரிப்பதன் மூலம். எவ்வாறாயினும், கோவாரன்ச் பங்களிக்கும் இரண்டு மாறிகள் நம்மிடம் "
"இருப்பதால், நிலையான விலகல்களால் நாம் பிரித்தால் மட்டுமே தரப்படுத்தல் செயல்படுகிறது. \\ "
"[#] _ வேறுவிதமாகக் கூறினால், * ஃச் * மற்றும் * ஒய் * க்கு இடையிலான தொடர்பை பின்வருமாறு"
" எழுதலாம்:"

#: ../../Ch12/Ch12_Regression_01.rst:173
msgid ""
"r_{XY}  = \\frac{\\mbox{Cov}(X,Y)}{ \\hat{\\sigma}_X \\ \\hat{\\sigma}_Y}\n"
"\n"
msgstr ""
"r_{XY}  = \\frac{\\mbox{Cov}(X,Y)}{ \\hat{\\sigma}_X \\ \\hat{\\sigma}_Y}\n"
"\n"

#: ../../Ch12/Ch12_Regression_01.rst:175
msgid ""
"By standardising the covariance, not only do we keep all of the nice "
"properties of the covariance discussed earlier, but the actual values of *r* "
"are on a meaningful scale: *r* = 1 implies a perfect positive relationship "
"and *r* = -1 implies a perfect negative relationship. I’ll expand a little "
"more on this point later, in subsection :ref:`Interpreting a correlation "
"<interpreting_a_correlation>`. But before I do, let’s look at how to "
"calculate correlations in jamovi."
msgstr ""
"கோவாரென்சை தரப்படுத்துவதன் மூலம், முன்னர் விவாதிக்கப்பட்ட கோவாரியன்சின் அனைத்து நல்ல "
"பண்புகளையும் நாம் வைத்திருப்பது மட்டுமல்லாமல், * r * இன் உண்மையான மதிப்புகள் ஒரு அர்த்தமுள்"
"ள அளவில் உள்ளன: * r * = 1 ஒரு சரியான நேர்மறையான உறவைக் குறிக்கிறது மற்றும் * r * = -"
"1 ஒரு சரியான எதிர்மறை உறவைக் குறிக்கிறது. இந்த கட்டத்தில் நான் பின்னர் இன்னும் கொஞ்சம் "
"விரிவுபடுத்துவேன், துணைப்பிரிவில்: குறிப்பு: `ஒரு தொடர்பை விளக்குவது "
"<விளக்கம்_ஏ_கோரேலேசன்>`. ஆனால் நான் செய்வதற்கு முன், சாமோவியில் உள்ள தொடர்புகளை எவ்வாறு "
"கணக்கிடுவது என்று பார்ப்போம்."

#: ../../Ch12/Ch12_Regression_01.rst:184
msgid "Calculating correlations in jamovi"
msgstr "சமோவியில் தொடர்புகளை கணக்கிடுதல்"

#: ../../Ch12/Ch12_Regression_01.rst:186
msgid ""
"Calculating correlations in jamovi can be done by clicking on the "
"``Regression`` → ``Correlation Matrix`` button. Transfer all four continuous "
"variables |continuous| across into the box on the right to get the output "
"in :numref:`fig-correlations`."
msgstr ""
"`` பின்னடைவு` `` `தொடர்பு மேட்ரிக்ச்`` பொத்தானைக் சொடுக்கு செய்வதன் மூலம் சாமோவியில் உள்ள "
"தொடர்புகளைக் கணக்கிடலாம். நான்கு தொடர்ச்சியான மாறிகள் இடமாற்றம் | தொடர்ச்சியான | "
"வெளியீட்டைப் பெற வலதுபுறத்தில் உள்ள பெட்டியில்: எண்ரெஃப்: `அத்தி-தொடர்புகள்`."

#: ../../Ch12/Ch12_Regression_01.rst:193
msgid "jamovi screenshot with correlations in the |parenthood|_ data set"
msgstr "| பெற்றோர்ஊட் | _ தரவு தொகுப்பில் உள்ள தொடர்புகளுடன் சாமோவி திரை காட்சி"

#: ../../Ch12/Ch12_Regression_01.rst:197
msgid ""
"jamovi screenshot showing correlations between variables in the |parenthood|"
"_ data set"
msgstr ""
"| பெற்றோர்உட் | _ தரவு தொகுப்பு ஆகியவற்றில் மாறிகள் இடையே தொடர்புகளைக் காட்டும் சாமோவி "
"திரைக்காட்சி"

#: ../../Ch12/Ch12_Regression_01.rst:205
msgid "Interpreting a correlation"
msgstr "ஒரு தொடர்பை விளக்குகிறது"

#: ../../Ch12/Ch12_Regression_01.rst:207
msgid ""
"Naturally, in real life you don’t see many correlations of 1. So how should "
"you interpret a correlation of, say, *r* = 0.4? The honest answer is that it "
"really depends on what you want to use the data for, and on how strong the "
"correlations in your field tend to be. A friend of mine in engineering once "
"argued that any correlation less than 0.95 is completely useless (I think he "
"was exaggerating, even for engineering). On the other hand, there are real "
"cases, even in psychology, where you should really expect correlations that "
"strong. For instance, one of the benchmark data sets used to test theories "
"of how people judge similarities is so clean that any theory that can’t "
"achieve a correlation of at least 0.9 really isn’t deemed to be successful. "
"However, when looking for (say) elementary correlates of intelligence (e.g., "
"inspection time, response time), if you get a correlation above 0.3 you’re "
"doing very very well. In short, the interpretation of a correlation depends "
"a lot on the context. That said, the rough guide in :numref:`tab-"
"interpretcorrelations` is pretty typical."
msgstr ""
"இயற்கையாகவே, நிச வாழ்க்கையில் நீங்கள் 1 இன் பல தொடர்புகளைக் காணவில்லை. ஆகவே, * r * = "
"0.4 என்ற தொடர்பை நீங்கள் எவ்வாறு விளக்க வேண்டும்? நேர்மையான பதில் என்னவென்றால், நீங்கள் தரவை "
"எதைப் பயன்படுத்த விரும்புகிறீர்கள் என்பதையும், உங்கள் துறையில் உள்ள தொடர்புகள் எவ்வளவு வலுவா"
"க இருக்கின்றன என்பதையும் பொறுத்தது. பொறியியலில் எனது நண்பர் ஒருவர் ஒருமுறை 0.95 க்கும் "
"குறைவான எந்த தொடர்பும் முற்றிலும் பயனற்றது என்று வாதிட்டார் (அவர் பொறியியலுக்காக கூட "
"மிகைப்படுத்தினார் என்று நான் நினைக்கிறேன்). மறுபுறம், உளவியலில் கூட உண்மையான வழக்குகள் உள்"
"ளன, அங்கு நீங்கள் வலுவான தொடர்புகளை எதிர்பார்க்க வேண்டும். உதாரணமாக, மக்கள் ஒற்றுமையை "
"எவ்வாறு தீர்மானிக்கிறார்கள் என்பதற்கான கோட்பாடுகளைச் சோதிக்கப் பயன்படுத்தப்படும் பெஞ்ச்மார்க் "
"தரவுத் தொகுப்புகளில் ஒன்று மிகவும் சுத்தமாக இருக்கிறது, குறைந்தது 0.9 தொடர்பை அடைய "
"முடியாத எந்தவொரு கோட்பாடும் உண்மையில் வெற்றிகரமாக கருதப்படவில்லை. இருப்பினும், "
"உளவுத்துறையின் தொடக்க தொடர்புகளை (எ.கா., ஆய்வு நேரம், மறுமொழி நேரம்) தேடும்போது, 0.3 "
"க்கு மேல் ஒரு தொடர்பு கிடைத்தால் நீங்கள் மிகச் சிறப்பாக செய்கிறீர்கள். சுருக்கமாக, ஒரு "
"தொடர்பின் விளக்கம் சூழலைப் பொறுத்தது. கரடுமுரடான வழிகாட்டி: NumRef: `தாவல்-விளக்கப்படம் "
"தொடர்புகள்` மிகவும் பொதுவானது."

#: ../../Ch12/Ch12_Regression_01.rst:223
msgid ""
"A rough guide to interpreting correlations. Note that I say a *rough* guide. "
"There aren’t hard and fast rules for what counts as strong or weak "
"relationships. It depends on the context."
msgstr ""
"தொடர்புகளை விளக்குவதற்கான ஒரு கடினமான வழிகாட்டி. நான் ஒரு * தோராயமான * வழிகாட்டி "
"என்று சொல்கிறேன் என்பதை நினைவில் கொள்க. வலுவான அல்லது பலவீனமான உறவுகள் எனக் "
"கருதப்படுவதற்கு கடினமான மற்றும் விரைவான விதிகள் இல்லை. இது சூழலைப் பொறுத்தது."

#: ../../Ch12/Ch12_Regression_01.rst:229
msgid "Correlation"
msgstr "ஒட்டுறவு"

#: ../../Ch12/Ch12_Regression_01.rst:229
msgid "Strength"
msgstr "வலிமை"

#: ../../Ch12/Ch12_Regression_01.rst:229
msgid "Direction"
msgstr "திசை"

#: ../../Ch12/Ch12_Regression_01.rst:231
msgid "-1.0 to -0.9"
msgstr "-1.0 முதல் -0.9 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:231 ../../Ch12/Ch12_Regression_01.rst:249
msgid "Very strong"
msgstr "மிகவும் வலுவானது"

#: ../../Ch12/Ch12_Regression_01.rst:231 ../../Ch12/Ch12_Regression_01.rst:233
#: ../../Ch12/Ch12_Regression_01.rst:235 ../../Ch12/Ch12_Regression_01.rst:237
#: ../../Ch12/Ch12_Regression_01.rst:239
msgid "Negative"
msgstr "எதிர்மம்"

#: ../../Ch12/Ch12_Regression_01.rst:233
msgid "-0.9 to -0.7"
msgstr "-0.9 முதல் -0.7 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:233 ../../Ch12/Ch12_Regression_01.rst:247
msgid "Strong"
msgstr "வலுவான"

#: ../../Ch12/Ch12_Regression_01.rst:235
msgid "-0.7 to -0.4"
msgstr "-0.7 முதல் -0.4 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:235 ../../Ch12/Ch12_Regression_01.rst:245
msgid "Moderate"
msgstr "மிதமான"

#: ../../Ch12/Ch12_Regression_01.rst:237
msgid "-0.4 to -0.2"
msgstr "-0.4 முதல் -0.2 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:237 ../../Ch12/Ch12_Regression_01.rst:243
msgid "Weak"
msgstr "மென்"

#: ../../Ch12/Ch12_Regression_01.rst:239
msgid "-0.2 to  0.0"
msgstr "-0.2 முதல் 0.0 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:239 ../../Ch12/Ch12_Regression_01.rst:241
msgid "Negligible"
msgstr "மிகக் குறைவு"

#: ../../Ch12/Ch12_Regression_01.rst:241
msgid "0.0 to  0.2"
msgstr "0.0 முதல் 0.2 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:241 ../../Ch12/Ch12_Regression_01.rst:243
#: ../../Ch12/Ch12_Regression_01.rst:245 ../../Ch12/Ch12_Regression_01.rst:247
#: ../../Ch12/Ch12_Regression_01.rst:249
msgid "Positive"
msgstr "நேரமம்"

#: ../../Ch12/Ch12_Regression_01.rst:243
msgid "0.2 to  0.4"
msgstr "0.2 முதல் 0.4 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:245
msgid "0.4 to  0.7"
msgstr "0.4 முதல் 0.7 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:247
msgid "0.7 to  0.9"
msgstr "0.7 முதல் 0.9 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:249
msgid "0.9 to  1.0"
msgstr "0.9 முதல் 1.0 வரை"

#: ../../Ch12/Ch12_Regression_01.rst:255
msgid "Anscombe’s quartet"
msgstr "அன்ச்காம்பின் குவார்டெட்"

#: ../../Ch12/Ch12_Regression_01.rst:259
msgid ""
"Anscombe’s quartet: All four of these data sets have a Pearson correlation "
"of *r* = 0.816, but they are qualitatively different from one another."
msgstr ""
"ANSCOMBE இன் குவார்டெட்: இந்த நான்கு தரவுத் தொகுப்புகளும் * r * = 0.816 இன் பியர்சன் "
"தொடர்பைக் கொண்டுள்ளன, ஆனால் அவை ஒருவருக்கொருவர் தர ரீதியாக வேறுபடுகின்றன."

#: ../../Ch12/Ch12_Regression_01.rst:264
msgid ""
"However, something that can never be stressed enough is that you should "
"*always* look at the scatterplot before attaching any interpretation to the "
"data. A correlation might not mean what you think it means. The classic "
"illustration of this is “Anscombe’s Quartet” (:ref:`Anscombe, 1973 "
"<Anscombe_1973>`), a collection of four data sets. Each data set has two "
"variables, an *X* and a *Y*. For all four data sets the mean value for *X* "
"is 9 and the mean for *Y* is 7.5. The standard deviations for all *X* "
"variables are almost identical, as are those for the *Y* variables. And in "
"each case the correlation between *X* and *Y* is *r* = 0.816`. You can "
"verify this yourself, since I happen to have saved it as a dataset called |"
"anscombe|_."
msgstr ""
"எவ்வாறாயினும், தரவுக்கு எந்தவொரு விளக்கத்தையும் இணைப்பதற்கு முன்பு நீங்கள் * எப்போதும் * "
"சிதறலைப் பார்க்க வேண்டும். ஒரு தொடர்பு என்பது நீங்கள் நினைப்பதை அர்த்தப்படுத்துவதில்லை. இதன் "
"உன்னதமான விளக்கம் “அன்ச்காம்பின் குவார்டெட்” (: குறிப்பு: `அன்ச்காம்பே, 1973 "
"<nscombe_1973>`), இது நான்கு தரவுத் தொகுப்புகளின் தொகுப்பாகும். ஒவ்வொரு தரவு "
"தொகுப்பிலும் இரண்டு மாறிகள் உள்ளன, ஒரு *x *மற்றும் A *y *. நான்கு தரவுகளுக்கும் * ஃச் * "
"க்கான சராசரி மதிப்பு 9 மற்றும் * ஒய் * க்கான சராசரி 7.5 ஆகும். * ஒய் * மாறிகள் போன்ற "
"அனைத்து * ஃச் * மாறிகளுக்கும் நிலையான விலகல்கள் கிட்டத்தட்ட ஒரே மாதிரியானவை. ஒவ்வொரு "
"சந்தர்ப்பத்திலும் * ஃச் * மற்றும் * ஒய் * க்கு இடையிலான தொடர்பு * r * = 0.816` ஆகும். இதை"
" நீங்களே சரிபார்க்கலாம், ஏனென்றால் நான் அதை | anscombe | _ எனப்படும் தரவுத்தொகுப்பாக "
"சேமித்துள்ளேன்."

#: ../../Ch12/Ch12_Regression_01.rst:275
msgid ""
"You’d think that these four data sets would look pretty similar to one "
"another. They do not. If we draw scatterplots of *X* against *Y* for all "
"four variables, as shown in :numref:`fig-anscombe`, we see that all four of "
"these are *spectacularly* different to each other. The lesson here, which so "
"very many people seem to forget in real life, is *always graph your raw "
"data* (chapter :doc:`../Ch05/Ch05_Graphics`)."
msgstr ""
"இந்த நான்கு தரவுத் தொகுப்புகள் ஒருவருக்கொருவர் மிகவும் ஒத்ததாக இருக்கும் என்று நீங்கள் "
"நினைப்பீர்கள். அவர்கள் இல்லை. நான்கு மாறிகளுக்கும் * ஒய் * க்கு எதிராக * ஃச் * இன் சிதறல்களை"
" நாம் வரைந்தால், இங்கில் காட்டப்பட்டுள்ளபடி: NumRef: `Fig-anscombe`, இவை நான்கு பேரும் "
"ஒருவருக்கொருவர் * கண்கவர் * வேறுபட்டவை என்பதைக் காண்கிறோம். இங்கே பாடம், நிச வாழ்க்கையில் "
"பலர் மறந்துவிட்டதாகத் தெரிகிறது, * எப்போதும் உங்கள் மூல தரவை வரைபடமாக்குகிறது * "
"(அத்தியாயம்: டாக்: `../ ch05/ch05_graphics`)."

#: ../../Ch12/Ch12_Regression_01.rst:283
msgid "Spearman’s rank correlations"
msgstr "ச்பியர்மேனின் தரவரிசை தொடர்பு"

#: ../../Ch12/Ch12_Regression_01.rst:285
msgid ""
"The Pearson correlation coefficient is useful for a lot of things, but it "
"does have shortcomings. One issue in particular stands out: what it actually "
"measures is the strength of the *linear* relationship between two variables. "
"In other words, what it gives you is a measure of the extent to which the "
"data all tend to fall on a single, perfectly straight line. Often, this is a "
"pretty good approximation to what we mean when we say “relationship”, and so "
"the Pearson correlation is a good thing to calculate. Sometimes though, it "
"isn’t."
msgstr ""
"பியர்சன் தொடர்பு குணகம் நிறைய விசயங்களுக்கு பயனுள்ளதாக இருக்கும், ஆனால் அதற்கு "
"குறைபாடுகள் உள்ளன. குறிப்பாக ஒரு சிக்கல் தனித்து நிற்கிறது: அது உண்மையில் அளவிடுவது "
"இரண்டு மாறிகள் இடையேயான * நேரியல் * உறவின் வலிமை. வேறு வார்த்தைகளில் கூறுவதானால், அது"
" உங்களுக்கு வழங்குவது தரவு அனைத்தும் ஒரு ஒற்றை, செய்தபின் நேர் கோட்டில் எந்த அளவிற்கு "
"விழுகிறது என்பதற்கான அளவீடு ஆகும். பெரும்பாலும், “உறவு” என்று நாம் கூறும்போது நாம் எதைக்"
" குறிக்கிறோம் என்பதற்கு இது ஒரு நல்ல தோராயமாகும், எனவே பியர்சன் தொடர்பு கணக்கிட ஒரு நல்"
"ல சேதி. சில நேரங்களில், அது இல்லை."

#: ../../Ch12/Ch12_Regression_01.rst:294
msgid ""
"One very common situation where the Pearson correlation isn’t quite the "
"right thing to use arises when an increase in one variable *X* really is "
"reflected in an increase in another variable *Y*, but the nature of the "
"relationship isn’t necessarily linear. An example of this might be the "
"relationship between effort and reward when studying for an exam. If you put "
"zero effort (*X*) into learning a subject then you should expect a grade of "
"0\\% (*Y*). However, a little bit of effort will cause a *massive* "
"improvement. Just turning up to lectures means that you learn a fair bit, "
"and if you just turn up to classes and scribble a few things down your grade "
"might rise to 35\\%, all without a lot of effort. However, you just don’t "
"get the same effect at the other end of the scale. As everyone knows, it "
"takes *a lot* more effort to get a grade of 90\\% than it takes to get a "
"grade of 55\\%. What this means is that, if I’ve got data looking at study "
"effort and grades, there’s a pretty good chance that Pearson correlations "
"will be misleading."
msgstr ""
"ஒரு மாறியின் அதிகரிப்பு *x *உண்மையில் மற்றொரு மாறியின் அதிகரிப்பில் பிரதிபலிக்கும் போது"
" பியர்சன் தொடர்பு சரியானது அல்ல, பியர்சன் தொடர்பு பயன்படுத்துவது சரியான சேதி அல்ல, ஆனால்"
" உறவின் தன்மை அவசியமில்லை நேரியல். ஒரு தேர்வுக்கு படிக்கும் போது முயற்சி மற்றும் "
"வெகுமதிக்கு இடையிலான உறவாக இதற்கு இருக்கலாம். ஒரு விசயத்தைக் கற்றுக்கொள்வதில் நீங்கள் சுழி"
"ய முயற்சியை (*x*) வைத்தால், நீங்கள் 0 \\% (*y*) தரத்தை எதிர்பார்க்க வேண்டும். இருப்பினும், "
"கொஞ்சம் முயற்சி * பாரிய * முன்னேற்றத்தை ஏற்படுத்தும். விரிவுரைகளைத் திருப்புவது என்பது "
"நீங்கள் ஒரு நியாயமான பிட் கற்றுக் கொண்டிருப்பதைக் குறிக்கிறது, மேலும் நீங்கள் வகுப்புகளைத் "
"திருப்பி, சில விசயங்களை எழுதினால், உங்கள் தரத்திற்கு கீழே 35 \\%ஆக உயரக்கூடும், இவை "
"அனைத்தும் அதிக முயற்சி இல்லாமல். இருப்பினும், அளவின் மறுமுனையில் நீங்கள் அதே விளைவைப் "
"பெறவில்லை. அனைவருக்கும் தெரியும், 55 \\% தரத்தைப் பெறுவதற்கு எடுப்பதை விட 90 \\% "
"தரத்தைப் பெறுவதற்கு * அதிக முயற்சி எடுக்கிறது. இதன் பொருள் என்னவென்றால், படிப்பு முயற்சி "
"மற்றும் தரங்களைப் பார்க்கும் தரவு எனக்கு கிடைத்தால், பியர்சன் தொடர்புகள் தவறாக வழிநடத்தும் "
"ஒரு நல்ல வாய்ப்பு உள்ளது."

#: ../../Ch12/Ch12_Regression_01.rst:311
msgid ""
"To illustrate, consider the data plotted in :numref:`fig-"
"ordinalRelationship`, showing the relationship between hours worked and "
"grade received for 10 students taking some class. The curious thing about "
"this (highly fictitious) data set is that increasing your effort *always* "
"increases your grade. It might be by a lot or it might be by a little, but "
"increasing effort will never decrease your grade. If we run a standard "
"Pearson correlation, it shows a strong relationship between hours worked and "
"grade received, with a correlation coefficient of **0.91**. However, this "
"doesn’t actually capture the observation that increasing hours worked "
"*always* increases the grade. There’s a sense here in which we want to be "
"able to say that the correlation is *perfect* but for a somewhat different "
"notion of what a “relationship” is. What we’re looking for is something that "
"captures the fact that there is a perfect **ordinal relationship** here. "
"That is, if student 1 works more hours than student 2, then we can guarantee "
"that student 1 will get the better grade. That’s not what a correlation of "
"*r* = 0.91 says at all."
msgstr ""
"விளக்குவதற்கு, திட்டமிடப்பட்ட தரவைக் கவனியுங்கள்: NumRef: `Fig-ordinalrelationhip`, "
"சில வகுப்பு எடுக்கும் 10 மாணவர்களுக்கு பெறப்பட்ட மணிநேரங்களுக்கும் தரத்திற்கும் இடையிலான "
"உறவைக் காட்டுகிறது. இந்த (மிகவும் கற்பனையான) தரவுத் தொகுப்பைப் பற்றிய ஆர்வமுள்ள சேதி "
"என்னவென்றால், உங்கள் முயற்சியை அதிகரிப்பது * எப்போதும் * உங்கள் தரத்தை அதிகரிக்கிறது. இது "
"நிறைய இருக்கலாம் அல்லது அது கொஞ்சம் இருக்கலாம், ஆனால் அதிகரிக்கும் முயற்சி உங்கள் தரத்தை "
"ஒருபோதும் குறைக்காது. நாங்கள் ஒரு நிலையான பியர்சன் தொடர்பை இயக்கினால், ** 0.91 ** இன் "
"தொடர்பு குணகத்துடன், வேலை செய்த மணிநேரங்களுக்கும் பெறப்பட்ட தரத்திற்கும் இடையே ஒரு வலுவா"
"ன உறவைக் காட்டுகிறது. இருப்பினும், இது உண்மையில் மணிநேரம் வேலை செய்தது * எப்போதும் * "
"தரத்தை அதிகரிக்கிறது என்ற அவதானிப்பைக் கைப்பற்றாது. தொடர்பு * சரியானது * என்று நாம் சொல்"
"ல விரும்பும் ஒரு உணர்வு இங்கே உள்ளது, ஆனால் ஒரு “உறவு” என்றால் என்ன என்பது பற்றிய சற்றே "
"வித்தியாசமான கருத்துக்கு. நாங்கள் தேடுவது இங்கே ஒரு சரியான ** சாதாரண உறவு ** உள்ளது "
"என்ற உண்மையைப் பிடிக்கிறது. அதாவது, மாணவர் 1 மாணவர் 2 ஐ விட அதிக மணிநேரம் வேலை "
"செய்தால், மாணவர் 1 சிறந்த தரத்தைப் பெறுவார் என்று நாங்கள் பொறுப்பு அளிக்க முடியும். * R * "
"= 0.91 இன் தொடர்பு எதுவும் சொல்லவில்லை."

#: ../../Ch12/Ch12_Regression_01.rst:330
msgid "relationship between hours worked and grade received"
msgstr "வேலை செய்த மணிநேரங்களுக்கும் பெறப்பட்ட தரத்திற்கும் இடையிலான உறவு"

#: ../../Ch12/Ch12_Regression_01.rst:334
msgid ""
"The relationship between hours worked and grade received for a toy data set "
"consisting of only 10 students (each circle corresponds to one student). The "
"dashed line through the middle shows the linear relationship between the two "
"variables. This produces a strong Pearson correlation of *r* = 0.91. "
"However, the interesting thing to note here is that there’s actually a "
"perfect monotonic relationship between the two variables. In this toy "
"example, increasing the hours worked always increases the grade received, as "
"illustrated by the solid line. This is reflected in a Spearman correlation "
"of ρ = 1.00. With such a small data set, however, it’s an open question as "
"to which version better describes the actual relationship involved."
msgstr ""
"10 மாணவர்களைக் கொண்ட ஒரு பொம்மை தரவுத் தொகுப்பிற்கான வேலை மற்றும் தரத்திற்கு இடையிலான "
"உறவு (ஒவ்வொரு வட்டமும் ஒரு மாணவருக்கு ஒத்திருக்கிறது). நடுத்தர வழியாக கோடு கோடு "
"இரண்டு மாறிகள் இடையிலான நேரியல் உறவைக் காட்டுகிறது. இது * r * = 0.91 இன் வலுவான "
"பியர்சன் தொடர்பை உருவாக்குகிறது. இருப்பினும், இங்கே கவனிக்க வேண்டிய சுவையான சேதி "
"என்னவென்றால், உண்மையில் இரண்டு மாறிகள் இடையே ஒரு சரியான மோனோடோனிக் உறவு உள்ளது. இந்த "
"பொம்மை எடுத்துக்காட்டில், திடமான கோட்டால் விளக்கப்பட்டுள்ளபடி, வேலை செய்யும் நேரங்களை "
"அதிகரிப்பது எப்போதும் பெறப்பட்ட தரத்தை அதிகரிக்கிறது. இது ρ = 1.00 இன் ச்பியர்மேன் "
"தொடர்பில் பிரதிபலிக்கிறது. இருப்பினும், இதுபோன்ற ஒரு சிறிய தரவுத் தொகுப்பைக் கொண்டு, எந்"
"த பதிப்பு சம்பந்தப்பட்ட உண்மையான உறவை சிறப்பாக விவரிக்கிறது என்பது ஒரு திறந்த கேள்வி."

#: ../../Ch12/Ch12_Regression_01.rst:348
msgid ""
"How should we address this? Actually, it’s really easy. If we’re looking for "
"ordinal relationships all we have to do is treat the data as if it were "
"ordinal scale |ordinal|! So, instead of measuring effort in terms of “hours "
"worked”, lets rank all 10 of our students in order of hours worked. That is, "
"student 1 did the least work out of anyone (2 hours) so they get the lowest "
"rank (rank = 1). Student 4 was the next laziest, putting in only 6 hours of "
"work over the whole semester, so they get the next lowest rank (rank = 2). "
"Notice that I’m using “rank = 1” to mean “low rank”. Sometimes in everyday "
"language we talk about “rank = 1” to mean “top rank” rather than “bottom "
"rank”. So be careful, you can rank “from smallest value to largest value” (i."
"e., small equals rank 1) or you can rank “from largest value to smallest "
"value” (i.e., large equals rank 1). In this case, I’m ranking from smallest "
"to largest, but as it’s really easy to forget which way you set things up "
"you have to put a bit of effort into remembering!"
msgstr ""
"இதை நாம் எவ்வாறு உரையாற்ற வேண்டும்? உண்மையில், இது மிகவும் எளிதானது. நாங்கள் சாதாரண "
"உறவுகளைத் தேடுகிறீர்களானால், நாம் செய்ய வேண்டியது தரவை ஆர்டினல் அளவுகோலாக கருதுவதுதான் "
"| ஆர்டினல் |! எனவே, “வேலை செய்த மணிநேரம்” அடிப்படையில் முயற்சியை அளவிடுவதற்கு பதிலா"
"க, எங்கள் 10 மாணவர்களையும் மணிநேர வேலை செய்தால் தரவரிசைப்படுத்த அனுமதிக்கிறது. அதாவது"
", மாணவர் 1 யாரிடமிருந்தும் (2 மணிநேரம்) குறைந்தது வேலை செய்தது, எனவே அவர்கள் மிகக் "
"குறைந்த தரவரிசையைப் பெறுகிறார்கள் (தரவரிசை = 1). மாணவர் 4 அடுத்த சோம்பேறி, முழு "
"செமச்டரிலும் 6 மணிநேர வேலையை மட்டுமே செலுத்துகிறது, எனவே அவர்கள் அடுத்த மிகக் குறைந்த "
"தரவரிசையைப் பெறுகிறார்கள் (தரவரிசை = 2). “குறைந்த தரவரிசை” என்று அர்த்தப்படுத்த "
"“தரவரிசை = 1” ஐப் பயன்படுத்துகிறேன் என்பதைக் கவனியுங்கள். சில நேரங்களில் அன்றாட மொழியில் "
"“தரவரிசை” என்பதை விட “சிறந்த தரவரிசை” என்று பொருள்படும் “தரவரிசை = 1” பற்றி "
"பேசுகிறோம். எனவே கவனமாக இருங்கள், நீங்கள் “மிகச்சிறிய மதிப்பிலிருந்து மிகப்பெரிய "
"மதிப்புக்கு” தரவரிசைப்படுத்தலாம் (அதாவது, சிறிய சமமான தரவரிசை 1) அல்லது நீங்கள் "
"“மிகப்பெரிய மதிப்பிலிருந்து மிகச்சிறிய மதிப்புக்கு” (அதாவது, பெரிய சமமான தரவரிசை 1)"
" தரவரிசைப்படுத்தலாம். இந்த விசயத்தில், நான் மிகச்சிறியவையிலிருந்து மிகப் பெரியவையாக "
"இருக்கிறேன், ஆனால் நீங்கள் எந்த வழியில் விசயங்களை அமைத்துள்ளீர்கள் என்பதை மறந்துவிடுவது "
"மிகவும் எளிதானது என்பதால், நினைவில் கொள்ள நீங்கள் கொஞ்சம் முயற்சி செய்ய வேண்டும்!"

#: ../../Ch12/Ch12_Regression_01.rst:426
msgid "ordinal"
msgstr "ordinal"

#: ../../Ch12/Ch12_Regression_01.rst:363
msgid ""
"Okay, so let’s have a look at our students when we rank them from worst to "
"best in terms of effort and reward:"
msgstr ""
"சரி, எனவே எங்கள் மாணவர்களை முயற்சி மற்றும் வெகுமதியின் அடிப்படையில் மோசமானவையிலிருந்து "
"சிறந்ததாக மதிப்பிடும்போது பார்ப்போம்:"

#: ../../Ch12/Ch12_Regression_01.rst:367
msgid "rank (hours worked)"
msgstr "தரவரிசை (மணிநேர வேலை)"

#: ../../Ch12/Ch12_Regression_01.rst:367
msgid "rank (grade received)"
msgstr "தரவரிசை (தரம் பெறப்பட்டது)"

#: ../../Ch12/Ch12_Regression_01.rst:369
msgid "**student 1**"
msgstr "** மாணவர் 1 **"

#: ../../Ch12/Ch12_Regression_01.rst:369
msgid "1"
msgstr "1"

#: ../../Ch12/Ch12_Regression_01.rst:371
msgid "**student 2**"
msgstr "** மாணவர் 2 **"

#: ../../Ch12/Ch12_Regression_01.rst:371
msgid "10"
msgstr "10"

#: ../../Ch12/Ch12_Regression_01.rst:373
msgid "**student 3**"
msgstr "** மாணவர் 3 **"

#: ../../Ch12/Ch12_Regression_01.rst:373
msgid "6"
msgstr "6"

#: ../../Ch12/Ch12_Regression_01.rst:375
msgid "**student 4**"
msgstr "** மாணவர் 4 **"

#: ../../Ch12/Ch12_Regression_01.rst:375
msgid "2"
msgstr "2"

#: ../../Ch12/Ch12_Regression_01.rst:377
msgid "**student 5**"
msgstr "** மாணவர் 5 **"

#: ../../Ch12/Ch12_Regression_01.rst:377
msgid "3"
msgstr "3"

#: ../../Ch12/Ch12_Regression_01.rst:379
msgid "**student 6**"
msgstr "** மாணவர் 6 **"

#: ../../Ch12/Ch12_Regression_01.rst:379
msgid "5"
msgstr "5"

#: ../../Ch12/Ch12_Regression_01.rst:381
msgid "**student 7**"
msgstr "** மாணவர் 7 **"

#: ../../Ch12/Ch12_Regression_01.rst:381
msgid "4"
msgstr "4"

#: ../../Ch12/Ch12_Regression_01.rst:383
msgid "**student 8**"
msgstr "** மாணவர் 8 **"

#: ../../Ch12/Ch12_Regression_01.rst:383
msgid "8"
msgstr "8"

#: ../../Ch12/Ch12_Regression_01.rst:385
msgid "**student 9**"
msgstr "** மாணவர் 9 **"

#: ../../Ch12/Ch12_Regression_01.rst:385
msgid "7"
msgstr "7"

#: ../../Ch12/Ch12_Regression_01.rst:387
msgid "**student 10**"
msgstr "** மாணவர் 10 **"

#: ../../Ch12/Ch12_Regression_01.rst:387
msgid "9"
msgstr "9"

#: ../../Ch12/Ch12_Regression_01.rst:390
msgid ""
"Hmm. These are *identical*. The student who put in the most effort got the "
"best grade, the student with the least effort got the worst grade, etc. As "
"the table above shows, these two rankings are identical, so if we now "
"correlate them we get a perfect relationship, with a correlation of **1.0**."
msgstr ""
"அ்ம். இவை *ஒரே மாதிரியானவை *. அதிக முயற்சியில் ஈடுபடும் மாணவர் சிறந்த தரத்தைப் பெற்றார்"
", குறைந்த முயற்சியைக் கொண்ட மாணவர் மிக மோசமான தரத்தைப் பெற்றார். மேலே உள்ள அட்டவணை "
"காண்பித்தபடி, இந்த இரண்டு தரவரிசைகளும் ஒரே மாதிரியானவை, எனவே இப்போது நாம் அவற்றைச் "
"தொடர்புபடுத்தினால், சரியான உறவைப் பெறுகிறோம், ** 1.0 ** இன் தொடர்புடன்."

#: ../../Ch12/Ch12_Regression_01.rst:396
msgid ""
"What we’ve just re-invented is **Spearman’s rank order correlation**, "
"usually denoted ρ to distinguish it from the Pearson correlation *r*. We can "
"calculate Spearman’s ρ using jamovi simply by clicking the ``Spearman`` "
"check box in the ``Correlation Matrix`` options panel."
msgstr ""
"நாம் இப்போது மீண்டும் கண்டுபிடித்திருப்பது ** ச்பியர்மேனின் தரவரிசை வரிசை தொடர்பு **, "
"வழக்கமாக அதை பியர்சன் தொடர்புகளிலிருந்து வேறுபடுத்துவதற்கு*r*. `` தொடர்பு மேட்ரிக்ச்` "
"விருப்பங்கள் குழுவில் `` ச்பியர்மேன்`` செக் பாக்சைக் சொடுக்கு செய்வதன் மூலம் சாமோவியைப் "
"பயன்படுத்துவதை நாங்கள் ச்பியர்மேனின் ρ பயன்படுத்தலாம்."

#: ../../Ch12/Ch12_Regression_01.rst:404
msgid ""
"Actually, even that table is more than I’d bother with. In practice, most "
"people pick *one* measure of central tendency, and *one* measure of "
"variability only."
msgstr ""
"உண்மையில், அந்த அட்டவணை கூட நான் கவலைப்படுவதை விட அதிகம். நடைமுறையில், பெரும்பாலான "
"மக்கள் மையப் போக்கின் * ஒரு * அளவையும், * ஒரு * மாறுபாட்டின் அளவையும் மட்டுமே தேர்வு "
"செய்கிறார்கள்."

#: ../../Ch12/Ch12_Regression_01.rst:409
msgid ""
"Just like we saw with the variance and the standard deviation, in practice "
"we divide by *N* - 1 rather than *N*."
msgstr ""
"மாறுபாடு மற்றும் நிலையான விலகலுடன் நாம் பார்த்தது போலவே, நடைமுறையில் *n *ஐ விட *n * "
"- 1 ஆல் வகுக்கிறோம்."

#: ../../Ch12/Ch12_Regression_01.rst:413
msgid "This is an oversimplification, but it’ll do for our purposes."
msgstr "இது மிகைப்படுத்தல், ஆனால் இது எங்கள் நோக்கங்களுக்காக செய்யும்."

#: ../../Ch12/Ch12_Regression_02.rst:4
msgid "Scatterplots"
msgstr "சிதறல்கள்"

#: ../../Ch12/Ch12_Regression_02.rst:6
msgid ""
"**Scatterplots** are a simple but effective tool for visualising the "
"relationship between *two* variables, like we saw with the figures in the "
"section on correlation (section :doc:`Ch12_Regression_01`). It’s this latter "
"application that we usually have in mind when we use the term “scatterplot”. "
"In this kind of plot each observation corresponds to one dot. The horizontal "
"location of the dot plots the value of the observation on one variable, and "
"the vertical location displays its value on the other variable. In many "
"situations you don’t really have a clear opinions about what the *causal* "
"relationship is (e.g., does A cause B, or does B cause A, or does some other "
"variable C control both A and B). If that’s the case, it doesn’t really "
"matter which variable you plot on the x-axis and which one you plot on the y-"
"axis. However, in many situations you do have a pretty strong idea which "
"variable you think is most likely to be causal, or at least you have some "
"suspicions in that direction. If so, then it’s conventional to plot the "
"cause variable on the x-axis, and the effect variable on the y-axis. With "
"that in mind, let’s look at how to draw scatterplots in jamovi, using the "
"same |parenthood|_ data set that I used when introducing correlations."
msgstr ""
". “சிதறல்” என்ற வார்த்தையை நாம் பயன்படுத்தும்போது வழக்கமாக மனதில் இருக்கும் இந்த பிந்தைய "
"பயன்பாடு தான். இந்த வகையான சதித்திட்டத்தில் ஒவ்வொரு அவதானிப்பும் ஒரு புள்ளிக்கு "
"ஒத்திருக்கிறது. புள்ளியின் கிடைமட்ட இருப்பிடம் ஒரு மாறியில் அவதானிப்பின் மதிப்பைத் "
"திட்டமிடுகிறது, மேலும் செங்குத்து இருப்பிடம் அதன் மதிப்பை மற்ற மாறியில் காட்டுகிறது. பல "
"சூழ்நிலைகளில் * காரண * உறவு என்றால் என்ன என்பது பற்றி உங்களுக்கு தெளிவான கருத்துக்கள் "
"இல்லை (எ.கா., ஒரு காரணமா, அல்லது பி ஒரு காரணத்தை ஏற்படுத்துகிறதா, அல்லது வேறு சில "
"மாறி சி ஏ மற்றும் பி இரண்டையும் கட்டுப்படுத்துகிறது). அப்படியானால், எக்ச்-அச்சில் நீங்கள் எந்"
"த மாறியை சூழ்ச்சி செய்கிறீர்கள், Y- அச்சில் நீங்கள் சூழ்ச்சி செய்யும் ஒரு முக்கியத்துவம் இல்லை. "
"இருப்பினும், பல சூழ்நிலைகளில் உங்களுக்கு ஒரு அழகான வலுவான சிந்தனை உள்ளது, எந்த "
"மாறுபாடு பெரும்பாலும் காரணமாக இருக்கும் என்று நீங்கள் கருதுகிறீர்கள், அல்லது குறைந்தபட்சம் "
"உங்களுக்கு சில சந்தேகங்கள் உள்ளன. அப்படியானால், எக்ச்-அச்சில் காரணம் மாறியைக் காண்பது "
"வழக்கமானதாகும், மேலும் Y- அச்சில் விளைவு மாறியாகும். இதைக் கருத்தில் கொண்டு, சமோவியில் "
"சிதறல் பிளாட்களை எவ்வாறு வரையலாம் என்பதைப் பார்ப்போம், அதே | பெற்றோர்உட் | _ தொடர்புகளை "
"அறிமுகப்படுத்தும் போது நான் பயன்படுத்திய தரவு தொகுப்பைப் பயன்படுத்துகிறோம்."

#: ../../Ch12/Ch12_Regression_02.rst:24
msgid ""
"Suppose my goal is to draw a scatterplot displaying the relationship between "
"the amount of sleep that I get (``dani.sleep``) and how grumpy I am the next "
"day (``dani.grump``). There are two different ways in which we can use "
"jamovi to get the plot that we’re after. The first way is to use the "
"``Plot`` option under the ``Regression`` → ``Correlation Matrix`` button, "
"giving us the output shown in :numref:`fig-scatterplot1`. Note that jamovi "
"draws a line through the points, we’ll come onto this a bit later in "
"section :doc:`Ch12_Regression_03`. Plotting a scatterplot in this way also "
"allow you to specify ``Densities for variables`` and this option adds a "
"density curve showing how the data in each variable is distributed."
msgstr ""
"நான் பெறும் தூக்கத்தின் அளவிற்கும் (`` டானி.லீப்``) இடையிலான உறவைக் காண்பிக்கும் ஒரு "
"சிதறலையும், அடுத்த நாள் நான் எவ்வளவு எரிச்சலூட்டுகிறேன் என்பதும் எனது குறிக்கோள் என்று "
"வைத்துக்கொள்வோம். நாம் பின்னர் சதித்திட்டத்தைப் பெற சமோவியைப் பயன்படுத்த இரண்டு வெவ்வேறு "
"வழிகள் உள்ளன. முதல் வழி `` பின்னடைவு`` → `` தொடர்பு மேட்ரிக்ச்`` பொத்தானின் கீழ் `` சதி` "
"விருப்பத்தைப் பயன்படுத்துவது, இதில் காட்டப்பட்டுள்ள வெளியீட்டை எங்களுக்குத் தருகிறது: "
"NumRef: `Fig-scatterplot1`. சமோவி புள்ளிகள் மூலம் ஒரு கோட்டை ஈர்க்கிறார் என்பதை "
"நினைவில் கொள்க, நாங்கள் இதை சிறிது நேரம் கழித்து பிரிவில் வருவோம்: டாக்: "
"`CH12_REGRESSION_03`. இந்த வழியில் ஒரு சிதறலைத் திட்டமிடுவது `` மாறிகளுக்கான "
"அடர்த்தி` `என்பதைக் குறிப்பிடவும் உங்களை அனுமதிக்கிறது, மேலும் இந்த விருப்பம் ஒவ்வொரு "
"மாறியிலும் தரவு எவ்வாறு விநியோகிக்கப்படுகிறது என்பதைக் காட்டும் அடர்த்தி வளைவைச் "
"சேர்க்கிறது."

#: ../../Ch12/Ch12_Regression_02.rst:37 ../../Ch12/Ch12_Regression_02.rst:41
msgid "Scatterplot created with the ``Correlation Matrix`` analysis in jamovi"
msgstr ""
"சமோவியில் `` தொடர்பு மேட்ரிக்ச்` பகுப்பாய்வு மூலம் சிதறல் பிளாட் உருவாக்கப்பட்டது"

#: ../../Ch12/Ch12_Regression_02.rst:45
msgid ""
"The second way do to it is to use one of the jamovi add-on modules. This "
"module is called ``scatr`` and you can install it by clicking on the large "
"``+`` icon in the top right of the jamovi screen, opening the jamovi "
"library, scrolling down until you find ``scatr`` and clicking ``Install``. "
"When you have done this, you will find a new ``Scatterplot`` command "
"available under the ``Exploration`` button. This plot is a bit different "
"than the first way, see :numref:`fig-scatterplot2`, but the important "
"information is the same."
msgstr ""
"சாமோவி கூடுதல் தொகுதிகளில் ஒன்றைப் பயன்படுத்துவதே இரண்டாவது வழி. இந்த தொகுதி `` "
"ச்காட்`` என்று அழைக்கப்படுகிறது, மேலும் சாமோவி திரையின் மேல் வலதுபுறத்தில் உள்ள பெரிய "
"``+`` ஐகானைக் சொடுக்கு செய்வதன் மூலம் அதை நிறுவலாம், சாமோவி நூலகத்தைத் திறந்து, `` "
"ச்காட்`` கண்டுபிடிக்கும் வரை கீழே உருட்டலாம் `` நிறுவு`` என்பதைக் சொடுக்கு செய்க. நீங்கள் "
"இதைச் செய்தவுடன், `` ஆய்வு` பொத்தானின் கீழ் புதிய `` சிதறல்` கட்டளையை நீங்கள் காணலாம். இந்த "
"சூழ்ச்சி முதல் வழியை விட சற்று வித்தியாசமானது, காண்க: NUMREF: `Fig-scaterplot2`, "
"ஆனால் முக்கியமான தகவல்கள் ஒன்றே."

#: ../../Ch12/Ch12_Regression_02.rst:56 ../../Ch12/Ch12_Regression_02.rst:60
msgid "Scatterplot cretaed with the ``scatr`` add-on module in jamovi"
msgstr "சமோவியில் `` ச்காட்` `கூடுதல் தொகுதி மூலம் சிதறடிக்கப்பட்டது"

#: ../../Ch12/Ch12_Regression_02.rst:65
msgid "More elaborate options"
msgstr "மேலும் விரிவான விருப்பங்கள்"

#: ../../Ch12/Ch12_Regression_02.rst:67
msgid ""
"Often you will want to look at the relationships between several variables "
"at once, using a **scatterplot matrix** (in jamovi via the ``Correlation "
"Matrix`` - ``Plot`` command). Just add another variable, for example ``baby."
"sleep`` to the list of variables to be correlated, and jamovi will create a "
"scatterplot matrix for you, just like the one in :numref:`fig-scatterplot3`."
msgstr ""
"** ச்கேட்டர்ப்ளாட் மேட்ரிக்ச் ** (சாமோவியில் `` தொடர்பு மேட்ரிக்ச்`` - `` சதி`` கட்டளை "
"வழியாக) பயன்படுத்தி, பல மாறிகள் இடையேயான உறவுகளை ஒரே நேரத்தில் நீங்கள் பார்க்க "
"விரும்புவீர்கள். மற்றொரு மாறியைச் சேர்க்கவும், எடுத்துக்காட்டாக `` குழந்தை.லீப்`` ஒன்றோடொன்று "
"தொடர்புபடுத்தப்பட வேண்டிய மாறிகள் பட்டியலில், சமோவி உங்களுக்காக ஒரு சிதறல் மேட்ரிக்சை "
"உருவாக்குவார், இதைப் போலவே: எண்ரீஃப்: `Fig-scatterplot3`."

#: ../../Ch12/Ch12_Regression_02.rst:76
msgid "Matrix of scatterplots cretaed with the ``Correlation Matrix`` analysis"
msgstr ""
"`` தொடர்பு மேட்ரிக்ச்`` பகுப்பாய்வு மூலம் உருவாக்கப்பட்ட சிதறல்களின் அணி"

#: ../../Ch12/Ch12_Regression_02.rst:80
msgid ""
"Matrix of scatterplots cretaed with the ``Correlation Matrix`` analysis in "
"jamovi."
msgstr ""
"சமோவியில் `` தொடர்பு மேட்ரிக்ச்`` பகுப்பாய்வோடு சிதறடிக்கப்பட்ட சிதறல்களின் மேட்ரிக்ச்."

#: ../../Ch12/Ch12_Regression_03.rst:4
msgid "What is a linear regression model?"
msgstr "நேரியல் பின்னடைவு மாதிரி என்றால் என்ன?"

#: ../../Ch12/Ch12_Regression_03.rst:6
msgid ""
"Stripped to its bare essentials, linear regression models are basically a "
"slightly fancier version of the Pearson correlation (section :doc:"
"`Ch12_Regression_01`), though as we’ll see regression models are much more "
"powerful tools."
msgstr ""
"அதன் அத்தியாவசியங்களுக்கு அகற்றப்பட்டால், நேரியல் பின்னடைவு மாதிரிகள் அடிப்படையில் பியர்சன் "
"தொடர்புகளின் சற்றே ஆர்வமுள்ள பதிப்பாகும் (பிரிவு: டிஓசி: `CH12_REGRESRACTE_01`), "
"பின்னடைவு மாதிரிகள் மிகவும் சக்திவாய்ந்த கருவிகள் என்று நாம் காணும் போது."

#: ../../Ch12/Ch12_Regression_03.rst:25
msgid ""
"Since the basic ideas in regression are closely tied to correlation, we’ll "
"return to the |parenthood|_ data set that we were using to illustrate how "
"correlations work. Recall that, in this data set we were trying to find out "
"why Dani is so very grumpy all the time and our working hypothesis was that "
"I’m not getting enough sleep. We drew some scatterplots to help us examine "
"the relationship between the amount of sleep I get and my grumpiness the "
"following day, as in :numref:`fig-scatterplot2`, and as we saw previously "
"this corresponds to a correlation of *r* = -0.90, but what we find ourselves "
"secretly imagining is something that looks closer to :numref:`fig-"
"regression1` (left panel). That is, we mentally draw a straight line through "
"the middle of the data. In statistics, this line that we’re drawing is "
"called a **regression line**. Notice that, since we’re not idiots, the "
"regression line goes through the middle of the data. We don’t find ourselves "
"imagining anything like the rather silly plot shown in :numref:`fig-"
"regression1` (right panel)."
msgstr ""
"பின்னடைவில் உள்ள அடிப்படை சிந்தனைகள் தொடர்புடன் நெருக்கமாக பிணைக்கப்பட்டுள்ளதால், தொடர்புகள் "
"எவ்வாறு செயல்படுகின்றன என்பதை விளக்குவதற்கு நாங்கள் பயன்படுத்தும் | பெற்றோர்ஊட் | _ தரவுத் "
"தொகுப்பிற்கு திரும்புவோம். நினைவில் கொள்ளுங்கள், இந்த தரவுத் தொகுப்பில், டானி ஏன் எப்போதுமே"
" மிகவும் எரிச்சலூட்டுகிறார் என்பதைக் கண்டுபிடிக்க முயற்சித்தோம், எங்கள் உழைக்கும் கருதுகோள் "
"என்னவென்றால், எனக்கு போதுமான தூக்கம் வரவில்லை. அடுத்த நாள், நான் பெறும் தூக்கத்தின் "
"அளவிற்கும் என் எரிச்சலுக்கும் இடையிலான உறவை ஆராய்வதற்கு நாங்கள் சில சிதறல்களை வரைந்தோம், "
"இங்: எண்ரெஃப்: `FIG-SCATERPLOT2` -0.90, ஆனால் நாம் ரகசியமாக கற்பனை செய்வது நெருக்கமா"
"ன ஒன்று: NumRef: `Fig- பின்னடைவு 1` (இடது குழு). அதாவது, தரவின் நடுவில் ஒரு நேர் "
"கோட்டை மனதளவில் வரைகிறோம். புள்ளிவிவரங்களில், நாங்கள் வரைதல் இந்த வரி ** பின்னடைவு வரி "
"** என்று அழைக்கப்படுகிறது. நாங்கள் முட்டாள்கள் அல்ல என்பதால், பின்னடைவு வரி தரவின் நடுவில் "
"செல்கிறது என்பதைக் கவனியுங்கள். காட்டப்பட்டுள்ள வேடிக்கையான சூழ்ச்சி போன்ற எதையும் நாம் "
"கற்பனை செய்வதைக் காணவில்லை: NumRef: `Fig-regreaction1` (வலது குழு)."

#: ../../Ch12/Ch12_Regression_03.rst:29
msgid "Best and poor choice of regression line"
msgstr "பின்னடைவு வரியின் சிறந்த மற்றும் மோசமான தேர்வு"

#: ../../Ch12/Ch12_Regression_03.rst:33
msgid ""
"The left panel shows the scatterplot of ``dani.sleep`` and ``dani.grump`` "
"from :numref:`fig-scatterplot2` with the best fitting regression line drawn "
"over the top. Not surprisingly, the line goes through the middle of the "
"data. In contrast, the right panel shows the same data, but with a very poor "
"choice of regression line drawn over the top."
msgstr ""
"இடது குழு `` டானி.லீப்`` மற்றும் `` டானி. ஆச்சரியப்படுவதற்கில்லை, வரி தரவின் நடுவில் "
"செல்கிறது. இதற்கு நேர்மாறாக, வலது குழு அதே தரவைக் காட்டுகிறது, ஆனால் மேலே வரையப்பட்ட "
"பின்னடைவு வரியின் மிக மோசமான தேர்வுடன்."

#: ../../Ch12/Ch12_Regression_03.rst:41
msgid ""
"This is not highly surprising. The line that I’ve drawn in :numref:`fig-"
"regression1` (right panel) doesn’t “fit” the data very well, so it doesn’t "
"make a lot of sense to propose it as a way of summarising the data, right? "
"This is a very simple observation to make, but it turns out to be very "
"powerful when we start trying to wrap just a little bit of maths around it. "
"To do so, let’s start with a refresher of some high school maths. The "
"formula for a straight line is usually written like this:"
msgstr ""
"இது மிகவும் ஆச்சரியமல்ல. நான் வரையப்பட்ட வரி: எண்ரெஃப்: `அத்தி-பின்னடைவு 1` (வலது குழு)"
" தரவை நன்றாக\" பொருந்தாது \", எனவே இதைச் சுருக்கமாகக் கூறும் ஒரு வழியாக அதை முன்மொழி"
"ய நிறைய பொருள் இல்லை தரவு, இல்லையா? இது மிகவும் எளிமையான அவதானிப்பாகும், ஆனால் அதைச் "
"சுற்றி கணிதத்தை சிறிது மடக்கத் தொடங்கும்போது அது மிகவும் சக்திவாய்ந்ததாக மாறும். அவ்வாறு "
"செய்ய, சில உயர்நிலைப் பள்ளி கணிதத்தின் புத்துணர்ச்சியுடன் ஆரம்பிக்கலாம். ஒரு நேர் கோட்டிற்கா"
"ன தேற்றம் பொதுவாக இதுபோன்று எழுதப்படுகிறது:"

#: ../../Ch12/Ch12_Regression_03.rst:49
msgid "*y* = *a* + *bx*"
msgstr "*y* = *a* + *bx*"

#: ../../Ch12/Ch12_Regression_03.rst:51
msgid ""
"Or, at least, that’s what it was when I went to high school all those years "
"ago. The two *variables* are *x* and *y*, and we have two *coefficients*, "
"*a* and *b*\\.\\ [#]_ The coefficient *a* represents the **y-intercept** of "
"the line, and coefficient *b* represents the *slope* of the line. Digging "
"further back into our decaying memories of high school (sorry, for some of "
"us high school was a long time ago), we remember that the intercept is "
"interpreted as “the value of *y* that you get when *x* = 0”. Similarly, a "
"slope of *b* means that if you increase the *x*-value by 1 unit, then the "
"*y*-value goes up by *b* units, and a negative slope means that the *y*-"
"value would go down rather than up. Ah yes, it’s all coming back to me now. "
"Now that we’ve remembered that it should come as no surprise to discover "
"that we use the exact same formula for a regression line. If *Y* is the "
"outcome variable (the DV) and *X* is the predictor variable (the IV), then "
"the formula that describes our regression is written like this:"
msgstr ""
"அல்லது, குறைந்தபட்சம், அந்த ஆண்டுகளுக்கு முன்பு நான் உயர்நிலைப் பள்ளிக்குச் சென்றபோது அதுதான்"
". இரண்டு*மாறிகள்**x*மற்றும்*y*, மற்றும் எங்களிடம் இரண்டு*குணகங்கள்*,*a*மற்றும்*b*\\. \\ "
"[#] _ குணகம்*A*** y- இடைமுகத்தை குறிக்கிறது ** வரியின், மற்றும் குணகம் * பி * வரியின்"
" * சாய்வு * ஐ குறிக்கிறது. உயர்நிலைப் பள்ளியின் எங்கள் அழுகும் நினைவுகளுக்கு மேலும் "
"மீண்டும் தோண்டுவது (மன்னிக்கவும், நம்மில் சிலர் உயர்நிலைப் பள்ளி நீண்ட காலத்திற்கு முன்பு), "
"இடைமறிப்பு “ * ஒய் * இன் மதிப்பு * ஃச் * = 0 என நீங்கள் பெறும் மதிப்பு என்று நாங்கள் "
"நினைவில் கொள்கிறோம் ”. இதேபோல், *b *இன் சாய்வு என்பது நீங்கள் *x *-value ஐ 1 அலகு மூலம் "
"அதிகரித்தால், *y *-மதிப்பு *b *அலகுகளால் அதிகரிக்கும், மற்றும் எதிர்மறை சாய்வு என்பது *"
"y *-மதிப்பு என்று பொருள் மேலே செல்வதை விட கீழே போகும். ஆமாம், இது எல்லாம் இப்போது "
"என்னிடம் திரும்பி வருகிறது. பின்னடைவு வரிக்கு அதே சூத்திரத்தை நாங்கள் பயன்படுத்துகிறோம் "
"என்பதைக் கண்டுபிடிப்பதில் ஆச்சரியமில்லை என்பதை இப்போது நினைவில் வைத்திருக்கிறோம். * ஒய் * "
"என்பது விளைவு மாறி (DV) மற்றும் * ஃச் * என்பது முன்கணிப்பு மாறி (IV) என்றால், எங்கள் "
"பின்னடைவை விவரிக்கும் தேற்றம் இப்படி எழுதப்பட்டுள்ளது:"

#: ../../Ch12/Ch12_Regression_03.rst:66
msgid "*Ŷ*\\ :sub:`i` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`i`"
msgstr "*Ŷ*\\ :sub:`i` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`i`"

#: ../../Ch12/Ch12_Regression_03.rst:68
msgid ""
"Hmm. Looks like the same formula, but there’s some extra frilly bits in this "
"version. Let’s make sure we understand them. Firstly, notice that I’ve "
"written *X*\\ :sub:`i` and *Y*\\ :sub:`i` rather than just plain old *X* and "
"*Y*. This is because we want to remember that we’re dealing with actual "
"data. In this equation, *X*\\ :sub:`i` is the value of predictor variable "
"for the i\\ th observation (i.e., the number of hours of sleep that I got on "
"day i of my little study), and *Y*\\ :sub:`i` is the corresponding value of "
"the outcome variable (i.e., my grumpiness on that day). And although I "
"haven’t said so explicitly in the equation, what we’re assuming is that this "
"formula works for all observations in the data set (i.e., for all i). "
"Secondly, notice that I wrote *Ŷ*\\ :sub:`i` and not *Y*\\ :sub:`i`. This is "
"because we want to make the distinction between the *actual data* *Y*\\ :sub:"
"`i`, and the *estimate* *Ŷ*\\ :sub:`i` (i.e., the prediction that our "
"regression line is making). Thirdly, I changed the letters used to describe "
"the coefficients from *a* and *b* to *b*\\ :sub:`0` and *b*\\ :sub:`1`. "
"That’s just the way that statisticians like to refer to the coefficients in "
"a regression model. I’ve no idea why they chose *b*, but that’s what they "
"did. In any case *b*\\ :sub:`0` always refers to the intercept term, and "
"*b*\\ :sub:`1` refers to the slope."
msgstr ""
"அ்ம். அதே தேற்றம் போல் தெரிகிறது, ஆனால் இந்த பதிப்பில் சில கூடுதல் ஃபிரில்லி பிட்கள் உள்"
"ளன. அவற்றைப் புரிந்துகொள்வதை உறுதிசெய்கிறோம். முதலாவதாக, நான் *x *\\: sub: `i` மற்றும்"
" *y *\\: துணை:` நான் பழைய பழைய *x *மற்றும் *y *ஐ விட. ஏனென்றால், நாங்கள் உண்மையான "
"தரவைக் கையாளுகிறோம் என்பதை நினைவில் கொள்ள விரும்புகிறோம். இந்த சமன்பாட்டில், *x *\\: "
"துணை: `நான்` நான் அவதானிப்புக்கான முன்கணிப்பு மாறியின் மதிப்பு (அதாவது, எனது சிறிய "
"ஆய்வின் நாளில் எனக்கு கிடைத்த தூக்கத்தின் மணிநேரம்), மற்றும் *y *\\: துணை: `நான்` விளைவு "
"மாறியின் தொடர்புடைய மதிப்பு (அதாவது, அந்த நாளில் என் எரிச்சல்). சமன்பாட்டில் நான் இவ்வளவு "
"வெளிப்படையாகச் சொல்லவில்லை என்றாலும், இந்த தேற்றம் தரவுத் தொகுப்பில் உள்ள அனைத்து "
"அவதானிப்புகளுக்கும் (அதாவது, எல்லாவற்றிற்கும்) செயல்படுகிறது என்று நாங்கள் கருதுகிறோம். "
"இரண்டாவதாக, நான் எழுதியதைக் கவனியுங்கள் ஏனென்றால், *உண்மையான தரவு * *y *\\: sub: `i`"
", மற்றும் *மதிப்பீடு * *ŷ *\\: துணை:` i` (அதாவது, எங்கள் பின்னடைவு வரி என்ற கணிப்பு "
"தயாரிக்கிறது). மூன்றாவதாக, குணகங்களை *A *மற்றும் *B *இலிருந்து *B *\\: துணை: `0` "
"மற்றும் *B *\\: துணை:` 1` என விவரிக்கப் பயன்படுத்தப்படும் கடிதங்களை மாற்றினேன். பின்னடைவு"
" மாதிரியில் குணகங்களைக் குறிப்பிட புள்ளிவிவர வல்லுநர்கள் விரும்பும் வழி இதுதான். அவர்கள் "
"ஏன் *பி *ஐத் தேர்ந்தெடுத்தார்கள் என்று எனக்குத் தெரியவில்லை, ஆனால் அதைத்தான் அவர்கள் செய்தார்கள்"
". எந்தவொரு சந்தர்ப்பத்திலும் *பி *\\: துணை: `0` எப்போதும் இடைமறிப்பு காலத்தைக் "
"குறிக்கிறது, மேலும் *பி *\\: துணை:` 1` சாய்வைக் குறிக்கிறது."

#: ../../Ch12/Ch12_Regression_03.rst:89
msgid ""
"Excellent, excellent. Next, I can’t help but notice that, regardless of "
"whether we’re talking about the good regression line or the bad one, the "
"data don’t fall perfectly on the line. Or, to say it another way, the data "
"*Y*\\ :sub:`i` are not identical to the predictions of the regression model "
"*Ŷ*\\ :sub:`i`. Since statisticians love to attach letters, names and "
"numbers to everything, let’s refer to the difference between the model "
"prediction and that actual data point as a *residual*, and we’ll refer to it "
"as ε\\ :sub:`i`.\\ [#]_ Written using mathematics, the residuals are defined "
"as"
msgstr ""
"சிறந்த, சிறந்த. அடுத்து, எனக்கு உதவ முடியாது, ஆனால் கவனிக்க முடியாது, நாங்கள் நல்ல "
"பின்னடைவு வரி அல்லது மோசமான ஒன்றைப் பற்றி பேசுகிறோமா என்பதைப் பொருட்படுத்தாமல், தரவு "
"வரியில் சரியாக வராது. அல்லது, இதை வேறு வழியில் சொல்ல, தரவு *y *\\: துணை: `நான்` "
"பின்னடைவு மாதிரியின் கணிப்புகளுக்கு ஒத்ததாக இல்லை *ŷ *\\: துணை: `நான்`. புள்ளிவிவர "
"வல்லுநர்கள் கடிதங்கள், பெயர்கள் மற்றும் எண்களை எல்லாவற்றிற்கும் இணைக்க விரும்புவதால், மாதிரி "
"முன்கணிப்பு மற்றும் உண்மையான தரவு புள்ளியை ஒரு *எஞ்சியவை *என்று குறிப்பிடுவோம், மேலும் "
"அதை ε \\: துணை: `நான்` என்று குறிப்பிடுவோம். \\ [#] _ கணிதத்தைப் பயன்படுத்தி "
"எழுதப்பட்டது, எச்சங்கள் என வரையறுக்கப்படுகின்றன"

#: ../../Ch12/Ch12_Regression_03.rst:99 ../../Ch12/Ch12_Regression_11.rst:60
msgid "ε\\ :sub:`i` = *Y*\\ :sub:`i` - *Ŷ*\\ :sub:`i`"
msgstr "ε\\ :sub:`i` = *Y*\\ :sub:`i` - *Ŷ*\\ :sub:`i`"

#: ../../Ch12/Ch12_Regression_03.rst:101
msgid ""
"which in turn means that we can write down the complete linear regression "
"model as"
msgstr ""
"இதன் பொருள் என்னவென்றால், முழுமையான நேரியல் பின்னடைவு மாதிரியை நாம் எழுதலாம்"

#: ../../Ch12/Ch12_Regression_03.rst:104
msgid ""
"*Y*\\ :sub:`i` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`i` + ε\\ :sub:"
"`i`"
msgstr ""
"*Y*\\ :sub:`i` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`i` + ε\\ "
":sub:`i`"

#: ../../Ch12/Ch12_Regression_03.rst:109
msgid ""
"Also sometimes written as *y* = mx + c where m is the slope coefficient and "
"c is the intercept (constant) coefficient."
msgstr ""
"சில சமயங்களில் * ஒய் * = mx + C என எழுதப்பட்டது, அங்கு m என்பது சாய்வு குணகம் மற்றும் C "
"என்பது இடைமறிப்பு (நிலையான) குணகம்."

#: ../../Ch12/Ch12_Regression_03.rst:113
msgid ""
"The ε symbol is the Greek letter epsilon. It’s traditional to use ε\\ :sub:"
"`i` or e\\ :sub:`i` to denote a residual."
msgstr ""
"Ε அடையாளம் கிரேக்க எழுத்து எப்சிலன் ஆகும். Ε \\: sub: `i` அல்லது இ \\: sub:` நான் ஒரு"
" எஞ்சியதைக் குறிக்கப் பயன்படுத்துவது பாரம்பரியமானது."

#: ../../Ch12/Ch12_Regression_04.rst:4
msgid "Estimating a linear regression model"
msgstr "ஒரு நேரியல் பின்னடைவு மாதிரியை மதிப்பிடுதல்"

#: ../../Ch12/Ch12_Regression_04.rst:8
msgid "Residuals associated with the best and with a poor regression line"
msgstr "சிறந்த மற்றும் மோசமான பின்னடைவு வரியுடன் தொடர்புடைய எச்சங்கள்"

#: ../../Ch12/Ch12_Regression_04.rst:12
msgid ""
"Depiction of the residuals associated with the best fitting regression line "
"(left panel), and the residuals associated with a poor regression line "
"(right panel). The residuals are much smaller for the good regression line. "
"Again, this is no surprise given that the good line is the one that goes "
"right through the middle of the data."
msgstr ""
"சிறந்த பொருத்துதல் பின்னடைவு வரி (இடது குழு) உடன் தொடர்புடைய எச்சங்களின் சித்தரிப்பு, "
"மற்றும் மோசமான பின்னடைவு வரியுடன் (வலது குழு) தொடர்புடைய எச்சங்கள். நல்ல பின்னடைவு "
"வரிக்கு எச்சங்கள் மிகவும் சிறியவை. மீண்டும், நல்ல வரி என்பது தரவின் நடுவில் சரியாகச் "
"செல்வதில் ஆச்சரியமில்லை."

#: ../../Ch12/Ch12_Regression_04.rst:20
msgid ""
"Okay, now let’s redraw our pictures but this time I’ll add some lines to "
"show the size of the residual for all observations. When the regression line "
"is good, our residuals (the lengths of the solid black lines) all look "
"pretty small, as shown in :numref:`fig-regression3` (left panel), but when "
"the regression line is a bad one the residuals are a lot larger, as you can "
"see from looking at :numref:`fig-regression3` (right panel). Hmm. Maybe what "
"we “want” in a regression model is *small* residuals. Yes, that does seem to "
"make sense. In fact, I think I’ll go so far as to say that the “best "
"fitting” regression line is the one that has the smallest residuals. Or, "
"better yet, since statisticians seem to like to take squares of everything "
"why not say that: The estimated regression coefficients, :math:`\\hat{b}_0` "
"and :math:`\\hat{b}_1`, are those that minimise the sum of the squared "
"residuals, which we could either write as"
msgstr ""
"சரி, இப்போது எங்கள் படங்களை மறுவடிவமைப்போம், ஆனால் இந்த நேரத்தில் எல்லா அவதானிப்புகளுக்கும்"
" எஞ்சிய அளவைக் காட்ட சில வரிகளைச் சேர்ப்பேன். பின்னடைவு வரி நன்றாக இருக்கும்போது, எங்கள் "
"எச்சங்கள் (திடமான கருப்பு கோடுகளின் நீளம்) அனைத்தும் காட்டப்பட்டுள்ளபடி மிகவும் சிறியதாக "
"இருக்கும்: NumRef: `Fig- பின்னடைவு 3` (இடது குழு), ஆனால் பின்னடைவு வரி மோசமானதாக "
"இருக்கும்போது எஞ்சியவை பார்ப்பதிலிருந்து நீங்கள் காணக்கூடியது போல்: NumRef: `Fig-"
"regreaction3` (வலது குழு). அ்ம். ஒரு பின்னடைவு மாதிரியில் நாம் “விரும்புவது” * சிறி"
"ய * எச்சங்கள். ஆம், அது அர்த்தமுள்ளதாகத் தெரிகிறது. உண்மையில், “சிறந்த பொருத்துதல்” "
"பின்னடைவு வரி மிகச்சிறிய எச்சங்களைக் கொண்டுள்ளது என்று சொல்லும் அளவிற்கு நான் செல்வேன் என்று"
" நினைக்கிறேன். . சதுர எச்சங்களின் தொகையை குறைப்பவர்கள், நாங்கள் எழுதலாம்"

#: ../../Ch12/Ch12_Regression_04.rst:34
msgid ""
"\\sum_i (Y_i - \\hat{Y}_i)^2\n"
"\n"
msgstr ""
"\\sum_i (Y_i - \\hat{Y}_i)^2\n"
"\n"

#: ../../Ch12/Ch12_Regression_04.rst:36
msgid "or as"
msgstr "அல்லது என"

#: ../../Ch12/Ch12_Regression_04.rst:38
msgid ""
"\\sum_i \\epsilon_{i}^2\n"
"\n"
msgstr ""
"\\sum_i \\epsilon_{i}^2\n"
"\n"

#: ../../Ch12/Ch12_Regression_04.rst:40
msgid ""
"Yes, yes that sounds even better. And since I’ve indented it like that, it "
"probably means that this is the right answer. And since this is the right "
"answer, it’s probably worth making a note of the fact that our regression "
"coefficients are *estimates* (we’re trying to guess the parameters that "
"describe a population!), which is why I’ve added the little hats, so that we "
"get :math:`\\hat{b}_0` and :math:`\\hat{b}_1` rather than *b*\\ :sub:`0` and "
"*b*\\ :sub:`1`. Finally, I should also note that, since there’s actually "
"more than one way to estimate a regression model, the more technical name "
"for this estimation process is **ordinary least squares (OLS) regression**."
msgstr ""
"ஆம், ஆம் அது இன்னும் சிறப்பாக தெரிகிறது. நான் அதை அப்படி உள்தள்ளப்பட்டதால், இது சரியான "
"பதில் என்று பொருள். இது சரியான பதில் என்பதால், எங்கள் பின்னடைவு குணகங்கள் * மதிப்பீடுகள் * "
"(மக்கள்தொகையை விவரிக்கும் அளவுருக்களை யூகிக்க முயற்சிக்கிறோம்!), அதனால்தான் நான் சிறியதைச்"
" சேர்த்துள்ளேன் தொப்பிகள், அதனால் நாம் பெறுகிறோம்: கணிதம்: `\\ தொப்பி {b} _0` மற்றும்: "
"கணிதம்:` \\ தொப்பி {b} _1` *b *\\: துணை: `0` மற்றும் *b *\\: துணை:` 1`. இறுதியா"
"க, பின்னடைவு மாதிரியை மதிப்பிடுவதற்கு ஒன்றுக்கு மேற்பட்ட வழிகள் இருப்பதால், இந்த "
"மதிப்பீட்டு செயல்முறைக்கான தொழில்நுட்ப பெயர் ** சாதாரண குறைந்தபட்ச சதுரங்கள் (OLS) "
"பின்னடைவு ** என்பதையும் நான் கவனத்தில் கொள்ள வேண்டும்."

#: ../../Ch12/Ch12_Regression_04.rst:51
msgid ""
"At this point, we now have a concrete definition for what counts as our "
"“best” choice of regression coefficients, :math:`\\hat{b}_0` and :math:"
"`\\hat{b}_1`. The natural question to ask next is, if our optimal regression "
"coefficients are those that minimise the sum squared residuals, how do we "
"*find* these wonderful numbers? The actual answer to this question is "
"complicated and doesn’t help you understand the logic of regression.\\ [#]_ "
"This time I’m going to let you off the hook. Instead of showing you the long "
"and tedious way first and then “revealing” the wonderful shortcut that "
"jamovi provides, let’s cut straight to the chase and just use jamovi to do "
"all the heavy lifting."
msgstr ""
"இந்த கட்டத்தில், பின்னடைவு குணகங்களின் எங்கள் “சிறந்த” தேர்வு எனக் கருதப்படுவதற்கு இப்போது "
"ஒரு உறுதியான வரையறை உள்ளது,: கணிதம்: `\\ தொப்பி {b} _0` மற்றும்: கணிதம்:` \\ தொப்பி "
"{b} _1`. அடுத்து கேட்க வேண்டிய இயல்பான கேள்வி என்னவென்றால், எங்கள் உகந்த பின்னடைவு "
"குணகங்கள் சதுரத்தில் சதுர எச்சங்களைக் குறைக்கும் என்றால், இந்த அற்புதமான எண்களை நாம் எவ்வாறு "
"கண்டுபிடிப்பது? இந்த கேள்விக்கான உண்மையான பதில் சிக்கலானது மற்றும் பின்னடைவின் தர்க்கத்தைப் "
"புரிந்துகொள்ள உங்களுக்கு உதவாது. \\ [#] _ இந்த நேரத்தில் நான் உங்களை கொக்கி விட்டுவிடப் "
"போகிறேன். முதலில் நீண்ட மற்றும் கடினமான வழியைக் காண்பிப்பதற்குப் பதிலாக, சாமோவி வழங்கும் "
"அற்புதமான குறுக்குவழியை \"வெளிப்படுத்துதல்\" என்பதற்குப் பதிலாக, சேசுக்கு நேராக வெட்டி"
", சமோவியைப் பயன்படுத்தி அனைத்து கனமான தூக்குதலையும் செய்யலாம்."

#: ../../Ch12/Ch12_Regression_04.rst:63
msgid "Linear regression in jamovi"
msgstr "சமோவியில் நேரியல் பின்னடைவு"

#: ../../Ch12/Ch12_Regression_04.rst:67 ../../Ch12/Ch12_Regression_04.rst:71
msgid "jamovi screenshot showing a simple linear regression analysis"
msgstr "எளிய நேரியல் பின்னடைவு பகுப்பாய்வைக் காட்டும் சாமோவி திரைக்காட்சி"

#: ../../Ch12/Ch12_Regression_04.rst:75
msgid ""
"To run my linear regression, open up the ``Regression`` - ``Linear "
"Regression`` analysis in jamovi, using the |parenthood|_ data set. Then "
"specify ``dani.grump`` as the ``Dependent Variable`` and ``dani.sleep`` as "
"the variable entered in the ``Covariates`` box. This gives the results shown "
"in :numref:`fig-reg1`, showing an intercept :math:`\\hat{b}_0` = 125.96 and "
"the slope :math:`\\hat{b}_1` = -8.94. In other words, the best-fitting "
"regression line that I plotted in :numref:`fig-regression1` has this formula:"
msgstr ""
"எனது நேரியல் பின்னடைவை இயக்க, | பெற்றோர் | _ தரவு தொகுப்பைப் பயன்படுத்தி சாமோவியில் `` "
"பின்னடைவு` ` -` `நேரியல் பின்னடைவு`` பகுப்பாய்வைத் திறக்கவும். `` டானி. இது "
"காட்டப்பட்டுள்ள முடிவுகளைத் தருகிறது: numref: `fig -reg1`, ஒரு இடைமறிப்பைக் "
"காட்டுகிறது: கணிதம்:` \\ தொப்பி {b} _0` = 125.96 மற்றும் சாய்வு: கணிதம்: `\\ தொப்பி "
"{b} _1` = -8.94. வேறு வார்த்தைகளில் கூறுவதானால், நான் திட்டமிட்ட சிறந்த பின்னடைவு வரி:"
" எண்ரெஃப்: `அத்தி-பின்னடைவு 1` இந்த சூத்திரத்தைக் கொண்டுள்ளது:"

#: ../../Ch12/Ch12_Regression_04.rst:83
msgid "*Ŷ*\\ :sub:`i` = 125.96 + (-8.94 \\ *X*\\ :sub:`i`)"
msgstr "*Ŷ*\\ :sub:`i` = 125.96 + (-8.94 \\ *X*\\ :sub:`i`)"

#: ../../Ch12/Ch12_Regression_04.rst:86
msgid "Interpreting the estimated model"
msgstr "மதிப்பிடப்பட்ட மாதிரியை விளக்குகிறது"

#: ../../Ch12/Ch12_Regression_04.rst:88
msgid ""
"The most important thing to be able to understand is how to interpret these "
"coefficients. Let’s start with :math:`\\hat{b}_1`, the slope. If we remember "
"the definition of the slope, a regression coefficient of :math:`\\hat{b}_1` "
"= -8.94 means that if I increase *X*\\ :sub:`i` by 1, then I’m decreasing "
"*Y*\\ :sub:`i` by 8.94. That is, each additional hour of sleep that I gain "
"will improve my mood, reducing my grumpiness by 8.94 grumpiness points. What "
"about the intercept? Well, since :math:`\\hat{b}_0` corresponds to “the "
"expected value of *Y*\\ :sub:`i` when *X*\\ :sub:`i` equals 0”, it’s pretty "
"straightforward. It implies that if I get zero hours of sleep (*X*\\ :sub:"
"`i` = 0) then my grumpiness will go off the scale, to an insane value of "
"(*Y*\\ :sub:`i` = \\125.96). Best to be avoided, I think."
msgstr ""
"இந்த குணகங்களை எவ்வாறு விளக்குவது என்பது புரிந்து கொள்ள முடியாத மிக முக்கியமான சேதி. "
"இதனுடன் ஆரம்பிக்கலாம்: கணிதம்: `\\ தொப்பி {b} _1`, சாய்வு. சாய்வின் வரையறையை நாம் "
"நினைவில் வைத்திருந்தால், ஒரு பின்னடைவு குணகம்: கணிதம்: `\\ தொப்பி {b} _1` = -8.94 "
"என்றால் நான் *x *\\: துணை:` நான் 1 ஆல் அதிகரித்தால், நான் குறைந்து வருகிறேன் *Y*\\: "
"துணை: `நான்` 8.94 க்குள். அதாவது, நான் பெறும் ஒவ்வொரு கூடுதல் மணிநேர தூக்கமும் எனது "
"மனநிலையை மேம்படுத்தும், என் எரிச்சலை 8.94 எரிச்சலூட்டும் புள்ளிகளால் குறைக்கும். "
"இடைமறிப்பு பற்றி என்ன? சரி, முதல்: கணிதம்: `\\ தொப்பி {b} _0`“ *y *\\: sub: `i` "
"போது *x *\\: sub:` நான் 0 க்கு சமம் ”என்பதற்கு ஒத்திருக்கிறது, இது மிகவும் நேரடியானது"
". எனக்கு சுழிய மணிநேர தூக்கத்தைப் பெற்றால் (*x*\\: துணை: `i` = 0) என் எரிச்சல் (*y*\\:"
" துணை:` i` = \\ 125.96). தவிர்க்கப்படுவது சிறந்தது, நான் நினைக்கிறேன்."

#: ../../Ch12/Ch12_Regression_04.rst:103
msgid ""
"Or at least, I’m assuming that it doesn’t help most people. But on the off-"
"chance that someone reading this is a proper kung fu master of linear "
"algebra (and to be fair, I always have a few of these people in my "
"intorductory statistics class), it *will* help *you* to know that the "
"solution to the estimation problem turns out to be :math:`\\hat{b} = "
"(\\mathbf{X}^\\prime\\mathbf{X})^{-1} \\mathbf{X}^\\prime y`, where :math:"
"`\\hat{b}` is a vector containing the estimated regression coefficients, "
"**X** is the “design matrix” that contains the predictor variables (plus an "
"additional column containing all ones; strictly **X** is a matrix of the "
"regressors, but I haven’t discussed the distinction yet), and *y* is a "
"vector containing the outcome variable. For everyone else, this isn’t "
"exactly helpful and can be downright scary. However, since quite a few "
"things in linear regression can be written in linear algebra terms, you’ll "
"see a bunch of footnotes like this one in this chapter. If you can follow "
"the maths in them, great. If not, ignore it."
msgstr ""
"அல்லது குறைந்த பட்சம், இது பெரும்பாலான மக்களுக்கு உதவாது என்று கருதுகிறேன். ஆனால் இதைப் "
"படிக்கும் ஒருவர் நேரியல் இயற்கணிதத்தின் சரியான குங் ஃபூ மாச்டர் (மற்றும் சரியாகச் "
"சொல்வதானால், இந்த நபர்களில் சிலரை எனது இன்டார்டரி புள்ளிவிவர வகுப்பில் நான் எப்போதும் "
"வைத்திருக்கிறேன்) மதிப்பீட்டு சிக்கலுக்கான தீர்வு: கணிதம்: `\\ தொப்பி {b} = (\\ mathbf "
"{X}^\\ prime \\ mathbf {X})^{-1} \\ MathBf {X}^\\ பிரைம் ஒய் `, எங்கே: கணிதம்:` "
"\\ தொப்பி {b} `என்பது மதிப்பிடப்பட்ட பின்னடைவு குணகங்களைக் கொண்ட ஒரு திசையன், ** ஃச் ** "
"என்பது முன்கணிப்பு மாறிகள் கொண்ட“ வடிவமைப்பு மேட்ரிக்ச் ”(மேலும் அனைத்தையும் கொண்ட கூடுதல் "
"நெடுவரிசை; கண்டிப்பாக ** ஃச் ** என்பது பின்னடைவுகளின் ஒரு அணி, ஆனால் நான் இன்னும் "
"வேறுபாட்டைப் பற்றி விவாதிக்கவில்லை), மற்றும்* y* என்பது விளைவு மாறியைக் கொண்ட ஒரு "
"திசையன். மற்ற அனைவருக்கும், இது சரியாக உதவாது, மேலும் பயமுறுத்தும். இருப்பினும், "
"நேரியல் பின்னடைவில் சில விசயங்களை நேரியல் இயற்கணித சொற்களில் எழுத முடியும் என்பதால், இந்"
"த அத்தியாயத்தில் இது போன்ற அடிக்குறிப்புகளை நீங்கள் காண்பீர்கள். அவற்றில் உள்ள கணிதத்தை நீங்கள் "
"பின்பற்ற முடிந்தால், சிறந்தது. இல்லையென்றால், அதை புறக்கணிக்கவும்."

#: ../../Ch12/Ch12_Regression_05.rst:4
msgid "Multiple linear regression"
msgstr "பல நேரியல் பின்னடைவு"

#: ../../Ch12/Ch12_Regression_05.rst:6
msgid ""
"The simple linear regression model that we’ve discussed up to this point "
"assumes that there’s a single predictor variable that you’re interested in, "
"in this case ``dani.sleep``. In fact, up to this point *every* statistical "
"tool that we’ve talked about has assumed that your analysis uses one "
"predictor variable and one outcome variable. However, in many (perhaps most) "
"research projects you actually have multiple predictors that you want to "
"examine. If so, it would be nice to be able to extend the linear regression "
"framework to be able to include multiple predictors. Perhaps some kind of "
"**multiple regression** model would be in order?"
msgstr ""
"இந்த கட்டத்தில் நாங்கள் விவாதித்த எளிய நேரியல் பின்னடைவு மாதிரி, நீங்கள் ஆர்வமுள்ள ஒரு "
"முன்கணிப்பு மாறி இருப்பதாகக் கருதுகிறது, இந்த விசயத்தில் `` டானி.லீப்``. உண்மையில், இந்த "
"கட்டம் * நாங்கள் பேசிய ஒவ்வொரு * புள்ளிவிவரக் கருவியும் உங்கள் பகுப்பாய்வு ஒரு முன்கணிப்பு "
"மாறியையும் ஒரு விளைவு மாறியையும் பயன்படுத்துகிறது என்று கருதுகிறது. இருப்பினும், பல "
"(ஒருவேளை பெரும்பாலான) ஆராய்ச்சித் திட்டங்களில் நீங்கள் ஆராய விரும்பும் பல முன்கணிப்பாளர்களைக்"
" கொண்டிருக்கிறீர்கள். அப்படியானால், பல முன்கணிப்பாளர்களைச் சேர்க்க நேரியல் பின்னடைவு "
"கட்டமைப்பை நீட்டிக்க முடிந்தால் நன்றாக இருக்கும். ஒருவேளை ஒருவிதமான ** பல பின்னடைவு ** "
"மாதிரி ஒழுங்காக இருக்கும்?"

#: ../../Ch12/Ch12_Regression_05.rst:17
msgid ""
"Multiple regression is conceptually very simple. All we do is add more terms "
"to our regression equation. Let’s suppose that we’ve got two variables that "
"we’re interested in; perhaps we want to use both ``dani.sleep`` and ``baby."
"sleep`` to predict the ``dani.grump`` variable. As before, we let *Y*\\ :sub:"
"`i` refer to my grumpiness on the i-th day. But now we have two *X* "
"variables: the first corresponding to the amount of sleep I got and the "
"second corresponding to the amount of sleep my son got. So we’ll let *X*\\ :"
"sub:`i1` refer to the hours I slept on the i-th day and *X*\\ :sub:`i2` "
"refers to the hours that the baby slept on that day. If so, then we can "
"write our regression model like this:"
msgstr ""
"பல பின்னடைவு கருத்தியல் ரீதியாக மிகவும் எளிமையானது. நாங்கள் செய்வது எங்கள் பின்னடைவு "
"சமன்பாட்டில் கூடுதல் விதிமுறைகளைச் சேர்ப்பதுதான். நாங்கள் ஆர்வமாக உள்ள இரண்டு மாறிகள் "
"கிடைத்துள்ளன என்று வைத்துக்கொள்வோம்; `` dani.grump`` மாறுபாட்டைக் கணிக்க `` டானி.லீப்`` "
"மற்றும் `` பேபி.லீப்` இரண்டையும் பயன்படுத்த விரும்புகிறோம். முன்பு போல, நாங்கள் *y *\\: "
"துணை: `நான் என் எரிச்சலைக் குறிப்பிடுகிறேன். ஆனால் இப்போது எங்களிடம் இரண்டு * ஃச் * "
"மாறிகள் உள்ளன: முதலாவது எனக்கு கிடைத்த தூக்கத்தின் அளவிற்கும், இரண்டாவது என் மகனுக்கு "
"கிடைத்த தூக்கத்திற்கும் ஒத்திருக்கிறது. எனவே *x *\\: sub: `i1` ஐ-வது நாளில் நான் தூங்கி"
"ய மணிநேரங்களைக் குறிக்க அனுமதிப்போம், *x *\\: துணை:` i2` என்பது அந்த நாளில் குழந்தை "
"தூங்கிய மணிநேரங்களைக் குறிக்கிறது. அப்படியானால், எங்கள் பின்னடைவு மாதிரியை இதுபோன்று "
"எழுதலாம்:"

#: ../../Ch12/Ch12_Regression_05.rst:29
msgid ""
"*Y*\\ :sub:`i` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`i1` + *b*\\ :"
"sub:`2` *X*\\ :sub:`i2` + ε\\ :sub:`i`"
msgstr ""
"*Y*\\ :sub:`i` = *b*\\ :sub:`0` + *b*\\ :sub:`1` *X*\\ :sub:`i1` + *b*\\ "
":sub:`2` *X*\\ :sub:`i2` + ε\\ :sub:`i`"

#: ../../Ch12/Ch12_Regression_05.rst:31
msgid ""
"As before, ε\\ :sub:`i` is the residual associated with the i-th "
"observation, :math:`{\\epsilon}_i = {Y}_i - \\hat{Y}_i`. In this model, we "
"now have three coefficients that need to be estimated: *b*\\ :sub:`0` is the "
"intercept, *b*\\ :sub:`1` is the coefficient associated with my sleep, and "
"*b*\\ :sub:`2` is the coefficient associated with my son’s sleep. However, "
"although the number of coefficients that need to be estimated has changed, "
"the basic idea of how the estimation works is unchanged: our estimated "
"coefficients :math:`\\hat{b}_0`, :math:`\\hat{b}_1` and :math:`\\hat{b}_2` "
"are those that minimise the sum squared residuals."
msgstr ""
"முன்பு போலவே, ε \\: துணை: `நான்` ஐ -வது அவதானிப்புடன் தொடர்புடையது,: கணிதம்: `{\\ "
"epsilon} _i = {Y} _i - \\ hat {Y} _ i`. இந்த மாதிரியில், இப்போது நம்மிடம் மூன்று "
"குணகங்கள் மதிப்பிடப்பட வேண்டும்: *பி *\\: துணை: `0` இடைமறிப்பு, *பி *\\: துணை:` 1` "
"என்பது என் தூக்கத்துடன் தொடர்புடைய குணகம், மற்றும் *பி *\\: துணை: `2` என்பது எனது மகனின்"
" தூக்கத்துடன் தொடர்புடைய குணகம். இருப்பினும், மதிப்பிட வேண்டிய குணகங்களின் எண்ணிக்கை "
"மாறிவிட்டாலும், மதிப்பீடு எவ்வாறு செயல்படுகிறது என்பதற்கான அடிப்படை சிந்தனை மாறாது: "
"எங்கள் மதிப்பிடப்பட்ட குணகங்கள்: கணிதம்: `\\ தொப்பி {b} _0`,: கணிதம்:` \\ தொப்பி {b} _1`"
" மற்றும்: கணிதம்: `\\ தொப்பி {b} _2` என்பது சதுர சதுர எச்சங்களைக் குறைக்கும்."

#: ../../Ch12/Ch12_Regression_05.rst:42
msgid "Doing it in jamovi"
msgstr "சாமோவியில் அதைச் செய்கிறார்"

#: ../../Ch12/Ch12_Regression_05.rst:44
msgid ""
"Multiple regression in jamovi is no different to simple regression. All we "
"have to do is add additional variables to the ``Covariates`` box in jamovi. "
"For example, if we want to use both ``dani.sleep`` and ``baby.sleep`` as "
"predictors in our attempt to explain why I’m so grumpy, then move ``baby."
"sleep`` across into the ``Covariates`` box alongside ``dani.sleep``. By "
"default, jamovi assumes that the model should include an intercept. The "
"coefficients we get this time are:"
msgstr ""
"சமோவியில் பல பின்னடைவு எளிய பின்னடைவுக்கு வேறுபட்டதல்ல. சமோவியில் உள்ள `` "
"கோவாரியட்டுகள்` பெட்டியில் கூடுதல் மாறிகள் சேர்க்க வேண்டும். எடுத்துக்காட்டாக, நான் ஏன் "
"இவ்வளவு எரிச்சலூட்டுகிறேன் என்பதை விளக்கும் முயற்சியில் முன்னறிவிப்பாளர்களாக `` டானி.லீப்` "
"மற்றும் `` பேபி.லீப்` இரண்டையும் பயன்படுத்த விரும்பினால், `` பேபி.லீப்`` ஐ முழுவதும் "
"நகர்த்தவும் `` டானி.லீப்` உடன் `` கோவாரியட்டுகள்` பெட்டியில். இயல்பாக, மாதிரியில் ஒரு "
"இடைமறிப்பு இருக்க வேண்டும் என்று சமோவி கருதுகிறார். இந்த நேரத்தில் நமக்கு கிடைக்கும் "
"குணகங்கள்:"

#: ../../Ch12/Ch12_Regression_05.rst:52
msgid ""
"Model coefficients for the linear model predicting ``dani.grump`` using "
"``baby.sleep`` and ``dani.sleep`` (from the |parenthood|_ data set)."
msgstr ""
"`` பேபி.லீப்`` மற்றும் `` டானி.லீப்`` (| பெற்றோர்ஊட் | _ தரவு தொகுப்பு) ஆகியவற்றைப் "
"பயன்படுத்தி `` டானி."

#: ../../Ch12/Ch12_Regression_05.rst:57
msgid "Predictor"
msgstr "முன்கணிப்பு"

#: ../../Ch12/Ch12_Regression_05.rst:57
msgid "Estimate"
msgstr "மதிப்பீடு"

#: ../../Ch12/Ch12_Regression_05.rst:59
msgid "Intercept"
msgstr "இடைமறிப்பு"

#: ../../Ch12/Ch12_Regression_05.rst:59
msgid "125.966"
msgstr "125.966"

#: ../../Ch12/Ch12_Regression_05.rst:61
msgid "``dani.sleep``"
msgstr "``dani.sleep``"

#: ../../Ch12/Ch12_Regression_05.rst:61
msgid "-8.950"
msgstr "-8.950"

#: ../../Ch12/Ch12_Regression_05.rst:63
msgid "``baby.sleep``"
msgstr "``baby.sleep``"

#: ../../Ch12/Ch12_Regression_05.rst:63
msgid "0.011"
msgstr "0.011"

#: ../../Ch12/Ch12_Regression_05.rst:66
msgid ""
"The coefficient associated with ``dani.sleep`` is quite large, suggesting "
"that every hour of sleep I lose makes me a lot grumpier. However, the "
"coefficient for ``baby.sleep`` is very small, suggesting that it doesn’t "
"really matter how much sleep my son gets. What matters as far as my "
"grumpiness goes is how much sleep *I* get. To get a sense of what this "
"multiple regression model looks like, :numref:`fig-scatter3d_1` shows a 3D "
"plot that plots all three variables, along with the regression model itself."
msgstr ""
"`` டானி.லீப்`` உடன் தொடர்புடைய குணகம் மிகப் பெரியது, இது நான் இழக்கும் ஒவ்வொரு மணிநேர "
"தூக்கமும் எனக்கு மிகவும் எரிச்சலூட்டுகிறது என்று கூறுகிறது. இருப்பினும், `` குழந்தை.லீப்`"
" `க்கான குணகம் மிகச் சிறியது, இது என் மகனுக்கு எவ்வளவு தூக்கம் பெறுகிறது என்பது "
"முக்கியமல்ல என்று கூறுகிறது. என் எரிச்சலைப் பொறுத்தவரை முக்கியமானது என்னவென்றால், எவ்வளவு"
" தூக்கம் * நான் * பெறுகிறேன். இந்த பல பின்னடைவு மாதிரி எப்படி இருக்கும் என்பதைப் "
"புரிந்துகொள்ள, NUMREF: `Fig-scatter3d_1` ஒரு 3D சதித்திட்டத்தைக் காட்டுகிறது, இது "
"மூன்று மாறிகள் பின்னடைவு மாதிரியுடன்."

#: ../../Ch12/Ch12_Regression_05.rst:77
msgid "3D visualisation of a multiple regression model"
msgstr "பல பின்னடைவு மாதிரியின் 3D காட்சிப்படுத்தல்"

#: ../../Ch12/Ch12_Regression_05.rst:81
msgid ""
"3D visualisation of a multiple regression model: There are two predictors in "
"the model, ``dani.sleep`` and ``baby.sleep`` and the outcome variable is "
"``dani.grump``. Together, these three variables form a 3D space. Each "
"observation (dot) is a point in this space. In much the same way that a "
"simple linear regression model forms a line in 2D space, this multiple "
"regression model forms a plane in 3D space. When we estimate the regression "
"coefficients what we’re trying to do is find a plane that is as close to all "
"the blue dots as possible."
msgstr ""
"பல பின்னடைவு மாதிரியின் 3D காட்சிப்படுத்தல்: மாதிரியில் இரண்டு முன்னறிவிப்பாளர்கள் உள்ளனர்"
", `` டானி.லீப்`` மற்றும் `` பேபி. ஒன்றாக, இந்த மூன்று மாறிகள் ஒரு 3D இடத்தை "
"உருவாக்குகின்றன. ஒவ்வொரு அவதானிப்பும் (புள்ளி) இந்த இடத்தில் ஒரு புள்ளி. ஒரு எளிய "
"நேரியல் பின்னடைவு மாதிரி 2 டி இடத்தில் ஒரு கோட்டை உருவாக்கும் அதே வழியில், இந்த பல "
"பின்னடைவு மாதிரி 3D இடத்தில் ஒரு விமானத்தை உருவாக்குகிறது. பின்னடைவு குணகங்களை நாங்கள்"
" மதிப்பிடும்போது, நாங்கள் என்ன செய்ய முயற்சிக்கிறோம் என்பது முடிந்தவரை எல்லா நீல "
"புள்ளிகளுக்கும் நெருக்கமான விமானத்தைக் கண்டுபிடிப்பதாகும்."

#: ../../Ch12/Ch12_Regression_05.rst:93
msgid "Formula for the general case"
msgstr "பொது வழக்குக்கான தேற்றம்"

#: ../../Ch12/Ch12_Regression_05.rst:95
msgid ""
"The equation that I gave above shows you what a multiple regression model "
"looks like when you include two predictors. Not surprisingly, then, if you "
"want more than two predictors all you have to do is add more *X* terms and "
"more *b* coefficients. In other words, if you have *K* predictor variables "
"in the model then the regression equation looks like this:"
msgstr ""
"நான் மேலே கொடுத்த சமன்பாடு, நீங்கள் இரண்டு முன்னறிவிப்பாளர்களைச் சேர்க்கும்போது பல பின்னடைவு"
" மாதிரி எப்படி இருக்கும் என்பதைக் காட்டுகிறது. ஆச்சரியப்படுவதற்கில்லை, நீங்கள் இரண்டு "
"முன்னறிவிப்பாளர்களுக்கு மேல் விரும்பினால், நீங்கள் செய்ய வேண்டியது எல்லாம் அதிக * ஃச் * "
"விதிமுறைகளையும், மேலும் * பி * குணகங்களையும் சேர்ப்பதுதான். வேறு வார்த்தைகளில் "
"கூறுவதானால், மாதிரியில் உங்களிடம் * K * முன்கணிப்பு மாறிகள் இருந்தால், பின்னடைவு "
"சமன்பாடு இப்படி தெரிகிறது:"

#: ../../Ch12/Ch12_Regression_05.rst:102
msgid ""
"Y_i = b_0 + \\left( \\sum_{k=1}^K b_{k} X_{ik} \\right) + \\epsilon_i\n"
"\n"
msgstr ""
"Y_i = b_0 + \\left( \\sum_{k=1}^K b_{k} X_{ik} \\right) + \\epsilon_i\n"
"\n"

#: ../../Ch12/Ch12_Regression_06.rst:4
msgid "Quantifying the fit of the regression model"
msgstr "பின்னடைவு மாதிரியின் பொருத்தத்தை அளவிடுதல்"

#: ../../Ch12/Ch12_Regression_06.rst:6
msgid ""
"So we now know how to estimate the coefficients of a linear regression "
"model. The problem is, we don’t yet know if this regression model is any "
"good. For example, the ``regression.1`` model *claims* that every hour of "
"sleep will improve my mood by quite a lot, but it might just be rubbish. "
"Remember, the regression model only produces a prediction *Ŷ*\\ :sub:`i` "
"about what my mood is like, but my actual mood is *Y*\\ :sub:`i`. If these "
"two are very close, then the regression model has done a good job. If they "
"are very different, then it has done a bad job."
msgstr ""
"எனவே ஒரு நேரியல் பின்னடைவு மாதிரியின் குணகங்களை எவ்வாறு மதிப்பிடுவது என்பது இப்போது "
"எங்களுக்குத் தெரியும். சிக்கல் என்னவென்றால், இந்த பின்னடைவு மாதிரி ஏதேனும் நல்லதா என்பதை "
"நாங்கள் இன்னும் தெரியவில்லை. எடுத்துக்காட்டாக, `` பின்னடைவு 1`` மாதிரி * கூறுகிறது * "
"ஒவ்வொரு மணிநேர தூக்கமும் என் மனநிலையை நிறைய மேம்படுத்தும், ஆனால் அது குப்பையாக "
"இருக்கலாம். நினைவில் கொள்ளுங்கள், பின்னடைவு மாதிரி ஒரு கணிப்பை மட்டுமே உருவாக்குகிறது *"
"ŷ *\\: துணை: `எனது மனநிலை எப்படி இருக்கிறது என்பதைப் பற்றி நான்` நான்`, ஆனால் எனது "
"உண்மையான மனநிலை *y *\\: துணை:` நான்`. இந்த இரண்டு மிக நெருக்கமாக இருந்தால், பின்னடைவு"
" மாதிரி ஒரு நல்ல வேலையைச் செய்துள்ளது. அவை மிகவும் வித்தியாசமாக இருந்தால், அது ஒரு "
"மோசமான வேலையைச் செய்துள்ளது."

#: ../../Ch12/Ch12_Regression_06.rst:16
msgid "The *R*\\² (R-squared) value"
msgstr "*R *\\ ² (r-squared) மதிப்பு"

#: ../../Ch12/Ch12_Regression_06.rst:18
msgid ""
"Once again, let’s wrap a little bit of mathematics around this. Firstly, "
"we’ve got the sum of the squared residuals"
msgstr ""
"மீண்டும், இதைச் சுற்றி சிறிது கணிதத்தை மடிக்கலாம். முதலாவதாக, சதுர எச்சங்களின் "
"கூட்டுத்தொகையை நாங்கள் பெற்றுள்ளோம்"

#: ../../Ch12/Ch12_Regression_06.rst:21
msgid ""
"\\mbox{SS}_{res} = \\sum_i (Y_i - \\hat{Y}_i)^2\n"
"\n"
msgstr ""
"\\mbox{SS}_{res} = \\sum_i (Y_i - \\hat{Y}_i)^2\n"
"\n"

#: ../../Ch12/Ch12_Regression_06.rst:23
msgid ""
"which we would hope to be pretty small. Specifically, what we’d like is for "
"it to be very small in comparison to the total variability in the outcome "
"variable"
msgstr ""
"இது மிகவும் சிறியதாக இருக்கும் என்று நம்புகிறோம். குறிப்பாக, விளைவு மாறியின் மொத்த "
"மாறுபாட்டுடன் ஒப்பிடுகையில், அது மிகச் சிறியதாக இருக்க வேண்டும் என்பதே நாங்கள் "
"விரும்புவது"

#: ../../Ch12/Ch12_Regression_06.rst:27
msgid ""
"\\mbox{SS}_{tot} = \\sum_i (Y_i - \\bar{Y})^2\n"
"\n"
msgstr ""
"\\mbox{SS}_{tot} = \\sum_i (Y_i - \\bar{Y})^2\n"
"\n"

#: ../../Ch12/Ch12_Regression_06.rst:29
msgid ""
"While we’re here, let’s calculate these values ourselves, not by hand "
"though. Let’s use jamovi instead. Open up the |parenthood|_ data set in so "
"that we can work in it. The first thing to do is calculate the *Ŷ* values, "
"and for the simple model that uses only a single predictor we would do the "
"following:"
msgstr ""
"நாங்கள் இங்கே இருக்கும்போது, இந்த மதிப்புகளை நாமே கணக்கிடுவோம், கையால் அல்ல. அதற்கு பதிலா"
"க சாமோவியைப் பயன்படுத்துவோம். | பெற்றோர்ஊட் | _ தரவுகளைத் திறக்கவும், இதனால் நாங்கள் அதில் "
"வேலை செய்ய முடியும். முதலில் செய்ய வேண்டியது * ŷ * மதிப்புகளைக் கணக்கிடுவதாகும், மேலும்"
" ஒரு முன்கணிப்பாளரை மட்டுமே பயன்படுத்தும் எளிய மாதிரிக்கு நாம் பின்வருவனவற்றை செய்வோம்:"

#: ../../Ch12/Ch12_Regression_06.rst:34
msgid ""
"Go to an empty column (at the end of the data set) and double click on the "
"column header, choose ``New computed variable`` and enter ``Y_pred`` in the "
"first line and the formula ``125.97 + (-8.94 * dani.sleep)`` in the line "
"starting with ``=`` (next to the *f*\\ :sub:`x`)."
msgstr ""
"வெற்று நெடுவரிசைக்குச் சென்று (தரவு தொகுப்பின் முடிவில்) மற்றும் நெடுவரிசை தலைப்பில் "
"இருமுறை சொடுக்கு செய்து, `` புதிய கணக்கிடப்பட்ட மாறி`` ஐத் தேர்ந்தெடுத்து முதல் வரியில் "
"`` y_pred`` மற்றும் `` 125.97 + சூத்திரத்தை உள்ளிடவும் 8.94 *dani.sleep) `` `` = ``"
" ( *f *\\: துணை: `x`) உடன் தொடங்கும் வரியில்."

#: ../../Ch12/Ch12_Regression_06.rst:39
msgid ""
"Okay, now that we’ve got a variable which stores the regression model "
"predictions for how grumpy I will be on any given day, let’s calculate our "
"sum of squared residuals. We would do that using the following formula:"
msgstr ""
"சரி, இப்போது எந்த நாளிலும் நான் எவ்வளவு எரிச்சலாக இருப்பேன் என்பதற்கான பின்னடைவு மாதிரி "
"கணிப்புகளை சேமிக்கும் ஒரு மாறியை நாங்கள் பெற்றுள்ளோம், எங்கள் சதுர எச்சங்களின் தொகையை "
"கணக்கிடுவோம். பின்வரும் சூத்திரத்தைப் பயன்படுத்தி நாங்கள் அதைச் செய்வோம்:"

#: ../../Ch12/Ch12_Regression_06.rst:44
msgid ""
"Calculate the squared residuals by creating a new column called ``sq_resid`` "
"using the formula ``(dani.grump - Y_pred) ^ 2``. The values in this column "
"are later summed up to obtain SS\\ :sub:`res`."
msgstr ""
"`` (Dani.grump - y_pred) ^ 2`` என்ற சூத்திரத்தைப் பயன்படுத்தி `` sq_resid`` என்ற "
"புதிய நெடுவரிசையை உருவாக்குவதன் மூலம் ச்கொயர் எச்சங்களைக் கணக்கிடுங்கள். இந்த "
"நெடுவரிசையில் உள்ள மதிப்புகள் பின்னர் SS \\: துணை: `res` ஐப் பெற சுருக்கப்பட்டுள்ளன."

#: ../../Ch12/Ch12_Regression_06.rst:48
msgid ""
"Calculate the squared deviation from the mean by creating yet another column "
"called ``sq_total`` using the formula ``(dani.grump - VMEAN(dani.grump)) ^ "
"2``. The values in this column are later summed up to obtain SS\\ :sub:`tot`."
msgstr ""
"`` (Dani.grump - vmean (dani.grump)) ^ 2`` என்ற சூத்திரத்தைப் பயன்படுத்தி `` "
"sq_total` என்ற மற்றொரு நெடுவரிசையை உருவாக்குவதன் மூலம் சராசரியிலிருந்து சதுர "
"விலகலைக் கணக்கிடுங்கள். இந்த நெடுவரிசையில் உள்ள மதிப்புகள் பின்னர் SS \\: துணை: `TOT` ஐப்"
" பெற சுருக்கப்பட்டுள்ளன."

#: ../../Ch12/Ch12_Regression_06.rst:53
msgid ""
"To calculate the sum of these values, click ``Descriptives`` → ``Descriptive "
"Statistics`` and move ``sq_resid`` and ``sq_total`` to the ``Variables`` "
"box. You’ll then need to select ``Sum`` from the ``Statistics`` drop-down "
"menu below. The sum of ``sq_resid`` has a value of **1838.722**. This is a "
"big number, however, that doesn’t mean very much. The sum of ``sq_total`` "
"has a value of **9998.590**. Well, it’s a much (about five times) bigger "
"number than the last one, so this does suggest that our regression model was "
"making good predictions (that is, it has greatly reduced the residual error "
"compared to the model that uses the mean as a single predictor). But it’s "
"not very interpretable."
msgstr ""
"இந்த மதிப்புகளின் கூட்டுத்தொகையை கணக்கிட, `` விளக்கங்கள்`` → `` விளக்க புள்ளிவிவரங்கள்`` "
"என்பதைக் சொடுக்கு செய்து `` sq_resid`` மற்றும் `` sq_total`` ஆகியவற்றை `` மாறிகள்` "
"பெட்டியில் நகர்த்தவும். கீழே உள்ள `` புள்ளிவிவரங்கள்` கீழ்தோன்றும் மெனுவிலிருந்து `` தொகை`` "
"தேர்ந்தெடுக்க வேண்டும். `` Sq_resid`` இன் தொகை ** 1838.722 ** மதிப்பைக் கொண்டுள்ளது. "
"இது ஒரு பெரிய எண், இருப்பினும், இது மிகவும் அர்த்தமல்ல. `` Sq_total`` இன் தொகை ** "
"9998.590 ** மதிப்பைக் கொண்டுள்ளது. சரி, இது கடைசியாக இருந்ததை விட மிகவும் (சுமார் "
"ஐந்து மடங்கு) பெரிய எண்ணிக்கையாகும், எனவே இது எங்கள் பின்னடைவு மாதிரி நல்ல கணிப்புகளைச் "
"செய்து கொண்டிருந்தது என்று இது அறிவுறுத்துகிறது (அதாவது, சராசரியைப் பயன்படுத்தும் "
"மாதிரியுடன் ஒப்பிடும்போது மீதமுள்ள பிழையை இது வெகுவாகக் குறைத்துள்ளது ஒற்றை முன்கணிப்பு)"
". ஆனால் இது மிகவும் விளக்கமளிக்கவில்லை."

#: ../../Ch12/Ch12_Regression_06.rst:64
msgid ""
"To can fix this, we’d like to convert these two fairly meaningless numbers "
"into one number. A nice, interpretable number, which for no particular "
"reason we’ll call *R*\\². What we would like is for the value of *R*\\² to "
"be equal to 1 if the regression model makes no errors in predicting the "
"data. In other words, if it turns out that the residual errors are zero. "
"That is, if SS\\ :sub:`res` = 0 then we expect *R*\\² = 1. Similarly, if the "
"model is completely useless, we would like *R*\\² to be equal to 0. What do "
"I mean by “useless”? Tempting as it is to demand that the regression model "
"move out of the house, cut its hair and get a real job, I’m probably going "
"to have to pick a more practical definition. In this case, all I mean is "
"that the residual sum of squares is no smaller than the total sum of "
"squares, SS\\ :sub:`res` = SS\\ :sub:`tot`. Wait, why don’t we do exactly "
"that? The formula that provides us with our *R*\\² value is pretty simple to "
"write down, and equally simple to calculate by hand:\\ [#]_"
msgstr ""
"இதை சரிசெய்ய, இந்த இரண்டு மிகவும் அர்த்தமற்ற எண்களை ஒரு எண்ணாக மாற்ற விரும்புகிறோம். ஒரு "
"நல்ல, விளக்கக்கூடிய எண், எந்தவொரு குறிப்பிட்ட காரணத்திற்காகவும் நாங்கள் *r *² என்று "
"அழைப்போம். தரவைக் கணிப்பதில் பின்னடைவு மாதிரி எந்த பிழையும் செய்யாவிட்டால், *r *\\ of இன்"
" மதிப்பு 1 க்கு சமமாக இருக்க வேண்டும் என்பதே நாம் விரும்புவது. வேறு வார்த்தைகளில் "
"கூறுவதானால், மீதமுள்ள பிழைகள் பூச்சியமாக இருக்கும் என்று மாறிவிட்டால். அதாவது, ss \\: "
"sub: `res` = 0 என்றால் *r *\\ ² = 1 என்று எதிர்பார்க்கிறோம். இதேபோல், மாதிரி முற்றிலும்"
" பயனற்றதாக இருந்தால், *r *\\ the 0 க்கு சமமாக இருக்க விரும்புகிறோம். என்ன செய்ய வேண்டும்"
" நான் “பயனற்றவர்” என்பதன் அர்த்தமா? பின்னடைவு மாதிரி வீட்டை விட்டு வெளியேற வேண்டும், அதன் "
"தலைமுடியை வெட்டி, உண்மையான வேலையைப் பெற வேண்டும் என்று கோருவதால், நான் இன்னும் நடைமுறை "
"வரையறையைத் தேர்வு செய்ய வேண்டியிருக்கும். இந்த விசயத்தில், நான் சொல்வது என்னவென்றால், "
"சதுரங்களின் எஞ்சிய தொகை மொத்த சதுரங்களின் தொகையை விட சிறியதல்ல, SS \\: sub: `res` = "
"ss \\: sub:` tot`. காத்திருங்கள், நாம் ஏன் அதைச் சரியாகச் செய்யக்கூடாது? எங்கள் *r *\\ "
"² மதிப்பை எங்களுக்கு வழங்கும் தேற்றம் எழுதுவது மிகவும் எளிதானது, மேலும் கையால் கணக்கிட "
"சமமாக எளிமையானது: \\ [#] _ _"

#: ../../Ch12/Ch12_Regression_06.rst:78
msgid "*R*\\² = 1 - (SS\\ :sub:`res` / SS\\ :sub:`tot`)"
msgstr "*R*\\² = 1 - (SS\\ :sub:`res` / SS\\ :sub:`tot`)"

#: ../../Ch12/Ch12_Regression_06.rst:79
msgid "*R*\\² = 1 - (1838.722 / 9998.590)"
msgstr "*R*\\² = 1 - (1838.722 / 9998.590)"

#: ../../Ch12/Ch12_Regression_06.rst:80
msgid "*R*\\² = 1 - 0.184"
msgstr "*R*\\² = 1 - 0.184"

#: ../../Ch12/Ch12_Regression_06.rst:82
msgid ""
"This gives a value for *R*\\² of **0.816**. The *R*\\² value, sometimes "
"called the **coefficient of determination**\\ [#]_ has a simple "
"interpretation: it is the *proportion* of the variance in the outcome "
"variable that can be accounted for by the predictor. So, in this case the "
"fact that we have obtained *R*\\² = 0.816 means that the predictor (``dani."
"sleep``) explains 81.6\\% of the variance in the outcome (``dani.grump``).\\ "
"[#]_"
msgstr ""
"இது ** 0.816 ** இன்*r*\\ க்கு க்கு ஒரு மதிப்பை அளிக்கிறது. *R*\\ ² மதிப்பு, சில "
"நேரங்களில் ** தீர்மானத்தின் குணகம் ** \\ [#] _ ஒரு எளிய விளக்கத்தைக் கொண்டுள்ளது: இது "
"விளைவு மாறியில் உள்ள மாறுபாட்டின்*விகிதம்*ஆகும், இது முன்கணிப்பாளரால் கணக்கிடப்படலாம். "
"எனவே, இந்த விசயத்தில் நாம் *r *\\ ² = 0.816 ஐப் பெற்றுள்ளோம் என்பதன் பொருள், முன்கணிப்பு "
"(`` டானி.லீப்``) 81.6 \\% முடிவில் மாறுபாட்டை விளக்குகிறது (`` dani.grump``) . \\ "
"[#] _"

#: ../../Ch12/Ch12_Regression_06.rst:89
msgid ""
"Naturally, you don’t actually need to do all these calculations yourself if "
"you want to obtain the *R*\\² value for your regression model. As we’ll see "
"later on in :ref:`Running the hypothesis tests in jamovi "
"<coefficients_in_jamovi>`, all you need to do is specify this as an option "
"in jamovi. However, let’s put that to one side for the moment. There’s "
"another property of *R*\\² that I want to point out."
msgstr ""
"இயற்கையாகவே, உங்கள் பின்னடைவு மாதிரிக்கான *r *\\ ² மதிப்பைப் பெற விரும்பினால் இந்த "
"கணக்கீடுகள் அனைத்தையும் நீங்களே செய்ய வேண்டிய அவசியமில்லை. நாம் பின்னர் பார்ப்பது போல்: ref: "
"`சமோவியில் உள்ள கருதுகோள் சோதனைகளை இயக்குதல் <ceoficients_in_jamovi>`, நீங்கள் செய்ய "
"வேண்டியது இதை சாமோவியில் ஒரு விருப்பமாகக் குறிப்பிடுவதுதான். இருப்பினும், இப்போதைக்கு "
"அதை ஒரு பக்கத்திற்கு வைப்போம். நான் சுட்டிக்காட்ட விரும்பும் *r *² of இன் மற்றொரு சொத்து "
"உள்ளது."

#: ../../Ch12/Ch12_Regression_06.rst:97
msgid "The relationship between regression and correlation"
msgstr "பின்னடைவுக்கும் தொடர்புக்கும் இடையிலான உறவு"

#: ../../Ch12/Ch12_Regression_06.rst:99
msgid ""
"At this point we can revisit my earlier claim that regression, in this very "
"simple form that I’ve discussed so far, is basically the same thing as a "
"correlation. Previously, we used the symbol *r* to denote a Pearson "
"correlation. Might there be some relationship between the value of the "
"correlation coefficient *r* and the *R*\\² value from linear regression? Of "
"course there is: the squared correlation *R*\\² is identical to the *R*\\² "
"value for a linear regression with only a single predictor. In other words, "
"running a Pearson correlation is more or less equivalent to running a linear "
"regression model that uses only one predictor variable."
msgstr ""
"இந்த கட்டத்தில், நான் இதுவரை விவாதித்த இந்த மிக எளிமையான வடிவத்தில் பின்னடைவு என்ற எனது "
"முந்தைய கூற்றை நாம் மறுபரிசீலனை செய்யலாம், அடிப்படையில் ஒரு தொடர்பு போன்றது. முன்னதாக, "
"ஒரு பியர்சன் தொடர்பைக் குறிக்க * r * குறியீட்டைப் பயன்படுத்தினோம். தொடர்பு குணகத்தின் "
"மதிப்பு *r *மற்றும் நேரியல் பின்னடைவிலிருந்து *r *\\ ² மதிப்பு ஆகியவற்றுக்கு இடையே சி"
"ல உறவுகள் இருக்கக்கூடும்? நிச்சயமாக உள்ளது: சதுர தொடர்பு *r *² ² ஒரு கணிப்பாளருடன் ஒரு"
" நேரியல் பின்னடைவுக்கான *r *\\ ² மதிப்புக்கு ஒத்ததாகும். வேறு வார்த்தைகளில் கூறுவதானால்"
", ஒரு பியர்சன் தொடர்பை இயக்குவது ஒரு நேரியல் பின்னடைவு மாதிரியை இயக்குவதற்கு "
"அதிகமாகவோ அல்லது குறைவாகவோ சமம், இது ஒரு முன்கணிப்பு மாறியை மட்டுமே "
"பயன்படுத்துகிறது."

#: ../../Ch12/Ch12_Regression_06.rst:110
msgid "The adjusted *R*\\² (R-squared) value"
msgstr "சரிசெய்யப்பட்ட *r *\\ ² (r- ச்கொயர்) மதிப்பு"

#: ../../Ch12/Ch12_Regression_06.rst:112
msgid ""
"One final thing to point out before moving on. It’s quite common for people "
"to report a slightly different measure of model performance, known as "
"“adjusted *R*\\²”. The motivation behind calculating the adjusted *R*\\² "
"value is the observation that adding more predictors into the model will "
"*always* cause the *R*\\² value to increase (or at least not decrease)."
msgstr ""
"நகரும் முன் சுட்டிக்காட்ட வேண்டிய ஒரு இறுதி சேதி. “சரிசெய்யப்பட்ட *r *\\ ²” என "
"அழைக்கப்படும் மாதிரி செயல்திறனின் சற்று மாறுபட்ட அளவைப் புகாரளிப்பது மிகவும் பொதுவானது"
". சரிசெய்யப்பட்ட *r *\\ ² மதிப்பைக் கணக்கிடுவதன் பின்னணியில் உள்ள உந்துதல் என்பது "
"மாதிரியில் அதிக முன்னறிவிப்பாளர்களைச் சேர்ப்பது *எப்போதும் * *r *² ² மதிப்பை அதிகரிக்க "
"(அல்லது குறைந்தது குறையாது) ஏற்படுத்தும் என்பதைக் கவனிப்பதாகும்."

#: ../../Ch12/Ch12_Regression_06.rst:119
msgid ""
"The adjusted *R*\\² value introduces a slight change to the calculation, as "
"follows. For a regression model with *K* predictors, fit to a data set "
"containing *N* observations, the adjusted *R*\\² is:"
msgstr ""
"சரிசெய்யப்பட்ட *r *\\ ² மதிப்பு கணக்கீட்டில் ஒரு சிறிய மாற்றத்தை பின்வருமாறு "
"அறிமுகப்படுத்துகிறது. *K *முன்னறிவிப்பாளர்களைக் கொண்ட ஒரு பின்னடைவு மாதிரிக்கு, *n "
"*அவதானிப்புகள் கொண்ட தரவுத் தொகுப்பிற்கு பொருந்தும், சரிசெய்யப்பட்ட *r *\\ ² is ஆகும்:"

#: ../../Ch12/Ch12_Regression_06.rst:124
msgid ""
"\\mbox{adj. } R^2 = 1 - \\left(\\frac{\\mbox{SS}_{res}}{\\mbox{SS}_{tot}} "
"\\times \\frac{N - 1}{N - K - 1} \\right)\n"
"\n"
msgstr ""
"\\mbox{adj. } R^2 = 1 - \\left(\\frac{\\mbox{SS}_{res}}{\\mbox{SS}_{tot}} "
"\\times \\frac{N - 1}{N - K - 1} \\right)\n"
"\n"

#: ../../Ch12/Ch12_Regression_06.rst:126
msgid ""
"This adjustment is an attempt to take the degrees of freedom into account. "
"The big advantage of the adjusted *R*\\² value is that when you add more "
"predictors to the model, the adjusted *R*\\² value will only increase if the "
"new variables improve the model performance more than you’d expect by "
"chance. The big disadvantage is that the adjusted *R*\\² value *can’t* be "
"interpreted in the elegant way that *R*\\² can. *R*\\² has a simple "
"interpretation as the proportion of variance in the outcome variable that is "
"explained by the regression model. To my knowledge, no equivalent "
"interpretation exists for adjusted *R*\\²."
msgstr ""
"இந்த சரிசெய்தல் சுதந்திரத்தின் அளவுகளை கணக்கில் எடுத்துக்கொள்ளும் முயற்சியாகும். சரிசெய்யப்பட்"
"ட *r *\\ ² மதிப்பின் பெரிய நன்மை என்னவென்றால், நீங்கள் மாதிரியில் அதிக "
"முன்னறிவிப்பாளர்களைச் சேர்க்கும்போது, புதிய மாறிகள் மாதிரி செயல்திறனை மேம்படுத்தினால் "
"மட்டுமே சரிசெய்யப்பட்ட *r *² ² மதிப்பு அதிகரிக்கும். . பெரிய குறைபாடு என்னவென்றால், "
"சரிசெய்யப்பட்ட *r *² ² மதிப்பு * *r *² gean முடிந்த நேர்த்தியான வழியில் விளக்க "
"முடியாது. *R*\\ ² பின்னடைவு மாதிரியால் விளக்கப்பட்ட விளைவு மாறியில் மாறுபாட்டின் "
"விகிதமாக ஒரு எளிய விளக்கத்தைக் கொண்டுள்ளது. எனது அறிவைப் பொறுத்தவரை, சரிசெய்யப்பட்ட *r "
"*² பெறுநர் க்கு சமமான விளக்கம் எதுவும் இல்லை."

#: ../../Ch12/Ch12_Regression_06.rst:137
msgid ""
"An obvious question then is whether you should report *R*\\² or adjusted "
"*R*\\². This is probably a matter of personal preference. If you care more "
"about interpretability, then *R*\\² is better. If you care more about "
"correcting for bias, then adjusted *R*\\² is probably better. Speaking just "
"for myself, I prefer *R*\\². My feeling is that it’s more important to be "
"able to interpret your measure of model performance. Besides, as we’ll see "
"in section :doc:`Ch12_Regression_07`, if you’re worried that the improvement "
"in *R*\\² that you get by adding a predictor is just due to chance and not "
"because it’s a better model, well we’ve got hypothesis tests for that."
msgstr ""
"ஒரு வெளிப்படையான கேள்வி என்னவென்றால், நீங்கள் *r *² ² அல்லது சரிசெய்யப்பட வேண்டுமா என்பது "
"*r *\\. இது அநேகமாக தனிப்பட்ட விருப்பத்தின் சேதி. விளக்கமளிக்கும் தன்மையைப் பற்றி நீங்கள் "
"அதிகம் அக்கறை கொண்டிருந்தால், *r *\\ ² சிறந்தது. சார்புகளை சரிசெய்வதில் நீங்கள் அதிகம் "
"அக்கறை கொண்டிருந்தால், சரிசெய்யப்பட்ட *r *² ² அநேகமாக சிறந்தது. எனக்காக மட்டுமே "
"பேசும்போது, நான் *r *\\ ² ஐ விரும்புகிறேன். உங்கள் மாதிரி செயல்திறனின் அளவை விளக்குவது"
" மிகவும் முக்கியமானது என்பது எனது உணர்வு. தவிர, பிரிவில் நாம் பார்ப்பது போல்: DOC: "
"`CH12_REGRESSION_07`, ஒரு முன்கணிப்பாளரைச் சேர்ப்பதன் மூலம் நீங்கள் பெறும் *r *² இருந்து "
"இல் முன்னேற்றம் என்பது வாய்ப்பு காரணமாக மட்டுமே என்று நீங்கள் கவலைப்படுகிறீர்கள் என்றால், அது "
"ஒரு சிறந்த மாதிரி என்பதால் அல்ல, அதற்கான கருதுகோள் சோதனைகள் கிடைத்துள்ளன."

#: ../../Ch12/Ch12_Regression_06.rst:150
msgid ""
"If you don't want to do these calculations by hand, just create another "
"computed variable called, e.g., ``R2``, and containing the formula ``1 - "
"VSUM(sq_resid) / VSUM(sq_total)``. But then you have a whole column "
"containing *R*\\²."
msgstr ""
"இந்த கணக்கீடுகளை நீங்கள் கையால் செய்ய விரும்பவில்லை என்றால், எ.கா., `` r2`` என அழைக்கப்படும்"
" மற்றொரு கணக்கிடப்பட்ட மாறியை உருவாக்கவும், `` 1 - VSUM (SQ_RESID) / VSUM "
"(SQ_TOTAL) `` `` ``. ஆனால் நீங்கள் *r *\\ with ஐக் கொண்ட முழு நெடுவரிசையையும் "
"வைத்திருக்கிறீர்கள்."

#: ../../Ch12/Ch12_Regression_06.rst:156
msgid ""
"And by “sometimes” I mean “almost never”. In practice everyone just calls it "
"“*R*-squared”."
msgstr ""
"“சில நேரங்களில்” என்பதன் மூலம் நான் “கிட்டத்தட்ட ஒருபோதும் இல்லை” என்று பொருள். நடைமுறையில்"
" எல்லோரும் இதை “*r*-squared” என்று அழைக்கிறார்கள்."

#: ../../Ch12/Ch12_Regression_06.rst:160
msgid ""
"If you made a mistake or could not follow the explanations, you can simply "
"download and open the |parenthood_r2|_ data set."
msgstr ""
"நீங்கள் தவறு செய்தால் அல்லது விளக்கங்களைப் பின்பற்ற முடியாவிட்டால், நீங்கள் வெறுமனே | "
"பெற்றோர்_ஆர் 2 | _ தரவு தொகுப்பு பதிவிறக்கம் செய்து திறக்கலாம்."

#: ../../Ch12/Ch12_Regression_07.rst:4
msgid "Hypothesis tests for regression models"
msgstr "பின்னடைவு மாதிரிகளுக்கான கருதுகோள் சோதனைகள்"

#: ../../Ch12/Ch12_Regression_07.rst:6
msgid ""
"So far we’ve talked about what a regression model is, how the coefficients "
"of a regression model are estimated, and how we quantify the performance of "
"the model (the last of these, incidentally, is basically our measure of "
"effect size). The next thing we need to talk about is hypothesis tests. "
"There are two different (but related) kinds of hypothesis tests that we need "
"to talk about: those in which we test whether the regression model as a "
"whole is performing significantly better than a null model, and those in "
"which we test whether a particular regression coefficient is significantly "
"different from zero."
msgstr ""
"ஒரு பின்னடைவு மாதிரி என்றால் என்ன, பின்னடைவு மாதிரியின் குணகங்கள் எவ்வாறு "
"மதிப்பிடப்படுகின்றன, மற்றும் மாதிரியின் செயல்திறனை எவ்வாறு அளவிடுகிறோம் (இவற்றில் "
"கடைசியாக, தற்செயலாக, அடிப்படையில் எங்கள் விளைவு அளவின் அளவீடு) பற்றி இதுவரை பேசினோம். "
"நாம் பேச வேண்டிய அடுத்த சேதி கருதுகோள் சோதனைகள். நாம் பேச வேண்டிய இரண்டு வெவ்வேறு "
"(ஆனால் தொடர்புடைய) வகையான கருதுகோள் சோதனைகள் உள்ளன: ஒட்டுமொத்தமாக பின்னடைவு மாதிரி "
"ஒரு சுழிய மாதிரியை விட கணிசமாக சிறப்பாக செயல்படுகிறதா என்பதை நாங்கள் சோதிக்கிறோம், "
"மேலும் ஒரு குறிப்பிட்ட பின்னடைவை நாம் சோதிக்கிறோம் குணகம் பூச்சியத்திலிருந்து கணிசமாக "
"வேறுபட்டது."

#: ../../Ch12/Ch12_Regression_07.rst:17
msgid "Testing the model as a whole"
msgstr "மாதிரியை ஒட்டுமொத்தமாக சோதித்தல்"

#: ../../Ch12/Ch12_Regression_07.rst:19
msgid ""
"Okay, suppose you’ve estimated your regression model. The first hypothesis "
"test you might try is the null hypothesis that there is *no relationship* "
"between the predictors and the outcome, and the alternative hypothesis that "
"*the data are distributed in exactly the way that the regression model "
"predicts*."
msgstr ""
"சரி, உங்கள் பின்னடைவு மாதிரியை நீங்கள் மதிப்பிட்டுள்ளீர்கள் என்று வைத்துக்கொள்வோம். நீங்கள் "
"முயற்சிக்கக்கூடிய முதல் கருதுகோள் சோதனை, முன்னறிவிப்பாளர்களுக்கும் விளைவுகளுக்கும் இடையில்"
" *எந்த உறவும் இல்லை என்பது இல்லை என்ற சுழிய கருதுகோள், மற்றும் பின்னடைவு மாதிரி கணிக்கும்"
" விதத்தில் தரவு சரியாக விநியோகிக்கப்படுகிறது என்ற மாற்று கருதுகோள் *."

#: ../../Ch12/Ch12_Regression_07.rst:25
msgid ""
"Formally, our “null model” corresponds to the fairly trivial “regression” "
"model in which we include 0 predictors and only include the intercept term "
"*b*\\ :sub:`0`:"
msgstr ""
"முறையாக, எங்கள் “பூச்ய மாதிரி” மிகவும் கீழான “பின்னடைவு” மாதிரியுடன் ஒத்திருக்கிறது, "
"அதில் நாங்கள் 0 முன்னறிவிப்பாளர்களை உள்ளடக்குகிறோம், மேலும் இடைமறிப்பு கால *b *\\: துணை:"
" `0`:"

#: ../../Ch12/Ch12_Regression_07.rst:29
msgid "H\\ :sub:`0`: *Y*\\ :sub:`i` = b\\ :sub:`0` + ε\\ :sub:`i`"
msgstr "H\\ :sub:`0`: *Y*\\ :sub:`i` = b\\ :sub:`0` + ε\\ :sub:`i`"

#: ../../Ch12/Ch12_Regression_07.rst:31
msgid ""
"If our regression model has *K* predictors, the “alternative model” is "
"described using the usual formula for a multiple regression model:"
msgstr ""
"எங்கள் பின்னடைவு மாதிரியில் * K * முன்னறிவிப்பாளர்கள் இருந்தால், பல பின்னடைவு மாதிரிக்கு "
"வழக்கமான சூத்திரத்தைப் பயன்படுத்தி “மாற்று மாதிரி” விவரிக்கப்படுகிறது:"

#: ../../Ch12/Ch12_Regression_07.rst:35
msgid ""
"H\\ :sub:`1`: *Y*\\ :sub:`i` = b\\ :sub:`0` + math:`\\left( \\sum_{k=1}^K "
"b_{k} X_{ik} \\right)` + ε\\ :sub:`i`"
msgstr ""
"H\\ :sub:`1`: *Y*\\ :sub:`i` = b\\ :sub:`0` + math:`\\left( \\sum_{k=1}^K "
"b_{k} X_{ik} \\right)` + ε\\ :sub:`i`"

#: ../../Ch12/Ch12_Regression_07.rst:37
msgid ""
"How can we test these two hypotheses against each other? The trick is to "
"understand that it’s possible to divide up the total variance SS\\ :sub:"
"`tot` into the sum of the residual variance SS\\ :sub:`res` and the "
"regression model variance SS\\ :sub:`mod`. I’ll skip over the "
"technicalities, since we’ll get to that later when we look at ANOVA in "
"chapter :doc:`../Ch13/Ch13_ANOVA`. But just note that"
msgstr ""
"இந்த இரண்டு கருதுகோள்களையும் ஒருவருக்கொருவர் எவ்வாறு சோதிக்க முடியும்? தந்திரம் என்பது "
"மொத்த மாறுபாட்டை SS \\: `TOT` என்ற மீதமுள்ள மாறுபாட்டின் தொகையாக பிரிக்க முடியும் "
"என்பதை புரிந்து கொள்ள வேண்டும்: SS \\: துணை:` ரெச்` மற்றும் பின்னடைவு மாதிரி மாறுபாடு "
"SS \\: `mod` . அத்தியாயத்தில் ANOVA ஐப் பார்க்கும்போது, தொழில்நுட்பங்களை நான் தவிர்ப்பேன்: "
"DOC: `../ ch13/ch13_anova`. ஆனால் அதை கவனியுங்கள்"

#: ../../Ch12/Ch12_Regression_07.rst:44
msgid "SS\\ :sub:`mod` = SS\\ :sub:`tot` - SS\\ :sub:`res`"
msgstr "SS\\ :sub:`mod` = SS\\ :sub:`tot` - SS\\ :sub:`res`"

#: ../../Ch12/Ch12_Regression_07.rst:46
msgid ""
"And we can convert the sums of squares into mean squares by dividing by the "
"degrees of freedom."
msgstr ""
"மேலும் சதுரங்களின் தொகையை சுதந்திரத்தின் அளவைக் காண்பிப்பதன் மூலம் சராசரி சதுரங்களாக "
"மாற்றலாம்."

#: ../../Ch12/Ch12_Regression_07.rst:49
msgid "MS\\ :sub:`mod` = SS\\ :sub:`mod` / *df*\\ :sub:`mod`"
msgstr "MS\\ :sub:`mod` = SS\\ :sub:`mod` / *df*\\ :sub:`mod`"

#: ../../Ch12/Ch12_Regression_07.rst:50
msgid "SS\\ :sub:`res` = SS\\ :sub:`res` / *df*\\ :sub:`res`"
msgstr "SS\\ :sub:`res` = SS\\ :sub:`res` / *df*\\ :sub:`res`"

#: ../../Ch12/Ch12_Regression_07.rst:52
msgid ""
"So, how many degrees of freedom do we have? As you might expect the *df* "
"associated with the model is closely tied to the number of predictors that "
"we’ve included. In fact, it turns out that *df*\\ :sub:`mod` = *K*. For the "
"residuals the total degrees of freedom is *df*\\ :sub:`res` = *N* - *K* - 1."
msgstr ""
"எனவே, நமக்கு எத்தனை டிகிரி விடுதலை உள்ளது? மாதிரியுடன் தொடர்புடைய * டி.எஃப் * நாங்கள்"
" சேர்த்துள்ள முன்னறிவிப்பாளர்களின் எண்ணிக்கையுடன் நெருக்கமாக பிணைக்கப்பட்டுள்ளது. உண்மையில், *"
"df *\\: sub: `mod` = *k *என்று மாறிவிடும். எச்சங்களுக்கு மொத்த சுதந்திரத்தின் அளவு *"
"df *\\: துணை: `res` = *n * - *k * - 1."

#: ../../Ch12/Ch12_Regression_07.rst:58
msgid ""
"Now that we’ve got our mean square values we can calculate an *F*-statistic "
"like this:"
msgstr ""
"இப்போது எங்கள் சராசரி சதுர மதிப்புகளைப் பெற்றுள்ளோம், இது போன்ற ஒரு *f *-statistical "
"ஐக் கணக்கிடலாம்:"

#: ../../Ch12/Ch12_Regression_07.rst:61
msgid "F = MS\\ :sub:`mod` / SS\\ :sub:`res`"
msgstr "F = MS\\ :sub:`mod` / SS\\ :sub:`res`"

#: ../../Ch12/Ch12_Regression_07.rst:63
msgid ""
"and the degrees of freedom associated with this are *K* and *N* - *K* - 1."
msgstr ""
"இதனுடன் தொடர்புடைய சுதந்திரத்தின் அளவுகள் * k * மற்றும் * n * - * k * - 1."

#: ../../Ch12/Ch12_Regression_07.rst:66
msgid ""
"We’ll see much more of the *F*-statistic in chapter :doc:`../Ch13/"
"Ch13_ANOVA`, but for now just know that we can interpret large *F*-values as "
"indicating that the null hypothesis is performing poorly in comparison to "
"the alternative hypothesis. In a moment I’ll show you how to do the test in "
"jamovi the easy way, but first let’s have a look at the tests for the "
"individual regression coefficients."
msgstr ""
"அத்தியாயத்தில் *f *-statistict இல் இன்னும் பலவற்றைக் காண்போம்: doc: `../ ch13/"
"ch13_anova`, ஆனால் இப்போது சுழிய கருதுகோள் செயல்படுகிறது என்பதைக் குறிக்கும் பெரிய *"
"f *-values ஐ விளக்க முடியும் என்பதை இப்போது அறிந்து கொள்ளுங்கள் மாற்று கருதுகோளுடன் "
"ஒப்பிடுகையில் மோசமாக. சாமோவியில் சோதனை செய்வது எப்படி எளிதான வழியை நான் உங்களுக்குக் "
"காண்பிப்பேன், ஆனால் முதலில் தனிப்பட்ட பின்னடைவு குணகங்களுக்கான சோதனைகளைப் பார்ப்போம்."

#: ../../Ch12/Ch12_Regression_07.rst:74
msgid "Tests for individual coefficients"
msgstr "தனிப்பட்ட குணகங்களுக்கான சோதனைகள்"

#: ../../Ch12/Ch12_Regression_07.rst:76
msgid ""
"The *F*-test that we’ve just introduced is useful for checking that the "
"model as a whole is performing better than chance. If your regression model "
"doesn’t produce a significant result for the *F*-test then you probably "
"don’t have a very good regression model (or, quite possibly, you don’t have "
"very good data). However, while failing this test is a pretty strong "
"indicator that the model has problems, *passing* the test (i.e., rejecting "
"the null) doesn’t imply that the model is good! Why is that, you might be "
"wondering? The answer to that can be found by looking at the coefficients "
"for the multiple regression model we have already looked at :numref:`tab-"
"parent_coeff` in section :doc:`Ch12_Regression_05` above, where the "
"coefficients we got were 125.966 (for the intercept), -8.950 (for ``dani."
"sleep``) and 0.011 (for ``baby.sleep``). I can’t help but notice that the "
"estimated regression coefficient for the ``baby.sleep`` variable is tiny, "
"relative to the value that we get for ``dani.sleep``. Given that these two "
"variables are absolutely on the same scale (they’re both measured in “hours "
"slept”), I find this illuminating. In fact, I’m beginning to suspect that "
"it’s really only the amount of sleep that *I* get that matters in order to "
"predict my grumpiness."
msgstr ""
"நாங்கள் இப்போது அறிமுகப்படுத்திய *f *-test, ஒட்டுமொத்த மாதிரியும் வாய்ப்பை விட சிறப்பாக "
"செயல்படுகிறதா என்பதை சரிபார்க்க பயனுள்ளதாக இருக்கும். உங்கள் பின்னடைவு மாதிரி *f *-"
"test க்கு ஒரு குறிப்பிடத்தக்க முடிவை உருவாக்கவில்லை என்றால், உங்களிடம் நல்ல பின்னடைவு "
"மாதிரி இல்லை (அல்லது, உங்களிடம் நல்ல தரவு இல்லை). இருப்பினும், இந்த சோதனையில் "
"தோல்வியுற்றாலும், மாதிரியில் சிக்கல்கள் உள்ளன என்பதற்கான மிக வலுவான குறிகாட்டியாகும், * "
"சோதனை * சோதனை (அதாவது, பூச்யத்தை நிராகரிப்பது) மாதிரி நல்லது என்பதைக் குறிக்காது! "
"அது ஏன், நீங்கள் யோசித்துக்கொண்டிருக்கலாம்? நாம் ஏற்கனவே பார்த்த பல பின்னடைவு மாதிரிக்கான "
"குணகங்களைப் பார்ப்பதன் மூலம் அதற்கான பதிலைக் காணலாம்: NumRef: `TAB-PARENT_COEFF` "
"பிரிவில்: DOC:` CH12_REGRESSION_05` மேலே, எங்களுக்கு கிடைத்த குணகங்கள் 125.966 "
"(அதற்கு இடைமறிப்பு), -8.950 (`` dani.sleep`` க்கு) மற்றும் 0.011 (`` kabe.sleep`` "
"க்கு). `` டானி.லீப்`` க்கு நாம் பெறும் மதிப்புடன் ஒப்பிடும்போது, `` குழந்தை.லீப்` `மாறிக்கா"
"ன மதிப்பிடப்பட்ட பின்னடைவு குணகம் சிறியது என்பதை எனக்கு உதவ முடியாது, ஆனால் கவனிக்க "
"முடியாது. இந்த இரண்டு மாறிகள் முற்றிலும் ஒரே அளவில் இருப்பதால் (அவை இரண்டும் “மணிநேரம் "
"தூங்குவதில்” அளவிடப்படுகின்றன), இது வெளிச்சம் போடுவதைக் காண்கிறேன். உண்மையில், என் "
"எரிச்சலைக் கணிப்பதற்காக * நான் * அந்த விசயங்களைப் பெறும் தூக்கத்தின் அளவு மட்டுமே என்று நான்"
" சந்தேகிக்கத் தொடங்கினேன்."

#: ../../Ch12/Ch12_Regression_07.rst:94
msgid ""
"We can re-use a hypothesis test that we discussed earlier, the *t*-test. The "
"test that we’re interested in has a null hypothesis that the true regression "
"coefficient is zero (*b* = 0), which is to be tested against the alternative "
"hypothesis that it isn’t (*b* ≠ 0). That is:"
msgstr ""
"நாம் முன்பு விவாதித்த ஒரு கருதுகோள் சோதனையை *t *-test மீண்டும் பயன்படுத்தலாம். உண்மையான "
"பின்னடைவு குணகம் பூச்சியமானது (* பி* = 0) என்ற சுழிய கருதுகோளைக் கொண்டுள்ளது, இது "
"மாற்று கருதுகோளுக்கு எதிராக சோதிக்கப்பட வேண்டும் (* பி* ≠ 0). அதாவது:"

#: ../../Ch12/Ch12_Regression_07.rst:100
msgid "H\\ :sub:`0`: *b* = 0"
msgstr "H\\ :sub:`0`: *b* = 0"

#: ../../Ch12/Ch12_Regression_07.rst:101
msgid "H\\ :sub:`1`: *b* ≠ 0"
msgstr "H\\ :sub:`1`: *b* ≠ 0"

#: ../../Ch12/Ch12_Regression_07.rst:103
msgid ""
"How can we test this? Well, if the central limit theorem is kind to us we "
"might be able to guess that the sampling distribution of :math:`\\hat{b}`, "
"the estimated regression coefficient, is a normal distribution with mean "
"centred on *b*. What that would mean is that if the null hypothesis were "
"true, then the sampling distribution of :math:`\\hat{b}` has mean zero and "
"unknown standard deviation. Assuming that we can come up with a good "
"estimate for the standard error of the regression coefficient, :math:"
"`SE(\\hat{b})`, then we’re in luck. That’s *exactly* the situation for which "
"we introduced the one-sample *t*-test way back in chapter :doc:`../Ch11/"
"Ch11_tTest`. So let’s define a *t*-statistic like this:"
msgstr ""
"இதை நாம் எவ்வாறு சோதிக்க முடியும்? Well, if the மைய limit theorem is kind பெறுநர் "
"us we might be able பெறுநர் guess that the மாதிரி எடுத்தல் பரவல் of :math:`\\hat"
"{b}`, the estimated regression coefficient, is a normal பரவல் with இடை, சராசரி"
" centred on *b*. இதன் பொருள் என்னவென்றால், சுழிய கருதுகோள் உண்மையாக இருந்தால், இதன் "
"மாதிரி விநியோகம்: கணிதம்: `\\ தொப்பி {b}` என்பது பூச்சியத்தையும் அறியப்படாத நிலையான "
"விலகலையும் குறிக்கிறது. பின்னடைவு குணகத்தின் நிலையான பிழைக்கான நல்ல மதிப்பீட்டை நாம் "
"கொண்டு வர முடியும் என்று கருதி, கணிதம்: `சே (\\ தொப்பி {b})`, பின்னர் நாங்கள் "
"அதிர்ச்டத்தில் இருக்கிறோம். அத்தியாயம்: டாக்: `../ ch11/ch11_ttest` என்ற அத்தியாயத்தில் "
"ஒரு மாதிரி *t *-test வழியை அறிமுகப்படுத்திய சூழ்நிலை இது *சரியாக *. எனவே இது போன்"
"ற ஒரு *t *-statistict ஐ வரையறுப்போம்:"

#: ../../Ch12/Ch12_Regression_07.rst:114
msgid ""
"t = \\frac{\\hat{b}}{SE(\\hat{b})}\n"
"\n"
msgstr ""
"t = \\frac{\\hat{b}}{SE(\\hat{b})}\n"
"\n"

#: ../../Ch12/Ch12_Regression_07.rst:116
msgid ""
"I’ll skip over the reasons why, but our degrees of freedom in this case are "
"*df* = *N* - *K* - 1. Irritatingly, the estimate of the standard error of "
"the regression coefficient, :math:`SE(\\hat{b})`, is not as easy to "
"calculate as the standard error of the mean that we used for the simpler *t*-"
"tests in chapter :doc:`../Ch11/Ch11_tTest`. In fact, the formula is somewhat "
"ugly, and not terribly helpful to look at.\\ [#]_ For our purposes it’s "
"sufficient to point out that the standard error of the estimated regression "
"coefficient depends on both the predictor and outcome variables, and it is "
"somewhat sensitive to violations of the homogeneity of variance assumption "
"(discussed shortly)."
msgstr ""
"ஏன் காரணங்களை நான் தவிர்ப்பேன், ஆனால் இந்த விசயத்தில் எங்கள் விடுதலை * df * = * n * - * "
"k * - 1. எரிச்சலூட்டும் வகையில், பின்னடைவு குணகத்தின் நிலையான பிழையின் மதிப்பீடு,: "
"கணிதம்: `சே . உண்மையில், தேற்றம் சற்றே அசிங்கமானது, மேலும் பார்க்க மிகவும் உதவாது. "
"மாறுபாடு அனுமானத்தின் ஒருமைப்பாட்டை மீறுவதற்கு ஓரளவு உணர்திறன் (விரைவில் "
"விவாதிக்கப்பட்டது)."

#: ../../Ch12/Ch12_Regression_07.rst:126
msgid ""
"In any case, this *t*-statistic can be interpreted in the same way as the "
"*t*-statistics that we discussed in chapter :doc:`../Ch11/Ch11_tTest`. "
"Assuming that you have a two-sided alternative (i.e., you don’t really care "
"if *b* > 0 or *b* < 0), then it’s the extreme values of *t* (i.e., a lot "
"less than zero or a lot greater than zero) that suggest that you should "
"reject the null hypothesis."
msgstr ""
"எப்படியிருந்தாலும், இந்த *t *-statistict அத்தியாயத்தில் நாம் விவாதித்த *t "
"*-புள்ளிவிவரங்களைப் போலவே விளக்கப்படலாம்: doc: `../ ch11/ch11_ttest`. உங்களிடம் இரு "
"பக்க மாற்று உள்ளது என்று கருதி (அதாவது, * b *> 0 அல்லது * b * <0) என்றால் நீங்கள் "
"உண்மையில் கவலைப்படவில்லை, பின்னர் இது * t * இன் தீவிர மதிப்புகள் (அதாவது, பூச்சியத்தை வி"
"ட மிகக் குறைவு அல்லது பூச்சியத்தை விட நிறைய பெரியது) நீங்கள் சுழிய கருதுகோளை "
"நிராகரிக்க வேண்டும் என்று பரிந்துரைக்கும்."

#: ../../Ch12/Ch12_Regression_07.rst:136
msgid "Running the hypothesis tests in jamovi"
msgstr "சமோவியில் கருதுகோள் சோதனைகளை இயக்குகிறது"

#: ../../Ch12/Ch12_Regression_07.rst:138
msgid ""
"To compute all of the statistics that we have talked about so far, all you "
"need to do is make sure the relevant options are checked in jamovi and then "
"run the regression. If we do that, as in :numref:`fig-reg2`, we get a whole "
"bunch of useful output."
msgstr ""
"இதுவரை நாங்கள் பேசிய அனைத்து புள்ளிவிவரங்களையும் கணக்கிட, நீங்கள் செய்ய வேண்டியதெல்லாம், "
"சாமோவியில் தொடர்புடைய விருப்பங்கள் சரிபார்க்கப்படுவதை உறுதிசெய்து பின்னடைவை இயக்க வேண்டும்"
". நாம் அதைச் செய்தால், உள்ளதைப் போல: NumRef: `Fig-reg2`, பயனுள்ள வெளியீட்டின் "
"முழுவதையும் நாங்கள் பெறுகிறோம்."

#: ../../Ch12/Ch12_Regression_07.rst:145
msgid "jamovi screenshot showing a multiple linear regression"
msgstr "சாமோவி திரைக்காட்சி பல நேரியல் பின்னடைவைக் காட்டுகிறது"

#: ../../Ch12/Ch12_Regression_07.rst:149
msgid ""
"jamovi screenshot showing a multiple linear regression analysis, with some "
"useful options checked."
msgstr ""
"சாமோவி திரைக்காட்சி பல நேரியல் பின்னடைவு பகுப்பாய்வைக் காட்டுகிறது, சில பயனுள்ள "
"விருப்பங்களுடன் சரிபார்க்கப்பட்டது."

#: ../../Ch12/Ch12_Regression_07.rst:154
msgid ""
"The ``Model Coefficients`` at the bottom of the jamovi analysis results "
"shown in :numref:`fig-reg2` provides the coefficients of the regression "
"model. Each row in this table refers to one of the coefficients in the "
"regression model. The first row is the intercept term, and the later ones "
"look at each of the predictors. The columns give you all of the relevant "
"information. The first column is the actual estimate of *b* (e.g., 125.97 "
"for the intercept, and -8.95 for the ``dani.sleep`` predictor). The second "
"column is the standard error estimate :math:`\\hat\\sigma_b`. The third and "
"fourth columns provide the lower and upper values for the 95\\% confidence "
"interval around the *b* estimate (more on this later). The fifth column "
"gives you the *t*-statistic, and it’s worth noticing that in this table :"
"math:`t= \\hat{b} / SE(\\hat{b})` every time. Finally, the last column gives "
"you the actual *p*-value for each of these tests.\\ [#]_"
msgstr ""

#: ../../Ch12/Ch12_Regression_07.rst:168
msgid ""
"The only thing that the coefficients table itself doesn’t list is the "
"degrees of freedom used in the *t*-test, which is always *N* - *K* - 1 and "
"is listed in the table at the top of the output, labelled ``Model Fit "
"Measures``. We can see from this table that the model performs significantly "
"better than you’d expect by chance (*F*\\(2,97) = 215.24, *p* < 0.001), "
"which isn’t all that surprising: the *R*\\² = 0.81 value indicate that the "
"regression model accounts for 81\\% of the variability in the outcome "
"measure (and 82\\% for the adjusted *R*\\²). However, when we look back up "
"at the *t*-tests for each of the individual coefficients, we have pretty "
"strong evidence that the ``baby.sleep`` variable has no significant effect. "
"All the work in this model is being done by the ``dani.sleep`` variable. "
"Taken together, these results suggest that this regression model is actually "
"the wrong model for the data. You’d probably be better off dropping the "
"``baby.sleep`` predictor entirely. In other words, the simple regression "
"model that we started with is the better model."
msgstr ""
"குணக அட்டவணையை பட்டியலிடாத ஒரே சேதி *t *-test இல் பயன்படுத்தப்படும் சுதந்திரத்தின் "
"அளவுகள், இது எப்போதும் *n * - *k * - 1 மற்றும் வெளியீட்டின் மேலே உள்ள அட்டவணையில் "
"பட்டியலிடப்பட்டுள்ளது , `` மாதிரி பொருத்தம் நடவடிக்கைகள்`` என்று பெயரிடப்பட்டது. இந்த "
"அட்டவணையில் இருந்து நீங்கள் எதிர்பார்ப்பதை விட கணிசமாக சிறப்பாக செயல்படுகிறது என்பதை இந்த "
"அட்டவணையில் இருந்து நாம் காணலாம் (*f*\\ (2,97) = 215.24,*ப*<0.001), இது "
"ஆச்சரியமல்ல:*r . எவ்வாறாயினும், ஒவ்வொரு தனிப்பட்ட குணகங்களுக்கும் *t *-tests ஐ திரும்பிப்"
" பார்க்கும்போது, `` குழந்தை.ச்லீப்`` மாறுபாடு குறிப்பிடத்தக்க விளைவைக் கொண்டிருக்கவில்லை "
"என்பதற்கு எங்களிடம் வலுவான சான்றுகள் உள்ளன. இந்த மாதிரியில் உள்ள அனைத்து வேலைகளும் `` "
"டானி.லீப்`` மாறுபாட்டால் செய்யப்படுகின்றன. ஒன்றாக எடுத்துக்கொண்டால், இந்த பின்னடைவு மாதிரி "
"உண்மையில் தரவுக்கு தவறான மாதிரி என்று இந்த முடிவுகள் தெரிவிக்கின்றன. `` குழந்தை.ச்லீப்`` "
"முன்னறிவிப்பாளரை முற்றிலுமாக கைவிடுவது நல்லது. வேறு வார்த்தைகளில் கூறுவதானால், நாங்கள் "
"தொடங்கிய எளிய பின்னடைவு மாதிரி சிறந்த மாதிரி."

#: ../../Ch12/Ch12_Regression_07.rst:188
msgid ""
"For advanced readers only. The vector of residuals is :math:`\\epsilon = y - "
"X \\hat{b}`. For *K* predictors plus the intercept, the estimated residual "
"variance is :math:`\\hat\\sigma^2 = \\epsilon^\\prime\\epsilon / (N - K - "
"1)`. The estimated covariance matrix of the coefficients is :math:"
"`\\hat\\sigma^2(\\mathbf{X}^\\prime\\mathbf{X})^{-1}`, the main diagonal of "
"which is :math:`SE(\\hat{b})`, our estimated standard errors."
msgstr ""
"மேம்பட்ட வாசகர்களுக்கு மட்டுமே. எச்சங்களின் திசையன்: கணிதம்: `\\ epsilon = ஒய் - ஃச் \\ "
"hat {b}`. * K * முன்னறிவிப்பாளர்கள் மற்றும் இடைமறிப்புக்கு, மதிப்பிடப்பட்ட எஞ்சிய "
"மாறுபாடு: கணிதம்: `\\ தொப்பி \\ சிக்மா^2 = \\ epsilon^\\ prime \\ epsilon / (n -"
" k - 1)`. குணகங்களின் மதிப்பிடப்பட்ட கோவாரன்ச் மேட்ரிக்ச்: கணிதம்: `\\ தொப்பி \\ சிக்மா^2 "
"(\\ mathbf {X}^\\ prime \\ mathbf {X})^{-1}`, இதன் முக்கிய மூலைவிட்டம்: கணித: ` "
"SE (\\ தொப்பி {b}) `, எங்கள் மதிப்பிடப்பட்ட நிலையான பிழைகள்."

#: ../../Ch12/Ch12_Regression_07.rst:198
msgid ""
"Note that, although jamovi has done multiple tests here, it hasn’t done a "
"Bonferroni correction or anything. These are standard one-sample *t*-tests "
"with a two-sided alternative. If you want to make corrections for multiple "
"tests, you need to do that yourself."
msgstr ""
"சமோவி இங்கு பல சோதனைகளைச் செய்திருந்தாலும், அது ஒரு போன்பெரோரோனி திருத்தம் அல்லது "
"எதையும் செய்யவில்லை என்பதை நினைவில் கொள்க. இவை இரு பக்க மாற்றீட்டைக் கொண்ட நிலையான ஒரு "
"மாதிரி *t *-டெச்ட்கள். பல சோதனைகளுக்கு நீங்கள் திருத்தங்களைச் செய்ய விரும்பினால், அதை "
"நீங்களே செய்ய வேண்டும்."

#: ../../Ch12/Ch12_Regression_09.rst:4
msgid "Regarding regression coefficients"
msgstr "பின்னடைவு குணகங்கள் குறித்து"

#: ../../Ch12/Ch12_Regression_09.rst:6
msgid ""
"Before moving on to discuss the assumptions underlying linear regression and "
"what you can do to check if they’re being met, there’s two more topics I "
"want to briefly discuss, both of which relate to the regression "
"coefficients. The first thing to talk about is calculating confidence "
"intervals for the coefficients. After that, I’ll discuss the somewhat murky "
"question of how to determine which predictor is most important."
msgstr ""
"நேரியல் பின்னடைவின் அடிப்படையிலான அனுமானங்கள் மற்றும் அவை நிறைவு செய்யப்படுகிறதா என்பதைச்"
" சரிபார்க்க நீங்கள் என்ன செய்ய முடியும் என்பதைப் பற்றி விவாதிக்கச் செல்வதற்கு முன், நான் "
"சுருக்கமாக விவாதிக்க விரும்பும் இன்னும் இரண்டு தலைப்புகள் உள்ளன, இவை இரண்டும் பின்னடைவு "
"குணகங்களுடன் தொடர்புடையவை. முதலில் பேச வேண்டிய சேதி குணகங்களுக்கான நம்பிக்கை "
"இடைவெளிகளைக் கணக்கிடுவதாகும். அதன்பிறகு, எந்த முன்கணிப்பு மிக முக்கியமானது என்பதை "
"எவ்வாறு தீர்மானிப்பது என்ற சற்றே இருண்ட கேள்வியைப் பற்றி விவாதிப்பேன்."

#: ../../Ch12/Ch12_Regression_09.rst:14
msgid "Confidence intervals for the coefficients"
msgstr "குணகங்களுக்கான நம்பிக்கை இடைவெளிகள்"

#: ../../Ch12/Ch12_Regression_09.rst:16
msgid ""
"Like any population parameter, the regression coefficients *b* cannot be "
"estimated with complete precision from a sample of data; that’s part of why "
"we need hypothesis tests. Given this, it’s quite useful to be able to report "
"confidence intervals that capture our uncertainty about the true value of "
"*b*. This is especially useful when the research question focuses heavily on "
"an attempt to find out *how* strongly variable *X* is related to variable "
"*Y*, since in those situations the interest is primarily in the regression "
"weight *b*."
msgstr ""
"எந்தவொரு மக்கள்தொகை அளவுருவையும் போலவே, பின்னடைவு குணகங்களையும் * b * தரவுகளின் "
"மாதிரியிலிருந்து முழுமையான துல்லியத்துடன் மதிப்பிட முடியாது; இதுதான் நமக்கு கருதுகோள்"
" சோதனைகள் தேவை என்பதன் ஒரு பகுதியாகும். இதைக் கருத்தில் கொண்டு, *B *இன் உண்மையான "
"மதிப்பைப் பற்றிய நமது நிச்சயமற்ற தன்மையைக் கைப்பற்றும் நம்பிக்கை இடைவெளிகளைப் புகாரளிக்க "
"இது மிகவும் பயனுள்ளதாக இருக்கும். ஆராய்ச்சி கேள்வி *y *y *உடன் எவ்வாறு தொடர்புடையது "
"என்பதைக் கண்டுபிடிக்கும் முயற்சியில் அதிக கவனம் செலுத்தும்போது இது மிகவும் பயனுள்ளதாக "
"இருக்கும், ஏனெனில் அந்த சூழ்நிலைகளில் ஆர்வம் முதன்மையாக பின்னடைவு எடையில் *b *."

#: ../../Ch12/Ch12_Regression_09.rst:26
msgid ""
"Fortunately, confidence intervals for the regression weights can be "
"constructed in the usual fashion"
msgstr ""
"அதிர்ச்டவசமாக, பின்னடைவு எடைகளுக்கான நம்பிக்கை இடைவெளிகள் வழக்கமான பாணியில் "
"கட்டமைக்கப்படலாம்"

#: ../../Ch12/Ch12_Regression_09.rst:29
msgid ""
"\\mbox{CI}(b) = \\hat{b} \\pm \\left( t_{crit} \\times SE(\\hat{b})  "
"\\right)\n"
"\n"
msgstr ""
"\\mbox{CI}(b) = \\hat{b} \\pm \\left( t_{crit} \\times SE(\\hat{b})  \\right)"
"\n"
"\n"

#: ../../Ch12/Ch12_Regression_09.rst:31
msgid ""
"where :math:`SE(\\hat{b})` is the standard error of the regression "
"coefficient, and *t*\\ :sub:`crit` is the relevant critical value of the "
"appropriate *t*-distribution. For instance, if it’s a 95\\% confidence "
"interval that we want, then the critical value is the 97.5th quantile of a "
"*t* distribution with *N* - *K* - 1 degrees of freedom. In other words, this "
"is basically the same approach to calculating confidence intervals that "
"we’ve used throughout."
msgstr ""
"எங்கே: கணிதம்: `சே (\\ தொப்பி {b})` என்பது பின்னடைவு குணகத்தின் நிலையான பிழை, மற்றும் "
"*டி *\\: துணை: `கிரிட்` என்பது பொருத்தமான *டி *-டிச்ட்ரிபியூசனின் பொருத்தமான "
"முக்கியமான மதிப்பு. உதாரணமாக, இது நாம் விரும்பும் 95 \\% நம்பிக்கை இடைவெளியாக "
"இருந்தால், முக்கியமான மதிப்பு * n * - * k * - 1 டிகிரி சுதந்திரத்துடன் A * t * "
"விநியோகத்தின் 97.5 வது அளவு. வேறு வார்த்தைகளில் கூறுவதானால், இது அடிப்படையில் நாம் "
"பயன்படுத்திய நம்பிக்கை இடைவெளிகளைக் கணக்கிடுவதற்கான அதே அணுகுமுறையாகும்."

#: ../../Ch12/Ch12_Regression_09.rst:38
msgid ""
"In jamovi we had already specified the ``95\\% Confidence interval`` as "
"shown in :numref:`fig-reg2`, although we could easily have chosen another "
"value, say a ``99\\% Confidence interval`` if that is what we decided on."
msgstr ""
"சாமோவியில் நாங்கள் ஏற்கனவே `` 95 \\% நம்பிக்கை இடைவெளி`` இல் காட்டப்பட்டுள்ளபடி "
"குறிப்பிட்டுள்ளோம்: NumRef: `Fig-reg2`, நாங்கள் மற்றொரு மதிப்பை எளிதில் "
"தேர்ந்தெடுத்திருக்கலாம் என்றாலும்,` `99 \\% நம்பிக்கை இடைவெளி`` என்று சொல்லுங்கள் நாங்கள் "
"முடிவு செய்தது."

#: ../../Ch12/Ch12_Regression_09.rst:43
msgid "Calculating standardised regression coefficients"
msgstr "தரப்படுத்தப்பட்ட பின்னடைவு குணகங்களைக் கணக்கிடுதல்"

#: ../../Ch12/Ch12_Regression_09.rst:45
msgid ""
"One more thing that you might want to do is to calculate “standardised” "
"regression coefficients, often denoted β. The rationale behind standardised "
"coefficients goes like this. In a lot of situations, your variables are on "
"fundamentally different scales. Suppose, for example, my regression model "
"aims to predict people’s IQ scores using their educational attainment "
"(number of years of education) and their income as predictors. Obviously, "
"educational attainment and income are not on the same scales. The number of "
"years of schooling might only vary by 10s of years, whereas income can vary "
"by 10,000s of dollars (or more). The units of measurement have a big "
"influence on the regression coefficients. The *b* coefficients only make "
"sense when interpreted in light of the units, both of the predictor "
"variables and the outcome variable. This makes it very difficult to compare "
"the coefficients of different predictors. Yet there are situations where you "
"really do want to make comparisons between different coefficients. "
"Specifically, you might want some kind of standard measure of which "
"predictors have the strongest relationship to the outcome. This is what "
"**standardised coefficients** aim to do."
msgstr ""
"நீங்கள் செய்ய விரும்பும் இன்னும் ஒரு சேதி, “தரப்படுத்தப்பட்ட” பின்னடைவு குணகங்களைக் "
"கணக்கிடுவது, பெரும்பாலும் குறிக்கப்படுகிறது. தரப்படுத்தப்பட்ட குணகங்களுக்குப் பின்னால் உள்ள "
"பகுத்தறிவு இப்படி செல்கிறது. நிறைய சூழ்நிலைகளில், உங்கள் மாறிகள் அடிப்படையில் வேறுபட்ட "
"அளவுகளில் உள்ளன. எடுத்துக்காட்டாக, எனது பின்னடைவு மாதிரி மக்களின் ஐ.க்யூ மதிப்பெண்களை "
"அவர்களின் கல்வி அடைதல் (கல்வியின் ஆண்டுகளின் எண்ணிக்கை) மற்றும் அவர்களின் வருமானத்தை "
"முன்னறிவிப்பாளர்களாக கணிப்பதை நோக்கமாகக் கொண்டுள்ளது என்று வைத்துக்கொள்வோம். வெளிப்படையாக, "
"கல்வி அடைதல் மற்றும் வருமானம் ஒரே அளவீடுகளில் இல்லை. பள்ளிப்படிப்பின் ஆண்டுகளின் எண்ணிக்கை "
"10 களின் ஆண்டுகளுக்கு மட்டுமே மாறுபடும், அதே நேரத்தில் வருமானம் 10,000 டாலர்கள் (அல்லது "
"அதற்கு மேற்பட்டவை) மாறுபடும். அளவீட்டு அலகுகள் பின்னடைவு குணகங்களில் பெரிய தாக்கத்தை "
"ஏற்படுத்துகின்றன. முன்கணிப்பு மாறிகள் மற்றும் விளைவு மாறி ஆகிய இரண்டின் அலகுகளின் "
"வெளிச்சத்தில் விளக்கப்படும்போது மட்டுமே * பி * குணகங்கள் அர்த்தமுள்ளதாக இருக்கும். வெவ்வேறு "
"முன்னறிவிப்பாளர்களின் குணகங்களை ஒப்பிடுவது இது மிகவும் கடினம். ஆயினும் வெவ்வேறு "
"குணகங்களுக்கு இடையில் ஒப்பிட்டுப் பார்க்க விரும்பும் சூழ்நிலைகள் உள்ளன. குறிப்பாக, எந்தவொரு "
"முன்னறிவிப்பாளர்களும் முடிவுக்கு வலுவான உறவைக் கொண்டுள்ள ஒருவித நிலையான அளவை நீங்கள் "
"விரும்பலாம். இதைத்தான் ** தரப்படுத்தப்பட்ட குணகங்கள் ** செய்ய வேண்டும்."

#: ../../Ch12/Ch12_Regression_09.rst:64
msgid ""
"The basic idea is quite simple; the standardised coefficients are the "
"coefficients that you would have obtained if you’d converted all the "
"variables to *z*-scores before running the regression.\\ [#]_ The idea here "
"is that, by converting all the predictors to *z*-scores, they all go into "
"the regression on the same scale, thereby removing the problem of having "
"variables on different scales. Regardless of what the original variables "
"were, a β value of 1 means that an increase in the predictor of 1 standard "
"deviation will produce a corresponding 1 standard deviation increase in the "
"outcome variable. Therefore, if variable A has a larger absolute value of β "
"than variable B, it is deemed to have a stronger relationship with the "
"outcome. Or at least that’s the idea. It’s worth being a little cautious "
"here, since this does rely very heavily on the assumption that “a 1 standard "
"deviation change” is fundamentally the same kind of thing for all variables. "
"It’s not always obvious that this is true."
msgstr ""
"அடிப்படை சிந்தனை மிகவும் எளிது; தரப்படுத்தப்பட்ட குணகங்கள் பின்னடைவை இயக்குவதற்கு முன்பு "
"நீங்கள் அனைத்து மாறிகளையும் *Z *-ச்கோர்களாக மாற்றினால் நீங்கள் பெறும் குணகங்கள் ஆகும். \\ [#]"
" _ இங்கே சிந்தனை என்னவென்றால், அனைத்து முன்னறிவிப்புகளையும் *Z *ஆக மாற்றுவதன் மூலம் "
"-மதிப்பெண்கள், அவை அனைத்தும் ஒரே அளவில் பின்னடைவுக்குச் செல்கின்றன, இதன் மூலம் வெவ்வேறு "
"அளவுகளில் மாறிகள் இருப்பதற்கான சிக்கலை நீக்குகின்றன. அசல் மாறிகள் என்ன என்பதைப் "
"பொருட்படுத்தாமல், 1 இன் β மதிப்பு 1 நிலையான விலகலின் முன்கணிப்பாளரின் அதிகரிப்பு விளைவு"
" மாறியில் 1 நிலையான விலகல் அதிகரிப்பை உருவாக்கும் என்பதாகும். ஆகையால், மாறி A க்கு "
"மாறி B ஐ விட β இன் பெரிய முழுமையான மதிப்பைக் கொண்டிருந்தால், அது முடிவுடன் வலுவான "
"உறவைக் கொண்டிருப்பதாகக் கருதப்படுகிறது. அல்லது குறைந்தபட்சம் அதுதான் சிந்தனை. இங்கே கொஞ்சம்"
" எச்சரிக்கையாக இருப்பது மதிப்புக்குரியது, ஏனென்றால் “1 நிலையான விலகல் மாற்றம்” என்பது "
"அனைத்து மாறிகளுக்கும் ஒரே மாதிரியான சேதி என்ற அனுமானத்தை இது பெரிதும் நம்பியுள்ளது. "
"இது உண்மை என்று எப்போதும் தெளிவாகத் தெரியவில்லை."

#: ../../Ch12/Ch12_Regression_09.rst:80
msgid ""
"Leaving aside the interpretation issues, let’s look at how it’s calculated. "
"What you could do is standardise all the variables yourself and then run a "
"regression, but there’s a much simpler way to do it. As it turns out, the β "
"coefficient for a predictor *X* and outcome *Y* has a very simple formula, "
"namely"
msgstr ""
"விளக்க சிக்கல்களை ஒதுக்கி வைத்துவிட்டு, அது எவ்வாறு கணக்கிடப்படுகிறது என்பதைப் பார்ப்போம். "
"நீங்கள் என்ன செய்ய முடியும் என்பது எல்லா மாறிகளையும் நீங்களே தரப்படுத்திக் கொண்டு, பின்னர் ஒரு"
" பின்னடைவை இயக்க வேண்டும், ஆனால் அதைச் செய்ய மிகவும் எளிமையான வழி உள்ளது. இது "
"மாறிவிட்டால், ஒரு முன்கணிப்பாளருக்கான β குணகம் * ஃச் * மற்றும் விளைவு * ஒய் * மிகவும் "
"எளிமையான சூத்திரத்தைக் கொண்டுள்ளது, அதாவது"

#: ../../Ch12/Ch12_Regression_09.rst:86
msgid "β\\ :sub:`X` = *b*\\ :sub:`X` × (σ\\ :sub:`X` / σ\\ :sub:`Y`)"
msgstr "β\\ :sub:`X` = *b*\\ :sub:`X` × (σ\\ :sub:`X` / σ\\ :sub:`Y`)"

#: ../../Ch12/Ch12_Regression_09.rst:88
msgid ""
"where σ\\ :sub:`X` is the standard deviation of the predictor, and σ\\ :sub:"
"`Y` is the standard deviation of the outcome variable *Y*. This makes "
"matters a lot simpler."
msgstr ""
"எங்கே σ \\: துணை: `x` என்பது முன்கணிப்பாளரின் நிலையான விலகல், மற்றும் σ \\: துணை:` y`"
" என்பது விளைவு மாறியின் நிலையான விலகல் *y *. இது விசயங்களை மிகவும் எளிதாக்குகிறது."

#: ../../Ch12/Ch12_Regression_09.rst:92
msgid ""
"To make things even simpler, jamovi has an option that computes the β "
"coefficients for you using the ``Standardized estimate`` checkbox in the "
"``Model Coefficients`` options, see results in :numref:`fig-reg3`."
msgstr ""
"விசயங்களை இன்னும் எளிமையாக்க, `` மாதிரி குணகங்கள்`` விருப்பங்களில் `` தரப்படுத்தப்பட்ட "
"மதிப்பீட்டை` தேர்வுப்பெட்டியைப் பயன்படுத்தி உங்களுக்கான β குணகங்களைக் கணக்கிடும் ஒரு "
"விருப்பத்தை சாமோவிக்கு கொண்டுள்ளது, முடிவுகளைப் பார்க்கவும்: எண்ரெஃப்: `Fig-reg3`."

#: ../../Ch12/Ch12_Regression_09.rst:98
msgid "Standardised coefficients with 95\\% confidence intervals"
msgstr "95 \\% நம்பிக்கை இடைவெளிகளுடன் தரப்படுத்தப்பட்ட குணகங்கள்"

#: ../../Ch12/Ch12_Regression_09.rst:102
msgid ""
"Standardised coefficients, with 95\\% confidence intervals, for multiple "
"linear regression"
msgstr ""
"பல நேரியல் பின்னடைவுக்கு 95 \\% நம்பிக்கை இடைவெளிகளுடன் தரப்படுத்தப்பட்ட குணகங்கள்"

#: ../../Ch12/Ch12_Regression_09.rst:107
msgid ""
"These results clearly show that the ``dani.sleep`` variable has a much "
"stronger effect than the ``baby.sleep`` variable. However, this is a perfect "
"example of a situation where it would probably make sense to use the "
"original coefficients *b* rather than the standardised coefficients β. After "
"all, my sleep and the baby’s sleep are *already* on the same scale: number "
"of hours slept. Why complicate matters by converting these to *z*-scores?"
msgstr ""
"இந்த முடிவுகள் `` டானி.லீப்`` மாறுபாடு `` குழந்தை.லீப்`` மாறியை விட மிகவும் வலுவான "
"விளைவைக் கொண்டிருப்பதை தெளிவாகக் காட்டுகிறது. இருப்பினும், தரப்படுத்தப்பட்ட குணகங்களை வி"
"ட அசல் குணகங்களை * B * ஐப் பயன்படுத்துவது அர்த்தமுள்ள ஒரு சூழ்நிலைக்கு இது ஒரு சிறந்த "
"எடுத்துக்காட்டு. எல்லாவற்றிற்கும் மேலாக, என் தூக்கமும் குழந்தையின் தூக்கமும் ஒரே அளவில் * "
"ஏற்கனவே * உள்ளன: மணிநேரங்கள் தூங்கின. இவற்றை *z *-ச்கோர்களாக மாற்றுவதன் மூலம் விசயங்களை "
"ஏன் சிக்கலாக்குவது?"

#: ../../Ch12/Ch12_Regression_09.rst:117
msgid ""
"Strictly, you standardise all the *regressors*. That is, every “thing” that "
"has a regression coefficient associated with it in the model. For the "
"regression models that I’ve talked about so far, each predictor variable "
"maps onto exactly one regressor, and vice versa. However, that’s not "
"actually true in general and we’ll see some examples of this in chapter :doc:"
"`../Ch14/Ch14_ANOVA2`. But, for now we don’t need to care too much about "
"this distinction."
msgstr ""
"கண்டிப்பாக, நீங்கள் அனைத்து *பின்னடைவுகளையும் *தரப்படுத்துகிறீர்கள். அதாவது, மாதிரியில் "
"தொடர்புடைய பின்னடைவு குணகம் கொண்ட ஒவ்வொரு “விசயம்”. நான் இதுவரை பேசிய பின்னடைவு "
"மாதிரிகளுக்கு, ஒவ்வொரு முன்கணிப்பாளரும் மாறி வரைபடங்கள் சரியாக ஒரு பின்னடைவுடன், மற்றும்"
" நேர்மாறாகவும். இருப்பினும், இது பொதுவாக உண்மையல்ல, இதன் சில எடுத்துக்காட்டுகளை "
"அத்தியாயத்தில் பார்ப்போம்: டாக்: `../ CH14/CH14_ANOVA2`. ஆனால், இப்போதைக்கு இந்த "
"வேறுபாட்டைப் பற்றி நாம் அதிகம் அக்கறை கொள்ள தேவையில்லை."

#: ../../Ch12/Ch12_Regression_10.rst:4
msgid "Assumptions of regression"
msgstr "பின்னடைவின் அனுமானங்கள்"

#: ../../Ch12/Ch12_Regression_10.rst:6
msgid ""
"The linear regression model that I’ve been discussing relies on several "
"assumptions. In section :doc:`Ch12_Regression_11` we’ll talk a lot more "
"about how to check that these assumptions are being met, but first let’s "
"have a look at each of them."
msgstr ""
"நான் விவாதிக்கும் நேரியல் பின்னடைவு மாதிரி பல அனுமானங்களை நம்பியுள்ளது. பிரிவில்: டாக்:"
" `CH12_REGRESSION_11` இந்த அனுமானங்கள் எவ்வாறு நிறைவு செய்யப்படுகின்றன என்பதை எவ்வாறு "
"சரிபார்க்கலாம் என்பது பற்றி நாங்கள் அதிகம் பேசுவோம், ஆனால் முதலில் அவை ஒவ்வொன்றையும் "
"பார்ப்போம்."

#: ../../Ch12/Ch12_Regression_10.rst:11
msgid ""
"*Normality*. Like many of the models in statistics, basic simple or multiple "
"linear regression relies on an assumption of normality. Specifically, it "
"assumes that the *residuals* are normally distributed. It’s actually okay if "
"the predictors *X* and the outcome *Y* are non-normal, so long as the "
"residuals ε are normal. See section :ref:`Checking the normality of the "
"residuals <checking_normality_residuals>`."
msgstr ""
"*இயல்புநிலை*. புள்ளிவிவரங்களில் உள்ள பல மாதிரிகளைப் போலவே, அடிப்படை எளிய அல்லது பல "
"நேரியல் பின்னடைவு இயல்புநிலையின் அனுமானத்தை நம்பியுள்ளது. குறிப்பாக, * எச்சங்கள் * "
"பொதுவாக விநியோகிக்கப்படுகின்றன என்று அது கருதுகிறது. முன்னறிவிப்பாளர்கள் * ஃச் * மற்றும்"
" விளைவு * ஒய் * ஆகியவை இயல்பானவை அல்ல, எஞ்சியவை இயல்பானவை வரை அது உண்மையில் "
"பரவாயில்லை. பிரிவு: ref ஐப் பார்க்கவும்: `எச்சங்களின் இயல்பான தன்மையை சரிபார்க்கிறது "
"<checking_normality_residuals>`."

#: ../../Ch12/Ch12_Regression_10.rst:18
msgid ""
"*Linearity*. A pretty fundamental assumption of the linear regression model "
"is that the relationship between *X* and *Y* actually is linear! Regardless "
"of whether it’s a simple regression or a multiple regression, we assume that "
"the relationships involved are linear."
msgstr ""
"*நேரியல்*. நேரியல் பின்னடைவு மாதிரியின் ஒரு அழகான அடிப்படை அனுமானம் என்னவென்றால், * ஃச்"
" * மற்றும் * ஒய் * க்கு இடையிலான உறவு உண்மையில் நேரியல்! இது ஒரு எளிய பின்னடைவு அல்லது"
" பல பின்னடைவு என்பதைப் பொருட்படுத்தாமல், சம்பந்தப்பட்ட உறவுகள் நேரியல் என்று நாங்கள் "
"கருதுகிறோம்."

#: ../../Ch12/Ch12_Regression_10.rst:23
msgid ""
"*Homogeneity of variance*. Strictly speaking, the regression model assumes "
"that each residual ε\\ :sub:`i` is generated from a normal distribution with "
"mean 0, and (more importantly for the current purposes) with a standard "
"deviation σ that is the same for every single residual. In practice, it’s "
"impossible to test the assumption that every residual is identically "
"distributed. Instead, what we care about is that the standard deviation of "
"the residual is the same for all values of *Ŷ*, and (if we’re being "
"especially paranoid) all values of every predictor *X* in the model."
msgstr ""
"*மாறுபாட்டின் ஒருமைப்பாடு*. கண்டிப்பாகச் சொல்வதானால், பின்னடைவு மாதிரி ஒவ்வொரு மீதமுள்ள "
"ε \\: துணை: `நான்` ஒரு சாதாரண விநியோகத்திலிருந்து சராசரி 0 உடன் உருவாக்கப்படுகிறது"
", மற்றும் (மிக முக்கியமாக தற்போதைய நோக்கங்களுக்காக) ஒரு நிலையான விலகலுடன் σ இது "
"ஒவ்வொரு எஞ்சியத்திற்கும் ஒன்றாகும் . நடைமுறையில், ஒவ்வொரு எச்சமும் ஒரே மாதிரியாக "
"விநியோகிக்கப்படுகிறது என்ற அனுமானத்தை சோதிக்க முடியாது. அதற்கு பதிலாக, நாம் அக்கறை "
"கொள்வது என்னவென்றால், மீதமுள்ளவற்றின் நிலையான விலகல் *ŷ *இன் அனைத்து மதிப்புகளுக்கும் ஒரே "
"மாதிரியாக இருக்கும், மேலும் (நாம் குறிப்பாக சித்தப்பிரமையாக இருந்தால்) மாதிரியில் உள்ள "
"ஒவ்வொரு முன்கணிப்பாளரின் அனைத்து மதிப்புகளும்."

#: ../../Ch12/Ch12_Regression_10.rst:32
msgid ""
"*Uncorrelated predictors*. The idea here is that, in a multiple regression "
"model, you don’t want your predictors to be too strongly correlated with "
"each other. This isn’t “technically” an assumption of the regression model, "
"but in practice it’s required. Predictors that are too strongly correlated "
"with each other (referred to as “collinearity”) can cause problems when "
"evaluating the model. See section :ref:`Checking for collinearity "
"<checking_collinearity>`."
msgstr ""
"*தொடர்பில்லாத முன்னறிவிப்பாளர்கள்*. இங்கே சிந்தனை என்னவென்றால், பல பின்னடைவு மாதிரியில், "
"உங்கள் முன்னறிவிப்பாளர்கள் ஒருவருக்கொருவர் மிகவும் வலுவாக தொடர்புபடுத்தப்படுவதை நீங்கள் "
"விரும்பவில்லை. இது பின்னடைவு மாதிரியின் அனுமானம் “தொழில்நுட்ப ரீதியாக” அல்ல, ஆனால் "
"நடைமுறையில் அது தேவைப்படுகிறது. ஒருவருக்கொருவர் மிகவும் வலுவாக தொடர்புபடுத்தப்பட்டுள்ள "
"முன்னறிவிப்பாளர்கள் (“கோலினரிட்டி” என்று குறிப்பிடப்படுகிறார்கள்) மாதிரியை "
"மதிப்பிடும்போது சிக்கல்களை ஏற்படுத்தும். பிரிவு: ref ஐப் பார்க்கவும்: `COLINEARITY ஐச் "
"சரிபார்க்கிறது <checking_colleinhity>`."

#: ../../Ch12/Ch12_Regression_10.rst:40
msgid ""
"*Residuals are independent of each other*. This is really just a “catch all” "
"assumption, to the effect that “there’s nothing else funny going on in the "
"residuals”. If there is something weird (e.g., the residuals all depend "
"heavily on some other unmeasured variable) going on, it might screw things "
"up."
msgstr ""
"*எச்சங்கள் ஒருவருக்கொருவர் சுயாதீனமாக உள்ளன*. இது உண்மையில் ஒரு “அனைத்தையும் பிடிக்கவும்” "
"அனுமானமாகும், இதன் விளைவாக “மீதமுள்ளவற்றில் வேறு எதுவும் இல்லை”. வித்தியாசமான ஒன்று "
"இருந்தால் (எ.கா., எச்சங்கள் அனைத்தும் வேறு சில அளவிடப்படாத மாறியைப் பொறுத்தது) நடந்து "
"கொண்டால், அது விசயங்களைத் திருகக்கூடும்."

#: ../../Ch12/Ch12_Regression_10.rst:46
msgid ""
"*No “bad” outliers*. Again, not actually a technical assumption of the model "
"(or rather, it’s sort of implied by all the others), but there is an "
"implicit assumption that your regression model isn’t being too strongly "
"influenced by one or two anomalous data points because this raises questions "
"about the adequacy of the model and the trustworthiness of the data in some "
"cases. See section :ref:`Three kinds of anomalous data <anomalous_data>`."
msgstr ""
"*“மோசமான” வெளிநாட்டவர்கள் இல்லை*. மீண்டும், உண்மையில் மாதிரியின் தொழில்நுட்ப அனுமானம் அல்ல "
"(அல்லது மாறாக, இது மற்றவர்கள் அனைவராலும் குறிக்கப்பட்டுள்ளது), ஆனால் உங்கள் பின்னடைவு "
"மாதிரி ஒன்று அல்லது இரண்டு முரண்பாடான தரவு புள்ளிகளால் மிகவும் வலுவாக பாதிக்கப்படவில்லை"
" என்ற மறைமுக அனுமானம் உள்ளது, ஏனெனில் இது சில சந்தர்ப்பங்களில் மாதிரியின் போதுமான தன்மை "
"மற்றும் தரவின் நம்பகத்தன்மை குறித்த கேள்விகளை எழுப்புகிறது. பிரிவு: ref ஐப் பார்க்கவும்: "
"`மூன்று வகையான முரண்பாடான தரவு <ஒழுங்கற்ற_டா>`."

#: ../../Ch12/Ch12_Regression_11.rst:4
msgid "Model checking"
msgstr "மாதிரி சோதனை"

#: ../../Ch12/Ch12_Regression_11.rst:6
msgid ""
"The main focus of this section is **regression diagnostics**, a term that "
"refers to the art of checking that the assumptions of your regression model "
"have been met, figuring out how to fix the model if the assumptions are "
"violated, and generally to check that nothing “funny” is going on. I refer "
"to this as the “art” of model checking with good reason. It’s not easy, and "
"while there are a lot of fairly standardised tools that you can use to "
"diagnose and maybe even cure the problems that ail your model (if there are "
"any, that is!), you really do need to exercise a certain amount of judgement "
"when doing this. It’s easy to get lost in all the details of checking this "
"thing or that thing, and it’s quite exhausting to try to remember what all "
"the different things are. This has the very nasty side effect that a lot of "
"people get frustrated when trying to learn *all* the tools, so instead they "
"decide not to do *any* model checking. This is a bit of a worry!"
msgstr ""
"இந்த பிரிவின் முக்கிய கவனம் ** பின்னடைவு கண்டறிதல் ** ஆகும், இது உங்கள் பின்னடைவு "
"மாதிரியின் அனுமானங்கள் நிறைவு செய்யப்பட்டுள்ளதா, அனுமானங்கள் மீறப்பட்டால் மாதிரியை எவ்வாறு "
"சரிசெய்வது என்பதைக் கண்டுபிடிப்பது, பொதுவாகச் சரிபார்க்கும் கலையை குறிக்கிறது "
"“வேடிக்கையானது” எதுவும் நடக்காது என்பதை சரிபார்க்கவும். இதை நான் நல்ல காரணத்துடன் மாதிரி"
" சோதனையின் “கலை” என்று குறிப்பிடுகிறேன். இது எளிதானது அல்ல, மேலும் உங்கள் மாதிரியைக் "
"கண்டறியவும், குணப்படுத்தவும் நீங்கள் பயன்படுத்தக்கூடிய நிறைய தரப்படுத்தப்பட்ட கருவிகள் உள்ளன "
"(ஏதேனும் இருந்தால், அதாவது!), நீங்கள் உண்மையில் ஒரு குறிப்பிட்ட தொகையை உடற்பயிற்சி செய்ய "
"வேண்டும் இதைச் செய்யும்போது தீர்ப்பு. இந்த விசயத்தை அல்லது அந்த விசயத்தை சரிபார்க்கும் அனைத்து"
" விவரங்களிலும் தொலைந்து போவது எளிதானது, மேலும் எல்லா வித்தியாசமான விசயங்களும் என்ன "
"என்பதை நினைவில் வைக்க முயற்சிப்பது மிகவும் சோர்வாக இருக்கிறது. * அனைத்து * கருவிகளையும்"
" கற்றுக்கொள்ள முயற்சிக்கும்போது நிறைய பேர் விரக்தியடைவார்கள், எனவே அதற்கு பதிலாக அவர்கள் *"
" எந்த * மாதிரி சரிபார்ப்பையும் செய்ய வேண்டாம் என்று முடிவு செய்கிறார்கள். இது கொஞ்சம் "
"கவலை!"

#: ../../Ch12/Ch12_Regression_11.rst:21
msgid ""
"In this section I describe several different things you can do to check that "
"your regression model is doing what it’s supposed to. It doesn’t cover the "
"full space of things you could do, but it’s still much more detailed than "
"what I see a lot of people doing in practice, and even I don’t usually cover "
"all of this in my intro stats class either. However, I do think it’s "
"important that you get a sense of what tools are at your disposal, so I’ll "
"try to introduce a bunch of them here. Finally, I should note that this "
"section draws quite heavily from :ref:`Fox and Weisberg (2011) <Fox_2011>`, "
"the book associated with the ``car`` package that is used to conduct "
"regression analysis in R. The ``car`` package is notable for providing some "
"excellent tools for regression diagnostics, and the book itself talks about "
"them in an admirably clear fashion. I don’t want to sound too gushy about "
"it, but I do think that :ref:`Fox and Weisberg (2011) <Fox_2011>` is well "
"worth reading, even if some of the advanced diagnostic techniques are only "
"available in R and not jamovi."
msgstr ""
"இந்த பிரிவில், உங்கள் பின்னடைவு மாதிரி என்ன செய்ய வேண்டும் என்பதைச் சரிபார்க்க நீங்கள் "
"செய்யக்கூடிய பல்வேறு விசயங்களை நான் விவரிக்கிறேன். இது நீங்கள் செய்யக்கூடிய விசயங்களின் "
"முழு இடத்தையும் மறைக்காது, ஆனால் நடைமுறையில் நிறைய பேர் செய்வதை நான் காணுவதை விட இது "
"இன்னும் விரிவானது, மேலும் எனது அறிமுக புள்ளிவிவர வகுப்பிலும் இவை அனைத்தையும் நான் "
"வழக்கமாக மறைக்க மாட்டேன். இருப்பினும், உங்கள் வசம் என்ன கருவிகள் உள்ளன என்பதைப் "
"புரிந்துகொள்வது முதன்மை என்று நான் நினைக்கிறேன், எனவே அவற்றில் ஒரு சிலவற்றை இங்கே "
"அறிமுகப்படுத்த முயற்சிக்கிறேன். இறுதியாக, இந்த பிரிவு மிகவும் பெரிதும் ஈர்க்கிறது என்பதை"
" நான் கவனிக்க வேண்டும்: ref: `ஃபாக்ச் மற்றும் வெயிச்பெர்க் (2011) <fox_2011>`, ஆர். "
"பின்னடைவு கண்டறிதலுக்கான சில சிறந்த கருவிகளை வழங்குவதில் `கார்` தொகுப்பு "
"குறிப்பிடத்தக்கது, மேலும் புத்தகமே அவற்றைப் பற்றி ஒரு தெளிவான பாணியில் பேசுகிறது. நான் "
"இதைப் பற்றி அதிகம் ஒலிக்க விரும்பவில்லை, ஆனால் நான் நினைக்கிறேன்: குறிப்பு: `ஃபாக்ச் மற்றும்"
" வெயிச்பெர்க் (2011) <fox_2011>` சில மேம்பட்ட கண்டறியும் நுட்பங்கள் ஆர் மற்றும் ஆர் மற்றும் "
"ஆர் மற்றும் ஆர் மற்றும் மற்றும் வாசிப்பு மதிப்புக்குரியது என்றாலும் கூட சமோவி அல்ல."

#: ../../Ch12/Ch12_Regression_11.rst:38
msgid "Three kinds of residuals"
msgstr "மூன்று வகையான எச்சங்கள்"

#: ../../Ch12/Ch12_Regression_11.rst:40
msgid ""
"The majority of regression diagnostics revolve around looking at the "
"residuals, and by now you’ve probably formed a sufficiently pessimistic "
"theory of statistics to be able to guess that, precisely *because* of the "
"fact that we care a lot about the residuals, there are several different "
"kinds of residual that we might consider. In particular, the following three "
"kinds of residuals are referred to in this section: “ordinary residuals”, "
"“standardised residuals”, and “Studentised residuals”. There is a fourth "
"kind that you’ll see referred to in some of the Figures, and that’s the "
"“Pearson residual”. However, for the models that we’re talking about in this "
"chapter, the Pearson residual is identical to the ordinary residual."
msgstr ""
"பின்னடைவு கண்டறிதல்கள் பெரும்பாலானவை எச்சங்களைப் பார்ப்பதைச் சுற்றி வருகின்றன, இப்போது நீங்கள்"
" புள்ளிவிவரங்களின் போதுமான அவநம்பிக்கையான கோட்பாட்டை உருவாக்கியிருக்கலாம், அதை யூகிக்க "
"முடியும், துல்லியமாக * ஏனெனில் * எஞ்சியதைப் பற்றி நாங்கள் அதிகம் அக்கறை காட்டுகிறோம், "
"அங்கு, நாம் கருத்தில் கொள்ளக்கூடிய பல்வேறு வகையான எஞ்சியவை. குறிப்பாக, பின்வரும் மூன்று "
"வகையான எச்சங்கள் இந்த பிரிவில் குறிப்பிடப்படுகின்றன: “சாதாரண எச்சங்கள்”, “தரப்படுத்தப்பட்ட "
"எச்சங்கள்” மற்றும் “மாணவர் எஞ்சியவை”. சில புள்ளிவிவரங்களில் நீங்கள் குறிப்பிடப்படும் நான்காவது"
" வகை உள்ளது, அதுதான் “பியர்சன் எஞ்சியவை”. இருப்பினும், இந்த அத்தியாயத்தில் நாம் பேசும் "
"மாதிரிகளுக்கு, பியர்சன் எச்சம் சாதாரண எச்சத்திற்கு ஒத்ததாக இருக்கிறது."

#: ../../Ch12/Ch12_Regression_11.rst:52
msgid ""
"The first and simplest kind of residuals that we care about are **ordinary "
"residuals**. These are the actual raw residuals that I’ve been talking about "
"throughout this chapter so far. The ordinary residual is just the difference "
"between the fitted value *Ŷ*\\ :sub:`i` and the observed value *Y*\\ :sub:"
"`i`. I’ve been using the notation ε\\ :sub:`i` to refer to the i-th ordinary "
"residual, and by gum I’m going to stick to it. With this in mind, we have "
"the very simple equation:"
msgstr ""
"நாங்கள் அக்கறை கொள்ளும் முதல் மற்றும் எளிமையான எச்சங்கள் ** சாதாரண எச்சங்கள் **. இந்த "
"அத்தியாயம் முழுவதும் நான் பேசிக் கொண்டிருந்த உண்மையான மூல எச்சங்கள் இவை. சாதாரண எச்சம் "
"பொருத்தப்பட்ட மதிப்புக்கு இடையேயான வேறுபாடு *ŷ *\\: துணை: `நான்` மற்றும் கவனிக்கப்பட்ட "
"மதிப்பு *y *\\: sub:` i`. நான் ε \\: sub: `நான்` நான் `ஐ-வது சாதாரண எச்சத்தைக் "
"குறிப்பிடுகிறேன், கம் மூலம் நான் அதனுடன் ஒட்டிக்கொள்ளப் போகிறேன். இதைக் கருத்தில் கொண்டு, "
"நம்மிடம் மிகவும் எளிமையான சமன்பாடு உள்ளது:"

#: ../../Ch12/Ch12_Regression_11.rst:62
msgid ""
"This is of course what we saw earlier, and unless I specifically refer to "
"some other kind of residual, this is the one I’m talking about. So there’s "
"nothing new here. I just wanted to repeat myself. One drawback to using "
"ordinary residuals is that they’re always on a different scale, depending on "
"what the outcome variable is and how good the regression model is. That is, "
"unless you’ve decided to run a regression model without an intercept term, "
"the ordinary residuals will have mean 0 but the variance is different for "
"every regression. In a lot of contexts, especially where you’re only "
"interested in the *pattern* of the residuals and not their actual values, "
"it’s convenient to estimate the **standardised residuals**, which are "
"normalised in such a way as to have standard deviation 1."
msgstr ""
"இது நிச்சயமாக நாங்கள் முன்பு பார்த்தது, வேறு சில வகையான எஞ்சியவற்றைக் குறிப்பிடாவிட்டால்"
", இதுதான் நான் பேசுகிறேன். எனவே இங்கே புதிதாக எதுவும் இல்லை. நான் என்னை மீண்டும் செய்ய "
"விரும்பினேன். சாதாரண எச்சங்களைப் பயன்படுத்துவதில் ஒரு குறைபாடு என்னவென்றால், அவை எப்போதும்"
" வேறு அளவில் இருக்கும், விளைவு மாறி என்றால் என்ன, பின்னடைவு மாதிரி எவ்வளவு நல்லது "
"என்பதைப் பொறுத்து. அதாவது, இடைமறிப்பு காலப்படி இல்லாமல் பின்னடைவு மாதிரியை இயக்க நீங்கள் "
"முடிவு செய்தாலொழிய, சாதாரண எச்சங்கள் சராசரி 0 ஐக் கொண்டிருக்கும், ஆனால் ஒவ்வொரு "
"பின்னடைவுக்கும் மாறுபாடு வேறுபட்டது. நிறைய சூழல்களில், குறிப்பாக நீங்கள் "
"எச்சங்களின்*வடிவத்தில் மட்டுமே ஆர்வமாக உள்ளீர்கள், அவற்றின் உண்மையான மதிப்புகள் அல்ல, ** "
"தரப்படுத்தப்பட்ட எச்சங்கள் ** ஐ மதிப்பிடுவது வசதியானது, அவை தரமானதாக இருக்கும் வகையில் "
"இயல்பாக்கப்படுகின்றன விலகல் 1."

#: ../../Ch12/Ch12_Regression_11.rst:75
msgid ""
"The way we calculate these is to divide the ordinary residual by an estimate "
"of the (population) standard deviation of these residuals. For technical "
"reasons, mumble mumble, the formula for this is:"
msgstr ""
"இவற்றைக் கணக்கிடும் வழி, இந்த எச்சங்களின் (மக்கள் தொகை) நிலையான விலகலின் மதிப்பீட்டால் சாதா"
"ரண எச்சத்தை பிரிப்பதாகும். தொழில்நுட்ப காரணங்களுக்காக, முணுமுணுப்பு முணுமுணுப்பு, இதற்கா"
"ன சூத்திரம்:"

#: ../../Ch12/Ch12_Regression_11.rst:79
msgid ""
"ε\\ :sub:`i`\\' = :math:`\\frac{\\epsilon_i}{\\hat{\\sigma} \\sqrt{1-h_i}}`"
msgstr ""
"ε\\ :sub:`i`\\' = :math:`\\frac{\\epsilon_i}{\\hat{\\sigma} \\sqrt{1-h_i}}`"

#: ../../Ch12/Ch12_Regression_11.rst:81
msgid ""
"where :math:`\\hat\\sigma` in this context is the estimated population "
"standard deviation of the ordinary residuals, and h\\ :sub:`i` is the “hat "
"value” of the *i*-th observation. I haven’t explained hat values to you yet "
"(but have no fear,\\ [#]_ it’s coming shortly), so this won’t make a lot of "
"sense. For now, it’s enough to interpret the standardised residuals as if "
"we’d converted the ordinary residuals to *z*-scores. In fact, that is more "
"or less the truth, it’s just that we’re being a bit fancier."
msgstr ""
"எங்கே: கணிதம்: `\\ தொப்பி \\ சிக்மா` இந்த சூழலில் சாதாரண எச்சங்களின் மதிப்பிடப்பட்ட "
"மக்கள்தொகை நிலையான விலகல், மற்றும் h \\: துணை:` நான் *i *-th அவதானிப்பின் “தொப்பி "
"மதிப்பு”. நான் இன்னும் தொப்பி மதிப்புகளை உங்களுக்கு விளக்கவில்லை (ஆனால் அச்சம் இல்லை, \\ "
"[#] _ இது விரைவில் வருகிறது), எனவே இது நிறைய அர்த்தத்தை ஏற்படுத்தாது. இப்போதைக்கு, "
"தரப்படுத்தப்பட்ட எச்சங்களை நாம் சாதாரண எச்சங்களை *z *-ச்கோர்களாக மாற்றுவது போல விளக்கினால் "
"போதும். உண்மையில், இது உண்மையை அதிகமாகவோ அல்லது குறைவாகவோ இல்லை, நாங்கள் கொஞ்சம் ஆர்வமா"
"க இருக்கிறோம்."

#: ../../Ch12/Ch12_Regression_11.rst:89
msgid ""
"The third kind of residuals are **Studentised residuals** (also called "
"“jackknifed residuals”) and they’re even fancier than standardised "
"residuals. Again, the idea is to take the ordinary residual and divide it by "
"some quantity in order to estimate some standardised notion of the residual."
msgstr ""
"மூன்றாவது வகையான எச்சங்கள் ** மாணவர்களின் எச்சங்கள் ** (“சாக்னிஃப்ட் எஞ்சியவர்கள்” என்றும் "
"அழைக்கப்படுகின்றன) மற்றும் அவை தரப்படுத்தப்பட்ட எச்சங்களை விட ஆர்வமாக உள்ளன. மீண்டும், மீதமுள்"
"ள சில தரப்படுத்தப்பட்ட கருத்தை மதிப்பிடுவதற்காக சாதாரண எஞ்சியவற்றை எடுத்து அதை ஓரளவு "
"பிரிக்க வேண்டும் என்பதே சிந்தனை."

#: ../../Ch12/Ch12_Regression_11.rst:94
msgid "The formula for doing the calculations this time is subtly different"
msgstr "இந்த நேரத்தில் கணக்கீடுகளைச் செய்வதற்கான தேற்றம் நுட்பமாக வேறுபட்டது"

#: ../../Ch12/Ch12_Regression_11.rst:96
msgid ""
"\\epsilon_{i}^* = \\frac{\\epsilon_i}{\\hat{\\sigma}_{(-i)} \\sqrt{1-h_i}}\n"
"\n"
msgstr ""
"\\epsilon_{i}^* = \\frac{\\epsilon_i}{\\hat{\\sigma}_{(-i)} \\sqrt{1-h_i}}\n"
"\n"

#: ../../Ch12/Ch12_Regression_11.rst:98
msgid ""
"Notice that our estimate of the standard deviation here is written :math:"
"`\\hat{\\sigma}_{(-i)}`. What this corresponds to is the estimate of the "
"residual standard deviation that you *would have obtained* if you just "
"deleted the i\\ th observation from the data set. This sounds like the sort "
"of thing that would be a nightmare to calculate, since it seems to be saying "
"that you have to run *N* new regression models (even a modern computer might "
"grumble a bit at that, especially if you’ve got a large data set). "
"Fortunately, some terribly clever person has shown that this standard "
"deviation estimate is actually given by the following equation:"
msgstr ""
"இங்கே நிலையான விலகல் பற்றிய எங்கள் மதிப்பீடு எழுதப்பட்டிருப்பதைக் கவனியுங்கள்: கணிதம்: `\\ "
"தொப்பி {\\ சிக்மா} _ {(-i)}`. தரவுத் தொகுப்பிலிருந்து i \\ th அவதானிப்பை நீக்கியால், "
"நீங்கள் பெற்றிருக்கும் மீதமுள்ள நிலையான விலகலின் மதிப்பீடு இது. இது கணக்கிட ஒரு கனவாக "
"இருக்கும், ஏனெனில் நீங்கள் * n * புதிய பின்னடைவு மாதிரிகளை இயக்க வேண்டும் என்று "
"கூறுவதாகத் தெரிகிறது (ஒரு நவீன கணினி கூட கொஞ்சம் முணுமுணுக்கக்கூடும், குறிப்பாக "
"உங்களுக்கு கிடைத்திருந்தால் ஒரு பெரிய தரவு தொகுப்பு). அதிர்ச்டவசமாக, சில பயங்கரமான "
"புத்திசாலித்தனமான நபர் இந்த நிலையான விலகல் மதிப்பீடு உண்மையில் பின்வரும் சமன்பாட்டால் "
"வழங்கப்படுகிறது என்பதைக் காட்டியுள்ளார்:"

#: ../../Ch12/Ch12_Regression_11.rst:109
msgid ""
"\\hat\\sigma_{(-i)} = \\hat{\\sigma} \\ \\sqrt{\\frac{N-K-1 - {\\epsilon_{i}"
"^\\prime}^2}{N-K-2}}\n"
"\n"
msgstr ""
"\\hat\\sigma_{(-i)} = \\hat{\\sigma} \\ \\sqrt{\\frac{N-K-1 - {\\epsilon_{i}^"
"\\prime}^2}{N-K-2}}\n"
"\n"

#: ../../Ch12/Ch12_Regression_11.rst:111
msgid "Isn’t that a pip?"
msgstr "அது ஒரு குழாய் இல்லையா?"

#: ../../Ch12/Ch12_Regression_11.rst:113
msgid ""
"Before moving on, I should point out that you don’t often need to obtain "
"these residuals yourself, even though they are at the heart of almost all "
"regression diagnostics. Most of the time the various options that provide "
"the diagnostics, or assumption checks, will take care of these calculations "
"for you. Even so, it’s always nice to know how to actually get hold of these "
"things yourself in case you ever need to do something non-standard."
msgstr ""
"நகர்வதற்கு முன், இந்த எச்சங்களை நீங்கள் அடிக்கடி பெற வேண்டிய அவசியமில்லை என்பதை நான் "
"சுட்டிக்காட்ட வேண்டும், அவை கிட்டத்தட்ட எல்லா பின்னடைவு கண்டறியும் இதயத்திலும் இருந்தாலும். "
"கண்டறியும் அல்லது அனுமான சோதனைகளை வழங்கும் பல்வேறு விருப்பங்கள் உங்களுக்காக இந்த "
"கணக்கீடுகளை கவனித்துக்கொள்ளும். அப்படியிருந்தும், நீங்கள் எப்போதாவது தரமற்ற ஒன்றைச் செய்ய "
"வேண்டியிருந்தால், இந்த விசயங்களை எவ்வாறு நீங்களே வைத்திருப்பது என்பதை அறிந்து கொள்வது "
"எப்போதுமே மகிழ்ச்சியாக இருக்கிறது."

#: ../../Ch12/Ch12_Regression_11.rst:124
msgid "Three kinds of anomalous data"
msgstr "மூன்று வகையான ஒழுங்கற்ற தரவு"

#: ../../Ch12/Ch12_Regression_11.rst:126
msgid ""
"One danger that you can run into with linear regression models is that your "
"analysis might be disproportionately sensitive to a smallish number of "
"“unusual” or “anomalous” observations. I discussed this idea previously in "
"subsection :ref:`Using box plots to detect outliers "
"<box_plots_detect_outliers>` in the context of discussing the outliers that "
"get automatically identified by the ``Box plot`` option under "
"``Exploration`` → ``Descriptives``, but this time we need to be much more "
"precise. In the context of linear regression, there are three conceptually "
"distinct ways in which an observation might be called “anomalous”. All three "
"are interesting, but they have rather different implications for your "
"analysis."
msgstr ""
"நேரியல் பின்னடைவு மாதிரிகளுடன் நீங்கள் இயக்கக்கூடிய ஒரு இடர் என்னவென்றால், உங்கள் பகுப்பாய்வு"
" ஒரு சிறிய எண்ணிக்கையிலான “அசாதாரண” அல்லது “முரண்பாடான” அவதானிப்புகளுக்கு "
"விகிதாசாரமாக உணர்திறன் கொண்டதாக இருக்கலாம். இந்த யோசனையை நான் முன்பு உட்பிரிவில் "
"விவாதித்தேன்: ren: `வெளியீட்டாளர்களைக் கண்டறிய பெட்டி அடுக்குகளைப் பயன்படுத்துதல் "
"<box_plots_detect_outliers>` `` ஆய்வு` `` `` `` `` `` பெட்டி சதி`` விருப்பத்தால் "
"தானாக அடையாளம் காணப்படும் வெளிநாட்டினரைப் பற்றி விவாதிக்கும் சூழலில் விளக்கங்கள்``, ஆனால் "
"இந்த நேரத்தில் நாம் மிகவும் துல்லியமாக இருக்க வேண்டும். நேரியல் பின்னடைவின் சூழலில், ஒரு "
"அவதானிப்பு \"முரண்பாடு\" என்று அழைக்கப்படும் மூன்று கருத்தியல் ரீதியாக வேறுபட்ட வழிகள் உள்"
"ளன. மூன்றும் சுவாரச்யமானவை, ஆனால் அவை உங்கள் பகுப்பாய்விற்கு வேறுபட்ட தாக்கங்களைக் "
"கொண்டுள்ளன."

#: ../../Ch12/Ch12_Regression_11.rst:138
msgid ""
"The first kind of unusual observation is an **outlier**. The definition of "
"an outlier (in this context) is an observation that is very different from "
"what the regression model predicts. An example is shown in :numref:`fig-"
"outlier`. In practice, we operationalise this concept by saying that an "
"outlier is an observation that has a very large Studentised residual, ε\\ :"
"sub:`i`\\ :sup:`*`. Outliers are interesting: a big outlier *might* "
"correspond to junk data, e.g., the variables might have been recorded "
"incorrectly in the data set, or some other defect may be detectable. Note "
"that you shouldn’t throw an observation away just because it’s an outlier. "
"But the fact that it’s an outlier is often a cue to look more closely at "
"that case and try to find out why it’s so different."
msgstr ""
"முதல் வகையான அசாதாரண அவதானிப்பு ஒரு ** வெளிநாட்டவர் **. ஒரு வெளிநாட்டவரின் வரையறை "
"(இந்த சூழலில்) பின்னடைவு மாதிரி கணித்ததிலிருந்து மிகவும் வேறுபட்ட ஒரு அவதானிப்பாகும். "
"ஒரு எடுத்துக்காட்டு இதில் காட்டப்பட்டுள்ளது: NumRef: `Fig-outlier`. நடைமுறையில், ஒரு "
"வெளிநாட்டவர் என்பது மிகப் பெரிய மாணவர் எஞ்சியிருக்கும் ஒரு அவதானிப்பு என்று கூறி இந்த "
"கருத்தை நாங்கள் செயல்படுத்துகிறோம், ε \\: துணை: `நான் \\: sup:`*`. வெளியீட்டாளர்கள் "
"சுவாரச்யமானவர்கள்: ஒரு பெரிய வெளிநாட்டவர் * குப்பை தரவுகளுடன் ஒத்திருக்கலாம், எ.கா., "
"தரவுத் தொகுப்பில் மாறிகள் தவறாக பதிவு செய்யப்பட்டிருக்கலாம் அல்லது வேறு சில குறைபாடுகள் "
"கண்டறியப்படலாம். இது ஒரு வெளிநாட்டவர் என்பதால் நீங்கள் ஒரு கவனிப்பை தூக்கி எறியக்கூடாது "
"என்பதை நினைவில் கொள்க. ஆனால் இது ஒரு வெளிநாட்டவர் என்பது பெரும்பாலும் அந்த விசயத்தை "
"மிகவும் நெருக்கமாகப் பார்த்து, அது ஏன் மிகவும் வித்தியாசமானது என்பதைக் கண்டுபிடிக்க "
"முயற்சிப்பது பெரும்பாலும் ஒரு குறிப்பாகும்."

#: ../../Ch12/Ch12_Regression_11.rst:153
msgid "Outliers and their effect"
msgstr "வெளிநாட்டவர்கள் மற்றும் அவற்றின் விளைவு"

#: ../../Ch12/Ch12_Regression_11.rst:157
msgid ""
"Illustration of outliers: The dotted lines plot the regression line that "
"would have been estimated without the anomalous observation included, and "
"the corresponding residual (i.e., the Studentised residual). The solid line "
"shows the regression line with the anomalous observation included. The "
"outlier has an unusual value on the outcome (y axis location) but not the "
"predictor (x axis location), and lies a long way from the regression line."
msgstr ""
"வெளியீட்டாளர்களின் விளக்கம்: புள்ளியிடப்பட்ட கோடுகள் சேர்க்கப்பட்ட ஒழுங்கற்ற கண்காணிப்பு இல்லாமல்"
" மதிப்பிடப்பட்ட பின்னடைவு கோட்டை சூழ்ச்சி செய்கின்றன, மேலும் அதனுடன் தொடர்புடைய எஞ்சியவை "
"(அதாவது, மாணவர் எஞ்சியவை). திடமான வரி சேர்க்கப்பட்ட முரண்பாடான கண்காணிப்புடன் பின்னடைவு "
"கோட்டைக் காட்டுகிறது. வெளிநாட்டவர் விளைவு (y அச்சு இருப்பிடம்) மீது அசாதாரண மதிப்பைக் "
"கொண்டுள்ளது, ஆனால் முன்கணிப்பு (x அச்சு இருப்பிடம்) அல்ல, மேலும் பின்னடைவு வரியிலிருந்து "
"நீண்ட தூரம் உள்ளது."

#: ../../Ch12/Ch12_Regression_11.rst:169
msgid "High leverage points and their effect"
msgstr "அதிக அந்நிய புள்ளிகள் மற்றும் அவற்றின் விளைவு"

#: ../../Ch12/Ch12_Regression_11.rst:173
msgid ""
"Illustration of high leverage points: The anomalous observation in this case "
"is unusual both in terms of the predictor (x axis) and the outcome (y axis), "
"but this unusualness is highly consistent with the pattern of correlations "
"that exists among the other observations. The observation falls very close "
"to the regression line and does not distort it."
msgstr ""
"உயர் அந்நியச் செலாவணி புள்ளிகளின் விளக்கம்: இந்த விசயத்தில் முரண்பாடான அவதானிப்பு "
"முன்கணிப்பு (x அச்சு) மற்றும் விளைவு (y அச்சு) ஆகியவற்றின் அடிப்படையில் அசாதாரணமானது, "
"ஆனால் இந்த அசாதாரணமானது மற்ற அவதானிப்புகளிடையே இருக்கும் தொடர்புகளின் வடிவத்துடன் "
"மிகவும் ஒத்துப்போகிறது. அவதானிப்பு பின்னடைவு கோட்டிற்கு மிக அருகில் விழுந்து அதை "
"சிதைக்காது."

#: ../../Ch12/Ch12_Regression_11.rst:181
msgid ""
"The second way in which an observation can be unusual is if it has high "
"**leverage**, which happens when the observation is very different from all "
"the other observations. This doesn’t necessarily have to correspond to a "
"large residual. If the observation happens to be unusual on all variables in "
"precisely the same way, it can actually lie very close to the regression "
"line. An example of this is shown in :numref:`fig-leverage`. The leverage of "
"an observation is operationalised in terms of its *hat value*, usually "
"written h\\ :sub:`i`. The formula for the hat value is rather complicated,\\ "
"[#]_ but it interpretation is not: h\\ :sub:`i` is a measure of the extent "
"to which the *i*-th observation is “in control” of where the regression line "
"ends up going."
msgstr ""
"ஒரு அவதானிப்பு அசாதாரணமானதாக இருக்கக்கூடிய இரண்டாவது வழி, அது அதிக ** அந்நியச் "
"செலாவணி ** ஐக் கொண்டிருந்தால், மற்ற எல்லா அவதானிப்புகளிலிருந்தும் அவதானிப்பு மிகவும் "
"வித்தியாசமாக இருக்கும்போது நிகழ்கிறது. இது ஒரு பெரிய எச்சத்துடன் ஒத்துப்போக வேண்டிய "
"அவசியமில்லை. எல்லா மாறிகளிலும் துல்லியமாக அதே வழியில் அவதானிப்பு அசாதாரணமானது என்றால்"
", அது உண்மையில் பின்னடைவு வரிக்கு மிக நெருக்கமாக இருக்கும். இதற்கு ஒரு எடுத்துக்காட்டு "
"இதில் காட்டப்பட்டுள்ளது: NumRef: `Fig-leverage`. ஒரு அவதானிப்பின் அந்நியச் செலாவணி அதன்"
" *தொப்பி மதிப்பின் அடிப்படையில் செயல்படுத்தப்படுகிறது, பொதுவாக எழுதப்பட்ட h \\: துணை: "
"`i`. தொப்பி மதிப்பிற்கான தேற்றம் மிகவும் சிக்கலானது, \\ [#] _ ஆனால் அது விளக்கம் இல்லை: "
"H \\: துணை: `நான் *i *-th அவதானிப்பு எந்த அளவிற்கு“ கட்டுப்பாட்டில் ”உள்ளது என்பதற்கான "
"ஒரு அளவீடு பின்னடைவு வரி செல்லும் இடத்தில்."

#: ../../Ch12/Ch12_Regression_11.rst:192
msgid ""
"In general, if an observation lies far away from the other ones in terms of "
"the predictor variables, it will have a large hat value (as a rough guide, "
"high leverage is when the hat value is more than 2 - 3 times the average; "
"and note that the sum of the hat values is constrained to be equal to *K* + "
"1). High leverage points are also worth looking at in more detail, but "
"they’re much less likely to be a cause for concern unless they are also "
"outliers."
msgstr ""
"பொதுவாக, முன்கணிப்பு மாறிகள் அடிப்படையில் ஒரு அவதானிப்பு மற்றவற்றிலிருந்து வெகு "
"தொலைவில் இருந்தால், அது ஒரு பெரிய தொப்பி மதிப்பைக் கொண்டிருக்கும் (ஒரு கடினமான "
"வழிகாட்டியாக, தொப்பி மதிப்பு சராசரியை விட 2 - 3 மடங்கு அதிகமாக இருக்கும்போது அதிக "
"அந்நியச் செலாவணி; தொப்பி மதிப்புகளின் தொகை * k * + 1 க்கு சமமாக இருக்க வேண்டும் என்பதை "
"நினைவில் கொள்க). அதிக அந்நியச் செலாவணி புள்ளிகளும் இன்னும் விரிவாகப் பார்க்க வேண்டியவை, "
"ஆனால் அவை வெளிநாட்டவர்களாக இல்லாவிட்டால் அவை கவலைக்கு ஒரு காரணமாக இருப்பதற்கான "
"வாய்ப்புகள் மிகக் குறைவு."

#: ../../Ch12/Ch12_Regression_11.rst:201
msgid "High influence points and their effect"
msgstr "அதிக செல்வாக்கு புள்ளிகள் மற்றும் அவற்றின் விளைவு"

#: ../../Ch12/Ch12_Regression_11.rst:205
msgid ""
"Illustration of high influence points: In this case, the anomalous "
"observation is highly unusual on the predictor variable (x axis), and falls "
"a long way from the regression line. As a consequence, the regression line "
"is highly distorted, even though (in this case) the anomalous observation is "
"entirely typical in terms of the outcome variable (y axis)."
msgstr ""
"அதிக செல்வாக்கு புள்ளிகளின் விளக்கம்: இந்த விசயத்தில், முன்கணிப்பு மாறியில் (எக்ச் அச்சு) "
"முரண்பாடான அவதானிப்பு மிகவும் அசாதாரணமானது, மேலும் பின்னடைவு வரியிலிருந்து நீண்ட தூரம்"
" விழுகிறது. இதன் விளைவாக, பின்னடைவு வரி மிகவும் சிதைந்துவிட்டது, (இந்த விசயத்தில்) "
"முரண்பாடான அவதானிப்பு விளைவு மாறியின் (Y அச்சு) அடிப்படையில் முற்றிலும் பொதுவானது."

#: ../../Ch12/Ch12_Regression_11.rst:213
msgid ""
"This brings us to our third measure of unusualness, the **influence** of an "
"observation. A high influence observation is an outlier that has high "
"leverage. That is, it is an observation that is very different to all the "
"other ones in some respect, and also lies a long way from the regression "
"line. This is illustrated in :numref:`fig-influence`. Notice the contrast to "
"the previous two figures. Outliers don’t move the regression line much and "
"neither do high leverage points. But something that is both an outlier and "
"has high leverage, well that has a big effect on the regression line. That’s "
"why we call these points high influence, and it’s why they’re the biggest "
"worry. We operationalise influence in terms of a measure known as **Cook’s "
"distance**."
msgstr ""
"இது எங்கள் மூன்றாவது சிறப்பான, ஒரு அவதானிப்பின் ** செல்வாக்கு ** க்கு நம்மை அழைத்துச் "
"செல்கிறது. அதிக செல்வாக்கு கண்காணிப்பு என்பது அதிக அந்நியச் செலாவணியைக் கொண்ட ஒரு "
"வெளிநாட்டவர். அதாவது, இது ஒரு அவதானிப்பாகும், இது மற்ற எல்லா இடங்களுக்கும் மிகவும் "
"வித்தியாசமானது, மேலும் பின்னடைவு வரியிலிருந்து நீண்ட தூரம் உள்ளது. இது இதில் "
"விளக்கப்பட்டுள்ளது: NumRef: `Fig-CONFLUENCE`. முந்தைய இரண்டு புள்ளிவிவரங்களுக்கு "
"மாறுபாட்டைக் கவனியுங்கள். வெளியீட்டாளர்கள் பின்னடைவு வரியை அதிகம் நகர்த்த மாட்டார்கள், மேலும்"
" அதிக அந்நியச் செலாவணி புள்ளிகள் இல்லை. ஆனால் ஒரு வெளிநாட்டவர் மற்றும் அதிக அந்நியச் "
"செலாவணி ஆகியவற்றைக் கொண்ட ஒன்று, இது பின்னடைவு வரியில் ஒரு பெரிய விளைவைக் கொண்டுள்ளது"
". அதனால்தான் இந்த புள்ளிகள் அதிக செல்வாக்கு என்று நாங்கள் அழைக்கிறோம், அதனால்தான் அவை "
"மிகப்பெரிய கவலை. ** குக்கின் தூரம் ** எனப்படும் ஒரு நடவடிக்கையின் அடிப்படையில் நாங்கள் "
"செல்வாக்கை செயல்படுத்துகிறோம்."

#: ../../Ch12/Ch12_Regression_11.rst:224
msgid ""
"D_i = \\frac{{\\epsilon_i^*}^2 }{K+1} \\times \\frac{h_i}{1-h_i}\n"
"\n"
msgstr ""
"D_i = \\frac{{\\epsilon_i^*}^2 }{K+1} \\times \\frac{h_i}{1-h_i}\n"
"\n"

#: ../../Ch12/Ch12_Regression_11.rst:226
msgid ""
"Notice that this is a multiplication of something that measures the outlier-"
"ness of the observation (the bit on the left), and something that measures "
"the leverage of the observation (the bit on the right)."
msgstr ""
"இது அவதானிப்பின் வெளிநாட்டவர் (இடதுபுறத்தில் பிட்) அளவிடும் ஒன்றின் பெருக்கம் என்பதைக் "
"கவனியுங்கள், மேலும் அவதானிப்பின் திறனை அளவிடும் ஒன்று (வலதுபுறத்தில் பிட்)."

#: ../../Ch12/Ch12_Regression_11.rst:230
msgid ""
"In order to have a large Cook’s distance an observation must be a fairly "
"substantial outlier *and* have high leverage. As a rough guide, Cook’s "
"distance greater than 1 is often considered large (that’s what I typically "
"use as a quick and dirty rule)."
msgstr ""
"ஒரு பெரிய சமையல்காரரின் தூரம் இருக்க ஒரு அவதானிப்பு மிகவும் கணிசமான வெளிநாட்டவராக "
"இருக்க வேண்டும் * மற்றும் * அதிக அந்நியச் செலாவணியைக் கொண்டிருக்க வேண்டும். ஒரு கடினமான "
"வழிகாட்டியாக, குக்கின் தூரம் 1 ஐ விட அதிகமாக பெரியதாகக் கருதப்படுகிறது (இதுதான் நான் "
"பொதுவாக விரைவான மற்றும் அழுக்கான விதியாகப் பயன்படுத்துகிறேன்)."

#: ../../Ch12/Ch12_Regression_11.rst:235
msgid ""
"In jamovi, information about Cook’s distance can be calculated by clicking "
"on the ``Cook’s Distance`` checkbox in the ``Assumption Checks`` → ``Data "
"Summary`` options. When you do this, for the multiple regression model we "
"have been using as an example in this chapter, you get the results as shown "
"in :numref:`fig-reg4`\\."
msgstr ""
"சாமோவியில், `` அனுமான காசோலைகள்` `` தரவு சுருக்கம்`` விருப்பங்களில் `` சமையல்காரரின் "
"தூரம்`` தேர்வுப்பெட்டியைக் சொடுக்கு செய்வதன் மூலம் குக்கின் தூரத்தைப் பற்றிய தகவல்களைக் கணக்கி"
"ட முடியும். நீங்கள் இதைச் செய்யும்போது, இந்த அத்தியாயத்தில் நாங்கள் ஒரு எடுத்துக்காட்டு எனப் "
"பயன்படுத்திக் கொண்டிருக்கும் பல பின்னடைவு மாதிரிக்கு, காட்டப்பட்டுள்ளபடி முடிவுகளைப் "
"பெறுவீர்கள்: numref: `fig-reg4` \\."

#: ../../Ch12/Ch12_Regression_11.rst:243 ../../Ch12/Ch12_Regression_11.rst:247
msgid "jamovi output showing the table for the Cook’s distance statistics"
msgstr "குக்கின் தூர புள்ளிவிவரங்களுக்கான அட்டவணையைக் காட்டும் சாமோவி வெளியீடு"

#: ../../Ch12/Ch12_Regression_11.rst:251
msgid ""
"You can see that, in this example, the mean Cook’s distance value is 0.01, "
"and the range is from 0.00000262 to 0.11, so this is some way off the rule "
"of thumb figure mentioned above that a Cook’s distance greater than 1 is "
"considered large."
msgstr ""
"இந்த எடுத்துக்காட்டில், சராசரி சமையல்காரரின் தூர மதிப்பு 0.01, மற்றும் வரம்பு "
"0.00000262 முதல் 0.11 வரை இருப்பதை நீங்கள் காணலாம், எனவே இது ஒரு சமையல்காரரின் தூரம் "
"1 ஐ விட பெரியதாகக் கருதப்படுகிறது."

#: ../../Ch12/Ch12_Regression_11.rst:256
msgid ""
"An obvious question to ask next is, if you do have large values of Cook’s "
"distance what should you do? As always, there’s no hard and fast rule. "
"Probably the first thing to do is to try running the regression with the "
"outlier with the greatest Cook’s distance\\ [#]_ excluded and see what "
"happens to the model performance and to the regression coefficients. If they "
"really are substantially different, it’s time to start digging into your "
"data set and your notes that you no doubt were scribbling as your ran your "
"study. Try to figure out *why* the point is so different. If you start to "
"become convinced that this one data point is badly distorting your results "
"then you might consider excluding it, but that’s less than ideal unless you "
"have a solid explanation for why this particular case is qualitatively "
"different from the others and therefore deserves to be handled separately."
msgstr ""
"அடுத்து கேட்க ஒரு வெளிப்படையான கேள்வி என்னவென்றால், உங்களிடம் குக்கின் தூரத்தின் பெரிய "
"மதிப்புகள் இருந்தால் நீங்கள் என்ன செய்ய வேண்டும்? எப்போதும் போல, கடினமான மற்றும் வேகமான விதி"
" இல்லை. மிகப் பெரிய சமையல்காரரின் தூரத்துடன் வெளிப்புற நபருடன் பின்னடைவை இயக்க "
"முயற்சிப்பது \\ [#] _ விலக்கப்பட்டு, மாதிரி செயல்திறனுக்கும் பின்னடைவு குணகங்களுக்கும் என்"
"ன நடக்கிறது என்பதைப் பாருங்கள். அவை உண்மையிலேயே கணிசமாக வேறுபட்டவை என்றால், உங்கள் தரவுத்"
" தொகுப்பைத் தோண்டத் தொடங்குவதற்கான நேரம் இது மற்றும் உங்கள் குறிப்புகள் உங்கள் ஆய்வை "
"இயக்கியதால் நீங்கள் எழுதுகிறீர்கள் என்பதில் சந்தேகமில்லை. * ஏன் * புள்ளி மிகவும் "
"வித்தியாசமானது என்பதைக் கண்டுபிடிக்க முயற்சி செய்யுங்கள். இந்த ஒரு தரவு புள்ளி உங்கள் "
"முடிவுகளை மோசமாக சிதைக்கிறது என்று நீங்கள் உறுதியாக நம்பத் தொடங்கினால், அதைத் தவிர்ப்பதை "
"நீங்கள் கருத்தில் கொள்ளலாம், ஆனால் இந்த குறிப்பிட்ட வழக்கு ஏன் மற்றவர்களிடமிருந்து தர ரீதியாக "
"வேறுபட்டது என்பதற்கு உங்களுக்கு உறுதியான விளக்கம் இல்லாவிட்டால் அது இலட்சியத்தை விடக் "
"குறைவானது, எனவே இருக்க தகுதியானது தனித்தனியாக கையாளப்படுகிறது."

#: ../../Ch12/Ch12_Regression_11.rst:272
msgid "Checking the normality of the residuals"
msgstr "எச்சங்களின் இயல்பான தன்மையை சரிபார்க்கிறது"

#: ../../Ch12/Ch12_Regression_11.rst:274
msgid ""
"Like many of the statistical tools we’ve discussed in this book, regression "
"models rely on a normality assumption. In this case, we assume that the "
"residuals are normally distributed. The first thing we can do is draw a QQ-"
"plot via the ``Assumption Checks`` → ``Q-Q plot of residuals`` option."
msgstr ""
"இந்த புத்தகத்தில் நாங்கள் விவாதித்த பல புள்ளிவிவர கருவிகளைப் போலவே, பின்னடைவு மாதிரிகள் "
"ஒரு இயல்பான அனுமானத்தை நம்பியுள்ளன. இந்த வழக்கில், எச்சங்கள் பொதுவாக விநியோகிக்கப்படுகின்"
"றன என்று நாங்கள் கருதுகிறோம். நாம் செய்யக்கூடிய முதல் சேதி `` அனுமான காசோலைகள்` `` `Q-"
"Q எச்சங்கள்` `விருப்பத்தின் வழியாக QQ- அடுக்கை வரைய வேண்டும்."

#: ../../Ch12/Ch12_Regression_11.rst:279
msgid ""
"The output is shown in :numref:`fig-reg5`, showing the standardised "
"residuals plotted as a function of their theoretical quantiles according to "
"the regression model."
msgstr ""
"வெளியீடு இதில் காட்டப்பட்டுள்ளது: NUMREF: `Fig-reg5`, பின்னடைவு மாதிரியின் படி அவற்றின்"
" தத்துவார்த்த அளவுகளின் செயல்பாடாக திட்டமிடப்பட்ட தரப்படுத்தப்பட்ட எச்சங்களை காட்டுகிறது."

#: ../../Ch12/Ch12_Regression_11.rst:285
msgid "Quantiles according to the model against standardised residuals"
msgstr "தரப்படுத்தப்பட்ட எச்சங்களுக்கு எதிரான மாதிரியின் படி அளவுகள்"

#: ../../Ch12/Ch12_Regression_11.rst:289
msgid ""
"Plot of the theoretical quantiles according to the model, against the "
"quantiles of the standardised residuals, produced in jamovi"
msgstr ""
"சமோவியில் விளைவாக்கம் செய்யப்படும் தரப்படுத்தப்பட்ட எச்சங்களின் அளவுகளுக்கு எதிராக, "
"மாதிரியின் படி தத்துவார்த்த அளவுகளின் சூழ்ச்சி"

#: ../../Ch12/Ch12_Regression_11.rst:294
msgid ""
"Another thing we should check is the relationship between the fitted values "
"and the residuals themselves. We can get jamovi to do this using the "
"``Residuals Plots`` option, which provides a scatterplot for each predictor "
"variable, the outcome variable, and the fitted values against residuals, "
"see :numref:`fig-reg6`. In these plots we are looking for a fairly uniform "
"distribution of “dots”, with no clear bunching or patterning of the “dots”. "
"Looking at these plots, there is nothing particularly worrying as the dots "
"are fairly evenly spread across the whole plot. There may be a little bit of "
"non-uniformity in the right panel, but it is not a strong deviation and "
"probably not worth worrying about."
msgstr ""
"நாம் சரிபார்க்க வேண்டிய மற்றொரு சேதி, பொருத்தப்பட்ட மதிப்புகளுக்கும் எச்சங்களுக்கும் இடையிலா"
"ன உறவு. ஒவ்வொரு முன்கணிப்பு மாறி, விளைவு மாறி மற்றும் எஞ்சியவர்களுக்கு எதிராக "
"பொருத்தப்பட்ட மதிப்புகள் ஆகியவற்றிற்கும் ஒரு சிதறல் பிளாட் வழங்கும் `` எச்சங்கள் அடுக்கு` "
"விருப்பத்தைப் பயன்படுத்தி இதைச் செய்ய சாமோவியைப் பெறலாம், பார்க்க: எண்: `Fig-reg6`. இந்த "
"அடுக்குகளில், “புள்ளிகளின்” தெளிவான கொத்து அல்லது வடிவமைத்தல் இல்லாமல், “புள்ளிகளின்” ஒரே"
" மாதிரியான விநியோகத்தை நாங்கள் தேடுகிறோம். இந்த அடுக்குகளைப் பார்க்கும்போது, புள்ளிகள் "
"முழு சதித்திட்டத்திலும் மிகவும் சமமாக பரவுவதால் குறிப்பாக கவலைப்படவில்லை. வலது பேனலில் "
"சீரான தன்மை இல்லாதது கொஞ்சம் இருக்கலாம், ஆனால் இது ஒரு வலுவான விலகல் அல்ல, அதைப் பற்றி "
"கவலைப்படத் தகுதியற்றது."

#: ../../Ch12/Ch12_Regression_11.rst:307 ../../Ch12/Ch12_Regression_11.rst:311
msgid "Residuals plots produced in jamovi"
msgstr "சமோவியில் விளைவாக்கம் செய்யப்படும் எஞ்சிய இடங்கள்"

#: ../../Ch12/Ch12_Regression_11.rst:315
msgid ""
"If we were worried, then in a lot of cases the solution to this problem (and "
"many others) is to transform one or more of the variables. We discussed the "
"basics of variable transformation in the sections :doc:`../Ch06/"
"Ch06_DataHandling_3` and :doc:`../Ch06/Ch06_DataHandling_4`, but I do want "
"to make special note of one additional possibility that I didn’t explain "
"fully earlier: the Box-Cox transform."
msgstr ""
"நாங்கள் கவலைப்பட்டால், பல சந்தர்ப்பங்களில் இந்த சிக்கலுக்கான தீர்வு (மற்றும் பலர்) ஒன்று அல்லது "
"அதற்கு மேற்பட்ட மாறிகளை மாற்றுவதாகும். பிரிவுகளில் மாறி மாற்றத்தின் அடிப்படைகளை நாங்கள் "
"விவாதித்தோம்: டாக்: `../ ch06/ch06_datahandling_3` மற்றும்: டாக்:` ../ ch06/"
"ch06_datahandling_4` டி முழுமையாக விளக்குகிறது: பாக்ச்-காக்ச் உருமாற்றம்."

#: ../../Ch12/Ch12_Regression_11.rst:324
msgid "The Box-Cox function is a fairly simple one and it’s very widely used."
msgstr ""
"பாக்ச்-காக்ச் செயல்பாடு மிகவும் எளிமையானது, இது மிகவும் பரவலாகப் பயன்படுத்தப்படுகிறது."

#: ../../Ch12/Ch12_Regression_11.rst:326
msgid ""
"f(x,\\lambda) = \\frac{x^\\lambda - 1}{\\lambda}\n"
"\n"
msgstr ""
"f(x,\\lambda) = \\frac{x^\\lambda - 1}{\\lambda}\n"
"\n"

#: ../../Ch12/Ch12_Regression_11.rst:328
msgid ""
"for all values of λ except λ = 0. When λ = 0 we just take the natural "
"logarithm (i.e., *ln*\\(x))."
msgstr ""
"λ = 0 தவிர of இன் அனைத்து மதிப்புகளுக்கும். λ = 0 போது நாம் இயற்கையான மடக்கை "
"எடுத்துக்கொள்கிறோம் (அதாவது, *ln *\\ (x))."

#: ../../Ch12/Ch12_Regression_11.rst:331
msgid ""
"You can calculate it using the ``BOXCOX`` function in the ``Compute`` "
"variables screen in jamovi."
msgstr ""
"சாமோவியில் உள்ள `` கம்ப்யூட்` மாறுபாடுகள் திரையில் `` பாக்ச் காக்ச்` செயல்பாட்டைப் "
"பயன்படுத்தி அதைக் கணக்கிடலாம்."

#: ../../Ch12/Ch12_Regression_11.rst:337
msgid "Checking for collinearity"
msgstr "COLINEARITY ஐ சரிபார்க்கிறது"

#: ../../Ch12/Ch12_Regression_11.rst:339
msgid ""
"The last kind of regression diagnostic that I’m going to discuss in this "
"chapter is the use of **variance inflation factors** (VIFs), which are "
"useful for determining whether or not the predictors in your regression "
"model are too highly correlated with each other. There is a variance "
"inflation factor associated with each predictor *X*\\ :sub:`k` in the model."
msgstr ""
"இந்த அத்தியாயத்தில் நான் விவாதிக்கப் போகும் கடைசி வகையான பின்னடைவு நோயறிதல் ** மாறுபாடு"
" பணவீக்க காரணிகள் ** (விஐஎஃப்எச்) ஐப் பயன்படுத்துவதாகும், அவை உங்கள் பின்னடைவு மாதிரியில் "
"உள்ள முன்னறிவிப்பாளர்கள் மிகவும் தொடர்புபடுத்தப்பட்டுள்ளார்களா இல்லையா என்பதை தீர்மானிக்க "
"பயனுள்ளதாக இருக்கும் ஒருவருக்கொருவர். ஒவ்வொரு முன்கணிப்பாளருடன் தொடர்புடைய மாறுபாடு "
"பணவீக்க காரணி உள்ளது *x *\\: துணை: `k` மாதிரியில்."

#: ../../Ch12/Ch12_Regression_11.rst:346
msgid "The formula for the k-th VIF is:"
msgstr "K-TH VIF க்கான சூத்திரம்:"

#: ../../Ch12/Ch12_Regression_11.rst:348
msgid "VIF\\ :sub:`k` = 1 / (1 - *R*\\²\\ :sub:`(-k)`\\)"
msgstr "VIF\\ :sub:`k` = 1 / (1 - *R*\\²\\ :sub:`(-k)`\\)"

#: ../../Ch12/Ch12_Regression_11.rst:350
msgid ""
"where *R*\\²\\ :sub:`(-k)` refers to *R*-squared value you would get if you "
"ran a regression using *X*\\ :sub:`k` as the outcome variable, and all the "
"other *X* variables as the predictors. The idea here is that *R*\\²\\ :sub:"
"`(-k)` is a very good measure of the extent to which *X*\\ :sub:`k` is "
"correlated with all the other variables in the model."
msgstr ""
"எங்கே *r *\\ ² \\: sub: `(-k)` என்பது *r *-squared மதிப்பைக் குறிக்கிறது *x *\\: "
"துணை: `k` விளைவு மாறியாகவும், மற்றும் அனைத்தும் முன்னறிவிப்பாளர்களாக மற்ற * ஃச் * "
"மாறிகள். இங்கே சிந்தனை என்னவென்றால், *r *\\ ² \\: துணை: `(-k)` என்பது *x *\\: துணை: "
"`k` மாதிரியில் உள்ள மற்ற எல்லா மாறிகளுடனும் தொடர்புடையது என்பதற்கு ஒரு நல்ல "
"நடவடிக்கையாகும் ."

#: ../../Ch12/Ch12_Regression_11.rst:356
msgid ""
"The square root of the VIF is pretty interpretable. It tells you how much "
"wider the confidence interval for the corresponding coefficient *b*\\ :sub:"
"`k` is, relative to what you would have expected if the predictors are all "
"nice and uncorrelated with one another. If you’ve only got two predictors, "
"the VIF values are always going to be the same, as we can see if we click on "
"the ``Collinearity`` checkbox in the ``Regression`` → ``Assumption Checks`` "
"options in jamovi. For both ``dani.sleep`` and ``baby.sleep`` the VIF is "
"1.65. And since the square root of 1.65 is 1.28, we see that the correlation "
"between our two predictors isn’t causing much of a problem."
msgstr ""
"VIF இன் சதுர வேர் மிகவும் விளக்கக்கூடியது. தொடர்புடைய குணகத்திற்கான நம்பிக்கை இடைவெளி "
"*பி *\\: துணை: `கே` என்பது, முன்னறிவிப்பாளர்கள் அனைவரும் நன்றாகவும் ஒருவருக்கொருவர் "
"தொடர்பில்லாதவராகவும் இருந்தால் நீங்கள் எதிர்பார்த்ததை ஒப்பிடுகையில். உங்களுக்கு இரண்டு "
"முன்னறிவிப்பாளர்கள் மட்டுமே கிடைத்தால், `` பின்னடைவு` `` `அனுமான காசோலைகள்`` என்ற "
"விருப்பங்களில்` `கோலைனீரிட்டி`` தேர்வுப்பெட்டியைக் சொடுக்கு செய்தால், விஐஎஃப் மதிப்புகள் "
"எப்போதுமே ஒரே மாதிரியாக இருக்கும். சாமோவியில். `` Dani.sleep`` மற்றும் `` "
"baby.sleep`` ஆகிய இரண்டிற்கும் VIF 1.65 ஆகும். 1.65 சதுர வேர் 1.28 ஆக இருப்பதால், "
"எங்கள் இரு முன்கணிப்பாளர்களுக்கிடையேயான தொடர்பு ஒரு பிரச்சினையை ஏற்படுத்தாது என்பதைக் "
"காண்கிறோம்."

#: ../../Ch12/Ch12_Regression_11.rst:367
msgid ""
"To give a sense of how we could end up with a model that has bigger "
"collinearity problems, suppose I were to run a much less interesting "
"regression model, in which I tried to predict the ``day`` on which the data "
"were collected, as a function of all the other variables in the data set. To "
"see why this would be a bit of a problem, let’s have a look at the "
"correlation matrix for all four variables:"
msgstr ""
"பெரிய கூட்டுறவு சிக்கல்களைக் கொண்ட ஒரு மாதிரியுடன் நாம் எவ்வாறு முடிவடையும் என்பதைப் "
"புரிந்துகொள்ள, நான் மிகவும் குறைவான சுவையான பின்னடைவு மாதிரியை இயக்க வேண்டும் என்று "
"வைத்துக்கொள்வோம், அதில் தரவு சேகரிக்கப்பட்ட `` நாள்`` கணிக்க முயற்சித்தேன், தரவு தொகுப்பில் "
"உள்ள மற்ற அனைத்து மாறிகளின் செயல்பாடாக. இது ஏன் ஒரு சிக்கலாக இருக்கும் என்பதைப் பார்க்க, "
"நான்கு மாறிகளுக்கும் தொடர்பு மேட்ரிக்சைப் பார்ப்போம்:"

#: ../../Ch12/Ch12_Regression_11.rst:382
msgid ""
"We have some fairly large correlations between some of our predictor "
"variables! When we run the regression model and look at the VIF values, we "
"see that the collinearity is causing a lot of uncertainty about the "
"coefficients. First, run the regression, as in :numref:`fig-reg7` and you "
"can see from the VIF values that, yep, that’s some mighty fine collinearity "
"there."
msgstr ""
"எங்கள் முன்கணிப்பு மாறிகள் சில இடையே சில பெரிய தொடர்புகள் உள்ளன! நாம் பின்னடைவு "
"மாதிரியை இயக்கி, VIF மதிப்புகளைப் பார்க்கும்போது, கோலினரிட்டி குணகங்களைப் பற்றி நிறைய "
"நிச்சயமற்ற தன்மையை ஏற்படுத்துகிறது என்பதைக் காண்கிறோம். முதலில், பின்னடைவை இயக்கவும்: "
"NumRef: `Fig-reg7` மற்றும் VIF மதிப்புகளிலிருந்து நீங்கள் காணலாம், ஆமாம், அது அங்கு சி"
"ல சிறந்த கூட்டுறவு."

#: ../../Ch12/Ch12_Regression_11.rst:390 ../../Ch12/Ch12_Regression_11.rst:394
msgid "Collinearity statistics for multiple regression, produced in jamovi"
msgstr ""
"பல பின்னடைவுகளுக்கான கொலினரிட்டி புள்ளிவிவரங்கள், சாமோவியில் தயாரிக்கப்படுகின்றன"

#: ../../Ch12/Ch12_Regression_11.rst:401
msgid "Or have no hope, as the case may be."
msgstr "அல்லது நம்பிக்கை இல்லை, ஏனெனில்."

#: ../../Ch12/Ch12_Regression_11.rst:404
msgid ""
"Again, for the linear algebra fanatics: the “hat matrix” is defined to be "
"that matrix **H** that converts the vector of observed values *y* into a "
"vector of fitted values ŷ, such that ŷ = **H**\\ *y*. The name comes from "
"the fact that this is the matrix that “puts a hat on *y*”. The hat *value* "
"of the i-th observation is the i-th diagonal element of this matrix (so "
"technically I should be writing it as h\\ :sub:`ii` rather than h\\ :sub:"
"`i`). Oh, and in case you care, here’s how it’s calculated: **H** = "
"**X**\\(**X**'**X**\\)\\ :sup:`-1` **X**'\\. Pretty, isn’t it?"
msgstr ""
"மீண்டும், நேரியல் இயற்கணித வெறியர்களுக்கு: “தொப்பி அணி” என்பது அந்த மேட்ரிக்ச் ** h ** என "
"வரையறுக்கப்படுகிறது, இது கவனிக்கப்பட்ட மதிப்புகளின் திசையனை*y*பொருத்தப்பட்ட மதிப்புகளின் "
"திசையனாக மாற்றுகிறது, அதாவது ŷ = ** h* *\\ *y *. இது “ *y *இல் ஒரு தொப்பியை "
"வைக்கும் மேட்ரிக்ச் என்ற உண்மையிலிருந்து இந்த பெயர் வருகிறது. I-TH அவதானிப்பின் தொப்பி * "
"மதிப்பு * இந்த மேட்ரிக்சின் I-TH மூலைவிட்டம் உறுப்பு ஆகும் (எனவே தொழில்நுட்ப ரீதியாக நான் "
"அதை H \\: துணை: `II` என்று H \\: துணை:` I`) என்று எழுத வேண்டும். ஓ, நீங்கள் அக்கறை "
"கொண்டிருந்தால், அது எவ்வாறு கணக்கிடப்பட்டது: ** h ** = ** ஃச் ** \\ (** ஃச் ** '** ஃச் "
"** \\) \\: sup: `-1` ** ஃச் ** '\\. அழகான, இல்லையா?"

#: ../../Ch12/Ch12_Regression_11.rst:414
msgid ""
"In order to obtain the Cook’s distance for each participant, open the drop-"
"down menu ``Save`` within the ``Linear Regression`` analysis options and set "
"the check box ``Cook's distance``. A new column containing Cook’s distances "
"will be added at the end of your data set. Those values can then be used in "
"connection with a :doc:`filter <../Ch06/Ch06_DataHandling_5>` to select "
"participants."
msgstr ""
"ஒவ்வொரு பங்கேற்பாளருக்கும் சமையல்காரரின் தூரத்தைப் பெறுவதற்காக, `` நேரியல் பின்னடைவு`` "
"பகுப்பாய்வு விருப்பங்களுக்குள் கீழ்தோன்றும் மெனுவைத் திறந்து `` குக்கின் தூரம்` என்ற "
"தேர்வுப்பெட்டியை அமைக்கவும். உங்கள் தரவு தொகுப்பின் முடிவில் குக்கின் தூரங்களைக் கொண்ட புதி"
"ய நெடுவரிசை சேர்க்கப்படும். அந்த மதிப்புகள் பின்னர் A: DOC: `வடிகட்டி <../ CH06/"
"CH06_DATAHANDLING_5>` பங்கேற்பாளர்களைத் தேர்ந்தெடுக்க பயன்படுத்தலாம்."

#: ../../Ch12/Ch12_Regression_12.rst:4
msgid "Model selection"
msgstr "மாதிரி தேர்வு"

#: ../../Ch12/Ch12_Regression_12.rst:6
msgid ""
"One fairly major problem that remains is the problem of “model selection”. "
"That is, if we have a data set that contains several variables, which ones "
"should we include as predictors, and which ones should we not include? In "
"other words, we have a problem of **variable selection**. In general, model "
"selection is a complex business but it’s made somewhat simpler if we "
"restrict ourselves to the problem of choosing a subset of the variables that "
"ought to be included in the model. Nevertheless, I’m not going to try "
"covering even this reduced topic in a lot of detail. Instead, I’ll talk "
"about two broad principles that you need to think about, and then discuss "
"one concrete tool that jamovi provides to help you select a subset of "
"variables to include in your model. First, the two principles:"
msgstr ""
"எஞ்சியிருக்கும் ஒரு பெரிய சிக்கல் “மாதிரி தேர்வு” இன் சிக்கல். அதாவது, பல மாறிகள் கொண்ட "
"ஒரு தரவுத் தொகுப்பு நம்மிடம் இருந்தால், அவை முன்னறிவிப்பாளர்களாக நாம் சேர்க்க வேண்டும், "
"எதைச் சேர்க்கக்கூடாது? வேறு வார்த்தைகளில் கூறுவதானால், எங்களுக்கு ** மாறி தேர்வு ** "
"சிக்கல் உள்ளது. பொதுவாக, மாதிரி தேர்வு ஒரு சிக்கலான வணிகமாகும், ஆனால் மாதிரியில் "
"சேர்க்கப்பட வேண்டிய மாறிகளின் துணைக்குழுவைத் தேர்ந்தெடுப்பதில் உள்ள சிக்கலுக்கு நம்மை "
"கட்டுப்படுத்தினால் அது சற்று எளிமையானது. ஆயினும்கூட, இந்த குறைக்கப்பட்ட தலைப்பைக் கூட "
"நிறைய விவரங்களில் மறைக்க முயற்சிக்கப் போவதில்லை. அதற்கு பதிலாக, நீங்கள் சிந்திக்க வேண்டிய "
"இரண்டு பரந்த கொள்கைகளைப் பற்றி நான் பேசுவேன், பின்னர் உங்கள் மாதிரியில் சேர்க்க மாறிகளின் "
"துணைக்குழுவைத் தேர்ந்தெடுக்க சாமோவி வழங்கும் ஒரு கான்கிரீட் கருவியைப் பற்றி விவாதிக்கிறேன்"
". முதலில், இரண்டு கொள்கைகள்:"

#: ../../Ch12/Ch12_Regression_12.rst:19
msgid ""
"It’s nice to have an actual substantive basis for your choices. That is, in "
"a lot of situations you the researcher have good reasons to pick out a "
"smallish number of possible regression models that are of theoretical "
"interest. These models will have a sensible interpretation in the context of "
"your field. Never discount the importance of this. Statistics serves the "
"scientific process, not the other way around."
msgstr ""
"உங்கள் தேர்வுகளுக்கு உண்மையான கணிசமான அடிப்படையைக் கொண்டிருப்பது மகிழ்ச்சி அளிக்கிறது. "
"அதாவது, பல சூழ்நிலைகளில், தத்துவார்த்த ஆர்வமுள்ள ஒரு சிறிய எண்ணிக்கையிலான பின்னடைவு "
"மாதிரிகளை எடுக்க ஆராய்ச்சியாளருக்கு நல்ல காரணங்கள் உள்ளன. இந்த மாதிரிகள் உங்கள் துறையின் "
"சூழலில் விவேகமான விளக்கத்தைக் கொண்டிருக்கும். இதன் முக்கியத்துவத்தை ஒருபோதும் தள்ளுபடி "
"செய்யாதீர்கள். புள்ளிவிவரங்கள் விஞ்ஞான செயல்முறைக்கு உதவுகின்றன, வேறு வழியில்லை."

#: ../../Ch12/Ch12_Regression_12.rst:27
msgid ""
"To the extent that your choices rely on statistical inference, there is a "
"trade off between simplicity and goodness of fit. As you add more predictors "
"to the model you make it more complex. Each predictor adds a new free "
"parameter (i.e., a new regression coefficient), and each new parameter "
"increases the model’s capacity to “absorb” random variations. So the "
"goodness of fit (e.g., *R*\\²) continues to rise, sometimes trivially or by "
"chance, as you add more predictors no matter what. If you want your model to "
"be able to generalise well to new observations you need to avoid throwing in "
"too many variables."
msgstr ""
"உங்கள் தேர்வுகள் புள்ளிவிவர அனுமானத்தை நம்பியிருக்கும் அளவிற்கு, எளிமைக்கும் பொருத்தத்தின் "
"நன்மைக்கும் இடையில் ஒரு வணிகம் உள்ளது. மாதிரியில் நீங்கள் அதிக முன்னறிவிப்பாளர்களைச் "
"சேர்க்கும்போது, அதை மிகவும் சிக்கலானதாக ஆக்குகிறீர்கள். ஒவ்வொரு முன்கணிப்பாளரும் ஒரு புதி"
"ய இலவச அளவுருவைச் சேர்க்கிறது (அதாவது, ஒரு புதிய பின்னடைவு குணகம்), மேலும் ஒவ்வொரு "
"புதிய அளவுருவும் சீரற்ற மாறுபாடுகளை “உறிஞ்சும்” மாதிரியின் திறனை அதிகரிக்கிறது. எனவே"
" பொருத்தத்தின் நன்மை (எ.கா., *r *\\ ²) தொடர்ந்து உயர்ந்து, சில நேரங்களில் அற்பமாக அல்லது "
"தற்செயலாக, நீங்கள் எதுவாக இருந்தாலும் அதிக முன்னறிவிப்பாளர்களைச் சேர்ப்பதால். உங்கள் மாதிரி "
"புதிய அவதானிப்புகளுக்கு நன்கு பொதுமைப்படுத்த முடியும் என்றால், நீங்கள் பல மாறிகளில் "
"வீசுவதைத் தவிர்க்க வேண்டும்."

#: ../../Ch12/Ch12_Regression_12.rst:37
msgid ""
"This latter principle is often referred to as **Ockham’s razor** and is "
"often summarised in terms of the following pithy saying: *do not multiply "
"entities beyond necessity*. In this context, it means don’t chuck in a bunch "
"of largely irrelevant predictors just to boost your *R*\\². Hmm. Yeah, the "
"original was better."
msgstr ""
"இந்த பிந்தைய கொள்கை பெரும்பாலும் ** ஓக்ஆமின் ரேசர் ** என குறிப்பிடப்படுகிறது, மேலும் இது"
" பெரும்பாலும் பின்வரும் பரிதாபத்தின் அடிப்படையில் சுருக்கமாகக் கூறப்படுகிறது:*தேவைக்கு "
"அப்பாற்பட்ட நிறுவனங்களை பெருக்க வேண்டாம்*. இந்த சூழலில், உங்கள் *r *\\ க்கு ஐ உயர்த்துவதற்கா"
"க பெரும்பாலும் பொருத்தமற்ற முன்கணிப்பாளர்களின் தொகுப்பில் சிக்க வேண்டாம் என்று பொருள். அ்ம். "
"ஆமாம், அசல் சிறப்பாக இருந்தது."

#: ../../Ch12/Ch12_Regression_12.rst:43
msgid ""
"In any case, what we need is an actual mathematical criterion that will "
"implement the qualitative principle behind Ockham’s razor in the context of "
"selecting a regression model. As it turns out there are several "
"possibilities. The one that I’ll talk about is the **Akaike information "
"criterion** (AIC; :ref:`Akaike, 1974 <Akaike_1974>`) simply because it’s "
"available as an option in jamovi."
msgstr ""
"எந்தவொரு சந்தர்ப்பத்திலும், நமக்குத் தேவையானது ஒரு உண்மையான கணித அளவுகோலாகும், இது "
"பின்னடைவு மாதிரியைத் தேர்ந்தெடுக்கும் சூழலில் ஓக்ஆமின் ரேசருக்கு பின்னால் உள்ள தரமான "
"கொள்கையை செயல்படுத்தும். பல சாத்தியங்கள் உள்ளன. நான் பேசுவது ** akaek செய்தி அளவுகோல் **"
" (AIC ;: ref: `akaek, 1974 <akaike_1974>`) இது சாமோவியில் ஒரு விருப்பமாக "
"இருப்பதால்."

#: ../../Ch12/Ch12_Regression_12.rst:50
msgid ""
"In the context of a linear regression model (and ignoring terms that don’t "
"depend on the model in any way!), the AIC for a model that has *K* predictor "
"variables plus an intercept is"
msgstr ""
"ஒரு நேரியல் பின்னடைவு மாதிரியின் சூழலில் (மற்றும் மாதிரியை எந்த வகையிலும் சார்ந்து இல்லா"
"த சொற்களைப் புறக்கணித்தல்!), * K * முன்கணிப்பு மாறிகள் மற்றும் ஒரு இடைமறிப்பு கொண்ட ஒரு "
"மாதிரிக்கான AIC"

#: ../../Ch12/Ch12_Regression_12.rst:54
msgid ""
"\\mbox{AIC} = \\displaystyle\\frac{\\mbox{SS}_{res}}{\\hat{\\sigma}^2} + 2K\n"
"\n"
msgstr ""
"\\mbox{AIC} = \\displaystyle\\frac{\\mbox{SS}_{res}}{\\hat{\\sigma}^2} + 2K\n"
"\n"

#: ../../Ch12/Ch12_Regression_12.rst:56
msgid ""
"The smaller the AIC value, the better the model performance. If we ignore "
"the low level details it’s fairly obvious what the AIC does. On the left we "
"have a term that increases as the model predictions get worse; on the right "
"we have a term that increases as the model complexity increases. The best "
"model is the one that fits the data well (low residuals, left hand side) "
"using as few predictors as possible (low K, right hand side). In short, this "
"is a simple implementation of Ockham’s razor."
msgstr ""
"AIC மதிப்பு சிறியது, மாதிரி செயல்திறன் சிறந்தது. குறைந்த அளவிலான விவரங்களை நாங்கள் "
"புறக்கணித்தால், AIC என்ன செய்கிறது என்பது மிகவும் தெளிவாகத் தெரிகிறது. இடதுபுறத்தில் "
"மாதிரி கணிப்புகள் மோசமடையும்போது அதிகரிக்கும் ஒரு சொல் உள்ளது; வலதுபுறத்தில் மாதிரி "
"சிக்கலானது அதிகரிக்கும் போது அதிகரிக்கும் ஒரு சொல் உள்ளது. சிறந்த மாதிரி என்பது தரவை "
"நன்கு பொருத்துகிறது (குறைந்த எச்சங்கள், இடது புறம்) முடிந்தவரை சில முன்னறிவிப்பாளர்களைப் "
"பயன்படுத்துகிறது (குறைந்த கே, வலது புறம்). சுருக்கமாக, இது ஓக்ஆமின் ரேசரின் எளிய "
"செயலாக்கமாகும்."

#: ../../Ch12/Ch12_Regression_12.rst:65
msgid ""
"AIC can be added to the ``Model Fit Measures`` output Table when the ``AIC`` "
"checkbox is clicked, and a rather clunky way of assessing different models "
"is seeing if the ``AIC`` value is lower if you remove one or more of the "
"predictors in the regression model. This is the only way currently "
"implemented in jamovi, but there are alternatives in other more powerful "
"programmes, such as R. These alternative methods can automate the process of "
"selectively removing (or adding) predictor variables to find the best AIC. "
"Although these methods are not implemented in jamovi, I will mention them "
"briefly below just so you know about them."
msgstr ""
"`` Aic`` தேர்வுப்பெட்டி சொடுக்கு செய்யப்படும்போது `` மாதிரி பொருத்தம் நடவடிக்கைகள்` "
"வெளியீட்டு அட்டவணையில் AIC ஐ சேர்க்கலாம், மேலும் வெவ்வேறு மாதிரிகளை மதிப்பிடுவதற்கான ஒரு"
" வழி `` aic`` மதிப்பு குறைவாக இருந்தால் நீங்கள் அகற்றினால் குறைவாக இருக்கிறதா என்று "
"பார்க்கிறீர்கள் பின்னடைவு மாதிரியில் ஒன்று அல்லது அதற்கு மேற்பட்ட முன்னறிவிப்பாளர்கள். "
"சாமோவியில் தற்போது செயல்படுத்தப்பட்ட ஒரே வழி இதுதான், ஆனால் ஆர் போன்ற பிற சக்திவாய்ந்த "
"நிரல்களில் மாற்று வழிகள் உள்ளன. இந்த மாற்று முறைகள் சிறந்த AIC ஐக் கண்டறிய முன்னறிவிப்பாளர்"
" மாறிகள் தேர்ந்தெடுக்கும் (அல்லது சேர்ப்பது) செயல்முறையை தானியக்கமாக்கலாம். இந்த முறைகள் "
"சமோவியில் செயல்படுத்தப்படவில்லை என்றாலும், அவற்றை சுருக்கமாகக் கீழே குறிப்பிடுவேன், எனவே "
"அவற்றைப் பற்றி உங்களுக்குத் தெரியும்."

#: ../../Ch12/Ch12_Regression_12.rst:77
msgid "Backward elimination"
msgstr "பின்தங்கிய நீக்குதல்"

#: ../../Ch12/Ch12_Regression_12.rst:79
msgid ""
"In backward elimination you start with the complete regression model, "
"including all possible predictors. Then, at each “step” we try all possible "
"ways of removing one of the variables, and whichever of these is best (in "
"terms of lowest AIC value) is accepted. This becomes our new regression "
"model, and we then try all possible deletions from the new model, again "
"choosing the option with lowest AIC. This process continues until we end up "
"with a model that has a lower AIC value than any of the other possible "
"models that you could produce by deleting one of its predictors."
msgstr ""
"பின்தங்கிய நீக்குதலில் நீங்கள் முழுமையான பின்னடைவு மாதிரியுடன் தொடங்குகிறீர்கள், இதில் "
"சாத்தியமான அனைத்து முன்னறிவிப்பாளர்களும் உட்பட. பின்னர், ஒவ்வொரு “படியிலும்” ஒரு மாறிகள் "
"ஒன்றை அகற்றுவதற்கான அனைத்து வழிகளையும் நாங்கள் முயற்சி செய்கிறோம், இவற்றில் எது சிறந்தது "
"(மிகக் குறைந்த AIC மதிப்பின் அடிப்படையில்) ஏற்றுக்கொள்ளப்படுகிறது. இது எங்கள் புதிய "
"பின்னடைவு மாதிரியாக மாறும், பின்னர் புதிய மாடலில் இருந்து சாத்தியமான அனைத்து "
"நீக்குதல்களையும் முயற்சிக்கிறோம், மீண்டும் குறைந்த AIC உடன் விருப்பத்தைத் தேர்வு செய்கிறோம். "
"அதன் முன்னறிவிப்பாளர்களில் ஒன்றை நீக்குவதன் மூலம் நீங்கள் தயாரிக்கக்கூடிய மற்ற சாத்தியமான "
"மாதிரிகளை விட குறைந்த AIC மதிப்பைக் கொண்ட ஒரு மாதிரியுடன் முடிவடையும் வரை இந்த "
"செயல்முறை தொடர்கிறது."

#: ../../Ch12/Ch12_Regression_12.rst:90
msgid "Forward selection"
msgstr "முன்னோக்கி தேர்வு"

#: ../../Ch12/Ch12_Regression_12.rst:92
msgid ""
"As an alternative, you can also try **forward selection**. This time around "
"we start with the smallest possible model as our start point, and only "
"consider the possible additions to the model. However, there’s one "
"complication. You also need to specify what the largest possible model "
"you’re willing to entertain is."
msgstr ""
"மாற்றாக, நீங்கள் ** முன்னோக்கி தேர்வை முயற்சி செய்யலாம் **. இந்த நேரத்தில் நாங்கள் எங்கள் தொடக்"
"க புள்ளியாக மிகச்சிறிய மாதிரியுடன் தொடங்குகிறோம், மேலும் மாதிரியில் சாத்தியமான "
"சேர்த்தல்களை மட்டுமே கருதுகிறோம். இருப்பினும், ஒரு சிக்கல் உள்ளது. நீங்கள் மகிழ்விக்க "
"விரும்பும் மிகப்பெரிய மாதிரி என்ன என்பதையும் நீங்கள் குறிப்பிட வேண்டும்."

#: ../../Ch12/Ch12_Regression_12.rst:98
msgid ""
"Although backward and forward selection can lead to the same conclusion, "
"they don’t always."
msgstr ""
"பின்தங்கிய மற்றும் முன்னோக்கி தேர்வு ஒரே முடிவுக்கு வழிவகுக்கும் என்றாலும், அவை எப்போதும் "
"இல்லை."

#: ../../Ch12/Ch12_Regression_12.rst:102
msgid "A caveat"
msgstr "ஒரு எச்சரிக்கை"

#: ../../Ch12/Ch12_Regression_12.rst:104
msgid ""
"Automated variable selection methods are seductive things, especially when "
"they’re bundled up in (fairly) simple functions in powerful statistical "
"programmes. They provide an element of objectivity to your model selection, "
"and that’s kind of nice. Unfortunately, they’re sometimes used as an excuse "
"for thoughtlessness. No longer do you have to think carefully about which "
"predictors to add to the model and what the theoretical basis for their "
"inclusion might be. Everything is solved by the magic of AIC. And if we "
"start throwing around phrases like Ockham’s razor, well it sounds like "
"everything is wrapped up in a nice neat little package that no-one can argue "
"with."
msgstr ""
"தானியங்கு மாறி தேர்வு முறைகள் கவர்ச்சியான விசயங்கள், குறிப்பாக அவை சக்திவாய்ந்த புள்ளிவி"
"வர நிரல்களில் (நியாயமான) எளிய செயல்பாடுகளில் தொகுக்கப்படும்போது. அவை உங்கள் மாதிரி "
"தேர்வுக்கு புறநிலைத்தன்மையின் ஒரு உறுப்பை வழங்குகின்றன, அது ஒரு வகையான நல்லது. "
"துரதிர்ச்டவசமாக, அவை சில நேரங்களில் சிந்தனையற்ற தன்மைக்கு ஒரு தவிர்க்கவும் "
"பயன்படுத்தப்படுகின்றன. எந்த முன்னறிவிப்பாளர்கள் மாதிரியைச் சேர்க்க வேண்டும் என்பதையும், அவர்கள்"
" சேர்ப்பதற்கான தத்துவார்த்த அடிப்படை என்னவாக இருக்கும் என்பதையும் நீங்கள் கவனமாக சிந்திக்க "
"வேண்டியதில்லை. எல்லாம் AIC இன் மந்திரத்தால் தீர்க்கப்படுகிறது. ஓக்ஆமின் ரேசர் போன்ற "
"சொற்றொடர்களைச் சுற்றி எறியத் தொடங்கினால், எல்லாமே ஒரு நல்ல தூய்மையான சிறிய தொகுப்பில் "
"மூடப்பட்டிருப்பது போல் தெரிகிறது."

#: ../../Ch12/Ch12_Regression_12.rst:115
msgid ""
"Or, perhaps not. Firstly, there’s very little agreement on what counts as an "
"appropriate model selection criterion. When I was taught backward "
"elimination as an undergraduate, we used *F*-tests to do it, because that "
"was the default method used by the software. I’ve described using AIC, and "
"since this is an introductory text that’s the only method I’ve described, "
"but the AIC is hardly the Word of the Gods of Statistics. It’s an "
"approximation, derived under certain assumptions, and it’s guaranteed to "
"work only for large samples when those assumptions are met. Alter those "
"assumptions and you get a different criterion, like the BIC for instance "
"(also available in jamovi). Take a different approach again and you get the "
"NML criterion. Decide that you’re a Bayesian and you get model selection "
"based on posterior odds ratios. Then there are a bunch of regression "
"specific tools that I haven’t mentioned. And so on. All of these different "
"methods have strengths and weaknesses, and some are easier to calculate than "
"others (AIC is probably the easiest of the lot, which might account for its "
"popularity). Almost all of them produce the same answers when the answer is "
"“obvious” but there’s a fair amount of disagreement when the model selection "
"problem becomes hard."
msgstr ""
"அல்லது, ஒருவேளை இல்லை. முதலாவதாக, பொருத்தமான மாதிரி தேர்வு அளவுகோலாகக் "
"கருதப்படுவதில் மிகக் குறைவான உடன்பாடு உள்ளது. இளங்கலை பட்டதாரியாக நான் பின்தங்கிய "
"நீக்குதல் கற்பிக்கப்பட்டபோது, அதைச் செய்ய *f *-tests ஐப் பயன்படுத்தினோம், ஏனென்றால் இது "
"மென்பொருளால் பயன்படுத்தப்படும் இயல்புநிலை முறையாகும். AIC ஐப் பயன்படுத்துவதை நான் "
"விவரித்தேன், இது ஒரு அறிமுக உரை என்பதால் நான் விவரித்த ஒரே முறை, ஆனால் AIC என்பது "
"புள்ளிவிவரங்களின் கடவுள்களின் வார்த்தையாகும். இது ஒரு தோராயமாகும், இது சில அனுமானங்களின்"
" கீழ் பெறப்பட்டது, மேலும் அந்த அனுமானங்கள் நிறைவு செய்யப்படும்போது பெரிய மாதிரிகளுக்கு "
"மட்டுமே வேலை செய்வது உறுதி. அந்த அனுமானங்களை மாற்றவும், உதாரணமாக BIC போன்ற வேறுபட்ட "
"அளவுகோலைப் பெறுவீர்கள் (சமோவியிலும் கிடைக்கிறது). மீண்டும் வேறு அணுகுமுறையை எடுத்துக் "
"கொள்ளுங்கள், நீங்கள் என்எம்எல் அளவுகோலைப் பெறுவீர்கள். நீங்கள் ஒரு பேய்சியன் என்று முடிவு "
"செய்யுங்கள், பின்புற முரண்பாடுகள் விகிதங்களின் அடிப்படையில் மாதிரி தேர்வைப் பெறுவீர்கள். நான்"
" குறிப்பிடாத பின்னடைவு குறிப்பிட்ட கருவிகள் உள்ளன. மற்றும் பல. இந்த வெவ்வேறு முறைகள் "
"அனைத்தும் பலங்களையும் பலவீனங்களையும் கொண்டிருக்கின்றன, மேலும் சிலவற்றை மற்றவர்களை விட "
"கணக்கிடுவது எளிதானது (AIC அநேகமாக எளிதானது, இது அதன் பிரபலத்திற்கு காரணமாக "
"இருக்கலாம்). பதில் “வெளிப்படையானது” என்று இருக்கும்போது கிட்டத்தட்ட அனைத்தும் ஒரே "
"பதில்களைத் தருகின்றன, ஆனால் மாதிரி தேர்வு சிக்கல் கடினமாக இருக்கும்போது நியாயமான அளவு "
"கருத்து வேறுபாடு உள்ளது."

#: ../../Ch12/Ch12_Regression_12.rst:135
msgid ""
"What does this mean in practice? Well, you *could* go and spend several "
"years teaching yourself the theory of model selection, learning all the ins "
"and outs of it so that you could finally decide on what you personally think "
"the right thing to do is. Speaking as someone who actually did that, I "
"wouldn’t recommend it. You’ll probably come out the other side even more "
"confused than when you started. A better strategy is to show a bit of common "
"sense. If you’re staring at the results of an automated backwards or "
"forwards selection procedure, and the model that makes sense is close to "
"having the smallest AIC but is narrowly defeated by a model that doesn’t "
"make any sense, then trust your instincts. Statistical model selection is an "
"inexact tool, and as I said at the beginning, *interpretability matters*."
msgstr ""
"இது நடைமுறையில் என்ன அர்த்தம்? சரி, நீங்கள் * சென்று பல ஆண்டுகளாக மாதிரி தேர்வின் "
"கோட்பாட்டைக் கற்பிக்கலாம், அதன் அனைத்து இன்ச் மற்றும் அவுட்களையும் கற்றுக் கொள்ளலாம், இதன்மூலம் "
"நீங்கள் தனிப்பட்ட முறையில் என்ன நினைக்கிறீர்கள் என்பதை நீங்கள் இறுதியாக தீர்மானிக்க முடியும். "
"உண்மையில் அதைச் செய்த ஒருவராகப் பேசும்போது, நான் அதை பரிந்துரைக்க மாட்டேன். நீங்கள் "
"தொடங்கியதை விட வேறு பக்கத்தை நீங்கள் குழப்பமடையச் செய்வீர்கள். ஒரு சிறந்த உத்தி என்பது பொது "
"அறிவைக் காண்பிப்பதாகும். நீங்கள் ஒரு தானியங்கி பின்னோக்கி அல்லது முன்னோக்கி தேர்வு "
"நடைமுறையின் முடிவுகளைப் பார்த்துக் கொண்டிருந்தால், மேலும் மிகச்சிறிய AIC ஐக் "
"கொண்டிருப்பதற்கு நெருக்கமாக இருக்கும் மாதிரி, ஆனால் எந்த அர்த்தமும் இல்லாத ஒரு மாதிரியால் "
"குறுகியதாக தோற்கடிக்கப்படுகிறது, பின்னர் உங்கள் உள்ளுணர்வுகளை நம்புங்கள். புள்ளிவிவர "
"மாதிரி தேர்வு ஒரு துல்லியமான கருவியாகும், ஆரம்பத்தில் நான் கூறியது போல், "
"*விளக்கமளிக்கும் விசயங்கள் *."

#: ../../Ch12/Ch12_Regression_12.rst:149
msgid "Comparing two regression models"
msgstr "இரண்டு பின்னடைவு மாதிரிகளை ஒப்பிடுகிறது"

#: ../../Ch12/Ch12_Regression_12.rst:151
msgid ""
"An alternative to using automated model selection procedures is for the "
"researcher to explicitly select two or more regression models to compare to "
"each other. You can do this in a few different ways, depending on what "
"research question you’re trying to answer. Suppose we want to know whether "
"or not the amount of sleep that my son got has any relationship to my "
"grumpiness, over and above what we might expect from the amount of sleep "
"that I got. We also want to make sure that the day on which we took the "
"measurement has no influence on the relationship. That is, we’re interested "
"in the relationship between ``baby.sleep`` and ``dani.grump``, and from that "
"perspective ``dani.sleep`` and ``day`` are nuisance variable or "
"**covariates** that we want to control for. In this situation, what we would "
"like to know is whether ``dani.grump ~ dani.sleep + day + baby.sleep`` "
"(which I’ll call Model 2, or ``M2``) is a better regression model for these "
"data than ``dani.grump ~ dani.sleep + day`` (which I’ll call Model 1, or "
"``M1``). There are two different ways we can compare these two models, one "
"based on a model selection criterion like AIC, and the other based on an "
"explicit hypothesis test. I’ll show you the AIC based approach first because "
"it’s simpler, and follows naturally from discussion in the last section. The "
"first thing I need to do is actually run the two regressions, note the AIC "
"for each one, and then select the model with the smaller AIC value as it is "
"judged to be the better model for these data. Actually, don’t do this just "
"yet. Read on because there is an easy way in jamovi to get the AIC values "
"for different models included in one table.\\ [#]_"
msgstr ""
"தானியங்கு மாதிரி தேர்வு நடைமுறைகளைப் பயன்படுத்துவதற்கான மாற்றாக, ஆராய்ச்சியாளர் "
"ஒருவருக்கொருவர் ஒப்பிடுவதற்கு இரண்டு அல்லது அதற்கு மேற்பட்ட பின்னடைவு மாதிரிகளை "
"வெளிப்படையாகத் தேர்ந்தெடுப்பது. நீங்கள் எந்த ஆராய்ச்சி கேள்விக்கு பதிலளிக்க முயற்சிக்கிறீர்கள் "
"என்பதைப் பொறுத்து இதை சில வித்தியாசமான வழிகளில் செய்யலாம். என் மகனுக்கு கிடைத்த "
"தூக்கத்தின் அளவு என் எரிச்சலுடன் ஏதேனும் உறவு இருக்கிறதா இல்லையா என்பதை நாங்கள் அறிய "
"விரும்புகிறோம், எனக்கு கிடைத்த தூக்கத்தின் அளவிலிருந்து நாம் எதிர்பார்க்கக்கூடியதை விடவும்"
". நாங்கள் அளவீட்டு எடுத்த நாளில் உறவில் எந்த செல்வாக்கும் இல்லை என்பதையும் உறுதிப்படுத்த "
"விரும்புகிறோம். அதாவது, `` குழந்தை.லீப்`` `மற்றும்` `டானி. நாம் கட்டுப்படுத்த விரும்பும் "
"கோவாரியட்டுகள் **. இந்த சூழ்நிலையில், `` டானி. இந்த தரவுகளுக்கு `` டானி. இந்த இரண்டு "
"மாதிரிகளை நாம் ஒப்பிடக்கூடிய இரண்டு வெவ்வேறு வழிகள் உள்ளன, ஒன்று AIC போன்ற மாதிரி "
"தேர்வு அளவுகோலை அடிப்படையாகக் கொண்டது, மற்றொன்று வெளிப்படையான கருதுகோள் சோதனையின் "
"அடிப்படையில். AIC அடிப்படையிலான அணுகுமுறையை நான் முதலில் காண்பிப்பேன், ஏனெனில் இது "
"எளிமையானது, மேலும் கடைசி பிரிவில் விவாதத்திலிருந்து இயல்பாகவே பின்பற்றப்படுகிறது. நான்"
" செய்ய வேண்டிய முதல் சேதி, உண்மையில் இரண்டு பின்னடைவுகளை இயக்குவது, ஒவ்வொன்றிற்கும் AIC "
"ஐக் கவனியுங்கள், பின்னர் சிறிய AIC மதிப்புடன் மாதிரியைத் தேர்ந்தெடுக்கவும், ஏனெனில் இது இந்"
"த தரவுகளுக்கு சிறந்த மாதிரியாக தீர்மானிக்கப்படுகிறது. உண்மையில், இதை இன்னும் செய்ய "
"வேண்டாம். ஒரு அட்டவணையில் சேர்க்கப்பட்டுள்ள வெவ்வேறு மாதிரிகளுக்கான AIC மதிப்புகளைப் பெற "
"சாமோவியில் எளிதான வழி இருப்பதால் படிக்கவும். \\ [#] _"

#: ../../Ch12/Ch12_Regression_12.rst:177
msgid ""
"A somewhat different approach to the problem comes out of the hypothesis "
"testing framework. Suppose you have two regression models, where one of them "
"(Model 1) contains a *subset* of the predictors from the other one (Model "
"2). That is, Model 2 contains all of the predictors included in Model 1, "
"plus one or more additional predictors. When this happens we say that Model "
"1 is **nested** within Model 2, or possibly that Model 1 is a **submodel** "
"of Model 2. Regardless of the terminology, what this means is that we can "
"think of Model 1 as a null hypothesis and Model 2 as an alternative "
"hypothesis. And in fact we can construct an *F* test for this in a fairly "
"straightforward fashion."
msgstr ""
"பிரச்சினைக்கு சற்றே மாறுபட்ட அணுகுமுறை கருதுகோள் சோதனை கட்டமைப்பிலிருந்து "
"வெளிவருகிறது. உங்களிடம் இரண்டு பின்னடைவு மாதிரிகள் உள்ளன என்று வைத்துக்கொள்வோம், அவற்றில் "
"ஒன்று (மாதிரி 1) மற்றொன்றிலிருந்து முன்னறிவிப்பாளர்களின் * துணைக்குழு * உள்ளது (மாதிரி "
"2). அதாவது, மாதிரி 2 இல் சேர்க்கப்பட்டுள்ள அனைத்து முன்னறிவிப்பாளர்களும், ஒன்று அல்லது "
"அதற்கு மேற்பட்ட கூடுதல் முன்னறிவிப்பாளர்களும் உள்ளனர். இது நிகழும்போது, மாதிரி 1 மாதிரி "
"2 க்குள் ** நெச்டட் ** என்று நாங்கள் கூறுகிறோம், அல்லது மாதிரி 1 என்பது மாதிரி 2 இன் ** "
"சப்மோடெல் ** ஆகும். சொற்களைப் பொருட்படுத்தாமல், இதன் பொருள் என்னவென்றால், மாதிரி 1 பற்றி "
"நாம் சிந்திக்க முடியும் ஒரு சுழிய கருதுகோள் மற்றும் மாதிரி 2 ஒரு மாற்று கருதுகோளாக. "
"உண்மையில் இதற்கான * f * சோதனையை மிகவும் நேரடியான பாணியில் உருவாக்கலாம்."

#: ../../Ch12/Ch12_Regression_12.rst:188
msgid ""
"We can fit both models to the data and obtain a residual sum of squares for "
"both models. I’ll denote these as SS\\ :sub:`res`\\ :sup:`(1)` and SS\\ :sub:"
"`res`\\ :sup:`(2)` respectively. The superscripting here just indicates "
"which model we’re talking about. Then our *F*-statistic is"
msgstr ""
"நாங்கள் இரண்டு மாடல்களையும் தரவுக்கு பொருத்தலாம் மற்றும் இரண்டு மாடல்களுக்கும் மீதமுள்ள "
"சதுரங்களைப் பெறலாம். நான் இவற்றை SS \\: sub: `res` \\: sup:` (1) `மற்றும் ss \\: "
"sub:` res` \\: sup: `(2)` என்று குறிப்பிடுகிறேன். இங்கே சூப்பர்ச்கிரிப்டிங் நாம் எந்த "
"மாதிரியைப் பற்றி பேசுகிறோம் என்பதைக் குறிக்கிறது. பின்னர் எங்கள் *f *-ச்டாடிச்டிக்"

#: ../../Ch12/Ch12_Regression_12.rst:194
msgid ""
"F = \\frac{(\\mbox{SS}_{res}^{(1)} - \\mbox{SS}_{res}^{(1)})/k}{(\\mbox{SS}"
"_{res}^{(2)})/(N-p-1)}\n"
"\n"
msgstr ""
"F = \\frac{(\\mbox{SS}_{res}^{(1)} - \\mbox{SS}_{res}^{(1)})/k}{(\\mbox"
"{SS}_{res}^{(2)})/(N-p-1)}\n"
"\n"

#: ../../Ch12/Ch12_Regression_12.rst:196
msgid ""
"where *N* is the number of observations, *p* is the number of predictors in "
"the full model (not including the intercept), and *k* is the difference in "
"the number of parameters between the two models.\\ [#]_ The degrees of "
"freedom here are *k* and *N* - *p* - 1. Note that it’s often more convenient "
"to think about the difference between those two SS values as a sum of "
"squares in its own right. That is"
msgstr ""
"* n * என்பது அவதானிப்புகளின் எண்ணிக்கை, * p * என்பது முழு மாதிரியில் உள்ள "
"முன்னறிவிப்பாளர்களின் எண்ணிக்கை (இடைமறிப்பு உட்பட), மற்றும் * K * என்பது இரண்டு "
"மாதிரிகளுக்கு இடையிலான அளவுருக்களின் எண்ணிக்கையில் உள்ள வேறுபாடு. \\ [#] _ இங்குள்ள "
"சுதந்திரத்தின் அளவுகள் * k * மற்றும் * n * - * p * - 1. அந்த இரண்டு எச்எச் மதிப்புகளுக்கு"
" இடையிலான வேறுபாட்டைப் பற்றி சிந்திப்பது பெரும்பாலும் வசதியானது என்பதை நினைவில் கொள்க. "
"அதாவது"

#: ../../Ch12/Ch12_Regression_12.rst:204
msgid ""
"SS\\ :sub:`Δ` = SS\\ :sub:`res`\\ :sup:`(1)` - SS\\ :sub:`res`\\ :sup:`(2)`"
msgstr ""
"SS\\ :sub:`Δ` = SS\\ :sub:`res`\\ :sup:`(1)` - SS\\ :sub:`res`\\ :sup:`(2)`"

#: ../../Ch12/Ch12_Regression_12.rst:206
msgid ""
"The reason why this is helpful is that we can express SS\\ :sub:`Δ` as a "
"measure of the extent to which the two models make different predictions "
"about the the outcome variable. Specifically,"
msgstr ""
"இது உதவியாக இருப்பதற்கான காரணம் என்னவென்றால், SS \\: Sub: `δ 'விளைவு மாறியைப் பற்றி "
"இரண்டு மாதிரிகள் எந்த அளவிற்கு வேறுபட்ட கணிப்புகளைச் செய்கின்றன என்பதை அளவிட முடியும். "
"குறிப்பாக,"

#: ../../Ch12/Ch12_Regression_12.rst:211
msgid ""
"SS\\ :sub:`Δ` = :math:`\\sum_{i} \\left(\\hat{y}_i^{(2)} - \\hat{y}_i^{(1)} "
"\\right)^2`"
msgstr ""
"SS\\ :sub:`Δ` = :math:`\\sum_{i} \\left(\\hat{y}_i^{(2)} - \\hat{y}_i^{(1)} "
"\\right)^2`"

#: ../../Ch12/Ch12_Regression_12.rst:213
msgid ""
"where *ŷ*\\ :sub:`i`\\ :sup:`(1)` is the fitted value for *y*\\ :sub:`i` "
"according to model M\\ :sub:`1` and *ŷ*\\ :sub:`i`\\ :sup:`(2)` is the "
"fitted value for *y*\\ :sub:`i` according to model M\\ :sub:`2`."
msgstr ""
"எங்கே *ŷ *\\: sub: `i` \\: sup:` (1) `என்பது *y *\\:` i` மாதிரி m \\: sub: `1` "
"மற்றும் *ŷ *ஆகியவற்றின் பொருத்தப்பட்ட மதிப்பு \\: துணை: `i` i: sup:` (2) `என்பது *y *"
"\\: துணை:` நான் மாதிரி M \\: துணை: `2` என்பதற்கு பொருத்தப்பட்ட மதிப்பு."

#: ../../Ch12/Ch12_Regression_12.rst:219 ../../Ch12/Ch12_Regression_12.rst:223
msgid "Model comparison in jamovi using the ``Model Builder`` option"
msgstr "`` மாதிரி பில்டர்`` விருப்பத்தைப் பயன்படுத்தி சாமோவியில் மாதிரி ஒப்பீடு"

#: ../../Ch12/Ch12_Regression_12.rst:227
msgid ""
"Okay, so that’s the hypothesis test that we use to compare two regression "
"models to one another. Now, how do we do it in jamovi? The answer is to use "
"the ``Model Builder`` option and specify the Model 1 predictors ``dani."
"sleep`` and ``day`` in ``Block 1`` and then add the additional predictor "
"from Model 2 (``baby.sleep``) in ``Block 2``, as in :numref:`fig-reg8`. This "
"shows, in the ``Model Comparisons`` Table, that for the comparisons between "
"Model 1 and Model 2, *F*\\ (1,96) = 0.00, *p* = 0.954. Since we have *p* > "
"0.05 we retain the null hypothesis (``M1``). This approach to regression, in "
"which we add all of our covariates into a null model, then *add* the "
"variables of interest into an alternative model, and then compare the two "
"models in a hypothesis testing framework, is often referred to as "
"**hierarchical regression**."
msgstr ""
"சரி, எனவே இரண்டு பின்னடைவு மாதிரிகளை ஒருவருக்கொருவர் ஒப்பிடுவதற்கு நாங்கள் பயன்படுத்தும்"
" கருதுகோள் சோதனை இதுதான். இப்போது, சமோவியில் அதை எப்படி செய்வது? `` மாதிரி பில்டர்` "
"விருப்பத்தைப் பயன்படுத்துவதும், மாதிரி 1 முன்னறிவிப்பாளர்களைக் குறிப்பிடுவதும் `டானி.லீப்``"
" மற்றும்` `நாள்``` `` பிளாக் 1`` இல் குறிப்பிடவும், பின்னர் மாதிரி 2 இலிருந்து கூடுதல் "
"முன்கணிப்பாளரைச் சேர்க்கவும் (` `` பிளாக் 2`` இல் `baby.sleep``), உள்ளதைப் போல: "
"numref:` fig-reg8`. மாதிரி 1 மற்றும் மாதிரி 2, *F *\\ (1,96) = 0.00, *p *= "
"0.954 க்கு இடையிலான ஒப்பீடுகளுக்கு இது `` மாதிரி ஒப்பீடுகள்` அட்டவணையில் காட்டுகிறது. "
"எங்களிடம் * p *> 0.05 இருப்பதால் சுழிய கருதுகோளை (`` M1``) வைத்திருக்கிறோம். "
"பின்னடைவுக்கான இந்த அணுகுமுறை, இதில் எங்கள் அனைத்து கோவாரியட்டுகள் அனைத்தையும் ஒரு சுழி"
"ய மாதிரியில் சேர்க்கிறோம், பின்னர் *வட்டி மாறிகளை ஒரு மாற்று மாதிரியில் சேர்க்கிறோம், "
"பின்னர் இரண்டு மாதிரிகளையும் ஒரு கருதுகோள் சோதனை கட்டமைப்பில் ஒப்பிட்டுப் பாருங்கள், "
"பெரும்பாலும் ** என குறிப்பிடப்படுகிறது ** படிநிலை பின்னடைவு **."

#: ../../Ch12/Ch12_Regression_12.rst:240
msgid ""
"We can also use this ``Model Comparison`` option to display a table that "
"shows the AIC and BIC for each model, making it easy to compare and identify "
"which model has the lowest value, as in :numref:`fig-reg8`."
msgstr ""
"ஒவ்வொரு மாடலுக்கும் AIC மற்றும் BIC ஐக் காட்டும் அட்டவணையைக் காண்பிப்பதற்கான இந்த `` மாதிரி"
" ஒப்பீடு` விருப்பத்தையும் நாம் பயன்படுத்தலாம், இது எந்த மாதிரியை மிகக் குறைந்த மதிப்பைக் "
"கொண்டுள்ளது என்பதை ஒப்பிட்டு அடையாளம் காண்பது: NUMREF: `Fig-reg8` ."

#: ../../Ch12/Ch12_Regression_12.rst:247
msgid ""
"While I’m on this topic I should point out that the empirical evidence "
"suggests that BIC is a better criterion than AIC. In most simulation studies "
"that I’ve seen, BIC does a much better job of selecting the correct model."
msgstr ""
"நான் இந்த தலைப்பில் இருக்கும்போது, அனுபவ சான்றுகள் AIC ஐ விட BIC ஒரு சிறந்த அளவுகோல் "
"என்று நான் சுட்டிக்காட்ட வேண்டும். நான் பார்த்த பெரும்பாலான உருவகப்படுத்துதல் ஆய்வுகளில், "
"சரியான மாதிரியைத் தேர்ந்தெடுப்பதில் BIC ஒரு சிறந்த வேலையைச் செய்கிறது."

#: ../../Ch12/Ch12_Regression_12.rst:252
msgid ""
"It’s worth noting in passing that this same *F*-statistic can be used to "
"test a much broader range of hypotheses than those that I’m mentioning here. "
"Very briefly, notice that the nested model M1 corresponds to the full model "
"M2 when we constrain some of the regression coefficients to zero. It is "
"sometimes useful to construct sub-models by placing other kinds of "
"constraints on the regression coefficients. For instance, maybe two "
"different coefficients might have to sum to zero, or something like that. "
"You can construct hypothesis tests for those kind of constraints too, but it "
"is somewhat more complicated and the sampling distribution for *F* can end "
"up being something known as the non-central *F*-distribution, which is "
"waaaaay beyond the scope of this book! All I want to do is alert you to this "
"possibility."
msgstr ""
"இதே *f *-நான் இங்கே குறிப்பிடுவதை விட பரந்த அளவிலான கருதுகோள்களை சோதிக்க "
"பயன்படுத்தப்படலாம் என்பதை கடந்து செல்வதில் கவனிக்கத்தக்கது. மிகச் சுருக்கமாக, சில பின்னடைவு"
" குணகங்களை பூச்சியமாகக் கட்டுப்படுத்தும்போது உள்ளமைக்கப்பட்ட மாதிரி M1 முழு மாதிரி M2 "
"உடன் ஒத்துப்போகிறது என்பதைக் கவனியுங்கள். பின்னடைவு குணகங்களில் பிற வகையான தடைகளை "
"வைப்பதன் மூலம் துணை மாதிரிகளை உருவாக்குவது சில நேரங்களில் பயனுள்ளதாக இருக்கும். "
"உதாரணமாக, இரண்டு வெவ்வேறு குணகங்கள் பூச்சியத்திற்கு தொகுக்க வேண்டியிருக்கலாம், அல்லது அது"
" போன்ற ஏதாவது இருக்கலாம். அந்த வகையான தடைகளுக்கும் நீங்கள் கருதுகோள் சோதனைகளை "
"உருவாக்கலாம், ஆனால் இது சற்றே மிகவும் சிக்கலானது மற்றும் *f *க்கான மாதிரி வழங்கல் மையமற்"
"ற *f *-distribution என அழைக்கப்படுகிறது, இது அதன் எல்லைக்கு அப்பாற்பட்டது இந்த புத்தகம்"
"! நான் செய்ய விரும்புவது இந்த சாத்தியத்திற்கு உங்களை எச்சரிக்க வேண்டும்."

#: ../../Ch12/Ch12_Regression_13.rst:4
msgid "Summary"
msgstr ""

#: ../../Ch12/Ch12_Regression_13.rst:6
msgid ""
"Want to know how strong the relationship is between two variables? Calculate "
"a :doc:`correlation <Ch12_Regression_01>`"
msgstr ""
"இரண்டு மாறிகள் இடையே உறவு எவ்வளவு வலுவானது என்பதை அறிய விரும்புகிறீர்களா? A: DOC: "
"`தொடர்பு <CH12_REGRESSION_01>`"

#: ../../Ch12/Ch12_Regression_13.rst:9
msgid "Drawing :doc:`scatterplots <Ch12_Regression_02>`"
msgstr "வரைதல்: டிஓசி: `சிதறல்கள் <CH12_REGRESSION_02>`"

#: ../../Ch12/Ch12_Regression_13.rst:11
msgid ""
":doc:`Basic ideas in linear regression <Ch12_Regression_03>` and :doc:`how "
"regression models are estimated <Ch12_Regression_04>`"
msgstr ""
":doc:`Basic ideas in நேரியல் regression <Ch12_Regression_03>` and :doc:`how "
"regression models அரே estimated <Ch12_Regression_04>`"

#: ../../Ch12/Ch12_Regression_13.rst:14
msgid ":doc:`Ch12_Regression_05`"
msgstr ":doc:`Ch12_Regression_05`"

#: ../../Ch12/Ch12_Regression_13.rst:16
msgid ""
"Measuring the :doc:`overall performance of a regression model using *R*\\² "
"<Ch12_Regression_06>`"
msgstr ""
"அளவிடுதல்: டிஓசி: ` *r *\\ ² <ch12_recression_06>` பயன்படுத்தி பின்னடைவு "
"மாதிரியின் ஒட்டுமொத்த செயல்திறன்> `"

#: ../../Ch12/Ch12_Regression_13.rst:19
msgid ":doc:`Ch12_Regression_07`"
msgstr ":doc:`Ch12_Regression_07`"

#: ../../Ch12/Ch12_Regression_13.rst:21
msgid ""
":doc:`Calculating confidence intervals for regression coefficients and "
"standardised coefficients <Ch12_Regression_09>`"
msgstr ""
":doc:`Calculating confidence intervals க்கு regression coefficients and "
"standardised coefficients <Ch12_Regression_09>`"

#: ../../Ch12/Ch12_Regression_13.rst:24
msgid ""
"The :doc:`assumptions of regression <Ch12_Regression_10>` and :doc:`how to "
"check them <Ch12_Regression_11>`"
msgstr ""
"தி: டாக்: `பின்னடைவின் அனுமானங்கள் <CH12_REGRESSION_10>` மற்றும்: டாக்: `<CH12 "
"பின்னடைவை எவ்வாறு சரிபார்க்கலாம் 11>`"

#: ../../Ch12/Ch12_Regression_13.rst:27
msgid ":doc:`Selecting a regression model <Ch12_Regression_12>`"
msgstr ":doc:`Selecting a regression மாதிரியுரு <Ch12_Regression_12>`"
