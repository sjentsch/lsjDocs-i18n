msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-06-12 11:37+0200\n"
"PO-Revision-Date: 2025-09-02 19:01+0000\n"
"Last-Translator: Максим Горпиніч <gorpinicmaksim0@gmail.com>\n"
"Language-Team: Ukrainian <https://hosted.weblate.org/projects/lsjdocs/ch08/"
"uk/>\n"
"Language: uk\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && "
"n%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2);\n"
"X-Generator: Weblate 5.13.1-dev\n"
"Generated-By: Babel 2.17.0\n"

#: ../../Ch08/Ch08_Estimation.rst:4
msgid "Estimating unknown quantities from a sample"
msgstr "Оцінювання невідомих величин з вибірки"

#: ../../Ch08/Ch08_Estimation.rst:18
msgid ""
"At the start of the last chapter I highlighted the critical distinction "
"between *descriptive statistics* and *inferential statistics*. As discussed "
"in :doc:`../Ch04/Ch04_Descriptives`, the role of descriptive statistics is "
"to concisely summarise what we *do* know. In contrast, the purpose of "
"inferential statistics is to “learn what we do not know from what we do”. "
"Now that we have a foundation in probability theory we are in a good "
"position to think about the problem of statistical inference. What kinds of "
"things would we like to learn about? And how do we learn them? These are the "
"questions that lie at the heart of inferential statistics, and they are "
"traditionally divided into two “big ideas”: estimation and hypothesis "
"testing. The goal in this chapter is to introduce the first of these big "
"ideas, estimation theory, but I’m going to witter on about sampling theory "
"first because estimation theory doesn’t make sense until you understand "
"sampling. As a consequence, this chapter divides naturally into two parts :"
"doc:`Ch08_Estimation_1` through :doc:`Ch08_Estimation_3` are focused on "
"sampling theory, and :doc:`Ch08_Estimation_4` and :doc:`Ch08_Estimation_5` "
"make use of sampling theory to discuss how statisticians think about "
"estimation."
msgstr ""
"На початку останнього розділу я підкреслив важливу відмінність між *описовою "
"статистикою* та *інференційною статистикою*. Як обговорювалося в :doc:`../"
"Ch04/Ch04_Descriptives`, роль описової статистики полягає в тому, щоб стисло "
"підсумувати те, що ми *знаємо*. На відміну від цього, метою інференційної "
"статистики є «дізнатися те, чого ми не знаємо, на основі того, що ми знаємо»"
". Тепер, коли ми маємо основи теорії ймовірностей, ми можемо розглянути "
"проблему статистичного інференції. Що саме ми хотіли б дізнатися? І як ми "
"можемо це дізнатися? Ці питання лежать в основі інференційної статистики, і "
"традиційно вони поділяються на дві «великі ідеї»: оцінювання та перевірка "
"гіпотез. Мета цього розділу — представити першу з цих великих ідей, теорію "
"оцінювання, але спочатку я розповім про теорію вибірки, оскільки теорія "
"оцінювання не має сенсу, доки ви не зрозумієте вибірку. Як наслідок, цей "
"розділ природно поділяється на дві частини: :doc:`Ch08_Estimation_1` до "
":doc:`Ch08_Estimation_3` зосереджені на теорії вибірки, а "
":doc:`Ch08_Estimation_4` і :doc:`Ch08_Estimation_5` використовують теорію "
"вибірки для обговорення того, як статистики думають про оцінку."

#: ../../Ch08/Ch08_Estimation_1.rst:4
msgid "Samples, populations and sampling"
msgstr "Вибірки, популяції та вибірка"

#: ../../Ch08/Ch08_Estimation_1.rst:6
msgid ""
"In the prelude to Part  I discussed the riddle of induction and highlighted "
"the fact that *all* learning requires you to make assumptions. Accepting "
"that this is true, our first task to come up with some fairly general "
"assumptions about data that make sense. This is where **sampling theory** "
"comes in. If probability theory is the foundations upon which all "
"statistical theory builds, sampling theory is the frame around which you can "
"build the rest of the house. Sampling theory plays a huge role in specifying "
"the assumptions upon which your statistical inferences rely. And in order to "
"talk about “making inferences” the way statisticians think about it we need "
"to be a bit more explicit about what it is that we’re drawing inferences "
"*from* (the sample) and what it is that we’re drawing inferences *about* "
"(the population)."
msgstr ""
"У вступі до частини I я обговорив загадку індукції та підкреслив той факт, "
"що *будь-яке* навчання вимагає від вас робити припущення. Приймаючи це як "
"факт, нашим першим завданням є сформулювати досить загальні припущення щодо "
"даних, які мають сенс. Тут на допомогу приходить **теорія вибірки**. Якщо "
"теорія ймовірності є фундаментом, на якому будується вся статистична теорія, "
"то теорія вибірки є каркасом, навколо якого можна побудувати решту будинку. "
"Теорія вибірки відіграє величезну роль у визначенні припущень, на яких "
"базуються ваші статистичні висновки. І щоб говорити про «робити висновки» "
"так, як про це думають статистики, нам потрібно бути трохи більш чіткими "
"щодо того, *з чого* ми робимо висновки (вибірка) і *про* що ми робимо "
"висновки (популяція)."

#: ../../Ch08/Ch08_Estimation_1.rst:20
msgid ""
"In almost every situation of interest what we have available to us as "
"researchers is a **sample** of data. We might have run experiment with some "
"number of participants, a polling company might have phoned some number of "
"people to ask questions about voting intentions, and so on. In this way the "
"data set available to us is finite and incomplete. We can’t possibly get "
"every person in the world to do our experiment, for example a polling "
"company doesn’t have the time or the money to ring up every voter in the "
"country. In our earlier discussion of :doc:`../Ch04/Ch04_Descriptives`, this "
"sample was the only thing we were interested in. Our only goal was to find "
"ways of describing, summarising and graphing that sample. This is about to "
"change."
msgstr ""
"У майже кожній ситуації, що нас цікавить, ми, як дослідники, маємо у своєму "
"розпорядженні **вибірку** даних. Ми могли провести експеримент з певною "
"кількістю учасників, соціологічна компанія могла зателефонувати певній "
"кількості людей, щоб задати їм питання про наміри голосування тощо. Таким "
"чином, набір даних, який ми маємо у своєму розпорядженні, є скінченним і "
"неповним. Ми не можемо залучити до нашого експерименту всіх людей у світі, "
"наприклад, соціологічна компанія не має часу чи грошей, щоб зателефонувати "
"кожному виборцю в країні. У нашій попередній дискусії про :doc:`../Ch04/"
"Ch04_Descriptives` ця вибірка була єдиною річчю, яка нас цікавила. Нашою "
"єдиною метою було знайти способи опису, узагальнення та графічного "
"представлення цієї вибірки. Це скоро зміниться."

#: ../../Ch08/Ch08_Estimation_1.rst:32
msgid "Defining a population"
msgstr "Визначення популяції"

#: ../../Ch08/Ch08_Estimation_1.rst:34
msgid ""
"A sample is a concrete thing. You can open up a data file and there’s the "
"data from your sample. A **population**, on the other hand, is a more "
"abstract idea. It refers to the set of all possible people, or all possible "
"observations, that you want to draw conclusions about and is generally "
"*much* bigger than the sample. In an ideal world the researcher would begin "
"the study with a clear idea of what the population of interest is, since the "
"process of designing a study and testing hypotheses with the data does "
"depend on the population about which you want to make statements."
msgstr ""
"Вибірка – це конкретна річ. Ви можете відкрити файл з даними і побачити дані "
"з вашої вибірки. Натомість **популяція** – це більш абстрактне поняття. Воно "
"означає сукупність усіх можливих людей або всіх можливих спостережень, про "
"які ви хочете зробити висновки, і зазвичай є *набагато* більшою за вибірку. "
"В ідеальному світі дослідник розпочинав би дослідження з чітким уявленням "
"про те, що таке цікава йому генеральна сукупність, оскільки процес розробки "
"дослідження та перевірки гіпотез за допомогою даних залежить від генеральної "
"сукупності, про яку ви хочете зробити висновки."

#: ../../Ch08/Ch08_Estimation_1.rst:44
msgid ""
"Sometimes it’s easy to state the population of interest. For instance, in "
"the “polling company” example that opened the chapter the population "
"consisted of all voters enrolled at the time of the study, millions of "
"people. The sample was a set of 1000 people who all belong to that "
"population. In most studies the situation is much less straightforward. In a "
"typical psychological experiment determining the population of interest is a "
"bit more complicated. Suppose I run an experiment using 100 undergraduate "
"students as my participants. My goal, as a cognitive scientist, is to try to "
"learn something about how the mind works. So, which of the following would "
"count as “the population”:"
msgstr ""
"Іноді легко визначити популяцію, що нас цікавить. Наприклад, у прикладі з «"
"компанією, що проводить опитування», який наводився на початку розділу, "
"популяція складалася з усіх виборців, зареєстрованих на момент дослідження, "
"тобто мільйонів людей. Вибірка складалася з 1000 осіб, які всі належали до "
"цієї популяції. У більшості досліджень ситуація набагато складніша. У "
"типовому психологічному експерименті визначення популяції, що нас цікавить, "
"є дещо складнішим. Припустимо, я проводжу експеримент, в якому беруть участь "
"100 студентів-бакалаврів. Моя мета, як когнітивного вченого, полягає в тому, "
"щоб дізнатися щось про те, як працює розум. Отже, що з наведеного нижче "
"можна вважати «популяцією»:"

#: ../../Ch08/Ch08_Estimation_1.rst:55
msgid ""
"All of the undergraduate psychology students at the University of Adelaide?"
msgstr "Усі студенти-психологи в Університеті Аделаїди?"

#: ../../Ch08/Ch08_Estimation_1.rst:58
msgid "Undergraduate psychology students in general, anywhere in the world?"
msgstr "Студенти-психологи загалом, де завгодно у світі?"

#: ../../Ch08/Ch08_Estimation_1.rst:60
msgid "Australians currently living?"
msgstr "Австралійці, які зараз проживають?"

#: ../../Ch08/Ch08_Estimation_1.rst:62
msgid "Australians of similar ages to my sample?"
msgstr "Австралійці того ж віку, що й моя вибірка?"

#: ../../Ch08/Ch08_Estimation_1.rst:64
msgid "Anyone currently alive?"
msgstr "Є хтось зараз живий?"

#: ../../Ch08/Ch08_Estimation_1.rst:66
msgid "Any human being, past, present or future?"
msgstr "Будь-яка людина, минула, теперішня чи майбутня?"

#: ../../Ch08/Ch08_Estimation_1.rst:68
msgid ""
"Any biological organism with a sufficient degree of intelligence operating "
"in a terrestrial environment?"
msgstr ""
"Будь-який біологічний організм з достатнім ступенем інтелекту, що діє в "
"земному середовищі?"

#: ../../Ch08/Ch08_Estimation_1.rst:71
msgid "Any intelligent being?"
msgstr "Якась розумна істота?"

#: ../../Ch08/Ch08_Estimation_1.rst:73
msgid ""
"Each of these defines a real group of mind-possessing entities, all of which "
"might be of interest to me as a cognitive scientist, and it’s not at all "
"clear which one ought to be the true population of interest. As another "
"example, consider the Wellesley-Croker game that we discussed in the "
"prelude. The sample here is a specific sequence of 12 wins and 0 losses for "
"Wellesley. What is the population?"
msgstr ""
"Кожен з них визначає реальну групу істот, що володіють розумом, і всі вони "
"можуть бути цікавими для мене як когнітивного вченого, і зовсім не ясно, яка "
"з них повинна бути справжньою популяцією, що представляє інтерес. Як ще один "
"приклад, розглянемо гру Велслі-Крокера, яку ми обговорювали в прелюдії. "
"Вибірка тут — це конкретна послідовність 12 перемог і 0 поразок для Велслі. "
"Що таке популяція?"

#: ../../Ch08/Ch08_Estimation_1.rst:80
msgid "All outcomes until Wellesley and Croker arrived at their destination?"
msgstr "Усі результати, поки Веллслі та Крокер не прибули до місця призначення?"

#: ../../Ch08/Ch08_Estimation_1.rst:82
msgid ""
"All outcomes if Wellesley and Croker had played the game for the rest of "
"their lives?"
msgstr "Якби Веллслі та Крокер грали в цю гру до кінця свого життя?"

#: ../../Ch08/Ch08_Estimation_1.rst:85
msgid ""
"All outcomes if Wellseley and Croker lived forever and played the game until "
"the world ran out of hills?"
msgstr ""
"Якби Веллслі та Крокер жили вічно та грали в гру, поки у світі не "
"закінчилися пагорби?"

#: ../../Ch08/Ch08_Estimation_1.rst:88
msgid ""
"All outcomes if we created an infinite set of parallel universes and the "
"Wellesely/Croker pair made guesses about the same 12 hills in each universe?"
msgstr ""
"Які б були результати, якби ми створили нескінченну множину паралельних "
"всесвітів, і пара Веллслі/Крокера зробила б припущення щодо тих самих 12 "
"пагорбів у кожному всесвіті?"

#: ../../Ch08/Ch08_Estimation_1.rst:92
msgid "Again, it’s not obvious what the population is."
msgstr "Знову ж таки, незрозуміло, яка чисельність населення."

#: ../../Ch08/Ch08_Estimation_1.rst:95
msgid "Simple random samples"
msgstr "Прості випадкові вибірки"

#: ../../Ch08/Ch08_Estimation_1.rst:97
msgid ""
"Irrespective of how I define the population, the critical point is that the "
"sample is a subset of the population and our goal is to use our knowledge of "
"the sample to draw inferences about the properties of the population. The "
"relationship between the two depends on the *procedure* by which the sample "
"was selected. This procedure is referred to as a **sampling method** and it "
"is important to understand why it matters."
msgstr ""
"Незалежно від того, як я визначаю сукупність, критичним моментом є те, що "
"вибірка є підмножиною сукупності, і наша мета полягає в тому, щоб "
"використовувати наші знання про вибірку для отримання висновків про "
"властивості сукупності. Взаємозв'язок між цими двома поняттями залежить від "
"*процедури*, за допомогою якої була відібрана вибірка. Ця процедура "
"називається **методом вибірки**, і важливо розуміти, чому вона має значення."

#: ../../Ch08/Ch08_Estimation_1.rst:104
msgid ""
"To keep things simple, let’s imagine that we have a bag containing 10 chips. "
"Each chip has a unique letter printed on it so we can distinguish between "
"the 10 chips. The chips come in two colours, black and white. This set of "
"chips is the population of interest and it is depicted graphically on the "
"left of :numref:`fig-srs1`. As you can see from looking at the picture there "
"are 4 black chips and 6 white chips, but of course in real life we wouldn’t "
"know that unless we looked in the bag. Now imagine you run the following "
"“experiment”: you shake up the bag, close your eyes, and pull out 4 chips "
"without putting any of them back into the bag. First out comes the *a* chip "
"(black), then the *c* chip (white), then *j* (white) and then finally *b* "
"(black). If you wanted you could then put all the chips back in the bag and "
"repeat the experiment, as depicted on the right hand side of :numref:`fig-"
"srs1`. Each time you get different results but the procedure is identical in "
"each case. The fact that the same procedure can lead to different results "
"each time we refer to as a *random* process.\\ [#]_ However, because we "
"shook the bag before pulling any chips out, it seems reasonable to think "
"that every chip has the same chance of being selected. A procedure in which "
"every member of the population has the same chance of being selected is "
"called a **simple random sample**. The fact that we did *not* put the chips "
"back in the bag after pulling them out means that you can’t observe the same "
"thing twice, and in such cases the observations are said to have been "
"sampled **without replacement**."
msgstr ""
"Для простоти уявимо, що у нас є мішок, в якому знаходиться 10 фішок. На "
"кожній фішці надрукована унікальна літера, щоб ми могли розрізнити 10 фішок. "
"Фішки бувають двох кольорів: чорного та білого. Цей набір фішок є "
"популяцією, що нас цікавить, і він зображений графічно зліва від :numref"
":`fig-srs1`. Як ви можете бачити на малюнку, є 4 чорні фішки і 6 білих "
"фішок, але, звичайно, в реальному житті ми б цього не знали, якби не "
"заглянули в мішок. Тепер уявіть, що ви проводите такий «експеримент»: ви "
"струшуєте мішок, закриваєте очі і витягуєте 4 фішки, не кладучи жодної з них "
"назад у мішок. Спочатку випадає фішка *a* (чорна), потім фішка *c* (біла), "
"потім *j* (біла) і, нарешті, *b* (чорна). Якщо ви хочете, ви можете покласти "
"всі фішки назад у мішок і повторити експеримент, як показано в правій "
"частині :numref:`fig-srs1`. Кожного разу ви отримуєте різні результати, але "
"процедура в кожному випадку однакова. Той факт, що одна і та ж процедура "
"може приводити до різних результатів кожного разу, ми називаємо *випадковим* "
"процесом. [#]_ Однак, оскільки ми струшували мішок перед тим, як витягувати "
"фішки, здається розумним вважати, що кожна фішка має однакову ймовірність "
"бути вибраною. Процедура, в якій кожен член сукупності має однакову "
"ймовірність бути вибраним, називається **простою випадковою вибіркою**. Той "
"факт, що ми *не* клали фішки назад у мішок після їх виймання, означає, що ви "
"не можете спостерігати одне й те саме двічі, і в таких випадках "
"спостерігання називаються вибіркою **без заміщення**."

#: ../../Ch08/Ch08_Estimation_1.rst:129 ../../Ch08/Ch08_Estimation_1.rst:133
msgid "Simple random sampling WITHOUT replacement from a finite population"
msgstr "Проста випадкова вибірка БЕЗ заміни з кінцевої генеральної сукупності"

#: ../../Ch08/Ch08_Estimation_1.rst:137
msgid ""
"To help make sure you understand the importance of the sampling procedure, "
"consider an alternative way in which the experiment could have been run. "
"Suppose that my 5-year old son had opened the bag and decided to pull out "
"four black chips without putting any of them back in the bag. This *biased* "
"sampling scheme is depicted in :numref:`fig-brs`. Now consider the "
"evidential value of seeing 4 black chips and 0 white chips. Clearly it "
"depends on the sampling scheme, does it not? If you know that the sampling "
"scheme is biased to select only black chips then a sample that consists of "
"only black chips doesn’t tell you very much about the population! For this "
"reason statisticians really like it when a data set can be considered a "
"simple random sample, because it makes the data analysis *much* easier."
msgstr ""
"Щоб переконатися, що ви розумієте важливість процедури вибірки, розгляньте "
"альтернативний варіант проведення експерименту. Припустимо, що мій 5-річний "
"син відкрив пакет і вирішив витягнути чотири чорні фішки, не кладучи жодної "
"з них назад у пакет. Ця *упереджена* схема вибірки зображена на малюнку "
":numref:`fig-brs`. Тепер розгляньте доказову цінність того, що ви бачите 4 "
"чорні фішки і 0 білих фішок. Очевидно, що це залежить від схеми вибірки, чи "
"не так? Якщо ви знаєте, що схема вибірки є упередженою і відбирає тільки "
"чорні фішки, то вибірка, що складається тільки з чорних фішок, не дає вам "
"багато інформації про сукупність! З цієї причини статистики дуже люблять, "
"коли набір даних можна вважати простою випадковою вибіркою, оскільки це "
"*значно* полегшує аналіз даних."

#: ../../Ch08/Ch08_Estimation_1.rst:151 ../../Ch08/Ch08_Estimation_1.rst:155
msgid "Biased sampling WITHOUT replacement from a finite population"
msgstr "Упереджена вибірка БЕЗ заміни з обмеженої сукупності"

#: ../../Ch08/Ch08_Estimation_1.rst:159
msgid ""
"A third procedure is worth mentioning. This time around we close our eyes, "
"shake the bag, and pull out a chip. This time, however, we record the "
"observation and then put the chip back in the bag. Again we close our eyes, "
"shake the bag, and pull out a chip. We then repeat this procedure until we "
"have 4 chips. Data sets generated in this way are still simple random "
"samples, but because we put the chips back in the bag immediately after "
"drawing them it is referred to as a sample **with replacement**. The "
"difference between this situation and the first one is that it is possible "
"to observe the same population member multiple times, as illustrated in "
"numref:`fig-srs2`."
msgstr ""
"Варто згадати про третю процедуру. Цього разу ми закриваємо очі, струшуємо "
"мішок і витягуємо фішку. Однак цього разу ми записуємо спостереження, а "
"потім кладемо фішку назад у мішок. Знову закриваємо очі, струшуємо мішок і "
"витягуємо фішку. Потім повторюємо цю процедуру, поки не отримаємо 4 фішки. "
"Набори даних, отримані таким чином, все ще є простими випадковими вибірками, "
"але оскільки ми кладемо фішки назад у мішок відразу після їх витягання, це "
"називається вибіркою **з заміщенням**. Відмінність цієї ситуації від першої "
"полягає в тому, що можна спостерігати одного і того ж члена популяції кілька "
"разів, як показано на numref:`fig-srs2`."

#: ../../Ch08/Ch08_Estimation_1.rst:171 ../../Ch08/Ch08_Estimation_1.rst:175
msgid "Simple random sampling WITH replacement from a finite population"
msgstr "Проста випадкова вибірка з заміною зі скінченної генеральної сукупності"

#: ../../Ch08/Ch08_Estimation_1.rst:179
msgid ""
"In my experience, most psychology experiments tend to be sampling without "
"replacement, because the same person is not allowed to participate in the "
"experiment twice. However, most statistical theory is based on the "
"assumption that the data arise from a simple random sample *with* "
"replacement. In real life this very rarely matters. If the population of "
"interest is large (e.g., has more than 10 entities!) the difference between "
"sampling with- and without- replacement is too small to be concerned with. "
"The difference between simple random samples and biased samples, on the "
"other hand, is not such an easy thing to dismiss."
msgstr ""
"З мого досвіду, більшість психологічних експериментів, як правило, "
"проводяться без заміщення, оскільки одна і та ж особа не може брати участь в "
"експерименті двічі. Однак більшість статистичних теорій базуються на "
"припущенні, що дані отримуються з простої випадкової вибірки *з* заміщенням. "
"У реальному житті це дуже рідко має значення. Якщо популяція, що нас "
"цікавить, є великою (наприклад, має більше 10 одиниць!), різниця між "
"вибіркою з заміщенням і без заміщення є надто малою, щоб нею перейматися. З "
"іншого боку, різницю між простими випадковими вибірками та вибірками з "
"відхиленням не так легко ігнорувати."

#: ../../Ch08/Ch08_Estimation_1.rst:190
msgid "Most samples are not simple random samples"
msgstr "Більшість вибірок не є простими випадковими вибірками"

#: ../../Ch08/Ch08_Estimation_1.rst:192
msgid ""
"As you can see from looking at the list of possible populations that I "
"showed above, it is almost impossible to obtain a simple random sample from "
"most populations of interest. When I run experiments I’d consider it a minor "
"miracle if my participants turned out to be a random sampling of the "
"undergraduate psychology students at Adelaide university, even though this "
"is by far the narrowest population that I might want to generalise to. A "
"thorough discussion of other types of sampling schemes is beyond the scope "
"of this book, but to give you a sense of what’s out there I’ll list a few of "
"the more important ones."
msgstr ""
"Як ви можете бачити з переліку можливих популяцій, який я навів вище, "
"отримати просту випадкову вибірку з більшості популяцій, що представляють "
"інтерес, майже неможливо. Коли я проводжу експерименти, я вважаю невеликим "
"дивом, якщо мої учасники виявляються випадковою вибіркою студентів-"
"психологів Аделаїдського університету, навіть незважаючи на те, що це "
"найвужча популяція, яку я міг би узагальнити. Детальне обговорення інших "
"типів схем вибірки виходить за рамки цієї книги, але щоб дати вам уявлення "
"про те, що існує, я перерахую кілька найважливіших з них."

#: ../../Ch08/Ch08_Estimation_1.rst:202
msgid ""
"*Stratified sampling*. Suppose your population is (or can be) divided into "
"several different sub-populations, or *strata*. Perhaps you’re running a "
"study at several different sites, for example. Instead of trying to sample "
"randomly from the population as a whole, you instead try to collect a "
"separate random sample from each of the strata. Stratified sampling is "
"sometimes easier to do than simple random sampling, especially when the "
"population is already divided into the distinct strata. It can also be more "
"efficient than simple random sampling, especially when some of the sub-"
"populations are rare. For instance, when studying schizophrenia it would be "
"much better to divide the population into two\\ [#]_ strata (schizophrenic "
"and not-schizophrenic) and then sample an equal number of people from each "
"group. If you selected people randomly you would get so few schizophrenic "
"people in the sample that your study would be useless. This specific kind of "
"of stratified sampling is referred to as *oversampling* because it makes a "
"deliberate attempt to over-represent rare groups."
msgstr ""
"*Стратифікована вибірка*. Припустимо, що ваша сукупність поділяється (або "
"може поділятися) на кілька різних підсукупностей, або *страт*. Наприклад, ви "
"проводите дослідження в декількох різних місцях. Замість того, щоб "
"намагатися відібрати випадкову вибірку з усієї сукупності, ви намагаєтеся "
"зібрати окрему випадкову вибірку з кожного страти. Стратифікована вибірка "
"іноді легша у виконанні, ніж проста випадкова вибірка, особливо коли "
"сукупність вже поділена на окремі страти. Вона також може бути ефективнішою "
"за просту випадкову вибірку, особливо коли деякі підгрупи сукупності є "
"рідкісними. Наприклад, при дослідженні шизофренії набагато краще розділити "
"популяцію на два [#]_ страти (шизофреніки та нешизофреніки), а потім "
"відібрати рівну кількість людей з кожної групи. Якщо вибрати людей "
"випадково, у вибірці буде так мало шизофреніків, що дослідження буде марним. "
"Цей конкретний вид стратифікованої вибірки називається *надмірною вибіркою*, "
"оскільки він є свідомою спробою надмірно представити рідкісні групи."

#: ../../Ch08/Ch08_Estimation_1.rst:220
msgid ""
"*Snowball sampling* is a technique that is especially useful when sampling "
"from a “hidden” or hard to access population and is especially common in "
"social sciences. For instance, suppose the researchers want to conduct an "
"opinion poll among transgender people. The research team might only have "
"contact details for a few trans folks, so the survey starts by asking them "
"to participate (stage 1). At the end of the survey the participants are "
"asked to provide contact details for other people who might want to "
"participate. In stage 2 those new contacts are surveyed. The process "
"continues until the researchers have sufficient data. The big advantage to "
"snowball sampling is that it gets you data in situations that might "
"otherwise be impossible to get any. On the statistical side, the main "
"disadvantage is that the sample is highly non-random, and non-random in ways "
"that are difficult to address. On the real life side, the disadvantage is "
"that the procedure can be unethical if not handled well, because hidden "
"populations are often hidden for a reason. I chose transgender people as an "
"example here to highlight this issue. If you weren’t careful you might end "
"up outing people who don’t want to be outed (very, very bad form), and even "
"if you don’t make that mistake it can still be intrusive to use people’s "
"social networks to study them. It’s certainly very hard to get people’s "
"informed consent *before* contacting them, yet in many cases the simple act "
"of contacting them and saying “hey we want to study you” can be hurtful. "
"Social networks are complex things, and just because you can use them to get "
"data doesn’t always mean you should."
msgstr ""
"*Сніговий вибір* — це метод, який є особливо корисним при вибірці з "
"«прихованої» або важкодоступної популяції і особливо поширений у соціальних "
"науках. Наприклад, припустимо, що дослідники хочуть провести опитування "
"серед трансгендерних людей. Дослідницька група може мати контактні дані лише "
"декількох трансгендерних людей, тому опитування починається з того, що їх "
"просять взяти участь (етап 1). Наприкінці опитування учасників просять "
"надати контактні дані інших людей, які можуть захотіти взяти участь. На "
"етапі 2 опитуються ці нові контакти. Процес триває, доки дослідники не "
"отримають достатню кількість даних. Великою перевагою снігової вибірки є те, "
"що вона дозволяє отримати дані в ситуаціях, коли інакше це було б неможливо. "
"З точки зору статистики, головним недоліком є те, що вибірка є вкрай "
"невипадковою, і невипадковою в такий спосіб, що це важко виправити. З точки "
"зору реального життя, недоліком є те, що ця процедура може бути неетичною, "
"якщо її не проводити обережно, оскільки приховані групи населення часто "
"приховані з певних причин. Я вибрав трансгендерних людей як приклад, щоб "
"підкреслити цю проблему. Якщо не бути обережним, можна викрити людей, які не "
"хочуть, щоб про них дізналися (що є дуже, дуже поганим тоном), і навіть якщо "
"не припуститися такої помилки, використання соціальних мереж людей для їх "
"дослідження все одно може бути втручанням у їхнє приватне життя. Звичайно, "
"дуже важко отримати інформовану згоду людей *перед* тим, як зв'язатися з "
"ними, але в багатьох випадках сам факт зв'язку з ними і слова «привіт, ми "
"хочемо вас дослідити» можуть бути образливими. Соціальні мережі — це складні "
"речі, і те, що ви можете використовувати їх для отримання даних, не завжди "
"означає, що ви повинні це робити."

#: ../../Ch08/Ch08_Estimation_1.rst:246
msgid ""
"*Convenience sampling* is more or less what it sounds like. The samples are "
"chosen in a way that is convenient to the researcher, and not selected at "
"random from the population of interest. Snowball sampling is one type of "
"convenience sampling, but there are many others. A common example in "
"psychology are studies that rely on undergraduate psychology students. These "
"samples are generally non-random in two respects. First, reliance on "
"undergraduate psychology students automatically means that your data are "
"restricted to a single sub-population. Second, the students usually get to "
"pick which studies they participate in, so the sample is a self selected "
"subset of psychology students and not a randomly selected subset. In real "
"life most studies are convenience samples of one form or another. This is "
"sometimes a severe limitation, but not always."
msgstr ""
"*Зручна вибірка* — це приблизно те, що випливає з назви. Вибірка формується "
"таким чином, щоб бути зручною для дослідника, а не випадковим чином з "
"цікавої для нього групи населення. Снігова вибірка — це один із видів "
"зручної вибірки, але існує й багато інших. Поширеним прикладом у психології "
"є дослідження, що базуються на студентах-психологах. Такі вибірки, як "
"правило, є невипадковими у двох аспектах. По-перше, використання студентів-"
"психологів автоматично означає, що ваші дані обмежуються однією підгрупою "
"населення. По-друге, студенти зазвичай самі вибирають, в яких дослідженнях "
"брати участь, тому вибірка є самовідібраною підгрупою студентів-психологів, "
"а не випадково відібраною підгрупою. У реальному житті більшість досліджень "
"є вибірками за зручністю в тій чи іншій формі. Іноді це є серйозним "
"обмеженням, але не завжди."

#: ../../Ch08/Ch08_Estimation_1.rst:261
msgid "How much does it matter if you don’t have a simple random sample?"
msgstr "Яке це має значення, якщо у вас немає простої випадкової вибірки?"

#: ../../Ch08/Ch08_Estimation_1.rst:263
msgid ""
"Okay, so real world data collection tends not to involve nice simple random "
"samples. Does that matter? A little thought should make it clear to you that "
"it *can* matter if your data are not a simple random sample. Just think "
"about the difference between :numref:`fig-srs1` and :numref:`fig-brs`. "
"However, it’s not quite as bad as it sounds. Some types of biased samples "
"are entirely unproblematic. For instance, when using a stratified sampling "
"technique you actually *know* what the bias is because you created it "
"deliberately, often to *increase* the effectiveness of your study, and there "
"are statistical techniques that you can use to adjust for the biases you’ve "
"introduced (not covered in this book!). So in those situations it’s not a "
"problem."
msgstr ""
"Гаразд, отже, збір даних у реальному світі, як правило, не передбачає "
"використання простих випадкових вибірок. Чи має це значення? Якщо трохи "
"подумати, то стане зрозуміло, що це *може* мати значення, якщо ваші дані не "
"є простою випадковою вибіркою. Просто подумайте про різницю між :numref:`fig-"
"srs1` та :numref:`fig-brs`. Однак це не так погано, як здається. Деякі типи "
"упереджених вибірок не становлять жодної проблеми. Наприклад, при "
"використанні методу стратифікованої вибірки ви насправді *знаєте*, яке саме "
"є упередження, оскільки ви створили його навмисно, часто для *підвищення* "
"ефективності вашого дослідження, і існують статистичні методи, які ви можете "
"використовувати для коригування введених вами упереджень (це не "
"розглядається в цій книзі!). Тож у таких ситуаціях це не є проблемою."

#: ../../Ch08/Ch08_Estimation_1.rst:276
msgid ""
"More generally though, it’s important to remember that random sampling is a "
"means to an end, and not the end in itself. Let’s assume you’ve relied on a "
"convenience sample, and as such you can assume it’s biased. A bias in your "
"sampling method is only a problem if it causes you to draw the wrong "
"conclusions. When viewed from that perspective, I’d argue that we don’t need "
"the sample to be randomly generated in *every* respect, we only need it to "
"be random with respect to the psychologically-relevant phenomenon of "
"interest. Suppose I’m doing a study looking at working memory capacity. In "
"study 1, I actually have the ability to sample randomly from all human "
"beings currently alive, with one exception: I can only sample people born on "
"a Monday. In study 2, I am able to sample randomly from the Australian "
"population. I want to generalise my results to the population of all living "
"humans. Which study is better? The answer, obviously, is study 1. Why? "
"Because we have no reason to think that being “born on a Monday” has any "
"interesting relationship to working memory capacity. In contrast, I can "
"think of several reasons why “being Australian” might matter. Australia is a "
"wealthy, industrialised country with a very well-developed education system. "
"People growing up in that system will have had life experiences much more "
"similar to the experiences of the people who designed the tests for working "
"memory capacity. This shared experience might easily translate into similar "
"beliefs about how to “take a test”, a shared assumption about how "
"psychological experimentation works, and so on. These things might actually "
"matter. For instance, “test taking” style might have taught the Australian "
"participants how to direct their attention exclusively on fairly abstract "
"test materials much more than people who haven’t grown up in a similar "
"environment. This could therefore lead to a misleading picture of what "
"working memory capacity is."
msgstr ""
"Однак, загалом важливо пам'ятати, що випадкова вибірка є засобом для "
"досягнення мети, а не самоціллю. Припустимо, ви покладалися на вибірку за "
"зручністю, і тому можете вважати її упередженою. Упередженість вашого методу "
"вибірки є проблемою лише в тому випадку, якщо вона змушує вас робити "
"неправильні висновки. Якщо дивитися з цієї точки зору, я б сказав, що нам не "
"потрібно, щоб вибірка була випадковою в *усіх* відношеннях, нам потрібно, "
"щоб вона була випадковою лише стосовно психологічно значущого явища, що нас "
"цікавить. Припустимо, я проводжу дослідження, присвячене дослідженню обсягу "
"робочої пам'яті. У дослідженні 1 я маю можливість проводити випадкову "
"вибірку серед усіх людей, що зараз живуть, за одним винятком: я можу брати в "
"вибірку лише людей, народжених у понеділок. У дослідженні 2 я можу проводити "
"випадкову вибірку з австралійського населення. Я хочу узагальнити свої "
"результати на все населення живих людей. Яке дослідження краще? Відповідь, "
"очевидно, — дослідження 1. Чому? Тому що ми не маємо підстав вважати, що «"
"народження в понеділок» має якийсь цікавий зв'язок з об'ємом робочої "
"пам'яті. Натомість я можу придумати кілька причин, чому «австралійське "
"походження» може мати значення. Австралія — багата, індустріалізована країна "
"з дуже добре розвиненою системою освіти. Люди, які виросли в цій системі, "
"матимуть життєвий досвід, набагато схожий на досвід людей, які розробляли "
"тести на обсяг робочої пам'яті. Цей спільний досвід може легко перетворитися "
"на схожі переконання щодо того, як «складати тест», спільні припущення про "
"те, як працюють психологічні експерименти, тощо. Ці речі можуть мати "
"значення. Наприклад, стиль «складання тестів» міг навчити австралійських "
"учасників зосереджувати свою увагу виключно на досить абстрактних тестових "
"матеріалах набагато більше, ніж людей, які не виросли в подібному "
"середовищі. Це може призвести до хибного уявлення про те, що таке обсяг "
"робочої пам'яті."

#: ../../Ch08/Ch08_Estimation_1.rst:306
msgid ""
"There are two points hidden in this discussion. First, when designing your "
"own studies, it’s important to think about what population you care about "
"and try hard to sample in a way that is appropriate to that population. In "
"practice, you’re usually forced to put up with a “sample of convenience” (e."
"g., psychology lecturers sample psychology students because that’s the least "
"expensive way to collect data, and our coffers aren’t exactly overflowing "
"with gold), but if so you should at least spend some time thinking about "
"what the dangers of this practice might be. Second, if you’re going to "
"criticise someone else’s study because they’ve used a sample of convenience "
"rather than laboriously sampling randomly from the entire human population, "
"at least have the courtesy to offer a specific theory as to *how* this might "
"have distorted the results."
msgstr ""
"У цій дискусії приховано два моменти. По-перше, при розробці власних "
"досліджень важливо подумати про те, яка група населення вас цікавить, і "
"постаратися зробити вибірку, яка буде відповідати цій групі. На практиці "
"зазвичай доводиться миритися з «вибіркою зручності» (наприклад, викладачі "
"психології беруть вибірку зі студентів-психологів, оскільки це найдешевший "
"спосіб збору даних, а наші скарбниці не переповнені золотом), але в такому "
"випадку слід принаймні витратити деякий час на обдумування можливих небезпек "
"такої практики. По-друге, якщо ви збираєтеся критикувати дослідження когось "
"іншого за те, що він використовував вибірку зручності, а не ретельно "
"підбирав випадкову вибірку з усього населення, то принаймні майте "
"ввічливість запропонувати конкретну теорію щодо того, *як* це могло "
"спотворити результати."

#: ../../Ch08/Ch08_Estimation_1.rst:321
msgid "Population parameters and sample statistics"
msgstr "Параметри популяції та статистика вибірки"

#: ../../Ch08/Ch08_Estimation_1.rst:323
msgid ""
"Okay. Setting aside the thorny methodological issues associated with "
"obtaining a random sample, let’s consider a slightly different issue. Up to "
"this point we have been talking about populations the way a scientist might. "
"To a psychologist a population might be a group of people. To an ecologist a "
"population might be a group of bears. In most cases the populations that "
"scientists care about are concrete things that actually exist in the real "
"world. Statisticians, however, are a funny lot. On the one hand, they *are* "
"interested in real world data and real science in the same way that "
"scientists are. On the other hand, they also operate in the realm of pure "
"abstraction in the way that mathematicians do. As a consequence, statistical "
"theory tends to be a bit abstract in how a population is defined. In much "
"the same way that psychological researchers operationalise our abstract "
"theoretical ideas in terms of concrete measurements (section :doc:`../Ch02/"
"Ch02_StudyDesign_1`), statisticians operationalise the concept of a "
"“population” in terms of mathematical objects that they know how to work "
"with. You’ve already come across these objects in chapter :doc:`../Ch07/"
"Ch07_Probability`. They’re called probability distributions."
msgstr ""
"Гаразд. Відкинувши складні методологічні питання, пов'язані з отриманням "
"випадкової вибірки, розглянемо дещо інше питання. До цього моменту ми "
"говорили про популяції так, як це робить науковець. Для психолога популяція "
"може бути групою людей. Для еколога популяція може бути групою ведмедів. У "
"більшості випадків популяції, які цікавлять науковців, є конкретними речами, "
"що насправді існують у реальному світі. Однак статистики — це дивна група "
"людей. З одного боку, вони *цікавляться* даними реального світу та реальною "
"наукою так само, як і вчені. З іншого боку, вони також працюють у сфері "
"чистої абстракції, як і математики. Як наслідок, статистична теорія має "
"тенденцію бути дещо абстрактною в тому, як визначається популяція. Так само, "
"як психологи реалізують наші абстрактні теоретичні ідеї у вигляді конкретних "
"вимірювань (розділ :doc:`../Ch02/Ch02_StudyDesign_1`), статистики реалізують "
"поняття «популяції» у вигляді математичних об'єктів, з якими вони вміють "
"працювати. Ви вже зустрічали ці об'єкти в розділі :doc:`../Ch07/"
"Ch07_Probability`. Вони називаються розподілами ймовірностей."

#: ../../Ch08/Ch08_Estimation_1.rst:341
msgid ""
"The idea is quite simple. Let’s say we’re talking about IQ scores. To a "
"psychologist the population of interest is a group of actual humans who have "
"IQ scores. A statistician “simplifies” this by operationally defining the "
"population as the probability distribution depicted in the left panel of :"
"numref:`fig-IQ_Pop_Smp`. IQ tests are designed so that the average IQ is "
"100, the standard deviation of IQ scores is 15, and the distribution of IQ "
"scores is normal. These values are referred to as the **population "
"parameters** because they are characteristics of the entire population. That "
"is, we say that the population mean µ is 100 and the population standard "
"deviation σ is 15."
msgstr ""
"Ідея досить проста. Припустимо, ми говоримо про показники IQ. Для психолога "
"цікавою популяцією є група реальних людей, які мають показники IQ. Статистик "
"«спрощує» це, операційно визначаючи популяцію як розподіл ймовірностей, "
"зображений на лівому панелі :numref:`fig-IQ_Pop_Smp`. Тести IQ розроблені "
"таким чином, що середній IQ дорівнює 100, стандартне відхилення показників "
"IQ становить 15, а розподіл показників IQ є нормальним. Ці значення "
"називаються **параметрами популяції**, оскільки вони є характеристиками "
"всієї популяції. Тобто ми говоримо, що середнє значення популяції µ дорівнює "
"100, а стандартне відхилення популяції σ становить 15."

#: ../../Ch08/Ch08_Estimation_1.rst:354
msgid "Population distribution of IQ and two samples with N=100 and N=10,000"
msgstr "Розподіл IQ у популяції та дві вибірки з N=100 та N=10 000"

#: ../../Ch08/Ch08_Estimation_1.rst:358
msgid ""
"The population distribution of IQ scores (left panel) and two samples drawn "
"randomly from it: In the middle panel, we have a sample of 100 observations, "
"and in the right panel, we have a sample of 10,000 observations."
msgstr ""
"Розподіл населення за показниками IQ (ліва панель) і дві вибірки, взяті з "
"нього випадковим чином: на середній панелі ми маємо вибірку зі 100 "
"спостережень, а на правій панелі — вибірку з 10 000 спостережень."

#: ../../Ch08/Ch08_Estimation_1.rst:364
msgid ""
"Now suppose I run an experiment. I select 100 people at random and "
"administer an IQ test, giving me a simple random sample from the population. "
"My sample would consist of a collection of numbers like this:"
msgstr ""
"Тепер припустимо, що я проводжу експеримент. Я випадково вибираю 100 осіб і "
"проводжу тест на IQ, отримуючи просту випадкову вибірку з населення. Моя "
"вибірка складатиметься з набору таких чисел:"

#: ../../Ch08/Ch08_Estimation_1.rst:373
msgid ""
"Each of these IQ scores is sampled from a normal distribution with mean 100 "
"and standard deviation 15. So if I plot a histogram of the sample I get "
"something like the one shown in the middle panel of :numref:`fig-"
"IQ_Pop_Smp`. As you can see, the histogram is *roughly* the right shape but "
"it’s a very crude approximation to the true population distribution shown in "
"the left panel of :numref:`fig-IQ_Pop_Smp`. When I calculate the mean of my "
"sample, I get a number that is fairly close to the population mean 100 but "
"not identical. In this case, it turns out that the people in my sample have "
"a mean IQ of 98.5, and the standard deviation of their IQ scores is 15.9. "
"These **sample statistics** are properties of my data set, and although they "
"are fairly similar to the true population values they are not the same. In "
"general, sample statistics are the things you can calculate from your data "
"set and the population parameters are the things you want to learn about. "
"Later on in this chapter I’ll talk about how you can estimate population "
"parameters using your sample statistics (:doc:`Ch08_Estimation_4`) and how "
"to work out how confident you are in your estimates (:doc:"
"`Ch08_Estimation_5`) but before we get to that there’s a few more ideas in "
"sampling theory that you need to know about."
msgstr ""
"Кожен з цих показників IQ відібрано з нормального розподілу із середнім "
"значенням 100 і стандартним відхиленням 15. Отже, якщо я побудую гістограму "
"вибірки, отримаю щось подібне до того, що показано на середній панелі :numref"
":`fig-IQ_Pop_Smp`. Як бачите, гістограма має *приблизно* правильну форму, "
"але це дуже грубе наближення до справжнього розподілу населення, показаного "
"на лівій панелі :numref:`fig-IQ_Pop_Smp`. Коли я обчислюю середнє значення "
"моєї вибірки, я отримую число, яке досить близько до середнього значення "
"населення 100, але не ідентичне йому. У цьому випадку виявляється, що люди в "
"моїй вибірці мають середній IQ 98,5, а стандартне відхилення їхніх IQ-балів "
"становить 15,9. Ці **вибіркові статистичні дані** є властивостями мого "
"набору даних, і хоча вони досить схожі на справжні значення генеральної "
"сукупності, вони не є однаковими. Загалом, вибіркові статистичні дані — це "
"те, що ви можете обчислити на основі вашого набору даних, а параметри "
"генеральної сукупності — це те, про що ви хочете дізнатися. Далі в цьому "
"розділі я розповім про те, як можна оцінити параметри генеральної сукупності "
"за допомогою статистики вибірки (:doc:`Ch08_Estimation_4`) і як визначити "
"ступінь впевненості у своїх оцінках (:doc:`Ch08_Estimation_5`), але перш ніж "
"перейти до цього, вам потрібно знати ще кілька ідей з теорії вибірки."

#: ../../Ch08/Ch08_Estimation_1.rst:394
msgid ""
"The proper mathematical definition of randomness is extraordinarily "
"technical, and way beyond the scope of this book. We’ll be non-technical "
"here and say that a process has an element of randomness to it whenever it "
"is possible to repeat the process and get different answers each time."
msgstr ""
"Правильне математичне визначення випадковості є надзвичайно технічним і "
"виходить далеко за межі цієї книги. Ми не будемо вдаватися до технічних "
"подробиць і скажемо, що процес має елемент випадковості, коли його можна "
"повторити і щоразу отримувати різні результати."

#: ../../Ch08/Ch08_Estimation_1.rst:401
msgid ""
"Nothing in life is that simple. There’s not an obvious division of people "
"into binary categories like “schizophrenic” and “not schizophrenic”. But "
"this isn’t a clinical psychology text so please forgive me a few "
"simplifications here and there."
msgstr ""
"У житті немає нічого такого простого. Не існує чіткого поділу людей на дві "
"категорії: «шизофреніки» та «не шизофреніки». Але це не підручник з "
"клінічної психології, тому прошу вибачити мені деякі спрощення тут і там."

#: ../../Ch08/Ch08_Estimation_2.rst:4
msgid "The law of large numbers"
msgstr "Закон великих чисел"

#: ../../Ch08/Ch08_Estimation_2.rst:6
msgid ""
"In the previous section I showed you the results of one fictitious IQ "
"experiment with a sample size of *N* = 100. The results were somewhat "
"encouraging as the true population mean is 100 and the sample mean of 98.5 "
"is a pretty reasonable approximation to it. In many scientific studies that "
"level of precision is perfectly acceptable, but in other situations you need "
"to be a lot more precise. If we want our sample statistics to be much closer "
"to the population parameters, what can we do about it?"
msgstr ""
"У попередньому розділі я показав вам результати одного вигаданого "
"експерименту з IQ із розміром вибірки *N* = 100. Результати були дещо "
"обнадійливими, оскільки справжнє середнє значення для сукупності становить "
"100, а середнє значення вибірки 98,5 є досить розумним наближенням до нього. "
"У багатьох наукових дослідженнях такий рівень точності є цілком прийнятним, "
"але в інших ситуаціях потрібно бути набагато точнішим. Якщо ми хочемо, щоб "
"статистика нашої вибірки була набагато ближчою до параметрів генеральної "
"сукупності, що ми можемо для цього зробити?"

#: ../../Ch08/Ch08_Estimation_2.rst:15
msgid ""
"The obvious answer is to collect more data. Suppose that we ran a much "
"larger experiment, this time measuring the IQs of 10,000 people. We can "
"simulate the results of this experiment using jamovi. The |IQsim|_ data set "
"is a jamovi data file. In this file I have generated 10,000 random numbers "
"sampled from a normal distribution for a population with ``mean = 100`` and "
"``sd = 15``. This was done by computing a new variable using the ``= "
"NORM(100,15)`` function. A histogram and density plot shows that this larger "
"sample is a much better approximation to the true population distribution "
"than the smaller one. This is reflected in the sample statistics. The mean "
"IQ for the larger sample turns out to be 99.68 and the standard deviation is "
"14.90. These values are now very close to the true population, as :numref:"
"`fig-IQsim` demonstrates."
msgstr ""
"Очевидним рішенням є збір більшої кількості даних. Припустимо, що ми провели "
"набагато більший експеримент, цього разу вимірявши IQ 10 000 людей. Ми "
"можемо змоделювати результати цього експерименту за допомогою jamovi. Набір "
"даних |IQsim|_ є файлом даних jamovi. У цьому файлі я згенерував 10 000 "
"випадкових чисел, відібраних із нормального розподілу для популяції з ``"
"середнім значенням = 100`` і ``sd = 15``. Це було зроблено шляхом обчислення "
"нової змінної за допомогою функції ``= NORM(100,15)``. Гістограма та графік "
"щільності показують, що ця більша вибірка набагато краще наближається до "
"справжнього розподілу популяції, ніж менша. Це відображається у вибірковій "
"статистиці. Середнє IQ для більшої вибірки становить 99,68, а стандартне "
"відхилення — 14,90. Ці значення тепер дуже близькі до справжньої популяції, "
"як показує :numref:`fig-IQsim`."

#: ../../Ch08/Ch08_Estimation_2.rst:30 ../../Ch08/Ch08_Estimation_2.rst:34
msgid "Random sample drawn from a normal distribution using jamovi"
msgstr "Випадкова вибірка, отримана з нормального розподілу за допомогою jamovi"

#: ../../Ch08/Ch08_Estimation_2.rst:38
msgid ""
"I feel a bit silly saying this, but the thing I want you to take away from "
"this is that large samples generally give you better information. I feel "
"silly saying it because it’s so bloody obvious that it shouldn’t need to be "
"said. In fact, it’s such an obvious point that when Jacob Bernoulli, one of "
"the founders of probability theory, formalised this idea back in 1713 he was "
"kind of a jerk about it. Here’s how he described the fact that we all share "
"this intuition:"
msgstr ""
"Мені трохи ніяково це говорити, але я хочу, щоб ви запам'ятали: великі "
"вибірки, як правило, дають більш якісну інформацію. Мені ніяково це "
"говорити, тому що це настільки очевидно, що про це навіть не варто "
"згадувати. Насправді, це настільки очевидний факт, що коли Якоб Бернуллі, "
"один із засновників теорії ймовірностей, у 1713 році формалізував цю ідею, "
"він виглядав трохи неприємним. Ось як він описав той факт, що ми всі "
"поділяємо цю інтуїцію:"

#: ../../Ch08/Ch08_Estimation_2.rst:46
msgid ""
"*For even the most stupid of men, by some instinct of nature, by himself and "
"without any instruction (which is a remarkable thing), is convinced that the "
"more observations have been made, the less danger there is of wandering from "
"one’s goal* (:ref:`Stigler, 1986 <Stigler_1986>`)."
msgstr ""
"*Навіть найдурніший з людей, завдяки якомусь природному інстинкту, "
"самостійно і без будь-яких настанов (що є надзвичайним явищем), переконаний, "
"що чим більше спостережень зроблено, тим менша небезпека відхилитися від "
"своєї мети* (:ref:`Stigler, 1986 <Stigler_1986>`)."

#: ../../Ch08/Ch08_Estimation_2.rst:52
msgid ""
"Okay, so the passage comes across as a bit condescending (not to mention "
"sexist), but his main point is correct. It really does feel obvious that "
"more data will give you better answers. The question is, why is this so? Not "
"surprisingly, this intuition that we all share turns out to be correct, and "
"statisticians refer to it as the **law of large numbers**. The law of large "
"numbers is a mathematical law that applies to many different sample "
"statistics but the simplest way to think about it is as a law about "
"averages. The sample mean is the most obvious example of a statistic that "
"relies on averaging (because that’s what the mean is… an average), so let’s "
"look at that. When applied to the sample mean what the law of large numbers "
"states is that as the sample gets larger, the sample mean tends to get "
"closer to the true population mean. Or, to say it a little bit more "
"precisely, as the sample size “approaches” infinity (written as *N* → ∞), "
"the sample mean approaches the population mean (*X̄* → µ).\\ [#]_"
msgstr ""
"Гаразд, цей уривок здається дещо зверхнім (не кажучи вже про сексизм), але "
"його основна думка є правильною. Дійсно, здається очевидним, що більше даних "
"дасть кращі відповіді. Питання в тому, чому це так? Не дивно, що ця "
"інтуїція, яку ми всі поділяємо, виявляється правильною, і статистики "
"називають її **законом великих чисел**. Закон великих чисел — це "
"математичний закон, який застосовується до багатьох різних статистичних "
"вибірок, але найпростіше його розглядати як закон про середні значення. "
"Середнє значення вибірки є найочевиднішим прикладом статистики, що базується "
"на усередненні (адже саме цим і є середнє значення — середнім), тож давайте "
"розглянемо його. Застосовуючи закон великих чисел до вибіркового середнього, "
"можна сказати, що з збільшенням вибірки вибіркове середнє наближається до "
"справжнього середнього значення генеральної сукупності. Або, якщо висловити "
"це трохи точніше, з наближенням розміру вибірки до нескінченності ("
"позначається як *N* → ∞), вибіркове середнє наближається до середнього "
"значення генеральної сукупності (*X̄* → µ).\\ [#]_"

#: ../../Ch08/Ch08_Estimation_2.rst:67
msgid ""
"I don’t intend to subject you to a proof that the law of large numbers is "
"true, but it’s one of the most important tools for statistical theory. The "
"law of large numbers is the thing we can use to justify our belief that "
"collecting more and more data will eventually lead us to the truth. For any "
"particular data set the sample statistics that we calculate from it will be "
"wrong, but the law of large numbers tells us that if we keep collecting more "
"data those sample statistics will tend to get closer and closer to the true "
"population parameters."
msgstr ""
"Я не маю наміру доводити вам, що закон великих чисел є правдивим, але це "
"один з найважливіших інструментів статистичної теорії. Закон великих чисел — "
"це те, що ми можемо використовувати, щоб обґрунтувати наше переконання, що "
"збір все більшої кількості даних зрештою приведе нас до істини. Для будь-"
"якого конкретного набору даних вибіркові статистичні дані, які ми обчислюємо "
"на його основі, будуть неправильними, але закон великих чисел говорить нам, "
"що якщо ми продовжуватимемо збирати більше даних, ці вибіркові статистичні "
"дані будуть наближатися все ближче і ближче до справжніх параметрів "
"сукупності."

#: ../../Ch08/Ch08_Estimation_2.rst:79
msgid ""
"Technically, the law of large numbers pertains to any sample statistic that "
"can be described as an average of independent quantities. That’s certainly "
"true for the sample mean. However, it’s also possible to write many other "
"sample statistics as averages of one form or another. The variance of a "
"sample, for instance, can be rewritten as a kind of average and so is "
"subject to the law of large numbers. The minimum value of a sample, however, "
"cannot be written as an average of anything and is therefore not governed by "
"the law of large numbers."
msgstr ""
"Технічно, закон великих чисел стосується будь-якої вибіркової статистики, "
"яку можна описати як середнє значення незалежних величин. Це, безумовно, "
"справедливо для вибіркового середнього. Однак можна також записати багато "
"інших вибіркових статистичних величин як середні значення тієї чи іншої "
"форми. Наприклад, дисперсія вибірки може бути переписана як певний середній "
"показник і, отже, підпадає під дію закону великих чисел. Однак мінімальне "
"значення вибірки не може бути записане як середнє значення чого-небудь і, "
"отже, не підпадає під дію закону великих чисел."

#: ../../Ch08/Ch08_Estimation_3.rst:4
msgid "Sampling distributions and the central limit theorem"
msgstr "Розподіл вибірки та центральна гранична теорема"

#: ../../Ch08/Ch08_Estimation_3.rst:6
msgid ""
"The law of large numbers is a very powerful tool but it’s not going to be "
"good enough to answer all our questions. Among other things, all it gives us "
"is a “long run guarantee”. In the long run, if we were somehow able to "
"collect an infinite amount of data, then the law of large numbers guarantees "
"that our sample statistics will be correct. But as John Maynard Keynes "
"famously argued in economics, a long run guarantee is of little use in real "
"life."
msgstr ""
"Закон великих чисел є дуже потужним інструментом, але він не зможе "
"відповісти на всі наші запитання. Серед іншого, він дає нам лише «"
"довгострокову гарантію». У довгостроковій перспективі, якщо ми якось зможемо "
"зібрати нескінченну кількість даних, то закон великих чисел гарантує, що "
"наша вибіркова статистика буде правильною. Але, як відомо, Джон Мейнард "
"Кейнс стверджував в економіці, що довгострокова гарантія мало корисна в "
"реальному житті."

#: ../../Ch08/Ch08_Estimation_3.rst:14
msgid ""
"*[The] long run is a misleading guide to current affairs. In the long run we "
"are all dead. Economists set themselves too easy, too useless a task, if in "
"tempestuous seasons they can only tell us, that when the storm is long past, "
"the ocean is flat again* (:ref:`Keynes, 1923 <Keynes_1923>`)."
msgstr ""
"*Довгострокова перспектива є оманливим орієнтиром для поточних справ. У "
"довгостроковій перспективі ми всі помремо. Економісти ставлять перед собою "
"занадто легке і марне завдання, якщо в бурхливі часи вони можуть лише "
"сказати нам, що коли буря давно минула, океан знову спокійний* (:ref:`"
"Keynes, 1923 <Keynes_1923>`)."

#: ../../Ch08/Ch08_Estimation_3.rst:20
msgid ""
"As in economics, so too in psychology and statistics. It is not enough to "
"know that we will *eventually* arrive at the right answer when calculating "
"the sample mean. Knowing that an infinitely large data set will tell me the "
"exact value of the population mean is cold comfort when my *actual* data set "
"has a sample size of *N* = 100. In real life, then, we must know something "
"about the behaviour of the sample mean when it is calculated from a more "
"modest data set!"
msgstr ""
"Як в економіці, так і в психології та статистиці. Недостатньо знати, що ми "
"*зрештою* отримаємо правильну відповідь при обчисленні середнього значення "
"вибірки. Знання того, що нескінченно великий набір даних дасть мені точне "
"значення середнього значення генеральної сукупності, є слабкою втіхою, коли "
"мій *фактичний* набір даних має розмір вибірки *N* = 100. Отже, в реальному "
"житті ми повинні знати щось про поведінку середнього значення вибірки, коли "
"воно обчислюється на основі більш скромного набору даних!"

#: ../../Ch08/Ch08_Estimation_3.rst:31
msgid "Sampling distribution of the mean"
msgstr "Розподіл вибірки середнього значення"

#: ../../Ch08/Ch08_Estimation_3.rst:33
msgid ""
"With this in mind, let’s abandon the idea that our studies will have sample "
"sizes of 10,000 and consider instead a very modest experiment indeed. This "
"time around we’ll sample *N* = 5 people and measure their IQ scores. As "
"before, I can simulate this experiment in jamovi ``= NORM(100,15)`` "
"function, but I only need 5 participant IDs this time, not 10,000. These are "
"the five numbers that jamovi generated:"
msgstr ""
"Маючи це на увазі, відмовімося від ідеї, що наші дослідження будуть мати "
"вибірку розміром 10 000, і розглянемо натомість дуже скромний експеримент. "
"Цього разу ми візьмемо вибірку *N* = 5 осіб і виміряємо їхні показники IQ. "
"Як і раніше, я можу змоделювати цей експеримент за допомогою функції jamovi "
"``= NORM(100,15)``, але цього разу мені потрібно лише 5 ідентифікаторів "
"учасників, а не 10 000. Ось п'ять чисел, які згенерував jamovi:"

#: ../../Ch08/Ch08_Estimation_3.rst:44
msgid ""
"The mean IQ in this sample turns out to be exactly 95. Not surprisingly, "
"this is much less accurate than the previous experiment. Now imagine that I "
"decided to **replicate** the experiment. That is, I repeat the procedure as "
"closely as possible and I randomly sample 5 new people and measure their IQ. "
"Again, jamovi allows me to simulate the results of this procedure, and "
"generates these five numbers:"
msgstr ""
"Середній IQ у цій вибірці становить рівно 95. Не дивно, що це набагато менш "
"точний результат, ніж у попередньому експерименті. Тепер уявіть, що я "
"вирішив **повторити** експеримент. Тобто я повторюю процедуру якомога "
"точніше, випадково відбираю 5 нових людей і вимірюю їх IQ. Знову ж таки, "
"jamovi дозволяє мені змоделювати результати цієї процедури і генерує ці "
"п'ять чисел:"

#: ../../Ch08/Ch08_Estimation_3.rst:55
msgid ""
"This time around, the mean IQ in my sample is 101. If I repeat the "
"experiment 10 times I obtain the results shown in :numref:`tab-"
"replications`, and as you can see the sample mean varies from one "
"replication to the next."
msgstr ""
"Цього разу середній IQ у моїй вибірці становить 101. Якщо я повторю "
"експеримент 10 разів, отримаю результати, показані в :numref:`tab-"
"replications`, і, як ви можете бачити, середнє значення вибірки варіюється "
"від одного повторення до іншого."

#: ../../Ch08/Ch08_Estimation_3.rst:59
msgid ""
"Ten replications of the IQ experiment, each with a sample size of *N* =5"
msgstr "Десять повторень експерименту IQ, кожна з розміром вибірки *N* = 5"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 1"
msgstr "Людина 1"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 2"
msgstr "Людина 2"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 3"
msgstr "Людина 3"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 4"
msgstr "Людина 4"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Person 5"
msgstr "Людина 5"

#: ../../Ch08/Ch08_Estimation_3.rst:63
msgid "Sample Mean"
msgstr "Середнє значення вибірки"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "Replication 1"
msgstr "Реплікація 1"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "90"
msgstr "90"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "82"
msgstr "82"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "94"
msgstr "94"

#: ../../Ch08/Ch08_Estimation_3.rst:65 ../../Ch08/Ch08_Estimation_3.rst:71
msgid "99"
msgstr "99"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "110"
msgstr "110"

#: ../../Ch08/Ch08_Estimation_3.rst:65
msgid "95.0"
msgstr "95.0"

#: ../../Ch08/Ch08_Estimation_3.rst:67
msgid "Replication 2"
msgstr "Реплікація 2"

#: ../../Ch08/Ch08_Estimation_3.rst:67
msgid "78"
msgstr "78"

#: ../../Ch08/Ch08_Estimation_3.rst:67
msgid "88"
msgstr "88"

#: ../../Ch08/Ch08_Estimation_3.rst:67 ../../Ch08/Ch08_Estimation_3.rst:69
msgid "111"
msgstr "111"

#: ../../Ch08/Ch08_Estimation_3.rst:67 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "117"
msgstr "117"

#: ../../Ch08/Ch08_Estimation_3.rst:67
msgid "101.0"
msgstr "101.0"

#: ../../Ch08/Ch08_Estimation_3.rst:69
msgid "Replication 3"
msgstr "Реплікація 3"

#: ../../Ch08/Ch08_Estimation_3.rst:69
msgid "122"
msgstr "122"

#: ../../Ch08/Ch08_Estimation_3.rst:69
msgid "91"
msgstr "91"

#: ../../Ch08/Ch08_Estimation_3.rst:69 ../../Ch08/Ch08_Estimation_3.rst:71
#: ../../Ch08/Ch08_Estimation_3.rst:73 ../../Ch08/Ch08_Estimation_3.rst:77
msgid "98"
msgstr "98"

#: ../../Ch08/Ch08_Estimation_3.rst:69 ../../Ch08/Ch08_Estimation_3.rst:81
msgid "86"
msgstr "86"

#: ../../Ch08/Ch08_Estimation_3.rst:69
msgid "101.6"
msgstr "101.6"

#: ../../Ch08/Ch08_Estimation_3.rst:71
msgid "Replication 4"
msgstr "Реплікація 4"

#: ../../Ch08/Ch08_Estimation_3.rst:71
msgid "96"
msgstr "96"

#: ../../Ch08/Ch08_Estimation_3.rst:71 ../../Ch08/Ch08_Estimation_3.rst:81
msgid "119"
msgstr "119"

#: ../../Ch08/Ch08_Estimation_3.rst:71 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "107"
msgstr "107"

#: ../../Ch08/Ch08_Estimation_3.rst:71
msgid "103.8"
msgstr "103.8"

#: ../../Ch08/Ch08_Estimation_3.rst:73
msgid "Replication 5"
msgstr "Реплікація 5"

#: ../../Ch08/Ch08_Estimation_3.rst:73 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "105"
msgstr "105"

#: ../../Ch08/Ch08_Estimation_3.rst:73
msgid "113"
msgstr "113"

#: ../../Ch08/Ch08_Estimation_3.rst:73
msgid "103"
msgstr "103"

#: ../../Ch08/Ch08_Estimation_3.rst:73
msgid "104.4"
msgstr "104.4"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "Replication 6"
msgstr "Реплікація 6"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "81"
msgstr "81"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "89"
msgstr "89"

#: ../../Ch08/Ch08_Estimation_3.rst:75 ../../Ch08/Ch08_Estimation_3.rst:77
msgid "93"
msgstr "93"

#: ../../Ch08/Ch08_Estimation_3.rst:75 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "85"
msgstr "85"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "114"
msgstr "114"

#: ../../Ch08/Ch08_Estimation_3.rst:75
msgid "92.4"
msgstr "92.4"

#: ../../Ch08/Ch08_Estimation_3.rst:77
msgid "Replication 7"
msgstr "Реплікація 7"

#: ../../Ch08/Ch08_Estimation_3.rst:77 ../../Ch08/Ch08_Estimation_3.rst:79
msgid "100"
msgstr "100"

#: ../../Ch08/Ch08_Estimation_3.rst:77 ../../Ch08/Ch08_Estimation_3.rst:81
msgid "108"
msgstr "108"

#: ../../Ch08/Ch08_Estimation_3.rst:77
msgid "133"
msgstr "133"

#: ../../Ch08/Ch08_Estimation_3.rst:77
msgid "106.4"
msgstr "106.4"

#: ../../Ch08/Ch08_Estimation_3.rst:79
msgid "Replication 8"
msgstr "Реплікація 8"

#: ../../Ch08/Ch08_Estimation_3.rst:79
msgid "102.8"
msgstr "102.8"

#: ../../Ch08/Ch08_Estimation_3.rst:81
msgid "Replication 9"
msgstr "Реплікація 9"

#: ../../Ch08/Ch08_Estimation_3.rst:81
msgid "73"
msgstr "73"

#: ../../Ch08/Ch08_Estimation_3.rst:81
msgid "116"
msgstr "116"

#: ../../Ch08/Ch08_Estimation_3.rst:81
msgid "100.4"
msgstr "100.4"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "Replication 10"
msgstr "Реплікація 10"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "95"
msgstr "95"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "126"
msgstr "126"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "112"
msgstr "112"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "120"
msgstr "120"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "76"
msgstr "76"

#: ../../Ch08/Ch08_Estimation_3.rst:83
msgid "105.8"
msgstr "105.8"

#: ../../Ch08/Ch08_Estimation_3.rst:86
msgid ""
"Now suppose that I decided to keep going in this fashion, replicating this "
"“five IQ scores” experiment over and over again. Every time I replicate the "
"experiment I write down the sample mean. Over time, I’d be amassing a new "
"data set, in which every experiment generates a single data point. The first "
"10 observations from my data set are the sample means listed in :numref:`tab-"
"replications`, so my data set starts out like this:"
msgstr ""
"Тепер припустимо, що я вирішив продовжувати в такому ж дусі, повторюючи цей "
"експеримент з «п'ятьма показниками IQ» знову і знову. Кожного разу, коли я "
"повторюю експеримент, я записую середнє значення вибірки. Згодом я накопичую "
"новий набір даних, в якому кожен експеримент генерує одну точку даних. Перші "
"10 спостережень з мого набору даних — це середні значення вибірки, "
"перелічені в :numref:`tab-replications`, тому мій набір даних починається "
"так:"

#: ../../Ch08/Ch08_Estimation_3.rst:98
msgid ""
"What if I continued like this for 10,000 replications, and then drew a "
"histogram. Well that’s exactly what I did, and you can see the results in :"
"numref:`fig-samplingDist4`. As this picture illustrates, the average of 5 IQ "
"scores is usually between 90 and 110. But more importantly, what it "
"highlights is that if we replicate an experiment over and over again, what "
"we end up with is a *distribution* of sample means! This distribution has a "
"special name in statistics, it’s called the **sampling distribution of the "
"mean**."
msgstr ""
"Що буде, якщо я продовжу так робити протягом 10 000 повторень, а потім "
"намалюю гістограму? Саме це я і зробив, і ви можете побачити результати в "
":numref:`fig-samplingDist4`. Як показує цей малюнок, середнє значення 5 "
"балів IQ зазвичай знаходиться в діапазоні від 90 до 110. Але що ще "
"важливіше, це підкреслює, що якщо ми повторюємо експеримент знову і знову, "
"то в результаті отримуємо *розподіл* середніх значень вибірки! Цей розподіл "
"має спеціальну назву в статистиці, він називається **вибірковим розподілом "
"середнього значення**."

#: ../../Ch08/Ch08_Estimation_3.rst:109
msgid "Sampling distribution: Mean for the “five IQ scores experiment”"
msgstr ""
"Розподіл вибірки: середнє значення для «експерименту з п'ятьма балами IQ»"

#: ../../Ch08/Ch08_Estimation_3.rst:113
msgid ""
"The sampling distribution of the mean for the “five IQ scores experiment”: "
"If you sample 5 people at random and calculate their average IQ you’ll "
"almost certainly get a number between 80 and 120, even though there are "
"quite a lot of individuals who have IQs above 120 or below 80. For "
"comparison, the black line plots the population distribution of IQ scores."
msgstr ""
"Розподіл вибірки середнього значення для «експерименту з п'ятьма показниками "
"IQ»: якщо ви випадково виберете 5 осіб і обчислите їх середній IQ, ви майже "
"напевно отримаєте число від 80 до 120, навіть незважаючи на те, що є досить "
"багато осіб, які мають IQ вище 120 або нижче 80. Для порівняння чорна лінія "
"відображає розподіл населення за показниками IQ."

#: ../../Ch08/Ch08_Estimation_3.rst:121
msgid ""
"Sampling distributions are another important theoretical idea in statistics, "
"and they’re crucial for understanding the behaviour of small samples. For "
"instance, when I ran the very first “five IQ scores” experiment, the sample "
"mean turned out to be 95. What the sampling distribution in :numref:`fig-"
"samplingDist4` tells us, though, is that the “five IQ scores” experiment is "
"not very accurate. If I repeat the experiment, the sampling distribution "
"tells me that I can expect to see a sample mean anywhere between 80 and 120."
msgstr ""
"Розподіл вибірки є ще однією важливою теоретичною ідеєю в статистиці, і він "
"має вирішальне значення для розуміння поведінки невеликих вибірок. "
"Наприклад, коли я провів перший експеримент з «п'ятьма показниками IQ», "
"середнє значення вибірки виявилося рівним 95. Однак розподіл вибірки в "
":numref:`fig-samplingDist4` показує, що експеримент з «п'ятьма показниками "
"IQ» не є дуже точним. Якщо я повторю експеримент, вибірковий розподіл "
"покаже, що середнє значення вибірки може бути в межах від 80 до 120."

#: ../../Ch08/Ch08_Estimation_3.rst:131
msgid "Sampling distributions exist for any sample statistic!"
msgstr "Розподіл вибірки існує для будь-якої вибіркової статистики!"

#: ../../Ch08/Ch08_Estimation_3.rst:133
msgid ""
"One thing to keep in mind when thinking about sampling distributions is that "
"*any* sample statistic you might care to calculate has a sampling "
"distribution. For example, suppose that each time I replicated the “five IQ "
"scores” experiment I wrote down the largest IQ score in the experiment. This "
"would give me a data set that started out like this:"
msgstr ""
"При розгляді розподілів вибірки слід пам'ятати, що *будь-яка* вибіркова "
"статистика, яку ви можете обчислити, має розподіл вибірки. Наприклад, "
"припустимо, що кожного разу, коли я повторював експеримент «п'ять балів IQ», "
"я записував найбільший бал IQ в експерименті. Це дало б мені набір даних, "
"який спочатку виглядав би так:"

#: ../../Ch08/Ch08_Estimation_3.rst:143
msgid ""
"Doing this over and over again would give me a very different sampling "
"distribution, namely the *sampling distribution of the maximum*. The "
"sampling distribution of the maximum of 5 IQ scores is shown in :numref:`fig-"
"samplingDistMax`. Not surprisingly, if you pick 5 people at random and then "
"find the person with the highest IQ score, they’re going to have an above "
"average IQ. Most of the time you’ll end up with someone whose IQ is measured "
"in the 100 to 140 range."
msgstr ""
"Якщо робити це знову і знову, я отримаю зовсім інший розподіл вибірки, а "
"саме *розподіл вибірки максимуму*. Розподіл вибірки максимуму 5 балів IQ "
"показано на малюнку :numref:`fig-samplingDistMax`. Не дивно, що якщо вибрати "
"5 людей навмання, а потім знайти людину з найвищим балом IQ, вона матиме IQ "
"вище середнього. У більшості випадків ви отримаєте людину, IQ якої "
"вимірюється в діапазоні від 100 до 140."

#: ../../Ch08/Ch08_Estimation_3.rst:153
msgid "Sampling distribution: Maximum for the “five IQ scores experiment”"
msgstr "Розподіл вибірки: Максимальний для «експерименту з п'ятьма балами IQ»"

#: ../../Ch08/Ch08_Estimation_3.rst:157
msgid ""
"The sampling distribution of the maximum for the “five IQ scores "
"experiment”: If you sample 5 people at random and select the one with the "
"highest IQ score you’ll probably see someone with an IQ between 100 and 140."
msgstr ""
"Розподіл вибірки максимального значення для «експерименту з п'ятьма "
"показниками IQ»: якщо ви випадково виберете 5 осіб і оберете ту, яка має "
"найвищий показник IQ, ви, ймовірно, побачите людину з IQ від 100 до 140."

#: ../../Ch08/Ch08_Estimation_3.rst:166
msgid "The central limit theorem"
msgstr "Центральна гранична теорема"

#: ../../Ch08/Ch08_Estimation_3.rst:168
msgid ""
"At this point I hope you have a pretty good sense of what sampling "
"distributions are, and in particular what the sampling distribution of the "
"mean is. In this section I want to talk about how the sampling distribution "
"of the mean changes as a function of sample size. Intuitively, you already "
"know part of the answer. If you only have a few observations, the sample "
"mean is likely to be quite inaccurate. If you replicate a small experiment "
"and recalculate the mean you’ll get a very different answer. In other words, "
"the sampling distribution is quite wide. If you replicate a large experiment "
"and recalculate the sample mean you’ll probably get the same answer you got "
"last time, so the sampling distribution will be very narrow. You can see "
"this visually in :numref:`fig-samplingDistDiffN`, showing that the bigger "
"the sample size, the narrower the sampling distribution gets. We can "
"quantify this effect by calculating the standard deviation of the sampling "
"distribution, which is referred to as the **standard error**. The standard "
"error of a statistic is often denoted SE, and since we’re usually interested "
"in the standard error of the sample *mean*, we often use the acronym SEM. As "
"you can see just by looking at the picture, as the sample size *N* "
"increases, the SEM decreases."
msgstr ""
"На цьому етапі я сподіваюся, що ви вже досить добре розумієте, що таке "
"вибіркові розподіли, і, зокрема, що таке вибірковий розподіл середнього "
"значення. У цьому розділі я хочу поговорити про те, як вибірковий розподіл "
"середнього значення змінюється в залежності від розміру вибірки. Інтуїтивно "
"ви вже знаєте частину відповіді. Якщо у вас є лише кілька спостережень, "
"вибіркове середнє значення, ймовірно, буде досить неточним. Якщо ви "
"повторите невеликий експеримент і перерахуєте середнє значення, ви отримаєте "
"зовсім іншу відповідь. Іншими словами, вибірковий розподіл є досить широким. "
"Якщо ви повторите великий експеримент і перерахуєте вибіркове середнє "
"значення, ви, ймовірно, отримаєте ту саму відповідь, що й минулого разу, "
"отже, вибірковий розподіл буде дуже вузьким. Ви можете побачити це візуально "
"на :numref:`fig-samplingDistDiffN`, що показує: чим більший розмір вибірки, "
"тим вужчим стає розподіл вибірки. Ми можемо кількісно оцінити цей ефект, "
"обчисливши стандартне відхилення вибіркового розподілу, яке називається **"
"стандартною похибкою**. Стандартна похибка статистичного показника часто "
"позначається SE, а оскільки нас зазвичай цікавить стандартна похибка *"
"середнього значення* вибірки, ми часто використовуємо абревіатуру SEM. Як ви "
"можете бачити, просто подивившись на малюнок, із збільшенням розміру вибірки "
"*N* SEM зменшується."

#: ../../Ch08/Ch08_Estimation_3.rst:190
msgid "Shape of the sampling distribution in dependence of the sample size"
msgstr "Форма розподілу вибірки залежно від розміру вибірки"

#: ../../Ch08/Ch08_Estimation_3.rst:194
msgid ""
"Illustration of the how sampling distribution of the mean depends on sample "
"size. In each panel I generated 10,000 samples of IQ data and calculated the "
"mean IQ observed within each of these data sets. The histograms in these "
"plots show the distribution of these means (i.e., the sampling distribution "
"of the mean). Each individual IQ score was drawn from a normal distribution "
"with mean 100 and standard deviation 15, which is shown as the solid black "
"line. In the left panel, each data set contained only a single observation, "
"so the mean of each sample is just one person’s IQ score. As a consequence, "
"the sampling distribution of the mean is of course identical to the "
"population distribution of IQ scores. However, when we raise the sample size "
"to 2 (middle panel) the mean of any one sample tends to be closer to the "
"population mean than a one person’s IQ score, and so the histogram (i.e., "
"the sampling distribution) is a bit narrower than the population "
"distribution. By the time we raise the sample size to 10 (right panel), we "
"can see that the distribution of sample means tend to be fairly tightly "
"clustered around the true population mean."
msgstr ""
"Ілюстрація того, як розподіл вибірки середнього значення залежить від "
"розміру вибірки. У кожній панелі я створив 10 000 вибірок даних IQ і "
"обчислив середнє IQ, спостережуване в кожній з цих наборів даних. Гістограми "
"на цих графіках показують розподіл цих середніх значень (тобто розподіл "
"вибірки середнього значення). Кожен індивідуальний показник IQ був взятий з "
"нормального розподілу із середнім значенням 100 і стандартним відхиленням "
"15, що показано чорною суцільною лінією. На лівій панелі кожен набір даних "
"містив лише одне спостереження, тому середнє значення кожної вибірки є "
"показником IQ лише однієї особи. Як наслідок, вибірковий розподіл середнього "
"значення, звичайно, ідентичний розподілу IQ-балів у популяції. Однак, коли "
"ми збільшуємо розмір вибірки до 2 (середня панель), середнє значення будь-"
"якої вибірки має тенденцію бути ближчим до середнього значення популяції, "
"ніж IQ-бал однієї людини, і тому гістограма (тобто вибірковий розподіл) є "
"дещо вужчою, ніж розподіл популяції. Коли ми збільшуємо розмір вибірки до 10 "
"(права панель), ми бачимо, що розподіл середніх значень вибірки має "
"тенденцію досить щільно групуватися навколо справжнього середнього значення "
"генеральної сукупності."

#: ../../Ch08/Ch08_Estimation_3.rst:213
msgid ""
"Okay, so that’s one part of the story. However, there’s something I’ve been "
"glossing over so far. All my examples up to this point have been based on "
"the “IQ scores” experiments, and because IQ scores are roughly normally "
"distributed I’ve assumed that the population distribution is normal. What if "
"it isn’t normal? What happens to the sampling distribution of the mean? The "
"remarkable thing is this, no matter what shape your population distribution "
"is, as *N* increases the sampling distribution of the mean starts to look "
"more like a normal distribution. To give you a sense of this I ran some "
"simulations. To do this, I started with the “ramped” distribution shown in "
"the histogram in :numref:`fig-cltDemo` (top-left panel). As you can see by "
"comparing the triangular shaped histogram to the bell curve plotted by the "
"black line, the population distribution doesn’t look very much like a normal "
"distribution at all. Next, I simulated the results of a large number of "
"experiments. In each experiment I took *N* = 2 samples from this "
"distribution, and then calculated the sample mean. :numref:`fig-cltDemo` "
"(top-right panel) plots the histogram of these sample means (i.e., the "
"sampling distribution of the mean for *N* = 2). This time, the histogram "
"produces a ∩-shaped distribution. It’s still not normal, but it’s a lot "
"closer to the black line than the population distribution in :numref:`fig-"
"cltDemo` (top-left panel). When I increase the sample size to *N* = 4, the "
"sampling distribution of the mean is very close to normal (:numref:`fig-"
"cltDemo`, bottom-left panel), and by the time we reach a sample size of *N* "
"= 8 (:numref:`fig-cltDemo`; bottom- right panel) it’s almost perfectly "
"normal. In other words, as long as your sample size isn’t tiny, the sampling "
"distribution of the mean will be approximately normal no matter what your "
"population distribution looks like!"
msgstr ""
"Гаразд, це одна частина історії. Однак є дещо, що я досі замовчував. Усі мої "
"приклади до цього моменту базувалися на експериментах з «оцінками IQ», і "
"оскільки оцінки IQ мають приблизно нормальний розподіл, я припустив, що "
"розподіл населення є нормальним. А що, якщо це не так? Що станеться з "
"вибірковим розподілом середнього значення? Дивовижно, але незалежно від "
"форми розподілу населення, із збільшенням *N* вибірковий розподіл середнього "
"значення починає все більше нагадувати нормальний розподіл. Щоб "
"проілюструвати це, я провів кілька моделювань. Для цього я почав із "
"«похилого» розподілу, показаного на гістограмі в :numref:`fig-cltDemo` ("
"верхня ліва панель). Як ви можете бачити, порівнюючи трикутну гістограму з "
"кривою дзвона, нанесеною чорною лінією, розподіл сукупності зовсім не схожий "
"на нормальний розподіл. Далі я провів моделювання результатів великої "
"кількості експериментів. У кожному експерименті я взяв *N* = 2 вибірки з "
"цього розподілу, а потім обчислив вибіркове середнє. :numref:`fig-cltDemo` ("
"права верхня панель) відображає гістограму цих середніх значень вибірки ("
"тобто вибірковий розподіл середнього значення для *N* = 2). Цього разу "
"гістограма утворює розподіл у формі ∩. Вона все ще не є нормальною, але "
"набагато ближча до чорної лінії, ніж розподіл генеральної сукупності в "
":numref:`fig-cltDemo` (верхня ліва панель). Коли я збільшую розмір вибірки "
"до *N* = 4, вибірковий розподіл середнього значення стає дуже близьким до "
"нормального (:numref:`fig-cltDemo`, нижня ліва панель), а коли ми досягаємо "
"розміру вибірки *N* = 8 (:numref:`fig-cltDemo`; нижня права панель), він "
"стає майже ідеально нормальним. Іншими словами, якщо розмір вибірки не є "
"надто малим, вибірковий розподіл середнього значення буде приблизно "
"нормальним незалежно від того, як виглядає розподіл генеральної сукупності!"

#: ../../Ch08/Ch08_Estimation_3.rst:242
msgid "Demonstration of the central limit theorem"
msgstr "Демонстрація центральної граничної теореми"

#: ../../Ch08/Ch08_Estimation_3.rst:246
msgid ""
"Demonstration of the central limit theorem: In the top-left panel, we have a "
"non-normal population distribution, and the remaining panels show the "
"sampling distribution of the mean for samples of size 2 (top-right), 4 "
"(bottom-left) and 8 (bottom-right) for data drawn from the distribution in "
"the top-left panel. As you can see, even though the original population "
"distribution is non-normal the sampling distribution of the mean becomes "
"pretty close to normal by the time you have a sample of even 4 observations."
msgstr ""
"Демонстрація центральної граничної теореми: у верхньому лівому вікні ми "
"маємо ненормальний розподіл популяції, а в інших вікнах показано вибірковий "
"розподіл середнього значення для вибірок розміром 2 (у верхньому правому "
"вікні), 4 (у нижньому лівому вікні) та 8 (у нижньому правому вікні) для "
"даних, взятих із розподілу у верхньому лівому вікні. Як бачимо, навіть якщо "
"вихідний розподіл населення є ненормальним, вибірковий розподіл середнього "
"значення стає досить близьким до нормального, коли маємо вибірку навіть із 4 "
"спостереженнями."

#: ../../Ch08/Ch08_Estimation_3.rst:256
msgid ""
"On the basis of these figures, it seems like we have evidence for all of the "
"following claims about the sampling distribution of the mean."
msgstr ""
"На основі цих цифр, схоже, ми маємо докази для всіх наступних тверджень щодо "
"розподілу середнього значення за вибіркою."

#: ../../Ch08/Ch08_Estimation_3.rst:259
msgid ""
"The mean of the sampling distribution is the same as the mean of the "
"population"
msgstr ""
"Середнє значення розподілу вибірки таке ж, як середнє значення генеральної "
"сукупності"

#: ../../Ch08/Ch08_Estimation_3.rst:262
msgid ""
"The standard deviation of the sampling distribution (i.e., the standard "
"error) gets smaller as the sample size increases"
msgstr ""
"Стандартне відхилення розподілу вибірки (тобто стандартна помилка) "
"зменшується зі збільшенням розміру вибірки"

#: ../../Ch08/Ch08_Estimation_3.rst:265
msgid ""
"The shape of the sampling distribution becomes normal as the sample size "
"increases"
msgstr "Форма розподілу вибірки стає нормальною зі збільшенням розміру вибірки"

#: ../../Ch08/Ch08_Estimation_3.rst:268
msgid ""
"As it happens, not only are all of these statements true, there is a very "
"famous theorem in statistics that proves all three of them, known as the "
"**central limit theorem**. Among other things, the central limit theorem "
"tells us that if the population distribution has mean µ and standard "
"deviation σ, then the sampling distribution of the mean also has mean µ and "
"the standard error of the mean is"
msgstr ""
"Як виявляється, не тільки всі ці твердження є правдивими, але й існує дуже "
"відома теорема в статистиці, яка доводить всі три з них, відома як **"
"центральна гранична теорема**. Серед іншого, центральна гранична теорема "
"говорить нам, що якщо розподіл популяції має середнє значення µ і стандартне "
"відхилення σ, то вибірковий розподіл середнього значення також має середнє "
"значення µ, а стандартна похибка середнього значення дорівнює"

#: ../../Ch08/Ch08_Estimation_3.rst:276
msgid ""
"\\mbox{SEM} = \\frac{\\sigma}{ \\sqrt{N} }\n"
"\n"
msgstr ""
"\\mbox{SEM} = \\frac{\\sigma}{ \\sqrt{N} }\n"
"\n"

#: ../../Ch08/Ch08_Estimation_3.rst:278
msgid ""
"Because we divide the population standard deviation σ by the square root of "
"the sample size *N*, the SEM gets smaller as the sample size increases. It "
"also tells us that the shape of the sampling distribution becomes normal.\\ "
"[#]_"
msgstr ""
"Оскільки ми ділимо стандартне відхилення σ на квадратний корінь з розміру "
"вибірки *N*, SEM зменшується із збільшенням розміру вибірки. Це також "
"свідчить про те, що форма вибіркового розподілу стає нормальною.\\ [#]_"

#: ../../Ch08/Ch08_Estimation_3.rst:283
msgid ""
"This result is useful for all sorts of things. It tells us why large "
"experiments are more reliable than small ones, and because it gives us an "
"explicit formula for the standard error it tells us *how much* more reliable "
"a large experiment is. It tells us why the normal distribution is, well, "
"*normal*. In real experiments, many of the things that we want to measure "
"are actually averages of lots of different quantities (e.g., arguably, "
"“general” intelligence as measured by IQ is an average of a large number of "
"“specific” skills and abilities), and when that happens, the averaged "
"quantity should follow a normal distribution. Because of this mathematical "
"law, the normal distribution pops up over and over again in real data."
msgstr ""
"Цей результат корисний для багатьох речей. Він пояснює, чому великі "
"експерименти є більш надійними, ніж малі, а також дає нам чітку формулу для "
"стандартної похибки, *яка показує*, на скільки великий експеримент є більш "
"надійним. Він пояснює, чому нормальний розподіл є, власне, *нормальним*. У "
"реальних експериментах багато речей, які ми хочемо виміряти, насправді є "
"середніми значеннями багатьох різних величин (наприклад, можна стверджувати, "
"що «загальний» інтелект, виміряний за допомогою IQ, є середнім значенням "
"великої кількості «специфічних» навичок і здібностей), і коли це "
"відбувається, усереднена величина повинна відповідати нормальному розподілу. "
"Завдяки цьому математичному закону нормальний розподіл знову і знову "
"з'являється в реальних даних."

#: ../../Ch08/Ch08_Estimation_3.rst:298
msgid ""
"As usual, I’m being a bit sloppy here. The central limit theorem is a bit "
"more general than this section implies. Like most introductory stats texts "
"I’ve discussed one situation where the central limit theorem holds: when "
"you’re taking an average across lots of independent events drawn from the "
"same distribution. However, the central limit theorem is much broader than "
"this. There’s a whole class of things called “*U*-statistics” for instance, "
"all of which satisfy the central limit theorem and therefore become normally "
"distributed for large sample sizes. The mean is one such statistic, but it’s "
"not the only one."
msgstr ""
"Як завжди, я тут трохи недбалий. Центральна гранична теорема є дещо більш "
"загальною, ніж це випливає з цього розділу. Як і в більшості вступних "
"підручників зі статистики, я розглянув одну ситуацію, в якій діє центральна "
"гранична теорема: коли ви обчислюєте середнє значення для багатьох "
"незалежних подій, взятих з одного і того ж розподілу. Однак центральна "
"гранична теорема є набагато ширшою. Існує цілий клас величин, які "
"називаються «*U*-статистиками», і всі вони задовольняють центральну граничну "
"теорему і тому мають нормальний розподіл для великих розмірів вибірки. "
"Середнє значення є однією з таких статистик, але не єдиною."

#: ../../Ch08/Ch08_Estimation_4.rst:4
msgid "Estimating population parameters"
msgstr "Оцінка параметрів популяції"

#: ../../Ch08/Ch08_Estimation_4.rst:6
msgid ""
"In all the IQ examples in the previous sections we actually knew the "
"population parameters ahead of time. As every undergraduate gets taught in "
"their very first lecture on the measurement of intelligence, IQ scores are "
"*defined* to have mean 100 and standard deviation 15. However, this is a bit "
"of a lie. How do we know that IQ scores have a true population mean of 100? "
"Well, we know this because the people who designed the tests have "
"administered them to very large samples, and have then “rigged” the scoring "
"rules so that their sample has mean 100. That’s not a bad thing of course, "
"it’s an important part of designing a psychological measurement. However, "
"it’s important to keep in mind that this theoretical mean of 100 only "
"attaches to the population that the test designers used to design the tests. "
"Good test designers will actually go to some lengths to provide “test norms” "
"that can apply to lots of different populations (e.g., different age groups, "
"nationalities etc)."
msgstr ""
"У всіх прикладах з IQ, наведених у попередніх розділах, ми заздалегідь знали "
"параметри популяції. Як навчають студентів на першому курсі на першій лекції "
"з вимірювання інтелекту, бали IQ *визначаються* як такі, що мають середнє "
"значення 100 і стандартне відхилення 15. Однак це не зовсім правда. Звідки "
"ми знаємо, що бали IQ мають справжнє середнє значення 100 для популяції? Ми "
"знаємо це, тому що люди, які розробляли тести, застосовували їх до дуже "
"великих вибірок, а потім «підлаштували» правила підрахунку балів так, щоб їх "
"вибірка мала середнє значення 100. Звичайно, це не є поганим, це важлива "
"частина розробки психологічного вимірювання. Однак важливо пам'ятати, що це "
"теоретичне середнє значення 100 стосується лише популяції, яку розробники "
"тестів використовували для розробки тестів. Хороші розробники тестів "
"докладають чималих зусиль, щоб створити «норми тестування», які можна "
"застосовувати до багатьох різних груп населення (наприклад, різних вікових "
"груп, національностей тощо)."

#: ../../Ch08/Ch08_Estimation_4.rst:22
msgid ""
"This is very handy, but of course almost every research project of interest "
"involves looking at a different population of people to those used in the "
"test norms. For instance, suppose you wanted to measure the effect of low "
"level lead poisoning on cognitive functioning in Port Pirie, a South "
"Australian industrial town with a lead smelter. Perhaps you decide that you "
"want to compare IQ scores among people in Port Pirie to a comparable sample "
"in Whyalla, a South Australian industrial town with a steel refinery.\\ [#]_ "
"Regardless of which town you’re thinking about, it doesn’t make a lot of "
"sense simply to *assume* that the true population mean IQ is 100. No-one "
"has, to my knowledge, produced sensible norming data that can automatically "
"be applied to South Australian industrial towns. We’re going to have to "
"**estimate** the population parameters from a sample of data. So how do we "
"do this?"
msgstr ""
"Це дуже зручно, але, звичайно, майже кожен цікавий дослідницький проект "
"передбачає вивчення іншої групи населення, ніж та, яка використовується в "
"тестових нормах. Наприклад, припустимо, ви хочете виміряти вплив низького "
"рівня отруєння свинцем на когнітивні функції в Порт-Пірі, промисловому місті "
"в Південній Австралії, де знаходиться свинцевий завод. Можливо, ви вирішите "
"порівняти показники IQ жителів Порт-Пірі з аналогічною вибіркою в Вайала, "
"промисловому місті в Південній Австралії, де знаходиться сталеливарний "
"завод. [#]_ Незалежно від того, про яке місто ви думаєте, не має сенсу "
"просто *припускати*, що середній IQ населення становить 100. Наскільки мені "
"відомо, ніхто не створив розумних нормативних даних, які можна було б "
"автоматично застосувати до промислових міст Південної Австралії. Нам "
"доведеться **оцінити** параметри населення на основі вибірки даних. Як це "
"зробити?"

#: ../../Ch08/Ch08_Estimation_4.rst:37
msgid "Estimating the population mean"
msgstr "Оцінка середнього значення популяції"

#: ../../Ch08/Ch08_Estimation_4.rst:39
msgid ""
"Suppose we go to Port Pirie and 100 of the locals are kind enough to sit "
"through an IQ test. The average IQ score among these people turns out to be "
"*X̄* = 98.5. So what is the true mean IQ for the entire population of Port "
"Pirie? Obviously, we don’t know the answer to that question. It could be "
"97.2, but it could also be 103.5. Our sampling isn’t exhaustive so we cannot "
"give a definitive answer. Nevertheless, if I was forced at gunpoint to give "
"a “best guess” I’d have to say 98.5. That’s the essence of statistical "
"estimation: giving a best guess."
msgstr ""
"Припустимо, ми їдемо до Порт-Пірі, і 100 місцевих жителів люб'язно "
"погоджуються пройти тест на IQ. Середній показник IQ серед цих людей "
"виявляється *X̄* = 98,5. То який же справжній середній IQ для всього "
"населення Порт-Пірі? Очевидно, що ми не знаємо відповіді на це питання. Він "
"може бути 97,2, а може бути і 103,5. Наша вибірка не є вичерпною, тому ми не "
"можемо дати остаточної відповіді. Проте, якби мене під дулом пістолета "
"змусили дати «найкраще припущення», я б сказав 98,5. У цьому полягає суть "
"статистичної оцінки: дати найкраще припущення."

#: ../../Ch08/Ch08_Estimation_4.rst:48
msgid ""
"In this example estimating the unknown poulation parameter is "
"straightforward. I calculate the sample mean and I use that as my **estimate "
"of the population mean**. It’s pretty simple, and in the next section I’ll "
"explain the statistical justification for this intuitive answer. However, "
"for the moment what I want to do is make sure you recognise that the sample "
"statistic and the estimate of the population parameter are conceptually "
"different things. A sample statistic is a description of your data, whereas "
"the estimate is a guess about the population. With that in mind, "
"statisticians often different notation to refer to them. For instance, if "
"the true population mean is denoted µ, then we would use :math:`\\hat\\mu` "
"to refer to our estimate of the population mean. In contrast, the sample "
"mean is denoted *X̄* or sometimes *m* or *M*. However, in simple random "
"samples the estimate of the population mean is identical to the sample mean. "
"If I observe a sample mean of *X̄* = 98.5 then my estimate of the population "
"mean is also :math:`\\hat\\mu` = 98.5. To help keep the notation clear, "
"here’s a handy table:"
msgstr ""
"У цьому прикладі оцінка невідомого параметра популяції є досить простою. Я "
"обчислюю середнє значення вибірки і використовую його як **оцінку середнього "
"значення популяції**. Це досить просто, і в наступному розділі я поясню "
"статистичне обґрунтування цього інтуїтивного відповіді. Однак на даний "
"момент я хочу переконатися, що ви розумієте, що вибіркова статистика і "
"оцінка параметра популяції є концептуально різними поняттями. Вибіркова "
"статистика — це опис ваших даних, тоді як оцінка — це припущення про "
"генеральну сукупність. З огляду на це, статистики часто використовують різні "
"позначення для їх позначення. Наприклад, якщо справжнє середнє значення "
"генеральної сукупності позначається µ, то ми будемо використовувати :math:`"
"\\hat\\mu` для позначення нашої оцінки середнього значення генеральної "
"сукупності. На відміну від цього, середнє значення вибірки позначається *X̄* "
"або іноді *m* чи *M*. Однак у простих випадкових вибірках оцінка середнього "
"значення генеральної сукупності є ідентичною середньому значенню вибірки. "
"Якщо я спостерігаю середнє значення вибірки *X̄* = 98,5, то моя оцінка "
"середнього значення генеральної сукупності також дорівнює :math:`\\hat\\mu` "
"= 98,5. Щоб полегшити розуміння позначень, ось зручна таблиця:"

#: ../../Ch08/Ch08_Estimation_4.rst:67 ../../Ch08/Ch08_Estimation_4.rst:265
msgid "Symbol"
msgstr "Символ"

#: ../../Ch08/Ch08_Estimation_4.rst:68 ../../Ch08/Ch08_Estimation_4.rst:265
msgid "What is it?"
msgstr "Що це?"

#: ../../Ch08/Ch08_Estimation_4.rst:69 ../../Ch08/Ch08_Estimation_4.rst:265
msgid "Do we know what it is?"
msgstr "Чи знаємо ми, що це таке?"

#: ../../Ch08/Ch08_Estimation_4.rst:70
msgid "*X̄*"
msgstr "*X̄*"

#: ../../Ch08/Ch08_Estimation_4.rst:71
msgid "Sample mean"
msgstr "Середнє значення вибірки"

#: ../../Ch08/Ch08_Estimation_4.rst:72 ../../Ch08/Ch08_Estimation_4.rst:267
#: ../../Ch08/Ch08_Estimation_4.rst:278
msgid "Yes, calculated from the raw data"
msgstr "Так, розраховано на основі необроблених даних"

#: ../../Ch08/Ch08_Estimation_4.rst:73
msgid "µ"
msgstr "µ"

#: ../../Ch08/Ch08_Estimation_4.rst:74
msgid "True population mean"
msgstr "Справжнє середнє значення населення"

#: ../../Ch08/Ch08_Estimation_4.rst:75 ../../Ch08/Ch08_Estimation_4.rst:270
#: ../../Ch08/Ch08_Estimation_4.rst:281
msgid "Almost never known for sure"
msgstr "Майже ніколи не відомо напевно"

#: ../../Ch08/Ch08_Estimation_4.rst:76
msgid ":math:`\\hat{\\mu}`"
msgstr ":math:`\\hat{\\mu}`"

#: ../../Ch08/Ch08_Estimation_4.rst:77
msgid "Estimate of the population mean"
msgstr "Оцінка до середнього значення популяції"

#: ../../Ch08/Ch08_Estimation_4.rst:78
msgid "Yes, identical to the sample mean in simple random samples"
msgstr ""
"Так, ідентично вибірковому середньому значенню у простих випадкових вибірках"

#: ../../Ch08/Ch08_Estimation_4.rst:82
msgid "Estimating the population standard deviation"
msgstr "Оцінка стандартного відхилення генеральної сукупності"

#: ../../Ch08/Ch08_Estimation_4.rst:84
msgid ""
"So far, estimation seems pretty simple, and you might be wondering why I "
"forced you to read through all that stuff about sampling theory. In the case "
"of the mean our estimate of the population parameter (i.e. :math:"
"`\\hat\\mu`) turned out to be identical to the corresponding sample "
"statistic (i.e. *X̄*). However, that’s not always true. To see this, let’s "
"have a think about how to construct an **estimate of the population standard "
"deviation**, which we’ll denote :math:`\\hat\\sigma`. What shall we use as "
"our estimate in this case? Your first thought might be that we could do the "
"same thing we did when estimating the mean, and just use the sample "
"statistic as our estimate. That’s almost the right thing to do, but not "
"quite."
msgstr ""
"Досі оцінка здається досить простою, і ви, можливо, дивуєтеся, чому я змусив "
"вас прочитати все це про теорію вибірки. У випадку середнього значення наша "
"оцінка параметра генеральної сукупності (тобто :math:`\\hat\\mu`) виявилася "
"ідентичною відповідній вибірковій статистиці (тобто *X̄*). Однак це не завжди "
"так. Щоб це зрозуміти, давайте поміркуємо, як побудувати **оцінку "
"стандартного відхилення генеральної сукупності**, яку позначимо :math:`\\hat"
"\\sigma`. Що ми будемо використовувати як оцінку в цьому випадку? Ваша перша "
"думка може бути такою, що ми можемо зробити те саме, що й при оцінці "
"середнього значення, і просто використовувати вибіркову статистику як нашу "
"оцінку. Це майже правильний підхід, але не зовсім."

#: ../../Ch08/Ch08_Estimation_4.rst:95
msgid ""
"Here’s why. Suppose I have a sample that contains a single observation. For "
"this example, it helps to consider a sample where you have no intuitions at "
"all about what the true population values might be, so let’s use something "
"completely fictitious. Suppose the observation in question measures the "
"*cromulence* of my shoes. It turns out that my shoes have a cromulence of "
"20. So here’s my sample:"
msgstr ""
"Ось чому. Припустимо, я маю вибірку, що містить одне спостереження. Для "
"цього прикладу корисно розглянути вибірку, де ви не маєте жодного уявлення "
"про те, якими можуть бути справжні значення генеральної сукупності, тому "
"давайте використаємо щось повністю вигадане. Припустимо, що дане "
"спостереження вимірює *кромулентність* мого взуття. Виявляється, що моє "
"взуття має кромулентність 20. Отже, ось моя вибірка:"

#: ../../Ch08/Ch08_Estimation_4.rst:102
msgid "``20``"
msgstr "``20``"

#: ../../Ch08/Ch08_Estimation_4.rst:104
msgid ""
"This is a perfectly legitimate sample, even if it does have a sample size of "
"*N* = 1. It has a sample mean of 20 and because every observation in this "
"sample is equal to the sample mean (obviously!) it has a sample standard "
"deviation of 0. As a description of the *sample* this seems quite right, the "
"sample contains a single observation and therefore there is no variation "
"observed within the sample. A sample standard deviation of *s* = 0 is the "
"right answer here. But as an estimate of the *population* standard deviation "
"it feels completely insane, right? Admittedly, you and I don’t know anything "
"at all about what “cromulence” is, but we know something about data. The "
"only reason that we don’t see any variability in the *sample* is that the "
"sample is too small to display any variation! So, if you have a sample size "
"of *N* = 1 it *feels* like the right answer is just to say “no idea at all”."
msgstr ""
"Це цілком законна вибірка, навіть якщо її розмір становить *N* = 1. Середнє "
"значення вибірки дорівнює 20, а оскільки кожне спостереження в цій вибірці "
"дорівнює середньому значенню вибірки (що очевидно!), стандартне відхилення "
"вибірки дорівнює 0. Як опис *вибірки* це здається цілком правильним, "
"оскільки вибірка містить одне спостереження і, отже, у вибірці не "
"спостерігається жодних відхилень. Стандартне відхилення вибірки *s* = 0 є "
"правильною відповіддю в цьому випадку. Але як оцінка стандартного відхилення "
"*популяції* це здається абсолютно божевільним, чи не так? Звісно, ми з вами "
"нічого не знаємо про те, що таке «кромулентність», але ми знаємо дещо про "
"дані. Єдина причина, чому ми не бачимо жодної варіативності у *вибірці*, "
"полягає в тому, що вибірка занадто мала, щоб відобразити будь-яку варіацію! "
"Отже, якщо розмір вибірки *N* = 1, *здається*, що правильною відповіддю буде "
"просто сказати «зовсім не знаю»."

#: ../../Ch08/Ch08_Estimation_4.rst:118
msgid ""
"Notice that you *don’t* have the same intuition when it comes to the sample "
"mean and the population mean. If forced to make a best guess about the "
"population mean it doesn’t feel completely insane to guess that the "
"population mean is 20. Sure, you probably wouldn’t feel very confident in "
"that guess because you have only the one observation to work with, but it’s "
"still the best guess you can make."
msgstr ""
"Зверніть увагу, що ви *не* маєте такої ж інтуїції, коли мова йде про середнє "
"значення вибірки та середнє значення генеральної сукупності. Якщо вас "
"змушують зробити найкраще припущення щодо середнього значення генеральної "
"сукупності, то припущення, що середнє значення генеральної сукупності "
"дорівнює 20, не здається зовсім безглуздим. Звичайно, ви, ймовірно, не "
"будете дуже впевнені в цьому припущенні, оскільки маєте лише одне "
"спостереження, але це все одно найкраще припущення, яке ви можете зробити."

#: ../../Ch08/Ch08_Estimation_4.rst:125
msgid ""
"Let’s extend this example a little. Suppose I now make a second observation. "
"My data set now has *N* = 2 observations of the cromulence of shoes, and the "
"complete sample now looks like this:"
msgstr ""
"Давайте трохи розширимо цей приклад. Припустимо, що я тепер зроблю друге "
"спостереження. Мій набір даних тепер містить *N* = 2 спостереження щодо "
"кромулентності взуття, і повна вибірка тепер виглядає так:"

#: ../../Ch08/Ch08_Estimation_4.rst:129
msgid "``20, 22``"
msgstr "``20, 22``"

#: ../../Ch08/Ch08_Estimation_4.rst:131
msgid ""
"This time around, our sample is *just* large enough for us to be able to "
"observe some variability: two observations is the bare minimum number needed "
"for any variability to be observed! For our new data set, the sample mean is "
"*X̄* = 21, and the sample standard deviation is *s* = 1. What intuitions do "
"we have about the population? Again, as far as the population mean goes, the "
"best guess we can possibly make is the sample mean. If forced to guess we’d "
"probably guess that the population mean cromulence is 21. What about the "
"standard deviation? This is a little more complicated. The sample standard "
"deviation is only based on two observations, and if you’re at all like me "
"you probably have the intuition that, with only two observations we haven’t "
"given the population “enough of a chance” to reveal its true variability to "
"us. It’s not just that we suspect that the estimate is *wrong*, after all "
"with only two observations we expect it to be wrong to some degree. The "
"worry is that the error is *systematic*. Specifically, we suspect that the "
"sample standard deviation is likely to be smaller than the population "
"standard deviation."
msgstr ""
"Цього разу наша вибірка є *достатньо* великою, щоб ми могли спостерігати "
"певну мінливість: два спостереження — це мінімальна кількість, необхідна для "
"спостереження будь-якої мінливості! Для нашого нового набору даних середнє "
"значення вибірки становить *X̄* = 21, а стандартне відхилення вибірки — *s* = "
"1. Які інтуїтивні висновки ми можемо зробити про генеральну сукупність? "
"Знову ж таки, що стосується середнього значення генеральної сукупності, "
"найкращим припущенням, яке ми можемо зробити, є середнє значення вибірки. "
"Якщо б нас змусили вгадати, ми б, ймовірно, припустили, що середнє значення "
"генеральної сукупності становить 21. А що щодо стандартного відхилення? Це "
"трохи складніше. Стандартне відхилення вибірки базується лише на двох "
"спостереженнях, і якщо ви хоч трохи схожі на мене, то, ймовірно, інтуїтивно "
"відчуваєте, що лише два спостереження не дають генеральній сукупності «"
"достатньої можливості» розкрити нам свою справжню мінливість. Ми не просто "
"підозрюємо, що оцінка є *неправильною*, адже з лише двома спостереженнями ми "
"очікуємо, що вона буде неправильною в певній мірі. Проблема полягає в тому, "
"що помилка є *систематичною*. Зокрема, ми підозрюємо, що стандартне "
"відхилення вибірки, ймовірно, буде меншим за стандартне відхилення "
"генеральної сукупності."

#: ../../Ch08/Ch08_Estimation_4.rst:147
msgid ""
"This intuition feels right, but it would be nice to demonstrate this "
"somehow. There are in fact mathematical proofs that confirm this intuition, "
"but unless you have the right mathematical background they don’t help very "
"much. Instead, what I’ll do is simulate the results of some experiments. "
"With that in mind, let’s return to our IQ studies. Suppose the true "
"population mean IQ is 100 and the standard deviation is 15. First I’ll "
"conduct an experiment in which I measure *N* = 2 IQ scores and I’ll "
"calculate the sample standard deviation. If I do this over and over again, "
"and plot a histogram of these sample standard deviations, what I have is the "
"*sampling distribution of the standard deviation*. I’ve plotted this "
"distribution in :numref:`fig-samplingDistSampleSD`. Even though the true "
"population standard deviation is 15 the average of the *sample* standard "
"deviations is only 8.5. Notice that this is a very different result to what "
"we found in :numref:`fig-samplingDistDiffN` (middle panel) when we plotted "
"the sampling distribution of the mean, where the population mean is 100 and "
"the average of the sample means is also 100."
msgstr ""
"Ця інтуїція здається правильною, але було б добре якось це продемонструвати. "
"Насправді існують математичні докази, які підтверджують цю інтуїцію, але "
"якщо ви не маєте відповідної математичної підготовки, вони не дуже "
"допоможуть. Натомість я продемонструю результати деяких експериментів. З "
"огляду на це, повернемося до наших досліджень IQ. Припустимо, що справжнє "
"середнє значення IQ населення становить 100, а стандартне відхилення — 15. "
"Спочатку я проведу експеримент, в якому виміряю *N* = 2 показники IQ і "
"обчислю стандартне відхилення вибірки. Якщо я буду робити це знову і знову і "
"будувати гістограму цих стандартних відхилень вибірки, я отримаю *розподіл "
"вибірки стандартного відхилення*. Я побудував цей розподіл на :numref:`fig-"
"samplingDistSampleSD`. Незважаючи на те, що справжнє стандартне відхилення "
"генеральної сукупності становить 15, середнє значення *вибіркових* "
"стандартних відхилень становить лише 8,5. Зверніть увагу, що цей результат "
"значно відрізняється від того, який ми отримали в :numref:`fig-"
"samplingDistDiffN` (середня панель), коли ми побудували вибірковий розподіл "
"середнього значення, де середнє значення генеральної сукупності становить "
"100, а середнє значення вибіркових середніх значень також становить 100."

#: ../../Ch08/Ch08_Estimation_4.rst:166
msgid "Sampling distrib. of the std. dev. for a “two IQ scores” experiment"
msgstr ""
"Розподіл вибірки стандартного відхилення для експерименту «два показники IQ»"

#: ../../Ch08/Ch08_Estimation_4.rst:170
msgid ""
"Sampling distribution of the sample standard deviation for a “two IQ scores” "
"experiment. The true population standard deviation is 15 (dashed line), but "
"as you can see from the histogram the vast majority of experiments will "
"produce a much smaller sample standard deviation than this. On average, this "
"experiment would produce a sample standard deviation of only 8.5, well below "
"the true value! In other words, the sample standard deviation is a biased "
"estimate of the population standard deviation."
msgstr ""
"Розподіл вибіркового стандартного відхилення для експерименту з «двома "
"показниками IQ». Справжнє стандартне відхилення генеральної сукупності "
"становить 15 (пунктирна лінія), але, як видно з гістограми, у переважній "
"більшості експериментів вибіркове стандартне відхилення буде значно меншим. "
"В середньому, цей експеримент дасть вибіркове стандартне відхилення лише "
"8,5, що значно нижче за справжнє значення! Іншими словами, стандартне "
"відхилення вибірки є упередженою оцінкою стандартного відхилення генеральної "
"сукупності."

#: ../../Ch08/Ch08_Estimation_4.rst:180
msgid ""
"Now let’s extend the simulation. Instead of restricting ourselves to the "
"situation where *N* = 2, let’s repeat the exercise for sample sizes from 1 "
"to 10. If we plot the average sample mean and average sample standard "
"deviation as a function of sample size, you get the results shown in :numref:"
"`fig-biasMeanSD`. On the left hand side I’ve plotted the average sample mean "
"and on the right hand side I’ve plotted the average standard deviation. The "
"two plots are quite different: *on average*, the average sample mean is "
"equal to the population mean. It is an **unbiased estimator**, which is "
"essentially the reason why your best estimate for the population mean is the "
"sample mean.\\ [#]_ The plot on the right is quite different: on average, "
"the sample standard deviation *s* is *smaller* than the population standard "
"deviation σ. It is a **biased estimator**. In other words, if we want to "
"make a “best guess” :math:`\\hat\\sigma` about the value of the population "
"standard deviation σ we should make sure our guess is a little bit larger "
"than the sample standard deviation *s*."
msgstr ""
"Тепер розширимо моделювання. Замість того, щоб обмежуватися ситуацією, де *N*"
" = 2, повторімо вправу для розмірів вибірки від 1 до 10. Якщо побудувати "
"графік середнього значення вибірки та середнього стандартного відхилення "
"вибірки як функції розміру вибірки, отримаємо результати, показані в :numref"
":`fig-biasMeanSD`. Зліва я зобразив середнє значення вибірки, а праворуч — "
"середнє стандартне відхилення. Ці два графіки досить сильно відрізняються: *"
"в середньому* середнє значення вибірки дорівнює середньому значенню "
"генеральної сукупності. Це **неупереджений оцінювач**, що є основною "
"причиною, чому найкращим оцінювачем середнього значення генеральної "
"сукупності є середнє значення вибірки. [#]_ Графік праворуч є зовсім іншим: "
"в середньому, стандартне відхилення вибірки *s* є *меншим* за стандартне "
"відхилення генеральної сукупності σ. Це **упереджений оцінювач**. Іншими "
"словами, якщо ми хочемо зробити «найкраще припущення» :math:`\\hat\\sigma` "
"щодо значення стандартного відхилення генеральної сукупності σ, ми повинні "
"переконатися, що наше припущення є трохи більшим за стандартне відхилення "
"вибірки *s*."

#: ../../Ch08/Ch08_Estimation_4.rst:198
msgid "Sample size: Mean (un-biased) and standard deviation (biased)"
msgstr ""
"Розмір вибірки: середнє значення (неупереджене) та стандартне відхилення "
"(упереджене)"

#: ../../Ch08/Ch08_Estimation_4.rst:202
msgid ""
"Illustration of the fact that the sample mean is an unbiased estimator of "
"the population mean (left panel), but the sample standard deviation is a "
"biased estimator of the population standard deviation (right panel). For the "
"figure, I generated 10,000 simulated data sets with 1 observation each, "
"10,000 more with 2 observations, and so on up to a sample size of 10. Each "
"data set consisted of fake IQ data, that is the data were normally "
"distributed with a true population mean of 100 and standard deviation 15. On "
"average, the sample means turn out to be 100, regardless of sample size "
"(left panel). However, the sample standard deviations turn out to be "
"systematically too small (right panel), especially for small sample sizes."
msgstr ""
"Ілюстрація того, що середнє значення вибірки є необ'єктивним оцінювачем "
"середнього значення генеральної сукупності (ліва панель), але стандартне "
"відхилення вибірки є необ'єктивним оцінювачем стандартного відхилення "
"генеральної сукупності (права панель). Для цього рисунка я створив 10 000 "
"модельованих наборів даних з 1 спостереженням у кожному, ще 10 000 з 2 "
"спостереженнями і так далі, аж до розміру вибірки 10. Кожен набір даних "
"складався з вигаданих даних про IQ, тобто дані мали нормальний розподіл із "
"справжнім середнім значенням генеральної сукупності 100 і стандартним "
"відхиленням 15. У середньому, середні значення вибірки виявляються рівними "
"100, незалежно від розміру вибірки (ліва панель). Однак стандартні "
"відхилення вибірки виявляються систематично занадто малими (права панель), "
"особливо для малих розмірів вибірки."

#: ../../Ch08/Ch08_Estimation_4.rst:215
msgid ""
"The fix to this systematic bias turns out to be very simple. Here’s how it "
"works. Before tackling the standard deviation let’s look at the variance. If "
"you recall from :doc:`../Ch04/Ch04_Descriptives_2`, the sample variance is "
"defined to be the average of the squared deviations from the sample mean. "
"That is:"
msgstr ""
"Вирішення цієї систематичної похибки виявляється дуже простим. Ось як це "
"працює. Перш ніж розглянути стандартне відхилення, давайте подивимося на "
"дисперсію. Якщо ви пам'ятаєте з :doc:`../Ch04/Ch04_Descriptives_2`, "
"дисперсія вибірки визначається як середнє значення квадратів відхилень від "
"середнього значення вибірки. Тобто:"

#: ../../Ch08/Ch08_Estimation_4.rst:221
msgid ""
"s^2 = \\frac{1}{N} \\sum_{i=1}^N (X_i - \\bar{X})^2\n"
"\n"
msgstr ""
"s^2 = \\frac{1}{N} \\sum_{i=1}^N (X_i - \\bar{X})^2\n"
"\n"

#: ../../Ch08/Ch08_Estimation_4.rst:223
msgid ""
"The sample variance *s*\\² is a biased estimator of the population variance "
"σ². But as it turns out, we only need to make a tiny tweak to transform this "
"into an unbiased estimator. All we have to do is divide by *N* - 1 rather "
"than by *N*. If we do that, we obtain the following formula:"
msgstr ""
"Діапазон вибірки *s*\\² є зміщеним оцінювачем діапазону сукупності σ². Але, "
"як виявляється, нам потрібно лише трохи змінити його, щоб перетворити на "
"незміщений оцінювач. Все, що нам потрібно зробити, це розділити на *N* - 1, "
"а не на *N*. Якщо ми це зробимо, отримаємо таку формулу:"

#: ../../Ch08/Ch08_Estimation_4.rst:228
msgid ""
"\\hat\\sigma^2 = \\frac{1}{N-1} \\sum_{i=1}^N (X_i - \\bar{X})^2\n"
"\n"
msgstr ""
"\\hat\\sigma^2 = \\frac{1}{N-1} \\sum_{i=1}^N (X_i - \\bar{X})^2\n"
"\n"

#: ../../Ch08/Ch08_Estimation_4.rst:230
msgid ""
"This is an unbiased estimator of the population variance σ². Moreover, this "
"finally answers the question we raised in :doc:`../Ch04/"
"Ch04_Descriptives_2`. Why did jamovi give us slightly different answers for "
"variance? It’s because jamovi calculates :math:`\\hat\\sigma^2` not *s*\\², "
"that’s why. A similar story applies for the standard deviation. If we divide "
"by *N* - 1 rather than *N* our estimate of the population standard deviation "
"becomes:"
msgstr ""
"Це є необ'єктивним оцінювачем дисперсії сукупності σ². Більше того, це "
"нарешті дає відповідь на питання, яке ми поставили в :doc:`../Ch04/"
"Ch04_Descriptives_2`. Чому jamovi дав нам дещо різні відповіді щодо "
"дисперсії? Тому що jamovi обчислює :math:`\\hat\\sigma^2`, а не *s*\\², ось "
"чому. Подібна ситуація стосується і стандартного відхилення. Якщо ми ділимо "
"на *N* - 1, а не на *N*, наша оцінка стандартного відхилення генеральної "
"сукупності стає такою:"

#: ../../Ch08/Ch08_Estimation_4.rst:237
msgid ""
"\\hat\\sigma = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (X_i - \\bar{X})^2}\n"
"\n"
msgstr ""
"\\hat\\sigma = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (X_i - \\bar{X})^2}\n"
"\n"

#: ../../Ch08/Ch08_Estimation_4.rst:239
msgid ""
"and when we use jamovi’s built in standard deviation function, what it’s "
"doing is calculating :math:`\\hat\\sigma`, not *s*.\\ [#]_"
msgstr ""
"і коли ми використовуємо вбудовану функцію стандартного відхилення jamovi, "
"вона обчислює :math:`\\hat\\sigma`, а не *s*.\\ [#]_"

#: ../../Ch08/Ch08_Estimation_4.rst:242
msgid ""
"One final point. In practice, a lot of people tend to refer to :math:"
"`\\hat{\\sigma}` (i.e., the formula where we divide by *N* - 1) as the "
"*sample* standard deviation. Technically, this is incorrect. The *sample* "
"standard deviation should be equal to *s* (i.e., the formula where we divide "
"by *N*). These aren’t the same thing, either conceptually or numerically. "
"One is a property of the sample, the other is an estimated characteristic of "
"the population. However, in almost every real life application what we "
"actually care about is the estimate of the population parameter, and so "
"people always report :math:`\\hat\\sigma` rather than *s*. This is the right "
"number to report, of course. It’s just that people tend to get a little bit "
"imprecise about terminology when they write it up, because “sample standard "
"deviation” is shorter than “estimated population standard deviation”. It’s "
"no big deal, and in practice I do the same thing everyone else does. "
"Nevertheless, I think it’s important to keep the two *concepts* separate. "
"It’s never a good idea to confuse “known properties of your sample” with "
"“guesses about the population from which it came”. The moment you start "
"thinking that *s* and :math:`\\hat\\sigma` are the same thing, you start "
"doing exactly that."
msgstr ""
"Останнє зауваження. На практиці багато хто схильний називати :math:`\\hat{"
"\\sigma}` (тобто формулу, в якій ми ділимо на *N* - 1) *вибірковим* "
"стандартним відхиленням. Технічно це невірно. Стандартне відхилення *вибірки*"
" повинно дорівнювати *s* (тобто формулі, в якій ми ділимо на *N*). Це не "
"одне й те саме, ні концептуально, ні числово. Одне є властивістю вибірки, "
"інше — оціночною характеристикою сукупності. Однак у майже всіх реальних "
"випадках нас цікавить саме оцінка параметра генеральної сукупності, тому "
"люди завжди вказують :math:`\\hat\\sigma`, а не *s*. Звичайно, це правильне "
"число, яке слід вказувати. Просто люди схильні бути неточними в "
"термінології, коли пишуть про це, оскільки «стандартне відхилення вибірки» є "
"коротшим виразом, ніж «оціночне стандартне відхилення генеральної сукупності»"
". Це не є великою проблемою, і на практиці я роблю те саме, що й усі інші. "
"Проте, я вважаю, що важливо розрізняти ці два *поняття*. Ніколи не варто "
"плутати «відомі властивості вибірки» з «припущеннями щодо генеральної "
"сукупності, з якої вона походить». У той момент, коли ви починаєте думати, "
"що *s* і :math:`\\hat\\sigma` є одним і тим самим, ви починаєте робити саме "
"це."

#: ../../Ch08/Ch08_Estimation_4.rst:261
msgid ""
"To finish this section off, here’s another couple of tables to help keep "
"things clear."
msgstr "На завершення цього розділу, ось ще кілька таблиць для наочності."

#: ../../Ch08/Ch08_Estimation_4.rst:267
msgid "*s*"
msgstr "*s*"

#: ../../Ch08/Ch08_Estimation_4.rst:267
msgid "Sample standard deviation"
msgstr "Стандартне відхилення вибірки"

#: ../../Ch08/Ch08_Estimation_4.rst:270
msgid "σ"
msgstr "σ"

#: ../../Ch08/Ch08_Estimation_4.rst:270
msgid "Population standard deviation"
msgstr "Стандартне відхилення популяції"

#: ../../Ch08/Ch08_Estimation_4.rst:273
msgid ":math:`\\hat{\\sigma}`"
msgstr ":math:`\\hat{\\sigma}`"

#: ../../Ch08/Ch08_Estimation_4.rst:273
msgid "Estimate of the population standard deviation"
msgstr "Оцінка до стандартного відхилення генеральної сукупності"

#: ../../Ch08/Ch08_Estimation_4.rst:273
msgid "Yes, but not the same as the sample standard deviation"
msgstr "Так, але не те саме, що стандартне відхилення вибірки"

#: ../../Ch08/Ch08_Estimation_4.rst:278
msgid "*s*\\²"
msgstr "*s*\\²"

#: ../../Ch08/Ch08_Estimation_4.rst:278
msgid "Sample variance"
msgstr "Дисперсія вибірки"

#: ../../Ch08/Ch08_Estimation_4.rst:281
msgid "σ²"
msgstr "σ²"

#: ../../Ch08/Ch08_Estimation_4.rst:281
msgid "Population variance"
msgstr "Дисперсія популяції"

#: ../../Ch08/Ch08_Estimation_4.rst:284
msgid ":math:`\\hat{\\sigma}^2`"
msgstr ":math:`\\hat{\\sigma}^2`"

#: ../../Ch08/Ch08_Estimation_4.rst:284
msgid "Estimate of the population variance"
msgstr "Оцінка дисперсії популяції"

#: ../../Ch08/Ch08_Estimation_4.rst:284
msgid "Yes, but not the same as the sample variance"
msgstr "Так, але не те саме, що й дисперсія вибірки"

#: ../../Ch08/Ch08_Estimation_4.rst:291
msgid ""
"Please note that if you were *actually* interested in this question you "
"would need to be a *lot* more careful than I’m being here. You *can’t* just "
"compare IQ scores in Whyalla to Port Pirie and assume that any differences "
"are due to lead poisoning. Even if it were true that the only differences "
"between the two towns corresponded to the different refineries (and it "
"isn’t, not by a long shot), you need to account for the fact that people "
"already *believe* that lead pollution causes cognitive deficits. If you "
"recall back to chapter :doc:`../Ch02/Ch02_StudyDesign`, this means that "
"there are different demand characteristics for the Port Pirie sample than "
"for the Whyalla sample. In other words, you might end up with an illusory "
"group difference in your data, caused by the fact that people *think* that "
"there is a real difference. I find it pretty implausible to think that the "
"locals wouldn’t be well aware of what you were trying to do if a bunch of "
"researchers turned up in Port Pirie with lab coats and IQ tests, and even "
"less plausible to think that a lot of people would be pretty resentful of "
"you for doing it. Those people won’t be as co-operative in the tests. Other "
"people in Port Pirie might be *more* motivated to do well because they don’t "
"want their home town to look bad. The motivational effects that would apply "
"in Whyalla are likely to be weaker, because people don’t have any concept of "
"“iron ore poisoning” in the same way that they have a concept for “lead "
"poisoning”. Psychology is *hard*."
msgstr ""
"Зверніть увагу, що якщо ви *дійсно* зацікавлені в цьому питанні, вам слід "
"бути *набагато* обережнішими, ніж я тут. Ви *не можете* просто порівняти "
"показники IQ у Вайаллі та Порт-Пірі і припустити, що будь-які відмінності "
"пов'язані з отруєнням свинцем. Навіть якщо б це було правдою, що єдині "
"відмінності між цими двома містами відповідають різним нафтопереробним "
"заводам (а це далеко не так), вам потрібно врахувати той факт, що люди вже "
"*вірять*, що забруднення свинцем спричиняє когнітивні порушення. Якщо ви "
"згадаєте розділ :doc:`../Ch02/Ch02_StudyDesign`, це означає, що для вибірки "
"з Порт-Пірі існують інші характеристики попиту, ніж для вибірки з Вайалли. "
"Іншими словами, ви можете отримати ілюзорну групову різницю у своїх даних, "
"спричинену тим, що люди *вважають*, що існує реальна різниця. Мені здається "
"досить неправдоподібним, що місцеві жителі не будуть добре обізнані про те, "
"що ви намагаєтеся зробити, якщо в Порт-Пірі з'явиться група дослідників у "
"лабораторних халатах з тестами на IQ, і ще менш правдоподібним, що багато "
"людей будуть вам дуже обурені за це. Ці люди не будуть так охоче "
"співпрацювати під час тестів. Інші мешканці Порт-Пірі можуть бути *більш* "
"мотивовані показати хороші результати, тому що не хочуть, щоб їхнє рідне "
"місто виглядало погано. Мотиваційний ефект, який можна було б очікувати в "
"Вайала, ймовірно, буде слабшим, тому що люди не мають уявлення про «отруєння "
"залізною рудою» так само, як вони мають уявлення про «отруєння свинцем». "
"Психологія — це *складна* наука."

#: ../../Ch08/Ch08_Estimation_4.rst:314
msgid ""
"I should note that I’m hiding something here. Unbiasedness is a desirable "
"characteristic for an estimator, but there are other things that matter "
"besides bias. However, it’s beyond the scope of this book to discuss this in "
"any detail. I just want to draw your attention to the fact that there’s some "
"hidden complexity here."
msgstr ""
"Слід зазначити, що я тут щось приховую. Неупередженість є бажаною "
"характеристикою для оцінювача, але крім упередженості є й інші важливі речі. "
"Однак детальне обговорення цього питання виходить за межі цієї книги. Я лише "
"хочу звернути вашу увагу на те, що тут є певна прихована складність."

#: ../../Ch08/Ch08_Estimation_4.rst:321
msgid ""
"Okay, I’m hiding something else here. In a bizarre and counter-intuitive "
"twist, since :math:`\\hat\\sigma^2` is an unbiased estimator of σ², you’d "
"assume that taking the square root would be fine and :math:`\\hat\\sigma` "
"would be an unbiased estimator of σ. Right? Weirdly, it’s not. There’s "
"actually a subtle, tiny bias in :math:`\\hat\\sigma`. This is just bizarre: :"
"math:`\\hat\\sigma^2` is an unbiased estimate of the population variance σ², "
"but when you take the square root, it turns out that :math:`\\hat\\sigma` is "
"a biased estimator of the population standard deviation σ. Weird, weird, "
"weird, right? So, why is :math:`\\hat\\sigma` biased? The technical answer "
"is “because non-linear transformations (e.g., the square root) don’t commute "
"with expectation”, but that just sounds like gibberish to everyone who "
"hasn’t taken a course in mathematical statistics. Fortunately, it doesn’t "
"matter for practical purposes. The bias is small, and in real life everyone "
"uses :math:`\\hat\\sigma` and it works just fine. Sometimes mathematics is "
"just annoying."
msgstr ""
"Гаразд, я приховую тут ще щось. У дивному і неінтуїтивному повороті, "
"оскільки :math:`\\hat\\sigma^2` є необ'єктивним оцінювачем σ², можна було б "
"припустити, що взяти квадратний корінь буде цілком прийнятно і :math:`\\hat"
"\\sigma` буде необ'єктивним оцінювачем σ. Правильно? Дивно, але це не так. "
"Насправді в :math:`\\hat\\sigma` є невелике, ледь помітне зміщення. Це "
"просто дивно: :math:`\\hat\\sigma^2` є необ'єктивною оцінкою дисперсії "
"сукупності σ², але коли ви берете квадратний корінь, виявляється, що :math:`"
"\\hat\\sigma` є зміщеною оцінкою стандартного відхилення сукупності σ. "
"Дивно, дивно, дивно, правда? То чому ж :math:`\\hat\\sigma` є зміщеним? "
"Технічна відповідь — «тому що нелінійні перетворення (наприклад, квадратний "
"корінь) не комутують з очікуванням», але для тих, хто не вивчав математичну "
"статистику, це звучить як нісенітниця. На щастя, для практичних цілей це не "
"має значення. Похибка невелика, і в реальному житті всі використовують "
":math:`\\hat\\sigma`, і це працює чудово. Іноді математика просто дратує."

#: ../../Ch08/Ch08_Estimation_5.rst:4
msgid "Estimating a confidence interval"
msgstr "Оцінка довірчого інтервалу"

#: ../../Ch08/Ch08_Estimation_5.rst:0
msgid "*Statistics means never having to say you’re certain*"
msgstr "*Статистика означає, що ніколи не потрібно казати, що ти впевнений*"

#: ../../Ch08/Ch08_Estimation_5.rst:10
msgid "Unknown origin\\ [#]_"
msgstr "Невідоме походження\\ [#]_"

#: ../../Ch08/Ch08_Estimation_5.rst:12
msgid ""
"Up to this point in this chapter, I’ve outlined the basics of sampling "
"theory which statisticians rely on to make guesses about population "
"parameters on the basis of a sample of data. As this discussion illustrates, "
"one of the reasons we need all this sampling theory is that every data set "
"leaves us with a some of uncertainty, so our estimates are never going to be "
"perfectly accurate. The thing that has been missing from this discussion is "
"an attempt to *quantify* the amount of uncertainty that attaches to our "
"estimate. It’s not enough to be able guess that, say, the mean IQ of "
"undergraduate psychology students is 115 (yes, I just made that number up). "
"We also want to be able to say something that expresses the degree of "
"certainty that we have in our guess. For example, it would be nice to be "
"able to say that there is a 95\\% chance that the true mean lies between 109 "
"and 121. The name for this is a **confidence interval** for the mean."
msgstr ""
"До цього моменту в цьому розділі я виклав основи теорії вибірки, на яку "
"спираються статистики, щоб робити припущення про параметри популяції на "
"основі вибірки даних. Як показує ця дискусія, одна з причин, чому нам "
"потрібна вся ця теорія вибірки, полягає в тому, що кожен набір даних залишає "
"нас з певною часткою невизначеності, тому наші оцінки ніколи не будуть "
"абсолютно точними. У цій дискусії бракує спроби *кількісно оцінити* ступінь "
"невизначеності, пов'язаної з нашою оцінкою. Недостатньо просто припустити, "
"що, скажімо, середній IQ студентів-психологів становить 115 (так, я щойно "
"вигадав це число). Ми також хочемо мати можливість висловити ступінь "
"впевненості в нашому припущенні. Наприклад, було б добре мати можливість "
"сказати, що ймовірність того, що справжнє середнє значення лежить в "
"діапазоні від 109 до 121, становить 95 %. Це називається **довірчим "
"інтервалом** для середнього значення."

#: ../../Ch08/Ch08_Estimation_5.rst:26
msgid ""
"Armed with an understanding of sampling distributions, constructing a "
"confidence interval for the mean is actually pretty easy. Here’s how it "
"works. Suppose the true population mean is µ and the standard deviation is "
"σ. I’ve just finished running my study that has *N* participants, and the "
"mean IQ among those participants is *X̄*. We know from our discussion of :ref:"
"`the central limit theorem <central_limit_theorem>` that the sampling "
"distribution of the mean is approximately normal. We also know from our "
"discussion of the :doc:`normal distribution <../Ch07/Ch07_Probability_5>`, "
"that there is a 95\\% chance that a normally-distributed quantity will fall "
"within about two standard deviations of the true mean."
msgstr ""
"Озброївшись розумінням вибіркових розподілів, побудувати довірчий інтервал "
"для середнього значення насправді досить просто. Ось як це працює. "
"Припустимо, що справжнє середнє значення популяції дорівнює µ, а стандартне "
"відхилення — σ. Я щойно завершив дослідження, в якому взяли участь *N* "
"учасників, і середній IQ серед цих учасників дорівнює *X̄*. З нашого "
"обговорення :ref:`the central limit theorem <central_limit_theorem>` ми "
"знаємо, що вибірковий розподіл середнього значення є приблизно нормальним. З "
"нашого обговорення :doc:`normal distribution <../Ch07/Ch07_Probability_5>` "
"ми також знаємо, що існує 95\\% ймовірність того, що нормально розподілена "
"величина буде знаходитися в межах приблизно двох стандартних відхилень від "
"істинного середнього значення."

#: ../../Ch08/Ch08_Estimation_5.rst:37
msgid ""
"To be more precise, the more correct answer is that there is a 95\\% chance "
"that a normally-distributed quantity will fall within 1.96 standard "
"deviations of the true mean. Next, recall that the standard deviation of the "
"sampling distribution is referred to as the standard error, and the standard "
"error of the mean is written as SEM. When we put all these pieces together, "
"we learn that there is a 95\\% probability that the sample mean *X̄* that we "
"have actually observed lies within 1.96 standard errors of the population "
"mean."
msgstr ""
"Точніше кажучи, більш правильною відповіддю є те, що існує 95\\% ймовірність "
"того, що нормально розподілена величина буде знаходитися в межах 1,96 "
"стандартних відхилень від справжнього середнього значення. Далі згадаймо, що "
"стандартне відхилення вибіркового розподілу називається стандартною "
"похибкою, а стандартна похибка середнього записується як SEM. Якщо поєднати "
"всі ці елементи, ми дізнаємося, що існує 95\\% ймовірність того, що середнє "
"значення вибірки *X̄*, яке ми фактично спостерігали, знаходиться в межах 1,96 "
"стандартних похибок середнього значення генеральної сукупності."

#: ../../Ch08/Ch08_Estimation_5.rst:45
msgid "Mathematically, we write this as:"
msgstr "Математично ми записуємо це так:"

#: ../../Ch08/Ch08_Estimation_5.rst:47
msgid "µ – 1.96 × SEM ≤ *X̄* ≤ µ + (1.96 × SEM)"
msgstr "µ – 1.96 × SEM ≤ *X̄* ≤ µ + (1.96 × SEM)"

#: ../../Ch08/Ch08_Estimation_5.rst:49
msgid ""
"where the SEM is equal to :math:`\\sigma / \\sqrt{N}` and we can be 95\\% "
"confident that this is true. However, that’s not answering the question that "
"we’re actually interested in. The equation above tells us what we should "
"expect about the sample mean given that we know what the population "
"parameters are. What we *want* is to have this work the other way around. We "
"want to know what we should believe about the population parameters, given "
"that we have observed a particular sample. However, it’s not too difficult "
"to do this. Using a little high school algebra, a sneaky way to rewrite our "
"equation is like this:"
msgstr ""
"де SEM дорівнює :math:`\\sigma / \\sqrt{N}` і ми можемо бути впевнені на 95\\"
"% що це правда. Однак це не відповідає на питання, яке нас насправді "
"цікавить. Вищезазначене рівняння показує нам, чого ми повинні очікувати від "
"середнього значення вибірки, якщо ми знаємо параметри генеральної "
"сукупності. Ми *хочемо*, щоб це працювало навпаки. Ми хочемо знати, що ми "
"повинні вважати про параметри генеральної сукупності, враховуючи, що ми "
"спостерігали конкретну вибірку. Однак це не дуже складно зробити. "
"Використовуючи трохи алгебри з середньої школи, можна хитро переписати наше "
"рівняння таким чином:"

#: ../../Ch08/Ch08_Estimation_5.rst:58
msgid "*X̄* − (1.96 × SEM) ≤ µ ≤ *X̄* + (1.96 × SEM)"
msgstr "*X̄* − (1.96 × SEM) ≤ µ ≤ *X̄* + (1.96 × SEM)"

#: ../../Ch08/Ch08_Estimation_5.rst:60
msgid ""
"What this is telling is is that the range of values has a 95\\% probability "
"of containing the population mean µ. We refer to this range as a **95\\% "
"confidence interval**, denoted *CI*\\ :sub:`95`\\ . In short, as long as *N* "
"is sufficiently large (large enough for us to believe that the sampling "
"distribution of the mean is normal), then we can write this as our formula "
"for the 95\\% confidence interval:"
msgstr ""
"Це означає, що діапазон значень має 95\\% ймовірність містити середнє "
"значення популяції µ. Ми називаємо цей діапазон **95\\% довірчим інтервалом**"
", що позначається *CI*\\ :sub:`95`\\ . Коротко кажучи, якщо *N* є достатньо "
"великим (достатньо великим, щоб ми могли вважати, що вибірковий розподіл "
"середнього значення є нормальним), то ми можемо записати це як формулу для "
"95\\% довірчого інтервалу:"

#: ../../Ch08/Ch08_Estimation_5.rst:67
msgid ""
"\\mbox{CI}_{95} = \\bar{X} \\pm \\left( 1.96 \\times \\frac{\\sigma}"
"{\\sqrt{N}} \\right)\n"
"\n"
msgstr ""
"\\mbox{CI}_{95} = \\bar{X} \\pm \\left( 1.96 \\times \\frac{\\sigma}{\\sqrt"
"{N}} \\right)\n"
"\n"

#: ../../Ch08/Ch08_Estimation_5.rst:69
msgid ""
"Of course, there’s nothing special about the number 1.96. It just happens to "
"be the multiplier you need to use if you want a 95\\% confidence interval. "
"If I’d wanted a 70\\% confidence interval, I would have used 1.04 as the "
"magic number rather than 1.96."
msgstr ""
"Звичайно, в числі 1,96 немає нічого особливого. Просто це множник, який "
"потрібно використовувати, якщо ви хочете отримати 95% довірчий інтервал. "
"Якби я хотів отримати 70% довірчий інтервал, я б використовував 1,04 як "
"магічне число, а не 1,96."

#: ../../Ch08/Ch08_Estimation_5.rst:75
msgid "A slight mistake in the formula"
msgstr "Невелика помилка у формулі"

#: ../../Ch08/Ch08_Estimation_5.rst:77
msgid ""
"As usual, I lied. The formula that I’ve given above for the 95\\% confidence "
"interval is approximately correct, but I glossed over an important detail in "
"the discussion. Notice my formula requires you to use the standard error of "
"the mean, *SEM*, which in turn requires you to use the true population "
"standard deviation σ. Yet, in :doc:`Ch08_Estimation_4` I stressed the fact "
"that we don’t actually *know* the true population parameters. Because we "
"don’t know the true value of σ we have to use an estimate of the population "
"standard deviation :math:`\\hat{\\sigma}` instead. This is pretty "
"straightforward to do, but this has the consequence that we need to use the "
"percentiles of the *t*-distribution rather than the normal distribution to "
"calculate our magic number, and the answer depends on the sample size. When "
"*N* is very large, we get pretty much the same value using the *t*-"
"distribution or the normal distribution: 1.96. But when *N* is small we get "
"a much bigger number when we use the *t*-distribution: 2.26."
msgstr ""
"Як завжди, я збрехав. Формула, яку я надав вище для 95\\% довірчого "
"інтервалу, є приблизно правильною, але я пропустив важливу деталь в "
"обговоренні. Зверніть увагу, що моя формула вимагає використання стандартної "
"похибки середнього значення, *SEM*, що, в свою чергу, вимагає використання "
"справжнього стандартного відхилення сукупності σ. Однак у "
":doc:`Ch08_Estimation_4` я наголосив на тому, що ми насправді не *знаємо* "
"справжніх параметрів сукупності. Оскільки ми не знаємо справжнього значення "
"σ, ми мусимо замість цього використовувати оцінку стандартного відхилення "
"генеральної сукупності :math:`\\hat{\\sigma}`. Це зробити досить просто, але "
"це має наслідком те, що для обчислення нашого магічного числа нам потрібно "
"використовувати процентилі *t*-розподілу, а не нормального розподілу, і "
"відповідь залежить від розміру вибірки. Коли *N* дуже велике, ми отримуємо "
"майже однакове значення, використовуючи *t*-розподіл або нормальний розподіл:"
" 1,96. Але коли *N* невелике, ми отримуємо набагато більше число, "
"використовуючи *t*-розподіл: 2,26."

#: ../../Ch08/Ch08_Estimation_5.rst:92
msgid ""
"There’s nothing too mysterious about what’s happening here. Bigger values "
"mean that the confidence interval is wider, indicating that we’re more "
"uncertain about what the true value of µ actually is. When we use the *t*-"
"distribution instead of the normal distribution we get bigger numbers, "
"indicating that we have more uncertainty. And why do we have that extra "
"uncertainty? Well, because our estimate of the population standard "
"deviation :math:`\\hat\\sigma` might be wrong! If it’s wrong, it implies "
"that we’re a bit less sure about what our sampling distribution of the mean "
"actually looks like, and this uncertainty ends up getting reflected in a "
"wider confidence interval."
msgstr ""
"У тому, що тут відбувається, немає нічого надто загадкового. Більші значення "
"означають, що довірчий інтервал ширший, що вказує на те, що ми менш впевнені "
"в тому, яким насправді є справжнє значення µ. Коли ми використовуємо *t*-"
"розподіл замість нормального розподілу, ми отримуємо більші числа, що вказує "
"на більшу невизначеність. А чому ми маємо цю додаткову невизначеність? Тому "
"що наша оцінка стандартного відхилення генеральної сукупності :math:`\\hat"
"\\sigma` може бути неправильною! Якщо вона неправильна, це означає, що ми "
"трохи менш впевнені в тому, як насправді виглядає розподіл вибірки "
"середнього значення, і ця невизначеність в кінцевому підсумку відображається "
"в ширшому довірчому інтервалі."

#: ../../Ch08/Ch08_Estimation_5.rst:103
msgid "Interpreting a confidence interval"
msgstr "Інтерпретація довірчого інтервалу"

#: ../../Ch08/Ch08_Estimation_5.rst:105
msgid ""
"The hardest thing about confidence intervals is understanding what they "
"*mean*. Whenever people first encounter confidence intervals, the first "
"instinct is almost always to say that “there is a 95\\% probability that the "
"true mean lies inside the confidence interval”. It’s simple and it seems to "
"capture the common sense idea of what it means to say that I am “95\\% "
"confident”. Unfortunately, it’s not quite right. The intuitive definition "
"relies very heavily on your own personal *beliefs* about the value of the "
"population mean. I say that I am 95\\% confident because those are my "
"beliefs. In everyday life that’s perfectly okay, but if you remember back "
"to :doc:`../Ch07/Ch07_Probability_2`, you’ll notice that talking about "
"personal belief and confidence is a Bayesian idea. However, confidence "
"intervals are *not* Bayesian tools. Like everything else in this chapter, "
"confidence intervals are *frequentist* tools, and if you are going to use "
"frequentist methods then it’s not appropriate to attach a Bayesian "
"interpretation to them. If you use frequentist methods, you must adopt "
"frequentist interpretations!"
msgstr ""
"Найскладніше в довірчих інтервалах — це зрозуміти, що вони *означають*. Коли "
"люди вперше стикаються з довірчими інтервалами, їх першою реакцією майже "
"завжди є твердження, що «існує 95 % ймовірність того, що справжнє середнє "
"значення лежить у межах довірчого інтервалу». Це просто і, здається, "
"відображає загальне уявлення про те, що означає «я впевнений на 95 %». На "
"жаль, це не зовсім правильно. Інтуїтивне визначення дуже сильно залежить від "
"ваших особистих *переконань* щодо значення середнього значення генеральної "
"сукупності. Я кажу, що я впевнений на 95 %, тому що це мої переконання. У "
"повсякденному житті це цілком нормально, але якщо ви згадаєте :doc:`../Ch07/"
"Ch07_Probability_2`, то помітите, що розмова про особисті переконання та "
"впевненість є байєсівською ідеєю. Однак довірчі інтервали *не* є "
"байєсівськими інструментами. Як і все інше в цьому розділі, довірчі "
"інтервали є *фреквентистськими* інструментами, і якщо ви збираєтеся "
"використовувати фреквентистські методи, то не варто надавати їм "
"байєсівського тлумачення. Якщо ви використовуєте фреквентистські методи, ви "
"повинні застосовувати фреквентистські тлумачення!"

#: ../../Ch08/Ch08_Estimation_5.rst:121
msgid ""
"Okay, so if that’s not the right answer, what is? Remember what we said "
"about frequentist probability. The only way we are allowed to make "
"“probability statements” is to talk about a sequence of events, and to count "
"up the frequencies of different kinds of events. From that perspective, the "
"nterpretation of a 95\\% confidence interval must have something to do with "
"replication. Specifically, if we replicated the experiment over and over "
"again and computed a 95\\% confidence interval for each replication, then "
"95\\% of those *intervals* would contain the true mean. More generally, 95\\"
"% of all confidence intervals constructed using this procedure should "
"contain the true population mean. This idea is illustrated in :numref:`fig-"
"confIntSmp`, which shows 50 confidence intervals constructed for a “measure "
"10 IQ scores” experiment (top panel) and another 50 confidence intervals for "
"a “measure 25 IQ scores” experiment (bottom panel). A bit fortuitously, "
"across the 100 replications that I simulated, it turned out that exactly 95 "
"of them contained the true mean."
msgstr ""
"Гаразд, якщо це не правильна відповідь, то яка ж правильна? Згадайте, що ми "
"говорили про частотну ймовірність. Єдиний спосіб, яким ми можемо робити «"
"ймовірнісні твердження», — це говорити про послідовність подій і "
"підраховувати частоту різних видів подій. З цієї точки зору, інтерпретація "
"95\\% довірчого інтервалу повинна мати щось спільне з повторенням. Зокрема, "
"якщо ми повторювали експеримент знову і знову та обчислювали 95\\% довірчий "
"інтервал для кожного повторення, то 95\\% цих *інтервалів* містили б "
"справжнє середнє значення. Більш загально, 95 % усіх довірчих інтервалів, "
"побудованих за допомогою цієї процедури, повинні містити справжнє середнє "
"значення популяції. Ця ідея проілюстрована в :numref:`fig-confIntSmp`, де "
"показано 50 довірчих інтервалів, побудованих для експерименту «вимірювання "
"10 балів IQ» (верхня панель), та ще 50 довірчих інтервалів для експерименту «"
"вимірювання 25 балів IQ» (нижня панель). Трохи випадково, серед 100 "
"повторень, які я моделював, виявилося, що саме 95 з них містили справжнє "
"середнє значення."

#: ../../Ch08/Ch08_Estimation_5.rst:138
msgid "Confidence intervals for IQ-samples with N=10 (top) and N=25 (bottom)"
msgstr "Довірчі інтервали для IQ-вибірок з N=10 (зверху) та N=25 (знизу)"

#: ../../Ch08/Ch08_Estimation_5.rst:142
msgid ""
"95\\% confidence intervals. The top panel shows 50 simulated replications of "
"an experiment in which we measure the IQs of 10 people. The dot marks the "
"location of the sample mean and the line shows the 95\\% confidence "
"interval. In total 47 of the 50 confidence intervals do contain the true "
"mean (i.e., 100), but the three intervals marked with asterisks do not. The "
"bottom panel shows a similar simulation, but this time, we simulate "
"replications of an experiment that measures the IQs of 25 people."
msgstr ""
"95\\% довірчі інтервали. Верхня панель показує 50 модельованих повторень "
"експерименту, в якому ми вимірюємо IQ 10 осіб. Крапка позначає місце "
"розташування середнього значення вибірки, а лінія показує 95\\% довірчий "
"інтервал. Всього 47 з 50 довірчих інтервалів містять справжнє середнє "
"значення (тобто 100), але три інтервали, позначені зірочками, не містять "
"його. Нижня панель показує подібну симуляцію, але цього разу ми симулюємо "
"повторення експерименту, в якому вимірюється IQ 25 осіб."

#: ../../Ch08/Ch08_Estimation_5.rst:152
msgid ""
"The critical difference here is that the Bayesian claim makes a probability "
"statement about the population mean (i.e., it refers to our uncertainty "
"about the population mean), which is not allowed under the frequentist "
"interpretation of probability because you can’t “replicate” a population! In "
"the frequentist claim, the population mean is fixed and no probabilistic "
"claims can be made about it. Confidence intervals, however, are repeatable "
"so we can replicate experiments. Therefore a frequentist is allowed to talk "
"about the probability that the *confidence interval* (a random variable) "
"contains the true mean, but is not allowed to talk about the probability "
"that the *true population mean* (not a repeatable event) falls within the "
"confidence interval."
msgstr ""
"Критична різниця тут полягає в тому, що байєсівське твердження робить "
"ймовірнісне твердження про середнє значення популяції (тобто воно стосується "
"нашої невизначеності щодо середнього значення популяції), що не допускається "
"за частотною інтерпретацією ймовірності, оскільки популяцію неможливо "
"«відтворити»! У частотній гіпотезі середнє значення популяції є фіксованим, "
"і про нього не можна робити жодних ймовірнісних тверджень. Однак довірчі "
"інтервали є повторюваними, тому ми можемо відтворювати експерименти. Отже, "
"частотник може говорити про ймовірність того, що *довірчий інтервал* ("
"випадкова змінна) містить справжнє середнє значення, але не може говорити "
"про ймовірність того, що *справжнє середнє значення популяції* ("
"неповторювана подія) потрапляє в довірчий інтервал."

#: ../../Ch08/Ch08_Estimation_5.rst:163
msgid ""
"I know that this seems a little pedantic, but it does matter. It matters "
"because the difference in interpretation leads to a difference in the "
"mathematics. There is a Bayesian alternative to confidence intervals, known "
"as *credible intervals*. In most situations credible intervals are quite "
"similar to confidence intervals, but in other cases they are drastically "
"different. As promised, though, I’ll talk more about the Bayesian "
"perspective in chapter :doc:`../Ch16/Ch16_Bayes`."
msgstr ""
"Я знаю, що це здається трохи педантичним, але це має значення. Це має "
"значення, тому що різниця в інтерпретації призводить до різниці в "
"математиці. Існує байєсівська альтернатива довірчим інтервалам, відома як *"
"достовірні інтервали*. У більшості випадків достовірні інтервали досить "
"схожі на довірчі інтервали, але в інших випадках вони кардинально "
"відрізняються. Як і обіцяв, я розповім більше про байєсівську перспективу в "
"розділі :doc:`../Ch16/Ch16_Bayes`."

#: ../../Ch08/Ch08_Estimation_5.rst:172
msgid "Calculating confidence intervals in jamovi"
msgstr "Обчислення довірчих інтервалів у jamovi"

#: ../../Ch08/Ch08_Estimation_5.rst:174
msgid ""
"jamovi provides a simple way to calculate confidence intervals for the mean "
"as part of the functionality of ``Descriptives``. Just set the check box "
"``Confidence interval for Mean``."
msgstr ""
"jamovi надає простий спосіб обчислення довірчих інтервалів для середнього "
"значення як частину функціональності ``Descriptives``. Просто встановіть "
"прапорець ``Confidence interval for Mean``."

#: ../../Ch08/Ch08_Estimation_5.rst:178
msgid ""
"95\\% confidence intervals are the de facto standard in psychology. So, for "
"example, if I load the |IQsim|_ data set (our simulated large sample data "
"with N=10,000), and check ``Confidence interval for Mean`` under "
"``Descriptives``, we obtain a mean IQ score of 99.683 with a 95\\% CI from "
"99.391 to 99.975."
msgstr ""
"95\\% довірчі інтервали є фактичним стандартом у психології. Так, наприклад, "
"якщо я завантажу набір даних |IQsim|_ (наші модельовані дані великої вибірки "
"з N=10 000) і перевірю ``Confidence interval for Mean`` в розділі "
"``Descriptives``, ми отримаємо середній бал IQ 99,683 з 95\\% ДІ від 99,391 "
"до 99,975."

#: ../../Ch08/Ch08_Estimation_5.rst:183
msgid ""
"When it comes to plotting confidence intervals for the mean in jamovi, this "
"is not (yet) available as part of the ``Descriptives`` options. However, "
"when we get onto learning about specific statistical tests, for example in "
"chapter :doc:`../Ch13/Ch13_ANOVA`, we will see that we can plot confidence "
"intervals as part of the data analysis. That’s pretty cool, so we’ll show "
"you how to do that later on."
msgstr ""
"Що стосується побудови довірчих інтервалів для середнього значення в jamovi, "
"то ця функція (поки що) не доступна в опціях ``Descriptives``. Однак, коли "
"ми перейдемо до вивчення конкретних статистичних тестів, наприклад, у "
"розділі :doc:`../Ch13/Ch13_ANOVA`, ми побачимо, що можна побудувати довірчі "
"інтервали в рамках аналізу даних. Це дуже цікаво, тому ми покажемо вам, як "
"це зробити, трохи пізніше."

#: ../../Ch08/Ch08_Estimation_5.rst:193
msgid ""
"This quote appears on a great many t-shirts and websites, and even gets a "
"mention in a few academic papers (e.g., https://doi."
"org/10.1080/10691898.2002.11910681), but I’ve never found the original "
"source."
msgstr ""
"Ця цитата з'являється на багатьох футболках та вебсайтах, і навіть "
"згадується в кількох академічних статтях (наприклад, https://doi.org/10.1080/"
"10691898.2002.11910681), але я так і не знайшов першоджерела."

#: ../../Ch08/Ch08_Estimation_6.rst:4
msgid "Summary"
msgstr "Короткий зміст"

#: ../../Ch08/Ch08_Estimation_6.rst:6
msgid ""
"In this chapter I’ve covered two main topics. The first half of the chapter "
"talks about sampling theory, and the second half talks about how we can use "
"sampling theory to construct estimates of the population parameters. The "
"section breakdown looks like this:"
msgstr ""
"У цьому розділі я розглянув дві основні теми. У першій половині розділу "
"йдеться про теорію вибірки, а в другій половині — про те, як ми можемо "
"використовувати теорію вибірки для побудови оцінок параметрів сукупності. "
"Розподіл розділів виглядає так:"

#: ../../Ch08/Ch08_Estimation_6.rst:11
msgid ""
":doc:`Basic ideas about samples, sampling and populations "
"<Ch08_Estimation_1>`"
msgstr ""
":doc:`Basic ideas about samples, sampling and populations "
"<Ch08_Estimation_1>`"

#: ../../Ch08/Ch08_Estimation_6.rst:14
msgid ""
":doc:`Statistical theory of sampling: the law of large numbers "
"<Ch08_Estimation_2>`"
msgstr ""
":doc:`Statistical theory of sampling: the law of large numbers "
"<Ch08_Estimation_2>`"

#: ../../Ch08/Ch08_Estimation_6.rst:17
msgid ":doc:`Ch08_Estimation_3`"
msgstr ":doc:`Ch08_Estimation_3`"

#: ../../Ch08/Ch08_Estimation_6.rst:19
msgid ":doc:`Ch08_Estimation_4`"
msgstr ":doc:`Ch08_Estimation_4`"

#: ../../Ch08/Ch08_Estimation_6.rst:21
msgid ":doc:`Ch08_Estimation_5`"
msgstr ":doc:`Ch08_Estimation_5`"

#: ../../Ch08/Ch08_Estimation_6.rst:23
msgid ""
"As always, there’s a lot of topics related to sampling and estimation that "
"aren’t covered in this chapter, but for an introductory psychology class "
"this is fairly comprehensive I think. For most applied researchers you won’t "
"need much more theory than this. One big question that I haven’t touched on "
"in this chapter is what you do when you don’t have a simple random sample. "
"There is a lot of statistical theory you can draw on to handle this "
"situation, but it’s well beyond the scope of this book."
msgstr ""
"Як завжди, є багато тем, пов'язаних з вибіркою та оцінкою, які не висвітлені "
"в цьому розділі, але для вступного курсу з психології, на мою думку, це "
"досить вичерпно. Більшості прикладних дослідників не знадобиться більше "
"теорії, ніж ця. Одне велике питання, якого я не торкався в цьому розділі, — "
"що робити, коли у вас немає простої випадкової вибірки. Існує багато "
"статистичних теорій, на які можна спиратися в такій ситуації, але це "
"виходить далеко за межі цієї книги."
