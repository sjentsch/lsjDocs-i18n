msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-06-12 11:37+0200\n"
"PO-Revision-Date: 2025-09-02 21:01+0000\n"
"Last-Translator: Максим Горпиніч <gorpinicmaksim0@gmail.com>\n"
"Language-Team: Ukrainian <https://hosted.weblate.org/projects/lsjdocs/ch11/"
"uk/>\n"
"Language: uk\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && "
"n%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2);\n"
"X-Generator: Weblate 5.13.1-dev\n"
"Generated-By: Babel 2.17.0\n"

#: ../../Ch11/Ch11_tTest.rst:4
msgid "Comparing two means"
msgstr "Порівняння двох засобів"

#: ../../Ch11/Ch11_tTest.rst:21
msgid ""
"In chapter :doc:`../Ch10/Ch10_ChiSquare` we covered the situation when your "
"outcome variable is nominal scale |nominal| and your predictor variable is "
"also nominal scale |nominal|. Lots of real world situations have that "
"character, and so you’ll find that χ²-tests in particular are quite widely "
"used. However, you’re much more likely to find yourself in a situation where "
"your outcome variable is interval scale or higher |continuous|, and what "
"you’re interested in is whether the average value of the outcome variable is "
"higher in one group or another. For instance, a psychologist might want to "
"know if anxiety levels are higher among parents than non-parents, or if "
"working memory capacity is reduced by listening to music (relative to not "
"listening to music). In a medical context we might want to know if a new "
"drug increases or decreases blood pressure. An agricultural scientist might "
"want to know whether adding phosphorus to Australian native plants will kill "
"them.\\ [#]_ In all these situations our outcome variable is a fairly "
"continuous |continuous|, interval or ratio scale variable, and our predictor "
"is a binary “grouping” variable |nominal|. In other words, we want to "
"compare the means of the two groups."
msgstr ""
"У розділі :doc:`../Ch10/Ch10_ChiSquare` ми розглянули ситуацію, коли ваша "
"змінна результату є номінальною шкалою |nominal|, а ваша змінна-прогнозуюча "
"також є номінальною шкалою |nominal|. Багато реальних ситуацій мають таку "
"характеристику, тому ви побачите, що тести χ² використовуються досить "
"широко. Однак набагато частіше ви можете опинитися в ситуації, коли ваша "
"змінна результату має інтервальну шкалу або вищу |неперервну|, і вас "
"цікавить, чи середнє значення змінної результату вище в одній групі, ніж в "
"іншій. Наприклад, психолог може хотіти дізнатися, чи рівень тривожності "
"вищий серед батьків, ніж серед людей, які не мають дітей, або чи слухання "
"музики знижує обсяг робочої пам'яті (порівняно з тим, коли музику не "
"слухають). У медичному контексті ми можемо хотіти дізнатися, чи новий "
"препарат підвищує чи знижує артеріальний тиск. Вчений-аграрій може хотіти "
"дізнатися, чи додавання фосфору до австралійських місцевих рослин вб'є їх. "
"[#]_ У всіх цих ситуаціях наша змінна результату є досить безперервною "
"|безперервною|, інтервальною або відносною змінною, а наш предиктор є "
"бінарною «групувальною» змінною |номінальною|. Іншими словами, ми хочемо "
"порівняти середні значення двох груп."

#: ../../Ch11/Ch11_tTest.rst:69 ../../Ch11/Ch11_tTest_03.rst:476
#: ../../Ch11/Ch11_tTest_05.rst:233 ../../Ch11/Ch11_tTest_09.rst:142
msgid "nominal"
msgstr "nominal"

#: ../../Ch11/Ch11_tTest.rst:66 ../../Ch11/Ch11_tTest_03.rst:473
#: ../../Ch11/Ch11_tTest_05.rst:230 ../../Ch11/Ch11_tTest_09.rst:139
msgid "continuous"
msgstr "continuous"

#: ../../Ch11/Ch11_tTest.rst:39
msgid ""
"The standard answer to the problem of comparing means is to use a *t*-test, "
"of which there are several varieties depending on exactly what question you "
"want to solve. As a consequence, the majority of this chapter focuses on "
"different types of *t*-test: :doc:`one sample t-tests <Ch11_tTest_02>` are "
"discussed first, followed by two different flavours of the independent "
"samples *t*-test: The :doc:`Student test <Ch11_tTest_03>` assumes that the "
"groups have the same standard deviation, the :doc:`Welch test "
"<Ch11_tTest_04>` does not. Afterwards, :doc:`paired samples t-tests "
"<Ch11_tTest_05>` are discussed. We’ll then talk about :doc:`one-sided tests "
"<Ch11_tTest_06>` and, after that, we’ll talk a bit about Cohen’s *d*, which "
"is the standard measure of :doc:`effect size <Ch11_tTest_07>` for a *t*-"
"test. The later sections of the chapter focus on the assumptions of the *t*-"
"tests, especially :doc:`normality <Ch11_tTest_08>` and possible :doc:"
"`remedies <Ch11_tTest_09>` if they are violated. However, before discussing "
"any of these useful things, we’ll start with a discussion of the *z*-test."
msgstr ""
"Стандартним рішенням проблеми порівняння середніх значень є використання *t*-"
"тесту, який має кілька різновидів залежно від того, яке саме питання ви "
"хочете вирішити. Як наслідок, більша частина цього розділу присвячена різним "
"типам *t*-тесту: спочатку розглядаються :doc:`t-тести для однієї вибірки "
"<Ch11_tTest_02>`, а потім два різновиди *t*-тесту для незалежних вибірок: "
":doc:`Тест Стьюдента <Ch11_tTest_03>` припускає, що групи мають однакове "
"стандартне відхилення, а :doc:`Тест Велча <Ch11_tTest_04>` — ні. Далі "
"обговорюються :doc:`t-тести для парних вибірок <Ch11_tTest_05>`. Потім ми "
"поговоримо про :doc:`односторонні тести <Ch11_tTest_06>`, а після цього "
"трохи поговоримо про *d* Коена, яке є стандартним показником :doc:`розміру "
"ефекту <Ch11_tTest_07>` для *t*-тесту. Останні розділи глави присвячені "
"припущенням *t*-тестів, особливо :doc:`нормальності <Ch11_tTest_08>` та "
"можливим :doc:`засобам виправлення <Ch11_tTest_09>` у разі їх порушення. "
"Однак, перш ніж обговорювати ці корисні речі, ми почнемо з обговорення "
"*z*-тесту."

#: ../../Ch11/Ch11_tTest.rst:58
msgid ""
"Informal experimentation in my garden suggests that yes, it does. Australian "
"natives are adapted to low phosphorus levels relative to everywhere else on "
"Earth, so if you’ve bought a house with a bunch of exotics and you want to "
"plant natives, keep them separate; nutrients to European plants are poison "
"to Australian ones."
msgstr ""
"Неформальні експерименти в моєму саду показують, що так, це справді так. "
"Австралійські рослини пристосовані до низького рівня фосфору порівняно з "
"іншими регіонами Землі, тому якщо ви придбали будинок з екзотичними "
"рослинами і хочете посадити місцеві, тримайте їх окремо; поживні речовини "
"для європейських рослин є отрутою для австралійських."

#: ../../Ch11/Ch11_tTest_01.rst:4
msgid "The one-sample *z*-test"
msgstr "Одновибірковий *z*-тест"

#: ../../Ch11/Ch11_tTest_01.rst:6
msgid ""
"In this section I’ll describe one of the most useless tests in all of "
"statistics: the **z-test**. Seriously – this test is almost never used in "
"real life. Its only real purpose is that, when teaching statistics, it’s a "
"very convenient stepping stone along the way towards the *t*-test, which is "
"probably the most (over)used tool in all statistics."
msgstr ""
"У цьому розділі я опишу один з найбільш марних тестів у всій статистиці: "
"**z-тест**. Серйозно – цей тест майже ніколи не використовується в реальному "
"житті. Його єдина реальна мета полягає в тому, що під час викладання "
"статистики він є дуже зручним проміжним етапом на шляху до *t*-тесту, який, "
"ймовірно, є найбільш (надмірно) використовуваним інструментом у всій "
"статистиці."

#: ../../Ch11/Ch11_tTest_01.rst:14
msgid "The inference problem that the test addresses"
msgstr "Проблема висновку, яку вирішує тест"

#: ../../Ch11/Ch11_tTest_01.rst:16
msgid ""
"To introduce the idea behind the *z*-test, let’s use a simple example. A "
"friend of mine, Dr Zeppo, grades his introductory statistics class on a "
"curve. Let’s suppose that the average grade in his class is 67.5, and the "
"standard deviation is 9.5. Of his many hundreds of students, it turns out "
"that 20 of them also take psychology classes. Out of curiosity, I find "
"myself wondering if the psychology students tend to get the same grades as "
"everyone else (i.e., the mean of 67.5) or do they tend to score higher or "
"lower? He emails me the |zeppo|_ data set, which I use to look at the "
"``grades`` of those students, in the jamovi spreadsheet view,"
msgstr ""
"Щоб пояснити суть *z*-тесту, скористаємося простим прикладом. Мій друг, "
"доктор Зеппо, оцінює своїх студентів на вступному курсі статистики за "
"кривою. Припустимо, що середній бал у його групі становить 67,5, а "
"стандартне відхилення — 9,5. З-поміж сотень його студентів 20 також "
"відвідують курси з психології. З цікавості я замислююсь, чи студенти-"
"психологи отримують такі самі оцінки, як і всі інші (тобто середнє значення "
"67,5), чи вони, як правило, отримують вищі або нижчі оцінки? Він надсилає "
"мені електронною поштою набір даних |zeppo|_, який я використовую для "
"перегляду ``оцінок`` цих студентів у таблиці jamovi."

#: ../../Ch11/Ch11_tTest_01.rst:30
msgid ""
"and then calculate the mean in ``Exploration`` → ``Descriptives``. The mean "
"value is 72.3."
msgstr ""
"а потім обчисліть середнє значення в ``Exploration`` → ``Descriptives``. "
"Середнє значення становить 72,3."

#: ../../Ch11/Ch11_tTest_01.rst:33
msgid ""
"Hmm. It *might* be that the psychology students are scoring a bit higher "
"than normal. That sample mean of *X̄* = 72.3 is a fair bit higher than the "
"hypothesised population mean of µ = 67.5 but, on the other hand, a sample "
"size of *N* = 20 isn’t all that big. Maybe it’s pure chance."
msgstr ""
"Хм. *Можливо*, студенти-психологи отримують трохи вищі бали, ніж зазвичай. "
"Середнє значення вибірки *X̄* = 72,3 є дещо вищим за гіпотетичне середнє "
"значення генеральної сукупності µ = 67,5, але, з іншого боку, розмір вибірки "
"*N* = 20 не є таким вже й великим. Можливо, це просто випадковість."

#: ../../Ch11/Ch11_tTest_01.rst:38
msgid ""
"To answer the question, it helps to be able to write down what it is that I "
"think I know. Firstly, I know that the sample mean is *X̄* = 72.3. If I’m "
"willing to assume that the psychology students have the same standard "
"deviation as the rest of the class then I can say that the population "
"standard deviation is σ = \\9.5. I’ll also assume that since Dr Zeppo is "
"grading to a curve, the psychology student grades are normally distributed."
msgstr ""
"Щоб відповісти на це питання, корисно записати те, що я, на мою думку, знаю. "
"По-перше, я знаю, що середнє значення вибірки становить *X̄* = 72,3. Якщо я "
"готовий припустити, що студенти-психологи мають таке саме стандартне "
"відхилення, як і решта класу, то я можу сказати, що стандартне відхилення "
"генеральної сукупності становить σ = \\9,5. Я також припущу, що, оскільки "
"доктор Зеппо оцінює за кривою, оцінки студентів-психологів мають нормальний "
"розподіл."

#: ../../Ch11/Ch11_tTest_01.rst:45
msgid ""
"Next, it helps to be clear about what I want to learn from the data. In this "
"case my research hypothesis relates to the *population* mean µ for the "
"psychology student grades, which is unknown. Specifically, I want to know if "
"µ = 67.5 or not. Given that this is what I know, can we devise a hypothesis "
"test to solve our problem? The data, along with the hypothesised "
"distribution from which they are thought to arise, are shown in :numref:`fig-"
"zeppo`. Not entirely obvious what the right answer is, is it? For this, we "
"are going to need some statistics."
msgstr ""
"Далі, корисно чітко усвідомити, що саме я хочу дізнатися з даних. У цьому "
"випадку моя дослідницька гіпотеза стосується *середнього* значення µ для "
"оцінок студентів-психологів, яке невідоме. Зокрема, я хочу дізнатися, чи µ = "
"67,5. З огляду на те, що це те, що я знаю, чи можемо ми розробити "
"гіпотетичний тест для вирішення нашої проблеми? Дані, а також гіпотетичний "
"розподіл, з якого, як вважається, вони походять, наведені в :numref:`fig-"
"zeppo`. Не зовсім очевидно, яка правильна відповідь, чи не так? Для цього "
"нам знадобляться деякі статистичні дані."

#: ../../Ch11/Ch11_tTest_01.rst:56
msgid "Theoretical and empirical distribution of student grades"
msgstr "Теоретичний та емпіричний розподіл оцінок студентів"

#: ../../Ch11/Ch11_tTest_01.rst:60
msgid ""
"The theoretical distribution (solid line) from which the psychology student "
"grades (bars) are supposed to have been generated."
msgstr ""
"Теоретичний розподіл (суцільна лінія), на основі якого нібито були "
"сформовані оцінки студентів-психологів (стовпчики)."

#: ../../Ch11/Ch11_tTest_01.rst:66
msgid "Constructing the hypothesis test"
msgstr "Побудова перевірки гіпотези"

#: ../../Ch11/Ch11_tTest_01.rst:68
msgid ""
"The first step in constructing a hypothesis test is to be clear about what "
"the null and alternative hypotheses are. This isn’t too hard to do. Our null "
"hypothesis, H\\ :sub:`0`, is that the true population mean µ for psychology "
"student grades is 67.5\\%, and our alternative hypothesis is that the "
"population mean *isn’t* 67.5\\%. If we write this in mathematical notation, "
"these hypotheses become:"
msgstr ""
"Першим кроком у побудові гіпотетичного тесту є чітке визначення нульової та "
"альтернативної гіпотез. Це не надто складно. Наша нульова гіпотеза, H\\ "
":sub:`0`, полягає в тому, що справжнє середнє значення µ для оцінок "
"студентів-психологів становить 67,5\\%, а наша альтернативна гіпотеза "
"полягає в тому, що середнє значення *не* становить 67,5\\%. Якщо записати це "
"в математичній нотації, ці гіпотези стануть такими:"

#: ../../Ch11/Ch11_tTest_01.rst:75
msgid "H\\ :sub:`0`: µ = 67.5"
msgstr "H\\ :sub:`0`: µ = 67.5"

#: ../../Ch11/Ch11_tTest_01.rst:76
msgid "H\\ :sub:`1`: µ ≠ 67.5"
msgstr "H\\ :sub:`1`: µ ≠ 67.5"

#: ../../Ch11/Ch11_tTest_01.rst:78
msgid ""
"though to be honest this notation doesn’t add much to our understanding of "
"the problem, it’s just a compact way of writing down what we’re trying to "
"learn from the data. The null hypotheses H\\ :sub:`0` and the alternative "
"hypothesis H\\ :sub:`1` for our test are both illustrated in :numref:`fig-"
"ztesthyp`. In addition to providing us with these hypotheses, the scenario "
"outlined above provides us with a fair amount of background knowledge that "
"might be useful. Specifically, there are two special pieces of information "
"that we can add:"
msgstr ""
"хоча, чесно кажучи, ця нотація не додає багато до нашого розуміння проблеми, "
"це просто компактний спосіб записати те, що ми намагаємося дізнатися з "
"даних. Нульові гіпотези H\\ :sub:`0` та альтернативна гіпотеза H\\ :sub:`1` "
"для нашого тесту проілюстровані на :numref:`fig-ztesthyp`. Окрім цих "
"гіпотез, описаний вище сценарій надає нам чимало корисної довідкової "
"інформації. Зокрема, ми можемо додати дві особливі відомості:"

#: ../../Ch11/Ch11_tTest_01.rst:87
msgid "The psychology grades are normally distributed."
msgstr "Оцінки з психології розподіляються за звичайним правилом."

#: ../../Ch11/Ch11_tTest_01.rst:89
msgid "The true standard deviation of these scores σ is known to be 9.5."
msgstr ""
"Відомо, що справжнє стандартне відхилення цих показників σ становить 9,5."

#: ../../Ch11/Ch11_tTest_01.rst:92
msgid ""
"For the moment, we’ll act as if these are absolutely trustworthy facts. In "
"real life, this kind of absolutely trustworthy background knowledge doesn’t "
"exist, and so if we want to rely on these facts we’ll just have make the "
"*assumption* that these things are true. However, since these assumptions "
"may or may not be warranted, we might need to check them. For now though, "
"we’ll keep things simple."
msgstr ""
"Наразі ми будемо діяти так, ніби це абсолютно достовірні факти. У реальному "
"житті такого роду абсолютно достовірних базових знань не існує, тому, якщо "
"ми хочемо покластися на ці факти, нам доведеться просто *припустити*, що "
"вони є правдивими. Однак, оскільки ці припущення можуть бути як "
"обґрунтованими, так і необґрунтованими, нам, можливо, доведеться їх "
"перевірити. Але поки що ми будемо триматися простоти."

#: ../../Ch11/Ch11_tTest_01.rst:101
msgid ""
"One-sample *z*-test: Illustration of the null and alternative hypotheses"
msgstr "Одновибірковий *z*-тест: ілюстрація нульової та альтернативної гіпотез"

#: ../../Ch11/Ch11_tTest_01.rst:105
msgid ""
"Graphical illustration of the null and alternative hypotheses assumed by the "
"one sample *z*-test (the two sided version, that is). The null and "
"alternative hypotheses both assume that the population distribution is "
"normal, and additionally assumes that the population standard deviation is "
"known (fixed at some value σ\\ :sub:`0`\\). The null hypothesis (left) is "
"that the population mean μ is equal to some specified value μ\\ :sub:`0`. "
"The alternative hypothesis is that the population mean differs from this "
"value, μ ≠ μ\\ :sub:`0`."
msgstr ""
"Графічна ілюстрація нульової та альтернативної гіпотез, прийнятих в "
"одновибірковому *z*-тесті (тобто двосторонній версії). Нульова та "
"альтернативна гіпотези припускають, що розподіл генеральної сукупності є "
"нормальним, а також припускають, що стандартне відхилення генеральної "
"сукупності є відомим (фіксованим на певному значенні σ\\ :sub:`0`\\). "
"Нульова гіпотеза (ліворуч) полягає в тому, що середнє значення генеральної "
"сукупності μ дорівнює певному заданому значенню μ\\ :sub:`0`. Альтернативна "
"гіпотеза полягає в тому, що середнє значення генеральної сукупності "
"відрізняється від цього значення, μ ≠ μ\\ :sub:`0`."

#: ../../Ch11/Ch11_tTest_01.rst:116
msgid ""
"The next step is to figure out what we would be a good choice for a "
"diagnostic test statistic, something that would help us discriminate between "
"H\\ :sub:`0` and H\\ :sub:`1`. Given that the hypotheses all refer to the "
"population mean µ, you’d feel pretty confident that the sample mean *X̄* "
"would be a pretty useful place to start. What we could do is look at the "
"difference between the sample mean *X̄* and the value that the null "
"hypothesis predicts for the population mean. In our example that would mean "
"we calculate *X̄* - 67.5. More generally, if we let µ\\ :sub:`0` refer to the "
"value that the null hypothesis claims is our population mean, then we’d want "
"to calculate"
msgstr ""
"Наступним кроком є визначення того, що буде хорошим вибором для "
"діагностичної статистики тесту, тобто того, що допоможе нам розрізнити H\\ "
":sub:`0` і H\\ :sub:`1`. З огляду на те, що всі гіпотези стосуються "
"середнього значення популяції µ, можна бути впевненим, що середнє значення "
"вибірки *X̄* буде досить корисним для початку. Ми можемо розглянути різницю "
"між середнім значенням вибірки *X̄* та значенням, яке нульова гіпотеза "
"передбачає для середнього значення генеральної сукупності. У нашому прикладі "
"це означатиме, що ми обчислимо *X̄* - 67,5. Більш загально, якщо ми дозволимо "
"µ\\ :sub:`0` посилатися на значення, яке нульова гіпотеза стверджує як "
"середнє значення генеральної сукупності, то ми хочемо обчислити"

#: ../../Ch11/Ch11_tTest_01.rst:128
msgid "*X̄* - µ\\ :sub:`0`"
msgstr "*X̄* - µ\\ :sub:`0`"

#: ../../Ch11/Ch11_tTest_01.rst:130
msgid ""
"If this quantity equals or is very close to 0, things are looking good for "
"the null hypothesis. If this quantity is a long way away from 0, then it’s "
"looking less likely that the null hypothesis is worth retaining. But how far "
"away from zero should it be for us to reject H\\ :sub:`0`?"
msgstr ""
"Якщо ця величина дорівнює або дуже близька до 0, то все виглядає добре для "
"нульової гіпотези. Якщо ця величина далека від 0, то менш імовірно, що "
"нульову гіпотезу варто зберегти. Але наскільки вона повинна бути далекою від "
"нуля, щоб ми відхилили H\\ :sub:`0`?"

#: ../../Ch11/Ch11_tTest_01.rst:136
msgid ""
"To figure that out we need to be a bit more sneaky, and we’ll need to rely "
"on those two pieces of background knowledge that I wrote down previously; "
"namely that the raw data are normally distributed and that we know the value "
"of the population standard deviation σ. If the null hypothesis is actually "
"true, and the true mean is µ\\ :sub:`0`, then these facts together mean that "
"we know the complete population distribution of the data: a normal "
"distribution with mean µ\\ :sub:`0` and standard deviation σ. Adopting the "
"notation from section :doc:`../Ch07/Ch07_Probability_5`, a statistician "
"might write this as:"
msgstr ""
"Щоб це з'ясувати, нам потрібно бути трохи більш хитрими і покластися на дві "
"факти, про які я писав раніше, а саме: що вихідні дані мають нормальний "
"розподіл і що ми знаємо значення стандартного відхилення σ генеральної "
"сукупності. Якщо нульова гіпотеза є дійсною, а справжнє середнє значення "
"дорівнює µ\\ :sub:`0`, то ці факти разом означають, що ми знаємо повний "
"розподіл даних у генеральній сукупності: нормальний розподіл із середнім "
"значенням µ\\ :sub:`0` і стандартним відхиленням σ. Використовуючи "
"позначення з розділу :doc:`../Ch07/Ch07_Probability_5`, статистик може "
"записати це так:"

#: ../../Ch11/Ch11_tTest_01.rst:145
msgid "X ~ Normal(µ\\ :sub:`0`, σ²)"
msgstr "X ~ Normal(µ\\ :sub:`0`, σ²)"

#: ../../Ch11/Ch11_tTest_01.rst:147
msgid ""
"Okay, if that’s true, then what can we say about the distribution of *X̄*? "
"Well, as we discussed earlier (see :ref:`The central limit theorem "
"<central_limit_theorem>`), the sampling distribution of the mean *X̄* is also "
"normal, and has mean µ. But the standard deviation of this sampling "
"distribution *SE(X̄)*, which is called the *standard error of the mean*, is"
msgstr ""
"Гаразд, якщо це правда, то що ми можемо сказати про розподіл *X̄*? Як ми вже "
"обговорювали раніше (див. :ref:`Центральна гранична теорема "
"<central_limit_theorem>`), вибірковий розподіл середнього значення *X̄* також "
"є нормальним і має середнє значення µ. Але стандартне відхилення цього "
"вибіркового розподілу *SE(X̄)*, яке називається *стандартною похибкою "
"середнього значення*, дорівнює"

#: ../../Ch11/Ch11_tTest_01.rst:153
msgid ""
"SE(X̄) = \\frac{\\sigma}{\\sqrt{N}}\n"
"\n"
msgstr ""
"SE(X̄) = \\frac{\\sigma}{\\sqrt{N}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_01.rst:155
msgid ""
"In other words, if the null hypothesis is true then the sampling "
"distribution of the mean can be written as follows:"
msgstr ""
"Іншими словами, якщо нульова гіпотеза істинна, то розподіл вибірки "
"середнього значення можна записати так:"

#: ../../Ch11/Ch11_tTest_01.rst:158
msgid "*X̄* ~ Normal(µ\\ :sub:`0`, *SE(X̄)*)"
msgstr "*X̄* ~ Normal(µ\\ :sub:`0`, *SE(X̄)*)"

#: ../../Ch11/Ch11_tTest_01.rst:160
msgid ""
"Now comes the trick. What we can do is convert the sample mean *X̄* into a :"
"doc:`standard score <../Ch04/Ch04_Descriptives_5>`. This is conventionally "
"written as *z*, but for now I’m going to refer to it as *z*\\ :sub:`X̄` (the "
"reason for using this expanded notation is to help you remember that we’re "
"calculating a standardised version of a sample mean, *not* a standardised "
"version of a single observation, which is what a *z*-score usually refers "
"to). When we do so the *z*-score for our sample mean is:"
msgstr ""
"Тепер настає час для хитрості. Ми можемо перетворити середнє значення "
"вибірки *X̄* на :doc:`standard score <../Ch04/Ch04_Descriptives_5>`. Зазвичай "
"це позначається як *z*, але поки що я буду називати це *z*\\ :sub:`X̄` ("
"причина використання цього розширеного позначення полягає в тому, щоб "
"допомогти вам запам'ятати, що ми обчислюємо стандартизовану версію "
"середнього значення вибірки, а *не* стандартизовану версію окремого "
"спостереження, на яке зазвичай посилається *z*-бал). Коли ми це робимо, *z*-"
"бал для середнього значення нашої вибірки дорівнює:"

#: ../../Ch11/Ch11_tTest_01.rst:168
msgid ""
"z_{\\bar{X}} = \\frac{\\bar{X} - \\mu_0}{SE(X̄)}\n"
"\n"
msgstr ""
"z_{\\bar{X}} = \\frac{\\bar{X} - \\mu_0}{SE(X̄)}\n"
"\n"

#: ../../Ch11/Ch11_tTest_01.rst:170
msgid "or, equivalently:"
msgstr "або, що еквівалентно:"

#: ../../Ch11/Ch11_tTest_01.rst:172
msgid ""
"z_{\\bar{X}} =  \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{N}}\n"
"\n"
msgstr ""
"z_{\\bar{X}} =  \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{N}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_01.rst:174
msgid ""
"This *z*-score is our test statistic. The nice thing about using this as our "
"test statistic is that like all *z*-scores, it has a standard normal "
"distribution:"
msgstr ""
"Цей *z*-оцінка є нашою тестовою статистикою. Перевага використання її як "
"тестової статистики полягає в тому, що, як і всі *z*-оцінки, вона має "
"стандартний нормальний розподіл:"

#: ../../Ch11/Ch11_tTest_01.rst:178
msgid "*z*\\ :sub:`*X̄*` ~ Normal(0, 1)"
msgstr "*z*\\ :sub:`*X̄*` ~ Normal(0, 1)"

#: ../../Ch11/Ch11_tTest_01.rst:180
msgid ""
"(again, see section :doc:`../Ch04/Ch04_Descriptives_5` if you’ve forgotten "
"why this is true). In other words, regardless of what scale the original "
"data are on, the *z*-statistic itself always has the same interpretation: "
"it’s equal to the number of standard errors that separate the observed "
"sample mean *X̄* from the population mean µ\\ :sub:`0` predicted by the null "
"hypothesis. Better yet, regardless of what the population parameters for the "
"raw scores actually are, the 5\\% critical regions for the *z*-test are "
"always the same, as illustrated in :numref:`fig-ztest`. And what this meant, "
"way back in the days where people did all their statistics by hand, is that "
"someone could publish a table like this:"
msgstr ""
"(якщо ви забули, чому це так, дивіться розділ :doc:`../Ch04/"
"Ch04_Descriptives_5`). Іншими словами, незалежно від того, в якій шкалі "
"представлені вихідні дані, сама *z*-статистика завжди має однакове "
"тлумачення: вона дорівнює кількості стандартних похибок, які відокремлюють "
"спостережуване середнє значення вибірки *X̄* від середнього значення "
"генеральної сукупності µ\\ :sub:`0`, передбаченого нульовою гіпотезою. "
"Більше того, незалежно від того, якими насправді є параметри генеральної "
"сукупності для необроблених балів, 5\\% критичні області для *z*-тесту "
"завжди однакові, як показано на :numref:`fig-ztest`. А це означало, що в ті "
"далекі часи, коли люди виконували всі статистичні обчислення вручну, хтось "
"міг опублікувати таку таблицю:"

#: ../../Ch11/Ch11_tTest_01.rst:192
msgid "desired α level"
msgstr "бажаний рівень α"

#: ../../Ch11/Ch11_tTest_01.rst:192
msgid "two-sided test"
msgstr "двосторонній тест"

#: ../../Ch11/Ch11_tTest_01.rst:192
msgid "one-sided test"
msgstr "односторонній тест"

#: ../../Ch11/Ch11_tTest_01.rst:194
msgid "0.1"
msgstr "0.1"

#: ../../Ch11/Ch11_tTest_01.rst:194 ../../Ch11/Ch11_tTest_01.rst:196
msgid "1.644854"
msgstr "1.644854"

#: ../../Ch11/Ch11_tTest_01.rst:194
msgid "1.281552"
msgstr "1.281552"

#: ../../Ch11/Ch11_tTest_01.rst:196
msgid "0.05"
msgstr "0.05"

#: ../../Ch11/Ch11_tTest_01.rst:196
msgid "1.959964"
msgstr "1.959964"

#: ../../Ch11/Ch11_tTest_01.rst:198
msgid "0.01"
msgstr "0.01"

#: ../../Ch11/Ch11_tTest_01.rst:198
msgid "2.575829"
msgstr "2.575829"

#: ../../Ch11/Ch11_tTest_01.rst:198
msgid "2.326348"
msgstr "2.326348"

#: ../../Ch11/Ch11_tTest_01.rst:200
msgid "0.001"
msgstr "0.001"

#: ../../Ch11/Ch11_tTest_01.rst:200
msgid "3.290527"
msgstr "3.290527"

#: ../../Ch11/Ch11_tTest_01.rst:200
msgid "3.090232"
msgstr "3.090232"

#: ../../Ch11/Ch11_tTest_01.rst:203
msgid ""
"This, in turn, meant that researchers could calculate their *z*-statistic by "
"hand and then look up the critical value in a text book."
msgstr ""
"Це, у свою чергу, означало, що дослідники могли розрахувати свою *z*-"
"статистику вручну, а потім знайти критичне значення в підручнику."

#: ../../Ch11/Ch11_tTest_01.rst:209
msgid "Rejection regions for the two- and one-sided *z*-tests"
msgstr "Області відхилення для дво- та одностороннього *z*-tests"

#: ../../Ch11/Ch11_tTest_01.rst:213
msgid ""
"Rejection regions for the two-sided *z*-test (left panel) and the one-sided "
"*z*-test (right panel)"
msgstr ""
"Області відхилення для двостороннього *z*-тесту (ліва панель) та "
"одностороннього *z*-тесту (права панель)"

#: ../../Ch11/Ch11_tTest_01.rst:219
msgid "A worked example, by hand"
msgstr "Зроблений вручну приклад"

#: ../../Ch11/Ch11_tTest_01.rst:221
msgid ""
"Now, as I mentioned earlier, the *z*-test is almost never used in practice. "
"It’s so rarely used in real life that the basic installation of jamovi "
"doesn’t have a built in function for it. However, the test is so incredibly "
"simple that it’s really easy to do one manually. Let’s go back to the |zeppo|"
"_ data set. The first thing I need to do is calculate the sample mean for "
"the ``grades`` variable, which I’ve already done (72.3). We already have the "
"known population standard deviation (σ = 9.5), and the value of the "
"population mean that the null hypothesis specifies (µ\\ :sub:`0` = 67.5), "
"and we know the sample size (*N* = 20)."
msgstr ""
"Як я вже згадував раніше, *z*-тест практично ніколи не використовується на "
"практиці. Він настільки рідко застосовується в реальному житті, що базова "
"версія jamovi не має вбудованої функції для його виконання. Однак цей тест "
"настільки простий, що його дуже легко виконати вручну. Повернемося до набору "
"даних |zeppo|_. Перше, що мені потрібно зробити, це обчислити середнє "
"значення вибірки для змінної ``grades``, що я вже зробив (72,3). Ми вже "
"маємо відоме стандартне відхилення генеральної сукупності (σ = 9,5) і "
"значення середнього значення генеральної сукупності, яке вказує нульова "
"гіпотеза (µ\\ :sub:`0` = 67,5), а також знаємо розмір вибірки (*N* = 20)."

#: ../../Ch11/Ch11_tTest_01.rst:231
msgid ""
"Next, let’s calculate the (true) standard error of the mean (easily done "
"with a calculator):"
msgstr ""
"Далі, давайте обчислимо (справжню) стандартну похибку середнього значення ("
"легко зробити за допомогою калькулятора):"

#: ../../Ch11/Ch11_tTest_01.rst:240
msgid "And finally, we calculate our *z*-score:"
msgstr "І нарешті, ми обчислюємо наш *z*-оцінку:"

#: ../../Ch11/Ch11_tTest_01.rst:248
msgid ""
"At this point, we would traditionally look up the value 2.26 in our table of "
"critical values. Our original hypothesis was two-sided (we didn’t really "
"have any theory about whether psych students would be better or worse at "
"statistics than other students) so our hypothesis test is two-sided (or two-"
"tailed) also. Looking at the little table that I showed earlier, we can see "
"that 2.26 is bigger than the critical value of 1.96 that would be required "
"to be significant at α = 0.05, but smaller than the value of 2.58 that would "
"be required to be significant at a level of α = 0.01. Therefore, we can "
"conclude that we have a significant effect, which we might write up by "
"saying something like this:"
msgstr ""
"На цьому етапі ми традиційно шукаємо значення 2,26 у нашій таблиці критичних "
"значень. Наша початкова гіпотеза була двосторонньою (ми не мали жодної "
"теорії щодо того, чи студенти-психологи будуть кращими чи гіршими у "
"статистиці, ніж інші студенти), тому наш тест гіпотези також є двостороннім ("
"або двоххвостим). Дивлячись на невелику таблицю, яку я показав раніше, ми "
"бачимо, що 2,26 більше за критичне значення 1,96, яке було б необхідним для "
"значущості при α = 0,05, але менше за значення 2,58, яке було б необхідним "
"для значущості при рівні α = 0,01. Отже, ми можемо зробити висновок, що "
"маємо значущий ефект, про що можна написати приблизно так:"

#: ../../Ch11/Ch11_tTest_01.rst:260
msgid ""
"With a mean grade of 72.3 in the sample of psychology students, and assuming "
"a true population standard deviation of 9.5, we can conclude that the "
"psychology students have significantly different statistics scores to the "
"class average (*z* = 2.26, *N* = 20, *p* < 0.05)."
msgstr ""
"З середнім балом 72,3 у вибірці студентів-психологів і припускаючи, що "
"справжнє стандартне відхилення популяції становить 9,5, ми можемо зробити "
"висновок, що студенти-психологи мають статистичні бали, які значно "
"відрізняються від середнього балу класу (*z* = 2,26, *N* = 20, *p* < 0,05)."

#: ../../Ch11/Ch11_tTest_01.rst:268
msgid "Assumptions of the *z*-test"
msgstr "Припущення щодо *z*-test"

#: ../../Ch11/Ch11_tTest_01.rst:270
msgid ""
"As I’ve said before, all statistical tests make assumptions. Some tests make "
"reasonable assumptions, while other tests do not. The test I’ve just "
"described, the one sample *z*-test, makes three basic assumptions. These are:"
msgstr ""
"Як я вже говорив раніше, всі статистичні тести базуються на припущеннях. "
"Деякі тести роблять обґрунтовані припущення, а інші — ні. Тест, який я щойно "
"описав, одновибірковий *z*-тест, базується на трьох основних припущеннях. Це:"

#: ../../Ch11/Ch11_tTest_01.rst:274
msgid ""
"*Normality*. As usually described, the *z*-test assumes that the true "
"population distribution is normal.\\ [#]_ This is often a pretty reasonable "
"assumption, and it’s also an assumption that we can check if we feel worried "
"about it (see section :doc:`Ch11_tTest_08`)."
msgstr ""
"*Нормальність*. Як зазвичай описується, *z*-тест припускає, що справжній "
"розподіл популяції є нормальним.\\ [#]_ Це часто є досить розумним "
"припущенням, і це також припущення, яке ми можемо перевірити, якщо нас це "
"турбує (див. розділ :doc:`Ch11_tTest_08`)."

#: ../../Ch11/Ch11_tTest_01.rst:279
msgid ""
"*Independence*. The second assumption of the test is that the observations "
"in your data set are not correlated with each other, or related to each "
"other in some funny way. This isn’t as easy to check statistically, it "
"relies a bit on good experimental design. An obvious (and stupid) example of "
"something that violates this assumption is a data set where you “copy” the "
"same observation over and over again in your data file so that you end up "
"with a massive “sample size”, which consists of only one genuine "
"observation. More realistically, you have to ask yourself if it’s really "
"plausible to imagine that each observation is a completely random sample "
"from the population that you’re interested in. In practice this assumption "
"is never met, but we try our best to design studies that minimise the "
"problems of correlated data."
msgstr ""
"*Незалежність*. Друге припущення тесту полягає в тому, що спостереження у "
"вашому наборі даних не корелюють між собою і не пов'язані між собою якимось "
"дивним чином. Це не так просто перевірити статистично, це дещо залежить від "
"хорошого експериментального дизайну. Очевидним (і безглуздим) прикладом "
"порушення цього припущення є набір даних, в якому ви «копіюєте» одне і те "
"саме спостереження знову і знову у вашому файлі даних, в результаті чого ви "
"отримуєте величезний «розмір вибірки», який складається лише з одного "
"справжнього спостереження. Більш реалістично, ви повинні запитати себе, чи "
"дійсно правдоподібно уявити, що кожне спостереження є повністю випадковою "
"вибіркою з популяції, яка вас цікавить. На практиці це припущення ніколи не "
"виконується, але ми робимо все можливе, щоб розробити дослідження, які "
"мінімізують проблеми корельованих даних."

#: ../../Ch11/Ch11_tTest_01.rst:293
msgid ""
"*Known standard deviation*. The third assumption of the *z*-test is that the "
"true standard deviation of the population is known to the researcher. This "
"is just stupid. In no real world data analysis problem do you know the "
"standard deviation σ of some population but are completely ignorant about "
"the mean µ. In other words, this assumption is *always* wrong."
msgstr ""
"*Відоме стандартне відхилення*. Третє припущення *z*-тесту полягає в тому, "
"що дослідник знає справжнє стандартне відхилення генеральної сукупності. Це "
"просто безглуздо. У жодному реальному завданні з аналізу даних ви не знаєте "
"стандартне відхилення σ якоїсь генеральної сукупності, але повністю не "
"знаєте про середнє значення µ. Іншими словами, це припущення *завжди* є "
"неправильним."

#: ../../Ch11/Ch11_tTest_01.rst:301
msgid ""
"In view of the stupidity of assuming that σ is known, let’s see if we can "
"live without it. This takes us out of the dreary domain of the *z*-test, and "
"into the magical kingdom of the *t*-test, with unicorns and fairies and "
"leprechauns!"
msgstr ""
"З огляду на безглуздість припущення, що σ є відомим, давайте подивимося, чи "
"можна обійтися без нього. Це виводить нас із похмурої області *z*-тесту і "
"переносить у чарівне королівство *t*-тесту, де живуть єдинороги, феї та "
"лепрекони!"

#: ../../Ch11/Ch11_tTest_01.rst:309
msgid ""
"Actually this is too strong. Strictly speaking requires the *z* test only "
"that the sampling distribution of the mean is normally distributed. If the "
"population is normal then it necessarily follows that the sampling "
"distribution of the mean is also normal. However, as we saw when talking "
"about the central limit theorem, it’s quite possible (even commonplace) for "
"the sampling distribution to be normal even if the population distribution "
"itself is non-normal. However, in light of the sheer ridiculousness of the "
"assumption that the true standard deviation is known, there really isn’t "
"much point in going into details on this front!"
msgstr ""
"Насправді це занадто сильне твердження. Строго кажучи, тест *z* вимагає лише "
"того, щоб вибіркова розподіл середнього значення мав нормальний розподіл. "
"Якщо генеральна сукупність є нормальною, то з цього обов'язково випливає, що "
"вибіркова розподіл середнього значення також є нормальним. Однак, як ми "
"бачили, коли говорили про центральну граничну теорему, цілком можливо ("
"навіть звичне), що вибіркова розподіл буде нормальним, навіть якщо розподіл "
"генеральної сукупності сам по собі є ненормальним. Однак, з огляду на "
"абсурдність припущення, що справжнє стандартне відхилення є відомим, немає "
"сенсу заглиблюватися в деталі цього питання!"

#: ../../Ch11/Ch11_tTest_02.rst:4
msgid "The one-sample *t*-test"
msgstr "Одновибірковий *t*-тест"

#: ../../Ch11/Ch11_tTest_02.rst:6
msgid ""
"After some thought, I decided that it might not be safe to assume that the "
"psychology student grades necessarily have the same standard deviation as "
"the other students in Dr Zeppo’s class. After all, if I’m entertaining the "
"hypothesis that they don’t have the same mean, then why should I believe "
"that they absolutely have the same standard deviation? In view of this, I "
"should really stop assuming that I know the true value of σ. This violates "
"the assumptions of my *z*-test, so in one sense I’m back to square one. "
"However, it’s not like I’m completely bereft of options. After all, I’ve "
"still got my raw data, and those raw data give me an *estimate* of the "
"population standard deviation, which is 9.52. In other words, while I can’t "
"say that I know that σ = 9.5, I *can* say that :math:`\\hat\\sigma` = 9.52."
msgstr ""
"Подумавши, я вирішив, що не можна з упевненістю стверджувати, що оцінки "
"студентів-психологів обов'язково мають таке саме стандартне відхилення, як і "
"оцінки інших студентів у класі доктора Зеппо. Адже якщо я висуваю гіпотезу, "
"що вони не мають однакової середньої величини, то чому я повинен вірити, що "
"вони обов'язково мають однакове стандартне відхилення? З огляду на це, я "
"дійсно повинен припинити припускати, що знаю справжнє значення σ. Це порушує "
"припущення мого *z*-тесту, тому в певному сенсі я повертаюся до вихідної "
"точки. Однак це не означає, що я повністю позбавлений варіантів. Зрештою, у "
"мене все ще є мої вихідні дані, і ці вихідні дані дають мені *оцінку* "
"стандартного відхилення генеральної сукупності, яке становить 9,52. Іншими "
"словами, хоча я не можу сказати, що знаю, що σ = 9,5, я *можу* сказати, що "
":math:`\\hat\\sigma` = 9,52."

#: ../../Ch11/Ch11_tTest_02.rst:20
msgid ""
"Okay, cool. The obvious thing that you might think to do is run a *z*-test, "
"but using the estimated standard deviation of 9.52 instead of relying on my "
"assumption that the true standard deviation is 9.5. And you probably "
"wouldn’t be surprised to hear that this would still give us a significant "
"result. This approach is close, but it’s not *quite* correct. Because we are "
"now relying on an *estimate* of the population standard deviation we need to "
"make some adjustment for the fact that we have some uncertainty about what "
"the true population standard deviation actually is. Maybe our data are just "
"a fluke …maybe the true population standard deviation is 11, for instance. "
"But if that were actually true, and we ran the *z*-test assuming σ = 11, "
"then the result would end up being *non-significant*. That’s a problem, and "
"it’s one we’re going to have to address."
msgstr ""
"Добре, чудово. Очевидним рішенням може здатися проведення *z*-тесту, але з "
"використанням оціненого стандартного відхилення 9,52 замість мого "
"припущення, що справжнє стандартне відхилення становить 9,5. І вас, мабуть, "
"не здивує, що це все одно дасть нам значущий результат. Цей підхід близький "
"до правильного, але не *зовсім* правильний. Оскільки ми зараз покладаємося "
"на *оцінку* стандартного відхилення генеральної сукупності, нам потрібно "
"внести деякі корективи з огляду на те, що ми маємо певну невизначеність щодо "
"того, яким насправді є справжнє стандартне відхилення генеральної "
"сукупності. Можливо, наші дані є просто випадковістю... Можливо, справжнє "
"стандартне відхилення генеральної сукупності становить, наприклад, 11. Але "
"якщо це дійсно так, і ми проведемо *z*-тест, припускаючи, що σ = 11, то "
"результат буде *незначущим*. Це проблема, яку нам доведеться вирішити."

#: ../../Ch11/Ch11_tTest_02.rst:36
msgid ""
"Illustration: Null and alternative hypotheses by the one-sample *t*-test"
msgstr ""
"Ілюстрація: Нульова та альтернативна гіпотези за одновибірковим *t*-критерієм"

#: ../../Ch11/Ch11_tTest_02.rst:40
msgid ""
"Graphical illustration of the null and alternative hypotheses assumed by the "
"(two-sided) one-sample *t*-test. Note the similarity to the *z*-test :numref:"
"`fig-ztesthyp`. The null hypothesis is that the population mean μ is equal "
"to some specified value μ\\ :sub:`0`\\, and the alternative hypothesis is "
"that it is not. Like the *z*-test, we assume that the data are normally "
"distributed, but we do not assume that the population standard deviation σ "
"is known in advance."
msgstr ""
"Графічна ілюстрація нульової та альтернативної гіпотез, прийнятих "
"(двостороннім) одновибірковим *t*-тестом. Зверніть увагу на схожість із *z*-"
"тестом :numref:`fig-ztesthyp`. Нульова гіпотеза полягає в тому, що середнє "
"значення μ генеральної сукупності дорівнює певному значенню μ\\ :sub:`0`\\, "
"а альтернативна гіпотеза — в тому, що це не так. Як і в *z*-тесті, ми "
"припускаємо, що дані мають нормальний розподіл, але не припускаємо, що "
"стандартне відхилення σ генеральної сукупності відоме заздалегідь."

#: ../../Ch11/Ch11_tTest_02.rst:51
msgid "Introducing the *t*-test"
msgstr "Представляємо *t*-тест"

#: ../../Ch11/Ch11_tTest_02.rst:53
msgid ""
"This ambiguity is annoying, and it was resolved in 1908 by a guy called "
"William Sealy Gosset (:ref:`Student, 1908 <Student_1908>`), who was working "
"as a chemist for the Guinness brewery at the time (:ref:`Box, 1987 "
"<Box_1987>`). Because Guinness took a dim view of its employees publishing "
"statistical analysis (apparently they felt it was a trade secret), he "
"published the work under the pseudonym “A Student” and, to this day, the "
"full name of the *t*-test is actually **Student’s *t*-test**. The key thing "
"that Gosset figured out is how we should accommodate the fact that we aren’t "
"completely sure what the true standard deviation is.\\ [#]_ The answer is "
"that it subtly changes the sampling distribution. In the *t*-test our test "
"statistic, now called a *t*-statistic, is calculated in exactly the same way "
"I mentioned above. If our null hypothesis is that the true mean is µ, but "
"our sample has mean *X̄* and our estimate of the population standard "
"deviation is :math:`\\hat{\\sigma}`, then our *t*-statistic is:"
msgstr ""
"Ця неоднозначність була дратівливою, і її вирішив у 1908 році чоловік на "
"ім'я Вільям Сілі Госсет (:ref:`Student, 1908 <Student_1908>`), який на той "
"час працював хіміком на пивоварні Гіннес (:ref:`Box, 1987 <Box_1987>`). "
"Оскільки компанія Гіннес негативно ставилася до публікації статистичних "
"аналізів своїми співробітниками (очевидно, вважаючи це комерційною таємницею)"
", він опублікував свою роботу під псевдонімом «Студент», і до цього дня "
"повна назва *t*-тесту насправді є ***t*-тестом Студента**. Ключовим "
"відкриттям Госсета було те, як ми повинні враховувати той факт, що ми не "
"можемо бути повністю впевнені в тому, яким є справжнє стандартне відхилення."
"\\ [#]_ Відповідь полягає в тому, що це дещо змінює розподіл вибірки. У *t*-"
"тесті наша тестова статистика, яка тепер називається *t*-статистикою, "
"обчислюється точно так само, як я згадував вище. Якщо наша нульова гіпотеза "
"полягає в тому, що справжнє середнє значення дорівнює µ, але наше вибіркове "
"середнє значення дорівнює *X̄*, а наша оцінка стандартного відхилення "
"генеральної сукупності дорівнює :math:`\\hat{\\sigma}`, то наша *t*-"
"статистика дорівнює:"

#: ../../Ch11/Ch11_tTest_02.rst:67
msgid ""
"t = \\frac{\\bar{X} - \\mu}{\\hat{\\sigma}/\\sqrt{N} }\n"
"\n"
msgstr ""
"t = \\frac{\\bar{X} - \\mu}{\\hat{\\sigma}/\\sqrt{N} }\n"
"\n"

#: ../../Ch11/Ch11_tTest_02.rst:69
msgid ""
"The only thing that has changed in the equation is that instead of using the "
"known true value σ, we use the estimate :math:`\\hat{\\sigma}`. And if this "
"estimate has been constructed from *N* observations, then the sampling "
"distribution turns into a *t*-distribution with *N* - 1 **degrees of "
"freedom** (df). The *t*-distribution is very similar to the normal "
"distribution, but has “heavier” tails, as discussed earlier in :doc:`../Ch07/"
"Ch07_Probability_6` and illustrated in :numref:`fig-ttestdist`. Notice, "
"though, that as *df* gets larger, the *t*-distribution starts to look "
"identical to the standard normal distribution. This is as it should be: if "
"you have a sample size of *N* = 70,000,000 then your “estimate” of the "
"standard deviation would be pretty much perfect, right? So, you should "
"expect that for large *N*, the *t*-test would behave exactly the same way as "
"a *z*-test. And that’s exactly what happens!"
msgstr ""
"Єдине, що змінилося в рівнянні, це те, що замість відомого справжнього "
"значення σ ми використовуємо оцінку :math:`\\hat{\\sigma}`. І якщо ця оцінка "
"була побудована на основі *N* спостережень, то вибірковий розподіл "
"перетворюється на *t*-розподіл з *N* - 1 **ступенями свободи** (df). *t*-"
"розподіл дуже схожий на нормальний розподіл, але має «важчі» хвости, як "
"обговорювалося раніше в :doc:`../Ch07/Ch07_Probability_6` і проілюстровано в "
":numref:`fig-ttestdist`. Зверніть увагу, що з збільшенням *df* *t*-розподіл "
"починає виглядати ідентично стандартному нормальному розподілу. Це нормально:"
" якщо розмір вибірки *N* = 70 000 000, то ваша «оцінка» стандартного "
"відхилення буде практично ідеальною, чи не так? Отже, слід очікувати, що для "
"великих *N* *t*-тест буде поводитися точно так само, як *z*-тест. І саме так "
"і відбувається!"

#: ../../Ch11/Ch11_tTest_02.rst:84
msgid "*t*-distribution with *df* = 2 and *df* = 10"
msgstr "*t*-розподіл з *df* = 2 та *df* = 10"

#: ../../Ch11/Ch11_tTest_02.rst:88
msgid ""
"The *t*-distribution with 2 degrees of freedom (left panel) and 10 degrees "
"of freedom (right panel), with a standard normal distribution (i.e., mean = "
"0 and std. dev. = 1) plotted as dotted lines for comparison purposes. Notice "
"that the *t*-distribution has heavier tails (leptokurtic: higher kurtosis) "
"than the normal distribution; this effect is quite exaggerated when the "
"degrees of freedom are very small, but negligible for larger values. In "
"other words, for large *df* the *t*-distribution is essentially identical to "
"a normal distribution."
msgstr ""
"Розподіл *t* з 2 ступенями свободи (ліва панель) і 10 ступенями свободи ("
"права панель), зі стандартним нормальним розподілом (тобто середнє = 0 і "
"стандартне відхилення = 1), нанесеним у вигляді пунктирних ліній для "
"порівняння. Зверніть увагу, що *t*-розподіл має більш важкі хвости "
"(лептокуртичний: вищий кутоз) ніж нормальний розподіл; цей ефект є досить "
"перебільшеним, коли ступені свободи є дуже малими, але незначним для більших "
"значень. Іншими словами, для великих *df* *t*-розподіл є по суті ідентичним "
"нормальному розподілу."

#: ../../Ch11/Ch11_tTest_02.rst:100 ../../Ch11/Ch11_tTest_03.rst:261
#: ../../Ch11/Ch11_tTest_05.rst:166
msgid "Doing the test in jamovi"
msgstr "Проходження тесту в jamovi"

#: ../../Ch11/Ch11_tTest_02.rst:102
msgid ""
"As you might expect, the mechanics of the *t*-test are almost identical to "
"the mechanics of the *z*-test. So there’s not much point in going through "
"the tedious exercise of showing you how to do the calculations using low "
"level commands. It’s pretty much identical to the calculations that we did "
"earlier, except that we use the estimated standard deviation and then we "
"test our hypothesis using the *t*-distribution rather than the normal "
"distribution. And so instead of going through the calculations in tedious "
"detail for a second time, I’ll jump straight to showing you how *t*-tests "
"are actually done. jamovi comes with a dedicated analysis for *t*-tests that "
"is very flexible (it can run lots of different kinds of *t*-tests). It’s "
"pretty straightforward to use; all you need to do is specify ``Analyses`` → "
"``T-Tests`` → ``One Sample T-Test``, move the variable you are interested in "
"(``X``) across into the ``Variables`` box, and type in the mean value for "
"the null hypothesis (``67.5``) in the ``Hypothesis`` → ``Test value`` box. "
"Easy enough (see :numref:`fig-ttest_one`, which, amongst other things that "
"we will get to in a moment, gives you a *t*statistic = 2.25, with 19 degrees "
"of freedom and an associated *p*-value of 0.036."
msgstr ""
"Як і слід було очікувати, механіка *t*-тесту майже ідентична механіці *z*-"
"тесту. Тому немає сенсу проводити нудне заняття, показуючи вам, як "
"виконувати обчислення за допомогою команд низького рівня. Це майже ідентично "
"обчисленням, які ми робили раніше, за винятком того, що ми використовуємо "
"оцінене стандартне відхилення, а потім перевіряємо нашу гіпотезу за "
"допомогою *t*-розподілу, а не нормального розподілу. Тому замість того, щоб "
"вдруге детально описувати обчислення, я відразу перейду до того, як "
"насправді проводяться *t*-тести. jamovi має спеціальний аналіз для *t*-"
"тестів, який є дуже гнучким (він може виконувати багато різних видів "
"*t*-тестів). Він досить простий у використанні; все, що вам потрібно "
"зробити, це вказати ``Аналіз`` → ``T-тести`` → ``T-тест для однієї вибірки``"
", перемістити змінну, яка вас цікавить (``X``), у поле ``Змінні`` та ввести "
"середнє значення для нульової гіпотези (``67,5``) у полі ``Гіпотеза`` → ``"
"Значення тесту``. Досить просто (див. :numref:`fig-ttest_one`, який, серед "
"іншого, про що ми поговоримо трохи пізніше, дає вам *t*-статистику = 2,25, з "
"19 ступенями свободи та відповідним *p*-значенням 0,036."

#: ../../Ch11/Ch11_tTest_02.rst:122 ../../Ch11/Ch11_tTest_02.rst:126
msgid "Conducting an One-sample *t*-test in jamovi"
msgstr "Проведення одновибіркового *t*-тесту в jamovi"

#: ../../Ch11/Ch11_tTest_02.rst:130
msgid ""
"Also reported are two other things you might care about: the 95\\% "
"confidence interval and a measure of effect size (we’ll talk more about "
"effect sizes later). So that seems straightforward enough. Now what do we "
"*do* with this output? Well, since we’re pretending that we actually care "
"about my toy example, we’re overjoyed to discover that the result is "
"statistically significant (i.e. *p*-value below 0.05). We could report the "
"result by saying something like this:"
msgstr ""
"Також повідомляються дві інші речі, які можуть вас зацікавити: 95\\% "
"довірчий інтервал і міра розміру ефекту (про розміри ефекту ми поговоримо "
"пізніше). Тож це здається досить простим. Що ж тепер *робити* з цими "
"результатами? Оскільки ми робимо вигляд, що нас дійсно цікавить мій "
"іграшковий приклад, ми радісно виявляємо, що результат є статистично "
"значущим (тобто *p*-значення нижче 0,05). Ми могли б повідомити про "
"результат, сказавши щось на кшталт:"

#: ../../Ch11/Ch11_tTest_02.rst:138
msgid ""
"With a mean grade of 72.3, the psychology students scored slightly higher "
"than the average grade of 67.5 (*t*\\(19) = 2.25, *p* < 0.05); the mean "
"difference was 4.80 and the 95\\% confidence interval was from 0.34 to 9.26."
msgstr ""
"З середнім балом 72,3 студенти-психологи отримали трохи вищий результат, ніж "
"середній бал 67,5 (*t*\\(19) = 2,25, *p* < 0,05); середня різниця становила "
"4,80, а 95\\% довірчий інтервал — від 0,34 до 9,26."

#: ../../Ch11/Ch11_tTest_02.rst:143
msgid ""
"where *t*\\(19) is shorthand notation for a *t*-statistic that has 19 "
"degrees of freedom. That said, it’s often the case that people don’t report "
"the confidence interval, or do so using a much more compressed form than "
"I’ve done here. For instance, it’s not uncommon to see the confidence "
"interval included as part of the stat block after reporting the mean "
"difference, like this:"
msgstr ""
"де *t*\\(19) є скороченим позначенням для *t*-статистики, що має 19 ступенів "
"свободи. Тим не менш, часто трапляється так, що люди не повідомляють про "
"довірчий інтервал або роблять це у набагато більш стислому вигляді, ніж я це "
"зробив тут. Наприклад, нерідко довірчий інтервал включають до блоку "
"статистичних даних після повідомлення про середню різницю, як-от:"

#: ../../Ch11/Ch11_tTest_02.rst:150
msgid "*t*\\(19) = 2.25, *p* = 0.036, CI\\ :sub:`95` = [0.34, 9.26]"
msgstr "*t*\\(19) = 2.25, *p* = 0.036, CI\\ :sub:`95` = [0.34, 9.26]"

#: ../../Ch11/Ch11_tTest_02.rst:152
msgid ""
"With that much jargon crammed into half a line, you know it must be really "
"smart.\\ [#]_"
msgstr ""
"З такою кількістю жаргону, втиснутого в піврядка, знаєш, це має бути справді "
"розумно.\\ [#]_"

#: ../../Ch11/Ch11_tTest_02.rst:158
msgid "Assumptions of the one sample *t*-test"
msgstr "Припущення одновибіркового *t*-тесту"

#: ../../Ch11/Ch11_tTest_02.rst:160
msgid ""
"Okay, so what assumptions does the one-sample *t*-test make? Well, since the "
"*t*-test is basically a *z*-test with the assumption of known standard "
"deviation removed, you shouldn’t be surprised to see that it makes the same "
"assumptions as the *z*-test, minus the one about the known standard "
"deviation. That is"
msgstr ""
"Гаразд, то які припущення робить одновибірковий *t*-тест? Оскільки *t*-тест "
"є, по суті, *z*-тестом без припущення про відоме стандартне відхилення, не "
"дивно, що він робить ті самі припущення, що й *z*-тест, за винятком "
"припущення про відоме стандартне відхилення. Тобто"

#: ../../Ch11/Ch11_tTest_02.rst:167
msgid ""
"*Normality*. We’re still assuming that the population distribution is normal,"
"\\ [#]_ and as noted earlier, there are standard tools that you can use to "
"check to see if this assumption is met (section :doc:`Ch11_tTest_08`), and "
"other tests you can do in it’s place if this assumption is violated "
"(section :doc:`Ch11_tTest_09`)."
msgstr ""
"*Нормальність*. Ми все ще припускаємо, що розподіл населення є нормальним,\\ "
"[#]_ і, як зазначалося раніше, існують стандартні інструменти, за допомогою "
"яких можна перевірити, чи виконується це припущення (розділ "
":doc:`Ch11_tTest_08`), а також інші тести, які можна провести замість цього, "
"якщо це припущення порушується (розділ :doc:`Ch11_tTest_09`)."

#: ../../Ch11/Ch11_tTest_02.rst:173
msgid ""
"*Independence*. Once again, we have to assume that the observations in our "
"sample are generated independently of one another. See the earlier "
"discussion about the *z*-test for specifics (section :ref:`Assumptions of "
"the *z*-test <assumptions_z_test>`)."
msgstr ""
"*Незалежність*. Знову ж таки, ми маємо припустити, що спостереження в нашій "
"вибірці генеруються незалежно одне від одного. Детальніше про це див. "
"попереднє обговорення *z*-тесту (розділ :ref:`Припущення *z*-тесту "
"<assumptions_z_test>`)."

#: ../../Ch11/Ch11_tTest_02.rst:178
msgid ""
"Overall, these two assumptions aren’t terribly unreasonable, and as a "
"consequence the one-sample *t*-test is pretty widely used in practice as a "
"way of comparing a sample mean against a hypothesised population mean."
msgstr ""
"В цілому, ці два припущення не є надто необґрунтованими, і, як наслідок, "
"одновибірковий *t*-тест досить широко використовується на практиці як спосіб "
"порівняння середнього значення вибірки з гіпотетичним середнім значенням "
"генеральної сукупності."

#: ../../Ch11/Ch11_tTest_02.rst:186
msgid ""
"Well, sort of. As I understand the history, Gosset only provided a partial "
"solution; the general solution to the problem was provided by Sir Ronald "
"Fisher."
msgstr ""
"Ну, щось на кшталт того. Наскільки я розумію історію, Госсет запропонував "
"лише часткове рішення; загальне рішення проблеми запропонував сер Рональд "
"Фішер."

#: ../../Ch11/Ch11_tTest_02.rst:191
msgid ""
"More seriously, I tend to think the reverse is true. I get very suspicious "
"of technical reports that fill their results sections with nothing except "
"the numbers. It might just be that I’m an arrogant jerk, but I often feel "
"like an author that makes no attempt to explain and interpret their analysis "
"to the reader either doesn’t understand it themselves, or is being a bit "
"lazy. Your readers are smart, but not infinitely patient. Don’t annoy them "
"if you can help it."
msgstr ""
"Більш серйозно, я схильний думати, що все навпаки. Я дуже підозріло ставлюся "
"до технічних звітів, в яких розділ результатів заповнений виключно цифрами. "
"Можливо, я просто зарозумілий дурень, але мені часто здається, що автор, "
"який не намагається пояснити і проінтерпретувати свій аналіз для читача, або "
"сам його не розуміє, або просто лінується. Ваші читачі розумні, але не "
"безмежно терплячі. Не дратуйте їх, якщо можете цього уникнути."

#: ../../Ch11/Ch11_tTest_02.rst:200
msgid ""
"A technical comment. In the same way that we can weaken the assumptions of "
"the *z*-test so that we’re only talking about the sampling distribution, we "
"*can* weaken the *t*-test assumptions so that we don’t have to assume "
"normality of the population. However, for the *t*-test it’s trickier to do "
"this. As before, we can replace the assumption of population normality with "
"an assumption that the sampling distribution of *X̄* is normal. However, "
"remember that we’re also relying on a sample estimate of the standard "
"deviation, and so we also require the sampling distribution of :math:"
"`\\hat{\\sigma}` to be χ². That makes things nastier, and this version is "
"rarely used in practice. Fortunately, if the population distribution is "
"normal, then both of these two assumptions are met."
msgstr ""
"Технічний коментар. Так само, як ми можемо послабити припущення *z*-тесту, "
"щоб говорити лише про вибіркове розподілення, ми *можемо* послабити "
"припущення *t*-тесту, щоб не припускати нормальність генеральної сукупності. "
"Однак для *t*-тесту це зробити складніше. Як і раніше, ми можемо замінити "
"припущення про нормальність генеральної сукупності припущенням, що "
"вибірковий розподіл *X̄* є нормальним. Однак пам'ятайте, що ми також "
"покладаємося на вибіркову оцінку стандартного відхилення, тому нам також "
"потрібно, щоб вибірковий розподіл :math:`\\hat{\\sigma}` був χ². Це "
"ускладнює ситуацію, і ця версія рідко використовується на практиці. На "
"щастя, якщо розподіл генеральної сукупності є нормальним, то обидва ці "
"припущення виконуються."

#: ../../Ch11/Ch11_tTest_03.rst:4
msgid "The independent samples *t*-test (Student test)"
msgstr "*t*-критерій незалежних вибірок (критерій Стьюдента)"

#: ../../Ch11/Ch11_tTest_03.rst:6
msgid ""
"Although the one sample *t*-test has its uses, it’s not the most typical "
"example of a *t*-test.\\ [#]_ A much more common situation arises when "
"you’ve got two different groups of observations. In psychology, this tends "
"to correspond to two different groups of participants, where each group "
"corresponds to a different condition in your study. For each person in the "
"study you measure some outcome variable of interest, and the research "
"question that you’re asking is whether or not the two groups have the same "
"population mean. This is the situation that the independent samples *t*-test "
"is designed for."
msgstr ""
"Хоча одновибірковий *t*-критерій має своє застосування, він не є "
"найпоширенішим приклад *t*-критерію. [#]_ Набагато частіше зустрічається "
"ситуація, коли ви маєте дві різні групи спостережень. У психології це, як "
"правило, відповідає двом різним групам учасників, де кожна група відповідає "
"різним умовам у вашому дослідженні. Для кожної особи в дослідженні ви "
"вимірюєте деяку змінну результату, що вас цікавить, і дослідницьке питання, "
"яке ви ставите, полягає в тому, чи мають дві групи однакове середнє значення "
"для популяції. Саме для такої ситуації призначений *t*-критерій для "
"незалежних вибірок."

#: ../../Ch11/Ch11_tTest_03.rst:17 ../../Ch11/Ch11_tTest_05.rst:24
msgid "The data"
msgstr "Дані"

#: ../../Ch11/Ch11_tTest_03.rst:19
msgid ""
"Suppose we have 33 students taking Dr Harpo’s statistics lectures, and Dr "
"Harpo doesn’t grade to a curve. Actually, Dr Harpo’s grading is a bit of a "
"mystery, so we don’t really know anything about what the average grade is "
"for the class as a whole. There are two tutors for the class, Anastasia and "
"Bernadette. There are *N*\\ :sub:`1` = 15 students in Anastasia’s tutorials, "
"and *N*\\ :sub:`2` = 18 in Bernadette’s tutorials. The research question I’m "
"interested in is whether Anastasia or Bernadette is a better tutor, or if it "
"doesn’t make much of a difference. Dr Harpo sends me the |harpo|_ data set "
"with the course grades. file. As usual, I’ll load the file into jamovi and "
"have a look at what variables it contains - there are three variables, "
"``ID``, ``grade`` and ``tutor``. The ``grade`` variable contains each "
"student’s grade, but it is not imported into jamovi with the correct "
"measurement level attribute, so I need to change this so it is regarded as a "
"continuous variable |continuous| (see :ref:`Changing measurement levels "
"<variable_editor>`). The ``tutor`` variable is a factor |nominal| that "
"indicates who each student’s tutor was - either Anastasia or Bernadette."
msgstr ""
"Припустимо, що у нас є 33 студенти, які відвідують лекції з статистики "
"доктора Харпо, і доктор Харпо не оцінює за кривою. Насправді, система "
"оцінювання доктора Харпо є дещо загадковою, тому ми нічого не знаємо про "
"середній бал класу в цілому. У класі є дві викладачки, Анастасія та "
"Бернадетта. У групі Анастасії навчається *N*\\ :sub:`1` = 15 студентів, а в "
"групі Бернадетти — *N*\\ :sub:`2` = 18. Мене цікавить питання, хто з них "
"краща викладачка — Анастасія чи Бернадетта, або ж це не має великого "
"значення. Доктор Харпо надсилає мені набір даних |harpo|_ з оцінками за "
"курс. файл. Як завжди, я завантажу файл у jamovi і подивлюся, які змінні він "
"містить — є три змінні: ``ID``, ``grade`` і ``tutor``. Змінна «grade» "
"містить оцінки кожного студента, але вона не імпортується в jamovi з "
"правильним атрибутом рівня вимірювання, тому мені потрібно змінити це, щоб "
"вона розглядалася як безперервна змінна |continuous| (див. :ref:`Зміна "
"рівнів вимірювання <variable_editor>`). Змінна «tutor» є фактором |nominal|, "
"який вказує, хто був репетитором кожного студента — Анастасія чи Бернадетт."

#: ../../Ch11/Ch11_tTest_03.rst:36
msgid ""
"We can calculate means and standard deviations, using the ``Exploration`` → "
"``Descriptives`` analysis, and here’s a nice little summary table:"
msgstr ""
"Ми можемо обчислити середні значення та стандартні відхилення, "
"використовуючи ``Exploration`` → ``Descriptives`` аналіз, і ось гарна "
"невелика зведена таблиця:"

#: ../../Ch11/Ch11_tTest_03.rst:40
msgid "mean"
msgstr "середній"

#: ../../Ch11/Ch11_tTest_03.rst:40
msgid "std. dev."
msgstr "'std. dev."

#: ../../Ch11/Ch11_tTest_03.rst:40
msgid "N"
msgstr "N"

#: ../../Ch11/Ch11_tTest_03.rst:42
msgid "**Anastasia’s students**"
msgstr "**Учні Анастасії**"

#: ../../Ch11/Ch11_tTest_03.rst:42
msgid "74.53"
msgstr "74.53"

#: ../../Ch11/Ch11_tTest_03.rst:42
msgid "9.00"
msgstr "9.00"

#: ../../Ch11/Ch11_tTest_03.rst:42
msgid "15"
msgstr "15"

#: ../../Ch11/Ch11_tTest_03.rst:44
msgid "**Bernadette’s students**"
msgstr "**Учні Бернадетти**"

#: ../../Ch11/Ch11_tTest_03.rst:44
msgid "69.06"
msgstr "69.06"

#: ../../Ch11/Ch11_tTest_03.rst:44
msgid "5.77"
msgstr "5.77"

#: ../../Ch11/Ch11_tTest_03.rst:44
msgid "18"
msgstr "18"

#: ../../Ch11/Ch11_tTest_03.rst:47
msgid ""
"To give you a more detailed sense of what’s going on here, I’ve plotted "
"histograms (not in jamovi, but using R) showing the distribution of grades "
"for both tutors (:numref:`fig-harpohist`), as well as a simpler plot showing "
"the means and corresponding confidence intervals for both groups of students "
"(:numref:`fig-ttestci`)."
msgstr ""
"Щоб дати вам більш детальне уявлення про те, що тут відбувається, я "
"побудував гістограми (не в jamovi, а за допомогою R), що показують розподіл "
"оцінок для обох викладачів (:numref:`fig-harpohist`), а також простіший "
"графік, що показує середні значення та відповідні довірчі інтервали для обох "
"груп студентів (:numref:`fig-ttestci`)."

#: ../../Ch11/Ch11_tTest_03.rst:55
msgid "Histogram with grades in Anastasia’s and Bernadette’s classes"
msgstr "Гістограма з оцінками в класах Анастасії та Бернадетти"

#: ../../Ch11/Ch11_tTest_03.rst:59
msgid ""
"Histograms showing the distribution of grades for students in Anastasia’s "
"(left panel) and in Bernadette’s (right panel) classes. Visually, these "
"suggest that students in Anastasia’s class may be getting slightly better "
"grades on average, though they also seem a bit more variable."
msgstr ""
"Гістограми, що показують розподіл оцінок учнів у класах Анастасії (ліва "
"панель) та Бернадетти (права панель). Візуально це свідчить про те, що учні "
"класу Анастасії в середньому отримують дещо кращі оцінки, хоча вони також "
"здаються дещо більш мінливими."

#: ../../Ch11/Ch11_tTest_03.rst:66
msgid "Mean grades (with error bars) in Anastasia’s and Bernadette’s classes"
msgstr "Середні оцінки (з похибками) у класах Анастасії та Бернадетти"

#: ../../Ch11/Ch11_tTest_03.rst:70
msgid ""
"The plots show the mean grade for students in Anastasia’s and Bernadette’s "
"tutorials. Error bars depict 95\\% confidence intervals around the mean. "
"Visually, it does look like there’s a real difference between the groups, "
"though it’s hard to say for sure."
msgstr ""
"На графіках показано середній бал студентів у групах Анастасії та "
"Бернадетти. Смуги похибки відображають 95 % довірчий інтервал навколо "
"середнього значення. Візуально здається, що між групами є реальна різниця, "
"хоча це важко сказати напевно."

#: ../../Ch11/Ch11_tTest_03.rst:78
msgid "Introducing the test"
msgstr "Знайомство з тестом"

#: ../../Ch11/Ch11_tTest_03.rst:80
msgid ""
"The **independent samples t-test** comes in two different forms, Student’s "
"and Welch’s. The original Student *t*-test, which is the one I’ll describe "
"in this section, is the simpler of the two but relies on much more "
"restrictive assumptions than the Welch *t*-test. Assuming for the moment "
"that you want to run a two-sided test, the goal is to determine whether two "
"“independent samples” of data are drawn from populations with the same mean "
"(the null hypothesis) or different means (the alternative hypothesis). When "
"we say “independent” samples, what we really mean here is that there’s no "
"special relationship between observations in the two samples. This probably "
"doesn’t make a lot of sense right now, but it will be clearer when we come "
"to talk about the paired samples *t*-test later on. For now, let’s just "
"point out that if we have an experimental design where participants are "
"randomly allocated to one of two groups, and we want to compare the two "
"groups’ mean performance on some outcome measure, then an independent "
"samples *t*-test (rather than a paired samples *t*-test) is what we’re after."
msgstr ""
"**Незалежний t-критерій для незалежних вибірок** існує у двох різних формах: "
"Стьюдента та Велча. Оригінальний *t*-критерій Стьюдента, який я опишу в "
"цьому розділі, є простішим з двох, але базується на набагато більш "
"обмежувальних припущеннях, ніж *t*-критерій Велча. Припустимо, що ви хочете "
"провести двосторонній тест. Мета полягає в тому, щоб визначити, чи дві «"
"незалежні вибірки» даних взяті з популяцій з однаковим середнім значенням ("
"нульова гіпотеза) або з різними середніми значеннями (альтернативна гіпотеза)"
". Коли ми говоримо про «незалежні» вибірки, ми маємо на увазі, що між "
"спостереженнями в двох вибірках немає особливого зв'язку. Наразі це, "
"ймовірно, не має великого сенсу, але стане зрозумілішим, коли ми пізніше "
"поговоримо про *t*-критерій для парних вибірок. Наразі зазначимо лише, що "
"якщо ми маємо експериментальний дизайн, в якому учасники випадковим чином "
"розподіляються на дві групи, і ми хочемо порівняти середні показники двох "
"груп за певним критерієм, то нам потрібен *t*-критерій для незалежних "
"вибірок (а не *t*-критерій для парних вибірок)."

#: ../../Ch11/Ch11_tTest_03.rst:98
msgid ""
"Okay, so let’s let µ\\ :sub:`1` denote the true population mean for group 1 "
"(e.g., Anastasia’s students), and µ\\ :sub:`2` will be the true population "
"mean for group 2 (e.g., Bernadette’s students),\\ [#]_ and as usual we’ll "
"let *X̄*\\ :sub:`1` and *X̄*\\ :sub:`2` denote the observed sample means for "
"both of these groups. Our null hypothesis states that the two population "
"means are identical (µ\\ :sub:`1` = µ\\ :sub:`1`) and the alternative to "
"this is that they are not (µ\\ :sub:`1` ≠ µ\\ :sub:`1`). Written in "
"mathematical-ese, this is:"
msgstr ""
"Гаразд, тож нехай µ\\ :sub:`1` позначає справжнє середнє значення популяції "
"для групи 1 (наприклад, учнів Анастасії), а µ\\ :sub:`2` буде справжнім "
"середнім значенням популяції для групи 2 (наприклад, учнів Бернадетти),\\ [#]"
"_ і, як зазвичай, нехай *X̄*\\ :sub:`1` і *X̄*\\ :sub:`2` позначати "
"спостережувані середні значення вибірки для обох цих груп. Наша нульова "
"гіпотеза стверджує, що два середні значення генеральної сукупності є "
"ідентичними (µ\\ :sub:`1` = µ\\ :sub:`1`), а альтернатива цьому — що вони не "
"є ідентичними (µ\\ :sub:`1` ≠ µ\\ :sub:`1`). У математичному вираженні це "
"виглядає так:"

#: ../../Ch11/Ch11_tTest_03.rst:107
msgid "H\\ :sub:`0`: µ\\ :sub:`1` = µ\\ :sub:`2`"
msgstr "H\\ :sub:`0`: µ\\ :sub:`1` = µ\\ :sub:`2`"

#: ../../Ch11/Ch11_tTest_03.rst:108
msgid "H\\ :sub:`1`: µ\\ :sub:`1` ≠ µ\\ :sub:`2`"
msgstr "H\\ :sub:`1`: µ\\ :sub:`1` ≠ µ\\ :sub:`2`"

#: ../../Ch11/Ch11_tTest_03.rst:112
msgid "Illustration: Null and alternative hypotheses, indep. samples *t*-test"
msgstr ""
"Ілюстрація: Нульова та альтернативна гіпотези, *t*-тест для незалежних "
"вибірок"

#: ../../Ch11/Ch11_tTest_03.rst:116
msgid ""
"Graphical illustration of the null and alternative hypotheses assumed by the "
"Student *t*-test for Independent Samples. The null hypothesis assumes that "
"both groups have the same mean µ, whereas the alternative assumes that they "
"have different means µ\\ :sub:`1` and µ\\ :sub:`2`\\. Notice that it is "
"assumed that the population distributions are normal, and that, although the "
"alternative hypothesis allows the group to have different means, it assumes "
"they have the same standard deviation."
msgstr ""
"Графічна ілюстрація нульової та альтернативної гіпотез, прийнятих у *t*-"
"критерії Стьюдента для незалежних вибірок. Нульова гіпотеза передбачає, що "
"обидві групи мають однакове середнє значення µ, тоді як альтернативна "
"гіпотеза передбачає, що вони мають різні середні значення µ\\ :sub:`1` та µ\\"
" :sub:`2`\\. Зверніть увагу, що передбачається, що розподіл популяції є "
"нормальним, і що, хоча альтернативна гіпотеза дозволяє групі мати різні "
"середні значення, вона передбачає, що вони мають однакове стандартне "
"відхилення."

#: ../../Ch11/Ch11_tTest_03.rst:126
msgid ""
"To construct a hypothesis test that handles this scenario we start by noting "
"that if the null hypothesis is true, then the difference between the "
"population means is *exactly* zero, µ\\ :sub:`1` - µ\\ :sub:`1` = 0. As a "
"consequence, a diagnostic test statistic will be based on the difference "
"between the two sample means. Because if the null hypothesis is true, then "
"we’d expect *X̄*\\ :sub:`1` – *X̄*\\ :sub:`2` to be *pretty close* to zero. "
"However, just like we saw with our one-sample tests (i.e., the one-sample "
"*z*-test and the one-sample *t*-test) we have to be precise about exactly "
"*how close* to zero this difference should be. And the solution to the "
"problem is more or less the same one. We calculate a standard error estimate "
"(SE), just like last time, and then divide the difference between means by "
"this estimate. So our **t-statistic** will be of the form:"
msgstr ""
"Щоб побудувати гіпотетичний тест, який враховує цей сценарій, спочатку "
"зауважимо, що якщо нульова гіпотеза є правдивою, то різниця між середніми "
"значеннями генеральної сукупності дорівнює *точно* нулю, µ\\ :sub:`1` - µ\\ "
":sub:`1` = 0. Як наслідок, діагностична тестова статистика буде базуватися "
"на різниці між двома середніми значеннями вибірки. Адже якщо нульова "
"гіпотеза є правдивою, то ми очікуємо, що *X̄*\\ :sub:`1` – *X̄*\\ :sub:`2` "
"буде *досить близьким* до нуля. Однак, як ми бачили на прикладі тестів для "
"однієї вибірки (тобто *z*-тесту для однієї вибірки та *t*-тесту для однієї "
"вибірки), ми маємо точно визначити, *наскільки близьким* до нуля має бути це "
"відхилення. І рішення проблеми є більш-менш таким самим. Ми обчислюємо "
"оцінку стандартної похибки (SE), як і минулого разу, а потім ділимо різницю "
"між середніми значеннями на цю оцінку. Отже, наша **t-статистика** матиме "
"вигляд:"

#: ../../Ch11/Ch11_tTest_03.rst:139
msgid "*t* = (*X̄*\\ :sub:`1` – *X̄*\\ :sub:`2`) / SE"
msgstr "*t* = (*X̄*\\ :sub:`1` – *X̄*\\ :sub:`2`) / SE"

#: ../../Ch11/Ch11_tTest_03.rst:141
msgid ""
"We just need to figure out what this standard error estimate actually is. "
"This is a bit trickier than was the case for either of the two tests we’ve "
"looked at so far, so we need to go through it a lot more carefully to "
"understand how it works."
msgstr ""
"Нам просто потрібно з'ясувати, що насправді являє собою ця оцінка "
"стандартної похибки. Це трохи складніше, ніж у випадку з двома тестами, які "
"ми розглядали до цього, тому нам потрібно проаналізувати це набагато "
"ретельніше, щоб зрозуміти, як це працює."

#: ../../Ch11/Ch11_tTest_03.rst:147
msgid "A “pooled estimate” of the standard deviation"
msgstr "«Об’єднана оцінка» стандартного відхилення"

#: ../../Ch11/Ch11_tTest_03.rst:149
msgid ""
"In the original “Student *t*-test”, we make the assumption that the two "
"groups have the same population standard deviation. That is, regardless of "
"whether the population means are the same, we assume that the population "
"standard deviations are identical, σ\\ :sub:`1` = σ\\ :sub:`2`. Since we’re "
"assuming that the two standard deviations are the same, we drop the "
"subscripts and refer to both of them as σ. How should we estimate this? How "
"should we construct a single estimate of a standard deviation when we have "
"two samples? The answer is, basically, we average them. Well, sort of. "
"Actually, what we do is take a *weighed* average of the *variance* "
"estimates, which we use as our **pooled estimate of the variance**. The "
"weight assigned to each sample is equal to the number of observations in "
"that sample, minus 1."
msgstr ""
"В оригінальному «студентському *t*-критерії» ми припускаємо, що дві групи "
"мають однакове стандартне відхилення популяції. Тобто, незалежно від того, "
"чи є середні значення популяції однаковими, ми припускаємо, що стандартні "
"відхилення популяції є ідентичними, σ\\ :sub:`1` = σ\\ :sub:`2`. Оскільки ми "
"припускаємо, що два стандартних відхилення однакові, ми відкидаємо індекси і "
"позначаємо їх обох як σ. Як ми повинні це оцінити? Як ми повинні побудувати "
"єдину оцінку стандартного відхилення, коли маємо дві вибірки? Відповідь, в "
"основному, полягає в тому, що ми обчислюємо їх середнє значення. Ну, "
"приблизно. Насправді ми беремо *зважене* середнє значення оцінок *дисперсії*"
", яке використовуємо як **об'єднану оцінку дисперсії**. Вага, присвоєна "
"кожній вибірці, дорівнює кількості спостережень у цій вибірці мінус 1."

#: ../../Ch11/Ch11_tTest_03.rst:161
msgid "Mathematically, we can write this as"
msgstr "Математично ми можемо записати це як"

#: ../../Ch11/Ch11_tTest_03.rst:163
msgid "w\\ :sub:`1` = *N*\\ :sub:`1` - 1"
msgstr "w\\ :sub:`1` = *N*\\ :sub:`1` - 1"

#: ../../Ch11/Ch11_tTest_03.rst:164
msgid "w\\ :sub:`2` = *N*\\ :sub:`2` - 1"
msgstr "w\\ :sub:`2` = *N*\\ :sub:`2` - 1"

#: ../../Ch11/Ch11_tTest_03.rst:166
msgid ""
"Now that we’ve assigned weights to each sample we calculate the pooled "
"estimate of the variance by taking the weighted average of the two variance "
"estimates, :math:`{\\hat\\sigma_1}^2` and :math:`{\\hat\\sigma_2}^2`"
msgstr ""
"Тепер, коли ми призначили ваги кожній вибірці, ми обчислюємо об'єднану "
"оцінку дисперсії, взявши середньозважене значення двох оцінок дисперсії., "
":math:`{\\hat\\sigma_1}^2` і :math:`{\\hat\\sigma_2}^2`"

#: ../../Ch11/Ch11_tTest_03.rst:171
msgid ""
"\\hat\\sigma^2_p = \\frac{w_1 {\\hat\\sigma_1}^2 + w_2 {\\hat\\sigma_2}^2}"
"{w_1 + w_2}\n"
"\n"
msgstr ""
"\\hat\\sigma^2_p = \\frac{w_1 {\\hat\\sigma_1}^2 + w_2 {\\hat\\sigma_2}^2}{"
"w_1 + w_2}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:173
msgid ""
"Finally, we convert the pooled variance estimate to a pooled standard "
"deviation estimate, by taking the square root."
msgstr ""
"Нарешті, ми перетворюємо об'єднану оцінку дисперсії на об'єднану оцінку "
"стандартного відхилення, беручи квадратний корінь."

#: ../../Ch11/Ch11_tTest_03.rst:176
msgid ""
"\\hat\\sigma_p = \\sqrt{\\frac{w_1 {\\hat\\sigma_1}^2 + w_2 {\\hat\\sigma_2}"
"^2}{w_1 + w_2}}\n"
"\n"
msgstr ""
"\\hat\\sigma_p = \\sqrt{\\frac{w_1 {\\hat\\sigma_1}^2 + w_2 {\\hat\\sigma_2"
"}^2}{w_1 + w_2}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:178
msgid ""
"And if you mentally substitute w\\ :sub:`1` = *N*\\ :sub:`1` - 1 and w\\ :"
"sub:`2` = *N*\\ :sub:`2` - 1 into this equation you get a very ugly looking "
"formula. A very ugly formula that actually seems to be the “standard” way of "
"describing the pooled standard deviation estimate. It’s not my favourite way "
"of thinking about pooled standard deviations, however. I prefer to think "
"about it like this. Our data set actually corresponds to a set of *N* "
"observations which are sorted into two groups. So let’s use the notation "
"*X*\\ :sub:`ik` to refer to the grade received by the i-th student in the k-"
"th tutorial group. That is, *X*\\ :sub:`11` is the grade received by the "
"first student in Anastasia’s class, *X*\\ :sub:`21` is her second student, "
"and so on. And we have two separate group means *X̄*\\ :sub:`1` and *X̄*\\ :"
"sub:`2`, which we could “generically” refer to using the notation *X̄*\\ :sub:"
"`k`, i.e., the mean grade for the k-th tutorial group. So far, so good. Now, "
"since every single student falls into one of the two tutorials, we can "
"describe their deviation from the group mean as the difference"
msgstr ""
"А якщо в думках підставити w\\ :sub:`1` = *N*\\ :sub:`1` - 1 і w\\ :sub:`2` "
"= *N*\\ :sub:`2` - 1 у це рівняння, ви отримаєте дуже непривабливу формулу. "
"Дуже непривабливу формулу, яка, насправді, здається «стандартним» способом "
"опису об'єднаної оцінки стандартного відхилення. Однак це не мій улюблений "
"спосіб мислення про об'єднані стандартні відхилення. Я вважаю за краще "
"думати про це так. Наш набір даних фактично відповідає набору *N* "
"спостережень, які сортуються на дві групи. Тож давайте використовувати "
"позначення *X*\\ :sub:`ik` для позначення оцінки, отриманої i-м студентом у "
"k-й навчальній групі. Тобто *X*\\ :sub:`11` — це оцінка, отримана першим "
"студентом у класі Анастасії, *X*\\ :sub:`21` — це її другий студент і так "
"далі. І ми маємо два окремі групові середні значення *X̄*\\ :sub:`1` і *X̄*\\ "
":sub:`2`, які ми можемо «загально» позначити за допомогою позначення *X̄*\\ "
":sub:`k`, тобто середньої оцінки для k-ї навчальної групи. Поки що все "
"добре. Тепер, оскільки кожен студент належить до однієї з двох навчальних "
"груп, ми можемо описати їх відхилення від середнього значення групи як "
"різницю"

#: ../../Ch11/Ch11_tTest_03.rst:194
msgid "*X*\\ :sub:`ik` - *X̄*\\ :sub:`k`"
msgstr "*X*\\ :sub:`ik` - *X̄*\\ :sub:`k`"

#: ../../Ch11/Ch11_tTest_03.rst:196
msgid ""
"So why not just use these deviations (i.e., the extent to which each "
"student’s grade differs from the mean grade in their tutorial)? Remember, a "
"variance is just the average of a bunch of squared deviations, so let’s do "
"that. Mathematically, we could write it like this:"
msgstr ""
"То чому б просто не використати ці відхилення (тобто ступінь, на який оцінка "
"кожного студента відрізняється від середньої оцінки в їхньому семінарі)? "
"Пам'ятайте, що дисперсія — це просто середнє значення суми квадратів "
"відхилень, тож давайте це зробимо. Математично ми можемо записати це так:"

#: ../../Ch11/Ch11_tTest_03.rst:201
msgid ""
"\\frac{\\sum_{ik} \\left( X_{ik} - \\bar{X}_k \\right)^2}{N}\n"
"\n"
msgstr ""
"\\frac{\\sum_{ik} \\left( X_{ik} - \\bar{X}_k \\right)^2}{N}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:203
msgid ""
"where the notation “Σ\\ :sub:`ik`” is a lazy way of saying “calculate a sum "
"by looking at all students in all tutorials”, since each “ik” corresponds to "
"one student.\\ [#]_ But, as we saw in chapter :doc:`../Ch08/"
"Ch08_Estimation`, calculating the variance by dividing by *N* produces a "
"biased estimate of the population variance. And previously we needed to "
"divide by *N* - 1 to fix this. However, as I mentioned at the time, the "
"reason why this bias exists is because the variance estimate relies on the "
"sample mean, and to the extent that the sample mean isn’t equal to the "
"population mean it can systematically bias our estimate of the variance. But "
"this time we’re relying on *two* sample means! Does this mean that we’ve got "
"more bias? Yes, yes it does. And does this mean we now need to divide by *N* "
"- 2 instead of *N* - 1, in order to calculate our pooled variance estimate? "
"Why, yes"
msgstr ""
"де позначення «Σ\\ :sub:`ik`» є спрощеним способом сказати «обчислити суму, "
"розглядаючи всіх студентів у всіх семінарах», оскільки кожне «ik» відповідає "
"одному студенту.\\ [#]_ Але, як ми бачили в розділі :doc:`../Ch08/"
"Ch08_Estimation`, обчислення дисперсії шляхом ділення на *N* дає упереджену "
"оцінку дисперсії генеральної сукупності. Раніше для виправлення цього нам "
"потрібно було ділити на *N* - 1. Однак, як я вже згадував тоді, причина "
"існування цього упередження полягає в тому, що оцінка дисперсії базується на "
"середньому значенні вибірки, і в тій мірі, в якій середнє значення вибірки "
"не дорівнює середньому значенню генеральної сукупності, це може систематично "
"упереджувати нашу оцінку дисперсії. Але цього разу ми покладаємося на *два* "
"середні значення вибірки! Чи означає це, що ми отримали більше "
"упередженості? Так, саме так. І чи означає це, що тепер нам потрібно ділити "
"на *N* - 2 замість *N* - 1, щоб обчислити нашу об'єднану оцінку дисперсії? "
"Так, саме так."

#: ../../Ch11/Ch11_tTest_03.rst:216
msgid ""
"\\hat\\sigma^2_p = \\frac{\\sum_{ik} \\left( X_{ik} - \\bar{X}_k \\right)^2}"
"{N -2}\n"
"\n"
msgstr ""
"\\hat\\sigma^2_p = \\frac{\\sum_{ik} \\left( X_{ik} - \\bar{X}_k \\right)^2}{"
"N -2}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:218
msgid ""
"Oh, and if you take the square root of this then you get :math:"
"`\\hat{\\sigma}_p`, the pooled standard deviation estimate. In other words, "
"the pooled standard deviation calculation is nothing special. It’s not "
"terribly different to the regular standard deviation calculation."
msgstr ""
"О, і якщо взяти квадратний корінь з цього, то отримаємо :math:`\\hat{\\sigma"
"}_p`, об'єднану оцінку стандартного відхилення. Іншими словами, обчислення "
"об'єднаного стандартного відхилення не є чимось особливим. Воно не надто "
"відрізняється від звичайного обчислення стандартного відхилення."

#: ../../Ch11/Ch11_tTest_03.rst:225
msgid "Completing the test"
msgstr "Завершення тесту"

#: ../../Ch11/Ch11_tTest_03.rst:227
msgid ""
"Regardless of which way you want to think about it, we now have our pooled "
"estimate of the standard deviation. From now on, I’ll drop the silly *p* "
"subscript, and just refer to this estimate as :math:`\\hat\\sigma`. Great. "
"Let’s now go back to thinking about the bloody hypothesis test, shall we? "
"Our whole reason for calculating this pooled estimate was that we knew it "
"would be helpful when calculating our *standard error* estimate. But "
"standard error of *what*? In the one-sample *t*-test it was the standard "
"error of the sample mean, SE(X̄), and since :math:`SE(X̄) = \\sigma / \\sqrt{N}"
"` that’s what the denominator of our *t*-statistic looked like. This time "
"around, however, we have *two* sample means. And what we’re interested in, "
"specifically, is the difference between the two *X̄*\\ :sub:`1` – *X̄*\\ :sub:"
"`2`. As a consequence, the standard error that we need to divide by is in "
"fact the **standard error of the difference** between means."
msgstr ""
"Незалежно від того, як ви хочете про це думати, тепер ми маємо нашу "
"об'єднану оцінку стандартного відхилення. Відтепер я відмовлюся від дурного "
"індексу *p* і просто буду називати цю оцінку :math:`\\hat\\sigma`. Чудово. "
"Давайте тепер повернемося до роздумів про кляту гіпотезу, добре? Єдина "
"причина, через яку ми обчислювали цю об'єднану оцінку, полягала в тому, що "
"ми знали, що вона буде корисною при обчисленні нашої оцінки *стандартної "
"похибки*. Але стандартна похибка *чого*? В одновибірковому *t*-тесті це була "
"стандартна похибка вибіркового середнього, SE(X̄), і оскільки :math:`SE(X̄) = "
"\\sigma / \\sqrt{N}`, саме так виглядав знаменник нашої *t*-статистики. "
"Однак цього разу ми маємо *два* вибіркові середні. І нас цікавить, зокрема, "
"різниця між двома *X̄*\\ :sub:`1` – *X̄*\\ :sub:`2`. Як наслідок, стандартна "
"похибка, на яку нам потрібно поділити, є насправді **стандартною похибкою "
"різниці** між середніми значеннями."

#: ../../Ch11/Ch11_tTest_03.rst:241
msgid ""
"As long as the two variables really do have the same standard deviation, "
"then our estimate for the standard error is"
msgstr ""
"Поки дві змінні дійсно мають однакове стандартне відхилення, наша оцінка "
"стандартної помилки буде"

#: ../../Ch11/Ch11_tTest_03.rst:244
msgid ""
"SE(\\bar{X}_1 - \\bar{X}_2) = \\hat\\sigma \\sqrt{\\frac{1}{N_1} + \\frac{1}"
"{N_2}}\n"
"\n"
msgstr ""
"SE(\\bar{X}_1 - \\bar{X}_2) = \\hat\\sigma \\sqrt{\\frac{1}{N_1} + \\frac"
"{1}{N_2}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:246
msgid "and our *t*-statistic is therefore"
msgstr "і тому наша *t*-статистика є"

#: ../../Ch11/Ch11_tTest_03.rst:248 ../../Ch11/Ch11_tTest_04.rst:42
msgid ""
"t = \\frac{\\bar{X}_1 - \\bar{X}_2}{SE(\\bar{X}_1 - \\bar{X}_2)}\n"
"\n"
msgstr ""
"t = \\frac{\\bar{X}_1 - \\bar{X}_2}{SE(\\bar{X}_1 - \\bar{X}_2)}\n"
"\n"

#: ../../Ch11/Ch11_tTest_03.rst:250
msgid ""
"Just as we saw with our one-sample test, the sampling distribution of this "
"*t*-statistic is a *t*-distribution (shocking, isn’t it?) as long as the "
"null hypothesis is true and all of the assumptions of the test are met. The "
"degrees of freedom, however, is slightly different. As usual, we can think "
"of the degrees of freedom to be equal to the number of data points minus the "
"number of constraints. In this case, we have *N* observations (*N*\\ :sub:"
"`1` in sample 1, and *N*\\ :sub:`2` in sample 2), and 2 constraints (the "
"sample means). So the total degrees of freedom for this test are *N* - 2."
msgstr ""
"Як ми бачили в тесті з однією вибіркою, вибіркове розподілення цієї *t*-"
"статистики є *t*-розподілом (дивно, чи не так?), якщо нульова гіпотеза є "
"істинною і всі припущення тесту виконуються. Однак ступінь свободи дещо "
"відрізняється. Як завжди, ми можемо вважати, що ступені свободи дорівнюють "
"кількості точок даних мінус кількість обмежень. У цьому випадку ми маємо *N* "
"спостережень (*N*\\ :sub:`1` у вибірці 1 і *N*\\ :sub:`2` у вибірці 2) і 2 "
"обмеження (середні значення вибірки). Отже, загальна кількість ступенів "
"свободи для цього тесту дорівнює *N* - 2."

#: ../../Ch11/Ch11_tTest_03.rst:263
msgid ""
"Not surprisingly, you can run an independent samples *t*-test easily in "
"jamovi. The outcome variable for our test is the student ``grade``, and the "
"groups are defined in terms of the ``tutor`` for each class. So you probably "
"won’t be too surprised that all you have to do in jamovi is go to the "
"relevant analysis (``Analyses`` → ``T-Tests`` → ``Independent Samples T-"
"Test``) and move the ``grade`` variable across to the ``Dependent "
"Variables`` box, and the ``tutor`` variable across into the ``Grouping "
"Variable`` box, as shown in :numref:`fig-ttest_ind`."
msgstr ""
"Не дивно, що в jamovi можна легко виконати *t*-тест для незалежних вибірок. "
"Змінною результату для нашого тесту є студент. ``grade``, а групи "
"визначаються з точки зору ``tutor`` для кожного класу. Тож ви, мабуть, не "
"будете надто здивовані, що все, що вам потрібно зробити в jamovi, це перейти "
"до відповідного аналізу (``Analyses`` → ``T-Tests`` → ``Independent Samples "
"T-Test``) і перемістити ``grade`` змінна поперек до ``Dependent Variables`` "
"коробка, і ``tutor`` змінна поперек у ``Grouping Variable`` коробку, як "
"показано на :numref:`fig-ttest_ind`."

#: ../../Ch11/Ch11_tTest_03.rst:274
msgid "Conducting an Independent Samples *t*-test in jamovi"
msgstr "Проведення *t*-тесту для незалежних вибірок в jamovi"

#: ../../Ch11/Ch11_tTest_03.rst:278
msgid ""
"Conducting an Independent Samples *t*-test in jamovi, with options for "
"recommended outputs checked."
msgstr ""
"Проведення *t*-тесту незалежних вибірок в jamovi з перевіркою опцій "
"рекомендованих виходів."

#: ../../Ch11/Ch11_tTest_03.rst:283
msgid ""
"The output has a very familiar form. First, it tells you what test was run, "
"and it tells you the name of the dependent variable that you used. It then "
"reports the test results. Just like last time the test results consist of a "
"*t*-statistic, the degrees of freedom, and the *p*-value. The final section "
"reports two things: it gives you a confidence interval and an effect size. "
"I’ll talk about effect sizes later. The confidence interval, however, I "
"should talk about now."
msgstr ""
"Результат має дуже звичну форму. Спочатку він повідомляє, який тест було "
"проведено, та називає залежну змінну, яку ви використовували. Потім він "
"повідомляє результати тесту. Як і минулого разу, результати тесту "
"складаються з *t*-статистики, ступенів свободи та *p*-значення. Останній "
"розділ повідомляє дві речі: він надає вам довірчий інтервал та розмір "
"ефекту. Про розмір ефекту я розповім пізніше. А ось про довірчий інтервал я "
"повинен розповісти зараз."

#: ../../Ch11/Ch11_tTest_03.rst:291
msgid ""
"It’s pretty important to be clear on what this confidence interval actually "
"refers to. It is a confidence interval for the *difference* between the "
"group means. In our example, Anastasia’s students had an average grade of "
"74.53, and Bernadette’s students had an average grade of 69.06, so the "
"difference between the two sample means is 5.48. But of course the "
"difference between population means might be bigger or smaller than this. "
"The confidence interval reported in :numref:`fig-ttest_ind` tells you that "
"there’s a if we replicated this study again and again, then 95\\% of the "
"time the true difference in means would lie between 0.20 and 10.76. Look "
"back at :doc:`../Ch08/Ch08_Estimation_5` for a reminder about what "
"confidence intervals mean."
msgstr ""
"Дуже важливо чітко розуміти, до чого насправді відноситься цей довірчий "
"інтервал. Це довірчий інтервал для *різниці* між середніми значеннями груп. "
"У нашому прикладі учні Анастасії мали середній бал 74,53, а учні Бернадетти —"
" 69,06, отже, різниця між двома середніми значеннями вибірки становить 5,48. "
"Але, звісно, різниця між середніми значеннями генеральної сукупності може "
"бути більшою або меншою. Довірчий інтервал, наведений у :numref:`fig-"
"ttest_ind`, показує, що якщо ми повторимо це дослідження знову і знову, то в "
"95\\% випадків справжня різниця в середніх значеннях буде знаходитися в "
"межах від 0,20 до 10,76. Поверніться до :doc:`../Ch08/Ch08_Estimation_5`, "
"щоб нагадати собі, що означають довірчі інтервали."

#: ../../Ch11/Ch11_tTest_03.rst:303
msgid ""
"In any case, the difference between the two groups is significant (just "
"barely), so we might write up the result using text like this:"
msgstr ""
"У будь-якому разі, різниця між двома групами є суттєвою (ледь-ледь), тому ми "
"можемо записати результат, використовуючи такий текст:"

#: ../../Ch11/Ch11_tTest_03.rst:306
msgid ""
"The mean grade in Anastasia’s class was 74.5\\% (std dev = 9.0), whereas the "
"mean in Bernadette’s class was 69.1\\% (std dev = 5.8). A Student’s "
"independent samples *t*-test showed that this 5.4\\% difference was "
"significant (*t*\\(31) = 2.1, *p* < 0.05, CI\\ :sub:`95` = [0.2, 10.8]`, *d* "
"= 0.74), suggesting that a genuine difference in learning outcomes has "
"occurred."
msgstr ""
"Середній бал у класі Анастасії становив 74,5 % (стандартне відхилення = 9,0)"
", тоді як середній бал у класі Бернадетти становив 69,1 % (стандартне "
"відхилення = 5,8). Незалежний *t*-критерій Стьюдента показав, що ця різниця "
"в 5,4 % є значущою (*t*\\(31) = 2,1, *p* < 0,05, CI\\ :sub:`95` = [0,2, 10,8]"
"`, *d* = 0,74), що свідчить про наявність реальної різниці в результатах "
"навчання."

#: ../../Ch11/Ch11_tTest_03.rst:313
msgid ""
"Notice that I’ve included the confidence interval and the effect size in the "
"stat block. People don’t always do this. At a bare minimum, you’d expect to "
"see the *t*-statistic, the degrees of freedom and the *p*-value. So you "
"should include something like this at a minimum: *t*\\(31) = 2.1, *p* < "
"0.05. If statisticians had their way, everyone would also report the "
"confidence interval and probably the effect size measure too, because they "
"are useful things to know. But real life doesn’t always work the way "
"statisticians want it to so you should make a judgment based on whether you "
"think it will help your readers and, if you’re writing a scientific paper, "
"the editorial standard for the journal in question. Some journals expect you "
"to report effect sizes, others don’t. Within some scientific communities it "
"is standard practice to report confidence intervals, in others it is not. "
"You’ll need to figure out what your audience expects. But, just for the sake "
"of clarity, if you’re taking my class, my default position is that it’s "
"usually worth including both the effect size and the confidence interval."
msgstr ""
"Зверніть увагу, що я включив до блоку статистичних даних довірчий інтервал і "
"розмір ефекту. Не завжди так роблять. Як мінімум, ви очікуєте побачити *t*-"
"статистику, ступені свободи та *p*-значення. Тому ви повинні включити "
"щонайменше таке: *t*\\(31) = 2,1, *p* < 0,05. Якби статистики мали свою "
"думку, то всі також повідомляли б про довірчий інтервал і, ймовірно, про "
"величину ефекту, оскільки це корисна інформація. Але реальне життя не завжди "
"працює так, як того хочуть статистики, тому ви повинні зробити висновок на "
"основі того, чи вважаєте ви, що це допоможе вашим читачам, а якщо ви пишете "
"наукову статтю, то на основі редакційних стандартів відповідного журналу. "
"Деякі журнали вимагають вказувати розмір ефекту, інші — ні. У деяких "
"наукових колах стандартною практикою є вказування довірчих інтервалів, в "
"інших — ні. Вам потрібно з'ясувати, чого очікує ваша аудиторія. Але, для "
"ясності, якщо ви відвідуєте мій курс, моя стандартна позиція полягає в тому, "
"що зазвичай варто вказувати і розмір ефекту, і довірчий інтервал."

#: ../../Ch11/Ch11_tTest_03.rst:332
msgid "Positive and negative *t*-values"
msgstr "Позитивні та негативні *t*-values"

#: ../../Ch11/Ch11_tTest_03.rst:334
msgid ""
"Before moving on to talk about the assumptions of the *t*-test, there’s one "
"additional point I want to make about the use of *t*-tests in practice. The "
"first one relates to the sign of the *t*-statistic (that is, whether it is a "
"positive number or a negative one). One very common worry that students have "
"when they start running their first *t*-test is that they often end up with "
"negative values for the *t*-statistic and don’t know how to interpret it. In "
"fact, it’s not at all uncommon for two people working independently to end "
"up with results that are almost identical, except that one person has a "
"negative *t*-values and the other one has a positive *t*-value. Assuming "
"that you’re running a two-sided test then the *p*-values will be identical. "
"On closer inspection, the students will notice that the confidence intervals "
"also have the opposite signs. This is perfectly okay. Whenever this happens, "
"what you’ll find is that the two versions of the results arise from slightly "
"different ways of running the *t*-test. What’s happening here is very "
"simple. The *t*-statistic that we calculate here is always of the form"
msgstr ""
"Перш ніж перейти до обговорення припущень *t*-тесту, я хочу зробити ще одне "
"зауваження щодо використання *t*-тестів на практиці. Перше стосується знака "
"*t*-статистики (тобто, чи є це додатне чи від'ємне число). Дуже поширеною "
"проблемою, з якою стикаються студенти, коли вперше проводять *t*-тест, є те, "
"що вони часто отримують від’ємні значення *t*-статистики і не знають, як їх "
"інтерпретувати. Насправді, зовсім не рідко буває так, що дві людини, які "
"працюють незалежно одна від одної, отримують майже однакові результати, за "
"винятком того, що одна людина має від'ємні *t*-значення, а інша — додатні "
"*t*-значення. Якщо ви проводите двосторонній тест, то *p*-значення будуть "
"однаковими. При детальнішому розгляді студенти помітять, що довірчі "
"інтервали також мають протилежні знаки. Це цілком нормально. Коли це "
"трапляється, ви побачите, що дві версії результатів є наслідком дещо різних "
"способів проведення *t*-тесту. Що тут відбувається, дуже просто. *t*-"
"статистика, яку ми тут обчислюємо, завжди має вигляд"

#: ../../Ch11/Ch11_tTest_03.rst:353
msgid "*t* = (mean 1 - mean 2) / SE"
msgstr "*t* = (середнє значення 1 - середнє значення 2) / SE"

#: ../../Ch11/Ch11_tTest_03.rst:355
msgid ""
"If “mean 1” is larger than “mean 2” the *t*-statistic will be positive, "
"whereas if “mean 2” is larger then the *t*-statistic will be negative. "
"Similarly, the confidence interval that jamovi reports is the confidence "
"interval for the difference “(mean 1) minus (mean 2)”, which will be the "
"reverse of what you’d get if you were calculating the confidence interval "
"for the difference “(mean 2) minus (mean 1)”."
msgstr ""
"Якщо «середнє 1» більше за «середнє 2», то *t*-статистика буде позитивною, а "
"якщо «середнє 2» більше, то *t*-статистика буде негативною. Аналогічно, "
"довірчий інтервал, який повідомляє jamovi, є довірчим інтервалом для різниці "
"«(середнє 1) мінус (середнє 2)», що буде протилежним до того, що ви "
"отримаєте, якщо обчислите довірчий інтервал для різниці «(середнє 2) мінус ("
"середнє 1)»."

#: ../../Ch11/Ch11_tTest_03.rst:362
msgid ""
"Okay, that’s pretty straightforward when you think about it, but now "
"consider our *t*-test comparing Anastasia’s class to Bernadette’s class. "
"Which one should we call “mean 1” and which one should we call “mean 2”. "
"It’s arbitrary. However, you really do need to designate one of them as "
"“mean 1” and the other one as “mean 2”. Not surprisingly, the way that "
"jamovi handles this is also pretty arbitrary. In earlier versions of the "
"book I used to try to explain it, but after a while I gave up, because it’s "
"not really all that important and to be honest I can never remember myself. "
"Whenever I get a significant *t*-test result, and I want to figure out which "
"mean is the larger one, I don’t try to figure it out by looking at the *t*-"
"statistic. Why would I bother doing that? It’s foolish. It’s easier just to "
"look at the actual group means since the jamovi output actually shows them!"
msgstr ""
"Гаразд, це досить просто, якщо подумати, але тепер розглянемо наш *t*-тест, "
"що порівнює клас Анастасії з класом Бернадетти. Який з них ми повинні "
"назвати «середнім 1», а який «середнім 2»? Це довільно. Однак вам дійсно "
"потрібно позначити один з них як «середнє 1», а інший — як «середнє 2». Не "
"дивно, що jamovi також досить довільно підходить до цього питання. У "
"попередніх версіях книги я намагався це пояснити, але через деякий час я "
"відмовився від цієї ідеї, оскільки це не так вже й важливо, і, чесно кажучи, "
"я сам ніколи не можу цього запам'ятати. Коли я отримую значущий результат "
"*t*-тесту і хочу з'ясувати, яке середнє більше, я не намагаюся це з'ясувати, "
"дивлячись на *t*-статистику. Навіщо мені це робити? Це безглуздо. Простіше "
"просто подивитися на фактичні середні групи, оскільки jamovi їх показує!"

#: ../../Ch11/Ch11_tTest_03.rst:376
msgid ""
"Here’s the important thing. Because it really doesn’t matter what jamovi "
"shows you, I usually try to *report* the *t*-statistic in such a way that "
"the numbers match up with the text. Suppose that what I want to write in my "
"report is “Anastasia’s class had higher grades than Bernadette’s class”. The "
"phrasing here implies that Anastasia’s group comes first, so it makes sense "
"to report the *t*-statistic as if Anastasia’s class corresponded to group 1. "
"If so, I would write"
msgstr ""
"Ось що важливо. Оскільки насправді не має значення, що показує вам jamovi, я "
"зазвичай намагаюся *звітувати* про *t*-статистику таким чином, щоб цифри "
"відповідали тексту. Припустимо, що я хочу написати у своєму звіті: «Клас "
"Анастасії мав вищі оцінки, ніж клас Бернадетти». Ця формулювання означає, що "
"група Анастасії посідає перше місце, тому має сенс подати *t*-статистику "
"так, ніби клас Анастасії відповідає групі 1. У такому разі я б написав"

#: ../../Ch11/Ch11_tTest_03.rst:384
msgid ""
"Anastasia’s class had higher grades than Bernadette’s class: *t*\\(31) = "
"2.1, *p* = 0.04."
msgstr ""
"Клас Анастасії мав вищі оцінки, ніж клас Бернадетт.: *t*\\(31) = 2.1, *p* = "
"0.04."

#: ../../Ch11/Ch11_tTest_03.rst:387
msgid ""
"(I wouldn’t actually underline the word “higher” in real life, I’m just "
"doing it to emphasise the point that “higher” corresponds to positive *t*-"
"values). On the other hand, suppose the phrasing I wanted to use has "
"Bernadette’s class listed first. If so, it makes more sense to treat her "
"class as group 1, and if so, the write up looks like this:"
msgstr ""
"(Насправді я б не підкреслював слово «вищий» у реальному житті, я роблю це "
"лише для того, щоб підкреслити, що «вищий» відповідає позитивним значенням "
"*t*). З іншого боку, припустимо, що у формулюванні, яке я хотів використати, "
"клас Бернадетт зазначений першим. У такому разі доцільніше розглядати її "
"клас як групу 1, і тоді запис виглядатиме так:"

#: ../../Ch11/Ch11_tTest_03.rst:393
msgid ""
"Bernadette’s class had lower grades than Anastasia’s class: *t*\\(31) = "
"-2.1, *p* = 0.04."
msgstr ""
"Клас Бернадетт мав нижчі оцінки, ніж клас Анастасії: *t*\\(31) = -2.1, *p* = "
"0.04."

#: ../../Ch11/Ch11_tTest_03.rst:396
msgid ""
"Because I’m talking about one group having “lower” scores this time around, "
"it is more sensible to use the negative form of the *t*-statistic. It just "
"makes it read more cleanly."
msgstr ""
"Оскільки цього разу я говорю про одну групу, яка має «нижчі» бали, розумніше "
"використовувати негативну форму *t*-статистики. Це просто робить її "
"зрозумілішою."

#: ../../Ch11/Ch11_tTest_03.rst:400
msgid ""
"One last thing: please note that you *can’t* do this for other types of test "
"statistics. It works for *t*-tests, but it wouldn’t be meaningful for χ²-"
"tests, *F*-tests or indeed for most of the tests I talk about in this book. "
"So don’t over-generalise this advice! I’m really just talking about *t*-"
"tests here and nothing else!"
msgstr ""
"І останнє: зверніть увагу, що ви *не можете* робити це для інших типів "
"тестових статистик. Це працює для *t*-тестів, але не буде мати сенсу для χ²-"
"тестів, *F*-тестів або, власне, для більшості тестів, про які я говорю в цій "
"книзі. Тож не узагальнюйте цю пораду надто широко! Я говорю тут виключно про "
"*t*-тести і ні про що інше!"

#: ../../Ch11/Ch11_tTest_03.rst:410
msgid "Assumptions of the Student *t*-test"
msgstr "Припущення студента *t*-test"

#: ../../Ch11/Ch11_tTest_03.rst:412
msgid ""
"As always, our hypothesis test relies on some assumptions. So what are they? "
"For the Student *t*-test there are three assumptions, some of which we saw "
"previously in the context of the one sample *t*-test (see section :ref:"
"`Assumptions of the one sample *t*-test <assumptions_one_sample_t_test>`):"
msgstr ""
"Як завжди, перевірка гіпотези базується на деяких припущеннях. Які ж вони? "
"Для t-критерію Стьюдента існує три припущення, деякі з яких ми вже "
"розглядали раніше в контексті t-критерію для однієї вибірки (див. розділ "
":ref:`Припущення t-критерію для однієї вибірки "
"<assumptions_one_sample_t_test>`):"

#: ../../Ch11/Ch11_tTest_03.rst:417
msgid ""
"*Normality*. Like the one-sample *t*-test, it is assumed that the data are "
"normally distributed. Specifically, we assume that both groups are normally "
"distributed. In section :doc:`Ch11_tTest_08`, we’ll discuss how to test for "
"normality, and in section :doc:`Ch11_tTest_09` we’ll discuss possible "
"solutions."
msgstr ""
"*Нормальність*. Як і в одновибірковому *t*-тесті, передбачається, що дані "
"мають нормальний розподіл. Зокрема, ми припускаємо, що обидві групи мають "
"нормальний розподіл. У розділі :doc:`Ch11_tTest_08` ми обговоримо, як "
"перевірити нормальність, а в розділі :doc:`Ch11_tTest_09` ми обговоримо "
"можливі рішення."

#: ../../Ch11/Ch11_tTest_03.rst:423
msgid ""
"*Independence*. Once again, it is assumed that the observations are "
"independently sampled. In the context of the Student test this has two "
"aspects to it. Firstly, we assume that the observations within each sample "
"are independent of one another (exactly the same as for the one-sample "
"test). However, we also assume that there are no cross-sample dependencies. "
"If, for instance, it turns out that you included some participants in both "
"experimental conditions of your study (e.g., by accidentally allowing the "
"same person to sign up to different conditions), then there are some cross "
"sample dependencies that you’d need to take into account."
msgstr ""
"*Незалежність*. Знову ж таки, припускається, що спостереження відбираються "
"незалежно. У контексті тесту Стьюдента це має два аспекти. По-перше, ми "
"припускаємо, що спостереження в межах кожної вибірки є незалежними одне від "
"одного (точно так само, як і для тесту з однією вибіркою). Однак ми також "
"припускаємо, що між вибірками немає взаємозалежності. Якщо, наприклад, ви "
"включили деяких учасників в обидві експериментальні умови вашого дослідження "
"(наприклад, випадково дозволивши одній і тій самій особі зареєструватися в "
"різних умовах), то існують певні взаємозалежності між вибірками, які вам "
"потрібно врахувати."

#: ../../Ch11/Ch11_tTest_03.rst:434
msgid ""
"*Homogeneity of variance* (also called “homoscedasticity”). The third "
"assumption is that the population standard deviation is the same in both "
"groups. You can test this assumption using the Levene test, which I’ll talk "
"about later on in the book (section :ref:`Checking the homogeneity of "
"variance assumption <homogeneity_of_variance_anova>`). However, there’s a "
"very simple remedy for this assumption if you are worried, which I’ll talk "
"about in the next section."
msgstr ""
"*Однорідність дисперсії* (також називається «гомоскедастичність»). Третє "
"припущення полягає в тому, що стандартне відхилення генеральної сукупності є "
"однаковим в обох групах. Ви можете перевірити це припущення за допомогою "
"тесту Левена, про який я розповім далі в цій книзі (розділ :ref:`Перевірка "
"припущення про однорідність дисперсії <homogeneity_of_variance_anova>`). "
"Однак, якщо вас турбує це припущення, є дуже простий спосіб його виправити, "
"про який я розповім у наступному розділі."

#: ../../Ch11/Ch11_tTest_03.rst:445
msgid "Although it is the simplest, which is why I started with it."
msgstr "Хоча він найпростіший, тому я з нього й почав."

#: ../../Ch11/Ch11_tTest_03.rst:448
msgid ""
"A funny question almost always pops up at this point: what the heck *is* the "
"population being referred to in this case? Is it the set of students "
"actually taking Dr Harpo’s class (all 33 of them)? The set of people who "
"might take the class (an unknown number of them)? Or something else? Does it "
"matter which of these we pick? It’s traditional in an introductory "
"behavioural stats class to mumble a lot at this point, but since I get asked "
"this question every year by my students, I’ll give a brief answer. "
"Technically yes, it does matter. If you change your definition of what the "
"“real world” population actually is, then the sampling distribution of your "
"observed mean *X̄* changes too. The *t*-test relies on an assumption that the "
"observations are sampled at random from an infinitely large population and, "
"to the extent that real life isn’t like that, then the *t*-test can be "
"wrong. In practice, however, this isn’t usually a big deal. Even though the "
"assumption is almost always wrong, it doesn’t lead to a lot of pathological "
"behaviour from the test, so we tend to just ignore it."
msgstr ""
"У цей момент майже завжди виникає кумедне запитання: про *яку* саме "
"популяцію йдеться в цьому випадку? Чи це група студентів, які фактично "
"відвідують заняття доктора Гарпо (всі 33 особи)? Група людей, які можуть "
"відвідувати заняття (їхня кількість невідома)? Чи щось інше? Чи має "
"значення, що саме ми оберемо? У вступному курсі з поведінкової статистики на "
"цьому етапі зазвичай багато бурмочуть, але оскільки мої студенти щороку "
"задають мені це питання, я дам коротку відповідь. Технічно, так, це має "
"значення. Якщо ви зміните своє визначення того, що таке «реальна» популяція, "
"то вибірковий розподіл вашого спостережуваного середнього значення *X̄* також "
"зміниться. *t*-тест базується на припущенні, що спостереження відбираються "
"випадковим чином з нескінченно великої сукупності, і, оскільки реальне життя "
"не є таким, *t*-тест може бути неправильним. Однак на практиці це зазвичай "
"не має великого значення. Хоча припущення майже завжди є неправильним, воно "
"не призводить до значних патологічних відхилень у тесті, тому ми, як "
"правило, просто ігноруємо його."

#: ../../Ch11/Ch11_tTest_03.rst:465
msgid ""
"A more correct notation will be introduced in chapter :doc:`../Ch13/"
"Ch13_ANOVA`."
msgstr ""
"Більш коректне позначення буде введено в розділі :doc:`../Ch13/Ch13_ANOVA`."

#: ../../Ch11/Ch11_tTest_04.rst:4
msgid "The independent samples *t*-test (Welch test)"
msgstr "*t* -критерій незалежних вибірок (критерій Велча)"

#: ../../Ch11/Ch11_tTest_04.rst:6
msgid ""
"The biggest problem with using the Student test in practice is the third "
"assumption listed in the previous section. It assumes that both groups have "
"the same standard deviation. This is rarely true in real life. If two "
"samples don’t have the same means, why should we expect them to have the "
"same standard deviation? There’s really no reason to expect this assumption "
"to be true. We’ll talk a little bit about how you can check this assumption "
"later on because it does crop up in a few different places, not just the *t*-"
"test. But right now I’ll talk about a different form of the *t*-test (:ref:"
"`Welch, 1947 <Welch_1947>`) that does not rely on this assumption. A "
"graphical illustration of what the **Welch t test** assumes about the data "
"is shown in :numref:`fig-ttesthyp2`, to provide a contrast with the Student "
"test version in :numref:`fig-ttesthyp`. I’ll admit it’s a bit odd to talk "
"about the cure before talking about the diagnosis, but as it happens the "
"``Welch's`` test can be specified as one of the ``Independent Samples T-"
"Test`` options in jamovi, so this is probably the best place to discuss it."
msgstr ""
"Найбільша проблема використання тесту Стьюдента на практиці полягає в "
"третьому припущенні, наведеному в попередньому розділі. Воно передбачає, що "
"обидві групи мають однакове стандартне відхилення. У реальному житті це "
"рідко буває правдою. Якщо дві вибірки не мають однакових середніх значень, "
"чому ми повинні очікувати, що вони матимуть однакове стандартне відхилення? "
"Насправді немає жодних підстав очікувати, що це припущення буде правдивим. "
"Пізніше ми трохи поговоримо про те, як можна перевірити це припущення, "
"оскільки воно зустрічається в декількох різних місцях, а не тільки в *t*-"
"тесті. Але зараз я розповім про іншу форму *t*-тесту (:ref:`Welch, 1947 "
"<Welch_1947>`), яка не покладається на це припущення. Графічна ілюстрація "
"того, що **t-тест Велча** припускає про дані, показана на :numref:`fig-"
"ttesthyp2`, щоб забезпечити контраст із версією тесту Стьюдента на :numref"
":`fig-ttesthyp`. Я визнаю, що трохи дивно говорити про лікування, не "
"обговоривши діагноз, але, як це часто буває, тест «Велча» можна вказати як "
"один з варіантів «Незалежного t-тесту для вибірки» в jamovi, тому, мабуть, "
"це найкраще місце для його обговорення."

#: ../../Ch11/Ch11_tTest_04.rst:24
msgid "Illustration: Null and alternative hypotheses for the Welch *t*-test"
msgstr "Ілюстрація: Нульова та альтернативна гіпотези для *t*-критерію Велча"

#: ../../Ch11/Ch11_tTest_04.rst:28
msgid ""
"Graphical illustration of the null and alternative hypotheses assumed by the "
"Welch *t*-test. Like the Student *t*-test for Independent Samples (:numref:"
"`fig-ttesthyp`) we assume that both samples are drawn from a normally-"
"distributed population; but the alternative hypothesis no longer requires "
"the two populations to have equal variance."
msgstr ""
"Графічна ілюстрація нульової та альтернативної гіпотез, прийнятих у тесті "
"Велча *t*. Як і в тесті Стьюдента *t* для незалежних вибірок (:numref:`fig-"
"ttesthyp`), ми припускаємо, що обидві вибірки взяті з нормально розподіленої "
"сукупності, але альтернативна гіпотеза більше не вимагає, щоб дві сукупності "
"мали рівну дисперсію."

#: ../../Ch11/Ch11_tTest_04.rst:36
msgid ""
"The Welch test is very similar to the Student test. For example, the *t*-"
"statistic that we use in the Welch test is calculated in much the same way "
"as it is for the Student test. That is, we take the difference between the "
"sample means and then divide it by some estimate of the standard error of "
"that difference:"
msgstr ""
"Тест Велча дуже схожий на тест Стьюдента. Наприклад, *t*-статистика, яку ми "
"використовуємо в тесті Велча, обчислюється майже так само, як і для тесту "
"Стьюдента. Тобто ми беремо різницю між середніми значеннями вибірки, а потім "
"ділимо її на деяку оцінку стандартної похибки цієї різниці:"

#: ../../Ch11/Ch11_tTest_04.rst:44
msgid ""
"The main difference is that the standard error calculations are different. "
"If the two populations have different standard deviations, then it’s a "
"complete nonsense to try to calculate a pooled standard deviation estimate, "
"because you’re averaging apples and oranges.\\ [#]_"
msgstr ""
"Основна відмінність полягає в тому, що розрахунки стандартної похибки є "
"різними. Якщо дві сукупності мають різні стандартні відхилення, то "
"намагатися обчислити об'єднану оцінку стандартного відхилення є повним "
"безглуздям, оскільки ви усереднюєте яблука та апельсини.\\ [#]_"

#: ../../Ch11/Ch11_tTest_04.rst:49
msgid ""
"But you can still estimate the standard error of the difference between "
"sample means, it just ends up looking different"
msgstr ""
"Але ви все ще можете оцінити стандартну похибку різниці між середніми "
"значеннями вибірки, просто вона виглядає по-іншому"

#: ../../Ch11/Ch11_tTest_04.rst:52
msgid ""
"SE(\\bar{X}_1 - \\bar{X}_2) = \\sqrt{ \\frac{{\\hat{\\sigma}_1}^2}{N_1} + "
"\\frac{{\\hat{\\sigma}_2}^2}{N_2} }\n"
"\n"
msgstr ""
"SE(\\bar{X}_1 - \\bar{X}_2) = \\sqrt{ \\frac{{\\hat{\\sigma}_1}^2}{N_1} + "
"\\frac{{\\hat{\\sigma}_2}^2}{N_2} }\n"
"\n"

#: ../../Ch11/Ch11_tTest_04.rst:54
msgid ""
"The reason why it’s calculated this way is beyond the scope of this book. "
"What matters for our purposes is that the *t*-statistic that comes out of "
"the Welch *t*-test is actually somewhat different to the one that comes from "
"the Student *t*-test."
msgstr ""
"Причина, чому це обчислюється таким чином, виходить за рамки цієї книги. Для "
"наших цілей важливо, що *t*-статистика, яка виходить з *t*-тесту Велча, "
"насправді дещо відрізняється від тієї, що виходить з *t*-тесту Стьюдента."

#: ../../Ch11/Ch11_tTest_04.rst:59
msgid ""
"The second difference between Welch and Student is that the degrees of "
"freedom are calculated in a very different way. In the Welch test, the "
"“degrees of freedom” doesn’t have to be a whole number any more, and it "
"doesn’t correspond all that closely to the “number of data points minus the "
"number of constraints” heuristic that I’ve been using up to this point."
msgstr ""
"Друга відмінність між тестом Велча і тестом Стьюдента полягає в тому, що "
"ступені свободи обчислюються зовсім по-різному. У тесті Велча «ступені "
"свободи» більше не обов'язково мають бути цілими числами і не відповідають "
"евристичному правилу «кількість точок даних мінус кількість обмежень», яке я "
"використовував до цього моменту."

#: ../../Ch11/Ch11_tTest_04.rst:66
msgid "The degrees of freedom are, in fact"
msgstr "Ступені свободи, фактично, є"

#: ../../Ch11/Ch11_tTest_04.rst:68
msgid ""
"\\mbox{df} = \\frac{ ({\\hat{\\sigma}_1}^2 / N_1 + {\\hat{\\sigma}_2}^2 / "
"N_2)^2 }{  ({\\hat{\\sigma}_1}^2 / N_1)^2 / (N_1 -1 )  + ({\\hat{\\sigma}_2}"
"^2 / N_2)^2 / (N_2 -1 ) }\n"
"\n"
msgstr ""
"\\mbox{df} = \\frac{ ({\\hat{\\sigma}_1}^2 / N_1 + {\\hat{\\sigma}_2}^2 / "
"N_2)^2 }{  ({\\hat{\\sigma}_1}^2 / N_1)^2 / (N_1 -1 )  + ({\\hat{\\sigma}_2}^"
"2 / N_2)^2 / (N_2 -1 ) }\n"
"\n"

#: ../../Ch11/Ch11_tTest_04.rst:70
msgid ""
"which is all pretty straightforward and obvious, right? Well, perhaps not. "
"It doesn’t really matter for our purposes. What matters is that you’ll see "
"that the “df” value that pops out of a Welch test tends to be a little bit "
"smaller than the one used for the Student test, and it doesn’t have to be a "
"whole number."
msgstr ""
"що є досить простим і очевидним, чи не так? Ну, можливо, не зовсім. Для "
"наших цілей це не має особливого значення. Важливо те, що ви побачите, що "
"значення «df», яке виходить з тесту Велча, як правило, є трохи меншим, ніж "
"те, що використовується для тесту Стьюдента, і воно не обов'язково має бути "
"цілим числом."

#: ../../Ch11/Ch11_tTest_04.rst:77
msgid "Doing the Welch test in jamovi"
msgstr "Проведення тесту Велча в jamovi"

#: ../../Ch11/Ch11_tTest_04.rst:79
msgid ""
"If you tick the check box for the ``Welch's`` test in the analysis we did "
"above, then this is what it gives you :numref:`fig-ttest_welch`:"
msgstr ""
"Якщо ви поставите прапорець біля пункту «тест Велча» в аналізі, який ми "
"виконали вище, то ось що він вам видасть: numref:`fig-ttest_welch`:"

#: ../../Ch11/Ch11_tTest_04.rst:84
msgid "Results showing the Welch test alongside the default Student’s *t*-test"
msgstr ""
"Результати, що показують тест Велча разом зі стандартним *t*-критерієм "
"Стьюдента"

#: ../../Ch11/Ch11_tTest_04.rst:88
msgid ""
"Results showing the Welch test alongside the default Student’s *t*-test in "
"jamovi"
msgstr ""
"Результати, що показують тест Велча разом зі стандартним *t* -тестом "
"Стьюдента в jamovi"

#: ../../Ch11/Ch11_tTest_04.rst:93
msgid ""
"The interpretation of this output should be fairly obvious. You read the "
"output for the Welch’s test in the same way that you would for the Student’s "
"test. You’ve got your descriptive statistics, the test results and some "
"other information. So that’s all pretty easy."
msgstr ""
"Інтерпретація цих результатів повинна бути досить очевидною. Ви читаєте "
"результати тесту Велча так само, як і результати тесту Стьюдента. Ви "
"отримали описові статистичні дані, результати тесту та деяку іншу "
"інформацію. Тож все це досить просто."

#: ../../Ch11/Ch11_tTest_04.rst:98
msgid ""
"Except, except… our result isn’t significant anymore. When we ran the "
"Student test we did get a significant effect, but the Welch test on the same "
"data set is not (*t*\\(23.02) = 2.03, *p* = 0.054). What does this mean? "
"Should we panic? Is the sky burning? Probably not. The fact that one test is "
"significant and the other isn’t doesn’t itself mean very much, especially "
"since I kind of rigged the data so that this would happen. As a general "
"rule, it’s not a good idea to go out of your way to try to interpret or "
"explain the difference between a *p*-value of 0.049 and a *p*-value of "
"0.051. If this sort of thing happens in real life, the *difference* in these "
"*p*-values is almost certainly due to chance. What does matter is that you "
"take a little bit of care in thinking about what test you use. The Student "
"test and the Welch test have different strengths and weaknesses. If the two "
"populations really do have equal variances, then the Student test is "
"slightly more powerful (lower Type II error rate) than the Welch test. "
"However, if they *don’t* have the same variances, then the assumptions of "
"the Student test are violated and you may not be able to trust it; you might "
"end up with a higher Type I error rate. So it’s a trade off. However, in "
"real life I tend to prefer the Welch test, because almost no-one *actually* "
"believes that the population variances are identical."
msgstr ""
"За винятком того, що... наш результат більше не є значущим. Коли ми провели "
"тест Стьюдента, ми отримали значущий ефект, але тест Велча на тому ж наборі "
"даних не дав значущого результату (*t*\\(23,02) = 2,03, *p* = 0,054). Що це "
"означає? Чи слід панікувати? Чи небо горить? Напевно, ні. Той факт, що один "
"тест є значущим, а інший — ні, сам по собі не має великого значення, "
"особливо з огляду на те, що я дещо підправив дані, щоб це сталося. Як "
"правило, не варто надто старатися, намагаючись інтерпретувати або пояснити "
"різницю між *p*-значенням 0,049 і *p*-значенням 0,051. Якщо таке трапляється "
"в реальному житті, *різниця* в цих *p*-значеннях майже напевно є випадковою. "
"Важливо, щоб ви трохи потурбувалися про те, який тест використовувати. Тест "
"Стьюдента і тест Велча мають різні сильні і слабкі сторони. Якщо дві "
"сукупності дійсно мають однакові дисперсії, то тест Стьюдента є дещо "
"потужнішим (нижчий рівень помилки II типу), ніж тест Велча. Однак, якщо вони "
"*не* мають однакових дисперсій, то припущення тесту Стьюдента порушуються і "
"ви не можете йому довіряти; ви можете отримати вищий рівень помилки I типу. "
"Тож це компроміс. Однак у реальному житті я схильний віддавати перевагу "
"тесту Велча, оскільки майже ніхто *насправді* не вірить, що дисперсії "
"генеральних сукупностей є ідентичними."

#: ../../Ch11/Ch11_tTest_04.rst:120
msgid "Assumptions of the test"
msgstr "Припущення тесту"

#: ../../Ch11/Ch11_tTest_04.rst:122
msgid ""
"The assumptions of the Welch test are very similar to those made by the "
"Student *t*-test (see :ref:`Assumptions of the Student *t*-test "
"<assumptions_student_t_test>`), except that the Welch test does not assume "
"homogeneity of variance. This leaves only the assumption of normality and "
"the assumption of independence. The specifics of these assumptions are the "
"same for the Welch test as for the Student test."
msgstr ""
"Припущення тесту Велча дуже схожі на припущення тесту Стьюдента *t* (див.: "
":ref:`Припущення тесту Стьюдента *t* <assumptions_student_t_test>`), за "
"винятком того, що тест Велча не передбачає однорідності дисперсії. Таким "
"чином, залишаються лише припущення про нормальність і незалежність. "
"Особливості цих припущень для тесту Велча такі самі, як і для тесту "
"Стьюдента."

#: ../../Ch11/Ch11_tTest_04.rst:132
msgid ""
"Well, I guess you can average apples and oranges, and what you end up with "
"is a delicious fruit smoothie. But no one really thinks that a fruit "
"smoothie is a very good way to describe the original fruits, do they?"
msgstr ""
"Ну, я думаю, можна змішати яблука і апельсини, і в результаті ви отримаєте "
"смачний фруктовий коктейль. Але ніхто ж не вважає, що фруктовий коктейль — "
"це дуже хороший спосіб описати оригінальні фрукти, чи не так?"

#: ../../Ch11/Ch11_tTest_05.rst:4
msgid "The paired-samples *t*-test"
msgstr "*t*-тест для парних вибірок"

#: ../../Ch11/Ch11_tTest_05.rst:6
msgid ""
"Regardless of whether we’re talking about the Student test or the Welch "
"test, an independent samples *t*-test is intended to be used in a situation "
"where you have two samples that are, well, independent of one another. This "
"situation arises naturally when participants are assigned randomly to one of "
"two experimental conditions, but it provides a very poor approximation to "
"other sorts of research designs. In particular, a repeated measures design, "
"in which each participant is measured (with respect to the same outcome "
"variable) in both experimental conditions, is not suited for analysis using "
"independent samples *t*-tests. For example, we might be interested in "
"whether listening to music reduces people’s working memory capacity. To that "
"end, we could measure each person’s working memory capacity in two "
"conditions: with music, and without music. In an experimental design such as "
"this one,\\ [#]_ each participant appears in *both* groups. This requires us "
"to approach the problem in a different way, by using the **paired samples t-"
"test**."
msgstr ""
"Незалежно від того, чи йдеться про тест Стьюдента чи тест Велча, незалежний "
"t-тест для незалежних вибірок призначений для використання в ситуації, коли "
"ви маєте дві вибірки, які, власне, є незалежними одна від одної. Така "
"ситуація виникає природно, коли учасників випадковим чином розподіляють на "
"дві експериментальні групи, але вона дає дуже погане наближення до інших "
"видів дослідницьких дизайнів. Зокрема, дизайн з повторними вимірами, в якому "
"кожен учасник вимірюється (відносно однієї і тієї ж змінної результату) в "
"обох експериментальних умовах, не підходить для аналізу з використанням "
"незалежних вибірок *t*-тестів. Наприклад, нас може цікавити, чи слухання "
"музики зменшує обсяг робочої пам'яті людей. Для цього ми могли б виміряти "
"обсяг робочої пам'яті кожної людини в двох умовах: з музикою і без музики. У "
"такому експериментальному дизайні, як цей,\\ [#]_ кожен учасник з'являється "
"в *обох* групах. Це вимагає від нас підійти до проблеми по-іншому, "
"використовуючи **t-тест для парних вибірок**."

#: ../../Ch11/Ch11_tTest_05.rst:26
msgid ""
"The data set that we’ll use this time comes from Dr Chico’s class.\\ [#]_ In "
"her class students take two major tests, one early in the semester and one "
"later in the semester. To hear her tell it, she runs a very hard class, one "
"that most students find very challenging. But she argues that by setting "
"hard assessments students are encouraged to work harder. Her theory is that "
"the first test is a bit of a “wake up call” for students. When they realise "
"how hard her class really is, they’ll work harder for the second test and "
"get a better mark. Is she right? To test this, let’s import the |chico|_ "
"data set into jamovi. This time jamovi does a good job during the import of "
"attributing measurement levels correctly. The |chico|_ data set contains "
"three variables: an ``id`` variable that identifies each student in the "
"class, the ``grade_test1`` variable that records the student grade for the "
"first test, and the ``grade_test2`` variable that has the grades for the "
"second test."
msgstr ""
"Набір даних, який ми будемо використовувати цього разу, походить з класу "
"доктора Чіко. [#]_ У її класі студенти складають два основних іспити: один "
"на початку семестру, а другий — наприкінці. За її словами, вона веде дуже "
"складний курс, який більшість студентів вважають дуже важким. Але вона "
"стверджує, що, встановлюючи високі вимоги до оцінювання, вона спонукає "
"студентів працювати старанніше. Її теорія полягає в тому, що перший іспит є "
"для студентів своєрідним «сигналом тривоги». Коли вони усвідомлюють, "
"наскільки важким є її курс, вони починають працювати старанніше, щоб "
"підготуватися до другого іспиту і отримати кращу оцінку. Чи має вона рацію? "
"Щоб перевірити це, імпортуємо набір даних |chico|_ до jamovi. Цього разу "
"jamovi добре впорався з імпортом, правильно визначивши рівні вимірювання. "
"Набір даних |chico|_ містить три змінні: змінну ``id``, яка ідентифікує "
"кожного студента в класі, змінну ``grade_test1``, яка фіксує оцінку студента "
"за перший тест, та змінну ``grade_test2``, яка містить оцінки за другий тест."

#: ../../Ch11/Ch11_tTest_05.rst:41
msgid ""
"If we look at the jamovi spreadsheet it does seem like the class is a hard "
"one (most grades are between 50\\% and 60\\%), but it does look like there’s "
"an improvement from the first test to the second one."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:47 ../../Ch11/Ch11_tTest_05.rst:51
msgid "Descriptives for the two grade test variables in the |chico|_ data set"
msgstr "Описи двох змінних тесту для оцінювання в наборі даних |chico|_"

#: ../../Ch11/Ch11_tTest_05.rst:55
msgid ""
"If we take a quick look at the descriptive statistics, in :numref:`fig-"
"ttest_paired1`, we see that this impression seems to be supported. Across "
"all 20 students the mean grade for the first test is 57\\%, but this rises "
"to 58\\% for the second test. Although, given that the standard deviations "
"are 6.6\\% and 6.4\\% respectively, it’s starting to feel like maybe the "
"improvement is just illusory; maybe just random variation. This impression "
"is reinforced when you see the means and confidence intervals plotted in :"
"numref:`fig-pairedt` (left panel). If we were to rely on this plot alone, "
"looking at how wide those confidence intervals are, we’d be tempted to think "
"that the apparent improvement in student performance is pure chance."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:69
msgid "Mean grade for test 1 and test 2 in Dr Chico's class"
msgstr "Середня оцінка за тест 1 та тест 2 у класі доктора Чіко"

#: ../../Ch11/Ch11_tTest_05.rst:73
msgid ""
"Mean grade for test 1 and test 2, with associated 95\\% confidence intervals "
"(left panel). Scatterplot showing the individual grades for test 1 and test "
"2 (middle panel). Histogram showing the improvement made by each student in "
"Dr Chico’s class (right panel). In the right panel, notice that almost the "
"entire distribution is above zero: the vast majority of students did improve "
"their performance from the first test to the second one."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:82
msgid ""
"Nevertheless, this impression is wrong. To see why, take a look at the "
"scatterplot of the grades for test 1 against the grades for test 2, shown "
"in :numref:`fig-pairedt` (middle panel). In this plot each dot corresponds "
"to the two grades for a given student. If their grade for test 1 (*x* co-"
"ordinate) equals their grade for test 2 (*y* co-ordinate), then the dot "
"falls on the line. Points falling above the line are the students that "
"performed better on the second test. Critically, almost all of the data "
"points fall above the diagonal line: almost all of the students *do* seem to "
"have improved their grade, if only by a small amount. This suggests that we "
"should be looking at the *improvement* made by each student from one test to "
"the next and treating that as our raw data. To do this, we’ll need to create "
"a new variable for the ``improvement`` that each student makes, and add it "
"to the |chico|_ data set. The easiest way to do this is to compute a new "
"variable, with the expression ``grade_test2 - grade_test1``."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:98
msgid ""
"Once we have computed this new ``improvement`` variable we can draw a "
"histogram showing the distribution of these improvement scores, shown in :"
"numref:`fig-pairedt` (right panel). When we look at the histogram, it’s very "
"clear that there *is* a real improvement here. The vast majority of the "
"students scored higher on test 2 than on test 1, reflected in the fact that "
"almost the entire histogram is above zero."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:106
msgid "What is the paired samples *t*-test?"
msgstr "Що таке парні зразки *t*-test?"

#: ../../Ch11/Ch11_tTest_05.rst:108
msgid ""
"In light of the previous exploration, let’s think about how to construct an "
"appropriate *t*-test. One possibility would be to try to run an independent "
"samples *t*-test using ``grade_test1`` and ``grade_test2`` as the variables "
"of interest. However, this is clearly the wrong thing to do as the "
"independent samples *t*-test assumes that there is no particular "
"relationship between the two samples. Yet clearly that’s not true in this "
"case because of the repeated measures structure in the data. To use the "
"language that I introduced in the last section, if we were to try to do an "
"independent samples *t*-test, we would be conflating the **within subject** "
"differences (which is what we’re interested in testing) with the **between "
"subject** variability (which we are not)."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:121
msgid ""
"The solution to the problem is obvious, I hope, since we already did all the "
"hard work in the previous section. Instead of running an independent samples "
"*t*-test on ``grade_test1`` and ``grade_test2``, we run a *one-sample* *t*-"
"test on the within-subject difference variable, ``improvement``. To "
"formalise this slightly, if *X*\\ :sub:`i1` is the score that the i-th "
"participant obtained on the first variable, and *X*\\ :sub:`i2` is the score "
"that the same person obtained on the second one, then the difference score "
"is:"
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:130
msgid "*D*\\ :sub:`i` = *X*\\ :sub:`i1` - *X*\\ :sub:`i2`}"
msgstr "*D*\\ :sub:`i` = *X*\\ :sub:`i1` - *X*\\ :sub:`i2`}"

#: ../../Ch11/Ch11_tTest_05.rst:132
msgid ""
"Notice that the difference scores is *variable 1 minus variable 2* and not "
"the other way around, so if we want improvement to correspond to a positive "
"valued difference, we actually want “test 2” to be our “variable 1”. "
"Equally, we would say that µ\\ :sub:`D` = µ\\ :sub:`1` - µ\\ :sub:`2` is the "
"population mean for this difference variable. So, to convert this to a "
"hypothesis test, our null hypothesis is that this mean difference is zero "
"and the alternative hypothesis is that it is not"
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:140
msgid "H\\ :sub:`0`: µ\\ :sub:`D` = 0"
msgstr "H\\ :sub:`0`: µ\\ :sub:`D` = 0"

#: ../../Ch11/Ch11_tTest_05.rst:141
msgid "H\\ :sub:`2`: µ\\ :sub:`D` ≠ 0"
msgstr "H\\ :sub:`2`: µ\\ :sub:`D` ≠ 0"

#: ../../Ch11/Ch11_tTest_05.rst:143
msgid ""
"This is assuming we’re talking about a two-sided test here. This is more or "
"less identical to the way we described the hypotheses for the one-sample *t*-"
"test. The only difference is that the specific value that the null "
"hypothesis predicts is 0. And so our *t*-statistic is defined in more or "
"less the same way too. If we let D̄ denote the mean of the difference scores, "
"then"
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:149
msgid ""
"t = \\frac{\\bar{D}}{SE(\\bar{D})}\n"
"\n"
msgstr ""
"t = \\frac{\\bar{D}}{SE(\\bar{D})}\n"
"\n"

#: ../../Ch11/Ch11_tTest_05.rst:151
msgid "which is"
msgstr "який є"

#: ../../Ch11/Ch11_tTest_05.rst:153
msgid ""
"t = \\frac{\\bar{D}}{\\hat\\sigma_D / \\sqrt{N}}\n"
"\n"
msgstr ""
"t = \\frac{\\bar{D}}{\\hat\\sigma_D / \\sqrt{N}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_05.rst:155
msgid ""
"where :math:`\\hat\\sigma_D` is the standard deviation of the difference "
"scores. Since this is just an ordinary, one-sample *t*-test, with nothing "
"special about it, the degrees of freedom are still *N* - 1. And that’s it. "
"The paired samples *t*-test really isn’t a new test at all. It’s a one-"
"sample *t*-test, but applied to the difference between two variables. It’s "
"actually very simple. The only reason it merits a discussion as long as the "
"one we’ve just gone through is that you need to be able to recognise *when* "
"a paired samples test is appropriate, and to understand *why* it’s better "
"than an independent samples *t*-test."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:168
msgid ""
"How do you do a paired samples *t*-test in jamovi? One possibility is to "
"follow the process I outlined above. That is, create a difference variable "
"and then run a one sample *t*-test on that. Since we’ve already created a "
"variable called ``improvement``, let’s do that and see what we get (see :"
"numref:`fig-ttest_paired2`\\)."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:176 ../../Ch11/Ch11_tTest_05.rst:180
msgid "Results showing a one sample *t*-test on paired difference scores"
msgstr ""
"Результати, що показують одновибірковий *t*-тест на парні різницеві бали"

#: ../../Ch11/Ch11_tTest_05.rst:184
msgid ""
"The output shown in :numref:`fig-ttest_paired2` is (obviously) formatted "
"exactly the same was as it was the last time we used the ``One Sample T-"
"Test`` analysis (section :doc:`Ch11_tTest_02`), and it confirms our "
"intuition. There’s an average improvement of 1.4\\% from test 1 to test 2, "
"and this is significantly different from 0 (*t*\\(19) = 6.48, *p* < 0.001)."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:190
msgid ""
"However, suppose you’re lazy and you don’t want to go to all the effort of "
"creating a new variable. Or perhaps you just want to keep the difference "
"between one-sample and paired-samples tests clear in your head. If so, you "
"can use the jamovi ``Paired Samples T-Test`` analysis, getting the results "
"shown in :numref:`fig-ttest_paired3`."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:198
msgid "Results showing a paired sample *t*-test"
msgstr "Результати, що показують *t*-тест для парних вибірок"

#: ../../Ch11/Ch11_tTest_05.rst:202
msgid ""
"Results showing a paired sample *t*-test. Compare it with :numref:`fig-"
"ttest_paired2`."
msgstr ""
"Результати, що показують *t*-тест для парних вибірок. Порівняйте його з "
":numref:`fig-ttest_paired2`."

#: ../../Ch11/Ch11_tTest_05.rst:207
msgid ""
"The numbers are identical to those that come from the one sample test, which "
"of course they have to be given that the paired samples *t*-test is just a "
"one sample test under the hood."
msgstr ""
"Цифри ідентичні тим, що отримані з тесту однієї вибірки, що, звичайно, "
"потрібно враховувати, враховуючи, що *t*-тест парних вибірок — це лише тест "
"однієї вибірки «під капотом»."

#: ../../Ch11/Ch11_tTest_05.rst:214
msgid ""
"This design is very similar to the one in section :doc:`../Ch10/"
"Ch10_ChiSquare_7` that motivated the McNemar test. This should be no "
"surprise. Both are standard repeated measures designs involving two "
"measurements. The only difference is that this time our outcome variable is "
"interval scale (working memory capacity, |continuous|) rather than a binary "
"scale variable (a yes-or-no question, |nominal|)."
msgstr ""

#: ../../Ch11/Ch11_tTest_05.rst:222
msgid ""
"At this point we have Drs Harpo, Chico and Zeppo. No prizes for guessing who "
"Dr Groucho is."
msgstr ""
"На цьому етапі у нас є доктори Харпо, Чіко та Зеппо. Немає нічого складного "
"в тому, хто такий доктор Граучо."

#: ../../Ch11/Ch11_tTest_06.rst:4
msgid "One-sided tests"
msgstr "Односторонні тести"

#: ../../Ch11/Ch11_tTest_06.rst:6
msgid ""
"When introducing the theory of null hypothesis tests, I mentioned that there "
"are some situations when it’s appropriate to specify a *one-sided* test (see "
"section :ref:`The difference between one-sided and two-sided tests "
"<one_vs_twosided_tests>`). So far all of the *t*-tests have been two-sided "
"tests. For instance, when we specified a one sample *t*-test for the grades "
"in Dr Zeppo’s class the null hypothesis was that the true mean was 67.5\\%. "
"The alternative hypothesis was that the true mean was greater than *or* less "
"than 67.5\\%. Suppose we were only interested in finding out if the true "
"mean is greater than 67.5\\%, and have no interest whatsoever in testing to "
"find out if the true mean is lower than \\67.5\\%. If so, our null "
"hypothesis would be that the true mean is 67.5\\% or less, and the "
"alternative hypothesis would be that the true mean is greater than 67.5\\%. "
"In jamovi, for the ``One Sample T-Test`` analysis, you can specify this by "
"clicking on the ``> Test Value`` option, under ``Hypothesis``. When you have "
"done this, you will get the results as shown in :numref:`fig-"
"ttest_onesided1`."
msgstr ""

#: ../../Ch11/Ch11_tTest_06.rst:24
msgid "jamovi results showing a ``One Sample T-Test``"
msgstr "результати jamovi показують a ``One Sample T-Test``"

#: ../../Ch11/Ch11_tTest_06.rst:28
msgid ""
"jamovi results showing a ``One Sample T-Test`` where the actual hypothesis "
"is one-sided, i.e. that the true mean is greater than 67.5\\%."
msgstr ""
"Результати jamovi показують «T-тест для однієї вибірки», де фактична "
"гіпотеза є односторонньою, тобто справжнє середнє значення перевищує 67,5%."

#: ../../Ch11/Ch11_tTest_06.rst:33
msgid ""
"Notice that there are a few changes from the output that we saw last time. "
"Most important is the fact that the actual hypothesis has changed, to "
"reflect the different test. The second thing to note is that although the "
"*t*-statistic and degrees of freedom have not changed, the *p*-value has. "
"This is because the one-sided test has a different rejection region from the "
"two-sided test. If you’ve forgotten why this is and what it means, you may "
"find it helpful to read back over chapter :doc:`../Ch09/"
"Ch09_HypothesisTesting`, and section :ref:`The difference between one-sided "
"and two-sided tests <one_vs_twosided_tests>` in particular. The third thing "
"to note is that the confidence interval is different too: it now reports a "
"“one-sided” confidence interval rather than a two-sided one. In a two-sided "
"confidence interval we’re trying to find numbers *a* and *b* such that we’re "
"confident that, if we were to repeat the study many times, then 95\\% of the "
"time the mean would lie *between* *a* and *b*. In a one-sided confidence "
"interval, we’re trying to find a single number *a* such that we’re confident "
"that 95\\% of the time the true mean would be *greater than* *a* (or less "
"than *a* if you selected ``Measure 1 < Measure 2`` in the ``Hypothesis`` "
"section)."
msgstr ""

#: ../../Ch11/Ch11_tTest_06.rst:51
msgid ""
"So that’s how to do a one-sided one sample *t*-test. However, all versions "
"of the *t*-test can be one-sided. For an independent samples *t*-test, you "
"could have a one-sided test if you’re only interested in testing to see if "
"group A has *higher* scores than group B, but have no interest in finding "
"out if group B has higher scores than group A. Let’s suppose that, for Dr "
"Harpo’s class, you wanted to see if Anastasia’s students had higher grades "
"than Bernadette’s. For this analysis, in the ``Hypothesis`` options, specify "
"that ``Group 1 > Group 2``. You should get the results shown in :numref:`fig-"
"ttest_onesided2`."
msgstr ""

#: ../../Ch11/Ch11_tTest_06.rst:63
msgid "One-sided hypothesis in an ``Independent Samples T-Test``"
msgstr "Одностороння гіпотеза в ``Independent Samples T-Test``"

#: ../../Ch11/Ch11_tTest_06.rst:67
msgid ""
"jamovi results showing an ``Independent Samples T-Test`` where the actual "
"hypothesis is one-sided, i.e. that Anastasia’s students had higher grades "
"than Bernadette’s."
msgstr ""
"Результати jamovi показують ``Independent Samples T-Test``, де фактична "
"гіпотеза є односторонньою, тобто, що учні Анастасії мали вищі оцінки, ніж "
"учні Бернадетт."

#: ../../Ch11/Ch11_tTest_06.rst:73
msgid ""
"Again, the output changes in a predictable way. The definition of the "
"alternative hypothesis has changed, the *p*-value has changed, and it now "
"reports a one-sided confidence interval rather than a two-sided one."
msgstr ""
"Знову ж таки, результат змінюється передбачуваним чином. Визначення "
"альтернативної гіпотези змінилося, значення *p* змінилося, і тепер воно "
"відображає односторонній довірчий інтервал, а не двосторонній."

#: ../../Ch11/Ch11_tTest_06.rst:78
msgid ""
"What about the paired samples *t*-test? Suppose we wanted to test the "
"hypothesis that grades go *up* from test 1 to test 2 in Dr Zeppo’s class, "
"and are not prepared to consider the idea that the grades go down. In jamovi "
"you would do this by specifying, under the ``Hypotheses`` option, that "
"``grade_test2`` (``Measure 1`` in jamovi, because we copied this first into "
"the paired variables box) > ``grade_test1`` (``Measure 2`` in jamovi). You "
"should get the results shown in :numref:`fig-ttest_onesided3`."
msgstr ""

#: ../../Ch11/Ch11_tTest_06.rst:89
msgid "One-sided hypothesis in an ``Paired Samples T-Test``"
msgstr "Одностороння гіпотеза в ``Paired Samples T-Test``"

#: ../../Ch11/Ch11_tTest_06.rst:93
msgid ""
"jamovi results showing a ``Paired Samples T-Test`` where the actual "
"hypothesis is one-sided, i.e. that ``grade_test2`` (``Measure 1``) is larger "
"than ``grade_test1`` (``Measure 2``)."
msgstr ""
"Результати jamovi показують ``T-тест парних вибірок``, де фактична гіпотеза "
"є односторонньою, тобто ``grade_test2`` (``Вимір 1``) більше, ніж "
"``grade_test1`` (``Вимір 2``)."

#: ../../Ch11/Ch11_tTest_06.rst:99
msgid ""
"Yet again, the output changes in a predictable way. The hypothesis has "
"changed, the *p*-value has changed, and the confidence interval is now one-"
"sided."
msgstr ""
"Знову ж таки, результат змінюється передбачуваним чином. Гіпотеза змінилася, "
"значення *p* змінилося, а довірчий інтервал тепер односторонній."

#: ../../Ch11/Ch11_tTest_07.rst:4
msgid "Effect size"
msgstr "Розмір ефекту"

#: ../../Ch11/Ch11_tTest_07.rst:6
msgid ""
"The most commonly used measure of effect size for a *t*-test is **Cohen’s "
"d** (:ref:`Cohen, 1988 <Cohen_1988>`). It’s a very simple measure in "
"principle, with quite a few wrinkles when you start digging into the "
"details. Cohen himself defined it primarily in the context of an independent "
"samples *t*-test, specifically the Student test. In that context, a natural "
"way of defining the effect size is to divide the difference between the "
"means by an estimate of the standard deviation. In other words, we’re "
"looking to calculate *something* along the lines of this:"
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:15
msgid "d = (mean 1 - mean 2) / std. dev."
msgstr "d = (середнє значення 1 - середнє значення 2) / стандартне відхилення."

#: ../../Ch11/Ch11_tTest_07.rst:17
msgid ""
"and he suggested a rough guide for interpreting *d* in :numref:`tab-"
"cohensdinterpretation`. You’d think that this would be pretty unambiguous, "
"but it’s not. This is largely because Cohen wasn’t too specific on what he "
"thought should be used as the measure of the standard deviation (in his "
"defence he was trying to make a broader point in his book, not nitpick about "
"tiny details). As discussed by :ref:`McGrath and Meyer (2006) "
"<McGrath_2006>`, there are several different versions in common usage, and "
"each author tends to adopt slightly different notation. For the sake of "
"simplicity (as opposed to accuracy), I’ll use *d* to refer to any statistic "
"that you calculate from the sample, and use δ to refer to a theoretical "
"population effect. Obviously, that does mean that there are several "
"different things all called *d*."
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:30
msgid ""
"My suspicion is that the only time that you would want Cohen’s *d* is when "
"you’re running a *t*-test, and jamovi has an option to calculate the effect "
"size for all the different flavours of *t*-test it provides."
msgstr ""
"Я підозрюю, що єдиний випадок, коли вам може знадобитися *d* Коена, — це "
"коли ви проводите *t*-тест, а jamovi має опцію для обчислення розміру ефекту "
"для всіх різних варіантів *t*-тесту, які він пропонує."

#: ../../Ch11/Ch11_tTest_07.rst:34
msgid ""
"A (very) rough guide to interpreting Cohen’s *d*. My personal recommendation "
"is to not use these blindly. The *d*-statistic has a natural interpretation "
"in and of itself. It re-describes the difference in means as the number of "
"standard deviations that separates those means. So it’s generally a good "
"idea to think about what that means in practical terms. In some contexts a "
"“small” effect could be of big practical importance. In other situations a "
"“large” effect may not be all that interesting."
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:45
msgid "*d*-value"
msgstr "*d*-значення"

#: ../../Ch11/Ch11_tTest_07.rst:45
msgid "rough interpretation"
msgstr "приблизне тлумачення"

#: ../../Ch11/Ch11_tTest_07.rst:47
msgid "about 0.2"
msgstr "про 0.2"

#: ../../Ch11/Ch11_tTest_07.rst:47
msgid "“small” effect"
msgstr "«малий» ефект"

#: ../../Ch11/Ch11_tTest_07.rst:49
msgid "about 0.5"
msgstr "про 0.5"

#: ../../Ch11/Ch11_tTest_07.rst:49
msgid "“moderate” effect"
msgstr "«помірний» ефект"

#: ../../Ch11/Ch11_tTest_07.rst:51
msgid "about 0.8"
msgstr "про 0.8"

#: ../../Ch11/Ch11_tTest_07.rst:51
msgid "“large” effect"
msgstr "«великий» ефект"

#: ../../Ch11/Ch11_tTest_07.rst:55
msgid "Cohen’s *d* from one sample"
msgstr "*d* Коена з одного семпла"

#: ../../Ch11/Ch11_tTest_07.rst:57
msgid ""
"The simplest situation to consider is the one corresponding to a one-sample "
"*t*-test. In this case, this is the one sample mean *X̄* and one "
"(hypothesised) population mean µ\\ :sub:`o` to compare it to. Not only that, "
"there’s really only one sensible way to estimate the population standard "
"deviation. We just use our usual estimate :math:`\\hat{\\sigma}`. Therefore, "
"we end up with the following as the only way to calculate d:"
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:64
msgid ""
"d = \\frac{\\bar{X} - \\mu_0}{\\hat{\\sigma}}\n"
"\n"
msgstr ""
"d = \\frac{\\bar{X} - \\mu_0}{\\hat{\\sigma}}\n"
"\n"

#: ../../Ch11/Ch11_tTest_07.rst:66
msgid ""
"When we look back at the results in :numref:`fig-ttest_one`, the effect size "
"value is Cohen’s *d* = 0.50. Overall, then, the psychology students in Dr "
"Zeppo’s class are achieving grades (mean = 72.3\\%) that are about 0.5 "
"standard deviations higher than the level that you’d expect (67.5\\%) if "
"they were performing at the same level as other students. Judged against "
"Cohen’s rough guide, this is a moderate effect size."
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:74
msgid "Cohen’s *d* from a Student’s *t*-test"
msgstr "Коенів *d* зі студентського блогу *t*-test"

#: ../../Ch11/Ch11_tTest_07.rst:76
msgid ""
"The majority of discussions of Cohen’s *d* focus on a situation that is "
"analogous to Student’s independent samples *t*-test, and it’s in this "
"context that the story becomes messier, since there are several different "
"versions of *d* that you might want to use in this situation. To understand "
"why there are multiple versions of *d*, it helps to take the time to write "
"down a formula that corresponds to the true population effect size δ. It’s "
"pretty straightforward, δ = (µ\\ :sub:`1` - µ\\ :sub:`2`) / σ."
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:84
msgid ""
"where, as usual, µ\\ :sub:`1` and µ\\ :sub:`2` are the population means "
"corresponding to group 1 and group 2 respectively, and σ is the standard "
"deviation (the same for both populations). The obvious way to estimate δ is "
"to do exactly the same thing that we did in the *t*-test itself, i.e., use "
"the sample means as the top line and a pooled standard deviation estimate "
"for the bottom line"
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:92
msgid ""
"d = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\hat{\\sigma}_p}\n"
"\n"
msgstr ""
"d = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\hat{\\sigma}_p}\n"
"\n"

#: ../../Ch11/Ch11_tTest_07.rst:94
msgid ""
"where :math:`\\hat\\sigma_p` is the exact same pooled standard deviation "
"measure that appears in the *t*-test. This is the most commonly used version "
"of Cohen’s *d* when applied to the outcome of a Student *t*-test, and is the "
"one provided in jamovi. It is sometimes referred to as Hedges’ *g* statistic "
"(:ref:`Hedges, 1981 <Hedges_1981>`)."
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:100
msgid ""
"However, there are other possibilities which I’ll briefly describe. Firstly, "
"you may have reason to want to use only one of the two groups as the basis "
"for calculating the standard deviation. This approach (often called Glass’ "
"*Δ*, pronounced *delta*) only makes most sense when you have good reason to "
"treat one of the two groups as a purer reflection of “natural variation” "
"than the other. This can happen if, for instance, one of the two groups is a "
"control group. Secondly, recall that in the usual calculation of the pooled "
"standard deviation we divide by *N* - 2 to correct for the bias in the "
"sample variance. In one version of Cohen’s *d* this correction is omitted, "
"and instead we divide by *N*. This version makes sense primarily when you’re "
"trying to calculate the effect size in the sample rather than estimating an "
"effect size in the population. Finally, there is a version based on :ref:"
"`Hedges and Olkin (1985) <Hedges_1985>`, who point out there is a small bias "
"in the usual (pooled) estimation for Cohen’s *d*. Thus they introduce a "
"small correction by multiplying the usual value of *d* by (*N* - 3) / (*N* "
"-2.25)."
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:117
msgid ""
"In any case, ignoring all those variations that you could make use of if you "
"wanted, let’s have a look at the default version in jamovi. In :numref:`fig-"
"ttest_ind` Cohen’s *d* = 0.74, indicating that the grade scores for students "
"in Anastasia’s class are, on average, 0.74 standard deviations higher than "
"the grade scores for students in Bernadette’s class. For a Welch-test, the "
"estimated effect size is the same (:numref:`fig-ttest_welch`)."
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:125
msgid "Cohen’s *d* from a paired-samples test"
msgstr "Коенів *d* з тесту парних зразків"

#: ../../Ch11/Ch11_tTest_07.rst:127
msgid ""
"Finally, what should we do for a paired samples *t*-test? In this case, the "
"answer depends on what it is you’re trying to do. jamovi assumes that you "
"want to measure your effect sizes relative to the distribution of difference "
"scores, and the measure of *d* that you calculate is:"
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:133
msgid ""
"d = \\frac{\\bar{D}}{\\hat{\\sigma}_D}\n"
"\n"
msgstr ""
"d = \\frac{\\bar{D}}{\\hat{\\sigma}_D}\n"
"\n"

#: ../../Ch11/Ch11_tTest_07.rst:135
msgid ""
"where :math:`\\hat{\\sigma}_D` is the estimate of the standard deviation of "
"the differences. In :numref:`fig-ttest_paired3` Cohen’s *d* = 1.45, "
"indicating that the time 2 grade scores are, on average, 1.45 standard "
"deviations higher than the time 1 grade scores."
msgstr ""
"де :math:`\\hat{\\sigma}_D` є оцінкою стандартного відхилення різниць. У "
":numref:`fig-ttest_paired3` *d* Коена = 1,45, що вказує на те, що оцінки за "
"2-й період в середньому на 1,45 стандартних відхилення вищі за оцінки за 1-й "
"період."

#: ../../Ch11/Ch11_tTest_07.rst:140
msgid ""
"This is the version of Cohen’s *d* that gets reported by the jamovi ``Paired "
"Samples T-Test`` analysis. The only wrinkle is figuring out whether this is "
"the measure you want or not. To the extent that you care about the practical "
"consequences of your research, you often want to measure the effect size "
"relative to the *original* variables, not the *difference* scores (e.g., the "
"1\\% improvement in Dr Chico’s class over time is pretty small when measured "
"against the amount of between-student variation in grades), in which case "
"you use the same versions of Cohen’s *d* that you would use for a Student or "
"Welch test. It’s not so straightforward to do this in jamovi; essentially "
"you have to change the structure of the data in the spreadsheet view so I "
"won’t go into that here,\\ [#]_ but the Cohen’s *d* for this perspective is "
"quite different: it is 0.22 which is quite small when assessed on the scale "
"of the original variables."
msgstr ""

#: ../../Ch11/Ch11_tTest_07.rst:158
msgid ""
"If you are interested, you can look at how this was done in the |chico2|_ "
"dataset"
msgstr ""
"Якщо вам цікаво, ви можете подивитися, як це було зроблено, у наборі даних "
"|chico2|_"

#: ../../Ch11/Ch11_tTest_08.rst:4
msgid "Checking the normality of a sample"
msgstr "Перевірка нормальності вибірки"

#: ../../Ch11/Ch11_tTest_08.rst:6
msgid ""
"All of the tests that we have discussed so far in this chapter have assumed "
"that the data are normally distributed. This assumption is often quite "
"reasonable, because :ref:`the central limit theorem <central_limit_theorem>` "
"does tend to ensure that many real world quantities are normally "
"distributed. Any time that you suspect that your variable is *actually* an "
"average of lots of different things, there’s a pretty good chance that it "
"will be normally distributed, or at least close enough to normal that you "
"can get away with using *t*-tests. However, life doesn’t come with "
"guarantees, and besides there are lots of ways in which you can end up with "
"variables that are highly non-normal. For example, any time you think that "
"your variable is actually the minimum of lots of different things, there’s a "
"very good chance it will end up quite skewed. In psychology, response time "
"(RT) data is a good example of this. If you suppose that there are lots of "
"things that could trigger a response from a human participant, then the "
"actual response will occur the first time one of these trigger events occurs."
"\\ [#]_ This means that RT data are systematically non-normal. Okay, so if "
"normality is assumed by all the tests, and is mostly but not always "
"satisfied (at least approximately) by real world data, how can we check the "
"normality of a sample? In this section I discuss two methods: QQ plots and "
"the Shapiro-Wilk test."
msgstr ""

#: ../../Ch11/Ch11_tTest_08.rst:27
msgid "QQ plots"
msgstr "QQ ділянки"

#: ../../Ch11/Ch11_tTest_08.rst:31
msgid "Histogram and QQ plot for normally-distributed data"
msgstr "Гістограма та QQ-графік для даних з нормальним розподілом"

#: ../../Ch11/Ch11_tTest_08.rst:35
msgid ""
"Histogram (left panel) and QQ plot (right panel) for the column ``Normal`` "
"in the |distributions|_ data set, a normally-distributed sample with 200 "
"observations. The Shapiro-Wilk statistic associated with these data is *W* = "
"0.992, indicating that no significant departures from normality were "
"detected (*p* = 0.361)."
msgstr ""

#: ../../Ch11/Ch11_tTest_08.rst:43
msgid "Histogram and QQ plot for skewed and tailed data"
msgstr "Гістограма та QQ-графік для асиметричних та хвостатих даних"

#: ../../Ch11/Ch11_tTest_08.rst:47
msgid ""
"In the top row, a histogram (top-left panel) and QQ plot (top-right panel) "
"for 200 observations in the column ``Skewed`` of the |distributions|_ data "
"set. The skewness of the data here is 1.543, and is reflected in a QQ plot "
"that curves upwards and is lacking the lower values within the "
"``Standardized Residuals``. As a consequence, the Shapiro-Wilk statistic is "
"*W* = 0.732, reflecting a significant departure from normality (*p* < "
"0.001). The bottom row shows the same plots for the 200 observations in the "
"column ``Heavy Tailed`` of the |distributions|_ data set. In this case, the "
"heavy tails in the data produce a high kurtosis (8.225), and cause the QQ "
"plot to flatten in the middle, and curve away sharply on either side. The "
"resulting Shapiro-Wilk statistic is *W* = 0.765, again reflecting a "
"significant deviation from normality (*p* < 0.001)."
msgstr ""

#: ../../Ch11/Ch11_tTest_08.rst:62
msgid ""
"One way to check whether a sample violates the normality assumption is to "
"draw a **“QQ plot”** (Quantile-Quantile plot). This allows you to visually "
"check whether you’re seeing any systematic violations. In a QQ plot, each "
"observation is plotted as a single dot. The x co-ordinate is the theoretical "
"quantile that the observation should fall in if the data were normally "
"distributed (with mean and variance estimated from the sample), and on the y "
"co-ordinate is the actual quantile of the data within the sample. If the "
"data are normal, the dots should form a straight line. For instance, lets "
"see what happens if we generate data by sampling from a normal distribution, "
"and then drawing a QQ plot. The results are shown in :numref:`fig-qq1`. As "
"you can see, these data form a pretty straight line; which is no surprise "
"given that we sampled them from a normal distribution! In contrast, have a "
"look at the two data sets shown in :numref:`fig-qq2`. The top panels show "
"the histogram and a QQ plot for a data set that is highly skewed: the QQ "
"plot curves upwards. The lower panels show the same plots for a heavy tailed "
"(i.e., high kurtosis) data set: in this case the QQ plot flattens in the "
"middle and curves sharply at either end."
msgstr ""

#: ../../Ch11/Ch11_tTest_08.rst:82
msgid "Shapiro-Wilk tests"
msgstr "Тести Шапіро-Вілка"

#: ../../Ch11/Ch11_tTest_08.rst:84
msgid ""
"QQ plots provide a nice way to informally check the normality of your data, "
"but sometimes you’ll want to do something a bit more formal and the "
"**Shapiro-Wilk test** (:ref:`Shapiro & Wilk, 1965 <Shapiro_1965>`) is "
"probably what you’re looking for.\\ [#]_ As you’d expect, the null "
"hypothesis being tested is that a set of *N* observations is normally "
"distributed."
msgstr ""

#: ../../Ch11/Ch11_tTest_08.rst:91
msgid ""
"The test statistic that it calculates is conventionally denoted as *W*, and "
"it’s calculated as follows. First, we sort the observations in order of "
"increasing size, and let *X*\\ :sub:`1` be the smallest value in the sample, "
"*X*\\ :sub:`2` be the second smallest and so on. Then the value of *W* is "
"given by"
msgstr ""

#: ../../Ch11/Ch11_tTest_08.rst:97
msgid ""
"W = \\frac{ \\left( \\sum_{i = 1}^N a_i X_i \\right)^2 }{ \\sum_{i = 1}^N "
"(X_i - \\bar{X})^2}\n"
"\n"
msgstr ""
"W = \\frac{ \\left( \\sum_{i = 1}^N a_i X_i \\right)^2 }{ \\sum_{i = 1}^N ("
"X_i - \\bar{X})^2}\n"
"\n"

#: ../../Ch11/Ch11_tTest_08.rst:99
msgid ""
"where *X̄* is the mean of the observations, and the *a*\\ :sub:`i` values are "
"an introductory text."
msgstr ""
"де *X̄* – це середнє значення спостережень, а значення *a*\\ :sub:`i` – це "
"вступний текст."

#: ../../Ch11/Ch11_tTest_08.rst:102
msgid ""
"Because it’s a little hard to explain the maths behind the *W* statistic, a "
"better idea is to give a broad brush description of how it behaves. Unlike "
"most … mumble, mumble … something complicated that is a bit beyond the scope "
"of of the test statistics that we’ll encounter in this book, it’s actually "
"*small* values of *W* that indicate departure from normality. The *W* "
"statistic has a maximum value of 1, which occurs when the data look "
"“perfectly normal”. The smaller the value of *W* the less normal the data "
"are. However, the sampling distribution for *W*, which is not one of the "
"standard ones that I discussed in chapter :doc:`../Ch07/Ch07_Probability` "
"and is in fact a complete pain in the arse to work with, does depend on the "
"sample size *N*. To give you a feel for what these sampling distributions "
"look like, I’ve plotted three of them in :numref:`fig-swdist`. Notice that, "
"as the sample size starts to get large, the sampling distribution becomes "
"very tightly clumped up near *W* = 1, and as a consequence, for larger "
"samples *W* doesn’t have to be very much smaller than 1 in order for the "
"test to be significant."
msgstr ""

#: ../../Ch11/Ch11_tTest_08.rst:120
msgid "Sampling distribution of the Shapiro-Wilk W statistic"
msgstr "Розподіл вибірки W-статистики Шапіро-Вілка"

#: ../../Ch11/Ch11_tTest_08.rst:124
msgid ""
"Sampling distribution of the Shapiro-Wilk W statistic, under the null "
"hypothesis that the data are normally-distributed, for samples of size 10, "
"20 and 50. Note that small values of W indicate departure from normality."
msgstr ""
"Розподіл вибірки статистики Шапіро-Уілка W, за нульовою гіпотезою, що дані "
"мають нормальний розподіл, для вибірок розміром 10, 20 і 50. Зверніть увагу, "
"що малі значення W вказують на відхилення від нормальності."

#: ../../Ch11/Ch11_tTest_08.rst:130
msgid ""
"To get the Shapiro-Wilk statistic in jamovi *t*-tests, check the option for "
"``Normality`` listed under ``Assumptions``. In the randomly sampled data "
"(*N* = 100) we used for the QQ plot, the value for the Shapiro-Wilk "
"normality test statistic was W = 0.99 with a *p*-value of 0.69. So, not "
"surprisingly, we have no evidence that these data depart from normality. "
"When reporting the results for a Shapiro-Wilk test, you should (as usual) "
"make sure to include the test statistic *W* and the *p*-value, though given "
"that the sampling distribution depends so heavily on *N* it would probably "
"be a politeness to include *N* as well."
msgstr ""

#: ../../Ch11/Ch11_tTest_08.rst:141
msgid "Example"
msgstr "Приклад"

#: ../../Ch11/Ch11_tTest_08.rst:143
msgid ""
"In the meantime, it’s probably worth showing you an example of what happens "
"to the QQ plot and the Shapiro-Wilk test when the data turn out to be non-"
"normal. For that, let’s look at the distribution of our AFL winning margins "
"variable (``afl.margins`` from the |aflsmall_margins|_ data set), which if "
"you remember back to th chapter on :doc:`../Ch04/Ch04_Descriptives` didn’t "
"look like they came from a normal distribution at all. Here’s what happens "
"to the QQ plot:"
msgstr ""

#: ../../Ch11/Ch11_tTest_08.rst:152
msgid ""
"QQ plot for the data (skewed) data in the ``afl.margins`` variable\n"
"of the |aflsmall_margins| dataset"
msgstr ""
"Графік QQ для даних (скошених) у змінній ``afl.margins`` набору даних "
"|aflsmall_margins|"

#: ../../Ch11/Ch11_tTest_08.rst:157
msgid ""
"QQ plot for the (skewed) data in the ``afl.margins`` variable of the |"
"aflsmall_margins|_ data set"
msgstr ""
"Графік QQ для (асимметричних) даних у змінній ``afl.margins`` набору даних "
"|aflsmall_margins|_"

#: ../../Ch11/Ch11_tTest_08.rst:162
msgid ""
"And when we run the Shapiro-Wilk test with ``afl.margins``, we get a value "
"for the Shapiro-Wilk normality test statistic of W = 0.94, and *p*-value = "
"9.481e-07. Clearly a significant effect!"
msgstr ""
"А коли ми запускаємо тест Шапіро-Уілка з ``afl.margins``, ми отримуємо "
"значення для статистики нормальності тесту Шапіро-Уілка W = 0,94 та *p*-"
"значення = 9,481e-07. Очевидно, що це значний ефект!"

#: ../../Ch11/Ch11_tTest_08.rst:169
msgid "This is a massive oversimplification."
msgstr "Це величезне спрощення."

#: ../../Ch11/Ch11_tTest_08.rst:172
msgid ""
"Either that, or the Kolmogorov-Smirnov test, which is probably more "
"traditional than the Shapiro-Wilk. Although most things I’ve read seem to "
"suggest Shapiro-Wilk is the better test of normality, the Kolomogorov-"
"Smirnov is a general purpose test of distributional equivalence that can be "
"adapted to handle other kinds of distribution tests. In jamovi the Shapiro-"
"Wilk test is preferred."
msgstr ""

#: ../../Ch11/Ch11_tTest_09.rst:4
msgid "Testing non-normal data with Wilcoxon tests"
msgstr "Тестування ненормальних даних за допомогою тестів Вілкоксона"

#: ../../Ch11/Ch11_tTest_09.rst:6
msgid ""
"Okay, suppose your data turn out to be pretty substantially non-normal, but "
"you still want to run something like a *t*-test? This situation occurs a lot "
"in real life. For the AFL winning margins data (``afl.margins`` from the |"
"aflsmall_margins|_ data set), for instance, the Shapiro-Wilk test made it "
"very clear that the normality assumption is violated. This is the situation "
"where you want to use Wilcoxon tests."
msgstr ""

#: ../../Ch11/Ch11_tTest_09.rst:13
msgid ""
"Like the *t*-test, the Wilcoxon test comes in two forms, one-sample and two-"
"sample, and they’re used in more or less the exact same situations as the "
"corresponding *t*-tests. Unlike the *t*-test, the Wilcoxon test doesn’t "
"assume normality, which is nice. In fact, they don’t make any assumptions "
"about what kind of distribution is involved. In statistical jargon, this "
"makes them **nonparametric tests**. While avoiding the normality assumption "
"is nice, there’s a drawback: the Wilcoxon test is usually less powerful than "
"the *t*-test (i.e., higher Type II error rate). I won’t discuss the Wilcoxon "
"tests in as much detail as the *t*-tests, but I’ll give you a brief overview."
msgstr ""

#: ../../Ch11/Ch11_tTest_09.rst:26
msgid "Two sample Mann-Whitney U test"
msgstr "Двовибірковий U-критерій Манна-Вітні"

#: ../../Ch11/Ch11_tTest_09.rst:28
msgid ""
"I’ll start by describing the **Mann-Whitney U test**, since it’s actually "
"simpler than the one sample version. Suppose we’re looking at the scores of "
"10 people on some test. Since my imagination has now failed me completely, "
"let’s pretend it’s a “test of awesomeness” and there are two groups of "
"people, “A” and “B”. I’m curious to know which group is more awesome. The "
"data are included in the |awesome|_ data set, and there are two variables "
"apart from the usual ``ID`` variable: ``scores`` |continuous| and ``group`` |"
"nominal|."
msgstr ""

#: ../../Ch11/Ch11_tTest_09.rst:37
msgid ""
"As long as there are no ties (i.e., people with the exact same awesomeness "
"score) then the test that we want to do is surprisingly simple. All we have "
"to do is construct a table that compares every observation in group A "
"against every observation in group B. Whenever the group A datum is larger, "
"we place a check mark in the table:"
msgstr ""

#: ../../Ch11/Ch11_tTest_09.rst:44
msgid "**Group B**"
msgstr "**Група B**"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "14.5"
msgstr "14.5"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "10.4"
msgstr "10.4"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "12.4"
msgstr "12.4"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "11.7"
msgstr "11.7"

#: ../../Ch11/Ch11_tTest_09.rst:46
msgid "13.0"
msgstr "13.0"

#: ../../Ch11/Ch11_tTest_09.rst:52
msgid "**Group A**"
msgstr "**Група A**"

#: ../../Ch11/Ch11_tTest_09.rst:48
msgid "6.4"
msgstr "6.4"

#: ../../Ch11/Ch11_tTest_09.rst:50
msgid "10.7"
msgstr "10.7"

#: ../../Ch11/Ch11_tTest_09.rst:50 ../../Ch11/Ch11_tTest_09.rst:52
#: ../../Ch11/Ch11_tTest_09.rst:94 ../../Ch11/Ch11_tTest_09.rst:96
msgid "✓"
msgstr "✓"

#: ../../Ch11/Ch11_tTest_09.rst:52
msgid "11.9"
msgstr "11.9"

#: ../../Ch11/Ch11_tTest_09.rst:54
msgid "7.3"
msgstr "7.3"

#: ../../Ch11/Ch11_tTest_09.rst:56
msgid "10.0"
msgstr "10.0"

#: ../../Ch11/Ch11_tTest_09.rst:59
msgid ""
"We then count up the number of checkmarks. This is our test statistic, *W*."
"\\ [#]_ The actual sampling distribution for *W* is somewhat complicated, "
"and I’ll skip the details. For our purposes, it’s sufficient to note that "
"the interpretation of *W* is qualitatively the same as the interpretation of "
"*t* or *z*. That is, if we want a two-sided test then we reject the null "
"hypothesis when *W* is very large or very small, but if we have a "
"directional (i.e., one-sided) hypothesis then we only use one or the other."
msgstr ""

#: ../../Ch11/Ch11_tTest_09.rst:67
msgid ""
"In jamovi, if we run an ``Independent Samples T-Test`` with ``scores`` |"
"continuous| as the dependent variable. and ``group`` as the grouping "
"variable |nominal|, and then under the options for ``Tests`` check the "
"option for ``Mann-Whitney U``, we will get results showing that U = 3 (i.e., "
"the same number of check marks as shown above), and a *p*-value = 0.05556."
msgstr ""

#: ../../Ch11/Ch11_tTest_09.rst:74
msgid "One sample Wilcoxon test"
msgstr "Один зразок тесту Вілкоксона"

#: ../../Ch11/Ch11_tTest_09.rst:76
msgid ""
"What about the **one sample Wilcoxon test** (or equivalently, the paired "
"samples Wilcoxon test)? Suppose I’m interested in finding out whether taking "
"a statistics class has any effect on the happiness of students. The |"
"happiness|_ data set contains the happiness of each student ``before`` "
"taking the class |ordinal| and ``after`` taking the class |ordinal|. The "
"``change`` score is the difference between the two. Just like we saw with "
"the *t*-test, there’s no fundamental difference between doing a paired-"
"samples test using ``before`` and ``after``, versus doing a one-sample test "
"using the ``change`` scores. As before, the simplest way to think about the "
"test is to construct a tabulation. The way to do it this time is to take "
"those change scores that are positive differences, and tabulate them against "
"all the complete sample. What you end up with is a table that looks like "
"this:"
msgstr ""

#: ../../Ch11/Ch11_tTest_09.rst:145
msgid "ordinal"
msgstr "ordinal"

#: ../../Ch11/Ch11_tTest_09.rst:90
msgid "all differences"
msgstr "всі відмінності"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-24"
msgstr "-24"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-14"
msgstr "-14"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-10"
msgstr "-10"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "7"
msgstr "7"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-6"
msgstr "-6"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-38"
msgstr "-38"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "2"
msgstr "2"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-35"
msgstr "-35"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "-30"
msgstr "-30"

#: ../../Ch11/Ch11_tTest_09.rst:92
msgid "5"
msgstr "5"

#: ../../Ch11/Ch11_tTest_09.rst:95
msgid "positive differences"
msgstr "позитивні відмінності"

#: ../../Ch11/Ch11_tTest_09.rst:94
msgid "7 2 5"
msgstr "7 2 5"

#: ../../Ch11/Ch11_tTest_09.rst:94
msgid "✓ ✓ ✓"
msgstr "✓ ✓ ✓"

#: ../../Ch11/Ch11_tTest_09.rst:99
msgid ""
"Counting up the tick marks this time we get a test statistic of *W* = 7. As "
"before, if our test is two-sided, then we reject the null hypothesis when "
"*W* is very large or very small. As far as running it in jamovi goes, it’s "
"pretty much what you’d expect. For the one-sample version, you specify the "
"``Wilcoxon rank`` option under ``Tests`` in the ``One Sample *t*-Test`` "
"options panel.This gives you Wilcoxon *W* = 7, *p*-value = 0.03711. As this "
"shows, we have a significant effect. Evidently, taking a statistics class "
"does have an effect on your happiness. Switching to a paired samples version "
"of the test won’t give us a different answer, of course; see :numref:`fig-"
"ttest_nonparametric`."
msgstr ""

#: ../../Ch11/Ch11_tTest_09.rst:112
msgid "Results for one sample and paired sample Wilcoxon non-parametric tests"
msgstr ""
"Результати для одновибіркових та парних вибіркових непараметричних тестів "
"Вілкоксона"

#: ../../Ch11/Ch11_tTest_09.rst:116
msgid ""
"jamovi screen showing results for one sample and paired sample Wilcoxon non-"
"parametric tests"
msgstr ""
"екран jamovi, що показує результати для одного зразка та парних зразків "
"непараметричних тестів Вілкоксона"

#: ../../Ch11/Ch11_tTest_09.rst:124
msgid ""
"Actually, there are two different versions of the test statistic that differ "
"from each other by a constant value. The version that I’ve described is the "
"one that jamovi calculates."
msgstr ""
"Насправді, існують дві різні версії тестової статистики, які відрізняються "
"одна від одної постійним значенням. Версія, яку я описав, — це та, яку "
"обчислює jamovi."

#: ../../Ch11/Ch11_tTest_10.rst:4
msgid "Summary"
msgstr "Короткий зміст"

#: ../../Ch11/Ch11_tTest_10.rst:6
msgid ""
"A :doc:`one sample *t*-test <Ch11_tTest_02>` is used to compare a single "
"sample mean against a hypothesised value for the population mean."
msgstr ""
"Для порівняння середнього значення однієї вибірки з гіпотетичним значенням "
"середнього значення генеральної сукупності використовується :doc:`t*-"
"критерій <Ch11_tTest_02>`."

#: ../../Ch11/Ch11_tTest_10.rst:9
msgid ""
"An :doc:`independent samples *t*-test <Ch11_tTest_03>` is used to compare "
"the means of two groups, and tests the null hypothesis that they have the "
"same mean. It comes in two forms: the :doc:`Student test <Ch11_tTest_03>` "
"assumes that the groups have the same standard deviation, the :doc:`Welch "
"test <Ch11_tTest_04>` does not."
msgstr ""

#: ../../Ch11/Ch11_tTest_10.rst:15
msgid ""
"A :doc:`paired samples *t*-test <Ch11_tTest_05>` is used when you have two "
"scores from each person, and you want to test the null hypothesis that the "
"two scores have the same mean. It is equivalent to taking the difference "
"between the two scores for each person, and then running a one sample *t*-"
"test on the difference scores."
msgstr ""

#: ../../Ch11/Ch11_tTest_10.rst:21
msgid ""
":doc:`Ch11_tTest_06` are perfectly legitimate as long as they are pre-"
"planned."
msgstr ":doc:`Ch11_tTest_06` цілком законні, якщо вони сплановані заздалегідь."

#: ../../Ch11/Ch11_tTest_10.rst:24
msgid ""
":doc:`Ch11_tTest_07` calculations for the difference between means can be "
"calculated via the Cohen’s *d*-statistic."
msgstr ""
":doc:`Ch11_tTest_07` обчислення різниці між середніми значеннями можна "
"виконати за допомогою *d*-статистики Коена."

#: ../../Ch11/Ch11_tTest_10.rst:27
msgid ""
"You can :doc:`check the normality of a sample <Ch11_tTest_08>` using QQ "
"plots and the Shapiro-Wilk test."
msgstr ""
"Ви можете :doc:`перевірити нормальність вибірки <Ch11_tTest_08>` за "
"допомогою QQ-діаграм та тесту Шапіро-Уілка."

#: ../../Ch11/Ch11_tTest_10.rst:30
msgid ""
"If your data are non-normal, you can use :doc:`Mann-Whitney or Wilcoxon "
"tests <Ch11_tTest_09>` instead of *t*-tests."
msgstr ""
"Якщо ваші дані не є нормальними, ви можете використовувати :doc:`тести Манна-"
"Вітні або Вілкоксона <Ch11_tTest_09>` замість *t*-тестів."
