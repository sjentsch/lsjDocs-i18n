msgid ""
msgstr ""
"Project-Id-Version: PROJECT VERSION\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-06-12 11:37+0200\n"
"PO-Revision-Date: 2025-09-03 09:05+0000\n"
"Last-Translator: Максим Горпиніч <gorpinicmaksim0@gmail.com>\n"
"Language-Team: Ukrainian <https://hosted.weblate.org/projects/lsjdocs/ch13/"
"uk/>\n"
"Language: uk\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && "
"n%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2);\n"
"X-Generator: Weblate 5.13.1-dev\n"
"Generated-By: Babel 2.17.0\n"

#: ../../Ch13/Ch13_ANOVA.rst:4
msgid "Comparing several means (one-way ANOVA)"
msgstr "Порівняння кількох середніх значень (однофакторний ANOVA)"

#: ../../Ch13/Ch13_ANOVA.rst:22
msgid ""
"This chapter introduces one of the most widely used tools in psychological "
"statistics, known as “the analysis of variance”, but usually referred to as "
"ANOVA. The basic technique was developed by Sir Ronald Fisher in the early "
"20th century and it is to him that we owe the rather unfortunate "
"terminology. The term ANOVA is a little misleading, in two respects. "
"Firstly, although the name of the technique refers to variances, ANOVA is "
"concerned with investigating differences in means. Secondly, there are "
"several different things out there that are all referred to as ANOVAs, some "
"of which have only a very tenuous connection to one another. Later on in the "
"book we’ll encounter a range of different ANOVA methods that apply in quite "
"different situations, but for the purposes of this chapter we’ll only "
"consider the simplest form of ANOVA, in which we have several different "
"groups of observations, and we’re interested in finding out whether those "
"groups differ in terms of some outcome variable of interest. This is the "
"question that is addressed by a **one-way ANOVA**."
msgstr ""
"У цьому розділі представлено один з найпоширеніших інструментів "
"психологічної статистики, відомий як «аналіз дисперсії», але зазвичай званий "
"ANOVA. Основна техніка була розроблена сером Рональдом Фішером на початку 20 "
"століття, і саме йому ми зобов'язані досить невдалою термінологією. Термін "
"ANOVA є дещо оманливим у двох аспектах. По-перше, хоча назва техніки "
"стосується дисперсій, ANOVA займається дослідженням відмінностей у середніх "
"значеннях. По-друге, існує кілька різних речей, які всі називаються ANOVA, "
"деякі з яких мають лише дуже слабкий зв'язок між собою. Далі в книзі ми "
"зустрінемося з низкою різних методів ANOVA, які застосовуються в досить "
"різних ситуаціях, але для цілей цього розділу ми розглянемо лише найпростішу "
"форму ANOVA, в якій ми маємо кілька різних груп спостережень і нас цікавить, "
"чи відрізняються ці групи за деякими результатами, що нас цікавлять. Це "
"питання вирішується за допомогою **однофакторного ANOVA**."

#: ../../Ch13/Ch13_ANOVA.rst:39
msgid ""
"The structure of this chapter is as follows: in section :doc:`Ch13_ANOVA_01` "
"I’ll introduce a fictitious data set that we’ll use as a running example "
"throughout the chapter. After introducing the data, I’ll describe the "
"mechanics of how a one-way ANOVA actually works (:doc:`Ch13_ANOVA_02`) and "
"then focus on :doc:`how you can run one in jamovi <Ch13_ANOVA_03>`. These "
"two sections are the core of the chapter. The remainder of the chapter "
"discusses a range of important topics that inevitably arise when running an "
"ANOVA, namely how to calculate :doc:`effect sizes <Ch13_ANOVA_04>`, and :doc:"
"`post-hoc tests and corrections for multiple comparisons <Ch13_ANOVA_05>`. "
"Afterwards, we will talk about the :doc:`assumptions the ANOVA relies upon "
"<Ch13_ANOVA_06>`, how to check those assumptions and some of the things you "
"can do if the assumptions are violated. Then we’ll cover :doc:`repeated "
"measures ANOVA <Ch13_ANOVA_07>` and it's non-parametric equivalent, the :doc:"
"`Friedman test <Ch13_ANOVA_08>`."
msgstr ""
"Структура цього розділу така: у розділі :doc:`Ch13_ANOVA_01` Я представлю "
"фіктивний набір даних, який ми використовуватимемо як приклад протягом "
"усього розділу. Після введення даних, Я опишу механіку того, як насправді "
"працює однофакторний дисперсійний аналіз (ANOVA). (:doc:`Ch13_ANOVA_02`) а "
"потім зосередитися на :doc:`how you can run one in jamovi <Ch13_ANOVA_03>`. "
"Ці два розділи є основою цього розділу. У решті розділу обговорюється низка "
"важливих тем, які неминуче виникають під час проведення дисперсійного "
"аналізу (ANOVA), а саме як розрахувати :doc:`effect sizes <Ch13_ANOVA_04>`, "
"і :doc:`post-hoc tests and corrections for multiple comparisons "
"<Ch13_ANOVA_05>`. Після цього ми поговоримо про те, :doc:`assumptions the "
"ANOVA relies upon <Ch13_ANOVA_06>`, як перевірити ці припущення та деякі "
"дії, які можна зробити, якщо припущення порушені. Тоді ми розглянемо :doc:`"
"repeated measures ANOVA <Ch13_ANOVA_07>` і його непараметричний еквівалент, "
":doc:`Friedman test <Ch13_ANOVA_08>`."

#: ../../Ch13/Ch13_ANOVA.rst:54
msgid ""
"At the end of the chapter we’ll talk a little about the :doc:`relationship "
"between ANOVA and other statistical tools <Ch13_ANOVA_09>`."
msgstr ""
"В кінці розділу ми трохи поговоримо про :doc:`relationship between ANOVA and "
"other statistical tools <Ch13_ANOVA_09>`."

#: ../../Ch13/Ch13_ANOVA_01.rst:4
msgid "An illustrative data set"
msgstr "Ілюстративний набір даних"

#: ../../Ch13/Ch13_ANOVA_01.rst:6
msgid ""
"Suppose you’ve become involved in a clinical trial in which you are testing "
"a new antidepressant drug called *Joyzepam*. In order to construct a fair "
"test of the drug’s effectiveness, the study involves three separate drugs to "
"be administered. One is a placebo, and the other is an existing "
"antidepressant / anti-anxiety drug called *Anxifree*. A collection of 18 "
"participants with moderate to severe depression are recruited for your "
"initial testing. Because the drugs are sometimes administered in conjunction "
"with psychological therapy, your study includes 9 people undergoing "
"cognitive behavioural therapy (CBT) and 9 who are not. Participants are "
"randomly assigned (doubly blinded, of course) a treatment, such that there "
"are 3 CBT people and 3 no-therapy people assigned to each of the 3 drugs. A "
"psychologist assesses the mood of each person after a 3 month run with each "
"drug, and the overall *improvement* in each person’s mood is assessed on a "
"scale ranging from -5 to +5. With that as the study design, let’s now load |"
"clinicaltrial|_ data set. It contains the three variables ``drug`` |"
"nominal|, ``therapy`` |nominal| and ``mood.gain`` |continuous|."
msgstr ""
"Припустимо, ви взяли участь у клінічному дослідженні, в рамках якого ви "
"тестуєте новий антидепресант під назвою *Joyzepam*. Щоб провести об'єктивне "
"тестування ефективності препарату, в дослідженні використовуються три окремі "
"препарати. Один з них — плацебо, а інший — існуючий антидепресант/"
"антитривожний препарат під назвою *Anxifree*. Для початкового тестування "
"набирається група з 18 учасників із помірною та тяжкою депресією. Оскільки "
"препарати іноді застосовуються у поєднанні з психологічною терапією, у "
"вашому дослідженні беруть участь 9 осіб, які проходять когнітивно-"
"поведінкову терапію (КПТ), та 9 осіб, які її не проходять. Учасникам "
"випадковим чином (звичайно, за подвійною сліпою методикою) призначається "
"лікування, таким чином, що до кожної з 3 груп препаратів приписано 3 особи, "
"які проходять КПТ, та 3 особи, які не проходять терапію. Психолог оцінює "
"настрій кожної людини після 3 місяців прийому кожного препарату, а загальне "
"*поліпшення* настрою кожної людини оцінюється за шкалою від -5 до +5. З "
"таким дизайном дослідження давайте завантажимо набір даних |clinicaltrial|_. "
"Він містить три змінні: ``drug`` |nominal|, ``therapy`` |nominal| та "
"``mood.gain`` |continuous|."

#: ../../Ch13/Ch13_ANOVA_01.rst:55 ../../Ch13/Ch13_ANOVA_08.rst:48
msgid "nominal"
msgstr "nominal"

#: ../../Ch13/Ch13_ANOVA_01.rst:52
msgid "continuous"
msgstr "continuous"

#: ../../Ch13/Ch13_ANOVA_01.rst:24
msgid ""
"For the purposes of this chapter, what we’re really interested in is the "
"effect of ``drug`` on ``mood.gain``. The first thing to do is calculate some "
"descriptive statistics and draw some graphs. In :doc:`../Ch04/"
"Ch04_Descriptives` we showed you how to do this, and some of the descriptive "
"statistics we can calculate in jamovi are shown in :numref:`fig-anova1`."
msgstr ""
"Для цілей цього розділу нас найбільше цікавить вплив ``drug`` на "
"``mood.gain``. Перше, що потрібно зробити, — це обчислити деякі описові "
"статистичні показники та побудувати графіки. У :doc:`../Ch04/"
"Ch04_Descriptives` ми показали, як це зробити, а деякі описові статистичні "
"показники, які ми можемо обчислити в jamovi, наведено в :numref:`fig-anova1`."

#: ../../Ch13/Ch13_ANOVA_01.rst:33 ../../Ch13/Ch13_ANOVA_01.rst:37
msgid "Descriptives for ``mood.gain``, and box plots by ``drug`` administered"
msgstr ""
"Описи для ``mood.gain``, та коробкові діаграми за допомогою ``drug`` введено"

#: ../../Ch13/Ch13_ANOVA_01.rst:41
msgid ""
"As the plot makes clear, there is a larger improvement in mood for "
"participants in the ``joyzepam`` group than for either the ``anxifree`` "
"group or the ``placebo`` group. The ``anxifree`` group shows a larger mood "
"gain than the ``placebo`` group, but the difference isn’t as large. The "
"question that we want to answer is are these difference “real”, or are they "
"just due to chance?"
msgstr ""
"Як видно з графіку, учасники групи ``joyzepam`` демонструють більш значне "
"поліпшення настрою, ніж учасники груп ``anxifree`` та ``placebo``. Група "
"``anxifree`` демонструє більш значне поліпшення настрою, ніж група "
"``placebo``, але різниця не така велика. Питання, на яке ми хочемо "
"відповісти, полягає в тому, чи є ці відмінності «реальними», чи вони є лише "
"випадковими?"

#: ../../Ch13/Ch13_ANOVA_02.rst:4
msgid "How ANOVA works"
msgstr "Як працює дисперсійний аналіз (ANOVA)"

#: ../../Ch13/Ch13_ANOVA_02.rst:6
msgid ""
"In order to answer the question posed by our |clinicaltrial|_ data we’re "
"going to run a one-way ANOVA. I’m going to start by showing you how to do it "
"the hard way, building the statistical tool from the ground up and showing "
"you how you could do it if you didn’t have access to any of the cool built-"
"in ANOVA functions in jamovi. And I hope you’ll read it carefully, try to do "
"it the long way once or twice to make sure you really understand how ANOVA "
"works, and then once you’ve grasped the concept never *ever* do it this way "
"again."
msgstr ""
"Щоб відповісти на питання, поставлене нашими даними |clinicaltrial|_, ми "
"проведемо однофакторний дисперсійний аналіз ANOVA. Я почну з того, що покажу "
"вам, як це зробити складнішим способом, створивши статистичний інструмент з "
"нуля і продемонструвавши, як це можна зробити, якщо у вас немає доступу до "
"жодної з вбудованих функцій ANOVA в jamovi. Я сподіваюся, що ви уважно "
"прочитаєте цю статтю, спробуєте зробити це складним способом один або два "
"рази, щоб переконатися, що ви дійсно розумієте, як працює ANOVA, а потім, "
"коли ви зрозумієте концепцію, *ніколи* не робіть це таким способом знову."

#: ../../Ch13/Ch13_ANOVA_02.rst:15
msgid ""
"The experimental design that I described in the previous section strongly "
"suggests that we’re interested in comparing the average mood change for the "
"three different drugs. In that sense, we’re talking about an analysis "
"similar to the *t*-test (chapter :doc:`../Ch11/Ch11_tTest`) but involving "
"more than two groups. If we let µ\\ :sub:`P` denote the population mean for "
"the mood change induced by the placebo, and let µ\\ :sub:`A` and µ\\ :sub:"
"`J` denote the corresponding means for our two drugs, Anxifree and Joyzepam, "
"then the (somewhat pessimistic) null hypothesis that we want to test is that "
"all three population means are identical. That is, *neither* of the two "
"drugs is any more effective than a placebo. We can write out this null "
"hypothesis as:"
msgstr ""
"Експериментальний дизайн, який я описав у попередньому розділі, чітко вказує "
"на те, що нас цікавить порівняння середньої зміни настрою для трьох різних "
"препаратів. У цьому сенсі ми говоримо про аналіз, подібний до *t*-тесту ("
"розділ :doc:`../Ch11/Ch11_tTest`), але з участю більше ніж двох груп. Якщо "
"позначити µ\\ :sub:`P` середнім значенням зміни настрою, спричиненої "
"плацебо, а µ\\ :sub:`A` і µ\\ :sub:`J` — відповідними середніми значеннями "
"для наших двох препаратів, Anxifree і Joyzepam, то (дещо песимістичною) "
"нульовою гіпотезою, яку ми хочемо перевірити, є те, що всі три середні "
"значення є однаковими. Тобто *жоден* з двох препаратів не є ефективнішим за "
"плацебо. Ми можемо записати цю нульову гіпотезу так:"

#: ../../Ch13/Ch13_ANOVA_02.rst:26
msgid ""
"H\\ :sub:`0`: it is true that µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`"
msgstr "H\\ :sub:`0`: це правда, що µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`"

#: ../../Ch13/Ch13_ANOVA_02.rst:28
msgid ""
"As a consequence, our alternative hypothesis is that at least one of the "
"three different treatments is different from the others. It’s a bit tricky "
"to write this mathematically, because (as we’ll discuss) there are quite a "
"few different ways in which the null hypothesis can be false. So for now "
"we’ll just write the alternative hypothesis like this:"
msgstr ""
"Як наслідок, наша альтернативна гіпотеза полягає в тому, що принаймні один "
"із трьох різних методів лікування відрізняється від інших. Математично це "
"трохи складно викласти, оскільки (як ми обговоримо далі) існує чимало різних "
"способів, за яких нульова гіпотеза може бути хибною. Тому наразі ми просто "
"запишемо альтернативну гіпотезу так:"

#: ../../Ch13/Ch13_ANOVA_02.rst:34
msgid ""
"H\\ :sub:`1`: it is NOT true that µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`"
msgstr ""
"H\\ :sub:`1`: це НЕ правда, що µ\\ :sub:`P` = µ\\ :sub:`A` = µ\\ :sub:`J`"

#: ../../Ch13/Ch13_ANOVA_02.rst:36
msgid ""
"This null hypothesis is a lot trickier to test than any of the ones we’ve "
"seen previously. How shall we do it? A sensible guess would be to “do an "
"ANOVA”, since that’s the title of the chapter, but it’s not particularly "
"clear why an “analysis of *variances*” will help us learn anything useful "
"about the *means*. In fact, this is one of the biggest conceptual "
"difficulties that people have when first encountering ANOVA. To see how this "
"works, I find it most helpful to start by talking about variances. In fact, "
"what I’m going to do is start by playing some mathematical games with the "
"formula that describes the variance. That is, we’ll start out by playing "
"around with variances and it will turn out that this gives us a useful tool "
"for investigating means."
msgstr ""
"Ця нульова гіпотеза набагато складніша для перевірки, ніж будь-яка з тих, "
"які ми бачили раніше. Як нам це зробити? Розумним припущенням було б «"
"провести ANOVA», оскільки це назва розділу, але не зовсім зрозуміло, чому «"
"аналіз *дисперсій*» допоможе нам дізнатися щось корисне про *середні "
"значення*. Насправді, це одна з найбільших концептуальних труднощів, з якими "
"стикаються люди, коли вперше стикаються з ANOVA. Щоб зрозуміти, як це "
"працює, я вважаю за найбільш корисним почати з розмови про дисперсії. "
"Насправді, я почну з математичних ігор з формулою, що описує дисперсію. "
"Тобто, ми почнемо з ігор з дисперсіями, і виявиться, що це дає нам корисний "
"інструмент для дослідження середніх значень."

#: ../../Ch13/Ch13_ANOVA_02.rst:49
msgid "Two formulas for the variance of *Y*"
msgstr "Дві формули для дисперсії *Y*"

#: ../../Ch13/Ch13_ANOVA_02.rst:51
msgid ""
"First, let’s start by introducing some notation. We’ll use *G* to refer to "
"the total number of groups. For our data set there are three drugs, so there "
"are *G* = 3 groups. Next, we’ll use *N* to refer to the total sample size; "
"there are a total of *N* = 18 people in our data set. Similarly, let’s use |"
"N_k| to denote the number of people in the *k*-th group. In our |"
"clinicaltrial|_ data, the sample size is |N_k| = 6` for all three groups.\\ "
"[#]_ Finally, we’ll use *Y* to denote the outcome variable. In our case, *Y* "
"refers to mood change. Specifically, we’ll use |Y_ik| to refer to the mood "
"change experienced by the *i*-th member of the *k*-th group. Similarly, "
"we’ll use |Yb| to be the average mood change, taken across all 18 people in "
"the experiment, and |Yb_k| to refer to the average mood change experienced "
"by the 6 people in group *k*."
msgstr ""
"Спочатку давайте ознайомимося з деякими позначеннями. Ми будемо "
"використовувати *G* для позначення загальної кількості груп. У нашому наборі "
"даних є три препарати, отже, є *G* = 3 групи. Далі ми будемо використовувати "
"*N* для позначення загального розміру вибірки; у нашому наборі даних є "
"загалом *N* = 18 осіб. Аналогічно, позначимо |N_k| для позначення кількості "
"осіб у *k*-й групі. У наших даних |clinicaltrial|_ розмір вибірки становить "
"|N_k| = 6` для всіх трьох груп.\\ [#]_ Нарешті, позначимо *Y* для позначення "
"змінної результату. У нашому випадку *Y* позначає зміну настрою. Зокрема, ми "
"будемо використовувати |Y_ik| для позначення зміни настрою, яку відчуває *i*-"
"й член *k*-ї групи. Аналогічно, ми будемо використовувати |Yb| для "
"позначення середньої зміни настрою, взятої по всіх 18 особах в експерименті, "
"і |Yb_k| для позначення середньої зміни настрою, яку відчувають 6 осіб в "
"групі *k*."

#: ../../Ch13/Ch13_ANOVA_02.rst:66
msgid ""
"Now that we’ve got our notation sorted out we can start writing down "
"formulas. To start with, let’s recall the :ref:`formula for the variance "
"<variance_formula>` that we used way back in those kinder days when we were "
"just doing descriptive statistics. The sample variance of *Y* is defined as "
"follows:"
msgstr ""
"Тепер, коли ми розібралися з позначеннями, можемо приступити до запису "
"формул. Для початку згадаємо :ref:`formula for the variance "
"<variance_formula>`, яку ми використовували в ті далекі часи, коли займалися "
"лише описовою статистикою. Вибіркова дисперсія *Y* визначається наступним "
"чином:"

#: ../../Ch13/Ch13_ANOVA_02.rst:72
msgid ""
"\\mbox{Var}(Y) = \\frac{1}{N} \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left(Y_{ik} "
"- \\bar{Y} \\right)^2\n"
"\n"
msgstr ""
"\\mbox{Var}(Y) = \\frac{1}{N} \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left(Y_{ik} -"
" \\bar{Y} \\right)^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:74
msgid ""
"This formula looks pretty much identical to the :ref:`formula for the "
"variance <variance_formula>`. The only difference is that this time around "
"I’ve got two summations here: I’m summing over groups (i.e., values for *k*) "
"and over the people within the groups (i.e., values for *:`i*). This is "
"purely a cosmetic detail. If I’d instead used the notation |Y_p| to refer to "
"the value of the outcome variable for person *p* in the sample, then I’d "
"only have a single summation. The only reason that we have a double "
"summation here is that I’ve classified people into groups, and then assigned "
"numbers to people within groups."
msgstr ""
"Ця формула виглядає майже ідентично до :ref:`formula for the variance "
"<variance_formula>`. Єдина відмінність полягає в тому, що цього разу я маю "
"тут два підсумки: я підсумовую групи (тобто значення для *k*) і людей у "
"групах (тобто значення для *:`i*). Це суто косметична деталь. Якби я замість "
"цього використовував позначення |Y_p| для позначення значення змінної "
"результату для особи *p* у вибірці, то мав би лише одне підсумовування. "
"Єдина причина, чому ми маємо тут подвійне підсумовування, полягає в тому, що "
"я класифікував осіб за групами, а потім присвоїв номери особам у групах."

#: ../../Ch13/Ch13_ANOVA_02.rst:84
msgid ""
"A concrete example might be useful here. Let’s consider this table, in which "
"we have a total of *N* = 5 people sorted into *G* = 2 groups. Arbitrarily, "
"let’s say that the “cool” people are group 1 and the “uncool” people are "
"group 2. It turns out that we have three cool people (*N*\\ :sub:`1` = 3) "
"and two uncool people (*N*\\ :sub:`2` = 2)."
msgstr ""
"Тут може бути корисним конкретний приклад. Розглянемо цю таблицю, в якій ми "
"маємо загалом *N* = 5 осіб, розділених на *G* = 2 групи. Довільно "
"припустимо, що «круті» люди — це група 1, а «некруті» — група 2. "
"Виявляється, що у нас є три круті людини (*N*\\ :sub:`1` = 3) і дві некруті "
"(*N*\\ :sub:`2` = 2)."

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "name"
msgstr "ім'я"

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "person"
msgstr "людина"

#: ../../Ch13/Ch13_ANOVA_02.rst:91 ../../Ch13/Ch13_ANOVA_02.rst:397
#: ../../Ch13/Ch13_ANOVA_02.rst:423 ../../Ch13/Ch13_ANOVA_02.rst:444
#: ../../Ch13/Ch13_ANOVA_02.rst:490 ../../Ch13/Ch13_ANOVA_02.rst:520
msgid "group"
msgstr "група"

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "group num."
msgstr "номер групи."

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "index in group"
msgstr "індекс у групі"

#: ../../Ch13/Ch13_ANOVA_02.rst:91
msgid "grumpiness"
msgstr "сварливість"

#: ../../Ch13/Ch13_ANOVA_02.rst:93
msgid "*p*"
msgstr "*p*"

#: ../../Ch13/Ch13_ANOVA_02.rst:93 ../../Ch13/Ch13_ANOVA_02.rst:399
#: ../../Ch13/Ch13_ANOVA_02.rst:425 ../../Ch13/Ch13_ANOVA_02.rst:446
#: ../../Ch13/Ch13_ANOVA_02.rst:492 ../../Ch13/Ch13_ANOVA_02.rst:522
msgid "*k*"
msgstr "*k*"

#: ../../Ch13/Ch13_ANOVA_02.rst:93
msgid "*i*"
msgstr "*i*"

#: ../../Ch13/Ch13_ANOVA_02.rst:93
msgid "|Y_ik| or |Y_p|"
msgstr "|Y_ik| або |Y_p|"

#: ../../Ch13/Ch13_ANOVA_02.rst:95
msgid "Ann"
msgstr "Енн"

#: ../../Ch13/Ch13_ANOVA_02.rst:95 ../../Ch13/Ch13_ANOVA_02.rst:97
#: ../../Ch13/Ch13_ANOVA_02.rst:99 ../../Ch13/Ch13_ANOVA_02.rst:101
#: ../../Ch13/Ch13_ANOVA_05.rst:43 ../../Ch13/Ch13_ANOVA_05.rst:206
#: ../../Ch13/Ch13_ANOVA_06.rst:333 ../../Ch13/Ch13_ANOVA_07.rst:66
msgid "1"
msgstr "1"

#: ../../Ch13/Ch13_ANOVA_02.rst:95 ../../Ch13/Ch13_ANOVA_02.rst:97
#: ../../Ch13/Ch13_ANOVA_02.rst:99
msgid "cool"
msgstr "круто"

#: ../../Ch13/Ch13_ANOVA_02.rst:95
msgid "20"
msgstr "20"

#: ../../Ch13/Ch13_ANOVA_02.rst:97
msgid "Ben"
msgstr "Бен"

#: ../../Ch13/Ch13_ANOVA_02.rst:97 ../../Ch13/Ch13_ANOVA_02.rst:101
#: ../../Ch13/Ch13_ANOVA_02.rst:103 ../../Ch13/Ch13_ANOVA_02.rst:596
#: ../../Ch13/Ch13_ANOVA_05.rst:45 ../../Ch13/Ch13_ANOVA_05.rst:204
#: ../../Ch13/Ch13_ANOVA_06.rst:333 ../../Ch13/Ch13_ANOVA_07.rst:68
#: ../../Ch13/Ch13_ANOVA_07.rst:74
msgid "2"
msgstr "2"

#: ../../Ch13/Ch13_ANOVA_02.rst:97
msgid "55"
msgstr "55"

#: ../../Ch13/Ch13_ANOVA_02.rst:99
msgid "Cat"
msgstr "Кіт"

#: ../../Ch13/Ch13_ANOVA_02.rst:99 ../../Ch13/Ch13_ANOVA_05.rst:47
#: ../../Ch13/Ch13_ANOVA_05.rst:202 ../../Ch13/Ch13_ANOVA_07.rst:70
msgid "3"
msgstr "3"

#: ../../Ch13/Ch13_ANOVA_02.rst:99
msgid "21"
msgstr "21"

#: ../../Ch13/Ch13_ANOVA_02.rst:101
msgid "Tim"
msgstr "Тім"

#: ../../Ch13/Ch13_ANOVA_02.rst:101 ../../Ch13/Ch13_ANOVA_05.rst:49
#: ../../Ch13/Ch13_ANOVA_05.rst:200 ../../Ch13/Ch13_ANOVA_07.rst:72
#: ../../Ch13/Ch13_ANOVA_07.rst:76
msgid "4"
msgstr "4"

#: ../../Ch13/Ch13_ANOVA_02.rst:101 ../../Ch13/Ch13_ANOVA_02.rst:103
msgid "uncool"
msgstr "некрутий"

#: ../../Ch13/Ch13_ANOVA_02.rst:101
msgid "91"
msgstr "91"

#: ../../Ch13/Ch13_ANOVA_02.rst:103
msgid "Egg"
msgstr "Яйце"

#: ../../Ch13/Ch13_ANOVA_02.rst:103 ../../Ch13/Ch13_ANOVA_05.rst:51
#: ../../Ch13/Ch13_ANOVA_05.rst:198 ../../Ch13/Ch13_ANOVA_07.rst:70
#: ../../Ch13/Ch13_ANOVA_07.rst:72 ../../Ch13/Ch13_ANOVA_07.rst:74
msgid "5"
msgstr "5"

#: ../../Ch13/Ch13_ANOVA_02.rst:103
msgid "22"
msgstr "22"

#: ../../Ch13/Ch13_ANOVA_02.rst:106
msgid ""
"Notice that I’ve constructed two different labelling schemes here. We have a "
"“person” variable *p* so it would be perfectly sensible to refer to |Y_p| as "
"the grumpiness of the *p*-th person in the sample. For instance, the table "
"shows that Tim is the fourth so we’d say *p* = 4. So, when talking about the "
"grumpiness *Y* of this “Tim” person, whoever he might be, we could refer to "
"his grumpiness by saying that |Y_p| = 91, for person *p* = 4 that is. "
"However, that’s not the only way we could refer to Tim. As an alternative we "
"could note that Tim belongs to the “uncool” group (*k* = 2), and is in fact "
"the first person listed in the “uncool” group (*i* = 1). So it’s equally "
"valid to refer to Tim’s grumpiness by saying that |Y_ik| = 91, where *k* = 2 "
"and *i* = 1."
msgstr ""
"Зверніть увагу, що я створив тут дві різні схеми маркування. Ми маємо змінну "
"«особа» *p*, тому цілком логічно було б називати |Y_p| «буркотливістю» *p*-ї "
"особи у вибірці. Наприклад, таблиця показує, що Тім є четвертим, тому ми "
"скажемо, що *p* = 4. Отже, коли ми говоримо про дратівливість *Y* цієї особи "
"«Тім», ким би він не був, ми можемо позначити його дратівливість, сказавши, "
"що |Y_p| = 91, тобто для особи *p* = 4. Однак це не єдиний спосіб позначити "
"Тіма. Як альтернативу, ми можемо зазначити, що Тім належить до групи "
"«некрутих» (*k* = 2) і, фактично, є першою особою в списку групи «некрутих» "
"(*i* = 1). Тому також можна вказати на буркотливість Тіма, сказавши, що "
"|Y_ik| = 91, де *k* = 2 і *i* = 1."

#: ../../Ch13/Ch13_ANOVA_02.rst:119
msgid ""
"In other words, each person *p* corresponds to a unique *ik* combination, "
"and so the formula that I gave above is actually identical to our original "
"formula for the variance, which would be"
msgstr ""
"Іншими словами, кожній особі *p* відповідає унікальна комбінація *ik*, тому "
"формула, яку я навів вище, фактично ідентична нашій початковій формулі для "
"дисперсії, яка була б"

#: ../../Ch13/Ch13_ANOVA_02.rst:123
msgid ""
"\\mbox{Var}(Y) = \\frac{1}{N} \\sum_{p=1}^N  \\left(Y_{p} - \\bar{Y} "
"\\right)^2\n"
"\n"
msgstr ""
"\\mbox{Var}(Y) = \\frac{1}{N} \\sum_{p=1}^N  \\left(Y_{p} - \\bar{Y} \\right"
")^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:125
msgid ""
"In both formulas, all we’re doing is summing over all of the observations in "
"the sample. Most of the time we would just use the simpler |Y_p| notation; "
"the equation using |Y_p| is clearly the simpler of the two. However, when "
"doing an ANOVA it’s important to keep track of which participants belong in "
"which groups, and we need to use the |Y_ik| notation to do this."
msgstr ""
"В обох формулах ми просто підсумовуємо всі спостереження у вибірці. У "
"більшості випадків ми просто використовуємо простішу нотацію |Y_p|; рівняння "
"з використанням |Y_p| є очевидно простішим з двох. Однак під час проведення "
"ANOVA важливо відстежувати, які учасники належать до яких груп, і для цього "
"нам потрібно використовувати нотацію |Y_ik|."

#: ../../Ch13/Ch13_ANOVA_02.rst:133
msgid "From variances to sums of squares"
msgstr "Від дисперсій до сум квадратів"

#: ../../Ch13/Ch13_ANOVA_02.rst:135
msgid ""
"Okay, now that we’ve got a good grasp on how the variance is calculated, "
"let’s define something called the **total sum of squares**, which is denoted "
"|SS_t|\\. This is very simple. Instead of averaging the squared deviations, "
"which is what we do when calculating the variance, we just add them up."
msgstr ""
"Гаразд, тепер, коли ми добре розуміємо, як обчислюється дисперсія, давайте "
"визначимо поняття **загальної суми квадратів**, яке позначається |SS_t|\\. "
"Це дуже просто. Замість того, щоб обчислювати середнє значення квадратів "
"відхилень, як ми робимо при обчисленні дисперсії, ми просто додаємо їх."

#: ../../Ch13/Ch13_ANOVA_02.rst:141
msgid ""
"So the formula for the total sum of squares is almost identical to the "
"formula for the variance"
msgstr ""
"Отже, формула для загальної суми квадратів майже ідентична формулі для "
"дисперсії"

#: ../../Ch13/Ch13_ANOVA_02.rst:144
msgid ""
"\\mbox{SS}_{tot} = \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left(Y_{ik} - \\bar{Y} "
"\\right)^2\n"
"\n"
msgstr ""
"\\mbox{SS}_{tot} = \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left(Y_{ik} - \\bar{Y} "
"\\right)^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:146
msgid ""
"When we talk about analysing variances in the context of ANOVA, what we’re "
"really doing is working with the total sums of squares rather than the "
"actual variance. One very nice thing about the total sum of squares is that "
"we can break it up into two different kinds of variation."
msgstr ""
"Коли ми говоримо про аналіз дисперсій в контексті ANOVA, насправді ми "
"працюємо з сумарними квадратами, а не з фактичною дисперсією. Однією з дуже "
"приємних особливостей сумарних квадратів є те, що ми можемо розділити їх на "
"два різних види варіацій."

#: ../../Ch13/Ch13_ANOVA_02.rst:151
msgid ""
"First, we can talk about the **within-group sum of squares**, in which we "
"look to see how different each individual person is from their own group mean"
msgstr ""
"Спочатку ми можемо поговорити про **суму квадратів всередині групи**, за "
"допомогою якої ми дивимося, наскільки кожна окрема людина відрізняється від "
"середнього значення для її власної групи"

#: ../../Ch13/Ch13_ANOVA_02.rst:155
msgid ""
"\\mbox{SS}_w = \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left( Y_{ik} - \\bar{Y}_k "
"\\right)^2\n"
"\n"
msgstr ""
"\\mbox{SS}_w = \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left( Y_{ik} - \\bar{Y}_k "
"\\right)^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:157
msgid ""
"where |Yb_k| is a group mean. In our example, |Yb_k| would be the average "
"mood change experienced by those people given the *k*-th drug. So, instead "
"of comparing individuals to the average of all people in the experiment, "
"we’re only comparing them to those people in the the same group. As a "
"consequence, you’d expect the value of |SS_w| to be smaller than the total "
"sum of squares, because it’s completely ignoring any group differences, i."
"e., whether the drugs will have different effects on people’s moods."
msgstr ""
"де |Yb_k| є середнім значенням групи. У нашому прикладі |Yb_k| буде "
"середньою зміною настрою, яку відчувають люди, яким було призначено *k*-й "
"препарат. Отже, замість того, щоб порівнювати окремих осіб із середнім "
"значенням усіх учасників експерименту, ми порівнюємо їх лише з тими людьми, "
"які належать до тієї самої групи. Як наслідок, можна очікувати, що значення "
"|SS_w| буде меншим за загальну суму квадратів, оскільки воно повністю "
"ігнорує будь-які групові відмінності, тобто те, чи матимуть препарати різний "
"вплив на настрій людей."

#: ../../Ch13/Ch13_ANOVA_02.rst:165
msgid ""
"Next, we can define a third notion of variation which captures *only* the "
"differences between groups. We do this by looking at the differences between "
"the group means |Yb_k| and grand mean |Yb|."
msgstr ""
"Далі ми можемо визначити третє поняття варіації, яке охоплює *лише* "
"відмінності між групами. Ми робимо це, розглядаючи відмінності між середніми "
"значеннями групи |Yb_k| та загальним середнім значенням |Yb|."

#: ../../Ch13/Ch13_ANOVA_02.rst:169
msgid ""
"In order to quantify the extent of this variation, what we do is calculate "
"the **between-group sum of squares**"
msgstr ""
"Щоб кількісно оцінити ступінь цієї варіації, ми обчислюємо **міжгрупову суму "
"квадратів**"

#: ../../Ch13/Ch13_ANOVA_02.rst:172
msgid ""
"\\begin{aligned}\n"
"\\mbox{SS}_{b} &=& \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left( \\bar{Y}_k - "
"\\bar{Y} \\right)^2 \\\\\n"
"              &=& \\sum_{k=1}^G N_k \\left( \\bar{Y}_k - \\bar{Y} "
"\\right)^2\\end{aligned}"
msgstr ""
"\\begin{aligned}\n"
"\\mbox{SS}_{b} &=& \\sum_{k=1}^G \\sum_{i=1}^{N_k} \\left( \\bar{Y}_k - \\bar"
"{Y} \\right)^2 \\\\\n"
"              &=& \\sum_{k=1}^G N_k \\left( \\bar{Y}_k - \\bar{Y} \\right)^"
"2\\end{aligned}"

#: ../../Ch13/Ch13_ANOVA_02.rst:178
msgid ""
"It’s not too difficult to show that the total variation among people in the "
"experiment |SS_t| is actually the sum of the differences between the groups |"
"SS_b| and the variation inside the groups |SS_w|. That is,"
msgstr ""
"Неважко показати, що загальна варіація між людьми в експерименті |SS_t| "
"насправді є сумою різниць між групами |SS_b| та варіацією всередині груп "
"|SS_w|. Тобто,"

#: ../../Ch13/Ch13_ANOVA_02.rst:182
msgid "|SS_w| + |SS_b| = |SS_t|"
msgstr "|SS_w| + |SS_b| = |SS_t|"

#: ../../Ch13/Ch13_ANOVA_02.rst:184
msgid "Yay."
msgstr "Ура."

#: ../../Ch13/Ch13_ANOVA_02.rst:188
msgid "Illustration of between and within groups variation"
msgstr "Ілюстрація варіацій між групами та всередині груп"

#: ../../Ch13/Ch13_ANOVA_02.rst:192
msgid ""
"Graphical illustration of “between groups” variation (left panel) and "
"“within groups” variation (right panel). In the left panel, the arrows show "
"the differences in the group means. In the right panel, the arrows highlight "
"the variability within each group."
msgstr ""
"Графічна ілюстрація варіації «між групами» (ліва панель) та варіації «"
"всередині груп» (права панель). На лівій панелі стрілки показують різницю в "
"середніх значеннях груп. На правій панелі стрілки підкреслюють варіативність "
"всередині кожної групи."

#: ../../Ch13/Ch13_ANOVA_02.rst:199
msgid ""
"Okay, so what have we found out? We’ve discovered that the total variability "
"associated with the outcome variable (|SS_t|\\) can be mathematically carved "
"up into the sum of “the variation due to the differences in the sample means "
"for the different groups” (|SS_b|\\) plus “all the rest of the variation” (|"
"SS_w|\\).\\ [#]_"
msgstr ""
"Гаразд, що ми з'ясували? Ми виявили, що загальна мінливість, пов'язана з "
"результатною змінною (|SS_t|), може бути математично розбита на суму «"
"варіації, зумовленої різницями в середніх значеннях вибірки для різних груп» "
"(|SS_b|) та «всієї решти варіації» (|SS_w|).\\ [#]_"

#: ../../Ch13/Ch13_ANOVA_02.rst:206
msgid ""
"How does that help me find out whether the groups have different population "
"means? Um. Wait. Hold on a second. Now that I think about it, this is "
"*exactly* what we were looking for. If the null hypothesis is true then "
"you’d expect all the sample means to be pretty similar to each other, right? "
"And that would imply that you’d expect |SS_b| to be really small, or at "
"least you’d expect it to be a lot smaller than “the variation associated "
"with everything else”, |SS_w|\\. Hmm. I detect a hypothesis test coming on."
msgstr ""
"Як це допоможе мені з'ясувати, чи мають групи різні середні значення "
"популяції? Гм. Зачекайте. Зараз, коли я про це думаю, це *саме* те, що ми "
"шукали. Якщо нульова гіпотеза є правдивою, то можна очікувати, що всі "
"середні значення вибірки будуть досить схожими між собою, чи не так? А це "
"означало б, що |SS_b| має бути дуже малим, або принаймні набагато меншим за «"
"варіацію, пов'язану з усім іншим», |SS_w|\\. Гм. Я відчуваю, що наближається "
"перевірка гіпотези."

#: ../../Ch13/Ch13_ANOVA_02.rst:215
msgid "From sums of squares to the *F*-test"
msgstr "Від сум квадратів до *F*-тесту"

#: ../../Ch13/Ch13_ANOVA_02.rst:217
msgid ""
"As we saw in the last section, the *qualitative* idea behind ANOVA is to "
"compare the two sums of squares values |SS_b| and |SS_w| to each other. If "
"the between-group variation |SS_b| is large relative to the within-group "
"variation |SS_w| then we have reason to suspect that the population means "
"for the different groups aren’t identical to each other. In order to convert "
"this into a workable hypothesis test, there’s a little bit of “fiddling "
"around” needed. What I’ll do is first show you *what* we do to calculate our "
"test statistic, the **F-ratio**, and then try to give you a feel for *why* "
"we do it this way."
msgstr ""
"Як ми бачили в попередньому розділі, *якісна* ідея, що лежить в основі "
"ANOVA, полягає в порівнянні двох сум квадратів значень |SS_b| та |SS_w| між "
"собою. Якщо міжгрупова варіація |SS_b| є великою порівняно з "
"внутрішньогруповою варіацією |SS_w|, то ми маємо підстави підозрювати, що "
"середні значення популяції для різних груп не є ідентичними між собою. Щоб "
"перетворити це на працездатний гіпотетичний тест, потрібно трохи "
"«поекспериментувати». Спочатку я покажу вам, *що* ми робимо, щоб обчислити "
"нашу тестову статистику, **F-коефіцієнт**, а потім спробую пояснити, *чому* "
"ми робимо це саме так."

#: ../../Ch13/Ch13_ANOVA_02.rst:228
msgid ""
"In order to convert our SS values into an *F*-ratio the first thing we need "
"to calculate is the **degrees of freedom** associated with the |SS_b| and |"
"SS_w| values. As usual, the degrees of freedom corresponds to the number of "
"unique “data points” that contribute to a particular calculation, minus the "
"number of “constraints” that they need to satisfy. For the within-groups "
"variability what we’re calculating is the variation of the individual "
"observations (*N* data points) around the group means (*G* constraints). In "
"contrast, for the between groups variability we’re interested in the "
"variation of the group means (*G* data points) around the grand mean (1 "
"constraint). Therefore, the degrees of freedom here are:"
msgstr ""
"Щоб перетворити наші значення SS у коефіцієнт *F*, спочатку потрібно "
"обчислити **ступені свободи**, пов'язані із значеннями |SS_b| та |SS_w|. Як "
"зазвичай, ступені свободи відповідають кількості унікальних «точок даних», "
"які впливають на конкретний розрахунок, мінус кількість «обмежень», яким "
"вони повинні відповідати. Для внутрішньогрупової мінливості ми обчислюємо "
"варіацію окремих спостережень (*N* точок даних) навколо середніх значень "
"групи (*G* обмежень). На відміну від цього, для міжгрупової мінливості нас "
"цікавить варіація середніх значень групи (*G* точок даних) навколо "
"загального середнього значення (1 обмеження). Отже, ступені свободи тут такі:"

#: ../../Ch13/Ch13_ANOVA_02.rst:241 ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "|df_b| = *G* - 1"
msgstr "|df_b| = *G* - 1"

#: ../../Ch13/Ch13_ANOVA_02.rst:242 ../../Ch13/Ch13_ANOVA_02.rst:290
msgid "|df_w| = *N* - *G*"
msgstr "|df_w| = *N* - *G*"

#: ../../Ch13/Ch13_ANOVA_02.rst:244
msgid ""
"Okay, that seems simple enough. What we do next is convert our summed "
"squares value into a “mean squares” value, which we do by dividing by the "
"degrees of freedom:"
msgstr ""
"Гаразд, це здається досить простим. Далі ми перетворюємо значення "
"підсумованих квадратів на значення «середніх квадратів», ділячи його на "
"кількість ступенів свободи:"

#: ../../Ch13/Ch13_ANOVA_02.rst:248 ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "|MS_b| = |SS_b| / |df_b|"
msgstr "|MS_b| = |SS_b| / |df_b|"

#: ../../Ch13/Ch13_ANOVA_02.rst:249 ../../Ch13/Ch13_ANOVA_02.rst:290
msgid "|MS_w| = |SS_w| / |df_w|"
msgstr "|MS_w| = |SS_w| / |df_w|"

#: ../../Ch13/Ch13_ANOVA_02.rst:251
msgid ""
"Finally, we calculate the *F*-ratio by dividing the between-groups MS by the "
"within-groups MS:"
msgstr ""
"Нарешті, ми обчислюємо *F*-співвідношення, ділячи міжгрупову MS на "
"внутрішньогрупову MS:"

#: ../../Ch13/Ch13_ANOVA_02.rst:254 ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "F = |MS_b| / |MS_w|"
msgstr "F = |MS_b| / |MS_w|"

#: ../../Ch13/Ch13_ANOVA_02.rst:256
msgid ""
"At a very general level, the intuition behind the *F*-statistic is "
"straightforward. Bigger values of *F* means that the between-groups "
"variation is large relative to the within-groups variation. As a "
"consequence, the larger the value of *F* the more evidence we have against "
"the null hypothesis. But how large does *F* have to be in order to actually "
"*reject* H\\ :sub:`0`? In order to understand this, you need a slightly "
"deeper understanding of what ANOVA is and what the mean squares values "
"actually are."
msgstr ""
"На дуже загальному рівні інтуїція, що лежить в основі *F*-статистики, є "
"досить простою. Більші значення *F* означають, що міжгрупова варіація є "
"великою порівняно з внутрішньогруповою варіацією. Як наслідок, чим більше "
"значення *F*, тим більше доказів ми маємо проти нульової гіпотези. Але "
"наскільки великим має бути *F*, щоб фактично *відхилити* H\\ :sub:`0`? Щоб "
"це зрозуміти, потрібно трохи глибше зрозуміти, що таке ANOVA і що таке "
"середні квадратичні значення."

#: ../../Ch13/Ch13_ANOVA_02.rst:265
msgid ""
"The next section discusses that in a bit of detail, but for readers that "
"aren’t interested in the details of what the test is actually measuring I’ll "
"cut to the chase. In order to complete our hypothesis test we need to know "
"the sampling distribution for *F* if the null hypothesis is true. Not "
"surprisingly, the sampling distribution for the *F*-statistic under the null "
"hypothesis is an *F*-distribution. If you recall our discussion of the *F*-"
"distribution in chapter :doc:`../Ch07/Ch07_Probability`, the *F*-"
"distribution has two parameters, corresponding to the two degrees of freedom "
"involved. The first one *df*\\ :sub:`1` is the between groups degrees of "
"freedom |df_b|, and the second one *df*\\ :sub:`2` is the within groups "
"degrees of freedom |df_w|\\."
msgstr ""
"У наступному розділі це питання розглядається більш детально, але для "
"читачів, які не цікавляться деталями того, що насправді вимірює тест, я "
"перейду відразу до суті. Щоб завершити перевірку гіпотези, нам потрібно "
"знати вибірковий розподіл для *F*, якщо нульова гіпотеза є правдивою. Не "
"дивно, що вибіркове розподілення для *F*-статистики за нульовою гіпотезою є "
"*F*-розподілом. Якщо ви пам'ятаєте наше обговорення *F*-розподілу в розділі "
":doc:`../Ch07/Ch07_Probability`, *F*-розподіл має два параметри, що "
"відповідають двом ступеням свободи. Перший *df*\\ :sub:`1` — це ступені "
"свободи між групами |df_b|, а другий *df*\\ :sub:`2` — це ступені свободи "
"всередині груп |df_w|\\."

#: ../../Ch13/Ch13_ANOVA_02.rst:276
msgid ""
"A summary of all the key quantities involved in a one-way ANOVA, including "
"the formulas showing how they are calculated, is shown in :numref:`tab-"
"anovatable`."
msgstr ""
"Зведений огляд усіх ключових величин, що беруть участь в однофакторному "
"дисперсійному аналізі (ANOVA), включаючи формули, що показують, як вони "
"розраховуються, наведено на рисунку. :numref:`tab-anovatable`."

#: ../../Ch13/Ch13_ANOVA_02.rst:279
msgid ""
"All of the key quantities involved in an ANOVA organised into a “standard” "
"ANOVA table. The formulas for all quantities (except the *p*-value which has "
"a very ugly formula and would be nightmarishly hard to calculate without a "
"computer) are shown."
msgstr ""
"Всі ключові величини, що використовуються в ANOVA, організовані в "
"«стандартну» таблицю ANOVA. Показані формули для всіх величин (крім *p*-"
"значення, яке має дуже складну формулу і яке було б надзвичайно важко "
"обчислити без комп'ютера)."

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "*df*"
msgstr "*df*"

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "sum of squares"
msgstr "сума квадратів"

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "mean squares"
msgstr "середньоквадратичні"

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "*F*-statistic"
msgstr "*F*-статистика"

#: ../../Ch13/Ch13_ANOVA_02.rst:286 ../../Ch13/Ch13_ANOVA_02.rst:594
msgid "*p*-value"
msgstr "*p*-значення"

#: ../../Ch13/Ch13_ANOVA_02.rst:288 ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "**between groups**"
msgstr "**між групами**"

#: ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "|SS_b| = |f_SS_b|"
msgstr "|SS_b| = |f_SS_b|"

#: ../../Ch13/Ch13_ANOVA_02.rst:288
msgid "[complicated]"
msgstr "[складний]"

#: ../../Ch13/Ch13_ANOVA_02.rst:290 ../../Ch13/Ch13_ANOVA_02.rst:598
msgid "**within groups**"
msgstr "**у групах**"

#: ../../Ch13/Ch13_ANOVA_02.rst:290
msgid "|SS_w| = |f_SS_w|"
msgstr "|SS_w| = |f_SS_w|"

#: ../../Ch13/Ch13_ANOVA_02.rst:296
msgid "The model for the data and the meaning of *F*"
msgstr "Модель для даних та значення *F*"

#: ../../Ch13/Ch13_ANOVA_02.rst:298
msgid ""
"At a fundamental level ANOVA is a competition between two different "
"statistical models, H\\ :sub:`0` and H\\ :sub:`1`. When I described the null "
"and alternative hypotheses at the start of the section, I was a little "
"imprecise about what these models actually are. I’ll remedy that now, though "
"you probably won’t like me for doing so. If you recall, our null hypothesis "
"was that all of the group means are identical to one another. If so, then a "
"natural way to think about the outcome variable |Y_ik| is to describe "
"individual scores in terms of a single population mean µ, plus the deviation "
"from that population mean. This deviation is usually denoted ϵ\\ :sub:`ik` "
"and is traditionally called the *error* or **residual** associated with that "
"observation. Be careful though. Just like we saw with the word "
"“significant”, the word “error” has a technical meaning in statistics that "
"isn’t quite the same as its everyday English definition. In everyday "
"language, “error” implies a mistake of some kind, but in statistics it "
"doesn’t (or at least, not necessarily). With that in mind, the word "
"“residual” is a better term than the word “error”. In statistics both words "
"mean “leftover variability”, that is “stuff” that the model can’t explain."
msgstr ""
"На фундаментальному рівні ANOVA є змаганням між двома різними статистичними "
"моделями, H\\ :sub:`0` та H\\ :sub:`1`. Коли я описував нульову та "
"альтернативну гіпотези на початку розділу, я був дещо неточним щодо того, що "
"насправді являють собою ці моделі. Зараз я виправлю це, хоча вам, ймовірно, "
"це не сподобається. Якщо ви пам'ятаєте, наша нульова гіпотеза полягала в "
"тому, що всі середні значення груп є ідентичними між собою. Якщо це так, то "
"природним способом розглядати змінну результату |Y_ik| є опис індивідуальних "
"балів у вигляді єдиного середнього значення популяції µ плюс відхилення від "
"цього середнього значення популяції. Це відхилення зазвичай позначається ϵ\\ "
":sub:`ik` і традиційно називається *похибкою* або **залишком**, пов'язаним з "
"цим спостереженням. Однак будьте обережні. Так само, як ми бачили зі словом "
"«значущий», слово «помилка» має технічне значення в статистиці, яке не "
"зовсім збігається з його повсякденним визначенням в англійській мові. У "
"повсякденній мові «помилка» означає якусь помилку, але в статистиці це не "
"так (або, принаймні, не обов'язково). З огляду на це, слово «залишок» є "
"кращим терміном, ніж слово «помилка». У статистиці обидва слова означають «"
"залишкову мінливість», тобто «те, що модель не може пояснити»."

#: ../../Ch13/Ch13_ANOVA_02.rst:318
msgid ""
"In any case, here’s what the null hypothesis looks like when we write it as "
"a statistical model"
msgstr ""
"У будь-якому разі, ось як виглядає нульова гіпотеза, якщо записати її як "
"статистичну модель"

#: ../../Ch13/Ch13_ANOVA_02.rst:321
msgid "|Y_ik| = µ + ϵ\\ :sub:`ik`"
msgstr "|Y_ik| = µ + ϵ\\ :sub:`ik`"

#: ../../Ch13/Ch13_ANOVA_02.rst:323
msgid ""
"where we make the *assumption* (discussed later) that the residual values "
"ϵ\\ :sub:`ik` are normally distributed, with mean 0 and a standard deviation "
"σ that is the same for all groups. To use the notation that we introduced in "
"chapter :doc:`../Ch07/Ch07_Probability` we would write this assumption like "
"this:"
msgstr ""
"де ми робимо *припущення* (обговорюється далі), що залишкові значення ϵ\\ "
":sub:`ik` мають нормальний розподіл із середнім значенням 0 і стандартним "
"відхиленням σ, яке є однаковим для всіх груп. Використовуючи позначення, які "
"ми ввели в розділі :doc:`../Ch07/Ch07_Probability`, ми б записали це "
"припущення так:"

#: ../../Ch13/Ch13_ANOVA_02.rst:329 ../../Ch13/Ch13_ANOVA_06.rst:29
msgid "ϵ\\ :sub:`ik` ~ Normal(0, σ²)"
msgstr "ϵ\\ :sub:`ik` ~ Normal(0, σ²)"

#: ../../Ch13/Ch13_ANOVA_02.rst:331
msgid ""
"What about the alternative hypothesis, H\\ :sub:`1`? The only difference "
"between the null hypothesis and the alternative hypothesis is that we allow "
"each group to have a different population mean. So, if we let µ\\ :sub:`k` "
"denote the population mean for the *k*-th group in our experiment, then the "
"statistical model corresponding to H\\ :sub:`1` is"
msgstr ""
"А що щодо альтернативної гіпотези, H\\ :sub:`1`? Єдина відмінність між "
"нульовою гіпотезою та альтернативною гіпотезою полягає в тому, що ми "
"допускаємо, що кожна група може мати різне середнє значення популяції. Отже, "
"якщо позначити µ\\ :sub:`k` середнє значення популяції для *k*-ї групи в "
"нашому експерименті, то статистична модель, що відповідає H\\ :sub:`1`, буде "
"такою"

#: ../../Ch13/Ch13_ANOVA_02.rst:338
msgid "|Y_ik| = µ\\ :sub:`k` + ϵ\\ :sub:`ik`"
msgstr "|Y_ik| = µ\\ :sub:`k` + ϵ\\ :sub:`ik`"

#: ../../Ch13/Ch13_ANOVA_02.rst:340
msgid ""
"where, once again, we assume that the error terms are normally distributed "
"with mean 0 and standard deviation σ. That is, the alternative hypothesis "
"also assumes that ϵ ~ Normal(0, σ²)"
msgstr ""
"де, знову ж таки, ми припускаємо, що члени помилки розподілені нормально із "
"середнім значенням 0 та стандартним відхиленням σ. Тобто, альтернативна "
"гіпотеза також припускає, що ϵ ~ Normal(0, σ²)"

#: ../../Ch13/Ch13_ANOVA_02.rst:345
msgid ""
"Okay, now that we’ve described the statistical models underpinning H\\ :sub:"
"`0` and H\\ :sub:`1` in more detail, it’s now pretty straightforward to say "
"what the mean square values are measuring, and what this means for the "
"interpretation of *F*. I won’t bore you with the proof of this but it turns "
"out that the within-groups mean square, |MS_w|, can be viewed as an "
"estimator (in the technical sense, chapter :doc:`../Ch08/Ch08_Estimation`) "
"of the error variance σ². The between-groups mean square |MS_b| is also an "
"estimator, but what it estimates is the error variance *plus* a quantity "
"that depends on the true differences among the group means. If we call this "
"quantity *Q*, then we can see that the *F*-statistic is basically:\\ [#]_"
msgstr ""
"Гаразд, тепер, коли ми більш детально описали статистичні моделі, що лежать "
"в основі H\\ :sub:`0` та H\\ :sub:`1`, можна досить просто сказати, що "
"вимірюють середні квадратичні значення і що це означає для інтерпретації *F*"
". Я не буду вас нудити доказом цього, але виявляється, що "
"середньоквадратичне значення всередині груп, |MS_w|, можна розглядати як "
"оцінювач (у технічному сенсі, розділ :doc:`../Ch08/Ch08_Estimation`) "
"дисперсії помилки σ². Середньоквадратичне значення між групами |MS_b| також "
"є оцінювачем, але воно оцінює дисперсію помилки *плюс* величину, яка "
"залежить від справжніх різниць між середніми значеннями груп. Якщо ми "
"назвемо цю величину *Q*, то побачимо, що статистика *F* в основному дорівнює:"
"\\ [#]_"

#: ../../Ch13/Ch13_ANOVA_02.rst:356
msgid ""
"F = \\frac{\\hat{Q} + \\hat\\sigma^2}{\\hat\\sigma^2}\n"
"\n"
msgstr ""
"F = \\frac{\\hat{Q} + \\hat\\sigma^2}{\\hat\\sigma^2}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:358
msgid ""
"where the true value *Q* = 0 if the null hypothesis is true, and *Q* > 0 if "
"the alternative hypothesis is true (:ref:`Hays, 1994 <Hays_1994>`, Ch. 10). "
"Therefore, at a bare minimum *the F-value must be larger than 1* to have any "
"chance of rejecting the null hypothesis. Note that this *doesn’t* mean that "
"it’s impossible to get an *F*-value less than 1. What it means is that if "
"the null hypothesis is true the sampling distribution of the *F*-ratio has a "
"mean of 1,\\ [#]_ and so we need to see *F*-values larger than 1 in order to "
"safely reject the null."
msgstr ""
"де справжнє значення *Q* = 0, якщо нульова гіпотеза є істинною, і *Q* > 0, "
"якщо альтернативна гіпотеза є істинною (:ref:`Hays, 1994 <Hays_1994>`, розд. "
"10). Отже, як мінімум, *значення F має бути більшим за 1*, щоб була хоч "
"якась ймовірність відхилення нульової гіпотези. Зауважте, що це *не* "
"означає, що неможливо отримати *F*-значення менше 1. Це означає, що якщо "
"нульова гіпотеза є істинною, то вибірковий розподіл *F*-коефіцієнта має "
"середнє значення 1,\\ [#]_ і тому нам потрібно бачити *F*-значення, більші "
"за 1, щоб безпечно відхилити нульову гіпотезу."

#: ../../Ch13/Ch13_ANOVA_02.rst:367
msgid ""
"To be a bit more precise about the sampling distribution, notice that if the "
"null hypothesis is true, both |MS_b| and |MS_w| are estimators of the "
"variance of the residuals ϵ\\ :sub:`ik`. If those residuals are normally "
"distributed, then you might suspect that the estimate of the variance of "
"ϵ\\ :sub:`ik` is χ²-distributed, because (as discussed in :doc:`../Ch07/"
"Ch07_Probability_6`) that’s what a χ²-distribution *is*: it’s what you get "
"when you square a bunch of normally-distributed things and add them up. And "
"since the *F*-distribution is (again, by definition) what you get when you "
"take the ratio between two things that are χ² distributed, we have our "
"sampling distribution. Obviously, I’m glossing over a whole lot of stuff "
"when I say this, but in broad terms, this really is where our sampling "
"distribution comes from."
msgstr ""
"Щоб бути більш точним щодо розподілу вибірки, зверніть увагу, що якщо "
"нульова гіпотеза є істинною, то як |MS_b|, так і |MS_w| є оцінками дисперсії "
"залишків ϵ\\ :sub:`ik`. Якщо ці залишки мають нормальний розподіл, то можна "
"припустити, що оцінка дисперсії ϵ\\ :sub:`ik` має χ²-розподіл, оскільки (як "
"обговорювалося в :doc:`../Ch07/Ch07_Probability_6`) саме таким і є "
"χ²-розподіл: його отримують, підносячи до квадрата низку величин з "
"нормальним розподілом і додаючи їх. А оскільки *F*-розподіл (знову ж таки, "
"за визначенням) — це те, що ви отримуєте, коли берете відношення між двома "
"величинами, які мають χ²-розподіл, ми маємо наш вибірковий розподіл. "
"Звичайно, я опускаю багато деталей, коли говорю це, але в загальних рисах "
"саме звідси береться наш вибірковий розподіл."

#: ../../Ch13/Ch13_ANOVA_02.rst:382
msgid "A worked example"
msgstr "Працюючий приклад"

#: ../../Ch13/Ch13_ANOVA_02.rst:384
msgid ""
"The previous discussion was fairly abstract and a little on the technical "
"side, so I think that at this point it might be useful to see a worked "
"example. For that, let’s go back to the |clinicaltrial|_ data set that was "
"introduced earlier in the chapter. The descriptive statistics that we "
"calculated at the beginning tell us our group means: An average mood gain of "
"0.45 for the placebo, 0.72 for Anxifree, and 1.48 for Joyzepam. With that in "
"mind, let’s party like it’s 1899\\ [#]_ and start doing some pencil and "
"paper calculations. I’ll only do this for the first 5 observations because "
"it’s not bloody 1899 and I’m very lazy. Let’s start by calculating |SS_w|, "
"the within-group sums of squares. First, let’s draw up a nice table to help "
"us with our calculations:"
msgstr ""
"Попереднє обговорення було досить абстрактним і дещо технічним, тому я "
"вважаю, що на цьому етапі було б корисно розглянути практичний приклад. Для "
"цього повернемося до набору даних |clinicaltrial|_, який був представлений "
"раніше в цьому розділі. Описові статистичні дані, які ми обчислили на "
"початку, показують середні значення для наших груп: середнє поліпшення "
"настрою становить 0,45 для плацебо, 0,72 для Anxifree і 1,48 для Joyzepam. "
"Маючи це на увазі, давайте веселитися, як у 1899 році\\ [#]_, і почнемо "
"робити розрахунки олівцем на папері. Я зроблю це тільки для перших 5 "
"спостережень, тому що зараз не 1899 рік, а я дуже лінивий. Почнемо з "
"обчислення |SS_w|, суми квадратів всередині групи. Спочатку складемо зручну "
"таблицю, яка допоможе нам у розрахунках:"

#: ../../Ch13/Ch13_ANOVA_02.rst:397 ../../Ch13/Ch13_ANOVA_02.rst:423
#: ../../Ch13/Ch13_ANOVA_02.rst:444
msgid "outcome"
msgstr "результат'"

#: ../../Ch13/Ch13_ANOVA_02.rst:399 ../../Ch13/Ch13_ANOVA_02.rst:425
#: ../../Ch13/Ch13_ANOVA_02.rst:446
msgid "|Y_ik|"
msgstr "|Y_ik|"

#: ../../Ch13/Ch13_ANOVA_02.rst:401 ../../Ch13/Ch13_ANOVA_02.rst:403
#: ../../Ch13/Ch13_ANOVA_02.rst:405 ../../Ch13/Ch13_ANOVA_02.rst:427
#: ../../Ch13/Ch13_ANOVA_02.rst:429 ../../Ch13/Ch13_ANOVA_02.rst:431
#: ../../Ch13/Ch13_ANOVA_02.rst:448 ../../Ch13/Ch13_ANOVA_02.rst:450
#: ../../Ch13/Ch13_ANOVA_02.rst:452 ../../Ch13/Ch13_ANOVA_02.rst:494
#: ../../Ch13/Ch13_ANOVA_02.rst:524
msgid "placebo"
msgstr "плацебо"

#: ../../Ch13/Ch13_ANOVA_02.rst:401 ../../Ch13/Ch13_ANOVA_02.rst:427
#: ../../Ch13/Ch13_ANOVA_02.rst:448 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.5"
msgstr "0.5"

#: ../../Ch13/Ch13_ANOVA_02.rst:403 ../../Ch13/Ch13_ANOVA_02.rst:429
#: ../../Ch13/Ch13_ANOVA_02.rst:450 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.3"
msgstr "0.3"

#: ../../Ch13/Ch13_ANOVA_02.rst:405 ../../Ch13/Ch13_ANOVA_02.rst:431
#: ../../Ch13/Ch13_ANOVA_02.rst:452 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.1"
msgstr "0.1"

#: ../../Ch13/Ch13_ANOVA_02.rst:407 ../../Ch13/Ch13_ANOVA_02.rst:409
#: ../../Ch13/Ch13_ANOVA_02.rst:433 ../../Ch13/Ch13_ANOVA_02.rst:435
#: ../../Ch13/Ch13_ANOVA_02.rst:454 ../../Ch13/Ch13_ANOVA_02.rst:456
#: ../../Ch13/Ch13_ANOVA_02.rst:496 ../../Ch13/Ch13_ANOVA_02.rst:526
msgid "anxifree"
msgstr "безтурботний"

#: ../../Ch13/Ch13_ANOVA_02.rst:407 ../../Ch13/Ch13_ANOVA_02.rst:433
#: ../../Ch13/Ch13_ANOVA_02.rst:454 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.6"
msgstr "0.6"

#: ../../Ch13/Ch13_ANOVA_02.rst:409 ../../Ch13/Ch13_ANOVA_02.rst:435
#: ../../Ch13/Ch13_ANOVA_02.rst:456 ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.4"
msgstr "0.4"

#: ../../Ch13/Ch13_ANOVA_02.rst:412
msgid ""
"At this stage, the only thing I’ve included in the table is the raw data "
"itself. That is, the grouping variable (i.e., ``drug``) and outcome variable "
"(i.e. ``mood.gain``) for each person. Note that the outcome variable here "
"corresponds to the |Y_ik| value in our equation previously. The next step in "
"the calculation is to write down, for each person in the study, the "
"corresponding group mean, |Yb_k|. This is slightly repetitive but not "
"particularly difficult since we already calculated those group means when "
"doing our descriptive statistics:"
msgstr ""
"На цьому етапі я включив у таблицю лише самі вихідні дані. Тобто групувальну "
"змінну (тобто ``drug``) та змінну результату (тобто ``mood.gain``) для "
"кожної особи. Зверніть увагу, що змінна результату тут відповідає значенню "
"|Y_ik| у нашому попередньому рівнянні. Наступним кроком у розрахунку є "
"записування для кожної особи в дослідженні відповідного групового середнього "
"значення |Yb_k|. Це дещо повторюється, але не є особливо складним, оскільки "
"ми вже розрахували ці групові середні значення під час виконання описової "
"статистики:"

#: ../../Ch13/Ch13_ANOVA_02.rst:423 ../../Ch13/Ch13_ANOVA_02.rst:444
#: ../../Ch13/Ch13_ANOVA_02.rst:490
msgid "group mean"
msgstr "середнє значення групи"

#: ../../Ch13/Ch13_ANOVA_02.rst:425 ../../Ch13/Ch13_ANOVA_02.rst:446
#: ../../Ch13/Ch13_ANOVA_02.rst:492
msgid "|Yb_k|"
msgstr "|Yb_k|"

#: ../../Ch13/Ch13_ANOVA_02.rst:427 ../../Ch13/Ch13_ANOVA_02.rst:429
#: ../../Ch13/Ch13_ANOVA_02.rst:431
msgid "**0.45**"
msgstr "**0.45**"

#: ../../Ch13/Ch13_ANOVA_02.rst:433 ../../Ch13/Ch13_ANOVA_02.rst:435
msgid "**0.72**"
msgstr "**0.72**"

#: ../../Ch13/Ch13_ANOVA_02.rst:438
msgid ""
"Now that we’ve written those down, we need to calculate, again for every "
"person, the deviation from the corresponding group mean. That is, we want to "
"subtract |Y_ik| - |Yb_k|. After we’ve done that, we need to square "
"everything. When we do that, here’s what we get:"
msgstr ""
"Тепер, коли ми це записали, нам потрібно обчислити, знову ж таки для кожної "
"особи, відхилення від відповідного середнього значення групи. Тобто, ми "
"хочемо відняти |Y_ik| - |Yb_k|. Після цього нам потрібно все піднести до "
"квадрата. Коли ми це зробимо, отримаємо таке:"

#: ../../Ch13/Ch13_ANOVA_02.rst:444
msgid "dev. from group mean"
msgstr "відхилення від середнього значення групи"

#: ../../Ch13/Ch13_ANOVA_02.rst:444
msgid "squared deviation"
msgstr "квадратичне відхилення"

#: ../../Ch13/Ch13_ANOVA_02.rst:446
msgid "(|Y_ik| - |Yb_k|)"
msgstr "(|Y_ik| - |Yb_k|)"

#: ../../Ch13/Ch13_ANOVA_02.rst:446
msgid "(|Y_ik| - |Yb_k|\\)²"
msgstr "(|Y_ik| - |Yb_k|\\)²"

#: ../../Ch13/Ch13_ANOVA_02.rst:448 ../../Ch13/Ch13_ANOVA_02.rst:450
#: ../../Ch13/Ch13_ANOVA_02.rst:452 ../../Ch13/Ch13_ANOVA_02.rst:494
msgid "0.45"
msgstr "0.45"

#: ../../Ch13/Ch13_ANOVA_02.rst:448
msgid "**0.05**"
msgstr "**0.05**"

#: ../../Ch13/Ch13_ANOVA_02.rst:448
msgid "**0.0025**"
msgstr "**0.0025**"

#: ../../Ch13/Ch13_ANOVA_02.rst:450
msgid "**-0.15**"
msgstr "**-0.15**"

#: ../../Ch13/Ch13_ANOVA_02.rst:450
msgid "**0.0225**"
msgstr "**0.0225**"

#: ../../Ch13/Ch13_ANOVA_02.rst:452
msgid "**-0.35**"
msgstr "**-0.35**"

#: ../../Ch13/Ch13_ANOVA_02.rst:452
msgid "**0.1225**"
msgstr "**0.1225**"

#: ../../Ch13/Ch13_ANOVA_02.rst:454 ../../Ch13/Ch13_ANOVA_02.rst:456
#: ../../Ch13/Ch13_ANOVA_02.rst:496
msgid "0.72"
msgstr "0.72"

#: ../../Ch13/Ch13_ANOVA_02.rst:454
msgid "**-0.12**"
msgstr "**-0.12**"

#: ../../Ch13/Ch13_ANOVA_02.rst:454
msgid "**0.0136**"
msgstr "**0.0136**"

#: ../../Ch13/Ch13_ANOVA_02.rst:456
msgid "**-0.32**"
msgstr "**-0.32**"

#: ../../Ch13/Ch13_ANOVA_02.rst:456
msgid "**0.1003**"
msgstr "**0.1003**"

#: ../../Ch13/Ch13_ANOVA_02.rst:459
msgid ""
"The last step is equally straightforward. In order to calculate the within-"
"group sum of squares we just add up the squared deviations across all "
"observations:"
msgstr ""
"Останній крок так само простий. Щоб обчислити суму квадратів всередині "
"групи, ми просто додаємо квадрати відхилень для всіх спостережень:"

#: ../../Ch13/Ch13_ANOVA_02.rst:463
msgid "|SS_w| = 0.0025 + 0.0225 + 0.1225 + 0.0136 + 0.1003 = 0.2614"
msgstr "|SS_w| = 0.0025 + 0.0225 + 0.1225 + 0.0136 + 0.1003 = 0.2614"

#: ../../Ch13/Ch13_ANOVA_02.rst:465
msgid ""
"Of course, if we actually wanted to get the *right* answer we’d need to do "
"this for all 18 observations in the data set, not just the first five. We "
"could continue with the pencil and paper calculations if we wanted to, but "
"it’s pretty tedious. Alternatively, it’s not too hard to do this in jamovi."
msgstr ""
"Звичайно, якщо ми дійсно хочемо отримати *правильну* відповідь, нам потрібно "
"зробити це для всіх 18 спостережень у наборі даних, а не тільки для перших "
"п'яти. Ми могли б продовжувати обчислення олівцем і папером, якби хотіли, "
"але це досить нудно. Альтернативно, це не дуже складно зробити в jamovi."

#: ../../Ch13/Ch13_ANOVA_02.rst:471
msgid ""
"Go to an empty column (at the end of the data set) and double click on the "
"column header, choose ``New computed variable`` and enter ``sq_res_wth`` in "
"the first line and the formula ``(mood.gain - VMEAN(mood.gain, group_by = "
"drug)) ^ 2`` in the line starting with ``=`` (next to the *f*\\ :sub:`x`). "
"``mood.gain`` represents |Y_ik|, ``VMEAN(mood.gain, group_by = drug)`` the "
"group mean |Yb_k|. This difference (third column in the table above) is then "
"squared and it is therefore not much surprise to see that the values are "
"(apart from rounding errors) identical to those in the last column of the "
"table above."
msgstr ""
"Перейдіть до порожньої колонки (в кінці набору даних) і двічі клацніть на "
"заголовку колонки, виберіть ``Нова обчислювана змінна`` і введіть "
"``sq_res_wth`` у першому рядку та формулу ``(mood.gain - VMEAN(mood.gain, "
"group_by = drug)) ^ 2`` у рядку, що починається з ``=`` (поруч із *f*\\ "
":sub:`x`). ``mood.gain`` представляє |Y_ik|, ``VMEAN(mood.gain, group_by = "
"drug)`` — середнє значення групи |Yb_k|. Ця різниця (третій стовпець у "
"таблиці вище) потім підноситься до квадрата, і тому не дивно, що значення ("
"за винятком похибок округлення) ідентичні значенням в останньому стовпці "
"таблиці вище."

#: ../../Ch13/Ch13_ANOVA_02.rst:481
msgid ""
"Okay. Now that we’ve calculated the within groups variation, |SS_w|, it’s "
"time to turn our attention to the between-group sum of squares, |SS_b|. The "
"calculations for this case are very similar. The main difference is that "
"instead of calculating the differences between an observation |Y_ik| and a "
"group mean |Yb_k| for all of the observations, we calculate the differences "
"between the group means |Yb_k| and the grand mean |Yb| (in this case 0.88) "
"for all of the groups."
msgstr ""
"Гаразд. Тепер, коли ми обчислили внутрішньогрупову варіацію |SS_w|, час "
"звернути увагу на міжгрупову суму квадратів |SS_b|. Обчислення в цьому "
"випадку дуже схожі. Основна відмінність полягає в тому, що замість "
"обчислення різниць між спостереженням |Y_ik| і середнім значенням групи "
"|Yb_k| для всіх спостережень, ми обчислюємо різниці між середніми значеннями "
"груп |Yb_k| і загальним середнім значенням |Yb| (у цьому випадку 0,88) для "
"всіх груп."

#: ../../Ch13/Ch13_ANOVA_02.rst:490
msgid "grand mean"
msgstr "великий середній"

#: ../../Ch13/Ch13_ANOVA_02.rst:490
msgid "deviation"
msgstr "відхилення"

#: ../../Ch13/Ch13_ANOVA_02.rst:490 ../../Ch13/Ch13_ANOVA_02.rst:520
msgid "squared deviations"
msgstr "квадратичні відхилення"

#: ../../Ch13/Ch13_ANOVA_02.rst:492
msgid "|Yb|"
msgstr "|Yb|"

#: ../../Ch13/Ch13_ANOVA_02.rst:492
msgid "|Yb_k| - |YB|"
msgstr "|Yb_k| - |YB|"

#: ../../Ch13/Ch13_ANOVA_02.rst:492 ../../Ch13/Ch13_ANOVA_02.rst:522
msgid "(|Yb_k| - |Yb|)²"
msgstr "(|Yb_k| - |Yb|)²"

#: ../../Ch13/Ch13_ANOVA_02.rst:494 ../../Ch13/Ch13_ANOVA_02.rst:496
#: ../../Ch13/Ch13_ANOVA_02.rst:498
msgid "0.88"
msgstr "0.88"

#: ../../Ch13/Ch13_ANOVA_02.rst:494
msgid "-0.43"
msgstr "-0.43"

#: ../../Ch13/Ch13_ANOVA_02.rst:494 ../../Ch13/Ch13_ANOVA_02.rst:524
msgid "0.19"
msgstr "0.19"

#: ../../Ch13/Ch13_ANOVA_02.rst:496
msgid "-0.16"
msgstr "-0.16"

#: ../../Ch13/Ch13_ANOVA_02.rst:496 ../../Ch13/Ch13_ANOVA_02.rst:526
msgid "0.03"
msgstr "0.03"

#: ../../Ch13/Ch13_ANOVA_02.rst:498 ../../Ch13/Ch13_ANOVA_02.rst:528
msgid "joyzepam"
msgstr "Джойзепам"

#: ../../Ch13/Ch13_ANOVA_02.rst:498
msgid "1.48"
msgstr "1.48"

#: ../../Ch13/Ch13_ANOVA_02.rst:498
msgid "0.60"
msgstr "0.60"

#: ../../Ch13/Ch13_ANOVA_02.rst:498 ../../Ch13/Ch13_ANOVA_02.rst:528
msgid "0.36"
msgstr "0.36"

#: ../../Ch13/Ch13_ANOVA_02.rst:501
msgid ""
"We create another computed variable with the name ``sq_res_btw`` and "
"``(VMEAN(mood.gain, group_by = drug) - VMEAN(mood.gain) - ) ^ 2`` as "
"formula. The term ``VMEAN(mood.gain, group_by = drug)`` represents the group "
"mean |Yb_k|, and ``VMEAN(mood.gain)`` the grand mean |Yb|. Again, we find "
"that the values for that variable are the same as in the last column of the "
"table above: the first three rows represent ``placebo``, followed by three "
"lines with ``anxifree`` and three lines with ``joyzepam``; the next nine "
"lines are a repetition of the first nine ones."
msgstr ""
"Ми створюємо ще одну обчислювану змінну з назвою ``sq_res_btw`` і ``(VMEAN("
"mood.gain, group_by = drug) - VMEAN(mood.gain) - ) ^ 2`` як формула. Термін "
"``VMEAN(mood.gain, group_by = drug)`` представляє середнє значення групи "
"|Yb_k|, та ``VMEAN(mood.gain)`` загальне середнє |Yb|. Знову ж таки, ми "
"виявляємо, що значення для цієї змінної такі ж, як і в останньому стовпці "
"таблиці вище: перші три рядки представляють ``placebo``, а потім три рядки з "
"``anxifree`` і три рядки з ``joyzepam``; Наступні дев'ять рядків є "
"повторенням перших дев'яти."

#: ../../Ch13/Ch13_ANOVA_02.rst:510
msgid ""
"However, for the between group calculations we need to multiply each of "
"these squared deviations by |N_k|, the number of observations in the group. "
"We do this because every *observation* in the group (all |N_k| of them) is "
"associated with a between group difference. So if there are six people in "
"the placebo group and the placebo group mean differs from the grand mean by "
"0.19, then the *total* between group variation associated with these six "
"people is 6 · 0.19 = 1.14. So we have to extend our little table of "
"calculations:"
msgstr ""
"Однак для розрахунків між групами нам потрібно помножити кожне з цих "
"квадратних відхилень на |N_k|, кількість спостережень у групі. Ми робимо це "
"тому, що кожне *спостереження* в групі (всі |N_k| з них) пов'язане з "
"міжгруповою різницею. Отже, якщо в групі плацебо є шість осіб, а середнє "
"значення групи плацебо відрізняється від загального середнього значення на "
"0,19, то *загальна* міжгрупова варіація, пов'язана з цими шістьма особами, "
"становить 6 · 0,19 = 1,14. Тому ми маємо розширити нашу невеличку таблицю "
"розрахунків:"

#: ../../Ch13/Ch13_ANOVA_02.rst:520 ../../Ch13/Ch13_ANOVA_02.rst:522
#: ../../Ch13/Ch13_ANOVA_02.rst:524 ../../Ch13/Ch13_ANOVA_02.rst:526
#: ../../Ch13/Ch13_ANOVA_02.rst:528
msgid "…"
msgstr "…"

#: ../../Ch13/Ch13_ANOVA_02.rst:520
msgid "sample size"
msgstr "розмір вибірки"

#: ../../Ch13/Ch13_ANOVA_02.rst:520
msgid "weighted squared deviat."
msgstr "зважене квадратичне відхилення."

#: ../../Ch13/Ch13_ANOVA_02.rst:522
msgid "|N_k|"
msgstr "|N_k|"

#: ../../Ch13/Ch13_ANOVA_02.rst:522
msgid "|N_k| · (|Yb_k| - |Yb|)²"
msgstr "|N_k| · (|Yb_k| - |Yb|)²"

#: ../../Ch13/Ch13_ANOVA_02.rst:524 ../../Ch13/Ch13_ANOVA_02.rst:526
#: ../../Ch13/Ch13_ANOVA_02.rst:528 ../../Ch13/Ch13_ANOVA_05.rst:53
#: ../../Ch13/Ch13_ANOVA_07.rst:66 ../../Ch13/Ch13_ANOVA_07.rst:68
#: ../../Ch13/Ch13_ANOVA_07.rst:74 ../../Ch13/Ch13_ANOVA_07.rst:76
msgid "6"
msgstr "6"

#: ../../Ch13/Ch13_ANOVA_02.rst:524
msgid "1.14"
msgstr "1.14"

#: ../../Ch13/Ch13_ANOVA_02.rst:526
msgid "0.18"
msgstr "0.18"

#: ../../Ch13/Ch13_ANOVA_02.rst:528
msgid "2.16"
msgstr "2.16"

#: ../../Ch13/Ch13_ANOVA_02.rst:531
msgid ""
"And so now our between group sum of squares is obtained by summing these "
"“weighted squared deviations” over all three groups in the study:"
msgstr ""
"І тепер наша міжгрупова сума квадратів отримується шляхом підсумовування цих "
"«зважених квадратів відхилень» по всіх трьох групах у дослідженні:"

#: ../../Ch13/Ch13_ANOVA_02.rst:534
msgid "|SS_b| = 1.14 + 0.18 + 2.16 = 3.48"
msgstr "|SS_b| = 1.14 + 0.18 + 2.16 = 3.48"

#: ../../Ch13/Ch13_ANOVA_02.rst:536
msgid ""
"As you can see, the between group calculations are a lot shorter (when "
"calculated b hand)."
msgstr ""
"Як бачите, міжгрупові розрахунки набагато коротші (якщо розраховувати "
"вручну)."

#: ../../Ch13/Ch13_ANOVA_02.rst:539
msgid ""
"In jamovi, we can calculate these sums, i.e., the values for |SS_b| and |"
"SS_w|, by clicking ``Descriptives`` →  ``Descriptive Statistics``, then "
"moving ``sq_res_wth`` and ``sq_res_btw`` to the ``Variables`` box, and "
"finally selecting ``Sum`` from the ``Statistics`` drop-down menu. The sum of "
"``sq_res_wth`` (|SS_w|) has a value of **1.392**, ``sq_res_wth`` (|SS_b|) a "
"value of **3.453** (just rounding errors away from the 3.48 we calculated "
"above)."
msgstr ""
"У jamovi ми можемо обчислити ці суми, тобто значення для |SS_b| та |SS_w|, "
"натиснувши ``Descriptives`` →  ``Descriptive Statistics``, потім рухається "
"``sq_res_wth`` і ``sq_res_btw`` до ``Variables`` поле, і нарешті вибір "
"``Sum`` з ``Statistics`` випадаюче меню. Сума ``sq_res_wth`` (|SS_w|) має "
"значення **1.392**, ``sq_res_wth`` (|SS_b|) значення **3,453** (це просто "
"помилка округлення від 3,48, яке ми розрахували вище)."

#: ../../Ch13/Ch13_ANOVA_02.rst:547
msgid ""
"Now that we’ve calculated our sums of squares values, |SS_b| and |SS_w|, the "
"rest of the ANOVA is pretty painless. The next step is to calculate the "
"degrees of freedom. Since we have *G* = 3 groups and *N* = 18 observations "
"in total our degrees of freedom can be calculated by simple subtraction:"
msgstr ""
"Тепер, коли ми обчислили суми квадратів значень |SS_b| та |SS_w|, решта "
"ANOVA є досить простою. Наступним кроком є обчислення ступенів свободи. "
"Оскільки ми маємо *G* = 3 групи та *N* = 18 спостережень загалом, наші "
"ступені свободи можна обчислити простим відніманням:"

#: ../../Ch13/Ch13_ANOVA_02.rst:552
msgid "|df_b| = *G* - 1 = 2 |df_w| = *N* - *G* = 15"
msgstr "|df_b| = *G* - 1 = 2 |df_w| = *N* - *G* = 15"

#: ../../Ch13/Ch13_ANOVA_02.rst:555
msgid ""
"Next, since we’ve now calculated the values for the sums of squares and the "
"degrees of freedom, for both the within-groups variability and the between-"
"groups variability, we can obtain the mean square values by dividing one by "
"the other:"
msgstr ""
"Далі, оскільки ми вже обчислили значення суми квадратів і ступенів свободи "
"як для внутрішньогрупової, так і для міжгрупової мінливості, ми можемо "
"отримати середні квадратичні значення, розділивши одне на інше:"

#: ../../Ch13/Ch13_ANOVA_02.rst:560
msgid ""
"\\begin{array}{lclclcl}\n"
"\\mbox{MS}_b &=& \\displaystyle\\frac{\\mbox{SS}_b }{  \\mbox{df}_b } &=& "
"\\displaystyle\\frac{3.453}{ 2} &=& 1.727 \\\\\n"
"\\mbox{MS}_w &=& \\displaystyle\\frac{\\mbox{SS}_w }{  \\mbox{df}_w } &=& "
"\\displaystyle\\frac{1.392}{15} &=& 0.093\n"
"\\end{array}"
msgstr ""
"\\begin{array}{lclclcl}\n"
"\\mbox{MS}_b &=& \\displaystyle\\frac{\\mbox{SS}_b }{  \\mbox{df}_b } &=& "
"\\displaystyle\\frac{3.453}{ 2} &=& 1.727 \\\\\n"
"\\mbox{MS}_w &=& \\displaystyle\\frac{\\mbox{SS}_w }{  \\mbox{df}_w } &=& "
"\\displaystyle\\frac{1.392}{15} &=& 0.093\n"
"\\end{array}"

#: ../../Ch13/Ch13_ANOVA_02.rst:567
msgid ""
"We’re almost done. The mean square values can be used to calculate the *F*-"
"value, which is the test statistic that we’re interested in. We do this by "
"dividing the between-groups MS value by the within-groups MS value.\\ [#]_"
msgstr ""
"Ми майже закінчили. Середні квадратичні значення можна використовувати для "
"обчислення значення *F*, яке є тестовою статистикою, що нас цікавить. Для "
"цього ми ділимо значення MS між групами на значення MS всередині груп.\\ [#]_"

#: ../../Ch13/Ch13_ANOVA_02.rst:572
msgid ""
"F = \\frac{\\mbox{MS}_b }{\\mbox{MS}_w} = \\frac{1.727}{0.093} = 18.611\n"
"\n"
msgstr ""
"F = \\frac{\\mbox{MS}_b }{\\mbox{MS}_w} = \\frac{1.727}{0.093} = 18.611\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_02.rst:574
msgid ""
"Woohooo! This is terribly exciting, yes? Now that we have our test "
"statistic, the last step is to find out whether the test itself gives us a "
"significant result. As discussed in chapter :doc:`../Ch09/"
"Ch09_HypothesisTesting` back in the “old days” what we’d do is open up a "
"statistics textbook or flick to the back section which would actually have a "
"huge lookup table and we would find the threshold *F*-value corresponding to "
"a particular value of α (the null hypothesis rejection region), e.g. 0.05, "
"0.01 or 0.001, for 2 and 15 degrees of freedom. Doing it this way would give "
"us a threshold *F*-value for an α of 0.001 of 11.34. As this is less than "
"our calculated *F*-value we say that *p* < 0.001. But those were the old "
"days, and nowadays fancy stats software calculates the exact *p*-value for "
"you. In fact, the exact *p*-value is 0.000086. So, unless we’re being "
"*extremely* conservative about our Type I error rate, we’re pretty much "
"guaranteed to reject the null hypothesis."
msgstr ""
"Ура! Це дуже захоплююче, чи не так? Тепер, коли ми маємо нашу тестову "
"статистику, останній крок полягає в тому, щоб з'ясувати, чи дає сам тест "
"значущий результат. Як обговорювалося в розділі :doc:`../Ch09/"
"Ch09_HypothesisTesting`, у «старі часи» ми б відкрили підручник зі "
"статистики або перегорнули б до кінцевої частини, де була б величезна "
"таблиця для пошуку, і знайшли б порогове значення *F*, що відповідає "
"конкретному значенню α (область відхилення нульової гіпотези), наприклад "
"0,05, 0,01 або 0,001, для 2 і 15 ступенів свободи. Таким чином ми отримаємо "
"порогове значення *F* для α, що дорівнює 0,001, яке становить 11,34. "
"Оскільки це менше, ніж наше обчислене значення *F*, ми говоримо, що *p* < "
"0,001. Але це було давно, а сьогодні сучасне програмне забезпечення для "
"статистики обчислює для вас точне значення *p*. Насправді точне значення *p* "
"дорівнює 0,000086. Отже, якщо ми не будемо *надзвичайно* консервативними "
"щодо рівня помилки I типу, ми майже напевно відхилимо нульову гіпотезу."

#: ../../Ch13/Ch13_ANOVA_02.rst:588
msgid ""
"At this point, we’re basically done. Having completed our calculations, it’s "
"traditional to organise all these numbers into an ANOVA table like the one "
"in :numref:`tab-anovatable`. For our |clinicaltrial|_ data, the ANOVA table "
"would look like this:\\ [#]_"
msgstr ""
"На цьому ми в основному закінчили. Завершивши розрахунки, зазвичай всі ці "
"цифри організовують у таблицю ANOVA, як у :numref:`tab-anovatable`. Для "
"наших даних |clinicaltrial|_ таблиця ANOVA буде виглядати так:\\ [#]_"

#: ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "3.453"
msgstr "3.453"

#: ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "1.727"
msgstr "1.727"

#: ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "18.611"
msgstr "18.611"

#: ../../Ch13/Ch13_ANOVA_02.rst:596
msgid "0.000086"
msgstr "0.000086"

#: ../../Ch13/Ch13_ANOVA_02.rst:598
msgid "15"
msgstr "15"

#: ../../Ch13/Ch13_ANOVA_02.rst:598
msgid "1.392"
msgstr "1.392"

#: ../../Ch13/Ch13_ANOVA_02.rst:598
msgid "0.093"
msgstr "0.093"

#: ../../Ch13/Ch13_ANOVA_02.rst:601
msgid ""
"These days, you’ll probably never have much reason to want to construct one "
"of these tables yourself, but you will find that almost all statistical "
"software (jamovi included) tends to organise the output of an ANOVA into a "
"table like this, so it’s a good idea to get used to reading them. However, "
"although the software will output a full ANOVA table, there’s almost never a "
"good reason to include the whole table in your write up. A pretty standard "
"way of reporting this result would be to write something like this:"
msgstr ""
"В наш час, ймовірно, у вас ніколи не буде особливих причин самостійно "
"складати таку таблицю, але ви побачите, що майже все статистичне програмне "
"забезпечення (включно з jamovi) має тенденцію організовувати результати "
"ANOVA у таку таблицю, тому варто звикнути до їхнього читання. Однак, хоча "
"програмне забезпечення і видає повну таблицю ANOVA, майже ніколи немає "
"вагомих причин включати всю таблицю у ваш звіт. Досить стандартним способом "
"представлення цього результату буде написання чогось на зразок такого:"

#: ../../Ch13/Ch13_ANOVA_02.rst:610
msgid ""
"One-way ANOVA showed a significant effect of drug on mood gain: *F*\\(2,15) "
"= 18.61, *p* < 0.001."
msgstr ""
"Однофакторний дисперсійний аналіз показав значний вплив препарату на "
"покращення настрою.: *F*\\(2,15) = 18.61, *p* < 0.001."

#: ../../Ch13/Ch13_ANOVA_02.rst:613
msgid "Sigh. So much work for one short sentence."
msgstr "Зітхає. Стільки роботи для одного короткого речення."

#: ../../Ch13/Ch13_ANOVA_02.rst:618
msgid ""
"When all groups have the same number of observations, the experimental "
"design is said to be “balanced”. Balance isn’t such a big deal for one-way "
"ANOVA, which is the topic of this chapter. It becomes more important when "
"you start doing more complicated ANOVAs."
msgstr ""
"Коли всі групи мають однакову кількість спостережень, експериментальний "
"дизайн вважається «збалансованим». Збалансованість не є такою важливою для "
"однофакторного ANOVA, який є темою цього розділу. Вона стає більш важливою, "
"коли ви починаєте виконувати більш складні ANOVA."

#: ../../Ch13/Ch13_ANOVA_02.rst:624
msgid ""
"|SS_w| is also referred to in an independent ANOVA as the error variance, or "
"SS\\ :sub:`error`"
msgstr ""
"|SS_w| також називається в незалежному дисперсійному аналізі (ANOVA) "
"дисперсією помилки, або SS\\ :sub:`error`"

#: ../../Ch13/Ch13_ANOVA_02.rst:628
msgid ""
"If you read ahead to chapter :doc:`../Ch14/Ch14_ANOVA2` and look at how the "
"“treatment effect” at level *k* of a factor is defined in terms of the α\\ :"
"sub:`k` values (see section :doc:`../Ch14/Ch14_ANOVA2_02`), it turns out "
"that *Q* refers to a weighted mean of the squared treatment effects, :math:"
"`Q = (\\sum_{k=1}^G N_k \\alpha_k^2)/(G-1)`."
msgstr ""
"Якщо ви прочитаєте розділ :doc:`../Ch14/Ch14_ANOVA2` і подивитеся, як «ефект "
"обробки» на рівні *k* фактора визначається за допомогою значень α\\ :sub:`k` "
"(див. розділ :doc:`../Ch14/Ch14_ANOVA2_02`), виявляється, що *Q* відноситься "
"до зваженого середнього значення квадратів ефектів обробки, :math:`Q = ("
"\\sum_{k=1}^G N_k \\alpha_k^2)/(G-1)`."

#: ../../Ch13/Ch13_ANOVA_02.rst:635
msgid ""
"Or, if we want to be sticklers for accuracy, :math:`1 + \\frac{2}{df_2 - 2}`."
msgstr ""
"Або, якщо ми хочемо бути прискіпливими до точності, :math:`1 + \\frac{2}{"
"df_2 - 2}`."

#: ../../Ch13/Ch13_ANOVA_02.rst:639
msgid ""
"Or, to be precise, party like “it’s 1899 and we’ve got no friends and "
"nothing better to do with our time than do some calculations that wouldn’t "
"have made any sense in 1899 because ANOVA didn’t exist until about the "
"1920s”."
msgstr ""
"Або, якщо бути точнішим, вечірка на кшталт «це 1899 рік, у нас немає друзів "
"і нічого кращого, чим зайняти свій час, окрім розрахунків, які не мали б "
"жодного сенсу в 1899 році, оскільки ANOVA з'явилася лише в 1920-х роках»."

#: ../../Ch13/Ch13_ANOVA_02.rst:645
msgid ""
"We could as well do this with creating yet another computed variable, named "
"``F`` using the formula ``(VSUM(sq_res_btw) / 2) / (VSUM(sq_res_wth) / 15)`` "
"which gives us 18.611 as value. If you could not reprodcuce the calculation "
"steps above, you can download and open the |clinicaltrial_anova|_ data set."
msgstr ""
"Ми могли б зробити це, створивши ще одну обчислювану змінну з назвою ``F`` "
"використовуючи формулу ``(VSUM(sq_res_btw) / 2) / (VSUM(sq_res_wth) / 15)`` "
"що дає нам значення 18,611. Якщо ви не змогли відтворити наведені вище кроки "
"розрахунку, ви можете завантажити та відкрити набір даних "
"|clinicaltrial_anova|_."

#: ../../Ch13/Ch13_ANOVA_02.rst:652
msgid ""
"In order to see the *p*-value with a high number of decimal places, click on "
"the settings menu (``⋮``, top-right corner) and set the ``p-value format`` "
"to ``16 dp``."
msgstr ""
"Щоб побачити значення *p* з великою кількістю знаків після коми, натисніть "
"на меню налаштувань (``⋮``, у верхньому правому куті) та встановіть ``p-"
"value format`` до ``16 dp``."

#: ../../Ch13/Ch13_ANOVA_03.rst:4
msgid "Running an ANOVA in jamovi"
msgstr "Проведення дисперсійного аналізу (ANOVA) в jamovi"

#: ../../Ch13/Ch13_ANOVA_03.rst:6
msgid ""
"I’m pretty sure I know what you’re thinking after reading the last section, "
"*especially* if you followed my advice and did all of that by pencil and "
"paper (i.e., in a spreadsheet) yourself. Doing the ANOVA calculations "
"yourself *sucks*. There’s quite a lot of calculations that we needed to do "
"along the way, and it would be tedious to have to do this over and over "
"again every time you wanted to do an ANOVA."
msgstr ""
"Я майже впевнений, що знаю, про що ви думаєте після прочитання останнього "
"розділу, *особливо* якщо ви дослухалися моєї поради і зробили все це "
"самостійно за допомогою олівця та паперу (тобто в електронній таблиці). "
"Самостійно виконувати розрахунки ANOVA *дуже нудно*. Нам довелося виконати "
"чимало розрахунків, і було б нудно робити це знову і знову щоразу, коли ви "
"хотіли б виконати ANOVA."

#: ../../Ch13/Ch13_ANOVA_03.rst:14
msgid "Using jamovi to specify your ANOVA"
msgstr "Використання jamovi для визначення вашого ANOVA"

#: ../../Ch13/Ch13_ANOVA_03.rst:16
msgid ""
"To make life easier for you, jamovi can do ANOVA… hurrah! Go to the "
"``ANOVA`` - ``ANOVA`` analysis, and move the ``mood.gain`` variable across "
"so it is in the ``Dependent Variable`` box, and then move the ``drug`` "
"variable across so it is in the ``Fixed Factors`` box. This should give the "
"results as shown in :numref:`fig-anova2`.\\ [#]_ Note I have also checked "
"the η² checkbox, pronounced “eta” squared, under the ``Effect Size`` option "
"and this is also shown on the results table. We will come back to effect "
"sizes a bit later."
msgstr ""
"Щоб полегшити вам життя, jamovi може виконати дисперсійний аналіз… ура! "
"Перейдіть до ``ANOVA`` - ``ANOVA`` аналіз та переміщення ``mood.gain`` "
"змінна по горизонталі, тому вона знаходиться в ``Dependent Variable`` поле, "
"а потім перемістіть ``drug`` змінна по горизонталі, тому вона знаходиться в "
"``Fixed Factors`` коробка. Це має дати результати, як показано на :numref"
":`fig-anova2`.\\ [#]_ Зверніть увагу, що я також поставив галочку навпроти "
"η², що вимовляється як «ета» у квадраті, під ``Effect Size`` опцію, і це "
"також показано в таблиці результатів. Ми повернемося до розмірів ефектів "
"трохи пізніше."

#: ../../Ch13/Ch13_ANOVA_03.rst:27
msgid "``ANOVA`` results table for ``mood.gain`` by ``drug`` administered"
msgstr "``ANOVA`` таблиця результатів для ``mood.gain`` від ``drug`` введено"

#: ../../Ch13/Ch13_ANOVA_03.rst:31
msgid ""
"jamovi ``ANOVA`` results table for ``mood.gain`` by ``drug`` administered"
msgstr ""
"jamovi ``ANOVA`` таблиця результатів для ``mood.gain`` від ``drug`` введено"

#: ../../Ch13/Ch13_ANOVA_03.rst:35
msgid ""
"The jamovi results table shows you the sums of squares values, the degrees "
"of freedom, and a couple of other quantities that we’re not really "
"interested in right now. Notice, however, that jamovi doesn’t use the names "
"“between-group” and “within-group”. Instead, it tries to assign more "
"meaningful names. In our particular example, the *between groups* variance "
"corresponds to the effect that the ``drug`` has on the outcome variable, and "
"the *within groups* variance corresponds to the “leftover” variability so it "
"calls that the *residuals*. If we compare these numbers to the numbers that "
"I calculated by hand in section :ref:`A worked example <worked_example>`, "
"you can see that they’re more or less the same, apart from rounding errors. "
"The between groups sums of squares is SS\\ :sub:`b` = 3.45, the within "
"groups sums of squares is SS\\ :sub:`w` = 1.39, and the degrees of freedom "
"are 2 and 15 respectively. We also get the *F*-value and the *p*-value and, "
"again, these are more or less the same, give or take rounding errors, to the "
"numbers that we calculated ourselves when doing it the long and tedious way."
msgstr ""
"Таблиця результатів jamovi показує суми квадратів значень, ступені свободи "
"та кілька інших величин, які нас зараз не цікавлять. Однак зверніть увагу, "
"що jamovi не використовує назви «міжгруповий» та «внутрішньогруповий». "
"Натомість він намагається присвоїти більш значущі назви. У нашому "
"конкретному прикладі дисперсія *між групами* відповідає впливу, який ``ліки``"
" мають на змінну результату, а дисперсія *всередині груп* відповідає "
"«залишковій» мінливості, тому вона називається *залишками*. Якщо порівняти "
"ці числа з тими, які я обчислив вручну в розділі :ref:`A worked example "
"<worked_example>`, можна побачити, що вони більш-менш однакові, за винятком "
"похибок округлення. Сума квадратів між групами становить SS\\ :sub:`b` = "
"3,45, сума квадратів всередині груп становить SS\\ :sub:`w` = 1,39, а "
"ступені свободи становлять відповідно 2 і 15. Ми також отримуємо значення *F*"
" і значення *p*, і, знову ж таки, вони більш-менш збігаються, з урахуванням "
"похибок округлення, з числами, які ми обчислили самостійно, використовуючи "
"довгий і нудний метод."

#: ../../Ch13/Ch13_ANOVA_03.rst:54
msgid ""
"The jamovi results are more accurate than the ones in the text above, due to "
"rounding errors."
msgstr ""
"Результати jamovi точніші, ніж ті, що наведені в тексті вище, через помилки "
"округлення."

#: ../../Ch13/Ch13_ANOVA_04.rst:4
msgid "Effect size"
msgstr "Розмір ефекту"

#: ../../Ch13/Ch13_ANOVA_04.rst:6
msgid ""
"There’s a few different ways you could measure the effect size in an ANOVA, "
"but the most commonly used measures are η² (**eta squared**) and partial η². "
"For a one-way analysis of variance they’re identical to each other, so for "
"the moment I’ll just explain η². The definition of η² is actually really "
"simple"
msgstr ""
"Існує кілька різних способів вимірювання розміру ефекту в ANOVA, але "
"найчастіше використовуються η² (**ета в квадраті**) і часткове η². Для "
"однофакторного дисперсійного аналізу вони ідентичні, тому поки що я поясню "
"тільки η². Визначення η² насправді дуже просте"

#: ../../Ch13/Ch13_ANOVA_04.rst:13
msgid "η² = SS\\ :sub:`b` / SS\\ :sub:`tot`"
msgstr "η² = SS\\ :sub:`b` / SS\\ :sub:`tot`"

#: ../../Ch13/Ch13_ANOVA_04.rst:15
msgid ""
"That’s all it is. So when I look at the ANOVA table in :numref:`fig-anova2`, "
"I see that SS\\ :sub:`b`   = 3.45 and SS\\ :sub:`tot` = 3.45 + 1.39 = 4.84. "
"Thus we get an η² value of"
msgstr ""
"Ось і все. Отже, коли я дивлюся на таблицю ANOVA у :numref:`fig-anova2`, я "
"бачу, що SS\\ :sub:`b` = 3,45 та SS\\ :sub:`tot` = 3,45 + 1,39 = 4,84. Таким "
"чином, ми отримуємо значення η²"

#: ../../Ch13/Ch13_ANOVA_04.rst:20
msgid "η² = 3.45 / 4.84 = 0.71"
msgstr "η² = 3.45 / 4.84 = 0.71"

#: ../../Ch13/Ch13_ANOVA_04.rst:22
msgid ""
"The interpretation of η² is equally straightforward. It refers to the "
"proportion of the variability in the outcome variable (``mood.gain``) that "
"can be explained in terms of the predictor (``drug``). A value of η² = 0 "
"means that there is no relationship at all between the two, whereas a value "
"of η = 1 means that the relationship is perfect. Better yet, the η² value is "
"very closely related to *R*\\², as discussed previously in subsection :doc:"
"`The *R*\\² (R-squared) value <../Ch12/Ch12_Regression_06>`, and has an "
"equivalent interpretation."
msgstr ""
"Інтерпретація η² є настільки ж простою. Вона стосується частки мінливості в "
"результативній змінній (``mood.gain``), яку можна пояснити за допомогою "
"предиктора (``drug``). Значення η² = 0 означає, що між цими двома змінними "
"немає жодного зв'язку, тоді як значення η = 1 означає, що зв'язок є "
"ідеальним. Більше того, значення η² дуже тісно пов'язане з *R*\\², як "
"обговорювалося раніше в підрозділі :doc:`The *R*\\² (R-squared) value <../"
"Ch12/Ch12_Regression_06>`, і має еквівалентне тлумачення."

#: ../../Ch13/Ch13_ANOVA_04.rst:31
msgid ""
"Although many statistics text books suggest η² as the default effect size "
"measure in ANOVA, there’s an interesting `blog post <https://daniellakens."
"blogspot.com.au/2015/06/why-you-should-use-omega-squared.html>`__ by Daniel "
"Lakens suggesting that eta-squared is perhaps not the best measure of effect "
"size in real world data analysis, because it can be a biased estimator. "
"Usefully, there is also an option in jamovi to specify omega-squared (ω²), "
"which is less biased, alongside eta-squared."
msgstr ""
"Хоча багато підручників зі статистики пропонують η² як стандартний показник "
"розміру ефекту в ANOVA, є цікавий блог-пост <https://"
"daniellakens.blogspot.com.au/2015/06/why-you-should-use-omega-"
"squared.html>__, в якому Даніель Лейкенс висловлює думку, що eta-squared, "
"можливо, не є найкращим показником розміру ефекту в аналізі реальних даних, "
"оскільки може бути упередженим оцінювачем. Корисно, що в jamovi також є "
"опція для визначення omega-squared (ω²), який є менш упередженим, поряд з "
"eta-squared."

#: ../../Ch13/Ch13_ANOVA_05.rst:4
msgid "Multiple comparisons and post-hoc tests"
msgstr "Багаторазові порівняння та постфактумні тести"

#: ../../Ch13/Ch13_ANOVA_05.rst:6
msgid ""
"Any time you run an ANOVA with more than two groups and you end up with a "
"significant effect, the first thing you’ll probably want to ask is which "
"groups are actually different from one another. In our drugs example, our "
"null hypothesis was that all three drugs (placebo, Anxifree and Joyzepam) "
"have the exact same effect on mood. But if you think about it, the null "
"hypothesis is actually claiming *three* different things all at once here. "
"Specifically, it claims that:"
msgstr ""
"Кожного разу, коли ви проводите ANOVA з більш ніж двома групами і отримуєте "
"значущий ефект, перше, що ви, ймовірно, захочете запитати, це які групи "
"насправді відрізняються одна від одної. У нашому прикладі з ліками нульова "
"гіпотеза полягала в тому, що всі три препарати (плацебо, Anxifree і Joyzepam)"
" мають однаковий вплив на настрій. Але якщо задуматися, нульова гіпотеза "
"насправді стверджує *три* різні речі одночасно. Зокрема, вона стверджує, що:"

#: ../../Ch13/Ch13_ANOVA_05.rst:14
msgid ""
"Your competitor’s drug (Anxifree) is no better than a placebo (i.e., µ\\ :"
"sub:`A` = µ\\ :sub:`P`)"
msgstr ""
"Препарат вашого конкурента (Anxifree) нічим не кращий за плацебо (тобто µ\\ "
":sub:`A` = µ\\ :sub:`P`)"

#: ../../Ch13/Ch13_ANOVA_05.rst:17
msgid ""
"Your drug (Joyzepam) is no better than a placebo (i.e., µ\\ :sub:`J` = µ\\ :"
"sub:`P`)"
msgstr ""
"Ваш препарат (Джойзепам) нічим не кращий за плацебо (тобто µ\\ :sub:`J` = µ\\"
" :sub:`P`)"

#: ../../Ch13/Ch13_ANOVA_05.rst:20
msgid ""
"Anxifree and Joyzepam are equally effective (i.e., µ\\ :sub:`J` = µ\\ :sub:"
"`A`)"
msgstr ""
"Анксіфрі та Джойзепам однаково ефективні (i.e., µ\\ :sub:`J` = µ\\ :sub:`A`)"

#: ../../Ch13/Ch13_ANOVA_05.rst:23
msgid ""
"If any one of those three claims is false, then the null hypothesis is also "
"false. So, now that we’ve rejected our null hypothesis, we’re thinking that "
"*at least* one of those things isn’t true. But which ones? All three of "
"these propositions are of interest. Since you certainly want to know if your "
"new drug Joyzepam is better than a placebo, it would be nice to know how "
"well it stacks up against an existing commercial alternative (i.e., "
"Anxifree). It would even be useful to check the performance of Anxifree "
"against the placebo. Even if Anxifree has already been extensively tested "
"against placebos by other researchers, it can still be very useful to check "
"that your study is producing similar results to earlier work."
msgstr ""
"Якщо хоча б одне з цих трьох тверджень є хибним, то нульова гіпотеза також є "
"хибною. Отже, тепер, коли ми відхилили нульову гіпотезу, ми вважаємо, що "
"*принаймні* одне з цих тверджень не є правдивим. Але яке саме? Всі три "
"твердження є цікавими. Оскільки ви, безсумнівно, хочете знати, чи новий "
"препарат Joyzepam є кращим за плацебо, було б добре дізнатися, як він "
"порівнюється з існуючою комерційною альтернативою (тобто Anxifree). Було б "
"навіть корисно перевірити ефективність Anxifree порівняно з плацебо. Навіть "
"якщо Anxifree вже було ретельно протестовано порівняно з плацебо іншими "
"дослідниками, все одно може бути дуже корисно перевірити, чи ваше "
"дослідження дає подібні результати до попередніх робіт."

#: ../../Ch13/Ch13_ANOVA_05.rst:35
msgid ""
"When we characterise the null hypothesis in terms of these three distinct "
"propositions, it becomes clear that there are eight possible “states of the "
"world” that we need to distinguish between:"
msgstr ""
"Коли ми характеризуємо нульову гіпотезу з точки зору цих трьох різних "
"тверджень, стає зрозуміло, що існує вісім можливих «станів світу», які нам "
"потрібно розрізняти:"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "possibility:"
msgstr "можливість:"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "is µ\\ :sub:`P` = µ\\ :sub:`A`"
msgstr "є µ\\ :sub:`P` = µ\\ :sub:`A`"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "is µ\\ :sub:`P` = µ\\ :sub:`J`"
msgstr "є µ\\ :sub:`P` = µ\\ :sub:`J`"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "is µ\\ :sub:`A` = µ\\ :sub:`J`"
msgstr "є µ\\ :sub:`A` = µ\\ :sub:`J`"

#: ../../Ch13/Ch13_ANOVA_05.rst:40
msgid "which hypothesis?"
msgstr "яка гіпотеза?"

#: ../../Ch13/Ch13_ANOVA_05.rst:43 ../../Ch13/Ch13_ANOVA_05.rst:45
#: ../../Ch13/Ch13_ANOVA_05.rst:47 ../../Ch13/Ch13_ANOVA_05.rst:49
#: ../../Ch13/Ch13_ANOVA_05.rst:51 ../../Ch13/Ch13_ANOVA_05.rst:53
#: ../../Ch13/Ch13_ANOVA_05.rst:55
msgid "✓"
msgstr "✓"

#: ../../Ch13/Ch13_ANOVA_05.rst:43
msgid "null"
msgstr "нульовий"

#: ../../Ch13/Ch13_ANOVA_05.rst:45 ../../Ch13/Ch13_ANOVA_05.rst:47
#: ../../Ch13/Ch13_ANOVA_05.rst:49 ../../Ch13/Ch13_ANOVA_05.rst:51
#: ../../Ch13/Ch13_ANOVA_05.rst:53 ../../Ch13/Ch13_ANOVA_05.rst:55
#: ../../Ch13/Ch13_ANOVA_05.rst:57
msgid "alternative"
msgstr "альтернатива"

#: ../../Ch13/Ch13_ANOVA_05.rst:55 ../../Ch13/Ch13_ANOVA_07.rst:66
#: ../../Ch13/Ch13_ANOVA_07.rst:68 ../../Ch13/Ch13_ANOVA_07.rst:76
msgid "7"
msgstr "7"

#: ../../Ch13/Ch13_ANOVA_05.rst:57 ../../Ch13/Ch13_ANOVA_07.rst:66
#: ../../Ch13/Ch13_ANOVA_07.rst:68 ../../Ch13/Ch13_ANOVA_07.rst:76
msgid "8"
msgstr "8"

#: ../../Ch13/Ch13_ANOVA_05.rst:60
msgid ""
"By rejecting the null hypothesis, we’ve decided that we *don’t* believe that "
"#1 is the true state of the world. The next question to ask is, which of the "
"other seven possibilities *do* we think is right? When faced with this "
"situation, its usually helps to look at the data. For instance, if we look "
"at the plots in :numref:`fig-anova1`, it’s tempting to conclude that "
"Joyzepam is better than the placebo and better than Anxifree, but there’s no "
"real difference between Anxifree and the placebo. However, if we want to get "
"a clearer answer about this, it might help to run some tests."
msgstr ""
"Відхиливши нульову гіпотезу, ми вирішили, що *не* віримо в те, що № 1 є "
"справжнім станом світу. Наступне питання, яке слід задати, — яка з інших "
"семи можливостей, *на* нашу думку, є правильною? У такій ситуації зазвичай "
"допомагає аналіз даних. Наприклад, якщо подивитися на графіки в :numref:`fig-"
"anova1`, то можна зробити висновок, що Joyzepam кращий за плацебо і кращий "
"за Anxifree, але між Anxifree і плацебо немає реальної різниці. Однак, якщо "
"ми хочемо отримати більш чітку відповідь на це питання, може бути корисно "
"провести кілька тестів."

#: ../../Ch13/Ch13_ANOVA_05.rst:71
msgid "Running “pairwise” *t*-tests"
msgstr "Проведення «парних» *t*-тестів"

#: ../../Ch13/Ch13_ANOVA_05.rst:73
msgid ""
"How might we go about solving our problem? Given that we’ve got three "
"separate pairs of means (placebo versus Anxifree, placebo versus Joyzepam, "
"and Anxifree versus Joyzepam) to compare, what we could do is run three "
"separate *t*-tests and see what happens. This is easy to do in jamovi. Go to "
"the ``ANOVA`` → ``Post Hoc Tests`` options, move the ``drug`` variable "
"across into the active box on the right, and then click on the ``No "
"correction`` checkbox. This will produce a neat table showing all the "
"pairwise *t*-test comparisons amongst the three levels of the ``drug`` "
"variable, as in :numref:`fig-anova3`."
msgstr ""
"Як ми можемо вирішити нашу проблему? Враховуючи, що ми маємо три окремі пари "
"середніх значень (плацебо проти Anxifree, плацебо проти Joyzepam та Anxifree "
"проти Joyzepam) для порівняння, ми можемо провести три окремі *t*-тести і "
"подивитися, що буде. Це легко зробити в jamovi. Перейдіть до опцій ``ANOVA`` "
"→ ``Post Hoc Tests``, перемістіть змінну ``drug`` у активне поле праворуч, а "
"потім натисніть на прапорець ``No correction``. У результаті з'явиться чітка "
"таблиця, що показує всі парні порівняння *t*-тестів між трьома рівнями "
"змінної ``drug``, як у :numref:`fig-anova3`."

#: ../../Ch13/Ch13_ANOVA_05.rst:85 ../../Ch13/Ch13_ANOVA_05.rst:89
msgid "Uncorrected pairwise *t*-tests as post-hoc comparisons in jamovi"
msgstr "Нескориговані попарні *t*-тести як постфактумні порівняння в jamovi"

#: ../../Ch13/Ch13_ANOVA_05.rst:94
msgid "Corrections for multiple testing"
msgstr "Виправлення для багаторазового тестування"

#: ../../Ch13/Ch13_ANOVA_05.rst:96
msgid ""
"In the previous section I hinted that there’s a problem with just running "
"lots and lots of *t*-tests. The concern is that, when running these "
"analyses, what we’re doing is going on a “fishing expedition”. We’re running "
"lots and lots of tests without much theoretical guidance in the hope that "
"some of them come up significant. This kind of theory-free search for group "
"differences is referred to as **post-hoc analysis** (“post-hoc” being Latin "
"for “after this”).\\ [#]_"
msgstr ""
"У попередньому розділі я натякнув, що є проблема з тим, щоб просто проводити "
"безліч *t*-тестів. Проблема полягає в тому, що, проводячи ці аналізи, ми "
"фактично займаємося «риболовлею». Ми проводимо безліч тестів без особливого "
"теоретичного підґрунтя, сподіваючись, що деякі з них виявляться значущими. "
"Такий пошук групових відмінностей без теоретичного підґрунтя називається "
"**постфактум-аналізом** («post-hoc» з латинської означає «після цього»).\\ "
"[#]_"

#: ../../Ch13/Ch13_ANOVA_05.rst:104
msgid ""
"It’s okay to run post-hoc analyses, but a lot of care is required. For "
"instance, the analysis that I ran in the previous section should be avoided, "
"as each *individual* *t*-test is designed to have a 5\\% Type I error rate "
"(i.e., α = 0.05) and I ran three of these tests. Imagine what would have "
"happened if my ANOVA involved 10 different groups, and I had decided to run "
"45 “post-hoc” *t*-tests to try to find out which ones were significantly "
"different from each other, you’d expect 2 or 3 of them to come up "
"significant *by chance alone*. As we saw in chapter :doc:`../Ch09/"
"Ch09_HypothesisTesting`, the central organising principle behind null "
"hypothesis testing is that we seek to control our Type I error rate, but now "
"that I’m running lots of *t*-tests at once in order to determine the source "
"of my ANOVA results, my actual Type I error rate across this whole *family* "
"of tests has gotten completely out of control."
msgstr ""
"Проводити пост-фактум аналіз можна, але потрібно бути дуже обережним. "
"Наприклад, аналіз, який я провів у попередньому розділі, слід уникати, "
"оскільки кожен *індивідуальний* *t*-тест розрахований на 5\\% рівень помилки "
"I типу (тобто α = 0,05), а я провів три таких тести. Уявіть, що сталося б, "
"якби мій ANOVA охоплював 10 різних груп, і я вирішив провести 45 "
"«постфактумних» *t*-тестів, щоб з'ясувати, які з них істотно відрізняються "
"одна від одної. Ви б очікували, що 2 або 3 з них виявляться істотними *"
"виключно завдяки випадковості*. Як ми бачили в розділі :doc:`../Ch09/"
"Ch09_HypothesisTesting`, центральним організаційним принципом тестування "
"нульової гіпотези є те, що ми прагнемо контролювати рівень помилки I типу, "
"але тепер, коли я проводжу багато *t*-тестів одночасно, щоб визначити "
"джерело результатів ANOVA, мій фактичний рівень помилки I типу по всій цій "
"*сім'ї* тестів повністю вийшов з-під контролю."

#: ../../Ch13/Ch13_ANOVA_05.rst:117
msgid ""
"The usual solution to this problem is to introduce an adjustment to the *p*-"
"value, which aims to control the total error rate across the family of tests "
"(:ref:`Shaffer, 1995 <Shaffer_1995>`). An adjustment of this form, which is "
"usually (but not always) applied because one is doing post-hoc analysis, is "
"often referred to as a **correction for multiple comparisons**, though it is "
"sometimes referred to as “simultaneous inference”. In any case, there are "
"quite a few different ways of doing this adjustment. I’ll discuss a few of "
"them in this section and in section :doc:`../Ch14/Ch14_ANOVA2_09`, but you "
"should be aware that there are many other methods out there (:ref:`Hsu, 1996 "
"<Hsu_1996>`)."
msgstr ""
"Звичайним рішенням цієї проблеми є введення коригування *p*-значення, яке "
"має на меті контролювати загальний рівень помилок у всій родині тестів "
"(:ref:`Shaffer, 1995 <Shaffer_1995>`). Коригування такого типу, яке зазвичай "
"(але не завжди) застосовується під час пост-гок аналізу, часто називають **"
"корекцією для множинних порівнянь**, хоча іноді його називають «одночасним "
"висновком». У будь-якому випадку, існує чимало різних способів здійснення "
"такого коригування. Я обговорю деякі з них у цьому розділі та в розділі "
":doc:`../Ch14/Ch14_ANOVA2_09`, але ви повинні знати, що існує багато інших "
"методів (:ref:`Hsu, 1996 <Hsu_1996>`)."

#: ../../Ch13/Ch13_ANOVA_05.rst:129
msgid "Bonferroni corrections"
msgstr "Поправки Бонферроні"

#: ../../Ch13/Ch13_ANOVA_05.rst:131
msgid ""
"The simplest of these adjustments is called the **Bonferroni correction** (:"
"ref:`Dunn, 1961 <Dunn_1961>`), and it’s very very simple indeed. Suppose "
"that my post-hoc analysis consists of *m* separate tests, and I want to "
"ensure that the total probability of making *any* Type I errors at all is at "
"most α.\\ [#]_ If so, then the Bonferroni correction just says “multiply all "
"your raw *p*-values by *m*”. If we let *p* denote the original *p*-value, "
"and let *p*'\\ :sub:`j` be the corrected value, then the Bonferroni "
"correction tells that:"
msgstr ""
"Найпростіша з цих корекцій називається **корекцією Бонферроні** (:ref:`Dunn, "
"1961 <Dunn_1961>`), і вона дійсно дуже проста. Припустимо, що мій пост-гок "
"аналіз складається з *m* окремих тестів, і я хочу переконатися, що загальна "
"ймовірність *будь-якої* помилки типу I не перевищує α.\\ [#]_ Якщо так, то "
"корекція Бонферроні просто говорить: «помножте всі ваші необроблені *p*-"
"значення на *m*». Якщо ми позначимо *p* як оригінальне *p*-значення, а *p*'\\"
" :sub:`j` як скориговане значення, то корекція Бонферроні говорить, що:"

#: ../../Ch13/Ch13_ANOVA_05.rst:140
msgid "*p*'\\ :sub:`j` = *m* × *p*"
msgstr "*p*'\\ :sub:`j` = *m* × *p*"

#: ../../Ch13/Ch13_ANOVA_05.rst:142
msgid ""
"And therefore, if you’re using the Bonferroni correction, you would reject "
"the null hypothesis if *p*'\\ :sub:`j` < α. The logic behind this correction "
"is very straightforward. We’re doing *m* different tests, so if we arrange "
"it so that each test has a Type I error rate of at most α / *m*, then the "
"*total* Type I error rate across these tests cannot be larger than α. That’s "
"pretty simple, so much so that in the original paper, the author writes,"
msgstr ""
"Отже, якщо ви використовуєте поправку Бонферроні, ви відхилите нульову "
"гіпотезу, якщо *p*'\\ :sub:`j` < α. Логіка цієї поправки дуже проста. Ми "
"проводимо *m* різних тестів, тому якщо ми організуємо їх так, щоб кожен тест "
"мав рівень помилки типу I не більше α / *m*, то *загальний* рівень помилки "
"типу I для всіх цих тестів не може бути більшим за α. Це досить просто, "
"настільки, що в оригінальній статті автор пише:"

#: ../../Ch13/Ch13_ANOVA_05.rst:150
msgid ""
"The method given here is so simple and so general that I am sure it must "
"have been used before this. I do not find it, however, so can only conclude "
"that perhaps its very simplicity has kept statisticians from realizing that "
"it is a very good method in some situations (:ref:`Dunn, 1961 <Dunn_1961>`, "
"pp. 52-53)."
msgstr ""
"Наведений тут метод настільки простий і загальний, що я впевнений, що його "
"вже використовували раніше. Однак я не знайшов його, тому можу лише зробити "
"висновок, що, можливо, саме його простота завадила статистикам усвідомити, "
"що в деяких ситуаціях це дуже хороший метод (:ref:`Dunn, 1961 <Dunn_1961>`, "
"с. 52-53)."

#: ../../Ch13/Ch13_ANOVA_05.rst:156
msgid ""
"To use the Bonferroni correction in jamovi, just click on the ``Bonferroni`` "
"checkbox in the ``Correction`` options, and you will see another column "
"added to the ``ANOVA`` results table showing the adjusted *p*-values for the "
"Bonferroni correction (:numref:`fig-anova3`). If we compare these three *p*-"
"values to those for the uncorrected, pairwise *t*-tests, it is clear that "
"the only thing that jamovi has done is multiply them by 3."
msgstr ""
"Щоб використовувати корекцію Бонферроні в jamovi, просто натисніть на "
"прапорець ``Bonferroni`` в опціях ``Correction``, і ви побачите, що до "
"таблиці результатів ``ANOVA`` додано ще один стовпець, який показує "
"скориговані *p*-значення для корекції Бонферроні (:numref:`fig-anova3`). "
"Якщо порівняти ці три *p*-значення з тими, що отримані для некоригованих "
"парних *t*-тестів, стає зрозуміло, що jamovi лише помножив їх на 3."

#: ../../Ch13/Ch13_ANOVA_05.rst:165
msgid "Holm corrections"
msgstr "Поправки Холма"

#: ../../Ch13/Ch13_ANOVA_05.rst:167
msgid ""
"Although the Bonferroni correction is the simplest adjustment out there, "
"it’s not usually the best one to use. One method that is often used instead "
"is the **Holm correction** (:ref:`Holm, 1979 <Holm_1979>`). The idea behind "
"the Holm correction is to pretend that you’re doing the tests sequentially, "
"starting with the smallest (raw) *p*-value and moving onto the largest one. "
"For the *j*-th largest of the *p*-values, the adjustment is *either*"
msgstr ""
"Хоча корекція Бонферроні є найпростішою з існуючих, зазвичай вона не є "
"найкращою для використання. Замість неї часто використовують метод **"
"корекції Холма** (:ref:`Holm, 1979 <Holm_1979>`). Ідея корекції Холма "
"полягає в тому, щоб уявити, що ви проводите тести послідовно, починаючи з "
"найменшого (сирого) значення *p* і переходячи до найбільшого. Для *j*-го за "
"величиною значення *p* коригування становить *або*"

#: ../../Ch13/Ch13_ANOVA_05.rst:174
msgid "*p*'\\ :sub:`j` = j × *p*\\ :sub:`j`"
msgstr "*p*'\\ :sub:`j` = j × *p*\\ :sub:`j`"

#: ../../Ch13/Ch13_ANOVA_05.rst:176
msgid ""
"(i.e., the biggest *p*-value remains unchanged, the second biggest *p*-value "
"is doubled, the third biggest *p*-value is tripled, and so on), *or*"
msgstr ""
"(тобто, найбільше значення *p* залишається незмінним, друге за величиною "
"значення *p* подвоюється, третє за величиною значення *p* потроюється тощо), "
"*або*"

#: ../../Ch13/Ch13_ANOVA_05.rst:180
msgid "*p*'\\ :sub:`j` = *p*'\\ :sub:`j + 1`"
msgstr "*p*'\\ :sub:`j` = *p*'\\ :sub:`j + 1`"

#: ../../Ch13/Ch13_ANOVA_05.rst:182
msgid ""
"whichever one is larger. This might sound a little confusing, so let’s go "
"through it a little more slowly. Here’s what the Holm correction does. "
"First, you sort all of your *p*-values in order, from smallest to largest. "
"For the smallest *p*-value all you do is multiply it by *m*, and you’re "
"done. However, for all the other ones it’s a two-stage process. For "
"instance, when you move to the second smallest *p*-value, you first multiply "
"it by *m* - 1. If this produces a number that is bigger than the adjusted "
"*p*-value that you got last time, then you keep it. But if it’s smaller than "
"the last one, then you copy the last *p*-value. To illustrate how this "
"works, consider the table below, which shows the calculations of a Holm "
"correction for a collection of five *p*-values:"
msgstr ""
"залежно від того, яке з них більше. Це може здатися трохи заплутаним, тому "
"давайте розберемося в цьому трохи повільніше. Ось як працює корекція Холма. "
"Спочатку ви сортуєте всі свої *p*-значення в порядку від найменшого до "
"найбільшого. Для найменшого *p*-значення все, що вам потрібно зробити, це "
"помножити його на *m*, і все готово. Однак для всіх інших це двоступеневий "
"процес. Наприклад, коли ви переходите до другого найменшого значення *p*, "
"спочатку помножте його на *m* - 1. Якщо в результаті ви отримаєте число, яке "
"є більшим за скориговане значення *p*, яке ви отримали минулого разу, то "
"залиште його. Але якщо воно менше за останнє, то копіюєте останнє значення "
"*p*. Щоб проілюструвати, як це працює, розгляньте таблицю нижче, яка показує "
"розрахунки корекції Холма для набору з п'яти значень *p*:"

#: ../../Ch13/Ch13_ANOVA_05.rst:196
msgid "raw *p* rank"
msgstr "сирий *p* ранг"

#: ../../Ch13/Ch13_ANOVA_05.rst:196
msgid "*j*"
msgstr "*j*"

#: ../../Ch13/Ch13_ANOVA_05.rst:196
msgid "*p* × *j*"
msgstr "*p* × *j*"

#: ../../Ch13/Ch13_ANOVA_05.rst:196
msgid "Holm *p*"
msgstr "Холм *p*"

#: ../../Ch13/Ch13_ANOVA_05.rst:198
msgid ".001"
msgstr ".001"

#: ../../Ch13/Ch13_ANOVA_05.rst:198
msgid "0.005"
msgstr "0.005"

#: ../../Ch13/Ch13_ANOVA_05.rst:200
msgid ".005"
msgstr ".005"

#: ../../Ch13/Ch13_ANOVA_05.rst:200
msgid "0.020"
msgstr "0.020"

#: ../../Ch13/Ch13_ANOVA_05.rst:202
msgid ".019"
msgstr ".019"

#: ../../Ch13/Ch13_ANOVA_05.rst:202 ../../Ch13/Ch13_ANOVA_05.rst:204
msgid "0.057"
msgstr "0.057"

#: ../../Ch13/Ch13_ANOVA_05.rst:204
msgid ".022"
msgstr ".022"

#: ../../Ch13/Ch13_ANOVA_05.rst:204
msgid "0.044"
msgstr "0.044"

#: ../../Ch13/Ch13_ANOVA_05.rst:206
msgid ".103"
msgstr ".103"

#: ../../Ch13/Ch13_ANOVA_05.rst:206
msgid "0.103"
msgstr "0.103"

#: ../../Ch13/Ch13_ANOVA_05.rst:209
msgid "Hopefully that makes things clear."
msgstr "Сподіваюся, це все прояснює."

#: ../../Ch13/Ch13_ANOVA_05.rst:211
msgid ""
"Although it’s a little harder to calculate, the Holm correction has some "
"very nice properties. It’s more powerful than Bonferroni (i.e., it has a "
"lower Type II error rate) but, counter-intuitive as it might seem, it has "
"the *same* Type I error rate. As a consequence, in practice there’s never "
"any reason to use the simpler Bonferroni correction since it is always "
"outperformed by the slightly more elaborate Holm correction. Because of "
"this, the Holm correction should be your *go to* multiple comparison "
"correction. :numref:`fig-anova3` also shows the Holm corrected *p*-values "
"and, as you can see, the biggest *p*-value (corresponding to the comparison "
"between Anxifree and the placebo) is unaltered. At a value of 0.15, it is "
"exactly the same as the value we got originally when we applied no "
"correction at all. In contrast, the smallest *p*-value (Joyzepam versus "
"placebo) has been multiplied by three."
msgstr ""
"Хоча її трохи складніше обчислити, корекція Холма має деякі дуже приємні "
"властивості. Вона є більш потужною, ніж корекція Бонферроні (тобто має "
"нижчий рівень помилки II типу), але, як не дивно, має *такий самий* рівень "
"помилки I типу. Як наслідок, на практиці ніколи немає причин використовувати "
"простішу поправку Бонферроні, оскільки вона завжди поступається дещо більш "
"складною поправкою Холма. З огляду на це, поправка Холма повинна бути вашим "
"*основним* вибором для поправки множинних порівнянь. :numref:`fig-anova3` "
"також показує скориговані за Холмом *p*-значення, і, як ви можете бачити, "
"найбільше *p*-значення (що відповідає порівнянню між Anxifree і плацебо) не "
"змінилося. Зі значенням 0,15 воно точно збігається із значенням, яке ми "
"отримали спочатку, коли не застосовували жодної корекції. Натомість найменше "
"значення *p* (Joyzepam проти плацебо) було помножено на три."

#: ../../Ch13/Ch13_ANOVA_05.rst:226
msgid "Writing up the post-hoc test"
msgstr "Написання постфактумного тесту"

#: ../../Ch13/Ch13_ANOVA_05.rst:228
msgid ""
"Finally, having run the post-hoc analysis to determine which groups are "
"significantly different to one another, you might write up the result like "
"this:"
msgstr ""
"Зрештою, виконавши постфактумний аналіз, щоб визначити, які групи суттєво "
"відрізняються одна від одної, ви можете записати результат так:"

#: ../../Ch13/Ch13_ANOVA_05.rst:232
msgid ""
"Post-hoc tests (using the Holm correction to adjust *p*) indicated that "
"Joyzepam produced a significantly larger mood change than both Anxifree (*p* "
"= 0.001) and the placebo (*p* = 9.0 · 10\\ :sup:`-5`). We found no evidence "
"that Anxifree performed better than the placebo (*p* = 0.15)."
msgstr ""
"Пост-хок тести (з використанням поправки Холма для коригування *p*) "
"показали, що Joyzepam викликав значно більшу зміну настрою, ніж Anxifree (*p*"
" = 0,001) і плацебо (*p* = 9,0 · 10\\ :sup:`-5`). Ми не знайшли доказів "
"того, що Anxifree діє краще, ніж плацебо (*p* = 0,15)."

#: ../../Ch13/Ch13_ANOVA_05.rst:238
msgid ""
"Or, if you don’t like the idea of reporting exact *p*-values, then you’d "
"change those numbers to *p* < 0.001`, *p* < 0.01 and *p* > 0.05 "
"respectively. Either way, the key thing is that you indicate that you used "
"Holm’s correction to adjust the *p*-values. And of course, I’m assuming that "
"elsewhere in the write up you’ve included the relevant descriptive "
"statistics (i.e., the group means and standard deviations), since these *p*-"
"values on their own aren’t terribly informative."
msgstr ""
"Або, якщо вам не подобається ідея повідомляти точні значення *p*, ви можете "
"змінити ці цифри на *p* < 0,001`, *p* < 0,01 та *p* > 0,05 відповідно. У "
"будь-якому випадку, головне — вказати, що ви використовували поправку Холма "
"для коригування значень *p*. І, звичайно, я припускаю, що в іншому місці "
"статті ви включили відповідні описові статистичні дані (тобто середні "
"значення групи та стандартні відхилення), оскільки ці *p*-значення самі по "
"собі не є надто інформативними."

#: ../../Ch13/Ch13_ANOVA_05.rst:250
msgid ""
"If you *do* have some theoretical basis for wanting to investigate some "
"comparisons but not others, it’s a different story. In those circumstances "
"you’re not really running “post-hoc” analyses at all, you’re making “planned "
"comparisons”. I do talk about this situation later in the book in section :"
"doc:`../Ch14/Ch14_ANOVA2_10`), but for now I want to keep things simple."
msgstr ""
"Якщо у вас *є* теоретичне обґрунтування для того, щоб досліджувати деякі "
"порівняння, а інші — ні, то це інша історія. У таких обставинах ви насправді "
"не проводите «постфактум» аналіз, а робите «заплановані порівняння». Я "
"говорю про цю ситуацію далі в книзі в розділі :doc:`../Ch14/Ch14_ANOVA2_10`)"
", але поки що я хочу, щоб все було просто."

#: ../../Ch13/Ch13_ANOVA_05.rst:257
msgid ""
"It’s worth noting in passing that not all adjustment methods try to do this. "
"What I’ve described here is an approach for controlling “family wise Type I "
"error rate”. However, there are other post-hoc tests that seek to control "
"the “false discovery rate”, which is a somewhat different thing."
msgstr ""
"Варто зауважити, що не всі методи коригування намагаються це зробити. Те, що "
"я тут описав, є підходом до контролю «рівня помилки I типу для всієї родини»"
". Однак існують й інші постфактумні тести, які намагаються контролювати «"
"рівень помилкових відкриттів», що є дещо іншим поняттям."

#: ../../Ch13/Ch13_ANOVA_06.rst:4
msgid "Assumptions of the one-way ANOVA"
msgstr "Припущення однофакторного ANOVA"

#: ../../Ch13/Ch13_ANOVA_06.rst:6
msgid ""
"Like any statistical test, analysis of variance relies on some assumptions "
"about the data, specifically the residuals. There are three key assumptions "
"that you need to be aware of: *normality*, *homogeneity of variance* and "
"*independence*."
msgstr ""
"Як і будь-який статистичний тест, аналіз дисперсії базується на деяких "
"припущеннях щодо даних, зокрема щодо залишків. Існує три основні припущення, "
"про які потрібно знати: *нормальність*, *однорідність дисперсії* та "
"*незалежність*."

#: ../../Ch13/Ch13_ANOVA_06.rst:11
msgid ""
"If you remember back to subsection :ref:`The model for the data and the "
"meaning of *F* <meaning_of_F>` which I hope you at least skimmed even if you "
"didn’t read the whole thing, I described the statistical models underpinning "
"ANOVA in this way:"
msgstr ""
"Якщо ви пам'ятаєте підрозділ :ref:`The model for the data and the meaning of "
"*F* <meaning_of_F>`, який, сподіваюся, ви хоча б пробігли очима, навіть якщо "
"не прочитали повністю, я описав статистичні моделі, що лежать в основі "
"ANOVA, таким чином:"

#: ../../Ch13/Ch13_ANOVA_06.rst:16
msgid "H\\ :sub:`0`: Y\\ :sub:`ik` = µ           + ϵ\\ :sub:`ik`"
msgstr "H\\ :sub:`0`: Y\\ :sub:`ik` = µ           + ϵ\\ :sub:`ik`"

#: ../../Ch13/Ch13_ANOVA_06.rst:17
msgid "H\\ :sub:`1`: Y\\ :sub:`ik` = µ\\ :sub:`k` + ϵ\\ :sub:`ik`"
msgstr "H\\ :sub:`1`: Y\\ :sub:`ik` = µ\\ :sub:`k` + ϵ\\ :sub:`ik`"

#: ../../Ch13/Ch13_ANOVA_06.rst:19
msgid ""
"In these equations µ refers to a single grand population mean which is the "
"same for all groups, and µ\\ :sub:`k` is the population mean for the *k*-th "
"group. Up to this point we’ve been mostly interested in whether our data are "
"best described in terms of a single grand mean (the null hypothesis) or in "
"terms of different group-specific means (the alternative hypothesis). This "
"makes sense, of course, as that’s actually the important research question! "
"However, all of our testing procedures have, implicitly, relied on a "
"specific assumption about the residuals, ϵ\\ :sub:`ik`, namely that"
msgstr ""
"У цих рівняннях µ позначає єдине загальне середнє значення популяції, яке є "
"однаковим для всіх груп, а µ\\ :sub:`k` — середнє значення популяції для *k*-"
"ї групи. До цього моменту нас найбільше цікавило, чи наші дані найкраще "
"описуються за допомогою єдиного загального середнього значення (нульова "
"гіпотеза), чи за допомогою різних середніх значень для окремих груп ("
"альтернативна гіпотеза). Звичайно, це має сенс, адже це і є важливе "
"дослідницьке питання! Однак усі наші процедури тестування неявним чином "
"базувалися на конкретному припущенні щодо залишків, ϵ\\ :sub:`ik`, а саме, що"

#: ../../Ch13/Ch13_ANOVA_06.rst:31
msgid ""
"None of the maths works properly without this bit. Or, to be precise, you "
"can still do all the calculations and you’ll end up with an *F*-statistic, "
"but you have no guarantee that this *F*-statistic actually measures what you "
"think it’s measuring, and so any conclusions that you might draw on the "
"basis of the *F* test might be wrong."
msgstr ""
"Без цього елемента жодна математична операція не буде працювати належним "
"чином. Або, якщо бути точнішим, ви все одно зможете виконати всі обчислення "
"і отримаєте *F*-статистику, але не будете мати жодної гарантії, що ця *F*-"
"статистика дійсно вимірює те, що ви вважаєте, і тому будь-які висновки, які "
"ви зробите на основі *F*-тесту, можуть бути помилковими."

#: ../../Ch13/Ch13_ANOVA_06.rst:38
msgid ""
"So, how do we check whether the assumption about the residuals is accurate? "
"Well, as I indicated above, there are three distinct claims buried in this "
"one statement, and we’ll consider them separately."
msgstr ""
"Отже, як нам перевірити, чи є припущення щодо залишків точним? Ну, як я "
"зазначав вище, в цьому одному твердженні приховані три окремі твердження, і "
"ми розглянемо їх окремо."

#: ../../Ch13/Ch13_ANOVA_06.rst:42
msgid ""
"**Homogeneity of variance**. Notice that we’ve only got the one value for "
"the population standard deviation (i.e., σ), rather than allowing each group "
"to have it’s own value (i.e., σ\\ :sub:`k`). This is referred to as the "
"homogeneity of variance (sometimes called homoscedasticity) assumption. "
"ANOVA assumes that the population standard deviation is the same for all "
"groups. We’ll talk about this extensively in subsection :ref:`Checking the "
"homogeneity of variance assumption <homogeneity_of_variance_anova>`."
msgstr ""
"**Однорідність дисперсії**. Зверніть увагу, що ми маємо лише одне значення "
"для стандартного відхилення генеральної сукупності (тобто σ), а не "
"дозволяємо кожній групі мати своє власне значення (тобто σ\\ :sub:`k`). Це "
"називається припущенням однорідності дисперсії (іноді його називають "
"гомоскедастичністю). ANOVA припускає, що стандартне відхилення генеральної "
"сукупності є однаковим для всіх груп. Ми детально обговоримо це в підрозділі "
":ref:`Checking the homogeneity of variance assumption "
"<homogeneity_of_variance_anova>`."

#: ../../Ch13/Ch13_ANOVA_06.rst:50
msgid ""
"**Normality**. The residuals are assumed to be normally distributed. As we "
"saw in subsection :doc:`../Ch11/Ch11_tTest_08`, we can assess this by "
"looking at QQ-plots (or running a Shapiro-Wilk test). I’ll talk about this "
"more in an ANOVA context in subsection :ref:`Checking the normality "
"assumption <normality_anova>`."
msgstr ""
"**Нормальність**. Припускається, що залишки мають нормальний розподіл. Як ми "
"бачили в підрозділі :doc:`../Ch11/Ch11_tTest_08`, ми можемо оцінити це, "
"розглянувши QQ-графіки (або виконавши тест Шапіро-Уілка). Я розповім про це "
"докладніше в контексті ANOVA в підрозділі :ref:`Checking the normality "
"assumption <normality_anova>`."

#: ../../Ch13/Ch13_ANOVA_06.rst:56
msgid ""
"**Independence**. The independence assumption is a little trickier. What it "
"basically means is that, knowing one residual tells you nothing about any "
"other residual. All of the ϵ\\ :sub:`ik` values are assumed to have been "
"generated without any “regard for” or “relationship to” any of the other "
"ones. There’s not an obvious or simple way to test for this, but there are "
"some situations that are clear violations of this. For instance, if you have "
"a repeated-measures design, where each participant in your study appears in "
"more than one condition, then independence doesn’t hold. There’s a special "
"relationship between some observations, namely those that correspond to the "
"same person! When that happens, you need to use something like repeated "
"measures ANOVA (see section :doc:`Ch13_ANOVA_07`)."
msgstr ""
"**Незалежність**. Припущення про незалежність є дещо складнішим. По суті, "
"воно означає, що знання одного залишку не дає жодної інформації про інші "
"залишки. Вважається, що всі значення ϵ\\ :sub:`ik` були згенеровані без "
"«врахування» або «зв'язку» з будь-якими іншими значеннями. Немає очевидного "
"або простого способу перевірити це, але є деякі ситуації, які є явними "
"порушеннями цього припущення. Наприклад, якщо ви маєте дизайн з "
"повторюваними вимірами, де кожен учасник вашого дослідження з'являється в "
"більш ніж одній умові, то незалежність не зберігається. Між деякими "
"спостереженнями, а саме тими, що відповідають одній і тій самій особі, існує "
"особливий зв'язок! У такому випадку вам потрібно використовувати щось на "
"зразок ANOVA з повторюваними вимірами (див. розділ :doc:`Ch13_ANOVA_07`)."

#: ../../Ch13/Ch13_ANOVA_06.rst:72
msgid "Checking the homogeneity of variance assumption"
msgstr "Перевірка припущення про однорідність дисперсії"

#: ../../Ch13/Ch13_ANOVA_06.rst:82
msgid ""
"There’s more than one way to skin a cat, as the saying goes, and more than "
"one way to test the homogeneity of variance assumption, too (though for some "
"reason no-one made a saying out of that). The most commonly used test for "
"this that I’ve seen in the literature is the **Levene test** (:ref:`Levene, "
"1960 <Levene_1960>`), and the closely related **Brown-Forsythe test** (:ref:"
"`Brown & Forsythe, 1974 <Brown_1974>`)."
msgstr ""
"Як кажуть, є більше ніж один спосіб зняти шкіру з кота, і є більше ніж один "
"спосіб перевірити припущення про однорідність дисперсії (хоча з якоїсь "
"причини ніхто не склав про це приказку). Найпоширенішим тестом для цього, "
"який я бачив у літературі, є **тест Левена** (:ref:`Levene, 1960 "
"<Levene_1960>`) та тісно пов'язаний з ним **тест Брауна-Форсайта** (:ref:`"
"Brown & Forsythe, 1974 <Brown_1974>`)."

#: ../../Ch13/Ch13_ANOVA_06.rst:89
msgid ""
"Regardless of whether you’re doing the standard Levene test or the Brown-"
"Forsythe test, the test statistic, which is sometimes denoted *F* but also "
"sometimes written as *W*, is calculated in exactly the same way that the *F*-"
"statistic for the regular ANOVA is calculated, just using a Z\\ :sub:`ik` "
"rather than Y\\ :sub:`ik`. With that in mind, we can go on to look at how to "
"run the test in jamovi."
msgstr ""
"Незалежно від того, чи ви виконуєте стандартний тест Левена, чи тест Брауна-"
"Форсайта, тестова статистика, яка іноді позначається *F*, а іноді "
"записується як *W*, обчислюється точно так само, як і *F*-статистика для "
"звичайного ANOVA, тільки замість Y\\ :sub:`ik` використовується Z\\ :sub:`ik`"
". Маючи це на увазі, ми можемо перейти до розгляду того, як виконати тест в "
"jamovi."

#: ../../Ch13/Ch13_ANOVA_06.rst:97
msgid ""
"The Levene test is shockingly simple. Suppose we have our outcome variable "
"Y\\ :sub:`ik`. All we do is define a new variable, which I’ll call Z\\ :sub:"
"`ik`, corresponding to the absolute deviation from the group mean"
msgstr ""
"Тест Левена надзвичайно простий. Припустимо, що ми маємо нашу змінну "
"результату Y\\ :sub:`ik`. Все, що ми робимо, це визначаємо нову змінну, яку "
"я назву Z\\ :sub:`ik`, що відповідає абсолютному відхиленню від середнього "
"значення групи"

#: ../../Ch13/Ch13_ANOVA_06.rst:102
msgid "Z\\ :sub:`ik` = Y\\ :sub:`ik` - Ȳ\\ :sub:`k`"
msgstr "Z\\ :sub:`ik` = Y\\ :sub:`ik` - Ȳ\\ :sub:`k`"

#: ../../Ch13/Ch13_ANOVA_06.rst:104
msgid ""
"Okay, what good does this do us? Well, let’s take a moment to think about "
"what Z\\ :sub:`ik` actually is and what we’re trying to test. The value of "
"Z\\ :sub:`ik` is a measure of how the *i*-th observation in the *k*-th group "
"deviates from its group mean. And our null hypothesis is that all groups "
"have the same variance, i.e., the same overall deviations from the group "
"means! So the null hypothesis in a Levene test is that the population means "
"of Z are identical for all groups. Hmm. So what we need now is a statistical "
"test of the null hypothesis that all group means are identical. Where have "
"we seen that before? Oh right, that’s what ANOVA is, and so all that the "
"Levene test does is run an ANOVA on the new variable Z\\ :sub:`ik`."
msgstr ""
"Гаразд, а що це нам дає? Давайте замислимося над тим, що таке Z\\ :sub:`ik` "
"і що ми намагаємося перевірити. Значення Z\\ :sub:`ik` є мірою відхилення "
"*i*-го спостереження в *k*-й групі від середнього значення групи. А наша "
"нульова гіпотеза полягає в тому, що всі групи мають однакову дисперсію, "
"тобто однакові загальні відхилення від середніх значень групи! Отже, нульова "
"гіпотеза в тесті Левена полягає в тому, що середні значення Z для всіх груп "
"є однаковими. Хм. Отже, зараз нам потрібен статистичний тест нульової "
"гіпотези, що всі середні значення груп є однаковими. Де ми це вже бачили? "
"Ага, це ж ANOVA, і тому все, що робить тест Левена, — це виконує ANOVA на "
"новій змінній Z\\ :sub:`ik`."

#: ../../Ch13/Ch13_ANOVA_06.rst:116
msgid ""
"What about the Brown-Forsythe test? Does that do anything particularly "
"different? Nope. The only change from the Levene test is that it constructs "
"the transformed variable *Z* in a slightly different way, using deviations "
"from the group *medians* rather than deviations from the group *means*. That "
"is, for the Brown-Forsythe test"
msgstr ""
"А що щодо тесту Брауна-Форсайта? Чи є в ньому якісь особливі відмінності? "
"Ні. Єдина відмінність від тесту Левена полягає в тому, що він будує "
"трансформовану змінну *Z* дещо іншим чином, використовуючи відхилення від "
"*медіани* групи, а не відхилення від *середнього значення* групи. Тобто для "
"тесту Брауна-Форсайта"

#: ../../Ch13/Ch13_ANOVA_06.rst:122
msgid "Z\\ :sub:`ik` = Y\\ :sub:`ik` - median\\ :sub:`k(Y)`"
msgstr "Z\\ :sub:`ik` = Y\\ :sub:`ik` - median\\ :sub:`k(Y)`"

#: ../../Ch13/Ch13_ANOVA_06.rst:124
msgid "where median\\ :sub:`k(Y)` is the median for group *k*."
msgstr "де median\\ :sub:`k(Y)` — це медіана для групи *k*."

#: ../../Ch13/Ch13_ANOVA_06.rst:127
msgid "Running the Levene-test in jamovi"
msgstr "Виконання тесту Левена в jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:129
msgid ""
"Okay, so how do we run the Levene test? Simple really - under the ``ANOVA`` "
"→ ``Assumption Checks`` option, just click on the ``Homogeneity tests`` "
"checkbox. If we look at the output, shown in :numref:`fig-anova4`, we see "
"that the test is non-significant (*F*\\{2,15} = 1.45, *p* = 0.266), so it "
"looks like the homogeneity of variance assumption is fine. However, looks "
"can be deceptive! If your sample size is pretty big, then the Levene test "
"could show up a significant effect (i.e., *p* < 0.05) even when the "
"homogeneity of variance assumption is not violated to an extent which "
"troubles the robustness of ANOVA. This was the point George Box was making "
"in the quote above. Similarly, if your sample size is quite small, then the "
"homogeneity of variance assumption might not be satisfied and yet a Levene "
"test could be non-significant (i.e. *p* > 0.05). What this means is that, "
"alongside any statistical test of the assumption being met, you should "
"always plot the standard deviation around the means for each group / "
"category in the analysis… just to see if they look fairly similar (i.e. "
"homogeneity of variance) or not."
msgstr ""
"Гаразд, то як же ми проводимо тест Левена? Все дуже просто — в опції "
"``ANOVA`` → ``Assumption Checks`` (Аналіз дисперсії → Перевірка припущень) "
"просто натисніть на прапорець ``Homogeneity tests`` (Тести однорідності). "
"Якщо подивитися на результат, показаний у :numref:`fig-anova4`, то бачимо, "
"що тест є неістотним (*F*\\{2,15} = 1,45, *p* = 0,266), тож, здається, "
"припущення про однорідність дисперсії є правильним. Однак зовнішній вигляд "
"може бути оманливим! Якщо розмір вибірки досить великий, тест Левена може "
"показати значущий ефект (тобто *p* < 0,05) навіть тоді, коли припущення про "
"однорідність дисперсії не порушується в мірі, яка ставить під сумнів "
"надійність ANOVA. Саме це мав на увазі Джордж Бокс у наведеному вище цитаті. "
"Аналогічно, якщо розмір вибірки досить малий, припущення про однорідність "
"дисперсії може не виконуватися, але тест Левена може бути неістотним (тобто "
"*p* > 0,05). Це означає, що, крім будь-якого статистичного тесту на "
"відповідність припущенню, ви завжди повинні побудувати графік стандартного "
"відхилення навколо середніх значень для кожної групи/категорії в аналізі... "
"просто щоб побачити, чи вони виглядають досить схожими (тобто однорідність "
"дисперсії), чи ні."

#: ../../Ch13/Ch13_ANOVA_06.rst:148 ../../Ch13/Ch13_ANOVA_06.rst:152
msgid "``Levene test`` output for ``One-Way ANOVA`` in jamovi"
msgstr "``Levene test`` вихід для ``One-Way ANOVA`` в jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:157
msgid "Removing the homogeneity of variance assumption"
msgstr "Вилучення припущення про однорідність дисперсії"

#: ../../Ch13/Ch13_ANOVA_06.rst:159
msgid ""
"In our example, the homogeneity of variance assumption turned out to be a "
"pretty safe one: the Levene test came back non-significant (notwithstanding "
"that we should also look at the plot of standard deviations), so we probably "
"don’t need to worry. However, in real life we aren’t always that lucky. How "
"do we save our ANOVA when the homogeneity of variance assumption is "
"violated? If you recall from our discussion of *t*-tests, we’ve seen this "
"problem before. The Student *t*-test assumes equal variances, so the "
"solution was to use the Welch *t*-test, which does not. In fact, :ref:`Welch "
"(1951) <Welch_1951>` also showed how we can solve this problem for ANOVA too "
"(the **Welch One-way test**). It’s implemented in jamovi using the ``One-Way "
"ANOVA`` analysis. This is a specific analysis approach just for one-way "
"ANOVA, and to run the Welch one-way ANOVA for our example, we would re-run "
"the analysis as previously, but this time use the jamovi ``ANOVA`` → ``One "
"Way ANOVA`` analysis command, and check the option ``Don't assume equal "
"(Welch’s)`` (see :numref:`fig-anova4a`)."
msgstr ""
"У нашому прикладі припущення про однорідність дисперсії виявилося досить "
"надійним: тест Левена дав неістотний результат (незважаючи на те, що нам "
"також слід розглянути графік стандартних відхилень), тому, ймовірно, нам не "
"варто турбуватися. Однак у реальному житті нам не завжди так щастить. Як "
"врятувати ANOVA, коли припущення про однорідність дисперсії порушується? "
"Якщо ви пам'ятаєте з нашого обговорення *t*-тестів, ми вже стикалися з цією "
"проблемою. *t*-тест Стьюдента припускає рівність дисперсій, тому рішенням "
"було використання *t*-тесту Велча, який цього не припускає. Насправді, :ref:`"
"Welch (1951) <Welch_1951>` також показав, як ми можемо вирішити цю проблему "
"для ANOVA (**односторонній тест Велча**). Він реалізований в jamovi за "
"допомогою аналізу ``One-Way ANOVA``. Це специфічний підхід до аналізу, "
"призначений тільки для одностороннього ANOVA, і щоб запустити односторонній "
"ANOVA Велча для нашого прикладу, ми б повторно запустили аналіз, як і "
"раніше, але цього разу використовували б команду аналізу jamovi ``ANOVA`` → "
"``One Way ANOVA`` і встановили б опцію ``Don't assume equal (Welch’s)`` ("
"див. :numref:`fig-anova4a`)."

#: ../../Ch13/Ch13_ANOVA_06.rst:176 ../../Ch13/Ch13_ANOVA_06.rst:180
msgid "Welch’s test as part of the One-Way ANOVA analysis in jamovi"
msgstr "Критерій Велча як частина однофакторного дисперсійного аналізу в jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:184
msgid ""
"To understand what’s happening here, let’s compare these numbers with those "
"obtained earlier in section :doc:`Ch13_ANOVA_03`, namely: *F*\\(2,15) = "
"18.611, *p* = 0.00009. As shown in :numref:`fig-anova4a`, these values are "
"also displayed in the ``One-Way ANOVA`` table (in the row starting with "
"``Fisher's``) if the option ``Assume equal (Fisher's)`` was chosen."
msgstr ""
"Щоб зрозуміти, що тут відбувається, порівняємо ці цифри з тими, що були "
"отримані раніше в розділі :doc:`Ch13_ANOVA_03`, а саме: *F*\\(2,15) = "
"18,611, *p* = 0,00009. Як показано в :numref:`fig-anova4a`, ці значення "
"також відображаються в таблиці ``One-Way ANOVA`` (у рядку, що починається з "
"``Fisher's``), якщо було обрано опцію ``Assume equal (Fisher's)``."

#: ../../Ch13/Ch13_ANOVA_06.rst:190
msgid ""
"Okay, so originally our ANOVA gave us the result *F*\\(2,15) = 18.6, whereas "
"the Welch one-way test gave us *F*\\(2,9.49) = 26.32. In other words, the "
"Welch test has reduced the within-groups degrees of freedom from 15 to 9.49, "
"and the *F*-value has increased from 18.6 to 26.32."
msgstr ""
"Отже, спочатку наш ANOVA дав нам результат *F*\\(2,15) = 18,6, тоді як "
"односторонній тест Велча дав нам *F*\\(2,9,49) = 26,32. Іншими словами, тест "
"Велча зменшив ступінь свободи всередині груп з 15 до 9,49, а значення *F* "
"збільшилося з 18,6 до 26,32."

#: ../../Ch13/Ch13_ANOVA_06.rst:199
msgid "Checking the normality assumption"
msgstr "Перевірка припущення про нормальність"

#: ../../Ch13/Ch13_ANOVA_06.rst:201
msgid ""
"Testing the normality assumption is relatively straightforward. We covered "
"most of what you need to know in section :doc:`../Ch11/Ch11_tTest_08`. The "
"only thing we really need to do is draw a QQ plot and, in addition if it is "
"available, run the Shapiro-Wilk test. The QQ plot is shown in :numref:`fig-"
"anova5` and it looks pretty normal to me. If the Shapiro-Wilk test is not "
"significant (i.e. *p* > 0.05) then this indicates that the assumption of "
"normality is not violated. However, as with Levene’s test, if the sample "
"size is large then a significant Shapiro-Wilk test may in fact be a false "
"positive, where the assumption of normality is not violated in any "
"substantive problematic sense for the analysis. And, similarly, a very small "
"sample can produce false negatives. That’s why a visual inspection of the QQ "
"plot is important."
msgstr ""
"Перевірка припущення про нормальність є відносно простою. Ми розглянули "
"більшість необхідних відомостей у розділі :doc:`../Ch11/Ch11_tTest_08`. "
"Єдине, що нам дійсно потрібно зробити, це побудувати QQ-графік і, якщо це "
"можливо, виконати тест Шапіро-Вілка. QQ-графік показано на :numref:`fig-"
"anova5`, і він виглядає цілком нормальним. Якщо тест Шапіро-Уілка не є "
"значущим (тобто *p* > 0,05), це означає, що припущення про нормальність не "
"порушено. Однак, як і в тесті Левена, якщо розмір вибірки великий, значущий "
"тест Шапіро-Уілка може насправді бути хибнопозитивним, коли припущення про "
"нормальність не порушується в жодному істотному проблемному сенсі для "
"аналізу. І, аналогічно, дуже мала вибірка може давати хибно негативні "
"результати. Ось чому візуальний огляд QQ-графіку є важливим."

#: ../../Ch13/Ch13_ANOVA_06.rst:214
msgid ""
"Alongside inspecting the QQ plot for any deviations from normality, the "
"Shapiro-Wilk test for our data does show a non-significant effect, with *p* "
"= 0.6053 (see :numref:`fig-anova4a`). This therefore supports the QQ plot "
"assessment; both checks find no indication that normality is violated."
msgstr ""
"Поряд з перевіркою QQ-графіку на наявність відхилень від нормальності, тест "
"Шапіро-Уілка для наших даних показує незначний ефект, з *p* = 0,6053 (див. "
":numref:`fig-anova4a`). Це підтверджує оцінку QQ-графіку; обидві перевірки "
"не виявляють ознак порушення нормальності."

#: ../../Ch13/Ch13_ANOVA_06.rst:222 ../../Ch13/Ch13_ANOVA_06.rst:226
msgid "QQ-plot produced from jamovi One-Way ANOVA options"
msgstr "QQ-діаграма, отримана з варіантів однофакторного ANOVA аналізу jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:231
msgid "Removing the normality assumption"
msgstr "Вилучення припущення про нормальність"

#: ../../Ch13/Ch13_ANOVA_06.rst:233
msgid ""
"Now that we’ve seen how to check for normality, we are led naturally to ask "
"what we can do to address violations of normality. In the context of a One-"
"way ANOVA, the easiest solution is probably to switch to a non-parametric "
"test (i.e., one that doesn’t rely on any particular assumption about the "
"kind of distribution involved). We’ve seen non-parametric tests before, in "
"section :doc:`../Ch11/Ch11_tTest_09`. When you only have two groups, the "
"Mann-Whitney or the Wilcoxon test provides the non-parametric alternative "
"that you need. When you’ve got three or more groups, you can use the "
"**Kruskal-Wallis rank sum test** (:ref:`Kruskal & Wallis, 1952 "
"<Kruskal_1952>`). So that’s the test we’ll talk about next."
msgstr ""
"Тепер, коли ми побачили, як перевіряти нормальність, ми природно задаємося "
"питанням, що можна зробити, щоб вирішити проблему порушення нормальності. У "
"контексті однофакторного дисперсійного аналізу найпростішим рішенням, "
"ймовірно, буде перехід до непараметричного тесту (тобто такого, що не "
"базується на жодних конкретних припущеннях щодо типу розподілу). Ми вже "
"розглядали непараметричні тести в розділі :doc:`../Ch11/Ch11_tTest_09`. Якщо "
"у вас є тільки дві групи, тест Манна-Уїтні або Вілкоксона надає необхідну "
"непараметричну альтернативу. Якщо у вас є три або більше груп, ви можете "
"використовувати **тест суми рангів Крускала-Уолліса** (:ref:`Kruskal & "
"Wallis, 1952 <Kruskal_1952>`). Отже, саме про цей тест ми поговоримо далі."

#: ../../Ch13/Ch13_ANOVA_06.rst:244
msgid ""
"The Kruskal-Wallis test is surprisingly similar to ANOVA, in some ways. In "
"ANOVA we started with Y\\ :sub:`ik`, the value of the outcome variable for "
"the *i*-th person in the *k*-th group. For the Kruskal-Wallis test what "
"we’ll do is rank order all of these Y\\ :sub:`ik` values and conduct our "
"analysis on the ranked data."
msgstr ""
"Тест Крускала-Уолліса в деяких аспектах напрочуд схожий на ANOVA. В ANOVA ми "
"почали з Y\\ :sub:`ik`, значенням результативної змінної для *i*-ї особи в "
"*k*-й групі. Для тесту Крускала-Уолліса ми зробимо ранжування всіх цих "
"значень Y\\ :sub:`ik` і проведемо аналіз за ранжованими даними."

#: ../../Ch13/Ch13_ANOVA_06.rst:250
msgid ""
"So let’s let R\\ :sub:`ik` refer to the ranking given to the *i*-th member "
"of the *k*-th group. Now, let’s calculate R̄\\ :sub:`k`, the average rank "
"given to observations in the *k*-th group:"
msgstr ""
"Отже, нехай R\\ :sub:`ik` буде рейтингом, наданим *i*-му члену *k*-ї групи. "
"Тепер обчислимо R̄\\ :sub:`k`, середній рейтинг, наданий спостереженням у *k*-"
"й групі:"

#: ../../Ch13/Ch13_ANOVA_06.rst:254
msgid ""
"\\bar{R}_k = \\frac{1}{N_K} \\sum_{i} R_{ik}\n"
"\n"
msgstr ""
"\\bar{R}_k = \\frac{1}{N_K} \\sum_{i} R_{ik}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:256
msgid "and let’s also calculate R̄, the grand mean rank"
msgstr "а також обчислимо R̄, загальний середній ранг"

#: ../../Ch13/Ch13_ANOVA_06.rst:258
msgid ""
"\\bar{R} = \\frac{1}{N} \\sum_{i} \\sum_{k} R_{ik}\n"
"\n"
msgstr ""
"\\bar{R} = \\frac{1}{N} \\sum_{i} \\sum_{k} R_{ik}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:260
msgid ""
"Now that we’ve done this, we can calculate the squared deviations from the "
"grand mean rank R̄. When we do this for the individual scores, i.e., if we "
"calculate (R\\ :sub:`ik` – R̄)², what we have is a “nonparametric” measure of "
"how far the *ik*-th observation deviates from the grand mean rank. When we "
"calculate the squared deviation of the group means from the grand means, i."
"e., if we calculate (R̄\\ :sub:`k` – R̄)², then what we have is a "
"nonparametric measure of how much the *group* deviates from the grand mean "
"rank. With this in mind, we’ll follow the same logic that we did with ANOVA "
"and define our *ranked* sums of squares measures, much like we did earlier. "
"First, we have our “total ranked sums of squares”"
msgstr ""
"Тепер, коли ми це зробили, ми можемо обчислити квадратичні відхилення від "
"загального середнього рангу R̄. Коли ми робимо це для окремих балів, тобто "
"якщо ми обчислюємо (R\\ :sub:`ik` – R̄)², ми отримуємо «непараметричну» міру "
"того, наскільки *ik*-те спостереження відхиляється від загального середнього "
"рангу. Коли ми обчислюємо квадратичне відхилення групових середніх значень "
"від загальних середніх значень, тобто якщо ми обчислюємо (R̄\\ :sub:`k` – R̄)"
"², то отримуємо непараметричну міру того, наскільки *група* відхиляється від "
"загального середнього рангу. Маючи це на увазі, ми будемо дотримуватися тієї "
"ж логіки, що і в ANOVA, і визначимо наші *ранжовані* суми квадратів мір, як "
"ми це робили раніше. По-перше, ми маємо наші «загальні ранжовані суми "
"квадратів»"

#: ../../Ch13/Ch13_ANOVA_06.rst:271
msgid ""
"\\mbox{RSS}_{tot} = \\sum_k \\sum_i ( R_{ik} - \\bar{R} )^2\n"
"\n"
msgstr ""
"\\mbox{RSS}_{tot} = \\sum_k \\sum_i ( R_{ik} - \\bar{R} )^2\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:273
msgid ""
"and we can define the “between groups ranked sums of squares” like this:"
msgstr "і ми можемо визначити «міжгрупові ранжовані суми квадратів» так:"

#: ../../Ch13/Ch13_ANOVA_06.rst:275
msgid ""
"\\begin{array}{rcl}\n"
"\\mbox{RSS}_{b} &=& \\sum_k \\sum_i ( \\bar{R}_k  - \\bar{R} )^2 \\\\\n"
"               &=& \\sum_k N_k ( \\bar{R}_k  - \\bar{R} )^2\n"
"\\end{array}"
msgstr ""
"\\begin{array}{rcl}\n"
"\\mbox{RSS}_{b} &=& \\sum_k \\sum_i ( \\bar{R}_k  - \\bar{R} )^2 \\\\\n"
"               &=& \\sum_k N_k ( \\bar{R}_k  - \\bar{R} )^2\n"
"\\end{array}"

#: ../../Ch13/Ch13_ANOVA_06.rst:282
msgid ""
"So, if the null hypothesis is true and there are no true group differences "
"at all, you’d expect the between group rank sums RSS\\ :sub:`b` to be very "
"small, much smaller than the total rank sums RSS\\ :sub:`tot`. Qualitatively "
"this is very much the same as what we found when we went about constructing "
"the ANOVA *F*-statistic, but for technical reasons the Kruskal-Wallis test "
"statistic, usually denoted *K*, is constructed in a slightly different way,"
msgstr ""
"Отже, якщо нульова гіпотеза є правдивою і між групами немає жодних реальних "
"відмінностей, можна очікувати, що сума рангів між групами RSS\\ :sub:`b` "
"буде дуже малою, набагато меншою за загальну суму рангів RSS\\ :sub:`tot`. "
"Якісно це дуже схоже на те, що ми виявили, коли будували ANOVA *F*-"
"статистику, але з технічних причин статистика тесту Крускала-Уолліса, яка "
"зазвичай позначається *K*, будується дещо інакше,"

#: ../../Ch13/Ch13_ANOVA_06.rst:291
msgid ""
"K = (N - 1) \\times \\frac{\\mbox{RSS}_b}{\\mbox{RSS}_{tot}}\n"
"\n"
msgstr ""
"K = (N - 1) \\times \\frac{\\mbox{RSS}_b}{\\mbox{RSS}_{tot}}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:293
msgid ""
"and if the null hypothesis is true, then the sampling distribution of *K* is "
"*approximately* χ² with *G* - 1 degrees of freedom (where *G* is the number "
"of groups). The larger the value of *K*, the less consistent the data are "
"with the null hypothesis, so this is a one-sided test. We reject H\\ :sub:"
"`0` when *K* is sufficiently large."
msgstr ""
"і якщо нульова гіпотеза є правдивою, то вибірковий розподіл *K* є *приблизно*"
" χ² зі ступенем свободи *G* - 1 (де *G* є кількістю груп). Чим більшим є "
"значення *K*, тим меншою є відповідність даних нульовій гіпотезі, тому це є "
"одностороннім тестом. Ми відкидаємо H\\ :sub:`0`, коли *K* є достатньо "
"великим."

#: ../../Ch13/Ch13_ANOVA_06.rst:299
msgid ""
"The description in the previous section illustrates the logic behind the "
"Kruskal-Wallis test. At a conceptual level, this is the right way to think "
"about how the test works. However, from a purely mathematical perspective "
"it’s needlessly complicated. I won’t show you the derivation, but you can "
"use a bit of algebraic jiggery-pokery [#]_ to show that the equation for *K* "
"can be rewritten as"
msgstr ""
"Опис у попередньому розділі ілюструє логіку, що лежить в основі тесту "
"Крускала-Уолліса. На концептуальному рівні це правильний спосіб розуміння "
"того, як працює тест. Однак з чисто математичної точки зору він є надмірно "
"складним. Я не буду показувати вам виведення, але ви можете використати "
"трохи алгебраїчних хитрощів [#]_, щоб показати, що рівняння для *K* можна "
"переписати як"

#: ../../Ch13/Ch13_ANOVA_06.rst:306
msgid ""
"K = \\frac{12}{N(N-1)} \\sum_k N_k {\\bar{R}_k}^2 - 3(N+1)\n"
"\n"
msgstr ""
"K = \\frac{12}{N(N-1)} \\sum_k N_k {\\bar{R}_k}^2 - 3(N+1)\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:308
msgid ""
"It’s this last equation that you sometimes see given for *K*. This is way "
"easier to calculate than the version I described in the previous section, "
"but it’s just that it’s totally meaningless to actual humans. It’s probably "
"best to think of *K* the way I described it earlier, as an analogue of ANOVA "
"based on ranks. But keep in mind that the test statistic that gets "
"calculated ends up with a rather different look to it than the one we used "
"for our original ANOVA."
msgstr ""
"Саме це останнє рівняння іноді використовується для *K*. Воно набагато "
"простіше для обчислення, ніж версія, яку я описав у попередньому розділі, "
"але воно абсолютно не має сенсу для реальних людей. Найкраще, мабуть, "
"розглядати *K* так, як я описав раніше, як аналог ANOVA на основі рангів. "
"Але майте на увазі, що обчислена тестова статистика має дещо інший вигляд, "
"ніж та, яку ми використовували для нашого оригінального ANOVA."

#: ../../Ch13/Ch13_ANOVA_06.rst:316
msgid ""
"But wait, there’s more! Dear lord, why is there always *more*? The story "
"I’ve told so far is only actually true when there are no ties in the raw "
"data. That is, if there are no two observations that have exactly the same "
"value. If there *are* ties, then we have to introduce a correction factor to "
"these calculations. At this point I’m assuming that even the most diligent "
"reader has stopped caring (or at least formed the opinion that the tie-"
"correction factor is something that doesn’t require their immediate "
"attention). So I’ll very quickly tell you how it’s calculated, and omit the "
"tedious details about *why* it’s done this way. Suppose we construct a "
"frequency table for the raw data, and let f\\ :sub:`j` be the number of "
"observations that have the *j*-th unique value. This might sound a bit "
"abstract, so here’s a concrete example from the frequency table of ``mood."
"gain`` from the |clinicaltrial|_ data set:"
msgstr ""
"Але зачекайте, це ще не все! Боже мій, чому завжди є *ще щось*? Історія, яку "
"я розповів до цього моменту, є правдивою лише в тому випадку, якщо в "
"вихідних даних немає рівних значень. Тобто, якщо немає двох спостережень, "
"які мають абсолютно однакове значення. Якщо рівних значень *є*, то ми маємо "
"ввести до цих розрахунків коригувальний коефіцієнт. На цьому етапі я "
"припускаю, що навіть найпильніший читач перестав цікавитися (або принаймні "
"сформував думку, що коефіцієнт корекції зв'язків — це щось, що не вимагає "
"його негайної уваги). Тому я дуже швидко розповім, як його обчислюють, і "
"опущу нудні подробиці про те, *чому* це робиться саме так. Припустимо, ми "
"будуємо таблицю частот для необроблених даних, і нехай f\\ :sub:`j` буде "
"кількістю спостережень, які мають *j*-те унікальне значення. Це може звучати "
"дещо абстрактно, тому ось конкретний приклад із таблиці частот ``mood.gain`` "
"із набору даних |clinicaltrial|_:"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.2"
msgstr "0.2"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.8"
msgstr "0.8"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "0.9"
msgstr "0.9"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.1"
msgstr "1.1"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.2"
msgstr "1.2"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.3"
msgstr "1.3"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.4"
msgstr "1.4"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.7"
msgstr "1.7"

#: ../../Ch13/Ch13_ANOVA_06.rst:331
msgid "1.8"
msgstr "1.8"

#: ../../Ch13/Ch13_ANOVA_06.rst:336
msgid ""
"Looking at this table, notice that the third entry in the frequency table "
"has a value of 2. Since this corresponds to a ``mood.gain`` of 0.3, this "
"table is telling us that two people’s mood increased by 0.3. More to the "
"point, in the mathematical notation I introduced above, this is telling us "
"that f\\ :sub:`3` = 2. Yay. So, now that we know this, the tie correction "
"factor (TCF) is:"
msgstr ""
"Дивлячись на цю таблицю, зверніть увагу, що третій запис у таблиці частот "
"має значення 2. Оскільки це відповідає ``mood.gain`` 0,3, ця таблиця показує "
"нам, що настрій двох людей підвищився на 0,3. Більш точно, у математичній "
"нотації, яку я представив вище, це означає, що f\\ :sub:`3` = 2. Ура. Отже, "
"тепер, коли ми це знаємо, коефіцієнт корекції зв'язки (TCF) дорівнює:"

#: ../../Ch13/Ch13_ANOVA_06.rst:343
msgid ""
"\\mbox{TCF} = 1 - \\frac{\\sum_j {f_j}^3 - f_j}{N^3 - N}\n"
"\n"
msgstr ""
"\\mbox{TCF} = 1 - \\frac{\\sum_j {f_j}^3 - f_j}{N^3 - N}\n"
"\n"

#: ../../Ch13/Ch13_ANOVA_06.rst:345
msgid ""
"The tie-corrected value of the Kruskal-Wallis statistic is obtained by "
"dividing the value of *K* by this quantity. It is this tie-corrected version "
"that jamovi calculates. And at long last, we’re actually finished with the "
"theory of the Kruskal-Wallis test. I’m sure you’re all terribly relieved "
"that I’ve cured you of the existential anxiety that naturally arises when "
"you realise that you *don’t* know how to calculate the tie-correction factor "
"for the Kruskal-Wallis test. Right?"
msgstr ""
"Значення статистики Крускала-Уолліса з поправкою на рівність отримується "
"шляхом ділення значення *K* на цю величину. Саме цю версію з поправкою на "
"рівність обчислює jamovi. І нарешті ми закінчили з теорією тесту Крускала-"
"Уолліса. Я впевнений, що ви всі відчуваєте величезне полегшення, оскільки я "
"позбавив вас екзистенційної тривоги, яка природно виникає, коли ви "
"усвідомлюєте, що *не* знаєте, як обчислити коефіцієнт корекції зв'язку для "
"тесту Крускала-Уолліса. Правда ж?"

#: ../../Ch13/Ch13_ANOVA_06.rst:355
msgid "How to run the Kruskal-Wallis test in jamovi"
msgstr "Як виконати тест Краскела-Уолліса в jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:357
msgid ""
"Despite the horror that we’ve gone through in trying to understand what the "
"Kruskal-Wallis test actually does, it turns out that running the test is "
"pretty painless, since jamovi has an analysis as part of the ``ANOVA`` "
"analysis set called ``Non-Parametric`` - ``One-Way ANOVA (Kruskall-"
"Wallis)``. Most of the time you’ll have data like the |clinicaltrial|_ data "
"set, in which you have your outcome variable ``mood.gain`` and a grouping "
"variable ``drug``. If so, you can just go ahead and run the analysis in "
"jamovi. What this gives us is a Kruskal-Wallis χ² = 12.076, *df* = 2, *p*-"
"value = 0.00239, as in :numref:`fig-anova6`."
msgstr ""
"Незважаючи на жах, який ми пережили, намагаючись зрозуміти, що насправді "
"робить тест Крускала-Уолліса, виявляється, що виконання тесту є досить "
"простим, оскільки jamovi має аналіз як частину набору аналізів ``ANOVA`` під "
"назвою ``Non-Parametric`` - ``One-Way ANOVA (Kruskall-Wallis)``. У більшості "
"випадків ви матимете дані, подібні до набору даних |clinicaltrial|_, в якому "
"є ваша змінна результату ``mood.gain`` і змінна групування ``drug``. Якщо "
"так, ви можете просто виконати аналіз в jamovi. В результаті ми отримаємо "
"Kruskal-Wallis χ² = 12,076, *df* = 2, *p*-значення = 0,00239, як у :numref"
":`fig-anova6`."

#: ../../Ch13/Ch13_ANOVA_06.rst:369
msgid "non-parametric ``One-Way ANOVA (Kruskal-Wallis)`` in jamovi"
msgstr "непараметричний ``One-Way ANOVA (Kruskal-Wallis)`` в jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:373
msgid "Non-parametric ``One-Way ANOVA (Kruskal-Wallis)`` in jamovi"
msgstr "Непараметричний ``One-Way ANOVA (Kruskal-Wallis)`` в jamovi"

#: ../../Ch13/Ch13_ANOVA_06.rst:380
msgid "A technical term."
msgstr "Технічний термін."

#: ../../Ch13/Ch13_ANOVA_07.rst:4
msgid "Repeated measures one-way ANOVA"
msgstr "Повторні вимірювання в одному напрямку ANOVA"

#: ../../Ch13/Ch13_ANOVA_07.rst:6
msgid ""
"The one-way repeated measures ANOVA test is a statistical method of testing "
"for significant differences between three or more groups where the same "
"participants are used in each group (or each participant is closely matched "
"with participants in other experimental groups). For this reason, there "
"should always be an equal number of scores (data points) in each "
"experimental group. This type of design and analysis can also be called a "
"“related ANOVA” or a “within-subjects ANOVA”."
msgstr ""
"Односторонній тест ANOVA з повторними вимірами — це статистичний метод "
"перевірки значущих відмінностей між трьома або більше групами, в яких "
"використовуються однакові учасники в кожній групі (або кожен учасник тісно "
"пов'язаний з учасниками в інших експериментальних групах). З цієї причини в "
"кожній експериментальній групі завжди має бути однакова кількість балів ("
"точок даних). Цей тип дизайну та аналізу також можна назвати «пов'язаним "
"ANOVA» або «ANOVA в межах суб'єктів»."

#: ../../Ch13/Ch13_ANOVA_07.rst:14
msgid ""
"The logic behind a repeated measures ANOVA is very similar to that of an "
"independent ANOVA (sometimes called a “between-subjects” ANOVA). You’ll "
"remember that earlier we showed that in a between-subjects ANOVA total "
"variability is partitioned into between-groups variability (SS\\ :sub:`b`) "
"and within-groups variability (SS\\ :sub:`w`), and after each is divided by "
"the respective degrees of freedom to give MS\\ :sub:`b` and MS\\ :sub:`w` "
"(see :numref:`tab-anovatable`) the *F*-ratio is calculated as:"
msgstr ""
"Логіка, що лежить в основі ANOVA з повторними вимірами, дуже схожа на логіку "
"незалежної ANOVA (іноді її називають ANOVA «між суб'єктами»). Ви пам'ятаєте, "
"що раніше ми показали, що в ANOVA між суб'єктами загальна мінливість "
"поділяється на мінливість між групами (SS\\ :sub:`b`) і мінливість всередині "
"груп (SS\\ :sub:`w`), і після того, як кожна з них ділиться на відповідні "
"ступені свободи, отримуємо MS\\ :sub:`b` і MS\\ :sub:`w` (див. :numref:`tab-"
"anovatable`), *F*-коефіцієнт обчислюється як:"

#: ../../Ch13/Ch13_ANOVA_07.rst:23
msgid "*F* = MS\\ :sub:`b` / MS\\ :sub:`w`"
msgstr "*F* = MS\\ :sub:`b` / MS\\ :sub:`w`"

#: ../../Ch13/Ch13_ANOVA_07.rst:25
msgid ""
"In a repeated measures ANOVA, the *F*-ratio is calculated in a similar way, "
"but whereas in an independent ANOVA the within-group variability (SS\\ :sub:"
"`w`) is used as the basis for the MS\\ :sub:`w` denominator, in a repeated "
"measures ANOVA the SS\\ :sub:`w` is partioned into two parts. As we are "
"using the same subjects in each group, we can remove the variability due to "
"the individual differences between subjects (referred to as SS\\ :sub:"
"`subjects`) from the within-groups variability. We won’t go into too much "
"technical detail about how this is done, but essentially each subject "
"becomes a level of a factor called subjects. The variability in this within-"
"subjects factor is then calculated in the same way as any between-subjects "
"factor. And then we can subtract SS\\ :sub:`subjects` from SS\\ :sub:`w` to "
"provide a smaller SS\\ :sub:`error` term:"
msgstr ""
"У ANOVA з повторними вимірами коефіцієнт *F* обчислюється аналогічним чином, "
"але тоді як в незалежній ANOVA внутрішньогрупова мінливість (SS\\ :sub:`w`) "
"використовується як основа для знаменника MS\\ :sub:`w`, в ANOVA з "
"повторними вимірами SS\\ :sub:`w` розділяється на дві частини. Оскільки ми "
"використовуємо однакових суб'єктів у кожній групі, ми можемо видалити "
"мінливість, зумовлену індивідуальними відмінностями між суб'єктами ("
"позначену як SS\\ :sub:`subjects`), з мінливості всередині груп. Ми не "
"будемо заглиблюватися в технічні деталі того, як це робиться, але, по суті, "
"кожен суб'єкт стає рівнем фактора, який називається суб'єктами. Потім "
"мінливість у цьому внутрішньосуб'єктному факторі обчислюється так само, як і "
"будь-який міжсуб'єктний фактор. І тоді ми можемо відняти SS\\ :sub:`subjects`"
" від SS\\ :sub:`w`, щоб отримати менший член SS\\ :sub:`error`:"

#: ../../Ch13/Ch13_ANOVA_07.rst:40
msgid "Independent ANOVA:       SS\\ :sub:`error` = SS\\ :sub:`w`"
msgstr "Незалежний ANOVA:       SS\\ :sub:`error` = SS\\ :sub:`w`"

#: ../../Ch13/Ch13_ANOVA_07.rst:41
msgid ""
"Repeated Measures ANOVA: SS\\ :sub:`error` = SS\\ :sub:`w` - SS\\ :sub:"
"`subjects`"
msgstr ""
"Повторні вимірювання ANOVA: SS\\ :sub:`error` = SS\\ :sub:`w` - SS\\ "
":sub:`subjects`"

#: ../../Ch13/Ch13_ANOVA_07.rst:43
msgid ""
"This change in SS\\ :sub:`error` term often leads to a more powerful "
"statistical test, but this does depend on whether the reduction in the SS\\ :"
"sub:`error` more than compensates for the reduction in degrees of freedom "
"for the error term: the degrees of freedom go from (*n* - *k*)\\ [#]_ to "
"(*n* - 1)(*k* - 1) remembering that there are more subjects in the "
"independent ANOVA design."
msgstr ""
"Ця зміна в терміні SS\\ :sub:`error` часто призводить до більш потужного "
"статистичного тесту, але це залежить від того, чи зменшення SS\\ :sub:`error`"
" більше ніж компенсує зменшення ступенів свободи для терміна помилки: "
"ступені свободи змінюються від (*n* - *k*)\\ [#]_ до (*n* - 1)(*k* - 1), "
"пам'ятаючи, що в незалежному дизайні ANOVA є більше суб'єктів."

#: ../../Ch13/Ch13_ANOVA_07.rst:51
msgid "Repeated measures ANOVA in jamovi"
msgstr "Повторні вимірювання ANOVA в jamovi"

#: ../../Ch13/Ch13_ANOVA_07.rst:53
msgid ""
"First, we need some data. :ref:`Geschwind (1972) <Geschwind_1972>` has "
"suggested that the exact nature of a patient’s language deficit following a "
"stroke can be used to diagnose the specific region of the brain that has "
"been damaged. A researcher is concerned with identifying the specific "
"communication difficulties experienced by six patients suffering from "
"Broca’s Aphasia (a language deficit commonly experienced following a stroke)."
msgstr ""
"Спочатку нам потрібні деякі дані. :ref:`Geschwind (1972) <Geschwind_1972>` "
"припустив, що точна природа мовного дефіциту пацієнта після інсульту може "
"бути використана для діагностики конкретної ділянки мозку, яка була "
"пошкоджена. Дослідник займається виявленням конкретних комунікативних "
"труднощів, з якими стикаються шість пацієнтів, що страждають на афазію Брока "
"(мовний дефіцит, який часто спостерігається після інсульту)."

#: ../../Ch13/Ch13_ANOVA_07.rst:60
msgid "Number of attempts successfully completed on three experimental tasks."
msgstr "Кількість успішно виконаних спроб у трьох експериментальних завданнях."

#: ../../Ch13/Ch13_ANOVA_07.rst:64
msgid "Participant"
msgstr "Учасник"

#: ../../Ch13/Ch13_ANOVA_07.rst:64
msgid "Speech"
msgstr "Промова"

#: ../../Ch13/Ch13_ANOVA_07.rst:64
msgid "Conceptual"
msgstr "Концептуальний"

#: ../../Ch13/Ch13_ANOVA_07.rst:64
msgid "Syntax"
msgstr "Синтаксис"

#: ../../Ch13/Ch13_ANOVA_07.rst:70
msgid "9"
msgstr "9"

#: ../../Ch13/Ch13_ANOVA_07.rst:79
msgid ""
"The patients were required to complete three word recognition tasks. On the "
"first (speech production) task, patients were required to repeat single "
"words read out aloud by the researcher. On the second (conceptual) task, "
"designed to test word comprehension, patients were required to match a "
"series of pictures with their correct name. On the third (syntax) task, "
"designed to test knowledge of correct word order, patients were asked to "
"reorder syntactically incorrect sentences. Each patient completed all three "
"tasks. The order in which patients attempted the tasks was counterbalanced "
"between participants. Each task consisted of a series of 10 attempts. The "
"number of attempts successfully completed by each patient are shown in :"
"numref:`tab-RManova`. Enter these data into jamovi ready for analysis (or "
"take a short-cut and load the |broca|_ data set)."
msgstr ""
"Пацієнти повинні були виконати три завдання на розпізнавання слів. У першому "
"(мовленнєвому) завданні пацієнти повинні були повторити окремі слова, "
"прочитані вголос дослідником. У другому (концептуальному) завданні, "
"призначеному для перевірки розуміння слів, пацієнти повинні були зіставити "
"серію зображень з їх правильною назвою. У третьому (синтаксичному) завданні, "
"призначеному для перевірки знання правильного порядку слів, пацієнти повинні "
"були переставити синтаксично неправильні речення. Кожен пацієнт виконав усі "
"три завдання. Порядок, в якому пацієнти виконували завдання, був "
"збалансований між учасниками. Кожне завдання складалося з серії з 10 спроб. "
"Кількість спроб, успішно виконаних кожним пацієнтом, показана в :numref:`tab-"
"RManova`. Введіть ці дані в jamovi, готові до аналізу (або скористайтеся "
"скороченням і завантажте набір даних |broca|_)."

#: ../../Ch13/Ch13_ANOVA_07.rst:93
msgid ""
"To perform a one-way related ANOVA in jamovi, open the one-way repeated "
"measures ANOVA dialogue box, as in :numref:`fig-RManova1`, via ``ANOVA - "
"Repeated Measures ANOVA``. Then:"
msgstr ""
"Щоб виконати однофакторний пов'язаний дисперсійний аналіз (ANOVA) в jamovi, "
"відкрийте діалогове вікно однофакторного повторюваного дисперсійного аналізу "
"(ANOVA), як показано на малюнку. :numref:`fig-RManova1`, через ``ANOVA - "
"Repeated Measures ANOVA``. Тоді:"

#: ../../Ch13/Ch13_ANOVA_07.rst:97
msgid ""
"Enter a name for the ``Repeated Measures Factors`` (orginally: ``RM Factor …"
"``). This should be a label that you choose to describe the conditions "
"repeated by all participants. For example, to describe the speech, "
"conceptual and syntax tasks completed by all participants a suitable label "
"would be ``Task``. Note that this new factor name represents the independent "
"variable in the analysis."
msgstr ""
"Введіть назву для ``Факторів повторних вимірювань`` (оригінальна назва: ``RM "
"Factor …``). Це має бути назва, яку ви обираєте для опису умов, що "
"повторюються для всіх учасників. Наприклад, для опису мовленнєвих, "
"концептуальних та синтаксичних завдань, які виконують всі учасники, "
"підходящою назвою буде ``Завдання``. Зверніть увагу, що ця нова назва "
"фактора представляє незалежну змінну в аналізі."

#: ../../Ch13/Ch13_ANOVA_07.rst:104
msgid ""
"Add a third level in the ``Repeated Measures Factors`` variable box, as "
"there are three levels representing the three tasks: ``Speech``, "
"``Conceptual`` and ``Syntax``. Change the labels of the levels accordingly."
msgstr ""
"Додайте третій рівень у ``Repeated Measures Factors`` змінна коробка, "
"оскільки є три рівні, що представляють три завдання: ``Speech``, "
"``Conceptual`` і ``Syntax``. Відповідно змініть мітки рівнів."

#: ../../Ch13/Ch13_ANOVA_07.rst:108
msgid ""
"Then move each of the levels variables across to the ``Repeated Measures "
"Cells`` text box."
msgstr ""
"Потім перемістіть кожну зі змінних рівнів до текстового поля ``Repeated "
"Measures Cells`` ."

#: ../../Ch13/Ch13_ANOVA_07.rst:111
msgid ""
"Finally, under the ``Assumption Checks`` option, tick the ``Sphericity "
"checks`` check box."
msgstr ""
"Зрештою, під ``Assumption Checks`` опцію, поставте позначку ``Sphericity "
"checks`` прапорець."

#: ../../Ch13/Ch13_ANOVA_07.rst:116 ../../Ch13/Ch13_ANOVA_07.rst:120
msgid "Repeated measures ANOVA dialogue box in jamovi"
msgstr "Діалогове вікно ANOVA з повторними вимірюваннями в jamovi"

#: ../../Ch13/Ch13_ANOVA_07.rst:124
msgid ""
"jamovi output for a one-way ``Repeated Measures ANOVA`` is produced as shown "
"in the :numref:`fig-RManova2` to :numref:`fig-RManova5`. The first output we "
"should look at is ``Mauchly’s Test of Sphericity``, which tests the "
"hypothesis that the variances of the differences between the conditions are "
"equal (meaning that the spread of difference scores between the study "
"conditions is approximately the same). In :numref:`fig-RManova2`, Mauchly’s "
"test significance level is *p* = 0.720. If Mauchly’s test is non-significant "
"(i.e. *p* > 0.05, as is the case in this analysis) then it is reasonable to "
"conclude that the variances of the differences are not significantly "
"different (i.e. they are roughly equal and sphericity can be assumed.)."
msgstr ""
"Вихідні дані jamovi для одностороннього ``ANOVA з повторними вимірами`` "
"представлені на малюнках від :numref:`fig-RManova2` до :numref:`fig-RManova5`"
". Перший результат, на який слід звернути увагу, — це ``тест сферичності "
"Мауклі``, який перевіряє гіпотезу про те, що дисперсії різниць між умовами є "
"рівними (тобто розкид балів різниці між умовами дослідження є приблизно "
"однаковим). На :numref:`fig-RManova2` рівень значущості тесту Мауклі "
"становить *p* = 0,720. Якщо тест Мауклі є неістотним (тобто *p* > 0,05, як у "
"цьому аналізі), то можна зробити висновок, що дисперсії різниць не "
"відрізняються істотно (тобто вони приблизно рівні, і можна припустити "
"сферичність)."

#: ../../Ch13/Ch13_ANOVA_07.rst:138 ../../Ch13/Ch13_ANOVA_07.rst:142
msgid "One-way repeated measures ANOVA output: Mauchly’s Test of Sphericity"
msgstr ""
"Результат однофакторного повторного вимірювання ANOVA: тест Моклі на "
"сферичність"

#: ../../Ch13/Ch13_ANOVA_07.rst:146
msgid ""
"If, on the other hand, Mauchly’s test had been significant (*p* < 0.05) then "
"we would conclude that there are significant differences between the "
"variance of the differences, and the requirement of sphericity has not been "
"met. In this case, we should apply a correction to the *F*-value obtained in "
"the one-way related ANOVA analysis:"
msgstr ""
"Якщо, з іншого боку, тест Маучлі був би значущим (*p* < 0,05), то ми б "
"зробили висновок, що існують значущі відмінності між дисперсією "
"відмінностей, і вимога сферичності не була виконана. У цьому випадку ми "
"повинні застосувати корекцію до значення *F*, отриманого в односторонньому "
"ANOVA-аналізі:"

#: ../../Ch13/Ch13_ANOVA_07.rst:153
msgid ""
"If the ``Greenhouse-Geisser`` value in the ``Tests of Sphericity`` table is "
"> 0.75 then you should use the Huynh-Feldt correction."
msgstr ""
"Якщо ``Greenhouse-Geisser`` значення в ``Tests of Sphericity`` таблиці > "
"0,75, тоді слід використовувати поправку Гюйня-Фельдта."

#: ../../Ch13/Ch13_ANOVA_07.rst:156
msgid ""
"But if the ``Greenhouse-Geisser`` value is < 0.75, then you should use the "
"Greenhouse-Geisser correction."
msgstr ""
"Але якщо значення ``Greenhouse-Geisser`` < 0,75, тоді слід використовувати "
"поправку Greenhouse-Geisser."

#: ../../Ch13/Ch13_ANOVA_07.rst:159
msgid ""
"Both these corrected *F*-values can be specified in the ``Sphericity "
"Corrections`` check boxes under the ``Assumption Checks`` options, and the "
"corrected *F*-values are then shown in the results table, as in :numref:`fig-"
"RManova3`."
msgstr ""
"Обидва ці скориговані значення *F* можна вказати в ``Sphericity Corrections``"
" прапорці під ``Assumption Checks`` опції, а виправлені значення *F* потім "
"відображаються в таблиці результатів, як у :numref:`fig-RManova3`."

#: ../../Ch13/Ch13_ANOVA_07.rst:166
msgid "Repeated measures ANOVA output: Tests of Within-Subjects Effects"
msgstr ""
"Вихідний результат ANOVA з повторними вимірюваннями: тести "
"внутрішньосуб'єктних ефектів"

#: ../../Ch13/Ch13_ANOVA_07.rst:170
msgid ""
"One-way repeated measures ANOVA output: Tests of Within-Subjects Effects"
msgstr ""
"Результат однофакторного повторного вимірювання ANOVA: тести "
"внутрішньосуб'єктних ефектів"

#: ../../Ch13/Ch13_ANOVA_07.rst:175
msgid ""
"In our analysis, we saw that the significance of Mauchly’s Test of "
"Sphericity was *p* = 0.720 (i.e. *p* > 0.05). So, this means we can assume "
"that the requirement of sphericity has been met so no correction to the *F*-"
"value is needed. Therefore, we can use the ``None`` Sphericity Correction "
"output values for the repeated measure ``Task``: *F* = 6.93, *df1* = 2, "
"*df2* = 10, *p* = 0.013, and we can conclude that the number of tests "
"successfully completed on each language task did vary significantly "
"depending on whether the task was speech, comprehension or syntax based "
"(*F*\\(2,10) = 6.93, *p* = 0.013)."
msgstr ""
"У нашому аналізі ми побачили, що значимість тесту сферичності Маучлі "
"становила *p* = 0,720 (тобто *p* > 0,05). Отже, це означає, що ми можемо "
"припустити, що вимога сферичності виконана, тому корекція значення *F* не "
"потрібна. Отже, ми можемо використовувати вихідні значення ``None`` (Без "
"корекції сферичності) для повторного вимірювання ``Task`` (Завдання): *F* = "
"6,93, *df1* = 2, *df2* = 10, *p* = 0,013, і ми можемо зробити висновок, що "
"кількість успішно виконаних тестів для кожного мовного завдання значно "
"відрізнялася залежно від того, чи було завдання пов'язане з мовленням, "
"розумінням або синтаксисом (*F*\\(2,10) = 6,93, *p* = 0,013)."

#: ../../Ch13/Ch13_ANOVA_07.rst:187 ../../Ch13/Ch13_ANOVA_07.rst:191
msgid "Post-hoc tests in repeated measures ANOVA in jamovi"
msgstr "Post-hoc тести з повторними вимірюваннями ANOVA в jamovi"

#: ../../Ch13/Ch13_ANOVA_07.rst:195
msgid ""
"Post-hoc tests can also be specified in jamovi for repeated measures ANOVA "
"in the same way as for independent ANOVA. The results are shown in :numref:"
"`fig-RManova4`. These indicate that there is a significant difference "
"between ``Speech`` and ``Syntax``, but not between other levels."
msgstr ""
"Пост-хок тести також можуть бути вказані в jamovi для ANOVA з повторними "
"вимірами таким же чином, як і для незалежної ANOVA. Результати показані в "
":numref:`fig-RManova4`. Вони вказують на те, що існує значна різниця між "
"``Speech`` і ``Syntax``, але не між іншими рівнями."

#: ../../Ch13/Ch13_ANOVA_07.rst:201
msgid ""
"Descriptive statistics (marginal means) can be reviewed to help interpret "
"the results, produced in the jamovi output as in :numref:`fig-RManova5`. "
"Comparison of the mean number of trials successfully completed by "
"participants shows that Broca’s Aphasics perform reasonably well on speech "
"production (mean = 7.17) and language comprehension (mean = 6.17) tasks. "
"However, their performance was considerably worse on the syntax task (mean = "
"4.33), with a significant difference in post-hoc tests between ``Speech`` "
"and ``Syntax`` task performance."
msgstr ""
"Для інтерпретації результатів можна переглянути описову статистику (граничні "
"середні значення), представлену у вихідних даних jamovi, як у :numref:`fig-"
"RManova5`. Порівняння середньої кількості успішно виконаних учасниками "
"випробувань показує, що афазики Брока досить добре справляються із "
"завданнями з мовлення (середнє = 7,17) та розуміння мови (середнє = 6,17). "
"Однак їхні результати були значно гіршими у завданні з синтаксису (середнє = "
"4,33), з істотною різницею в пост-гок тестах між результатами завдань "
"``Мовлення`` та ``Синтаксис``."

#: ../../Ch13/Ch13_ANOVA_07.rst:212 ../../Ch13/Ch13_ANOVA_07.rst:216
msgid "One-way repeated measures ANOVA output: Descriptive Statistics"
msgstr "Вихід однофакторного повторного вимірювання ANOVA: описова статистика"

#: ../../Ch13/Ch13_ANOVA_07.rst:223
msgid "(n - k): (number of subjects - number of groups)"
msgstr "(n - k): (кількість суб'єктів - кількість груп)"

#: ../../Ch13/Ch13_ANOVA_08.rst:4
msgid "The Friedman non-parametric repeated measures ANOVA test"
msgstr "Непараметричний тест Фрідмана з повторними вимірюваннями ANOVA"

#: ../../Ch13/Ch13_ANOVA_08.rst:6
msgid ""
"The Friedman test is a non-parametric version of a repeated measures ANOVA "
"and can be used instead of the Kruskall-Wallis test when testing for "
"differences between three or more groups |nominal| where the same "
"participants are in each group, or each participant is closely matched with "
"participants in other conditions. If the dependent variable is ordinal |"
"ordinal|, or if the assumption of normality is not met, then the Friedman "
"test can be used."
msgstr ""
"Тест Фрідмана є непараметричною версією ANOVA з повторними вимірами і може "
"використовуватися замість тесту Крускалла-Уолліса при перевірці відмінностей "
"між трьома або більше групами |номінальними|, де в кожній групі знаходяться "
"однакові учасники, або кожен учасник тісно пов'язаний з учасниками в інших "
"умовах. Якщо залежна змінна є порядковою |порядковою|, або якщо припущення "
"про нормальність не виконується, то можна використовувати тест Фрідмана."

#: ../../Ch13/Ch13_ANOVA_08.rst:51
msgid "ordinal"
msgstr "ordinal"

#: ../../Ch13/Ch13_ANOVA_08.rst:15 ../../Ch13/Ch13_ANOVA_08.rst:19
msgid "``Repeated Measures ANOVA (Non-parametric)`` dialogue box in jamovi"
msgstr "``Repeated Measures ANOVA (Non-parametric)`` діалогове вікно в jamovi"

#: ../../Ch13/Ch13_ANOVA_08.rst:23
msgid ""
"As with the Kruskall-Wallis test, the underlying mathematics is complicated, "
"and won’t be presented here. For the purpose of this book, it is sufficient "
"to note that jamovi calculates the tie-corrected version of the Friedman "
"test, and in :numref:`fig-RManova6` there is an example using the Broca’s "
"Aphasia data we have already looked at."
msgstr ""
"Як і у випадку з тестом Крускалла-Уолліса, математика, що лежить в основі "
"цього тесту, є складною і не буде тут представлена. Для цілей цієї книги "
"достатньо зазначити, що jamovi обчислює версію тесту Фрідмана з поправкою на "
"рівність, а в :numref:`fig-RManova6` наведено приклад з використанням даних "
"про афазію Брока, які ми вже розглядали."

#: ../../Ch13/Ch13_ANOVA_08.rst:29
msgid ""
"It’s pretty straightforward to run a Friedman test in jamovi. Just select "
"``Analyses`` → ``ANOVA`` → ``Repeated Measures ANOVA (Non-parametric)``, as "
"in :numref:`fig-RManova6`. Then highlight and transfer the names of the "
"repeated measures variables you wish to compare (``Speech``, ``Conceptual``, "
"``Syntax``) into the ``Measures:`` text box. To produce descriptive "
"statistics (means and medians) for the three repeated measures variables, "
"click on the ``Descriptives`` button."
msgstr ""
"Виконати тест Фрідмана в jamovi досить просто. Просто виберіть ``Analyses`` →"
" ``ANOVA`` → ``Repeated Measures ANOVA (Non-parametric)``, як у :numref:`fig-"
"RManova6`. Потім виділіть та перенесіть назви змінних повторних вимірювань, "
"які ви хочете порівняти (``Speech``, ``Conceptual``, ``Syntax``) у "
"``Measures:`` текстове поле. Щоб отримати описову статистику (середні "
"значення та медіани) для трьох змінних повторних вимірювань, натисніть на "
"кнопку ``Descriptives`` ."

#: ../../Ch13/Ch13_ANOVA_08.rst:37
msgid ""
"The jamovi results show descriptive statistics, χ²-value, degrees of "
"freedom, and the *p*-value (:numref:`fig-RManova6`). Since the *p*-value is "
"less than the level conventionally used to determine significance (*p* < "
"0.05), we can conclude that Broca’s Aphasics perform reasonably well on "
"speech production (median = 7.5) and language comprehension (median = 6.5) "
"tasks. However, their performance was considerably worse on the syntax task "
"(median = 4.5), with a significant difference in post-hoc tests between "
"Speech and Syntax task performance."
msgstr ""
"Результати jamovi показують описову статистику, значення χ², ступені свободи "
"та значення *p* (:numref:`fig-RManova6`). Оскільки значення *p* менше за "
"рівень, що зазвичай використовується для визначення значущості (*p* < 0,05), "
"ми можемо зробити висновок, що пацієнти з афазією Брока досить добре "
"справляються із завданнями з мовленнєвого виробництва (медіана = 7,5) та "
"мовленнєвого розуміння (медіана = 6,5). Однак їхні результати були значно "
"гіршими у завданні на синтаксис (медіана = 4,5), з істотною різницею в пост-"
"гок тестах між результатами завдань на мовлення та синтаксис."

#: ../../Ch13/Ch13_ANOVA_09.rst:4
msgid "On the relationship between ANOVA and the Student *t*-test"
msgstr "Про зв'язок між (ANOVA) та тестом Стьюдента *t*-test"

#: ../../Ch13/Ch13_ANOVA_09.rst:6
msgid ""
"There’s one last thing I want to point out before finishing. It’s something "
"that a lot of people find kind of surprising, but it’s worth knowing about. "
"An ANOVA with two groups is identical to the Student *t*-test. No, really. "
"It’s not just that they are similar, but they are actually equivalent in "
"every meaningful way. I won’t try to prove that this is always true, but I "
"will show you a single concrete demonstration. Suppose that, instead of "
"running an ANOVA on our ``mood.gain ~ drug`` model, let’s instead do it "
"using ``therapy`` as the predictor. If we run this ANOVA we get an *F*-"
"statistic of F(1,16) = 1.71, and a *p*-value = 0.210. Since we only have two "
"groups, I didn’t actually need to resort to an ANOVA, I could have just "
"decided to run a Student *t*-test. So let’s see what happens when I do that: "
"I get a *t*-statistic of t(16) = -1.3068 and a *p*-value = 0.21. Curiously, "
"the *p*-values are identical. Once again we obtain a value of *p* = 0.210. "
"But what about the test statistic? Having run a *t*-test instead of an "
"ANOVA, we get a somewhat different answer, namely t(16) = -1.3068. However, "
"there is a fairly straightforward relationship here. If we square the *t*-"
"statistic then we get the *F*-statistic from before: -1.3068² = 1.7077."
msgstr ""
"Перед тим, як закінчити, я хочу зазначити ще одну річ. Багато хто вважає це "
"дещо дивним, але про це варто знати. ANOVA з двома групами ідентична *t*-"
"критерію Стьюдента. Ні, справді. Вони не просто схожі, а фактично "
"еквівалентні в усіх значущих аспектах. Я не буду намагатися довести, що це "
"завжди так, але покажу вам один конкретний приклад. Припустимо, що замість "
"того, щоб проводити ANOVA на нашій моделі ``mood.gain ~ drug``, ми зробимо "
"це, використовуючи ``therapy`` як предиктор. Якщо ми проведемо цей ANOVA, ми "
"отримаємо *F*-статистику F(1,16) = 1,71 і *p*-значення = 0,210. Оскільки у "
"нас є тільки дві групи, мені насправді не потрібно було вдаватися до ANOVA, "
"я міг просто вирішити провести *t*-критерій Стьюдента. Тож давайте "
"подивимося, що станеться, коли я це зроблю: я отримую *t*-статистику t(16) = "
"-1,3068 і *p*-значення = 0,21. Цікаво, що *p*-значення є ідентичними. Ми "
"знову отримуємо значення *p* = 0,210. А що щодо тестової статистики? "
"Провівши *t*-тест замість ANOVA, ми отримуємо дещо іншу відповідь, а саме "
"t(16) = -1,3068. Однак тут існує досить проста залежність. Якщо ми піднесемо "
"*t*-статистику до квадрата, то отримаємо *F*-статистику, яку ми отримали "
"раніше: -1,3068² = 1,7077."

#: ../../Ch13/Ch13_ANOVA_10.rst:4
msgid "Summary"
msgstr "Короткий зміст"

#: ../../Ch13/Ch13_ANOVA_10.rst:6
msgid ""
"There’s a fair bit covered in this chapter, but there’s still a lot missing. "
"Most obviously, I haven’t discussed how to run an ANOVA when you are "
"interested in more than one grouping variable, but that will be discussed in "
"a lot of detail in chapter :doc:`../Ch14/Ch14_ANOVA2`. In terms of what we "
"have discussed, the key topics were:"
msgstr ""
"У цьому розділі розглянуто чимало питань, але багато чого ще не висвітлено. "
"Зокрема, я не розповів, як виконати ANOVA, якщо вас цікавить більше ніж одна "
"групувальна змінна, але це буде детально розглянуто в розділі :doc:`../Ch14/"
"Ch14_ANOVA2`. Щодо того, що ми вже обговорили, то основними темами були:"

#: ../../Ch13/Ch13_ANOVA_10.rst:12
msgid ""
"The basic logic behind :doc:`how ANOVA works <Ch13_ANOVA_02>` and :doc:`how "
"to run one in jamovi <Ch13_ANOVA_03>`."
msgstr ""
"Основна логіка :doc:`how ANOVA works <Ch13_ANOVA_02>` і :doc:`how to run one "
"in jamovi <Ch13_ANOVA_03>`."

#: ../../Ch13/Ch13_ANOVA_10.rst:15
msgid "How to compute an :doc:`effect size <Ch13_ANOVA_04>` for an ANOVA."
msgstr "Як обчислити :doc:`effect size <Ch13_ANOVA_04>` для ANOVA."

#: ../../Ch13/Ch13_ANOVA_10.rst:17
msgid ""
":doc:`Post-hoc analysis and corrections for multiple testing "
"<Ch13_ANOVA_05>`."
msgstr ""
":doc:`Post-hoc analysis and corrections for multiple testing "
"<Ch13_ANOVA_05>`."

#: ../../Ch13/Ch13_ANOVA_10.rst:19
msgid ""
"The :doc:`assumptions made by the ANOVA <Ch13_ANOVA_06>`: How to check the "
"homogeneity of variance assumption and what to do if it is violated; as well "
"as how to check the normality assumption and what to do if it is violated."
msgstr ""
":doc:`assumptions made by the ANOVA <Ch13_ANOVA_06>`: Як перевірити "
"припущення про однорідність дисперсії та що робити, якщо воно порушено; а "
"також як перевірити припущення про нормальність та що робити, якщо воно "
"порушено."

#: ../../Ch13/Ch13_ANOVA_10.rst:23
msgid ""
":doc:`Repeated measures ANOVA <Ch13_ANOVA_07>` and its non-parametric "
"equivalent, the :doc:`Friedman test <Ch13_ANOVA_08>`."
msgstr ""
":doc:`Repeated measures ANOVA <Ch13_ANOVA_07>` та його непараметричний "
"еквівалент, :doc:`Friedman test <Ch13_ANOVA_08>`."

#: ../../Ch13/Ch13_ANOVA_10.rst:26
msgid ""
"As with all of the chapters in this book, there are quite a few different "
"sources that I’ve relied upon, but the one stand-out text that I’ve been "
"most heavily influenced by is :ref:`Sahai and Ageel (2000) <Sahai_2000>`. "
"It’s not a good book for beginners, but it’s an excellent book for more "
"advanced readers who are interested in understanding the mathematics behind "
"ANOVA."
msgstr ""
"Як і у всіх розділах цієї книги, я спирався на чимало різних джерел, але "
"найбільший вплив на мене справив текст :ref:`Sahai and Ageel (2000) "
"<Sahai_2000>`. Ця книга не підходить для початківців, але є чудовим "
"посібником для більш досвідчених читачів, які хочуть зрозуміти математику, "
"що лежить в основі ANOVA."
