msgid ""
msgstr ""
"Project-Id-Version: Learning statistics with jamovi\n"
"Report-Msgid-Bugs-To: sebastian.jentschke@uib.no\n"
"POT-Creation-Date: 2025-06-12 11:37+0200\n"
"PO-Revision-Date: 2025-09-03 19:22+0000\n"
"Last-Translator: Максим Горпиніч <gorpinicmaksim0@gmail.com>\n"
"Language-Team: Ukrainian <https://hosted.weblate.org/projects/lsjdocs/ch16/"
"uk/>\n"
"Language: uk\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && "
"n%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2);\n"
"X-Generator: Weblate 5.13.1-rc\n"
"Generated-By: Babel 2.10.3\n"

#: ../../Ch16/Ch16_Bayes.rst:4
msgid "Bayesian statistics"
msgstr "Байєсівська статистика"

#: ../../Ch16/Ch16_Bayes.rst:0
msgid ""
"*In our reasonings concerning matter of fact, there are all imaginable "
"degrees of assurance, from the highest certainty to the lowest species of "
"moral evidence. A wise man, therefore, proportions his belief to the "
"evidence.*"
msgstr ""
"*У наших міркуваннях щодо фактичних обставин існують усі можливі ступені "
"впевненості, від найвищої впевненості до найнижчого виду морального доказу. "
"Тому мудра людина співвідносить свою віру з доказами.*"

#: ../../Ch16/Ch16_Bayes.rst:24
msgid "`David Hume <https://en.wikiquote.org/wiki/David_Hume>`__"
msgstr "`Девід Х'юм <https://en.wikiquote.org/wiki/David_Hume>`__"

#: ../../Ch16/Ch16_Bayes.rst:26
msgid ""
"The ideas I’ve presented to you in this book describe inferential statistics "
"from the frequentist perspective. I’m not alone in doing this. In fact, "
"almost every textbook given to undergraduate psychology students presents "
"the opinions of the frequentist statistician as *the* theory of inferential "
"statistics, the one true way to do things. I have taught this way for "
"practical reasons. The frequentist view of statistics dominated the academic "
"field of statistics for most of the 20th century, and this dominance is even "
"more extreme among applied scientists. It was and is current practice among "
"psychologists to use frequentist methods. Because frequentist methods are "
"ubiquitous in scientific papers, every student of statistics needs to "
"understand those methods, otherwise they will be unable to make sense of "
"what those papers are saying! Unfortunately, in my opinion at least, the "
"current practice in psychology is often misguided and the reliance on "
"frequentist methods is partly to blame. In this chapter I explain why I "
"think this and provide an introduction to Bayesian statistics, an approach "
"that I think is generally superior to the orthodox approach."
msgstr ""
"Ідеї, які я представив вам у цій книзі, описують інференційну статистику з "
"точки зору частоти. Я не єдиний, хто так робить. Насправді, майже кожен "
"підручник для студентів-психологів представляє думки статистиків-частотистів "
"як *єдину* теорію інференційної статистики, єдиний правильний спосіб робити "
"речі. Я викладав це з практичних міркувань. Частотний підхід до статистики "
"домінував в академічній сфері статистики протягом більшої частини 20 "
"століття, і ця домінація є ще більш вираженою серед вчених-практиків. "
"Використання частотних методів було і залишається поширеною практикою серед "
"психологів. Оскільки частотні методи є повсюдними в наукових статтях, кожен "
"студент, який вивчає статистику, повинен розуміти ці методи, інакше він не "
"зможе зрозуміти, про що йдеться в цих статтях! На жаль, на мою думку, "
"сучасна практика в психології часто є хибною, і частково в цьому винна "
"залежність від частотних методів. У цьому розділі я пояснюю, чому я так "
"вважаю, і даю вступ до байєсівської статистики, підходу, який, на мою думку, "
"загалом є кращим за ортодоксальний підхід."

#: ../../Ch16/Ch16_Bayes.rst:44
msgid ""
"This chapter comes in two parts: In sections :doc:`Ch16_Bayes_1` through :"
"doc:`Ch16_Bayes_3` I talk about what Bayesian statistics are all about, "
"covering the basic mathematical rules for how it works as well as an "
"explanation for why I think the Bayesian approach is so useful. Afterwards, "
"I provide a brief overview of how you can do :doc:`Bayesian versions of *t*-"
"tests <Ch16_Bayes_5>`."
msgstr ""
"Цей розділ складається з двох частин: у розділах :doc:`Ch16_Bayes_1` до "
":doc:`Ch16_Bayes_3` я розповідаю про те, що таке байєсівська статистика, "
"висвітлюючи основні математичні правила її функціонування, а також "
"пояснюючи, чому, на мою думку, байєсівський підхід є таким корисним. Далі я "
"надаю короткий огляд того, як можна виконати :doc:`Bayesian versions of *t*-"
"tests <Ch16_Bayes_5>`."

#: ../../Ch16/Ch16_Bayes_1.rst:4
msgid "Probabilistic reasoning by rational agents"
msgstr "Ймовірнісні міркування раціональних агентів"

#: ../../Ch16/Ch16_Bayes_1.rst:6
msgid ""
"From a Bayesian perspective statistical inference is all about *belief "
"revision*. I start out with a set of candidate hypotheses *h* about the "
"world. I don’t know which of these hypotheses is true, but do I have some "
"beliefs about which hypotheses are plausible and which are not. When I "
"observe the data, *d*, I have to revise those beliefs. If the data are "
"consistent with a hypothesis, my belief in that hypothesis is strengthened. "
"If the data are inconsistent with the hypothesis, my belief in that "
"hypothesis is weakened. That’s it! At the end of this section I’ll give a "
"precise description of how Bayesian reasoning works, but first I want to "
"work through a simple example in order to introduce the key ideas. Consider "
"the following reasoning problem."
msgstr ""
"З байєсівської точки зору, статистичний висновок полягає у *перегляді "
"переконань*. Я починаю з набору гіпотез *h* про світ. Я не знаю, яка з цих "
"гіпотез є правдивою, але маю певні переконання щодо того, які гіпотези є "
"правдоподібними, а які ні. Коли я спостерігаю дані *d*, я мушу переглянути "
"ці переконання. Якщо дані узгоджуються з гіпотезою, моя віра в цю гіпотезу "
"посилюється. Якщо дані не відповідають гіпотезі, моя віра в цю гіпотезу "
"послаблюється. Ось і все! Наприкінці цього розділу я дам точний опис того, "
"як працює байєсівське міркування, але спочатку я хочу розглянути простий "
"приклад, щоб представити ключові ідеї. Розглянемо наступну задачу на "
"міркування."

#: ../../Ch16/Ch16_Bayes_1.rst:19
msgid "*I’m carrying an umbrella. Do you think it will rain?*"
msgstr "*Я несу парасольку. Як думаєш, буде дощ?*"

#: ../../Ch16/Ch16_Bayes_1.rst:21
msgid ""
"In this problem I have presented you with a single piece of data (*d* = I’m "
"carrying the umbrella), and I’m asking you to tell me your belief or "
"hypothesis about whether it’s raining. You have two alternatives, *h*: "
"either it will rain today or it will not. How should you solve this problem?"
msgstr ""
"У цій задачі я представив вам єдину інформацію (*d* = я ношу парасольку) і "
"прошу вас висловити свою думку або гіпотезу про те, чи буде дощ. У вас є два "
"варіанти, *h*: або сьогодні буде дощ, або не буде. Як вирішити цю задачу?"

#: ../../Ch16/Ch16_Bayes_1.rst:28
msgid "Priors: what you believed before"
msgstr "Попередні події: у що ви вірили раніше"

#: ../../Ch16/Ch16_Bayes_1.rst:30
msgid ""
"The first thing you need to do is ignore what I told you about the umbrella, "
"and write down your pre-existing beliefs about rain. This is important. If "
"you want to be honest about how your beliefs have been revised in the light "
"of new evidence (data) then you *must* say something about what you believed "
"before those data appeared! So, what might you believe about whether it will "
"rain today? You probably know that I live in Australia and that much of "
"Australia is hot and dry. The city of Adelaide where I live has a "
"Mediterranean climate, very similar to southern California, southern Europe "
"or northern Africa. I’m writing this in January and so you can assume it’s "
"the middle of summer. In fact, you might have decided to take a quick look "
"on Wikipedia and discovered that Adelaide gets an `average of 4.6 days of "
"rain across the 31 days of January <https://en.wikipedia.org/wiki/"
"Climate_of_Adelaide>`__. Without knowing anything else, you might conclude "
"that the probability of January rain in Adelaide is about 15\\%, and the "
"probability of a dry day is 85\\%. If this is really what you believe about "
"Adelaide rainfall (and now that I’ve told it to you I’m betting that this "
"really *is* what you believe) then what I have written here is your **prior "
"distribution**, written *P*\\ (h):"
msgstr ""
"Перше, що вам потрібно зробити, це проігнорувати те, що я вам сказав про "
"парасольку, і записати свої попередні переконання про дощ. Це важливо. Якщо "
"ви хочете бути чесними щодо того, як ваші переконання змінилися у світлі "
"нових доказів (даних), то ви *повинні* сказати щось про те, у що ви вірили "
"до появи цих даних! Отже, що ви можете думати про те, чи буде сьогодні дощ? "
"Ви, мабуть, знаєте, що я живу в Австралії і що більша частина Австралії "
"спекотна і суха. Місто Аделаїда, де я живу, має середземноморський клімат, "
"дуже схожий на південну Каліфорнію, південну Європу або північну Африку. Я "
"пишу це в січні, тож ви можете припустити, що зараз середина літа. "
"Насправді, ви, можливо, вирішили швидко зазирнути у Вікіпедію і дізналися, "
"що в Аделаїді «в середньому випадає 4,6 дні дощу протягом 31 дня січня "
"<https://en.wikipedia.org/wiki/Climate_of_Adelaide>». Не знаючи нічого "
"іншого, ви можете зробити висновок, що ймовірність дощу в Аделаїді в січні "
"становить приблизно 15 %, а ймовірність сухого дня — 85 %. Якщо ви дійсно "
"так вважаєте про кількість опадів в Аделаїді (а тепер, коли я вам про це "
"сказав, я готовий побитися об заклад, що ви дійсно так вважаєте), то *те*, "
"що я тут написав, є вашим **попереднім розподілом**, позначеним *P*\\ (h):"

#: ../../Ch16/Ch16_Bayes_1.rst:50 ../../Ch16/Ch16_Bayes_1.rst:71
msgid "Hypothesis"
msgstr "Гіпотеза"

#: ../../Ch16/Ch16_Bayes_1.rst:50
msgid "Degree of Belief"
msgstr "Ступінь віри"

#: ../../Ch16/Ch16_Bayes_1.rst:52 ../../Ch16/Ch16_Bayes_1.rst:73
msgid "**Rainy day**"
msgstr "**Дощовий день**"

#: ../../Ch16/Ch16_Bayes_1.rst:52 ../../Ch16/Ch16_Bayes_1.rst:144
msgid "0.15"
msgstr "0.15"

#: ../../Ch16/Ch16_Bayes_1.rst:54 ../../Ch16/Ch16_Bayes_1.rst:75
msgid "**Dry day**"
msgstr "**Сухий день**"

#: ../../Ch16/Ch16_Bayes_1.rst:54 ../../Ch16/Ch16_Bayes_1.rst:146
msgid "0.85"
msgstr "0.85"

#: ../../Ch16/Ch16_Bayes_1.rst:58
msgid "Likelihoods: theories about the data"
msgstr "Ймовірності: теорії про дані"

#: ../../Ch16/Ch16_Bayes_1.rst:60
msgid ""
"To solve the reasoning problem you need a theory about my behaviour. When "
"does Dani carry an umbrella? You might guess that I’m not a complete idiot,"
"\\ [#]_ and I try to carry umbrellas only on rainy days. On the other hand, "
"you also know that I have young kids, and you wouldn’t be all that surprised "
"to know that I’m pretty forgetful about this sort of thing. Let’s suppose "
"that on rainy days I remember my umbrella about 30\\% of the time (I really "
"am awful at this). But let’s say that on dry days I’m only about 5\\% likely "
"to be carrying an umbrella. So you might write out a little table like this:"
msgstr ""
"Щоб вирішити задачу на логічне мислення, вам потрібна теорія про мою "
"поведінку. Коли Дані бере з собою парасольку? Ви можете припустити, що я не "
"повний ідіот,\\ [#]_ і намагаюся брати парасольку тільки в дощові дні. З "
"іншого боку, ви також знаєте, що у мене є маленькі діти, і вас не дуже "
"здивує, що я досить забудькуватий у таких речах. Припустимо, що в дощові дні "
"я пам'ятаю про парасольку приблизно в 30 % випадків (я дійсно дуже погано це "
"роблю). Але припустимо, що в сухі дні я беру парасольку з собою лише в 5 % "
"випадків. Тож ви можете скласти таку таблицю:"

#: ../../Ch16/Ch16_Bayes_1.rst:71 ../../Ch16/Ch16_Bayes_1.rst:130
#: ../../Ch16/Ch16_Bayes_1.rst:142 ../../Ch16/Ch16_Bayes_1.rst:173
#: ../../Ch16/Ch16_Bayes_1.rst:219 ../../Ch16/Ch16_Bayes_1.rst:252
msgid "Umbrella"
msgstr "Парасолька"

#: ../../Ch16/Ch16_Bayes_1.rst:71
msgid "No umbrella"
msgstr "Без парасольки"

#: ../../Ch16/Ch16_Bayes_1.rst:73
msgid "0.30"
msgstr "0.30"

#: ../../Ch16/Ch16_Bayes_1.rst:73
msgid "0.70"
msgstr "0.70"

#: ../../Ch16/Ch16_Bayes_1.rst:75
msgid "0.05"
msgstr "0.05"

#: ../../Ch16/Ch16_Bayes_1.rst:75
msgid "0.95"
msgstr "0.95"

#: ../../Ch16/Ch16_Bayes_1.rst:78
msgid ""
"It’s important to remember that each cell in this table describes your "
"beliefs about what data *d* will be observed, *given* the truth of a "
"particular hypothesis *h*. This “conditional probability” is written *P*\\ "
"(d|h), which you can read as “the probability of *d* given *h*”. In Bayesian "
"statistics, this is referred to as the **likelihood** of the data *d* given "
"the hypothesis *h*.\\ [#]_"
msgstr ""
"Важливо пам'ятати, що кожна комірка в цій таблиці описує ваші переконання "
"щодо того, які дані *d* будуть спостережуватися, *за умови* істинності "
"певної гіпотези *h*. Ця «умовна ймовірність» записується як *P*\\ (d|h), що "
"можна прочитати як «ймовірність *d* за умови *h*». У байєсівській статистиці "
"це називається **ймовірністю** даних *d* за умови гіпотези *h*.\\ [#]_"

#: ../../Ch16/Ch16_Bayes_1.rst:87
msgid "The joint probability of data and hypothesis"
msgstr "Спільна ймовірність даних та гіпотези"

#: ../../Ch16/Ch16_Bayes_1.rst:89
msgid ""
"At this point all the elements are in place. Having written down the priors "
"and the likelihood, you have all the information you need to do Bayesian "
"reasoning. The question now becomes *how* do we use this information? As it "
"turns out, there’s a very simple equation that we can use here, but it’s "
"important that you understand why we use it so I’m going to try to build it "
"up from more basic ideas."
msgstr ""
"На цьому етапі всі елементи вже на місці. Записавши апріорні ймовірності та "
"ймовірності, ви маєте всю необхідну інформацію для байєсівського міркування. "
"Тепер питання полягає в тому, *як* ми використовуємо цю інформацію? Як "
"виявляється, тут можна застосувати дуже просте рівняння, але важливо, щоб ви "
"розуміли, чому ми його використовуємо, тому я спробую побудувати його на "
"основі більш базових ідей."

#: ../../Ch16/Ch16_Bayes_1.rst:96
msgid ""
"Let’s start out with one of the rules of probability theory. I listed it way "
"back in :numref:`tab-probrules`, but I didn’t make a big deal out of it at "
"the time and you probably ignored it. The rule in question is the one that "
"talks about the probability that *two* things are true. In our example you "
"might want to calculate the probability that today is rainy (i.e., "
"hypothesis *h* is true) and I’m carrying an umbrella (i.e., data *d* is "
"observed). The **joint probability** of the hypothesis and the data is "
"written *P*\\ (d, h), and you can calculate it by multiplying the prior "
"*P*\\ (h) by the likelihood *P*\\ (d|h). Mathematically, we say that:"
msgstr ""
"Почнемо з одного з правил теорії ймовірностей. Я вже згадував про нього в "
":numref:`tab-probrules`, але тоді не приділив йому особливої уваги, і ви, "
"мабуть, проігнорували його. Це правило стосується ймовірності того, що *дві* "
"речі є правдивими. У нашому прикладі ви можете обчислити ймовірність того, "
"що сьогодні дощитиме (тобто гіпотеза *h* є істинною) і я маю з собою "
"парасольку (тобто дані *d* є спостережуваними). **Спільна ймовірність** "
"гіпотези та даних записується як *P*\\ (d, h), і її можна обчислити, "
"помноживши апріорну ймовірність *P*\\ (h) на ймовірність *P*\\ (d|h). "
"Математично ми говоримо, що:"

#: ../../Ch16/Ch16_Bayes_1.rst:106
msgid "*P*\\ (d, h) = *P*\\ (d|h) *P*\\ (h)"
msgstr "*P*\\ (d, h) = *P*\\ (d|h) *P*\\ (h)"

#: ../../Ch16/Ch16_Bayes_1.rst:108
msgid ""
"So, what is the probability that today is a rainy day *and* I remember to "
"carry an umbrella? As we discussed earlier, the prior tells us that the "
"probability of a rainy day is 15\\%, and the likelihood tells us that the "
"probability of me remembering my umbrella on a rainy day is 30\\%. So the "
"probability that both of these things are true is calculated by multiplying "
"the two:"
msgstr ""
"Отже, яка ймовірність того, що сьогодні дощитиме *і* я не забуду взяти з "
"собою парасольку? Як ми вже обговорювали раніше, апріорна ймовірність дощу "
"становить 15 %, а ймовірність того, що я не забуду взяти з собою парасольку "
"в дощовий день, становить 30 %. Отже, ймовірність того, що обидві ці події "
"відбудуться, обчислюється шляхом множення цих двох величин:"

#: ../../Ch16/Ch16_Bayes_1.rst:115
msgid ""
"\\begin{aligned}\n"
"P(\\mbox{rainy}, \\mbox{umbrella}) & = & P(\\mbox{umbrella} | \\mbox{rainy}) "
"\\times P(\\mbox{rainy}) \\\\\n"
"& = & 0.30 \\times 0.15 \\\\\n"
"& = & 0.045\\end{aligned}"
msgstr ""
"\\begin{aligned}\n"
"P(\\mbox{rainy}, \\mbox{umbrella}) & = & P(\\mbox{umbrella} | \\mbox{rainy}) "
"\\times P(\\mbox{rainy}) \\\\\n"
"& = & 0.30 \\times 0.15 \\\\\n"
"& = & 0.045\\end{aligned}"

#: ../../Ch16/Ch16_Bayes_1.rst:122
msgid ""
"In other words, before being told anything about what actually happened, you "
"think that there is a 4.5\\% probability that today will be a rainy day and "
"that I will remember an umbrella. However, there are of course *four* "
"possible things that could happen, right? So let’s repeat the exercise for "
"all four. If we do that, we end up with the following table:"
msgstr ""
"Іншими словами, до того, як вам розповіли про те, що насправді сталося, ви "
"вважаєте, що ймовірність того, що сьогодні буде дощовий день і що я не "
"забуду парасольку, становить 4,5 %. Однак, звичайно, існує *чотири* можливі "
"варіанти розвитку подій, чи не так? Тож давайте повторимо вправу для всіх "
"чотирьох варіантів. Якщо ми це зробимо, отримаємо таку таблицю:"

#: ../../Ch16/Ch16_Bayes_1.rst:130 ../../Ch16/Ch16_Bayes_1.rst:142
#: ../../Ch16/Ch16_Bayes_1.rst:173 ../../Ch16/Ch16_Bayes_1.rst:219
#: ../../Ch16/Ch16_Bayes_1.rst:252
msgid "No-umbrella"
msgstr "Без парасольки"

#: ../../Ch16/Ch16_Bayes_1.rst:132 ../../Ch16/Ch16_Bayes_1.rst:144
#: ../../Ch16/Ch16_Bayes_1.rst:175 ../../Ch16/Ch16_Bayes_1.rst:221
#: ../../Ch16/Ch16_Bayes_1.rst:254
msgid "**Rainy**"
msgstr "**Дощовий**"

#: ../../Ch16/Ch16_Bayes_1.rst:132 ../../Ch16/Ch16_Bayes_1.rst:144
msgid "0.0450"
msgstr "0.0450"

#: ../../Ch16/Ch16_Bayes_1.rst:132 ../../Ch16/Ch16_Bayes_1.rst:144
msgid "0.1050"
msgstr "0.1050"

#: ../../Ch16/Ch16_Bayes_1.rst:134 ../../Ch16/Ch16_Bayes_1.rst:146
#: ../../Ch16/Ch16_Bayes_1.rst:177 ../../Ch16/Ch16_Bayes_1.rst:223
#: ../../Ch16/Ch16_Bayes_1.rst:256
msgid "**Dry**"
msgstr "**Сухий**"

#: ../../Ch16/Ch16_Bayes_1.rst:134 ../../Ch16/Ch16_Bayes_1.rst:146
msgid "0.0425"
msgstr "0.0425"

#: ../../Ch16/Ch16_Bayes_1.rst:134 ../../Ch16/Ch16_Bayes_1.rst:146
msgid "0.8075"
msgstr "0.8075"

#: ../../Ch16/Ch16_Bayes_1.rst:137
msgid ""
"This table captures all the information about which of the four "
"possibilities are likely. To really get the full picture, though, it helps "
"to add the row totals and column totals. That gives us this table:"
msgstr ""
"Ця таблиця містить всю інформацію про те, які з чотирьох можливостей є "
"найімовірнішими. Однак, щоб отримати повну картину, варто додати суми рядків "
"і суми стовпців. В результаті ми отримаємо таку таблицю:"

#: ../../Ch16/Ch16_Bayes_1.rst:142
msgid "Total"
msgstr "Всього"

#: ../../Ch16/Ch16_Bayes_1.rst:148 ../../Ch16/Ch16_Bayes_1.rst:225
#: ../../Ch16/Ch16_Bayes_1.rst:258
msgid "**Total**"
msgstr "**Всього**"

#: ../../Ch16/Ch16_Bayes_1.rst:148
msgid "0.0875"
msgstr "0.0875"

#: ../../Ch16/Ch16_Bayes_1.rst:148
msgid "0.9125"
msgstr "0.9125"

#: ../../Ch16/Ch16_Bayes_1.rst:148
msgid "1.00"
msgstr "1.00"

#: ../../Ch16/Ch16_Bayes_1.rst:151
msgid ""
"This is a very useful table, so it’s worth taking a moment to think about "
"what all these numbers are telling us. First, notice that the row sums "
"aren’t telling us anything new at all. For example, the first row tells us "
"that if we ignore all this umbrella business, the chance that today will be "
"a rainy day is 15\\%. That’s not surprising, of course, as that’s our prior."
"\\ [#]_ The important thing isn’t the number itself. Rather, the important "
"thing is that it gives us some confidence that our calculations are "
"sensible! Now take a look at the column sums and notice that they tell us "
"something that we haven’t explicitly stated yet. In the same way that the "
"row sums tell us the probability of rain, the column sums tell us the "
"probability of me carrying an umbrella. Specifically, the first column tells "
"us that on average (i.e., ignoring whether it’s a rainy day or not) the "
"probability of me carrying an umbrella is 8.75\\%. Finally, notice that when "
"we sum across all four logically-possible events, everything adds up to 1. "
"In other words, what we have written down is a proper probability "
"distribution defined over all possible combinations of data and hypothesis."
msgstr ""
"Це дуже корисна таблиця, тому варто приділити хвилинку, щоб подумати, що нам "
"говорять всі ці цифри. По-перше, зверніть увагу, що суми рядків не дають нам "
"жодної нової інформації. Наприклад, перший рядок говорить нам, що якщо ми "
"проігноруємо всю цю справу з парасольками, ймовірність того, що сьогодні "
"буде дощовий день, становить 15\\%. Звичайно, це не дивно, адже це наше "
"попереднє припущення. [#]_ Важливим є не саме число. Важливим є те, що воно "
"дає нам певну впевненість у тому, що наші розрахунки є обґрунтованими! Тепер "
"погляньте на суми стовпців і зверніть увагу, що вони повідомляють нам те, "
"чого ми ще не зазначали прямо. Так само, як суми рядків повідомляють нам про "
"ймовірність дощу, суми стовпців повідомляють нам про ймовірність того, що я "
"візьму з собою парасольку. Зокрема, перший стовпець показує, що в середньому "
"(тобто, не враховуючи, дощитиме чи ні) ймовірність того, що я візьму з собою "
"парасольку, становить 8,75\\%. Нарешті, зверніть увагу, що коли ми "
"підсумовуємо всі чотири логічно можливі події, все додається до 1. Іншими "
"словами, те, що ми записали, є правильним розподілом ймовірностей, "
"визначеним для всіх можливих комбінацій даних та гіпотез."

#: ../../Ch16/Ch16_Bayes_1.rst:169
msgid ""
"Now, because this table is so useful, I want to make sure you understand "
"what all the elements correspond to and how they written:"
msgstr ""
"Тепер, оскільки ця таблиця така корисна, я хочу переконатися, що ви "
"розумієте, чому відповідають усі елементи та як вони записуються:"

#: ../../Ch16/Ch16_Bayes_1.rst:175
msgid "*P*\\ (Umbrella, Rainy)"
msgstr "*P*\\ (Парасолька, Дощовий)"

#: ../../Ch16/Ch16_Bayes_1.rst:175
msgid "*P*\\ (No-umbrella, Rainy)"
msgstr "*P*\\ (Без парасольки, дощ)"

#: ../../Ch16/Ch16_Bayes_1.rst:175
msgid "*P*\\ (Rainy)"
msgstr "*P*\\ (Дощовий)"

#: ../../Ch16/Ch16_Bayes_1.rst:177
msgid "*P*\\ (Umbrella, Dry)"
msgstr "*P*\\ (Парасолька, суха)"

#: ../../Ch16/Ch16_Bayes_1.rst:177
msgid "*P*\\ (No-umbrella, Dry)"
msgstr "*P*\\ (Без парасольки, сухий)"

#: ../../Ch16/Ch16_Bayes_1.rst:177
msgid "*P*\\ (Dry)"
msgstr "*P*\\ (Сухий)"

#: ../../Ch16/Ch16_Bayes_1.rst:179
msgid "*P*\\ (Umbrella)"
msgstr "*P*\\ (Парасолька)"

#: ../../Ch16/Ch16_Bayes_1.rst:179
msgid "*P*\\ (No-umbrella)"
msgstr "*P*\\ (Без парасольки)"

#: ../../Ch16/Ch16_Bayes_1.rst:182
msgid ""
"Finally, let’s use “proper” statistical notation. In the rainy day problem, "
"the data corresponds to the observation that I do or do not have an "
"umbrella. So we’ll let *d*\\ :sub:`1` refer to the possibility that you "
"observe me carrying an umbrella, and *d*\\ :sub:`2` refers to you observing "
"me not carrying one. Similarly, *h*\\ :sub:`1` is your hypothesis that today "
"is rainy, and *h*\\ :sub:`2` is the hypothesis that it is not. Using this "
"notation, the table looks like this:"
msgstr ""
"Нарешті, давайте використаємо «правильну» статистичну нотацію. У задачі про "
"дощовий день дані відповідають спостереженню, що я маю або не маю "
"парасольку. Отже, *d*\\ :sub:`1` буде означати ймовірність того, що ви "
"побачите, як я несу парасольку, а *d*\\ :sub:`2` — ймовірність того, що ви "
"побачите, як я несу парасольку. Аналогічно, *h*\\ :sub:`1` — це ваша "
"гіпотеза, що сьогодні дощитиме, а *h*\\ :sub:`2` — гіпотеза, що дощу не "
"буде. Використовуючи цю нотацію, таблиця виглядає так:"

#: ../../Ch16/Ch16_Bayes_1.rst:191
msgid "**d**\\ :sub:`1`"
msgstr "**d**\\ :sub:`1`"

#: ../../Ch16/Ch16_Bayes_1.rst:191
msgid "**d**\\ :sub:`2`"
msgstr "**d**\\ :sub:`2`"

#: ../../Ch16/Ch16_Bayes_1.rst:193
msgid "**h**\\ :sub:`1`"
msgstr "**h**\\ :sub:`1`"

#: ../../Ch16/Ch16_Bayes_1.rst:193
msgid "*P*\\ (h\\ :sub:`1`\\ , d\\ :sub:`1`\\ )"
msgstr "*P*\\ (h\\ :sub:`1`\\ , d\\ :sub:`1`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:193
msgid "*P*\\ (h\\ :sub:`1`\\ , d\\ :sub:`2`\\ )"
msgstr "*P*\\ (h\\ :sub:`1`\\ , d\\ :sub:`2`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:193
msgid "*P*\\ (h\\ :sub:`1`\\ )"
msgstr "*P*\\ (h\\ :sub:`1`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:195
msgid "**h**\\ :sub:`2`"
msgstr "**h**\\ :sub:`2`"

#: ../../Ch16/Ch16_Bayes_1.rst:195
msgid "*P*\\ (h\\ :sub:`2`\\ , d\\ :sub:`1`\\ )"
msgstr "*P*\\ (h\\ :sub:`2`\\ , d\\ :sub:`1`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:195
msgid "*P*\\ (h\\ :sub:`2`\\ , d\\ :sub:`2`\\ )"
msgstr "*P*\\ (h\\ :sub:`2`\\ , d\\ :sub:`2`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:195
msgid "*P*\\ (h\\ :sub:`2`\\ )"
msgstr "*P*\\ (h\\ :sub:`2`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:197
msgid "*P*\\ (d\\ :sub:`1`\\ )"
msgstr "*P*\\ (d\\ :sub:`1`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:197
msgid "*P*\\ (d\\ :sub:`2`\\ )"
msgstr "*P*\\ (d\\ :sub:`2`\\ )"

#: ../../Ch16/Ch16_Bayes_1.rst:201
msgid "Updating beliefs using Bayes’ rule"
msgstr "Оновлення переконань за допомогою правила Байєса"

#: ../../Ch16/Ch16_Bayes_1.rst:203
msgid ""
"The table we laid out in the last section is a very powerful tool for "
"solving the rainy day problem, because it considers all four logical "
"possibilities and states exactly how confident you are in each of them "
"before being given any data. It’s now time to consider what happens to our "
"beliefs when we are actually given the data. In the rainy day problem, you "
"are told that I really *am* carrying an umbrella. This is something of a "
"surprising event. According to our table, the probability of me carrying an "
"umbrella is only 8.75\\%. But that makes sense, right? A guy carrying an "
"umbrella on a summer day in a hot dry city is pretty unusual, and so you "
"really weren’t expecting that. Nevertheless, the data tells you that it is "
"true. No matter how unlikely you thought it was, you must now adjust your "
"beliefs to accommodate the fact that you now *know* that I have an umbrella."
"\\ [#]_ To reflect this new knowledge, our *revised* table must have the "
"following numbers:"
msgstr ""
"Таблиця, яку ми склали в останньому розділі, є дуже потужним інструментом "
"для вирішення проблеми дощового дня, оскільки вона враховує всі чотири "
"логічні можливості і точно вказує, наскільки ви впевнені в кожній з них, "
"перш ніж отримати будь-які дані. Тепер настав час розглянути, що "
"відбувається з нашими переконаннями, коли ми фактично отримуємо дані. У "
"проблемі дощового дня вам кажуть, що я дійсно *маю* з собою парасольку. Це "
"дещо несподівана подія. Згідно з нашою таблицею, ймовірність того, що я маю "
"з собою парасольку, становить лише 8,75 %. Але це логічно, чи не так? "
"Чоловік з парасолькою в літній день у спекотному сухому місті — це досить "
"незвично, тож ви дійсно не очікували цього. Проте дані свідчать, що це "
"правда. Незалежно від того, наскільки малоймовірним ви вважали це, тепер ви "
"мусите скоригувати свої переконання, щоб врахувати той факт, що ви тепер "
"*знаєте*, що я маю парасольку. [#]_ Щоб відобразити ці нові знання, наша "
"*переглянута* таблиця повинна містити такі цифри:"

#: ../../Ch16/Ch16_Bayes_1.rst:221 ../../Ch16/Ch16_Bayes_1.rst:223
#: ../../Ch16/Ch16_Bayes_1.rst:225 ../../Ch16/Ch16_Bayes_1.rst:254
#: ../../Ch16/Ch16_Bayes_1.rst:256 ../../Ch16/Ch16_Bayes_1.rst:258
msgid "0"
msgstr "0"

#: ../../Ch16/Ch16_Bayes_1.rst:225 ../../Ch16/Ch16_Bayes_1.rst:258
msgid "1"
msgstr "1"

#: ../../Ch16/Ch16_Bayes_1.rst:228
msgid ""
"In other words, the facts have eliminated any possibility of “no umbrella”, "
"so we have to put zeros into any cell in the table that implies that I’m not "
"carrying an umbrella. Also, you know for a fact that I am carrying an "
"umbrella, so the column sum on the left must be 1 to correctly describe the "
"fact that *P*\\ (umbrella) = 1."
msgstr ""
"Іншими словами, факти виключають будь-яку можливість «відсутності парасольки»"
", тому ми повинні ввести нулі в будь-яку комірку таблиці, яка означає, що я "
"не маю парасольки. Крім того, ви точно знаєте, що я маю парасольку, тому "
"сума стовпця ліворуч повинна дорівнювати 1, щоб правильно описати факт, що "
"*P*\\ (парасолька) = 1."

#: ../../Ch16/Ch16_Bayes_1.rst:234
msgid ""
"What two numbers should we put in the empty cells? Again, let’s not worry "
"about the maths, and instead think about our intuitions. When we wrote out "
"our table the first time, it turned out that those two cells had almost "
"identical numbers, right? We worked out that the joint probability of “rain "
"and umbrella” was 4.5\\%, and the joint probability of “dry and umbrella” "
"was 4.25\\%. In other words, before I told you that I am in fact carrying an "
"umbrella, you’d have said that these two events were almost identical in "
"probability, yes? But notice that *both* of these possibilities are "
"consistent with the fact that I actually am carrying an umbrella. From the "
"perspective of these two possibilities, very little has changed. I hope "
"you’d agree that it’s *still* true that these two possibilities are equally "
"plausible. So what we expect to see in our final table is some numbers that "
"preserve the fact that “rain and umbrella” is *slightly* more plausible than "
"“dry and umbrella”, while still ensuring that numbers in the table add up. "
"Something like this, perhaps?"
msgstr ""
"Які два числа ми повинні вписати в порожні клітинки? Знову ж таки, не будемо "
"замислюватися над математикою, а замість цього покладаймося на свою "
"інтуїцію. Коли ми вперше склали таблицю, виявилося, що ці дві клітинки "
"містили майже однакові числа, чи не так? Ми підрахували, що спільна "
"ймовірність «дощу і парасольки» становила 4,5 %, а спільна ймовірність «"
"сухої погоди і парасольки» — 4,25 %. Іншими словами, до того, як я сказав "
"вам, що насправді маю з собою парасольку, ви б сказали, що ці дві події "
"мають майже однакову ймовірність, так? Але зверніть увагу, що *обидві* ці "
"можливості узгоджуються з тим фактом, що я насправді маю з собою парасольку. "
"З точки зору цих двох можливостей, мало що змінилося. Сподіваюся, ви "
"погодитеся, що *все ще* вірно, що ці дві можливості однаково ймовірні. Отже, "
"ми очікуємо, що в нашій остаточній таблиці будуть цифри, які збережуть той "
"факт, що «дощ і парасолька» *трохи* більш ймовірні, ніж «суха погода і "
"парасолька», і водночас забезпечать, щоб цифри в таблиці додавалися. "
"Можливо, щось на зразок цього?"

#: ../../Ch16/Ch16_Bayes_1.rst:254
msgid "0.514"
msgstr "0.514"

#: ../../Ch16/Ch16_Bayes_1.rst:256
msgid "0.486"
msgstr "0.486"

#: ../../Ch16/Ch16_Bayes_1.rst:261
msgid ""
"What this table is telling you is that, after being told that I’m carrying "
"an umbrella, you believe that there’s a 51.4\\% chance that today will be a "
"rainy day, and a 48.6\\% chance that it won’t. That’s the answer to our "
"problem! The **posterior probability** of rain *P*\\ (h|d) given that I am "
"carrying an umbrella is 51.4\\%"
msgstr ""
"Ця таблиця показує, що після того, як я сказав вам, що маю з собою "
"парасольку, ви вважаєте, що ймовірність дощу сьогодні становить 51,4 %, а "
"ймовірність відсутності дощу — 48,6 %. Ось і відповідь на наше завдання! **"
"Апостеріорна ймовірність** дощу *P*\\ (h|d) за умови, що я маю з собою "
"парасольку, становить 51,4 %."

#: ../../Ch16/Ch16_Bayes_1.rst:267
msgid ""
"How did I calculate these numbers? You can probably guess. To work out that "
"there was a 0.514 probability of “rain”, all I did was take the 0.045 "
"probability of “rain and umbrella” and divide it by the 0.0875 chance of "
"“umbrella”. This produces a table that satisfies our need to have everything "
"sum to 1, and our need not to interfere with the relative plausibility of "
"the two events that are actually consistent with the data. To say the same "
"thing using fancy statistical jargon, what I’ve done here is divide the "
"joint probability of the hypothesis and the data *P*\\ (d, h) by the "
"**marginal probability** of the data *P*\\ (d), and this is what gives us "
"the posterior probability of the hypothesis *given* the data that have been "
"observed. To write this as an equation:\\ [#]_"
msgstr ""
"Як я розрахував ці цифри? Ви, мабуть, можете здогадатися. Щоб обчислити, що "
"ймовірність «дощу» становить 0,514, я просто взяв ймовірність «дощу і "
"парасольки» 0,045 і розділив її на ймовірність «парасольки» 0,0875. У "
"результаті отримали таблицю, яка задовольняє нашу потребу, щоб сума всіх "
"чисел дорівнювала 1, і нашу потребу не втручатися у відносну ймовірність "
"двох подій, які фактично відповідають даним. Якщо висловити те саме, "
"використовуючи вишуканий статистичний жаргон, то я розділив спільну "
"ймовірність гіпотези та даних *P*\\ (d, h) на **маржинальну ймовірність** "
"даних *P*\\ (d), і це дає нам апостеріорну ймовірність гіпотези *за умови* "
"спостережуваних даних. Якщо записати це у вигляді рівняння:\\ [#]_"

#: ../../Ch16/Ch16_Bayes_1.rst:280
msgid ""
"P(h | d) = \\frac{P(d,h)}{P(d)}\n"
"\n"
msgstr ""
"P(h | d) = \\frac{P(d,h)}{P(d)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_1.rst:282
msgid ""
"However, remember what I said at the start of the last section, namely that "
"the joint probability *P*\\ (d, h) is calculated by multiplying the prior "
"*P*\\ (h) by the likelihood *P*\\ (d|h). In real life, the things we "
"actually know how to write down are the priors and the likelihood, so let’s "
"substitute those back into the equation. This gives us the following formula "
"for the posterior probability"
msgstr ""
"Однак пам'ятайте, що я сказав на початку останнього розділу, а саме, що "
"спільна ймовірність *P*\\ (d, h) обчислюється шляхом множення апріорної "
"ймовірності *P*\\ (h) на ймовірність *P*\\ (d|h). У реальному житті ми "
"знаємо, як записати апріорні ймовірності та ймовірності, тому підставимо їх "
"назад у рівняння. Це дає нам наступну формулу для апостеріорної ймовірності"

#: ../../Ch16/Ch16_Bayes_1.rst:289
msgid ""
"P(h | d) = \\frac{P(d|h) P(h)}{P(d)}\n"
"\n"
msgstr ""
"P(h | d) = \\frac{P(d|h) P(h)}{P(d)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_1.rst:291
msgid ""
"And this formula, folks, is known as **Bayes’ rule**. It describes how a "
"learner starts out with prior beliefs about the plausibility of different "
"hypotheses, and tells you how those beliefs should be revised in the face of "
"data. In the Bayesian paradigm, all statistical inference flows from this "
"one simple rule."
msgstr ""
"І ця формула, друзі, відома як **правило Байєса**. Вона описує, як учень "
"починає з попередніх переконань про правдоподібність різних гіпотез, і "
"розповідає, як ці переконання слід переглянути з огляду на дані. У "
"байєсівській парадигмі всі статистичні висновки випливають з цього одного "
"простого правила."

#: ../../Ch16/Ch16_Bayes_1.rst:300
msgid "It’s a leap of faith, I know, but let’s run with it okay?"
msgstr "Це стрибок віри, я знаю, але давайте почнемо, гаразд?"

#: ../../Ch16/Ch16_Bayes_1.rst:303
msgid ""
"Um. I hate to bring this up, but some statisticians would object to me using "
"the word “likelihood” here. The problem is that the word “likelihood” has a "
"very specific meaning in frequentist statistics, and it’s not quite the same "
"as what it means in Bayesian statistics. As far as I can tell Bayesians "
"didn’t originally have any agreed upon name for the likelihood, and so it "
"became common practice for people to use the frequentist terminology. This "
"wouldn’t have been a problem except for the fact that the way that Bayesians "
"use the word turns out to be quite different to the way frequentists do. "
"This isn’t the place for yet another lengthy history lesson but, to put it "
"crudely, when a Bayesian says “*a* likelihood function” they’re usually "
"referring one of the *rows* of the table. When a frequentist says the same "
"thing, they’re referring to the same table, but to them “*a* likelihood "
"function” almost always refers to one of the *columns*. This distinction "
"matters in some contexts, but it’s not important for our purposes."
msgstr ""
"Гм. Мені неприємно про це говорити, але деякі статистики заперечували б "
"проти використання мною слова «ймовірність» в цьому контексті. Проблема в "
"тому, що слово «ймовірність» має дуже конкретне значення в частотній "
"статистиці, і воно не зовсім збігається з тим, що воно означає в "
"байєсівській статистиці. Наскільки я розумію, байєсівці спочатку не мали "
"узгодженої назви для ймовірності, тому люди почали широко використовувати "
"термінологію частотників. Це не було б проблемою, якби не той факт, що "
"баєсівці використовують це слово зовсім інакше, ніж частотники. Це не місце "
"для чергового довгого уроку історії, але, грубо кажучи, коли баєсівець каже "
"«*a* функція ймовірності», він зазвичай має на увазі один із *рядків* "
"таблиці. Коли частотист каже те саме, він має на увазі ту саму таблицю, але "
"для нього «*a* функція ймовірності» майже завжди означає один із *стовпців*. "
"Ця відмінність має значення в деяких контекстах, але для наших цілей вона не "
"є важливою."

#: ../../Ch16/Ch16_Bayes_1.rst:321
msgid ""
"Just to be clear, “prior” information is pre-existing knowledge or beliefs, "
"before we collect or use any data to improve that information."
msgstr ""
"Просто щоб було зрозуміло, «попередня» інформація — це вже існуючі знання чи "
"переконання, що виникають до того, як ми зберемо або використаємо будь-які "
"дані для покращення цієї інформації."

#: ../../Ch16/Ch16_Bayes_1.rst:326
msgid ""
"If we were being a bit more sophisticated, we could extend the example to "
"accommodate the possibility that I’m lying about the umbrella. But let’s "
"keep things simple, shall we?"
msgstr ""
"Якби ми були трохи складнішими, ми могли б розширити приклад, щоб врахувати "
"можливість того, що я брешу щодо парасольки. Але давайте спростимо все, "
"добре?"

#: ../../Ch16/Ch16_Bayes_1.rst:331
msgid ""
"You might notice that this equation is actually a restatement of the same "
"basic rule I listed at the start of the last section. If you multiply both "
"sides of the equation by *P*\\ (d), then you get *P*\\ (d) *P*\\ (h|d) = "
"*P*\\ (d, h), which is the rule for how joint probabilities are calculated. "
"So I’m not actually introducing any “new” rules here, I’m just using the "
"same rule in a different way."
msgstr ""
"Ви можете помітити, що це рівняння є фактично переформулюванням того самого "
"основного правила, яке я навів на початку попереднього розділу. Якщо "
"помножити обидві частини рівняння на *P*\\ (d), то отримаємо *P*\\ (d) *P*\\ "
"(h|d) = *P*\\ (d, h), що є правилом обчислення спільних ймовірностей. Тому я "
"насправді не вводжу тут жодних «нових» правил, а просто використовую те саме "
"правило по-іншому."

#: ../../Ch16/Ch16_Bayes_2.rst:4
msgid "Bayesian hypothesis tests"
msgstr "Перевірки баєсівських гіпотез"

#: ../../Ch16/Ch16_Bayes_2.rst:6
msgid ""
"In chapter :doc:`../Ch09/Ch09_HypothesisTesting`, I described the orthodox "
"approach to hypothesis testing. It took an entire chapter to describe, "
"because null hypothesis testing is a very elaborate contraption that people "
"find very hard to make sense of. In contrast, the Bayesian approach to "
"hypothesis testing is incredibly simple. Let’s pick a setting that is "
"closely analogous to the orthodox scenario. There are two hypotheses that we "
"want to compare, a null hypothesis *h*\\ :sub:`0` and an alternative "
"hypothesis *h*\\ :sub:`1`. Prior to running the experiment we have some "
"beliefs *P*\\ (h) about which hypotheses are true. We run an experiment and "
"obtain data *d*. Unlike frequentist statistics, Bayesian statistics does "
"allow us to talk about the probability that the null hypothesis is true. "
"Better yet, it allows us to calculate the **posterior probability of the "
"null hypothesis**, using Bayes’ rule:"
msgstr ""
"У розділі :doc:`../Ch09/Ch09_HypothesisTesting` я описав ортодоксальний "
"підхід до перевірки гіпотез. На це пішов цілий розділ, оскільки перевірка "
"нульової гіпотези — це дуже складний механізм, який людям важко зрозуміти. "
"На відміну від цього, байєсівський підхід до перевірки гіпотез надзвичайно "
"простий. Давайте виберемо ситуацію, яка дуже схожа на ортодоксальний "
"сценарій. Є дві гіпотези, які ми хочемо порівняти: нульова гіпотеза *h*\\ "
":sub:`0` та альтернативна гіпотеза *h*\\ :sub:`1`. Перед проведенням "
"експерименту ми маємо певні переконання *P*\\ (h) щодо того, які гіпотези є "
"правдивими. Ми проводимо експеримент і отримуємо дані *d*. На відміну від "
"частотної статистики, байєсівська статистика дозволяє нам говорити про "
"ймовірність того, що нульова гіпотеза є істинною. Більше того, вона дозволяє "
"нам обчислити **апостеріорну ймовірність нульової гіпотези**, використовуючи "
"правило Байєса:"

#: ../../Ch16/Ch16_Bayes_2.rst:20
msgid ""
"P(h_0 | d) = \\frac{P(d|h_0) P(h_0)}{P(d)}\n"
"\n"
msgstr ""
"P(h_0 | d) = \\frac{P(d|h_0) P(h_0)}{P(d)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:22
msgid ""
"This formula tells us exactly how much belief we should have in the null "
"hypothesis after having observed the data *d*. Similarly, we can work out "
"how much belief to place in the alternative hypothesis using essentially the "
"same equation. All we do is change the subscript:"
msgstr ""
"Ця формула точно показує, наскільки ми повинні вірити в нульову гіпотезу "
"після спостереження даних *d*. Аналогічно, ми можемо обчислити, наскільки ми "
"повинні вірити в альтернативну гіпотезу, використовуючи практично те саме "
"рівняння. Все, що нам потрібно зробити, це змінити індекс:"

#: ../../Ch16/Ch16_Bayes_2.rst:27
msgid ""
"P(h_1 | d) = \\frac{P(d|h_1) P(h_1)}{P(d)}\n"
"\n"
msgstr ""
"P(h_1 | d) = \\frac{P(d|h_1) P(h_1)}{P(d)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:29
msgid ""
"It’s all so simple that I feel like an idiot even bothering to write these "
"equations down, since all I’m doing is copying Bayes rule from the previous "
"section.\\ [#]_"
msgstr ""
"Все так просто, що я почуваюся ідіотом, навіть намагаючись записати ці "
"рівняння, бо все, що я роблю, це копіюю правило Баєса з попереднього розділу."
"\\ [#]_"

#: ../../Ch16/Ch16_Bayes_2.rst:34
msgid "The Bayes factor"
msgstr "Байєсівський Фактор"

#: ../../Ch16/Ch16_Bayes_2.rst:36
msgid ""
"In practice, most Bayesian data analysts tend not to talk in terms of the "
"raw posterior probabilities *P*\\ (h\\ :sub:`0`\\|d) and *P*\\ (h\\ :sub:"
"`1`\\|d). Instead, we tend to talk in terms of the **posterior odds** ratio. "
"Think of it like betting. Suppose, for instance, the posterior probability "
"of the null hypothesis is 25\\%, and the posterior probability of the "
"alternative is 75\\%. The alternative hypothesis is three times as probable "
"as the null, so we say that the *odds* are 3:1 in favour of the alternative. "
"Mathematically, all we have to do to calculate the posterior odds is divide "
"one posterior probability by the other"
msgstr ""
"На практиці більшість аналітиків, які використовують байєсівський підхід, "
"зазвичай не говорять про необроблені апостеріорні ймовірності *P*\\ (h\\ "
":sub:`0`\\|d) та *P*\\ (h\\ :sub:`1`\\|d). Натомість ми зазвичай говоримо "
"про **апостеріорне відношення шансів**. Уявіть собі, що це як ставки. "
"Припустимо, наприклад, що апостеріорна ймовірність нульової гіпотези "
"становить 25\\%, а апостеріорна ймовірність альтернативної гіпотези — 75\\%. "
"Альтернативна гіпотеза втричі ймовірніша за нульову, тому ми говоримо, що *"
"відношення шансів* становить 3:1 на користь альтернативної гіпотези. "
"Математично, щоб обчислити апостеріорні шанси, нам потрібно лише поділити "
"одну апостеріорну ймовірність на іншу"

#: ../../Ch16/Ch16_Bayes_2.rst:46
msgid ""
"\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{0.75}{0.25} = 3\n"
"\n"
msgstr ""
"\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{0.75}{0.25} = 3\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:48
msgid "Or, to write the same thing in terms of the equations above"
msgstr "Або, якщо записати те саме через наведені вище рівняння"

#: ../../Ch16/Ch16_Bayes_2.rst:50
msgid ""
"\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{P(d|h_1)}{P(d|h_0)} \\times "
"\\frac{P(h_1)}{P(h_0)}\n"
"\n"
msgstr ""
"\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{P(d|h_1)}{P(d|h_0)} \\times \\frac"
"{P(h_1)}{P(h_0)}\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:52
msgid ""
"Actually, this equation is worth expanding on. There are three different "
"terms here that you should know. On the left hand side, we have the "
"posterior odds, which tells you what you believe about the relative "
"plausibilty of the null hypothesis and the alternative hypothesis *after* "
"seeing the data. On the right hand side, we have the **prior odds**, which "
"indicates what you thought *before* seeing the data. In the middle, we have "
"the **Bayes factor**, which describes the amount of evidence provided by the "
"data"
msgstr ""
"Насправді, це рівняння варто розширити. Тут є три різних терміни, про які ви "
"повинні знати. Зліва ми маємо апостеріорні шанси, які показують, що ви "
"думаєте про відносну правдоподібність нульової гіпотези та альтернативної "
"гіпотези *після* ознайомлення з даними. Справа ми маємо **апріорні шанси**, "
"які показують, що ви думали *до* ознайомлення з даними. Посередині ми маємо "
"**фактор Байєса**, який описує кількість доказів, наданих даними"

#: ../../Ch16/Ch16_Bayes_2.rst:61
msgid ""
"\\begin{array}{ccccc}\\displaystyle\n"
"\\frac{P(h_1 | d)}{P(h_0 | d)} & = & \\displaystyle\\frac{P(d|h_1)}{P(d|"
"h_0)} & \\times & \\displaystyle\\frac{P(h_1)}{P(h_0)} \\\\[6pt] \\\\[-2pt]\n"
"\\uparrow                      & ~ & \\uparrow                               "
"& ~      & \\uparrow                           \\\\[6pt]\n"
"\\mbox{Posterior odds}         & ~ & \\mbox{Bayes factor}                    "
"& ~      & \\mbox{Prior odds}                  \\\\\n"
"\\end{array}"
msgstr ""
"\\begin{array}{ccccc}\\displaystyle\n"
"\\frac{P(h_1 | d)}{P(h_0 | d)} & = & \\displaystyle\\frac{P(d|h_1)}{P(d|h_0)}"
" & \\times & \\displaystyle\\frac{P(h_1)}{P(h_0)} \\\\[6pt] \\\\[-2pt]\n"
"\\uparrow                      & ~ & \\uparrow                               "
"& ~      & \\uparrow                           \\\\[6pt]\n"
"\\mbox{Posterior odds}         & ~ & \\mbox{Bayes factor}                    "
"& ~      & \\mbox{Prior odds}                  \\\\\n"
"\\end{array}"

#: ../../Ch16/Ch16_Bayes_2.rst:69
msgid ""
"The Bayes factor (sometimes abbreviated as **BF**) has a special place in "
"Bayesian hypothesis testing, because it serves a similar role to the *p*-"
"value in orthodox hypothesis testing. The Bayes factor quantifies the "
"strength of evidence provided by the data, and as such it is the Bayes "
"factor that people tend to report when running a Bayesian hypothesis test. "
"The reason for reporting Bayes factors rather than posterior odds is that "
"different researchers will have different priors. Some people might have a "
"strong bias to believe the null hypothesis is true, others might have a "
"strong bias to believe it is false. Because of this, the polite thing for an "
"applied researcher to do is report the Bayes factor. That way, anyone "
"reading the paper can multiply the Bayes factor by their own *personal* "
"prior odds, and they can work out for themselves what the posterior odds "
"would be. In any case, by convention we like to pretend that we give equal "
"consideration to both the null hypothesis and the alternative, in which case "
"the prior odds equals 1, and the posterior odds becomes the same as the "
"Bayes factor."
msgstr ""
"Коефіцієнт Байєса (іноді скорочується як **BF**) займає особливе місце в "
"байєсівському тестуванні гіпотез, оскільки виконує подібну роль до *p*-"
"значення в ортодоксальному тестуванні гіпотез. Коефіцієнт Байєса кількісно "
"оцінює силу доказів, наданих даними, і саме про коефіцієнт Байєса люди "
"зазвичай повідомляють при проведенні байєсівського тестування гіпотез. "
"Причиною повідомлення коефіцієнтів Байєса, а не апостеріорних шансів, є те, "
"що різні дослідники матимуть різні апріорні ймовірності. Деякі люди можуть "
"мати сильну упередженість вірити в істинність нульової гіпотези, інші можуть "
"мати сильну упередженість вірити в її хибність. З огляду на це, ввічливим "
"для прикладного дослідника буде повідомити коефіцієнт Байєса. Таким чином, "
"кожен, хто читає статтю, може помножити коефіцієнт Байєса на свої *особисті* "
"апріорні шанси і самостійно обчислити апостеріорні шанси. У будь-якому "
"випадку, за звичаєм ми робимо вигляд, що однаково враховуємо як нульову "
"гіпотезу, так і альтернативну, і в цьому випадку апріорні шанси дорівнюють "
"1, а апостеріорні шанси стають такими ж, як коефіцієнт Байєса."

#: ../../Ch16/Ch16_Bayes_2.rst:87
msgid "Interpreting Bayes factors"
msgstr "Інтерпретація байєсівських факторів"

#: ../../Ch16/Ch16_Bayes_2.rst:89
msgid ""
"One of the really nice things about the Bayes factor is the numbers are "
"inherently meaningful. If you run an experiment and you compute a Bayes "
"factor of 4, it means that the evidence provided by your data corresponds to "
"betting odds of 4:1 in favour of the alternative. However, there have been "
"some attempts to quantify the standards of evidence that would be considered "
"meaningful in a scientific context. The two most widely used are from :ref:"
"`Jeffreys (1961) <Jeffreys_1961>` and :ref:`Kass and Raftery (1995) "
"<Kass_1995>`. Of the two, I tend to prefer the :ref:`Kass and Raftery (1995) "
"<Kass_1995>` table because it’s a bit more conservative. So here it is:"
msgstr ""
"Однією з дійсно приємних особливостей коефіцієнта Байєса є те, що цифри "
"мають внутрішнє значення. Якщо ви проводите експеримент і обчислюєте "
"коефіцієнт Байєса, що дорівнює 4, це означає, що докази, надані вашими "
"даними, відповідають ставкам 4:1 на користь альтернативи. Однак були деякі "
"спроби кількісно оцінити стандарти доказів, які вважалися б значущими в "
"науковому контексті. Два найпоширеніші стандарти взяті з :ref:`Jeffreys "
"(1961) <Jeffreys_1961>` та :ref:`Kass and Raftery (1995) <Kass_1995>`. З цих "
"двох я схиляюся до таблиці :ref:`Kass and Raftery (1995) <Kass_1995>`, "
"оскільки вона є дещо більш консервативною. Ось вона:"

#: ../../Ch16/Ch16_Bayes_2.rst:100
msgid "Bayes factor"
msgstr "Байєсівський фактор"

#: ../../Ch16/Ch16_Bayes_2.rst:100
msgid "Interpretation"
msgstr "Інтерпретація"

#: ../../Ch16/Ch16_Bayes_2.rst:102
msgid "1 –   3"
msgstr "1 –   3"

#: ../../Ch16/Ch16_Bayes_2.rst:102
msgid "Negligible evidence"
msgstr "Незначні докази"

#: ../../Ch16/Ch16_Bayes_2.rst:104
msgid "3 –  20"
msgstr "3 –  20"

#: ../../Ch16/Ch16_Bayes_2.rst:104
msgid "Positive evidence"
msgstr "Позитивні докази"

#: ../../Ch16/Ch16_Bayes_2.rst:106
msgid "20 – 150"
msgstr "20 – 150"

#: ../../Ch16/Ch16_Bayes_2.rst:106
msgid "Strong evidence"
msgstr "Переконливі докази"

#: ../../Ch16/Ch16_Bayes_2.rst:108
msgid "> 150"
msgstr "> 150"

#: ../../Ch16/Ch16_Bayes_2.rst:108
msgid "Very strong evidence"
msgstr "Дуже вагомі докази"

#: ../../Ch16/Ch16_Bayes_2.rst:111
msgid ""
"And to be perfectly honest, I think that even the :ref:`Kass and Raftery "
"(1995) <Kass_1995>` standards are being a bit charitable. If it were up to "
"me, I’d have called the “positive evidence” category “weak evidence”. To me, "
"anything in the range 3:1 to 20:1 is “weak” or “modest” evidence at best. "
"But there are no hard and fast rules here. What counts as strong or weak "
"evidence depends entirely on how conservative you are and upon the standards "
"that your community insists upon before it is willing to label a finding as "
"“true”."
msgstr ""
"І, якщо бути чесним, я вважаю, що навіть стандарти :ref:`Kass and Raftery "
"(1995) <Kass_1995>` є дещо занадто поблажливими. Якби це залежало від мене, "
"я б назвав категорію «позитивних доказів» «слабкими доказами». На мій "
"погляд, будь-що в діапазоні від 3:1 до 20:1 є «слабкими» або «помірними» "
"доказами в кращому випадку. Але тут немає жорстких і чітких правил. Те, що "
"вважається сильними або слабкими доказами, повністю залежить від того, "
"наскільки ви консервативні, і від стандартів, яких дотримується ваша "
"спільнота, перш ніж визнати висновок «правдивим»."

#: ../../Ch16/Ch16_Bayes_2.rst:119
msgid ""
"In any case, note that all the numbers listed above make sense if the Bayes "
"factor is greater than 1 (i.e., the evidence favours the alternative "
"hypothesis). However, one big practical advantage of the Bayesian approach "
"relative to the orthodox approach is that it also allows you to quantify "
"evidence *for* the null. When that happens, the Bayes factor will be less "
"than 1. You can choose to report a Bayes factor less than 1, but to be "
"honest I find it confusing. For example, suppose that the likelihood of the "
"data under the null hypothesis *P*\\ (d|h\\ :sub:`0`) is equal to 0.2, and "
"the corresponding likelihood *P*\\ (d|h\\ :sub:`1`) under the alternative "
"hypothesis is 0.1. Using the equations given above, Bayes factor here would "
"be"
msgstr ""
"У будь-якому випадку, зверніть увагу, що всі наведені вище цифри мають сенс, "
"якщо коефіцієнт Байєса більший за 1 (тобто докази свідчать на користь "
"альтернативної гіпотези). Однак, одна велика практична перевага "
"байєсівського підходу порівняно з ортодоксальним підходом полягає в тому, що "
"він також дозволяє кількісно оцінити докази *на користь* нульової гіпотези. "
"У цьому випадку коефіцієнт Байєса буде менше 1. Ви можете вирішити "
"повідомити про коефіцієнт Байєса менше 1, але, чесно кажучи, я вважаю це "
"заплутаним. Наприклад, припустимо, що ймовірність даних за нульовою "
"гіпотезою *P*\\ (d|h\\ :sub:`0`) дорівнює 0,2, а відповідна ймовірність *P*\\"
" (d|h\\ :sub:`1`) за альтернативною гіпотезою дорівнює 0,1. Використовуючи "
"наведені вище рівняння, коефіцієнт Байєса тут буде"

#: ../../Ch16/Ch16_Bayes_2.rst:131
msgid ""
"\\mbox{BF} = \\frac{P(d|h_1)}{P(d|h_0)} = \\frac{0.1}{0.2} = 0.5\n"
"\n"
msgstr ""
"\\mbox{BF} = \\frac{P(d|h_1)}{P(d|h_0)} = \\frac{0.1}{0.2} = 0.5\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:133
msgid ""
"Read literally, this result tells is that the evidence in favour of the "
"alternative is 0.5 to 1. I find this hard to understand. To me, it makes a "
"lot more sense to turn the equation “upside down”, and report the amount op "
"evidence in favour of the *null*. In other words, what we calculate is this"
msgstr ""
"Якщо читати буквально, цей результат говорить про те, що докази на користь "
"альтернативи становлять від 0,5 до 1. Мені це важко зрозуміти. На мій "
"погляд, набагато логічніше «перевернути» рівняння і вказати кількість "
"доказів на користь *нульової гіпотези*. Іншими словами, ми обчислюємо таке"

#: ../../Ch16/Ch16_Bayes_2.rst:139
msgid ""
"\\mbox{BF}^\\prime = \\frac{P(d|h_0)}{P(d|h_1)} = \\frac{0.2}{0.1} = 2\n"
"\n"
msgstr ""
"\\mbox{BF}^\\prime = \\frac{P(d|h_0)}{P(d|h_1)} = \\frac{0.2}{0.1} = 2\n"
"\n"

#: ../../Ch16/Ch16_Bayes_2.rst:141
msgid ""
"And what we would report is a Bayes factor of 2:1 in favour of the null. "
"Much easier to understand, and you can interpret this using the table above."
msgstr ""
"І ми б повідомили про коефіцієнт Байєса 2:1 на користь нуля. Це набагато "
"легше зрозуміти, і ви можете інтерпретувати це, використовуючи таблицю вище."

#: ../../Ch16/Ch16_Bayes_2.rst:148
msgid ""
"Obviously, this is a highly simplified story. All the complexity of real "
"life Bayesian hypothesis testing comes down to how you calculate the "
"likelihood *P*\\ (d|h) when the hypothesis *h* is a complex and vague thing. "
"I’m not going to talk about those complexities in this book, but I do want "
"to highlight that although this simple story is true as far as it goes, real "
"life is messier than I’m able to cover in an introductory stats textbook."
msgstr ""
"Очевидно, що це дуже спрощена історія. Вся складність реального життя "
"байєсівського тестування гіпотез зводиться до того, як ви обчислюєте "
"ймовірність *P*\\ (d|h), коли гіпотеза *h* є складною і нечіткою річчю. Я не "
"буду говорити про ці складнощі в цій книзі, але хочу підкреслити, що хоча ця "
"проста історія є правдивою в межах свого контексту, реальне життя є більш "
"заплутаним, ніж я можу висвітлити в підручнику з вступної статистики."

#: ../../Ch16/Ch16_Bayes_3.rst:4
msgid "Why be a Bayesian?"
msgstr "Чому варто бути баєсівцем?"

#: ../../Ch16/Ch16_Bayes_3.rst:6
msgid ""
"Up to this point I’ve focused exclusively on the logic underpinning Bayesian "
"statistics. We’ve talked about the idea of “probability as a degree of "
"belief”, and what it implies about how a rational agent should reason about "
"the world. The question that you have to answer for yourself is this: how do "
"*you* want to do your statistics? Do you want to be an orthodox "
"statistician, relying on sampling distributions and *p*-values to guide your "
"decisions? Or do you want to be a Bayesian, relying on things like prior "
"beliefs, Bayes factors and the rules for rational belief revision? And to be "
"perfectly honest, I can’t answer this question for you. Ultimately it "
"depends on what you think is right. It’s your call and your call alone. That "
"being said, I can talk a little about why *I* prefer the Bayesian approach."
msgstr ""
"До цього моменту я зосереджувався виключно на логіці, що лежить в основі "
"байєсівської статистики. Ми говорили про ідею «ймовірності як ступеня "
"переконаності» та про те, що це означає для раціонального мислення про світ. "
"Питання, на яке ви повинні відповісти собі, таке: як *ви* хочете займатися "
"статистикою? Ви хочете бути ортодоксальним статистиком, покладаючись на "
"вибіркові розподіли та *p*-значення для прийняття рішень? Або ви хочете бути "
"байєсівцем, покладаючись на такі речі, як попередні переконання, байєсівські "
"коефіцієнти та правила раціонального перегляду переконань? І, якщо бути "
"чесним, я не можу відповісти на це питання за вас. В кінцевому рахунку, це "
"залежить від того, що ви вважаєте правильним. Це ваш вибір і тільки ваш. "
"Однак я можу трохи розповісти про те, чому *я* віддаю перевагу байєсівському "
"підходу."

#: ../../Ch16/Ch16_Bayes_3.rst:20
msgid "Statistics that mean what you think they mean"
msgstr "Статистика, яка означає саме те, що ви думаєте"

#: ../../Ch16/Ch16_Bayes_3.rst:0
msgid ""
"*You keep using that word. I do not think it means what you think it means*"
msgstr ""
"*Ти продовжуєш використовувати це слово. Я не думаю, що воно означає те, що "
"ти думаєш*"

#: ../../Ch16/Ch16_Bayes_3.rst:27
msgid ""
"`Inigo Montoya, The Princess Bride <https://www.imdb.com/title/tt0093779/"
"quotes>`__\\ [#]_"
msgstr ""
"`Ініго Монтойя, «Принцеса-наречена» <https://www.imdb.com/title/tt0093779/"
"quotes>`__\\ [#]_"

#: ../../Ch16/Ch16_Bayes_3.rst:30
msgid ""
"To me, one of the biggest advantages to the Bayesian approach is that it "
"answers the right questions. Within the Bayesian framework, it is perfectly "
"sensible and allowable to refer to “the probability that a hypothesis is "
"true”. You can even try to calculate this probability. Ultimately, isn’t "
"that what you *want* your statistical tests to tell you? To an actual human "
"being, this would seem to be the whole *point* of doing statistics, i.e., to "
"determine what is true and what isn’t. Any time that you aren’t exactly sure "
"about what the truth is, you should use the language of probability theory "
"to say things like “there is an 80\\% chance that Theory A is true, but a "
"20\\% chance that Theory B is true instead”."
msgstr ""
"На мій погляд, одна з найбільших переваг байєсівського підходу полягає в "
"тому, що він дає відповіді на правильні питання. У рамках байєсівської "
"моделі цілком розумно і допустимо посилатися на «ймовірність того, що "
"гіпотеза є правдивою». Ви навіть можете спробувати обчислити цю ймовірність. "
"Зрештою, чи не це ви *хочете*, щоб вам показали ваші статистичні тести? Для "
"звичайної людини це, здається, і є *сенс* статистики, тобто визначити, що є "
"правдою, а що ні. Кожного разу, коли ви не впевнені в тому, що є правдою, ви "
"повинні використовувати мову теорії ймовірностей, щоб сказати щось на кшталт "
"«існує 80 % ймовірності, що теорія А є правдивою, але 20 % ймовірності, що "
"правдивою є теорія Б»."

#: ../../Ch16/Ch16_Bayes_3.rst:42
msgid ""
"This seems so obvious to a human, yet it is explicitly forbidden within the "
"orthodox framework. To a frequentist, such statements are a nonsense because "
"“the theory is true” is not a repeatable event. A theory is true or it is "
"not, and no probabilistic statements are allowed, no matter how much you "
"might want to make them. There’s a reason why, back in section :doc:`../Ch09/"
"Ch09_HypothesisTesting_05`, I repeatedly warned you *not* to interpret the "
"*p*-value as the probability that the null hypothesis is true. There’s a "
"reason why almost every textbook on statstics is forced to repeat that "
"warning. It’s because people desperately *want* that to be the correct "
"interpretation. Frequentist dogma notwithstanding, a lifetime of experience "
"of teaching undergraduates and of doing data analysis on a daily basis "
"suggests to me that most actual humans think that “the probability that the "
"hypothesis is true” is not only meaningful, it’s the thing we care *most* "
"about. It’s such an appealing idea that even trained statisticians fall prey "
"to the mistake of trying to interpret a *p*-value this way. For example, "
"here is a quote from an `official Newspoll report in 2013 <https://about.abc."
"net.au/reports-publications/appreciation-survey-summary-report-2013>`__, "
"explaining how to interpret their (frequentist) data analysis:"
msgstr ""
"Для людини це здається очевидним, але в ортодоксальній парадигмі це "
"категорично заборонено. Для прихильника частотного підходу такі твердження є "
"безглуздими, оскільки «теорія є істинною» не є повторюваною подією. Теорія є "
"істинною або не є, і жодні ймовірнісні твердження не допускаються, як би "
"сильно ви не хотіли їх зробити. Є причина, чому в розділі :doc:`../Ch09/"
"Ch09_HypothesisTesting_05` я неодноразово попереджав вас *не* інтерпретувати "
"*p*-значення як ймовірність того, що нульова гіпотеза є істинною. Є причина, "
"чому майже кожен підручник зі статистики змушений повторювати це "
"попередження. Це тому, що люди відчайдушно *хочуть*, щоб це було правильною "
"інтерпретацією. Незважаючи на догму частотистів, багаторічний досвід "
"викладання студентам і щоденного аналізу даних підказує мені, що більшість "
"людей вважають, що «ймовірність того, що гіпотеза є істинною» не тільки має "
"значення, але й є тим, що нас цікавить *найбільше*. Ця ідея настільки "
"приваблива, що навіть досвідчені статистики потрапляють у пастку, "
"намагаючись інтерпретувати *p*-значення саме таким чином. Наприклад, ось "
"цитата з «офіційного звіту Newspoll за 2013 рік <https://about.abc.net.au/"
"reports-publications/appreciation-survey-summary-report-2013>», в якій "
"пояснюється, як інтерпретувати їхній (фреквентистський) аналіз даних:"

#: ../../Ch16/Ch16_Bayes_3.rst:61
msgid ""
"Throughout the report, where relevant, statistically significant changes "
"have been noted. All significance tests have been based on the 95 percent "
"level of confidence. **This means that if a change is noted as being "
"statistically significant, there is a 95 percent probability that a real "
"change has occurred**, and is not simply due to chance variation. (emphasis "
"added)"
msgstr ""
"У всьому звіті, де це доречно, зазначено статистично значущі зміни. Усі "
"тести значущості базуються на рівні достовірності 95 відсотків. **Це "
"означає, що якщо зміна визнана статистично значущою, існує 95-відсоткова "
"ймовірність, що реальна зміна відбулася**, а не є просто випадковою "
"варіацією. (підкреслення додано)"

#: ../../Ch16/Ch16_Bayes_3.rst:68
msgid ""
"Nope! That’s *not* what *p* < 0.05 means. That’s *not* what 95\\% confidence "
"means to a frequentist statistician. The bolded section is just plain wrong. "
"Orthodox methods cannot tell you that “there is a 95\\% chance that a real "
"change has occurred”, because this is not the kind of event to which "
"frequentist probabilities may be assigned. To an ideological frequentist, "
"this sentence should be meaningless. Even if you’re a more pragmatic "
"frequentist, it’s still the wrong definition of a *p*-value. It is simply "
"not an allowed or correct thing to say if you want to rely on orthodox "
"statistical tools."
msgstr ""
"Ні! Це *не* те, що означає *p* < 0,05. Це *не* те, що означає 95\\% довірча "
"ймовірність для статистика-фреквентиста. Виділений жирним шрифтом фрагмент є "
"просто неправильним. Ортодоксальні методи не можуть сказати вам, що «існує "
"95\\% ймовірність того, що відбулася реальна зміна», оскільки це не той вид "
"події, до якого можна застосувати фреквентистські ймовірності. Для "
"ідеологічного частотиста це речення має бути безглуздим. Навіть якщо ви є "
"більш прагматичним частотистом, це все одно неправильне визначення *p*-"
"значення. Це просто неприпустимо і неправильно говорити, якщо ви хочете "
"покладатися на ортодоксальні статистичні інструменти."

#: ../../Ch16/Ch16_Bayes_3.rst:78
msgid ""
"On the other hand, let’s suppose you are a Bayesian. Although the bolded "
"passage is the wrong definition of a *p*-value, it’s pretty much exactly "
"what a Bayesian means when they say that the posterior probability of the "
"alternative hypothesis is greater than 95\\%. And here’s the thing. If the "
"Bayesian posterior is actually the thing you *want* to report, why are you "
"even trying to use orthodox methods? If you want to make Bayesian claims, "
"all you have to do is be a Bayesian and use Bayesian tools."
msgstr ""
"З іншого боку, припустимо, ви є байєсіанцем. Хоча виділений жирним шрифтом "
"фрагмент є неправильним визначенням *p*-значення, це майже точно те, що "
"мають на увазі байєсіанці, коли кажуть, що апостеріорна ймовірність "
"альтернативної гіпотези перевищує 95\\%. І ось у чому справа. Якщо "
"байєсівська апостеріорна ймовірність є тим, про що ви *хочете* повідомити, "
"то навіщо ви взагалі намагаєтеся використовувати ортодоксальні методи? Якщо "
"ви хочете робити байєсівські твердження, все, що вам потрібно зробити, це "
"бути байєсівцем і використовувати байєсівські інструменти."

#: ../../Ch16/Ch16_Bayes_3.rst:87
msgid ""
"Speaking for myself, I found this to be the most liberating thing about "
"switching to the Bayesian view. Once you’ve made the jump, you no longer "
"have to wrap your head around counter-intuitive definitions of *p*-values. "
"You don’t have to bother remembering why you can’t say that you’re 95\\% "
"confident that the true mean lies within some interval. All you have to do "
"is be honest about what you believed before you ran the study and then "
"report what you learned from doing it. Sounds nice, doesn’t it? To me, this "
"is the big promise of the Bayesian approach. You do the analysis you really "
"want to do, and express what you really believe the data are telling you."
msgstr ""
"Що стосується мене, то я вважаю, що це найвигідніша річ у переході на "
"байєсівський підхід. Після того, як ви зробили цей крок, вам більше не "
"доведеться ламати голову над неінтуїтивними визначеннями *p*-значень. Вам не "
"доведеться пам'ятати, чому ви не можете сказати, що на 95 % впевнені, що "
"справжнє середнє значення лежить в межах певного інтервалу. Все, що вам "
"потрібно зробити, це чесно сказати, у що ви вірили до проведення "
"дослідження, а потім повідомити, що ви дізналися в результаті його "
"проведення. Звучить непогано, чи не так? Для мене це велика перевага "
"байєсівського підходу. Ви проводите аналіз, який дійсно хочете провести, і "
"висловлюєте те, що, на вашу думку, дійсно показують дані."

#: ../../Ch16/Ch16_Bayes_3.rst:99
msgid "Evidentiary standards you can believe"
msgstr "Стандарти доказів, яким ви можете довіряти"

#: ../../Ch16/Ch16_Bayes_3.rst:0
msgid ""
"If [*p*] is below 0.02 it is strongly indicated that the [null] hypothesis "
"fails to account for the whole of the facts. We shall not often be astray if "
"we draw a conventional line at 0.05 and consider that [smaller values of "
"*p*] indicate a real discrepancy."
msgstr ""
"Якщо [*p*] менше 0,02, це є вагомою ознакою того, що гіпотеза [null] не "
"враховує всіх фактів. Ми не помилимося, якщо проведемо умовну межу на рівні "
"0,05 і вважатимемо, що [менші значення *p*] вказують на реальну розбіжність."

#: ../../Ch16/Ch16_Bayes_3.rst:109
msgid ":ref:`Sir Ronald Fisher (1925) <Fisher_1925>`"
msgstr ":ref:`Sir Ronald Fisher (1925) <Fisher_1925>`"

#: ../../Ch16/Ch16_Bayes_3.rst:111
msgid ""
"Consider the quote above by Sir Ronald Fisher, one of the founders of what "
"has become the orthodox approach to statistics. If anyone has ever been "
"entitled to express an opinion about the intended function of *p*-values, "
"it’s Fisher. In this passage, taken from his classic guide *Statistical "
"Methods for Research Workers*, he’s pretty clear about what it means to "
"reject a null hypothesis at *p* < 0.05. In his opinion, if we take *p* < "
"0.05 to mean there is “a real effect”, then “we shall not often be astray”. "
"This view is hardly unusual. In my experience, most practitioners express "
"views very similar to Fisher’s. In essence, the *p* < 0.05 convention is "
"assumed to represent a fairly stringent evidential standard."
msgstr ""
"Розглянемо цитату вище, авторства сера Рональда Фішера, одного із "
"засновників того, що стало ортодоксальним підходом до статистики. Якщо хтось "
"і мав право висловлювати думку про передбачувану функцію *p*-значень, то це "
"саме Фішер. У цьому уривку, взятому з його класичного посібника *Статистичні "
"методи для науковців*, він досить чітко пояснює, що означає відхилення "
"нульової гіпотези при *p* < 0,05. На його думку, якщо ми вважаємо, що *p* < "
"0,05 означає «реальний ефект», то «ми не будемо часто помилятися». Ця думка "
"не є чимось незвичайним. З мого досвіду, більшість практиків висловлюють "
"думки, дуже схожі на думку Фішера. По суті, вважається, що угода *p* < 0,05 "
"представляє досить суворий стандарт доказовості."

#: ../../Ch16/Ch16_Bayes_3.rst:123
msgid ""
"Well, how true is that? One way to approach this question is to try to "
"convert *p*-values to Bayes factors, and see how the two compare. It’s not "
"an easy thing to do because a *p*-value is a fundamentally different kind of "
"calculation to a Bayes factor, and they don’t measure the same thing. "
"However, there have been some attempts to work out the relationship between "
"the two, and it’s somewhat surprising. For example, :ref:`Johnson (2013) "
"<Johnson_2013>` presents a pretty compelling case that (for *t*-tests at "
"least) the *p* < 0.05 threshold corresponds roughly to a Bayes factor of "
"somewhere between 3:1 and 5:1 in favour of the alternative. If that’s right, "
"then Fisher’s claim is a bit of a stretch. Let’s suppose that the null "
"hypothesis is true about half the time (i.e., the prior probability of H\\ :"
"sub:`0` is 0.5), and we use those numbers to work out the posterior "
"probability of the null hypothesis given that it has been rejected at *p* < "
"0.05. Using the data from :ref:`Johnson (2013) <Johnson_2013>`, we see that "
"if you reject the null at *p* < 0.05, you’ll be correct about 80\\% of the "
"time. I don’t know about you but, in my opinion, an evidential standard that "
"ensures you’ll be wrong on 20\\% of your decisions isn’t good enough. The "
"fact remains that, quite contrary to Fisher’s claim, if you reject at *p* < "
"0.05 you shall quite often go astray. It’s not a very stringent evidential "
"threshold at all."
msgstr ""
"Ну, наскільки це правда? Один із способів підійти до цього питання — "
"спробувати перетворити *p*-значення на байєсівські коефіцієнти і порівняти "
"їх. Це нелегко, оскільки *p*-значення — це принципово інший вид обчислення, "
"ніж байєсівський коефіцієнт, і вони вимірюють не одне й те саме. Однак були "
"зроблені деякі спроби з'ясувати взаємозв'язок між ними, і результат дещо "
"дивує. Наприклад, :ref:`Johnson (2013) <Johnson_2013>` наводить досить "
"переконливі докази того, що (принаймні для *t*-тестів) поріг *p* < 0,05 "
"приблизно відповідає байєсівському коефіцієнту від 3:1 до 5:1 на користь "
"альтернативи. Якщо це вірно, то твердження Фішера є дещо перебільшеним. "
"Припустимо, що нульова гіпотеза є істинною приблизно в половині випадків ("
"тобто апріорна ймовірність H\\ :sub:`0` дорівнює 0,5), і ми використовуємо "
"ці числа для обчислення апостеріорної ймовірності нульової гіпотези, "
"враховуючи, що вона була відхилена при *p* < 0,05. Використовуючи дані з "
":ref:`Johnson (2013) <Johnson_2013>`, ми бачимо, що якщо ви відхилите "
"нульову гіпотезу при *p* < 0,05, ви будете праві приблизно в 80\\% випадків. "
"Не знаю, як ви, але, на мою думку, стандарт доказовості, який гарантує, що "
"ви помилитеся в 20\\% своїх рішень, не є достатнім. Фактом залишається те, "
"що, всупереч твердженням Фішера, якщо ви відхилите гіпотезу при *p* < 0,05, "
"ви досить часто будете помилятися. Це зовсім не дуже суворий поріг "
"доказовості."

#: ../../Ch16/Ch16_Bayes_3.rst:145
msgid "The *p*-value is a lie."
msgstr "Значення *p* — це брехня."

#: ../../Ch16/Ch16_Bayes_3.rst:0
msgid "*The cake is a lie.*"
msgstr "*Торт — брехня.*"

#: ../../Ch16/Ch16_Bayes_3.rst:154
msgid "`Portal <https://knowyourmeme.com/memes/the-cake-is-a-lie>`__"
msgstr "`Портал <https://knowyourmeme.com/memes/the-cake-is-a-lie>`__"

#: ../../Ch16/Ch16_Bayes_3.rst:157
msgid ""
"Okay, at this point you might be thinking that the real problem is not with "
"orthodox statistics, just the *p* < 0.05 standard. In one sense, that’s "
"true. The recommendation that :ref:`Johnson (2013) <Johnson_2013>` gives is "
"not that “everyone must be a Bayesian now”. Instead, the suggestion is that "
"it would be wiser to shift the conventional standard to something like a *p* "
"< 0.01 level. That’s not an unreasonable view to take, but in my view the "
"problem is a little more severe than that. In my opinion, there’s a fairly "
"big problem built into the way most (but not all) orthodox hypothesis tests "
"are constructed. They are grossly naive about how humans actually do "
"research, and because of this most *p*-values are wrong."
msgstr ""
"Гаразд, на цьому етапі ви, можливо, думаєте, що справжня проблема полягає не "
"в ортодоксальній статистиці, а лише в стандарті *p* < 0,05. В якомусь сенсі "
"це правда. Рекомендація, яку дає :ref:`Johnson (2013) <Johnson_2013>`, "
"полягає не в тому, що «тепер усі повинні бути байєсіанцями». Натомість, вона "
"полягає в тому, що розумніше було б змінити традиційний стандарт на щось на "
"зразок рівня *p* < 0,01. Це не є необґрунтованою думкою, але, на мій погляд, "
"проблема є дещо серйознішою. На мою думку, у способі побудови більшості (але "
"не всіх) ортодоксальних гіпотетичних тестів закладена досить серйозна "
"проблема. Вони надто наївні щодо того, як люди насправді проводять "
"дослідження, і через це більшість значень *p* є неправильними."

#: ../../Ch16/Ch16_Bayes_3.rst:168
msgid ""
"Sounds like an absurd claim, right? Well, consider the following scenario. "
"You’ve come up with a really exciting research hypothesis and you design a "
"study to test it. You’re very diligent, so you run a power analysis to work "
"out what your sample size should be, and you run the study. You run your "
"hypothesis test and out pops a *p*-value of 0.072. Really bloody annoying, "
"right?"
msgstr ""
"Звучить як абсурдне твердження, чи не так? Ну, розгляньте наступний "
"сценарій. Ви придумали дійсно цікаву гіпотезу для дослідження і розробили "
"експеримент, щоб її перевірити. Ви дуже старанні, тому проводите аналіз "
"потужності, щоб визначити, яким має бути розмір вибірки, і проводите "
"дослідження. Ви перевіряєте гіпотезу і отримуєте значення *p* 0,072. Дуже "
"прикро, чи не так?"

#: ../../Ch16/Ch16_Bayes_3.rst:175
msgid "What should you do? Here are some possibilities:"
msgstr "Що вам слід зробити? Ось кілька можливостей:"

#: ../../Ch16/Ch16_Bayes_3.rst:177
msgid ""
"You conclude that there is no effect and try to publish it as a null result"
msgstr ""
"Ви робите висновок, що ефекту немає, і намагаєтеся опублікувати його як "
"нульовий результат"

#: ../../Ch16/Ch16_Bayes_3.rst:180
msgid ""
"You guess that there might be an effect and try to publish it as a "
"“borderline significant” result"
msgstr ""
"Ви здогадуєтеся, що може бути ефект, і намагаєтеся опублікувати його як «"
"межово значний» результат"

#: ../../Ch16/Ch16_Bayes_3.rst:183
msgid "You give up and try a new study"
msgstr "Ви здаєтеся та пробуєте нове навчання"

#: ../../Ch16/Ch16_Bayes_3.rst:185
msgid ""
"You collect some more data to see if the *p*-value goes up or (preferably!) "
"drops below the “magic” criterion of *p* < 0.05"
msgstr ""
"Ви збираєте додаткові дані, щоб побачити, чи значення *p* зростає, або "
"(бажано!) падає нижче «магічного» критерію *p* < 0,05"

#: ../../Ch16/Ch16_Bayes_3.rst:188
msgid ""
"Which would *you* choose? Before reading any further, I urge you to take "
"some time to think about it. Be honest with yourself. But don’t stress about "
"it too much, because you’re screwed no matter what you choose. Based on my "
"own experiences as an author, reviewer and editor, as well as stories I’ve "
"heard from others, here’s what will happen in each case:"
msgstr ""
"Що б *ви* вибрали? Перш ніж читати далі, я закликаю вас подумати над цим. "
"Будьте чесними з собою. Але не переймайтеся надто, бо ви в будь-якому разі "
"провалитеся. Виходячи з мого власного досвіду як автора, рецензента та "
"редактора, а також з історій, які я чув від інших, ось що станеться в "
"кожному випадку:"

#: ../../Ch16/Ch16_Bayes_3.rst:194
msgid ""
"Let’s start with option 1. If you try to publish it as a null result, the "
"paper will struggle to be published. Some reviewers will think that *p* = "
"0.072 is not really a null result. They’ll argue it’s borderline "
"significant. Other reviewers will agree it’s a null result but will claim "
"that even though some null results *are* publishable, yours isn’t. One or "
"two reviewers might even be on your side, but you’ll be fighting an uphill "
"battle to get it through."
msgstr ""
"Почнемо з варіанту 1. Якщо ви спробуєте опублікувати його як нульовий "
"результат, стаття буде важко опублікувати. Деякі рецензенти вважатимуть, що "
"*p* = 0,072 не є насправді нульовим результатом. Вони стверджуватимуть, що "
"це межа значущості. Інші рецензенти погодяться, що це нульовий результат, "
"але стверджуватимуть, що хоча деякі нульові результати *можуть* бути "
"опубліковані, ваш — ні. Один або два рецензенти можуть навіть бути на вашому "
"боці, але вам доведеться вести важку боротьбу, щоб домогтися публікації."

#: ../../Ch16/Ch16_Bayes_3.rst:202
msgid ""
"Okay, let’s think about option number 2. Suppose you try to publish it as a "
"borderline significant result. Some reviewers will claim that it’s a null "
"result and should not be published. Others will claim that the evidence is "
"ambiguous, and that you should collect more data until you get a clear "
"significant result. Again, the publication process does not favour you."
msgstr ""
"Гаразд, давайте розглянемо варіант № 2. Припустимо, ви намагаєтеся "
"опублікувати його як результат, що межує з істотним. Деякі рецензенти "
"стверджуватимуть, що це нульовий результат і його не слід публікувати. Інші "
"стверджуватимуть, що докази є неоднозначними і що вам слід зібрати більше "
"даних, поки не отримаєте чіткий істотний результат. Знову ж таки, процес "
"публікації не на вашу користь."

#: ../../Ch16/Ch16_Bayes_3.rst:209
msgid ""
"Given the difficulties in publishing an “ambiguous” result like *p* = 0.072, "
"option number 3 might seem tempting: give up and do something else. But "
"that’s a recipe for career suicide. If you give up and try a new project "
"every time you find yourself faced with ambiguity, your work will never be "
"published. And if you’re in academia without a publication record you can "
"lose your job. So that option is out."
msgstr ""
"З огляду на труднощі з публікацією «неоднозначного» результату, такого як *p*"
" = 0,072, варіант № 3 може здатися привабливим: здатися і зайнятися чимось "
"іншим. Але це рецепт кар'єрного самогубства. Якщо ви здаєтеся і пробуєте "
"новий проект щоразу, коли стикаєтеся з неоднозначністю, ваша робота ніколи "
"не буде опублікована. А якщо ви працюєте в академічній сфері і не маєте "
"публікацій, ви можете втратити роботу. Тож цей варіант відпадає."

#: ../../Ch16/Ch16_Bayes_3.rst:217
msgid ""
"It looks like you’re stuck with option 4. You don’t have conclusive results, "
"so you decide to collect some more data and re-run the analysis. Seems "
"sensible, but unfortunately for you, if you do this all of your *p*-values "
"are now incorrect. *All* of them. Not just the *p*-values that you "
"calculated for *this* study. All of them. All the *p*-values you calculated "
"in the past and all the *p*-values you will calculate in the future. "
"Fortunately, no-one will notice. You’ll get published, and you’ll have lied."
msgstr ""
"Схоже, ви застрягли на варіанті 4. У вас немає остаточних результатів, тому "
"ви вирішуєте зібрати ще трохи даних і повторити аналіз. Здається розумним, "
"але, на жаль для вас, якщо ви це зробите, всі ваші *p*-значення тепер будуть "
"неправильними. *Всі* вони. Не тільки *p*-значення, які ви обчислили для "
"*цього* дослідження. Всі вони. Всі *p*-значення, які ви обчислили в "
"минулому, і всі *p*-значення, які ви обчислите в майбутньому. На щастя, "
"ніхто цього не помітить. Ваша робота буде опублікована, і ви збрехали."

#: ../../Ch16/Ch16_Bayes_3.rst:226
msgid ""
"Wait, what? How can that last part be true? I mean, it sounds like a "
"perfectly reasonable strategy doesn’t it? You collected some data, the "
"results weren’t conclusive, so now what you want to do is collect more data "
"until the the results *are* conclusive. What’s wrong with that?"
msgstr ""
"Стривайте, що? Як це може бути правдою? Адже це звучить як цілком розумна "
"стратегія, чи не так? Ви зібрали деякі дані, результати не були остаточними, "
"тож тепер ви хочете зібрати більше даних, доки результати не *стануть* "
"остаточними. Що в цьому поганого?"

#: ../../Ch16/Ch16_Bayes_3.rst:231
msgid ""
"Honestly, there’s nothing wrong with it. It’s a reasonable, sensible and "
"rational thing to do. In real life, this is exactly what every researcher "
"does. Unfortunately, the theory of null hypothesis testing as I described it "
"in chapter :doc:`../Ch09/Ch09_HypothesisTesting` *forbids* you from doing "
"this.\\ [#]_ The reason is that the theory assumes that the experiment is "
"finished and all the data are in. And because it assumes the experiment is "
"over, it only considers *two* possible decisions. If you’re using the "
"conventional *p* < 0.05 threshold, those decisions are:"
msgstr ""
"Чесно кажучи, в цьому немає нічого поганого. Це розумне, розсудливе і "
"раціональне рішення. У реальному житті саме так і роблять усі дослідники. На "
"жаль, теорія перевірки нульової гіпотези, яку я описав у розділі :doc:`../"
"Ch09/Ch09_HypothesisTesting`, *забороняє* вам це робити. [#]_ Причина в "
"тому, що теорія припускає, що експеримент завершено і всі дані зібрано. А "
"оскільки вона припускає, що експеримент завершено, вона розглядає лише *два* "
"можливі рішення. Якщо ви використовуєте традиційний поріг *p* < 0,05, ці "
"рішення такі:"

#: ../../Ch16/Ch16_Bayes_3.rst:241 ../../Ch16/Ch16_Bayes_3.rst:255
msgid "Outcome"
msgstr "Результат"

#: ../../Ch16/Ch16_Bayes_3.rst:241 ../../Ch16/Ch16_Bayes_3.rst:255
msgid "Action"
msgstr "Дія"

#: ../../Ch16/Ch16_Bayes_3.rst:243 ../../Ch16/Ch16_Bayes_3.rst:257
msgid "*p* less than 0.05"
msgstr "*p* менше ніж 0.05"

#: ../../Ch16/Ch16_Bayes_3.rst:243
msgid "Reject the null"
msgstr "Відхилити нуль"

#: ../../Ch16/Ch16_Bayes_3.rst:245
msgid "*p* greater than 0.05"
msgstr "*p* більше ніж 0.05"

#: ../../Ch16/Ch16_Bayes_3.rst:245
msgid "Retain the null"
msgstr "Зберегти нульове значення"

#: ../../Ch16/Ch16_Bayes_3.rst:248
msgid ""
"What *you’re* doing is adding a third possible action to the decision making "
"problem. Specifically, what you’re doing is using the *p*-value itself as a "
"reason to justify continuing the experiment. And as a consequence you’ve "
"transformed the decision-making procedure into one that looks more like this:"
msgstr ""
"Ви *додаєте* третю можливу дію до процесу прийняття рішення. А саме, ви "
"використовуєте саме значення *p* як підставу для продовження експерименту. В "
"результаті ви перетворили процедуру прийняття рішення на таку, що виглядає "
"приблизно так:"

#: ../../Ch16/Ch16_Bayes_3.rst:257
msgid "Stop the experiment and reject the null"
msgstr "Зупинити експеримент та відхилити нульове значення"

#: ../../Ch16/Ch16_Bayes_3.rst:259
msgid "*p* between 0.05 and 0.1"
msgstr "*p* між 0,05 та 0,1"

#: ../../Ch16/Ch16_Bayes_3.rst:259
msgid "Continue the experiment"
msgstr "Продовжити експеримент"

#: ../../Ch16/Ch16_Bayes_3.rst:261
msgid "*p* greater than 0.1"
msgstr "*p* більше ніж 0.1"

#: ../../Ch16/Ch16_Bayes_3.rst:261
msgid "Stop the experiment and retain the null"
msgstr "Зупинити експеримент та зберегти нульове значення"

#: ../../Ch16/Ch16_Bayes_3.rst:264
msgid ""
"The “basic” theory of null hypothesis testing isn’t built to handle this "
"sort of thing, not in the form I described back in chapter :doc:`../Ch09/"
"Ch09_HypothesisTesting`. If you’re the kind of person who would choose to "
"“collect more data” in real life, it implies that you are *not* making "
"decisions in accordance with the rules of null hypothesis testing. Even if "
"you happen to arrive at the same decision as the hypothesis test, you aren’t "
"following the decision *process* it implies, and it’s this failure to follow "
"the process that is causing the problem (a `related problem <https://xkcd."
"com/1478>`__). Your *p*-values are a lie."
msgstr ""
"«Базова» теорія перевірки нульової гіпотези не призначена для вирішення "
"таких питань, принаймні не в тому вигляді, який я описав у розділі :doc:`../"
"Ch09/Ch09_HypothesisTesting`. Якщо ви належите до тих людей, які в реальному "
"житті вирішили б «зібрати більше даних», це означає, що ви *не* приймаєте "
"рішення відповідно до правил перевірки нульової гіпотези. Навіть якщо ви "
"прийдете до того самого рішення, що й перевірка гіпотези, ви не дотримуєтеся "
"*процесу* прийняття рішення, який вона передбачає, і саме це недотримання "
"процесу є причиною проблеми (`пов'язана проблема <https://xkcd.com/1478>`__)"
". Ваші *p*-значення є неправдивими."

#: ../../Ch16/Ch16_Bayes_3.rst:274
msgid ""
"Worse yet, they’re a lie in a dangerous way, because they’re all *too "
"small*. To give you a sense of just how bad it can be, consider the "
"following (worst case) scenario. Imagine you’re a really super-enthusiastic "
"researcher on a tight budget who didn’t pay any attention to my warnings "
"above. You design a study comparing two groups. You desperately want to see "
"a significant result at the *p* < 0.05 level, but you really don’t want to "
"collect any more data than you have to (because it’s expensive). In order to "
"cut costs you start collecting data but every time a new observation arrives "
"you run a *t*-test on your data. If the *t*-tests says *p* < 0.05 then you "
"stop the experiment and report a significant result. If not, you keep "
"collecting data. You keep doing this until you reach your pre-defined "
"spending limit for this experiment. Let’s say that limit kicks in at *N* = "
"1000 observations. As it turns out, the truth of the matter is that there is "
"no real effect to be found: the null hypothesis is true. So, what’s the "
"chance that you’ll make it to the end of the experiment and (correctly) "
"conclude that there is no effect? In an ideal world, the answer here should "
"be 95\\%. After all, the whole *point* of the *p* < 0.05 criterion is to "
"control the Type I error rate at 5\\%, so what we’d hope is that there’s "
"only a 5\\% chance of falsely rejecting the null hypothesis in this "
"situation. However, there’s no guarantee that will be true. You’re breaking "
"the rules. Because you’re running tests repeatedly, “peeking” at your data "
"to see if you’ve gotten a significant result, all bets are off."
msgstr ""
"Гірше того, вони є небезпечною брехнею, тому що всі вони *занадто малі*. Щоб "
"ви зрозуміли, наскільки це може бути погано, розгляньте наступний (найгірший)"
" сценарій. Уявіть, що ви дуже ентузіастичний дослідник з обмеженим бюджетом, "
"який не звернув уваги на мої попередження вище. Ви розробляєте дослідження, "
"в якому порівнюєте дві групи. Ви дуже хочете побачити значущий результат на "
"рівні *p* < 0,05, але не хочете збирати більше даних, ніж потрібно (бо це "
"дорого). Щоб скоротити витрати, ви починаєте збирати дані, але щоразу, коли "
"з'являється нове спостереження, ви проводите *t*-тест на ваших даних. Якщо "
"*t*-тест показує *p* < 0,05, ви припиняєте експеримент і повідомляєте про "
"значущий результат. Якщо ні, ви продовжуєте збирати дані. Ви продовжуєте це "
"робити, поки не досягнете заздалегідь визначеного ліміту витрат на цей "
"експеримент. Припустимо, що цей ліміт настає при *N* = 1000 спостереженнях. "
"Як виявляється, насправді ніякого реального ефекту не виявлено: нульова "
"гіпотеза є правдивою. Тож, яка ймовірність того, що ви дійдете до кінця "
"експерименту і (правильно) зробите висновок, що ефекту немає? В ідеальному "
"світі відповідь тут мала б бути 95\\%. Адже вся *суть* критерію *p* < 0,05 "
"полягає в тому, щоб контролювати рівень помилки I типу на рівні 5 %, тому ми "
"сподіваємося, що в цій ситуації ймовірність помилкового відхилення нульової "
"гіпотези становить лише 5 %. Однак немає гарантії, що це буде так. Ви "
"порушуєте правила. Оскільки ви повторно проводите тести, «підглядаючи» у "
"свої дані, щоб перевірити, чи отримали ви значущий результат, усі ставки "
"скасовуються."

#: ../../Ch16/Ch16_Bayes_3.rst:301
msgid "Effect of re-running your tests every time new data arrive"
msgstr "Вплив повторного запуску тестів щоразу, коли надходять нові дані"

#: ../../Ch16/Ch16_Bayes_3.rst:305
msgid ""
"How badly can things go wrong if you re-run your tests every time new data "
"arrive? If you are a frequentist, the answer is “very wrong”."
msgstr ""
"Наскільки погано може піти щось не так, якщо ви перезапускаєте тести щоразу, "
"коли надходять нові дані? Якщо ви часто їх тестуєте, відповідь буде «дуже "
"погано»."

#: ../../Ch16/Ch16_Bayes_3.rst:310
msgid ""
"So how bad is it? The answer is shown as the solid black line in :numref:"
"`fig-adapt`, and it’s *astoundingly* bad. If you peek at your data after "
"every single observation, there is a 49\\% chance that you will make a Type "
"I error. That’s, um, quite a bit bigger than the 5\\% that it’s supposed to "
"be. By way of comparison, imagine that you had used the following strategy. "
"Start collecting data. Every single time an observation arrives, run a :doc:"
"`Ch16_Bayes_5` and look at the Bayes factor. I’ll assume that :ref:`Johnson "
"(2013) <Johnson_2013>` is right, and I’ll treat a Bayes factor of 3:1 as "
"roughly equivalent to a *p*-value of 0.05.\\ [#]_ This time around, our "
"trigger happy researcher uses the following procedure. If the Bayes factor "
"is 3:1 or more in favour of the null, stop the experiment and retain the "
"null. If it is 3:1 or more in favour of the alternative, stop the experiment "
"and reject the null. Otherwise continue testing. Now, just like last time, "
"let’s assume that the null hypothesis is true. What happens? As it happens, "
"I ran the simulations for this scenario too, and the results are shown as "
"the dashed line in :numref:`fig-adapt`. It turns out that the Type I error "
"rate is much much lower than the 49\\% rate that we were getting by using "
"the orthodox *t*-test."
msgstr ""
"Тож наскільки це погано? Відповідь показана чорною суцільною лінією на "
":numref:`fig-adapt`, і вона *вражаюче* погана. Якщо ви переглядаєте свої "
"дані після кожного спостереження, є 49\\% ймовірність, що ви зробите помилку "
"типу I. Це, е-е-е, значно більше, ніж 5\\% , як повинно бути. Для порівняння "
"уявіть, що ви використовували таку стратегію. Почніть збирати дані. Кожного "
"разу, коли з'являється спостереження, запустіть :doc:`Ch16_Bayes_5` і "
"подивіться на коефіцієнт Байєса. Я припущу, що :ref:`Johnson (2013) "
"<Johnson_2013>` має рацію, і буду вважати коефіцієнт Байєса 3:1 приблизно "
"еквівалентним значенню *p* 0,05. [#]_ Цього разу наш дослідник, який любить "
"поспішати, використовує таку процедуру. Якщо коефіцієнт Байєса становить 3:1 "
"або більше на користь нульової гіпотези, експеримент припиняється і нульова "
"гіпотеза зберігається. Якщо він становить 3:1 або більше на користь "
"альтернативної гіпотези, експеримент припиняється і нульова гіпотеза "
"відхиляється. В іншому випадку тестування продовжується. Тепер, як і "
"минулого разу, припустимо, що нульова гіпотеза є правдивою. Що відбувається? "
"Я провів симуляції і для цього сценарію, і результати показані пунктирною "
"лінією на :numref:`fig-adapt`. Виявляється, що рівень помилки I типу "
"набагато нижчий за 49 %, який ми отримували, використовуючи ортодоксальний "
"*t*-тест."

#: ../../Ch16/Ch16_Bayes_3.rst:329
msgid ""
"In some ways, this is remarkable. The entire *point* of orthodox null "
"hypothesis testing is to control the Type I error rate. Bayesian methods "
"aren’t actually designed to do this at all. Yet, as it turns out, when faced "
"with a “trigger happy” researcher who keeps running hypothesis tests as the "
"data come in, the Bayesian approach is much more effective. Even the 3:1 "
"standard, which most Bayesians would consider unacceptably lax, is much "
"safer than the *p* < 0.05 rule."
msgstr ""
"В деякому сенсі це дивно. Вся суть *ортодоксального* тестування нульової "
"гіпотези полягає в контролі рівня помилки I типу. Байєсівські методи "
"насправді зовсім не призначені для цього. Однак, як виявляється, у випадку з "
"«запальним» дослідником, який постійно проводить тестування гіпотез у міру "
"надходження даних, байєсівський підхід є набагато ефективнішим. Навіть "
"стандарт 3:1, який більшість байєсівців вважають неприйнятно м'яким, є "
"набагато безпечнішим, ніж правило *p* < 0,05."

#: ../../Ch16/Ch16_Bayes_3.rst:338
msgid "Is it really this bad?"
msgstr "Невже це справді так погано?"

#: ../../Ch16/Ch16_Bayes_3.rst:340
msgid ""
"The example I gave in the previous section is a pretty extreme situation. In "
"real life, people don’t run hypothesis tests every time a new observation "
"arrives. So it’s not fair to say that the *p* < 0.05 threshold “really” "
"corresponds to a 49\\% Type I error rate (i.e., *p* = 0.49). But the fact "
"remains that if you want your *p*-values to be honest then you either have "
"to switch to a completely different way of doing hypothesis tests or enforce "
"a strict rule of *no peeking*. You are *not* allowed to use the data to "
"decide when to terminate the experiment. You are *not* allowed to look at a "
"“borderline” *p*-value and decide to collect more data. You aren’t even "
"allowed to change your data analysis strategy after looking at data. You are "
"strictly required to follow these rules, otherwise the *p*-values you "
"calculate will be nonsense."
msgstr ""
"Приклад, який я навів у попередньому розділі, є досить екстремальною "
"ситуацією. У реальному житті люди не проводять гіпотетичні тести щоразу, "
"коли з'являється нове спостереження. Тому некоректно стверджувати, що поріг "
"*p* < 0,05 «насправді» відповідає 49\\% рівню помилки типу I (тобто *p* = "
"0,49). Але факт залишається фактом: якщо ви хочете, щоб ваші значення *p* "
"були чесними, то вам доведеться або перейти на зовсім інший спосіб перевірки "
"гіпотез, або дотримуватися суворого правила *не підглядати*. Ви *не* маєте "
"права використовувати дані для прийняття рішення про завершення "
"експерименту. Ви *не* можете дивитися на «граничне» значення *p* і "
"вирішувати збирати більше даних. Ви навіть не можете змінювати свою "
"стратегію аналізу даних після перегляду даних. Ви зобов'язані суворо "
"дотримуватися цих правил, інакше обчислені вами значення *p* будуть "
"безглуздими."

#: ../../Ch16/Ch16_Bayes_3.rst:354
msgid ""
"And yes, these rules are surprisingly strict. As a class exercise a couple "
"of years back, I asked students to think about this scenario. Suppose you "
"started running your study with the intention of collecting *N* = 80 people. "
"When the study starts out you follow the rules, refusing to look at the data "
"or run any tests. But when you reach *N* = 50 your willpower gives in… and "
"you take a peek. Guess what? You’ve got a significant result! Now, sure, you "
"know you *said* that you’d keep running the study out to a sample size of "
"*N* = 80, but it seems sort of pointless now, right? The result is "
"significant with a sample size of *N* = 50, so wouldn’t it be wasteful and "
"inefficient to keep collecting data? Aren’t you tempted to stop? Just a "
"little? Well, keep in mind that if you do, your Type I error rate at *p* < "
"0.05 just ballooned out to 8\\%. When you report *p* < 0.05 in your paper, "
"what you’re *really* saying is *p* < 0.08. That’s how bad the consequences "
"of “just one peek” can be."
msgstr ""
"І так, ці правила напрочуд суворі. Кілька років тому в рамках класного "
"завдання я попросив студентів подумати над таким сценарієм. Припустимо, ви "
"розпочали дослідження з наміром зібрати *N* = 80 осіб. На початку "
"дослідження ви дотримуєтеся правил, відмовляючись переглядати дані або "
"проводити будь-які тести. Але коли ви досягаєте *N* = 50, ваша сила волі "
"слабшає... і ви заглядаєте в дані. І що ж? Ви отримали значущий результат! "
"Звичайно, ви знаєте, що *сказали*, що будете продовжувати дослідження до "
"досягнення розміру вибірки *N* = 80, але зараз це здається безглуздим, чи не "
"так? Результат є значущим при розмірі вибірки *N* = 50, тож чи не буде "
"марним і неефективним продовжувати збирати дані? Чи не виникає у вас спокуса "
"зупинитися? Хоча б трохи? Майте на увазі, що якщо ви це зробите, ваш рівень "
"помилки I типу при *p* < 0,05 просто зріс до 8\\%. Коли ви вказуєте *p* < "
"0,05 у своїй статті, ви *насправді* маєте на увазі *p* < 0,08. Ось такими "
"серйозними можуть бути наслідки «лише одного погляду»."

#: ../../Ch16/Ch16_Bayes_3.rst:370
msgid ""
"Now consider this. The scientific literature is filled with *t*-tests, "
"ANOVAs, regressions and χ²-tests. When I wrote this book I didn’t pick these "
"tests arbitrarily. The reason why these four tools appear in most "
"introductory statistics texts is that these are the bread and butter tools "
"of science. None of these tools include a correction to deal with “data "
"peeking”: they all assume that you’re not doing it. But how realistic is "
"that assumption? In real life, how many people do you think have “peeked” at "
"their data before the experiment was finished and adapted their subsequent "
"behaviour after seeing what the data looked like? Except when the sampling "
"procedure is fixed by an external constraint, I’m guessing the answer is "
"“most people have done it”. If that has happened, you can infer that the "
"reported *p*-values are wrong. Worse yet, because we don’t know what "
"decision process they actually followed, we have no way to know what the *p*-"
"values *should* have been. You can’t compute a *p*-value when you don’t know "
"the decision making procedure that the researcher used. And so the reported "
"*p*-value remains a lie."
msgstr ""
"А тепер подумайте про таке. Наукова література переповнена *t*-тестами, "
"ANOVA, регресіями та χ²-тестами. Коли я писав цю книгу, я не вибирав ці "
"тести довільно. Причина, чому ці чотири інструменти з'являються в більшості "
"вступних текстів зі статистики, полягає в тому, що вони є основними "
"інструментами науки. Жоден з цих інструментів не включає корекцію для роботи "
"з «переглядом даних»: всі вони припускають, що ви цього не робите. Але "
"наскільки реалістичним є це припущення? Як ви думаєте, скільки людей у "
"реальному житті *підглядали* свої дані до закінчення експерименту і "
"адаптували свою подальшу поведінку після того, як побачили, як виглядають "
"дані? За винятком випадків, коли процедура вибірки фіксується зовнішніми "
"обмеженнями, я припускаю, що відповідь буде «більшість людей це робили». "
"Якщо це сталося, ви можете зробити висновок, що заявлені *p*-значення є "
"неправильними. Гірше того, оскільки ми не знаємо, яким процесом прийняття "
"рішень вони насправді керувалися, ми не маємо можливості дізнатися, якими "
"*p*-значення мали бути. Ви не можете обчислити *p*-значення, якщо не знаєте "
"процедуру прийняття рішень, яку використовував дослідник. Отже, заявлене *p*-"
"значення залишається неправдою."

#: ../../Ch16/Ch16_Bayes_3.rst:386
msgid ""
"Given all of the above, what is the take home message? It’s not that "
"Bayesian methods are foolproof. If a researcher is determined to cheat, they "
"can always do so. Bayes’ rule cannot stop people from lying, nor can it stop "
"them from rigging an experiment. That’s not my point here. My point is the "
"same one I made at the very beginning of the book in section :doc:`../Ch01/"
"Ch01_WhyStats_1`: the reason why we run statistical tests is to protect us "
"from ourselves. And the reason why “data peeking” is such a concern is that "
"it’s so tempting, *even for honest researchers*. A theory for statistical "
"inference has to acknowledge this. Yes, you might try to defend *p*-values "
"by saying that it’s the fault of the researcher for not using them properly, "
"but to my mind that misses the point. A theory of statistical inference that "
"is so completely naive about humans that it doesn’t even consider the "
"possibility that the researcher might *look at their own data* isn’t a "
"theory worth having. In essence, my point is this:"
msgstr ""
"З огляду на все вищесказане, який висновок можна зробити? Справа не в тому, "
"що байєсівські методи є надійними. Якщо дослідник вирішив обдурити, він "
"завжди може це зробити. Правило Байєса не може зупинити людей від брехні, як "
"і не може зупинити їх від фальсифікації експерименту. Це не те, про що я "
"говорю. Моя думка така сама, як і на самому початку книги в розділі :doc:`../"
"Ch01/Ch01_WhyStats_1`: ми проводимо статистичні тести, щоб захистити себе "
"від самих себе. А причина, чому «підглядання даних» є такою проблемою, "
"полягає в тому, що це дуже спокусливо, *навіть для чесних дослідників*. "
"Теорія статистичного виведення повинна це визнавати. Так, ви можете "
"спробувати захистити *p*-значення, сказавши, що це вина дослідника, який не "
"використовує їх належним чином, але, на мій погляд, це не має значення. "
"Теорія статистичного виведення, яка настільки наївна щодо людей, що навіть "
"не враховує можливість того, що дослідник може *переглянути власні дані*, не "
"є теорією, яка варта уваги. По суті, моя думка така:"

#: ../../Ch16/Ch16_Bayes_3.rst:0
msgid "*Good laws have their origins in bad morals.*"
msgstr "*Добрі закони беруть свій початок у поганій моралі.*"

#: ../../Ch16/Ch16_Bayes_3.rst:405
msgid "`Ambrosius Macrobius <https://www.quotes.net/quote/20857>`__"
msgstr "`Амвросій Макробій <https://www.quotes.net/quote/20857>`__"

#: ../../Ch16/Ch16_Bayes_3.rst:408
msgid ""
"Good rules for statistical testing have to acknowledge human frailty. None "
"of us are without sin. None of us are beyond temptation. A good system for "
"statistical inference should still work even when it is used by actual "
"humans. Orthodox null hypothesis testing does not.\\ [#]_"
msgstr ""
"Хороші правила статистичного тестування повинні враховувати людську "
"слабкість. Ніхто з нас не є безгрішним. Ніхто з нас не є недосяжним для "
"спокуси. Хороша система статистичного висновку повинна працювати навіть "
"тоді, коли її використовують реальні люди. Ортодоксальне тестування нульової "
"гіпотези цього не робить. [#]_"

#: ../../Ch16/Ch16_Bayes_3.rst:416
msgid ""
"I should note in passing that I’m not the first person to use this quote to "
"complain about frequentist methods. Rich Morey and colleagues had the idea "
"first. I’m shamelessly stealing it because it’s such an awesome pull quote "
"to use in this context and I refuse to miss any opportunity to quote *The "
"Princess Bride*."
msgstr ""
"Слід зазначити, що я не перший, хто використовує цей цитату, щоб "
"поскаржитися на частотні методи. Першими цю ідею запропонували Річ Морі та "
"його колеги. Я безсоромно її запозичую, бо це чудова цитата, яку можна "
"використати в цьому контексті, і я не хочу втрачати жодної нагоди "
"процитувати *Принцесу-наречену*."

#: ../../Ch16/Ch16_Bayes_3.rst:423
msgid ""
"In the interests of being completely honest, I should acknowledge that not "
"all orthodox statistical tests rely on this silly assumption. There are a "
"number of *sequential analysis* tools that are sometimes used in clinical "
"trials and the like. These methods are built on the assumption that data are "
"analysed as they arrive, and these tests aren’t horribly broken in the way "
"I’m complaining about here. However, sequential analysis methods are "
"constructed in a very different fashion to the “standard” version of null "
"hypothesis testing. They don’t make it into any introductory textbooks, and "
"they’re not very widely used in the psychological literature. The concern "
"I’m raising here is valid for every single orthodox test I’ve presented so "
"far and for almost every test I’ve seen reported in the papers I read."
msgstr ""
"Щоб бути повністю чесним, я повинен визнати, що не всі ортодоксальні "
"статистичні тести базуються на цьому безглуздому припущенні. Існує ряд "
"інструментів *послідовного аналізу*, які іноді використовуються в клінічних "
"випробуваннях тощо. Ці методи базуються на припущенні, що дані аналізуються "
"по мірі їх надходження, і ці тести не є настільки жахливими, як я тут "
"скаржуся. Однак методи послідовного аналізу побудовані зовсім інакше, ніж "
"«стандартна» версія тестування нульової гіпотези. Вони не входять до жодного "
"вступного підручника і не дуже широко використовуються в психологічній "
"літературі. Проблема, яку я тут піднімаю, стосується кожного ортодоксального "
"тесту, який я представив до цього моменту, і майже кожного тесту, про який я "
"читав у статтях."

#: ../../Ch16/Ch16_Bayes_3.rst:436
msgid ""
"Some readers might wonder why I picked 3:1 rather than 5:1, given that :ref:"
"`Johnson (2013) <Johnson_2013>` suggests that *p* = 0.05 lies somewhere in "
"that range. I did so in order to be charitable to the *p*-value. If I’d "
"chosen a 5:1 Bayes factor instead, the results would look even better for "
"the Bayesian approach."
msgstr ""
"Деякі читачі можуть задатися питанням, чому я вибрав 3:1, а не 5:1, "
"враховуючи, що :ref:`Johnson (2013) <Johnson_2013>` припускає, що *p* = 0,05 "
"лежить десь у цьому діапазоні. Я зробив це, щоб бути поблажливим до значення "
"*p*. Якби я вибрав коефіцієнт Байєса 5:1, результати були б ще кращими для "
"байєсівського підходу."

#: ../../Ch16/Ch16_Bayes_3.rst:443
msgid ""
"Okay, I just *know* that some knowledgeable frequentists will read this and "
"start complaining about this section. Look, I’m not dumb. I absolutely know "
"that if you adopt a sequential analysis perspective you can avoid these "
"errors within the orthodox framework. I also know that you can explictly "
"design studies with interim analyses in mind. So yes, in one sense I’m "
"attacking a “straw man” version of orthodox methods. However, the straw man "
"that I’m attacking is the one that *is used by almost every single "
"practitioner*. If it ever reaches the point where sequential methods become "
"the norm among experimental psychologists and I’m no longer forced to read "
"20 extremely dubious ANOVAs a day, I promise I’ll rewrite this section and "
"dial down the vitriol. But until that day arrives, I stand by my claim that "
"*default* Bayes factor methods are much more robust in the face of data "
"analysis practices as they exist in the real world. *Default* orthodox "
"methods suck, and we all know it."
msgstr ""
"Гаразд, я просто *знаю*, що деякі обізнані прихильники частотного підходу "
"прочитають це і почнуть скаржитися на цей розділ. Послухайте, я не дурний. Я "
"абсолютно впевнений, що якщо ви приймете послідовний підхід до аналізу, ви "
"зможете уникнути цих помилок в рамках ортодоксальної моделі. Я також знаю, "
"що ви можете чітко розробити дослідження з урахуванням проміжних аналізів. "
"Тож так, в певному сенсі я атакую «солом'яну версію» ортодоксальних методів. "
"Однак солом'яна версія, яку я атакую, — це та, яку *використовують майже всі "
"практикуючі фахівці*. Якщо колись послідовні методи стануть нормою серед "
"експериментальних психологів і я більше не буду змушений читати 20 "
"надзвичайно сумнівних ANOVA на день, я обіцяю переписати цей розділ і "
"зменшити гостроту висловлювань. Але доки цей день не настане, я залишаюся "
"при своїй думці, що *стандартні* методи байєсівського коефіцієнта набагато "
"надійніші в контексті практик аналізу даних, які існують у реальному світі. "
"*Стандартні* ортодоксальні методи — це лажа, і ми всі це знаємо."

#: ../../Ch16/Ch16_Bayes_5.rst:4
msgid "Bayesian *t*-tests"
msgstr "Баєсівські *t*-тести"

#: ../../Ch16/Ch16_Bayes_5.rst:6
msgid ""
"An important type of statistical inference problem discussed in this book is "
"the comparison between two means, discussed in some detail in the chapter on "
"*t*-tests (chapter :doc:`../Ch11/Ch11_tTest`). If you can remember back that "
"far, you’ll recall that there are several versions of the *t*-test. I’ll "
"talk a little about Bayesian versions of the independent samples *t*-tests "
"and the paired samples *t*-test in this section."
msgstr ""
"Важливим типом статистичної інференційної задачі, що розглядається в цій "
"книзі, є порівняння двох середніх значень, яке детально обговорюється в "
"розділі про *t*-тести (розділ :doc:`../Ch11/Ch11_tTest`). Якщо ви "
"пам'ятаєте, то знаєте, що існує кілька версій *t*-тесту. У цьому розділі я "
"трохи розповім про байєсівські версії *t*-тестів для незалежних вибірок та "
"*t*-тестів для парних вибірок."

#: ../../Ch16/Ch16_Bayes_5.rst:14
msgid "Independent samples *t*-test"
msgstr "Незалежні зразки *t*-test"

#: ../../Ch16/Ch16_Bayes_5.rst:16
msgid ""
"The most common type of *t*-test is the independent samples *t*-test, and it "
"arises when you have data as in the |harpo|_ data set that we used in the "
"earlier chapter on *t*-tests (chapter :doc:`../Ch11/Ch11_tTest`). In this "
"data set, we have two groups of students, those who received lessons from "
"Anastasia and those who took their classes with Bernadette. The question we "
"want to answer is whether there’s any difference in the grades received by "
"these two groups of students. Back in that chapter, I suggested you could "
"analyse this kind of data using the Independent Samples *t*-test in jamovi, "
"which gave us the results in :numref:`fig-bayes1`. As we obtain a *p*-value "
"less than 0.05, we reject the null hypothesis."
msgstr ""
"Найпоширенішим типом *t*-тесту є *t*-тест незалежних вибірок, який "
"застосовується, коли ви маєте дані, як у наборі даних |harpo|_, який ми "
"використовували в попередньому розділі про *t*-тести (розділ :doc:`../Ch11/"
"Ch11_tTest`). У цьому наборі даних ми маємо дві групи студентів: тих, хто "
"отримував уроки від Анастасії, і тих, хто відвідував заняття з Бернадеттою. "
"Питання, на яке ми хочемо відповісти, полягає в тому, чи є якась різниця в "
"оцінках, отриманих цими двома групами студентів. У тому розділі я "
"запропонував проаналізувати такі дані за допомогою *t*-тесту незалежних "
"вибірок у jamovi, що дало нам результати, наведені у :numref:`fig-bayes1`. "
"Оскільки ми отримали *p*-значення менше 0,05, ми відхиляємо нульову гіпотезу."

#: ../../Ch16/Ch16_Bayes_5.rst:29 ../../Ch16/Ch16_Bayes_5.rst:33
msgid "``Independent Samples T-Test`` result in jamovi"
msgstr "``Independent Samples T-Test`` призводити до jamovi"

#: ../../Ch16/Ch16_Bayes_5.rst:37
msgid ""
"What does the Bayesian version of the *t*-test look like? We can get the "
"Bayes factor by selecting the ``Bayes Factor`` checkbox under the ``Tests`` "
"option, and accepting the suggested default value for the ``Prior``. This "
"gives the results shown in the table in :numref:`fig-bayes2`. What we get in "
"this table is a Bayes factor statistic of 1.75, meaning that the evidence "
"provided by these data are about 1.8:1 in favour of the alternative "
"hypothesis."
msgstr ""
"Як виглядає байєсівська версія *t*-тесту? Ми можемо отримати байєсівський "
"коефіцієнт, встановивши прапорець ``Bayes Factor`` в опції ``Tests`` і "
"прийнявши запропоноване значення за замовчуванням для ``Prior``. Це дає "
"результати, показані в таблиці в :numref:`fig-bayes2`. У цій таблиці ми "
"отримуємо байєсівський коефіцієнт 1,75, що означає, що докази, надані цими "
"даними, приблизно в 1,8:1 на користь альтернативної гіпотези."

#: ../../Ch16/Ch16_Bayes_5.rst:46 ../../Ch16/Ch16_Bayes_5.rst:50
msgid "``Bayes Factor`` analysis alongside ``Independent Samples T-Test``"
msgstr "``Bayes Factor`` аналіз поряд ``Independent Samples T-Test``"

#: ../../Ch16/Ch16_Bayes_5.rst:54
msgid ""
"Before moving on, it’s worth highlighting the difference between the "
"orthodox test results and the Bayesian one. According to the orthodox test, "
"we obtained a significant result, though only barely. Nevertheless, many "
"people would happily accept *p* = 0.043 as reasonably strong evidence for an "
"effect. In contrast, notice that the Bayesian test doesn’t even reach 2:1 "
"odds in favour of an effect, and would be considered very weak evidence at "
"best. In my experience that’s a pretty typical outcome. Bayesian methods "
"usually require more evidence before rejecting the null."
msgstr ""
"Перш ніж продовжувати, варто підкреслити різницю між результатами "
"ортодоксального тесту та байєсівського. Згідно з ортодоксальним тестом, ми "
"отримали значущий результат, хоча й ледь-ледь. Проте багато хто з радістю "
"прийняв би *p* = 0,043 як досить вагомий доказ ефекту. Натомість, зверніть "
"увагу, що байєсівський тест навіть не досягає співвідношення 2:1 на користь "
"ефекту і в кращому разі вважатиметься дуже слабким доказом. З мого досвіду, "
"це досить типовий результат. Байєсівські методи зазвичай вимагають більше "
"доказів, перш ніж відхилити нульову гіпотезу."

#: ../../Ch16/Ch16_Bayes_5.rst:64
msgid "Paired samples *t*-test"
msgstr "Парні зразки *t*-test"

#: ../../Ch16/Ch16_Bayes_5.rst:66
msgid ""
"Back in section :doc:`../Ch11/Ch11_tTest_05` I discussed the |chico|_ data "
"set in which student grades were measured on two tests, and we were "
"interested in finding out whether grades went up from test 1 to test 2. "
"Because every student did both tests, the tool we used to analyse the data "
"was a paired samples *t*-test. :numref:`fig-bayes3` shows the jamovi results "
"table for the conventional ``Paired Samples T-Test`` alongside the ``Bayes "
"Factor`` analysis. At this point, I hope you can read this output without "
"any difficulty. The data provide evidence of about 6000:1 in favour of the "
"alternative. We could probably reject the null with some confidence!"
msgstr ""
"У розділі :doc:`../Ch11/Ch11_tTest_05` я розглядав набір даних |chico|_, в "
"якому оцінювалися результати студентів за двома тестами, і нас цікавило, чи "
"покращилися оцінки від тесту 1 до тесту 2. Оскільки кожен студент складав "
"обидва тести, для аналізу даних ми використовували *t*-критерій для парних "
"вибірок. :numref:`fig-bayes3` показує таблицю результатів jamovi для "
"звичайного ``T-тесту для парних вибірок`` поряд з аналізом ``фактора Байєса``"
". На цьому етапі я сподіваюся, що ви можете без труднощів прочитати цей "
"результат. Дані надають докази приблизно 6000:1 на користь альтернативи. Ми, "
"ймовірно, можемо відхилити нульову гіпотезу з певною впевненістю!"

#: ../../Ch16/Ch16_Bayes_5.rst:78 ../../Ch16/Ch16_Bayes_5.rst:82
msgid "``Paired Samples T-Test`` and ``Bayes Factor`` result in jamovi"
msgstr "``Paired Samples T-Test`` і ``Bayes Factor`` призводити до jamovi"

#: ../../Ch16/Ch16_Bayes_8.rst:4
msgid "Summary"
msgstr "Короткий зміст"

#: ../../Ch16/Ch16_Bayes_8.rst:6
msgid ""
"The first half of this chapter was focused primarily on the theoretical "
"underpinnings of Bayesian statistics. I introduced the mathematics for how "
"Bayesian inference works (section :doc:`Ch16_Bayes_1`), and gave a very "
"basic overview of how :doc:`Ch16_Bayes_2` are typically done. Finally, I "
"devoted some space to talking about why I think Bayesian methods are worth "
"using (section :doc:`Ch16_Bayes_3`). Then I gave a practical example, a :doc:"
"`Ch16_Bayes_5`."
msgstr ""
"Перша половина цього розділу була присвячена переважно теоретичним основам "
"байєсівської статистики. Я представив математику, на якій базується "
"байєсівське виведення (розділ :doc:`Ch16_Bayes_1`), і дав дуже базовий огляд "
"того, як зазвичай виконуються :doc:`Ch16_Bayes_2`. Насамкінець я присвятив "
"деякий простір обговоренню того, чому, на мою думку, байєсівські методи "
"варті використання (розділ :doc:`Ch16_Bayes_3`). Потім я навів практичний "
"приклад, :doc:`Ch16_Bayes_5`."

#: ../../Ch16/Ch16_Bayes_8.rst:13
msgid ""
"If you’re interested in learning more about the Bayesian approach, there are "
"many good books you could look into. :ref:`John Kruschke’s (2015) "
"<Kruschke_2015>` book *Doing Bayesian Data Analysis* is a pretty good place "
"to start and is a nice mix of theory and practice. His approach is a little "
"different to the “Bayes factor” approach that I’ve discussed here, so you "
"won’t be covering the same ground. If you’re a cognitive psychologist, you "
"might want to check out :ref:`Michael Lee and Eric-Jan Wagenmakers’ (2014) "
"<Lee_2014>` book *Bayesian Cognitive Modeling*. I picked these two because I "
"think they’re especially useful for people in my discipline, but there’s a "
"lot of good books out there, so look around!"
msgstr ""
"Якщо ви хочете дізнатися більше про байєсівський підхід, є багато хороших "
"книг, які ви можете прочитати. :ref:`John Kruschke’s (2015) <Kruschke_2015>` "
"*Doing Bayesian Data Analysis* (Байєсівський аналіз даних) є досить хорошим "
"початком і містить вдале поєднання теорії та практики. Його підхід дещо "
"відрізняється від підходу «фактора Байєса», який я тут обговорював, тому ви "
"не будете повторювати вже вивчене. Якщо ви когнітивний психолог, вам може "
"бути цікава книга :ref:`Michael Lee and Eric-Jan Wagenmakers’ (2014) "
"<Lee_2014>` *Байєсівське когнітивне моделювання*. Я вибрав ці дві книги, "
"тому що вважаю їх особливо корисними для людей моєї спеціальності, але є "
"багато інших хороших книг, тож пошукайте!"
